PMID- 37438534
OWN - NLM
STAT- MEDLINE
DCOM- 20230807
LR  - 20240621
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Print)
IS  - 0028-0836 (Linking)
VI  - 620
IP  - 7972
DP  - 2023 Aug
TI  - Large language models encode clinical knowledge.
PG  - 172-180
LID - 10.1038/s41586-023-06291-2 [doi]
AB  - Large language models (LLMs) have demonstrated impressive capabilities, but the 
      bar for clinical applications is high. Attempts to assess the clinical knowledge 
      of models typically rely on automated evaluations based on limited benchmarks. 
      Here, to address these limitations, we present MultiMedQA, a benchmark combining 
      six existing medical question answering datasets spanning professional medicine, 
      research and consumer queries and a new dataset of medical questions searched 
      online, HealthSearchQA. We propose a human evaluation framework for model answers 
      along multiple axes including factuality, comprehension, reasoning, possible harm 
      and bias. In addition, we evaluate Pathways Language Model(1) (PaLM, a 
      540-billion parameter LLM) and its instruction-tuned variant, Flan-PaLM(2) on 
      MultiMedQA. Using a combination of prompting strategies, Flan-PaLM achieves 
      state-of-the-art accuracy on every MultiMedQA multiple-choice dataset (MedQA(3), 
      MedMCQA(4), PubMedQA(5) and Measuring Massive Multitask Language Understanding 
      (MMLU) clinical topics(6)), including 67.6% accuracy on MedQA (US Medical 
      Licensing Exam-style questions), surpassing the prior state of the art by more 
      than 17%. However, human evaluation reveals key gaps. To resolve this, we 
      introduce instruction prompt tuning, a parameter-efficient approach for aligning 
      LLMs to new domains using a few exemplars. The resulting model, Med-PaLM, 
      performs encouragingly, but remains inferior to clinicians. We show that 
      comprehension, knowledge recall and reasoning improve with model scale and 
      instruction prompt tuning, suggesting the potential utility of LLMs in medicine. 
      Our human evaluations reveal limitations of today's models, reinforcing the 
      importance of both evaluation frameworks and method development in creating safe, 
      helpful LLMs for clinical applications.
CI  - © 2023. The Author(s).
FAU - Singhal, Karan
AU  - Singhal K
AD  - Google Research, Mountain View, CA, USA. karansinghal@google.com.
FAU - Azizi, Shekoofeh
AU  - Azizi S
AUID- ORCID: 0000-0002-7447-6031
AD  - Google Research, Mountain View, CA, USA. shekazizi@google.com.
FAU - Tu, Tao
AU  - Tu T
AD  - Google Research, Mountain View, CA, USA.
FAU - Mahdavi, S Sara
AU  - Mahdavi SS
AD  - Google Research, Mountain View, CA, USA.
FAU - Wei, Jason
AU  - Wei J
AD  - Google Research, Mountain View, CA, USA.
FAU - Chung, Hyung Won
AU  - Chung HW
AD  - Google Research, Mountain View, CA, USA.
FAU - Scales, Nathan
AU  - Scales N
AD  - Google Research, Mountain View, CA, USA.
FAU - Tanwani, Ajay
AU  - Tanwani A
AD  - Google Research, Mountain View, CA, USA.
FAU - Cole-Lewis, Heather
AU  - Cole-Lewis H
AD  - Google Research, Mountain View, CA, USA.
FAU - Pfohl, Stephen
AU  - Pfohl S
AD  - Google Research, Mountain View, CA, USA.
FAU - Payne, Perry
AU  - Payne P
AD  - Google Research, Mountain View, CA, USA.
FAU - Seneviratne, Martin
AU  - Seneviratne M
AD  - Google Research, Mountain View, CA, USA.
FAU - Gamble, Paul
AU  - Gamble P
AD  - Google Research, Mountain View, CA, USA.
FAU - Kelly, Chris
AU  - Kelly C
AUID- ORCID: 0000-0002-1246-844X
AD  - Google Research, Mountain View, CA, USA.
FAU - Babiker, Abubakr
AU  - Babiker A
AD  - Google Research, Mountain View, CA, USA.
FAU - Schärli, Nathanael
AU  - Schärli N
AD  - Google Research, Mountain View, CA, USA.
FAU - Chowdhery, Aakanksha
AU  - Chowdhery A
AD  - Google Research, Mountain View, CA, USA.
FAU - Mansfield, Philip
AU  - Mansfield P
AUID- ORCID: 0000-0003-4969-0543
AD  - Google Research, Mountain View, CA, USA.
FAU - Demner-Fushman, Dina
AU  - Demner-Fushman D
AD  - National Library of Medicine, Bethesda, MD, USA.
FAU - Agüera Y Arcas, Blaise
AU  - Agüera Y Arcas B
AD  - Google Research, Mountain View, CA, USA.
FAU - Webster, Dale
AU  - Webster D
AUID- ORCID: 0000-0002-3023-8824
AD  - Google Research, Mountain View, CA, USA.
FAU - Corrado, Greg S
AU  - Corrado GS
AD  - Google Research, Mountain View, CA, USA.
FAU - Matias, Yossi
AU  - Matias Y
AUID- ORCID: 0000-0003-3960-6002
AD  - Google Research, Mountain View, CA, USA.
FAU - Chou, Katherine
AU  - Chou K
AD  - Google Research, Mountain View, CA, USA.
FAU - Gottweis, Juraj
AU  - Gottweis J
AD  - Google Research, Mountain View, CA, USA.
FAU - Tomasev, Nenad
AU  - Tomasev N
AUID- ORCID: 0000-0003-1624-0220
AD  - DeepMind, London, UK.
FAU - Liu, Yun
AU  - Liu Y
AUID- ORCID: 0000-0003-4079-8275
AD  - Google Research, Mountain View, CA, USA.
FAU - Rajkomar, Alvin
AU  - Rajkomar A
AD  - Google Research, Mountain View, CA, USA.
FAU - Barral, Joelle
AU  - Barral J
AD  - Google Research, Mountain View, CA, USA.
FAU - Semturs, Christopher
AU  - Semturs C
AUID- ORCID: 0000-0001-6108-2773
AD  - Google Research, Mountain View, CA, USA.
FAU - Karthikesalingam, Alan
AU  - Karthikesalingam A
AD  - Google Research, Mountain View, CA, USA. alankarthi@google.com.
FAU - Natarajan, Vivek
AU  - Natarajan V
AD  - Google Research, Mountain View, CA, USA. natviv@google.com.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20230712
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
EIN - Nature. 2023 Aug;620(7973):E19. doi: 10.1038/s41586-023-06455-0. PMID: 37500979
MH  - *Benchmarking
MH  - Bias
MH  - Clinical Competence
MH  - Comprehension
MH  - *Computer Simulation
MH  - Datasets as Topic
MH  - *Knowledge
MH  - Licensure
MH  - *Medicine/methods/standards
MH  - *Natural Language Processing
MH  - Patient Safety
MH  - Physicians
PMC - PMC10396962
COIS- This study was funded by Alphabet Inc. and/or a subsidiary thereof (Alphabet). 
      K.S., S.A., T.T., V.N., A.K., S.S.M., C.S., J.W., H.W.C., N. Scales, A.T., 
      H.C.-L., S.P., P.P., M.S., P.G., C.K., A.B., N. Schärli, A.C., P.M., B.A.A., 
      D.W., G.S.C., Y.M., K.C., J.G., A.R., N.T., J.B. and Y.L. are employees of 
      Alphabet and may own stock as part of the standard compensation package. D.D.-F. 
      is affiliated with the US National Library of Medicine.
EDAT- 2023/07/13 01:06
MHDA- 2023/08/04 06:43
PMCR- 2023/07/12
CRDT- 2023/07/12 23:31
PHST- 2023/01/25 00:00 [received]
PHST- 2023/06/05 00:00 [accepted]
PHST- 2023/08/04 06:43 [medline]
PHST- 2023/07/13 01:06 [pubmed]
PHST- 2023/07/12 23:31 [entrez]
PHST- 2023/07/12 00:00 [pmc-release]
AID - 10.1038/s41586-023-06291-2 [pii]
AID - 6291 [pii]
AID - 10.1038/s41586-023-06291-2 [doi]
PST - ppublish
SO  - Nature. 2023 Aug;620(7972):172-180. doi: 10.1038/s41586-023-06291-2. Epub 2023 
      Jul 12.

PMID- 37566454
OWN - NLM
STAT- MEDLINE
DCOM- 20230828
LR  - 20241007
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Aug 11
TI  - Ethical Considerations of Using ChatGPT in Health Care.
PG  - e48009
LID - 10.2196/48009 [doi]
LID - e48009
AB  - ChatGPT has promising applications in health care, but potential ethical issues 
      need to be addressed proactively to prevent harm. ChatGPT presents potential 
      ethical challenges from legal, humanistic, algorithmic, and informational 
      perspectives. Legal ethics concerns arise from the unclear allocation of 
      responsibility when patient harm occurs and from potential breaches of patient 
      privacy due to data collection. Clear rules and legal boundaries are needed to 
      properly allocate liability and protect users. Humanistic ethics concerns arise 
      from the potential disruption of the physician-patient relationship, humanistic 
      care, and issues of integrity. Overreliance on artificial intelligence (AI) can 
      undermine compassion and erode trust. Transparency and disclosure of AI-generated 
      content are critical to maintaining integrity. Algorithmic ethics raise concerns 
      about algorithmic bias, responsibility, transparency and explainability, as well 
      as validation and evaluation. Information ethics include data bias, validity, and 
      effectiveness. Biased training data can lead to biased output, and overreliance 
      on ChatGPT can reduce patient adherence and encourage self-diagnosis. Ensuring 
      the accuracy, reliability, and validity of ChatGPT-generated content requires 
      rigorous validation and ongoing updates based on clinical practice. To navigate 
      the evolving ethical landscape of AI, AI in health care must adhere to the 
      strictest ethical standards. Through comprehensive ethical guidelines, health 
      care professionals can ensure the responsible use of ChatGPT, promote accurate 
      and reliable information exchange, protect patient privacy, and empower patients 
      to make informed decisions about their health care.
CI  - ©Changyu Wang, Siru Liu, Hao Yang, Jiulin Guo, Yuxuan Wu, Jialin Liu. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      11.08.2023.
FAU - Wang, Changyu
AU  - Wang C
AUID- ORCID: 0000-0003-4548-331X
AD  - Department of Medical Informatics, West China Medical School, Sichuan University, 
      Chengdu, China.
AD  - West China College of Stomatology, Sichuan University, Chengdu, China.
FAU - Liu, Siru
AU  - Liu S
AUID- ORCID: 0000-0002-5003-5354
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, United States.
FAU - Yang, Hao
AU  - Yang H
AUID- ORCID: 0000-0002-3505-9403
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
FAU - Guo, Jiulin
AU  - Guo J
AUID- ORCID: 0009-0006-5995-8290
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
FAU - Wu, Yuxuan
AU  - Wu Y
AUID- ORCID: 0000-0003-1333-4627
AD  - Department of Medical Informatics, West China Medical School, Sichuan University, 
      Chengdu, China.
FAU - Liu, Jialin
AU  - Liu J
AUID- ORCID: 0000-0002-1369-4625
AD  - Department of Medical Informatics, West China Medical School, Sichuan University, 
      Chengdu, China.
AD  - Information Center, West China Hospital, Sichuan University, Chengdu, China.
AD  - Department of Otolaryngology-Head and Neck Surgery, West China Hospital, Sichuan 
      University, Chengdu, China.
LA  - eng
PT  - Journal Article
DEP - 20230811
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Data Collection
MH  - *Disclosure
MH  - Patient Compliance
PMC - PMC10457697
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - algorithm
OT  - artificial intelligence
OT  - artificial intelligence development
OT  - development
OT  - ethics
OT  - health care
OT  - large language models
OT  - patient privacy
OT  - patient safety
OT  - privacy
OT  - safety
COIS- Conflicts of Interest: None declared.
EDAT- 2023/08/11 12:42
MHDA- 2023/08/28 06:42
PMCR- 2023/08/11
CRDT- 2023/08/11 11:53
PHST- 2023/04/07 00:00 [received]
PHST- 2023/07/25 00:00 [accepted]
PHST- 2023/07/05 00:00 [revised]
PHST- 2023/08/28 06:42 [medline]
PHST- 2023/08/11 12:42 [pubmed]
PHST- 2023/08/11 11:53 [entrez]
PHST- 2023/08/11 00:00 [pmc-release]
AID - v25i1e48009 [pii]
AID - 10.2196/48009 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Aug 11;25:e48009. doi: 10.2196/48009.

PMID- 37824352
OWN - NLM
STAT- MEDLINE
DCOM- 20231101
LR  - 20231115
IS  - 1972-2680 (Electronic)
IS  - 1972-2680 (Linking)
VI  - 17
IP  - 9
DP  - 2023 Sep 30
TI  - ChatGPT: ethical concerns and challenges in academics and research.
PG  - 1292-1299
LID - 10.3855/jidc.18738 [doi]
AB  - INTRODUCTION: The emergence of artificial intelligence (AI) has presented several 
      opportunities to ease human work. AI applications are available for almost every 
      domain of life. A new technology, Chat Generative Pre-Trained Transformer 
      (ChatGPT), was introduced by OpenAI in November 2022, and has become a topic of 
      discussion across the world. ChatGPT-3 has brought many opportunities, as well as 
      ethical and privacy considerations. ChatGPT is a large language model (LLM) which 
      has been trained on the events that happened until 2021. The use of AI and its 
      assisted technologies in scientific writing is against research and publication 
      ethics. Therefore, policies and guidelines need to be developed over the use of 
      such tools in scientific writing. The main objective of the present study was to 
      highlight the use of AI and AI assisted technologies such as the ChatGPT and 
      other chatbots in the scientific writing and in the research domain resulting in 
      bias, spread of inaccurate information and plagiarism. METHODOLOGY: Experiments 
      were designed to test the accuracy of ChatGPT when used in research and academic 
      writing. RESULTS: The information provided by ChatGPT was inaccurate and may have 
      far-reaching implications in the field of medical science and engineering. 
      Critical thinking should be encouraged among researchers to raise awareness about 
      the associated privacy and ethical risks. CONCLUSIONS: Regulations for ethical 
      and privacy concerns related to the use of ChatGPT in academics and research need 
      to be developed.
CI  - Copyright (c) 2023 Ankita Guleria, Kewal Krishan, Vishal Sharma, Tanuj Kanchan.
FAU - Guleria, Ankita
AU  - Guleria A
AD  - Department of Anthropology, Panjab University, Sector-14, Chandigarh, India.
FAU - Krishan, Kewal
AU  - Krishan K
AD  - Department of Anthropology, Panjab University, Sector-14, Chandigarh, India.
FAU - Sharma, Vishal
AU  - Sharma V
AD  - Institute of Forensic Science and Criminology, Panjab University, Sector-14, 
      Chandigarh, India.
FAU - Kanchan, Tanuj
AU  - Kanchan T
AD  - Department of Forensic Medicine and Toxicology, All India Institute of Medical 
      Sciences, Jodhpur, India.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230930
PL  - Italy
TA  - J Infect Dev Ctries
JT  - Journal of infection in developing countries
JID - 101305410
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Organizations
OTO - NOTNLM
OT  - ChatGPT
OT  - Open AI
OT  - artificial intelligence
OT  - chatbot
OT  - privacy concerns
OT  - publication ethics
COIS- No Conflict of Interest is declared
EDAT- 2023/10/12 18:42
MHDA- 2023/11/01 12:44
CRDT- 2023/10/12 12:43
PHST- 2023/06/14 00:00 [received]
PHST- 2023/07/12 00:00 [accepted]
PHST- 2023/11/01 12:44 [medline]
PHST- 2023/10/12 18:42 [pubmed]
PHST- 2023/10/12 12:43 [entrez]
AID - 10.3855/jidc.18738 [doi]
PST - epublish
SO  - J Infect Dev Ctries. 2023 Sep 30;17(9):1292-1299. doi: 10.3855/jidc.18738.

PMID- 37874780
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240927
IS  - 2767-3170 (Electronic)
IS  - 2767-3170 (Linking)
VI  - 2
IP  - 10
DP  - 2023 Oct
TI  - Centering health equity in large language model deployment.
PG  - e0000367
LID - 10.1371/journal.pdig.0000367 [doi]
LID - e0000367
FAU - Singh, Nina
AU  - Singh N
AUID- ORCID: 0000-0002-4623-2451
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, New York, United States of America.
FAU - Lawrence, Katharine
AU  - Lawrence K
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, New York, United States of America.
FAU - Richardson, Safiya
AU  - Richardson S
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, New York, United States of America.
FAU - Mann, Devin M
AU  - Mann DM
AD  - Department of Population Health, New York University Grossman School of Medicine, 
      New York, New York, United States of America.
AD  - Medical Center Information Technology, New York University Langone Health, New 
      York, New York, United States of America.
LA  - eng
GR  - K23 HL145114/HL/NHLBI NIH HHS/United States
PT  - Journal Article
DEP - 20231024
PL  - United States
TA  - PLOS Digit Health
JT  - PLOS digital health
JID - 9918335064206676
PMC - PMC10597518
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/24 18:42
MHDA- 2023/10/24 18:43
PMCR- 2023/10/24
CRDT- 2023/10/24 13:22
PHST- 2023/10/24 18:43 [medline]
PHST- 2023/10/24 18:42 [pubmed]
PHST- 2023/10/24 13:22 [entrez]
PHST- 2023/10/24 00:00 [pmc-release]
AID - PDIG-D-23-00181 [pii]
AID - 10.1371/journal.pdig.0000367 [doi]
PST - epublish
SO  - PLOS Digit Health. 2023 Oct 24;2(10):e0000367. doi: 10.1371/journal.pdig.0000367. 
      eCollection 2023 Oct.

PMID- 37261894
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230619
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Jun 1
TI  - Large Language Models in Medical Education: Opportunities, Challenges, and Future 
      Directions.
PG  - e48291
LID - 10.2196/48291 [doi]
LID - e48291
AB  - The integration of large language models (LLMs), such as those in the Generative 
      Pre-trained Transformers (GPT) series, into medical education has the potential 
      to transform learning experiences for students and elevate their knowledge, 
      skills, and competence. Drawing on a wealth of professional and academic 
      experience, we propose that LLMs hold promise for revolutionizing medical 
      curriculum development, teaching methodologies, personalized study plans and 
      learning materials, student assessments, and more. However, we also critically 
      examine the challenges that such integration might pose by addressing issues of 
      algorithmic bias, overreliance, plagiarism, misinformation, inequity, privacy, 
      and copyright concerns in medical education. As we navigate the shift from an 
      information-driven educational paradigm to an artificial intelligence (AI)-driven 
      educational paradigm, we argue that it is paramount to understand both the 
      potential and the pitfalls of LLMs in medical education. This paper thus offers 
      our perspective on the opportunities and challenges of using LLMs in this 
      context. We believe that the insights gleaned from this analysis will serve as a 
      foundation for future recommendations and best practices in the field, fostering 
      the responsible and effective use of AI technologies in medical education.
CI  - ©Alaa Abd-alrazaq, Rawan AlSaad, Dari Alhuwail, Arfan Ahmed, Padraig Mark Healy, 
      Syed Latifi, Sarah Aziz, Rafat Damseh, Sadam Alabed Alrazak, Javaid Sheikh. 
      Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      01.06.2023.
FAU - Abd-Alrazaq, Alaa
AU  - Abd-Alrazaq A
AUID- ORCID: 0000-0001-7695-4626
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
FAU - AlSaad, Rawan
AU  - AlSaad R
AUID- ORCID: 0000-0002-3235-0860
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
AD  - College of Computing and Information Technology, University of Doha for Science 
      and Technology, Doha, Qatar.
FAU - Alhuwail, Dari
AU  - Alhuwail D
AUID- ORCID: 0000-0001-5038-3044
AD  - Information Science Department, College of Life Sciences, Kuwait University, 
      Kuwait, Kuwait.
FAU - Ahmed, Arfan
AU  - Ahmed A
AUID- ORCID: 0000-0002-4025-5767
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
FAU - Healy, Padraig Mark
AU  - Healy PM
AUID- ORCID: 0000-0002-5804-0342
AD  - Office of Educational Development, Division of Medical Education, Weill Cornell 
      Medicine-Qatar, Doha, Qatar.
FAU - Latifi, Syed
AU  - Latifi S
AUID- ORCID: 0000-0003-0505-609X
AD  - Office of Educational Development, Division of Medical Education, Weill Cornell 
      Medicine-Qatar, Doha, Qatar.
FAU - Aziz, Sarah
AU  - Aziz S
AUID- ORCID: 0000-0002-0861-9743
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
FAU - Damseh, Rafat
AU  - Damseh R
AUID- ORCID: 0000-0001-6797-0448
AD  - Department of Computer Science and Software Engineering, United Arab Emirates 
      University, Abu Dhabi, United Arab Emirates.
FAU - Alabed Alrazak, Sadam
AU  - Alabed Alrazak S
AUID- ORCID: 0000-0002-8586-7564
AD  - Department of Mechanical & Industrial Engineering, Faculty of Applied Science and 
      Engineering, University of Toronto, Toronto, ON, Canada.
FAU - Sheikh, Javaid
AU  - Sheikh J
AUID- ORCID: 0000-0002-5762-4186
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
LA  - eng
PT  - Journal Article
DEP - 20230601
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10273039
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT-4
OT  - artificial intelligence
OT  - educators
OT  - generative AI
OT  - large language models
OT  - medical education
OT  - students
COIS- Conflicts of Interest: A Abd-alrazaq is an Associate Editor of JMIR Nursing at 
      the time of this publication. The other authors have no conflicts of interest to 
      declare.
EDAT- 2023/06/01 13:09
MHDA- 2023/06/01 13:10
PMCR- 2023/06/01
CRDT- 2023/06/01 11:53
PHST- 2023/04/19 00:00 [received]
PHST- 2023/05/17 00:00 [accepted]
PHST- 2023/05/15 00:00 [revised]
PHST- 2023/06/01 13:10 [medline]
PHST- 2023/06/01 13:09 [pubmed]
PHST- 2023/06/01 11:53 [entrez]
PHST- 2023/06/01 00:00 [pmc-release]
AID - v9i1e48291 [pii]
AID - 10.2196/48291 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Jun 1;9:e48291. doi: 10.2196/48291.

PMID- 39974299
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250222
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 17
IP  - 2
DP  - 2025 Feb
TI  - DeepSeek in Healthcare: Revealing Opportunities and Steering Challenges of a New 
      Open-Source Artificial Intelligence Frontier.
PG  - e79221
LID - 10.7759/cureus.79221 [doi]
LID - e79221
AB  - Generative Artificial Intelligence (GAI) has driven several advancements in 
      healthcare, with large language models (LLMs) such as OpenAI's ChatGPT, Google's 
      Gemini, and Microsoft's Copilot demonstrating potential in clinical decision 
      support, medical education, and research acceleration. However, their 
      closed-source architecture, high computational costs, and limited adaptability to 
      specialized medical contexts remained key barriers to universal adoption. Now, 
      with the rise of DeepSeek's DeepThink (R1), an open-source LLM, gaining 
      prominence since mid-January 2025, new opportunities and challenges emerge for 
      healthcare integration and AI-driven research. Unlike proprietary models, 
      DeepSeek fosters continuous learning by leveraging publicly available open-source 
      datasets, possibly enhancing adaptability to the ever-evolving medical knowledge 
      and scientific reasoning. Its transparent, community-driven approach may enable 
      greater customization, regional specialization, and collaboration among data 
      researchers and clinicians. Additionally, DeepSeek supports offline deployment, 
      addressing some data privacy concerns. Despite these promising advantages, 
      DeepSeek presents ethical and regulatory challenges. Users' data privacy worries 
      have emerged, with concerns about user data retention policies and potential 
      developer access to user-generated content without opt-out options. Additionally, 
      when used in healthcare applications, its compliance with China's data-sharing 
      regulations highlights the urgent need for clear international data privacy and 
      governance. Furthermore, like other LLMs, DeepSeek may face limitations related 
      to inherent biases, hallucinations, and output reliability, which warrants 
      rigorous validation and human oversight before clinical application. This 
      editorial explores DeepSeek's potential role in clinical workflows, medical 
      education, and research while also highlighting its challenges related to 
      security, accuracy, and responsible AI governance. With careful implementation, 
      ethical considerations, and international collaboration, DeepSeek and similar 
      LLMs could enhance healthcare innovation, providing cost-effective, scalable AI 
      solutions while ensuring human expertise remains at the forefront of patient 
      care.
CI  - Copyright © 2025, Temsah et al.
FAU - Temsah, Abdulrahman
AU  - Temsah A
AD  - Software Engineering, Alfaisal University, Riyadh, SAU.
FAU - Alhasan, Khalid
AU  - Alhasan K
AD  - Pediatric Department, College of Medicine, King Saud University, Riyadh, SAU.
AD  - Kidney and Pancreas Health Center, Organ Transplant Center of Excellence, King 
      Faisal Specialist Hospital and Research Center, Riyadh, SAU.
FAU - Altamimi, Ibraheem
AU  - Altamimi I
AD  - Evidence-Based Research Chair, Family and Community Medicine, College of 
      Medicine, King Saud University, Riyadh, SAU.
FAU - Jamal, Amr
AU  - Jamal A
AD  - Evidence-Based Research Chair, Family and Community Medicine, College of 
      Medicine, King Saud University, Riyadh, SAU.
FAU - Al-Eyadhy, Ayman
AU  - Al-Eyadhy A
AD  - Pediatric Department, College of Medicine, King Saud University, Riyadh, SAU.
AD  - Pediatric Intensive Care Unit, Pediatric Department, King Saud University Medical 
      City, Riyadh, SAU.
FAU - Malki, Khalid H
AU  - Malki KH
AD  - Research Chair of Voice, Swallowing, and Communication Disorders, Department of 
      Otolaryngology-Head and Neck Surgery, College of Medicine, King Saud University, 
      Riyadh, SAU.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - Pediatric Department, College of Medicine, King Saud University, Riyadh, SAU.
AD  - Evidence-Based Research Chair, Family and Community Medicine, College of 
      Medicine, King Saud University, Riyadh, SAU.
AD  - Pediatric Intensive Care Unit, Pediatric Department, King Saud University Medical 
      City, Riyadh, SAU.
LA  - eng
PT  - Editorial
DEP - 20250218
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11836063
OTO - NOTNLM
OT  - ai hallucinations and bias in medicine
OT  - deepseek deepthink r1 open-source ai
OT  - ethical considerations in ai-driven healthcare
OT  - generative artificial intelligence (gai) in healthcare
OT  - healthcare data privacy and ai compliance
OT  - hipaa and gdpr ai compliance
OT  - large language models (llms) in medicine
OT  - medical education and ai integration
OT  - offline ai deployment for healthcare
OT  - open-source ai for medical research
COIS- Conflicts of interest: In compliance with the ICMJE uniform disclosure form, all 
      authors declare the following: Payment/services info: All authors have declared 
      that no financial support was received from any organization for the submitted 
      work. Financial relationships: All authors have declared that they have no 
      financial relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2025/02/20 06:22
MHDA- 2025/02/20 06:23
PMCR- 2025/02/18
CRDT- 2025/02/20 05:28
PHST- 2025/02/18 00:00 [accepted]
PHST- 2025/02/20 06:23 [medline]
PHST- 2025/02/20 06:22 [pubmed]
PHST- 2025/02/20 05:28 [entrez]
PHST- 2025/02/18 00:00 [pmc-release]
AID - 10.7759/cureus.79221 [doi]
PST - epublish
SO  - Cureus. 2025 Feb 18;17(2):e79221. doi: 10.7759/cureus.79221. eCollection 2025 
      Feb.

PMID- 37515957
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20230814
IS  - 1532-2793 (Electronic)
IS  - 0260-6917 (Linking)
VI  - 129
DP  - 2023 Oct
TI  - Revolutionizing nursing education through Ai integration: A reflection on the 
      disruptive impact of ChatGPT.
PG  - 105916
LID - S0260-6917(23)00210-1 [pii]
LID - 10.1016/j.nedt.2023.105916 [doi]
AB  - Artificial intelligence (AI) is driving global change. An AI language model like 
      ChatGPT could revolutionize the delivery of nursing education in the future. 
      ChatGPT is an AI-enabled text generator that has garnered significant attention 
      due to its ability to engage in conversations and answer questions. Nurse 
      educators play a crucial role in preparing nursing students for a 
      technology-integrated healthcare system, and the emergence of ChatGPT presents 
      both opportunities and challenges. While the technology has limitations and 
      potential biases, it also has the potential to benefit students by facilitating 
      learning, improving digital literacy, and encouraging critical thinking about AI 
      integration in healthcare. Nurse educators can incorporate ChatGPT into their 
      curriculum through formative or summative assessments and should prioritize 
      faculty development to understand and use AI technologies effectively. 
      Collaboration between educational institutions, regulatory bodies, and educators 
      is crucial to establish provincial and national competencies and frameworks that 
      reflect the increasing importance of AI in nursing education and practice. It is 
      paramount that nurses and nurse educators be open to AI-enabled innovations as 
      well as continue to critically think about their potential value to advance the 
      profession so nurses are better prepared to lead the digital future.
CI  - Copyright © 2023 Elsevier Ltd. All rights reserved.
FAU - Castonguay, Alexandre
AU  - Castonguay A
AD  - University of Montreal, Nursing Faculty, Marguerite-d'Youville Campus, C.P. 6128 
      succ. Centre-ville, Montréal, Québec H3C 3J7, Canada. Electronic address: 
      alexandre.castonguay.2@umontreal.ca.
FAU - Farthing, Pamela
AU  - Farthing P
AD  - Saskatchewan Polytechnic, Faculty, School of Nursing, SCBScN, Canada. Electronic 
      address: pamela.farthing@saskpolytech.ca.
FAU - Davies, Shauna
AU  - Davies S
AD  - University of Regina, Canada. Electronic address: shauna.davies@uregina.ca.
FAU - Vogelsang, Laura
AU  - Vogelsang L
AD  - University of Lethbridge, Faculty of Health Sciences, Canada. Electronic address: 
      laura.vogelsang@uleth.ca.
FAU - Kleib, Manal
AU  - Kleib M
AD  - University of Alberta, Faculty of Nursing, Canada. Electronic address: 
      manal.kleib@ualberta.ca.
FAU - Risling, Tracie
AU  - Risling T
AD  - University of Calgary, Faculty of Nursing, Canada. Electronic address: 
      tracie.risling@ucalgary.ca.
FAU - Green, Nadia
AU  - Green N
AD  - University of Alberta, Faculty of Nursing, Canada. Electronic address: 
      ntgreen@ualberta.ca.
LA  - eng
PT  - Journal Article
DEP - 20230718
PL  - Scotland
TA  - Nurse Educ Today
JT  - Nurse education today
JID - 8511379
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Nursing
MH  - Curriculum
MH  - Delivery of Health Care
MH  - Learning
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Authorship
OT  - Health knowledge, attitudes, practice
OT  - Nursing education research
OT  - Nursing informatics
OT  - Nursing students
OT  - Social responsibility
COIS- Declaration of competing interest The authors declare that they have no 
      conflicting interests.
EDAT- 2023/07/30 01:06
MHDA- 2023/08/14 06:42
CRDT- 2023/07/29 18:06
PHST- 2023/03/03 00:00 [received]
PHST- 2023/06/06 00:00 [revised]
PHST- 2023/07/17 00:00 [accepted]
PHST- 2023/08/14 06:42 [medline]
PHST- 2023/07/30 01:06 [pubmed]
PHST- 2023/07/29 18:06 [entrez]
AID - S0260-6917(23)00210-1 [pii]
AID - 10.1016/j.nedt.2023.105916 [doi]
PST - ppublish
SO  - Nurse Educ Today. 2023 Oct;129:105916. doi: 10.1016/j.nedt.2023.105916. Epub 2023 
      Jul 18.

PMID- 38776081
OWN - NLM
STAT- MEDLINE
DCOM- 20240522
LR  - 20250211
IS  - 2574-3805 (Electronic)
IS  - 2574-3805 (Linking)
VI  - 7
IP  - 5
DP  - 2024 May 1
TI  - Assessing the Risk of Bias in Randomized Clinical Trials With Large Language 
      Models.
PG  - e2412687
LID - 10.1001/jamanetworkopen.2024.12687 [doi]
LID - e2412687
AB  - IMPORTANCE: Large language models (LLMs) may facilitate the labor-intensive 
      process of systematic reviews. However, the exact methods and reliability remain 
      uncertain. OBJECTIVE: To explore the feasibility and reliability of using LLMs to 
      assess risk of bias (ROB) in randomized clinical trials (RCTs). DESIGN, SETTING, 
      AND PARTICIPANTS: A survey study was conducted between August 10, 2023, and 
      October 30, 2023. Thirty RCTs were selected from published systematic reviews. 
      MAIN OUTCOMES AND MEASURES: A structured prompt was developed to guide ChatGPT 
      (LLM 1) and Claude (LLM 2) in assessing the ROB in these RCTs using a modified 
      version of the Cochrane ROB tool developed by the CLARITY group at McMaster 
      University. Each RCT was assessed twice by both models, and the results were 
      documented. The results were compared with an assessment by 3 experts, which was 
      considered a criterion standard. Correct assessment rates, sensitivity, 
      specificity, and F1 scores were calculated to reflect accuracy, both overall and 
      for each domain of the Cochrane ROB tool; consistent assessment rates and Cohen κ 
      were calculated to gauge consistency; and assessment time was calculated to 
      measure efficiency. Performance between the 2 models was compared using risk 
      differences. RESULTS: Both models demonstrated high correct assessment rates. LLM 
      1 reached a mean correct assessment rate of 84.5% (95% CI, 81.5%-87.3%), and LLM 
      2 reached a significantly higher rate of 89.5% (95% CI, 87.0%-91.8%). The risk 
      difference between the 2 models was 0.05 (95% CI, 0.01-0.09). In most domains, 
      domain-specific correct rates were around 80% to 90%; however, sensitivity below 
      0.80 was observed in domains 1 (random sequence generation), 2 (allocation 
      concealment), and 6 (other concerns). Domains 4 (missing outcome data), 5 
      (selective outcome reporting), and 6 had F1 scores below 0.50. The consistent 
      rates between the 2 assessments were 84.0% for LLM 1 and 87.3% for LLM 2. LLM 1's 
      κ exceeded 0.80 in 7 and LLM 2's in 8 domains. The mean (SD) time needed for 
      assessment was 77 (16) seconds for LLM 1 and 53 (12) seconds for LLM 2. 
      CONCLUSIONS: In this survey study of applying LLMs for ROB assessment, LLM 1 and 
      LLM 2 demonstrated substantial accuracy and consistency in evaluating RCTs, 
      suggesting their potential as supportive tools in systematic review processes.
FAU - Lai, Honghao
AU  - Lai H
AD  - Department of Health Policy and Management, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Ge, Long
AU  - Ge L
AD  - Department of Health Policy and Management, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Key Laboratory of Evidence Based Medicine and Knowledge Translation of Gansu 
      Province, Lanzhou, China.
FAU - Sun, Mingyao
AU  - Sun M
AD  - Evidence-Based Nursing Center, School of Nursing, Lanzhou University, Lanzhou, 
      China.
FAU - Pan, Bei
AU  - Pan B
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
FAU - Huang, Jiajie
AU  - Huang J
AD  - College of Nursing, Gansu University of Chinese Medicine, Lanzhou, China.
FAU - Hou, Liangying
AU  - Hou L
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Department of Health Research Methods, Evidence, and Impact, McMaster University, 
      Ontario, Canada.
FAU - Yang, Qiuyu
AU  - Yang Q
AD  - Department of Health Policy and Management, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Liu, Jiayi
AU  - Liu J
AD  - Department of Health Policy and Management, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Liu, Jianing
AU  - Liu J
AD  - College of Nursing, Gansu University of Chinese Medicine, Lanzhou, China.
FAU - Ye, Ziying
AU  - Ye Z
AD  - Department of Health Policy and Management, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Xia, Danni
AU  - Xia D
AD  - Department of Health Policy and Management, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Zhao, Weilong
AU  - Zhao W
AD  - Department of Health Policy and Management, School of Public Health, Lanzhou 
      University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Wang, Xiaoman
AU  - Wang X
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
FAU - Liu, Ming
AU  - Liu M
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Department of Health Research Methods, Evidence, and Impact, McMaster University, 
      Ontario, Canada.
FAU - Talukdar, Jhalok Ronjan
AU  - Talukdar JR
AD  - Department of Health Research Methods, Evidence, and Impact, McMaster University, 
      Ontario, Canada.
FAU - Tian, Jinhui
AU  - Tian J
AD  - Key Laboratory of Evidence Based Medicine and Knowledge Translation of Gansu 
      Province, Lanzhou, China.
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
FAU - Yang, Kehu
AU  - Yang K
AD  - Key Laboratory of Evidence Based Medicine and Knowledge Translation of Gansu 
      Province, Lanzhou, China.
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
FAU - Estill, Janne
AU  - Estill J
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Institute of Global Health, University of Geneva, Geneva, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20240501
PL  - United States
TA  - JAMA Netw Open
JT  - JAMA network open
JID - 101729235
SB  - IM
MH  - Humans
MH  - *Randomized Controlled Trials as Topic
MH  - *Bias
MH  - Reproducibility of Results
MH  - Language
MH  - Risk Assessment/methods
PMC - PMC11112444
COIS- Conflict of Interest Disclosures: None reported.
EDAT- 2024/05/22 12:43
MHDA- 2024/05/22 12:44
PMCR- 2024/05/22
CRDT- 2024/05/22 11:33
PHST- 2024/05/22 12:44 [medline]
PHST- 2024/05/22 12:43 [pubmed]
PHST- 2024/05/22 11:33 [entrez]
PHST- 2024/05/22 00:00 [pmc-release]
AID - 2818882 [pii]
AID - zoi240441 [pii]
AID - 10.1001/jamanetworkopen.2024.12687 [doi]
PST - epublish
SO  - JAMA Netw Open. 2024 May 1;7(5):e2412687. doi: 
      10.1001/jamanetworkopen.2024.12687.

PMID- 38214966
OWN - NLM
STAT- MEDLINE
DCOM- 20240116
LR  - 20241023
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Jan 12
TI  - Automated Paper Screening for Clinical Reviews Using Large Language Models: Data 
      Analysis Study.
PG  - e48996
LID - 10.2196/48996 [doi]
LID - e48996
AB  - BACKGROUND: The systematic review of clinical research papers is a 
      labor-intensive and time-consuming process that often involves the screening of 
      thousands of titles and abstracts. The accuracy and efficiency of this process 
      are critical for the quality of the review and subsequent health care decisions. 
      Traditional methods rely heavily on human reviewers, often requiring a 
      significant investment of time and resources. OBJECTIVE: This study aims to 
      assess the performance of the OpenAI generative pretrained transformer (GPT) and 
      GPT-4 application programming interfaces (APIs) in accurately and efficiently 
      identifying relevant titles and abstracts from real-world clinical review data 
      sets and comparing their performance against ground truth labeling by 2 
      independent human reviewers. METHODS: We introduce a novel workflow using the 
      Chat GPT and GPT-4 APIs for screening titles and abstracts in clinical reviews. A 
      Python script was created to make calls to the API with the screening criteria in 
      natural language and a corpus of title and abstract data sets filtered by a 
      minimum of 2 human reviewers. We compared the performance of our model against 
      human-reviewed papers across 6 review papers, screening over 24,000 titles and 
      abstracts. RESULTS: Our results show an accuracy of 0.91, a macro F(1)-score of 
      0.60, a sensitivity of excluded papers of 0.91, and a sensitivity of included 
      papers of 0.76. The interrater variability between 2 independent human screeners 
      was κ=0.46, and the prevalence and bias-adjusted κ between our proposed methods 
      and the consensus-based human decisions was κ=0.96. On a randomly selected subset 
      of papers, the GPT models demonstrated the ability to provide reasoning for their 
      decisions and corrected their initial decisions upon being asked to explain their 
      reasoning for incorrect classifications. CONCLUSIONS: Large language models have 
      the potential to streamline the clinical review process, save valuable time and 
      effort for researchers, and contribute to the overall quality of clinical 
      reviews. By prioritizing the workflow and acting as an aid rather than a 
      replacement for researchers and reviewers, models such as GPT-4 can enhance 
      efficiency and lead to more accurate and reliable conclusions in medical 
      research.
CI  - ©Eddie Guo, Mehul Gupta, Jiawen Deng, Ye-Jean Park, Michael Paget, Christopher 
      Naugler. Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 12.01.2024.
FAU - Guo, Eddie
AU  - Guo E
AUID- ORCID: 0000-0002-7223-0505
AD  - Cumming School of Medicine, University of Calgary, Calgary, AB, Canada.
FAU - Gupta, Mehul
AU  - Gupta M
AUID- ORCID: 0000-0001-7931-0666
AD  - Cumming School of Medicine, University of Calgary, Calgary, AB, Canada.
FAU - Deng, Jiawen
AU  - Deng J
AUID- ORCID: 0000-0002-8274-6468
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, AB, Canada.
FAU - Park, Ye-Jean
AU  - Park YJ
AUID- ORCID: 0009-0008-1068-8992
AD  - Temerty Faculty of Medicine, University of Toronto, Toronto, AB, Canada.
FAU - Paget, Michael
AU  - Paget M
AUID- ORCID: 0000-0002-3322-7661
AD  - Cumming School of Medicine, University of Calgary, Calgary, AB, Canada.
FAU - Naugler, Christopher
AU  - Naugler C
AUID- ORCID: 0000-0002-4570-1279
AD  - Cumming School of Medicine, University of Calgary, Calgary, AB, Canada.
LA  - eng
PT  - Journal Article
DEP - 20240112
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Biomedical Research
MH  - Consensus
MH  - Data Analysis
MH  - Problem Solving
MH  - *Systematic Reviews as Topic
MH  - Natural Language Processing
MH  - *Artificial Intelligence
MH  - Workflow
PMC - PMC10818236
OTO - NOTNLM
OT  - Chat GPT
OT  - GPT
OT  - GPT-4
OT  - LLM
OT  - NLP
OT  - abstract screening
OT  - classification
OT  - extract
OT  - extraction
OT  - free text
OT  - language model
OT  - large language models
OT  - natural language processing
OT  - nonopiod analgesia
OT  - review methodology
OT  - review methods
OT  - screening
OT  - systematic
OT  - systematic review
OT  - unstructured data
COIS- Conflicts of Interest: None declared.
EDAT- 2024/01/12 12:41
MHDA- 2024/01/15 12:42
PMCR- 2024/01/12
CRDT- 2024/01/12 11:53
PHST- 2023/05/14 00:00 [received]
PHST- 2023/09/28 00:00 [accepted]
PHST- 2023/08/30 00:00 [revised]
PHST- 2024/01/15 12:42 [medline]
PHST- 2024/01/12 12:41 [pubmed]
PHST- 2024/01/12 11:53 [entrez]
PHST- 2024/01/12 00:00 [pmc-release]
AID - v26i1e48996 [pii]
AID - 10.2196/48996 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Jan 12;26:e48996. doi: 10.2196/48996.

PMID- 37976385
OWN - NLM
STAT- MEDLINE
DCOM- 20240122
LR  - 20240131
IS  - 1940-5480 (Electronic)
IS  - 1067-151X (Linking)
VI  - 32
IP  - 3
DP  - 2024 Feb 1
TI  - ChatGPT's Ability to Assist with Clinical Documentation: A Randomized Controlled 
      Trial.
PG  - 123-129
LID - 10.5435/JAAOS-D-23-00474 [doi]
AB  - INTRODUCTION: Clinical documentation is a critical aspect of health care that 
      enables healthcare providers to communicate effectively with each other and 
      maintain accurate patient care records. Artificial intelligence tools, such as 
      chatbots and virtual assistants, have the potential to assist healthcare 
      providers in clinical documentation. ChatGPT is an artificial intelligence 
      conversational model that generates human-like responses to text-based prompts. 
      In this study, we sought to investigate ChatGPT's ability to assist with writing 
      a history of present illness based on standardized patient histories. METHODS: A 
      blinded, randomized controlled study was conducted to compare the use of typing, 
      dictation, and ChatGPT as tools to document history of present illness (HPI) of 
      standardized patient histories. Eleven study participants, consisting of medical 
      students, orthopaedic surgery residents, and attending surgeons, completed three 
      HPIs using a different documentation technique for each one. Participants were 
      randomized into cohorts based on the type of documentation technique. 
      Participants were asked to interview standardized patients and document the 
      patient's history of present illness using their assigned method. RESULTS: 
      ChatGPT was found to be intermediate for speed; dictation was fastest, but 
      produced markedly longer and higher quality patient histories based on Physician 
      Documentation Quality Instrument score compared with dictation and typing. 
      However, ChatGPT included erroneous information in 36% of the documents. Poor 
      agreement existed on the quality of patient histories between reviewers. 
      DISCUSSION: Our study suggests that ChatGPT has the potential to improve clinical 
      documentation by producing more comprehensive and organized HPIs. ChatGPT can 
      generate longer and more detailed documentation compared with typing or dictation 
      documentation methods. However, additional studies are needed to investigate and 
      address concerns regarding privacy, bias, and accuracy of information.
CI  - Copyright © 2023 by the American Academy of Orthopaedic Surgeons.
FAU - Baker, Hayden P
AU  - Baker HP
AUID- ORCID: 0000-0002-9306-7006
AD  - From the Department of Orthopaedic Surgery, University of Chicago, Chicago, IL.
FAU - Dwyer, Emma
AU  - Dwyer E
FAU - Kalidoss, Senthooran
AU  - Kalidoss S
FAU - Hynes, Kelly
AU  - Hynes K
FAU - Wolf, Jennifer
AU  - Wolf J
FAU - Strelzow, Jason A
AU  - Strelzow JA
LA  - eng
PT  - Journal Article
PT  - Randomized Controlled Trial
DEP - 20231117
PL  - United States
TA  - J Am Acad Orthop Surg
JT  - The Journal of the American Academy of Orthopaedic Surgeons
JID - 9417468
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Communication
MH  - Documentation
MH  - Health Facilities
MH  - *Surgeons
EDAT- 2023/11/17 18:42
MHDA- 2024/01/22 06:42
CRDT- 2023/11/17 14:23
PHST- 2023/05/23 00:00 [received]
PHST- 2023/09/29 00:00 [accepted]
PHST- 2024/01/22 06:42 [medline]
PHST- 2023/11/17 18:42 [pubmed]
PHST- 2023/11/17 14:23 [entrez]
AID - 00124635-990000000-00834 [pii]
AID - 10.5435/JAAOS-D-23-00474 [doi]
PST - ppublish
SO  - J Am Acad Orthop Surg. 2024 Feb 1;32(3):123-129. doi: 10.5435/JAAOS-D-23-00474. 
      Epub 2023 Nov 17.

PMID- 38506920
OWN - NLM
STAT- MEDLINE
DCOM- 20240321
LR  - 20240406
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Mar 20
TI  - Incorporating ChatGPT in Medical Informatics Education: Mixed Methods Study on 
      Student Perceptions and Experiential Integration Proposals.
PG  - e51151
LID - 10.2196/51151 [doi]
LID - e51151
AB  - BACKGROUND: The integration of artificial intelligence (AI) technologies, such as 
      ChatGPT, in the educational landscape has the potential to enhance the learning 
      experience of medical informatics students and prepare them for using AI in 
      professional settings. The incorporation of AI in classes aims to develop 
      critical thinking by encouraging students to interact with ChatGPT and critically 
      analyze the responses generated by the chatbot. This approach also helps students 
      develop important skills in the field of biomedical and health informatics to 
      enhance their interaction with AI tools. OBJECTIVE: The aim of the study is to 
      explore the perceptions of students regarding the use of ChatGPT as a learning 
      tool in their educational context and provide professors with examples of prompts 
      for incorporating ChatGPT into their teaching and learning activities, thereby 
      enhancing the educational experience for students in medical informatics courses. 
      METHODS: This study used a mixed methods approach to gain insights from students 
      regarding the use of ChatGPT in education. To accomplish this, a structured 
      questionnaire was applied to evaluate students' familiarity with ChatGPT, gauge 
      their perceptions of its use, and understand their attitudes toward its use in 
      academic and learning tasks. Learning outcomes of 2 courses were analyzed to 
      propose ChatGPT's incorporation in master's programs in medicine and medical 
      informatics. RESULTS: The majority of students expressed satisfaction with the 
      use of ChatGPT in education, finding it beneficial for various purposes, 
      including generating academic content, brainstorming ideas, and rewriting text. 
      While some participants raised concerns about potential biases and the need for 
      informed use, the overall perception was positive. Additionally, the study 
      proposed integrating ChatGPT into 2 specific courses in the master's programs in 
      medicine and medical informatics. The incorporation of ChatGPT was envisioned to 
      enhance student learning experiences and assist in project planning, programming 
      code generation, examination preparation, workflow exploration, and technical 
      interview preparation, thus advancing medical informatics education. In medical 
      teaching, it will be used as an assistant for simplifying the explanation of 
      concepts and solving complex problems, as well as for generating clinical 
      narratives and patient simulators. CONCLUSIONS: The study's valuable insights 
      into medical faculty students' perspectives and integration proposals for ChatGPT 
      serve as an informative guide for professors aiming to enhance medical 
      informatics education. The research delves into the potential of ChatGPT, 
      emphasizes the necessity of collaboration in academic environments, identifies 
      subject areas with discernible benefits, and underscores its transformative role 
      in fostering innovative and engaging learning experiences. The envisaged 
      proposals hold promise in empowering future health care professionals to work in 
      the rapidly evolving era of digital health care.
CI  - ©Sabrina Magalhães Araujo, Ricardo Cruz-Correia. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 20.03.2024.
FAU - Magalhães Araujo, Sabrina
AU  - Magalhães Araujo S
AUID- ORCID: 0000-0003-1443-2106
AD  - Center for Health Technology and Services Research, Faculty of Medicine, 
      University of Porto, Porto, Portugal.
FAU - Cruz-Correia, Ricardo
AU  - Cruz-Correia R
AUID- ORCID: 0000-0002-3764-5158
AD  - Center for Health Technology and Services Research, Faculty of Medicine, 
      University of Porto, Porto, Portugal.
AD  - Department of Community Medicine, Information and Decision Sciences, Faculty of 
      Medicine, University of Porto, Porto, Portugal.
AD  - Working Group Education, European Federation for Medical Informatics, Le 
      Mont-sur-Lausanne, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20240320
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - Educational Status
MH  - *Medical Informatics
MH  - *Students, Medical
MH  - Faculty, Medical
PMC - PMC10993110
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - education
OT  - generative language model
OT  - medical informatics
COIS- Conflicts of Interest: None declared.
EDAT- 2024/03/20 12:42
MHDA- 2024/03/21 12:43
PMCR- 2024/03/20
CRDT- 2024/03/20 11:54
PHST- 2023/07/27 00:00 [received]
PHST- 2023/11/10 00:00 [accepted]
PHST- 2023/09/29 00:00 [revised]
PHST- 2024/03/21 12:43 [medline]
PHST- 2024/03/20 12:42 [pubmed]
PHST- 2024/03/20 11:54 [entrez]
PHST- 2024/03/20 00:00 [pmc-release]
AID - v10i1e51151 [pii]
AID - 10.2196/51151 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Mar 20;10:e51151. doi: 10.2196/51151.

PMID- 38145471
OWN - NLM
STAT- MEDLINE
DCOM- 20231226
LR  - 20240114
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Dec 25
TI  - AI-Enabled Medical Education: Threads of Change, Promising Futures, and Risky 
      Realities Across Four Potential Future Worlds.
PG  - e50373
LID - 10.2196/50373 [doi]
LID - e50373
AB  - BACKGROUND: The rapid trajectory of artificial intelligence (AI) development and 
      advancement is quickly outpacing society's ability to determine its future role. 
      As AI continues to transform various aspects of our lives, one critical question 
      arises for medical education: what will be the nature of education, teaching, and 
      learning in a future world where the acquisition, retention, and application of 
      knowledge in the traditional sense are fundamentally altered by AI? OBJECTIVE: 
      The purpose of this perspective is to plan for the intersection of health care 
      and medical education in the future. METHODS: We used GPT-4 and scenario-based 
      strategic planning techniques to craft 4 hypothetical future worlds influenced by 
      AI's integration into health care and medical education. This method, used by 
      organizations such as Shell and the Accreditation Council for Graduate Medical 
      Education, assesses readiness for alternative futures and effectively manages 
      uncertainty, risk, and opportunity. The detailed scenarios provide insights into 
      potential environments the medical profession may face and lay the foundation for 
      hypothesis generation and idea-building regarding responsible AI implementation. 
      RESULTS: The following 4 worlds were created using OpenAI's GPT model: AI 
      Harmony, AI conflict, The world of Ecological Balance, and Existential Risk. 
      Risks include disinformation and misinformation, loss of privacy, widening 
      inequity, erosion of human autonomy, and ethical dilemmas. Benefits involve 
      improved efficiency, personalized interventions, enhanced collaboration, early 
      detection, and accelerated research. CONCLUSIONS: To ensure responsible AI use, 
      the authors suggest focusing on 3 key areas: developing a robust ethical 
      framework, fostering interdisciplinary collaboration, and investing in education 
      and training. A strong ethical framework emphasizes patient safety, privacy, and 
      autonomy while promoting equity and inclusivity. Interdisciplinary collaboration 
      encourages cooperation among various experts in developing and implementing AI 
      technologies, ensuring that they address the complex needs and challenges in 
      health care and medical education. Investing in education and training prepares 
      professionals and trainees with necessary skills and knowledge to effectively use 
      and critically evaluate AI technologies. The integration of AI in health care and 
      medical education presents a critical juncture between transformative 
      advancements and significant risks. By working together to address both immediate 
      and long-term risks and consequences, we can ensure that AI integration leads to 
      a more equitable, sustainable, and prosperous future for both health care and 
      medical education. As we engage with AI technologies, our collective actions will 
      ultimately determine the state of the future of health care and medical education 
      to harness AI's power while ensuring the safety and well-being of humanity.
CI  - ©Michelle I Knopp, Eric J Warm, Danielle Weber, Matthew Kelleher, Benjamin 
      Kinnear, Daniel J Schumacher, Sally A Santen, Eneida Mendonça, Laurah Turner. 
      Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      25.12.2023.
FAU - Knopp, Michelle I
AU  - Knopp MI
AUID- ORCID: 0000-0002-2584-1039
AD  - Department of Internal Medicine, College of Medicine, University of Cincinnati, 
      Cincinnati, OH, United States.
FAU - Warm, Eric J
AU  - Warm EJ
AUID- ORCID: 0000-0002-6088-2434
AD  - Department of Internal Medicine, College of Medicine, University of Cincinnati, 
      Cincinnati, OH, United States.
FAU - Weber, Danielle
AU  - Weber D
AUID- ORCID: 0000-0002-4857-6936
AD  - Departments of Internal Medicine and Pediatrics, College of Medicine, University 
      of Cincinnati, Cincinnati, OH, United States.
FAU - Kelleher, Matthew
AU  - Kelleher M
AUID- ORCID: 0000-0002-6400-1745
AD  - Departments of Internal Medicine and Pediatrics, College of Medicine, University 
      of Cincinnati, Cincinnati, OH, United States.
FAU - Kinnear, Benjamin
AU  - Kinnear B
AUID- ORCID: 0000-0003-0052-4130
AD  - Department of Pediatrics, College of Medicine, University of Cincinnati, 
      Cincinnati, OH, United States.
FAU - Schumacher, Daniel J
AU  - Schumacher DJ
AUID- ORCID: 0000-0001-5507-8452
AD  - Department of Pediatrics, College of Medicine, University of Cincinnati, 
      Cincinnati, OH, United States.
FAU - Santen, Sally A
AU  - Santen SA
AUID- ORCID: 0000-0002-8327-8002
AD  - Department of Medical Education, College of Medicine, University of Cincinnati, 
      Cincinnati, OH, United States.
FAU - Mendonça, Eneida
AU  - Mendonça E
AUID- ORCID: 0000-0003-4297-9221
AD  - Department of Pediatrics, College of Medicine, University of Cincinnati, 
      Cincinnati, OH, United States.
FAU - Turner, Laurah
AU  - Turner L
AUID- ORCID: 0000-0002-4567-1313
AD  - Department of Medical Education, College of Medicine, University of Cincinnati, 
      Cincinnati, OH, United States.
LA  - eng
PT  - Journal Article
DEP - 20231225
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Software
MH  - *Education, Medical
MH  - Educational Status
MH  - Humanities
PMC - PMC10786199
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT-4
OT  - Open-AI
OT  - OpenAI
OT  - artificial intelligence
OT  - autonomous
OT  - autonomy
OT  - ethic
OT  - ethical
OT  - ethics
OT  - ethics and AI
OT  - future
OT  - future of healthcare
OT  - generative
OT  - medical education
OT  - privacy
OT  - scenario
OT  - scenario planning
OT  - strategic planning
COIS- Conflicts of Interest: DW has received funding from National Board of Medical 
      Examiners for a project using natural language processing and a large language 
      model to evaluate clinical reasoning in resident documentation. LT has received 
      funding from the American Medical Association for a project using large language 
      models to develop a platform that generates clinical skills practice scenarios.
EDAT- 2023/12/25 12:42
MHDA- 2023/12/26 06:41
PMCR- 2023/12/25
CRDT- 2023/12/25 11:53
PHST- 2023/06/28 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/12/01 00:00 [revised]
PHST- 2023/12/26 06:41 [medline]
PHST- 2023/12/25 12:42 [pubmed]
PHST- 2023/12/25 11:53 [entrez]
PHST- 2023/12/25 00:00 [pmc-release]
AID - v9i1e50373 [pii]
AID - 10.2196/50373 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Dec 25;9:e50373. doi: 10.2196/50373.

PMID- 38123252
OWN - NLM
STAT- MEDLINE
DCOM- 20231222
LR  - 20241031
IS  - 2589-7500 (Electronic)
IS  - 2589-7500 (Linking)
VI  - 6
IP  - 1
DP  - 2024 Jan
TI  - Assessing the potential of GPT-4 to perpetuate racial and gender biases in health 
      care: a model evaluation study.
PG  - e12-e22
LID - S2589-7500(23)00225-X [pii]
LID - 10.1016/S2589-7500(23)00225-X [doi]
AB  - BACKGROUND: Large language models (LLMs) such as GPT-4 hold great promise as 
      transformative tools in health care, ranging from automating administrative tasks 
      to augmenting clinical decision making. However, these models also pose a danger 
      of perpetuating biases and delivering incorrect medical diagnoses, which can have 
      a direct, harmful impact on medical care. We aimed to assess whether GPT-4 
      encodes racial and gender biases that impact its use in health care. METHODS: 
      Using the Azure OpenAI application interface, this model evaluation study tested 
      whether GPT-4 encodes racial and gender biases and examined the impact of such 
      biases on four potential applications of LLMs in the clinical domain-namely, 
      medical education, diagnostic reasoning, clinical plan generation, and subjective 
      patient assessment. We conducted experiments with prompts designed to resemble 
      typical use of GPT-4 within clinical and medical education applications. We used 
      clinical vignettes from NEJM Healer and from published research on implicit bias 
      in health care. GPT-4 estimates of the demographic distribution of medical 
      conditions were compared with true US prevalence estimates. Differential 
      diagnosis and treatment planning were evaluated across demographic groups using 
      standard statistical tests for significance between groups. FINDINGS: We found 
      that GPT-4 did not appropriately model the demographic diversity of medical 
      conditions, consistently producing clinical vignettes that stereotype demographic 
      presentations. The differential diagnoses created by GPT-4 for standardised 
      clinical vignettes were more likely to include diagnoses that stereotype certain 
      races, ethnicities, and genders. Assessment and plans created by the model showed 
      significant association between demographic attributes and recommendations for 
      more expensive procedures as well as differences in patient perception. 
      INTERPRETATION: Our findings highlight the urgent need for comprehensive and 
      transparent bias assessments of LLM tools such as GPT-4 for intended use cases 
      before they are integrated into clinical care. We discuss the potential sources 
      of these biases and potential mitigation strategies before clinical 
      implementation. FUNDING: Priscilla Chan and Mark Zuckerberg.
CI  - Copyright © 2024 The Author(s). Published by Elsevier Ltd. This is an Open Access 
      article under the CC BY 4.0 license. Published by Elsevier Ltd.. All rights 
      reserved.
FAU - Zack, Travis
AU  - Zack T
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, CA, USA; Helen Diller Family Comprehensive Cancer 
      Center, University of California San Francisco, San Francisco, CA, USA.
FAU - Lehman, Eric
AU  - Lehman E
AD  - Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute 
      of Technology, Cambridge, MA, USA.
FAU - Suzgun, Mirac
AU  - Suzgun M
AD  - Department of Computer Science, Stanford University, Stanford, CA, USA; Stanford 
      Law School, Stanford University, Stanford, CA, USA.
FAU - Rodriguez, Jorge A
AU  - Rodriguez JA
AD  - Division of General Internal Medicine, Brigham and Women's Hospital, Boston, MA, 
      USA.
FAU - Celi, Leo Anthony
AU  - Celi LA
AD  - Laboratory for Computational Physiology, Massachusetts Institute of Technology, 
      Cambridge, MA, USA; Division of Pulmonary, Critical Care and Sleep Medicine, Beth 
      Israel Deaconess Medical Center, Boston, MA, USA; Department of Biostatistics, 
      Harvard T H Chan School of Public Health, Boston, MA, USA.
FAU - Gichoya, Judy
AU  - Gichoya J
AD  - Department of Radiology, Emory University, Atlanta, GA, USA.
FAU - Jurafsky, Dan
AU  - Jurafsky D
AD  - Department of Computer Science, Stanford University, Stanford, CA, USA; 
      Department of Linguistics, Stanford University, Stanford, CA, USA.
FAU - Szolovits, Peter
AU  - Szolovits P
AD  - Computer Science and Artificial Intelligence Laboratory, Massachusetts Institute 
      of Technology, Cambridge, MA, USA.
FAU - Bates, David W
AU  - Bates DW
AD  - Division of General Internal Medicine, Brigham and Women's Hospital, Boston, MA, 
      USA; Department of Health Policy and Management, Harvard T H Chan School of 
      Public Health, Boston, MA, USA.
FAU - Abdulnour, Raja-Elie E
AU  - Abdulnour RE
AD  - Division of Pulmonary and Critical Care Medicine, Brigham and Women's Hospital, 
      Boston, MA, USA; Harvard Medical School, Boston, MA, USA.
FAU - Butte, Atul J
AU  - Butte AJ
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, CA, USA; Center for Data-Driven Insights and 
      Innovation, University of California, Office of the President, Oakland, CA, USA.
FAU - Alsentzer, Emily
AU  - Alsentzer E
AD  - Division of General Internal Medicine, Brigham and Women's Hospital, Boston, MA, 
      USA; Harvard Medical School, Boston, MA, USA. Electronic address: 
      ealsentzer@bwh.harvard.edu.
LA  - eng
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - England
TA  - Lancet Digit Health
JT  - The Lancet. Digital health
JID - 101751302
SB  - IM
CIN - Lancet Digit Health. 2024 Jan;6(1):e2-e3. doi: 10.1016/S2589-7500(23)00246-7. 
      PMID: 38123253
EIN - Lancet Digit Health. 2024 Jul;6(7):e445. doi: 10.1016/S2589-7500(24)00120-1. 
      PMID: 38906610
MH  - Female
MH  - Humans
MH  - Male
MH  - *Health Facilities
MH  - Clinical Decision-Making
MH  - Diagnosis, Differential
MH  - *Education, Medical
MH  - Delivery of Health Care
COIS- Declaration of interests TZ reports no external financial interests; he works in 
      an unpaid role as a clinical consultant with Xyla. EL reports personal fees and 
      equity from Xyla. MS reports personal fees from Xyla and serves as an intern at 
      Microsoft Research. LAC reports travel support from Australia New Zealand College 
      of Intensive Care Medicine, cloud credits from Oracle, Amazon, and Google, and a 
      role as Editor-in-Chief of PLOS Digital Health. JG reports support from the US 
      National Science Foundation (grant #1928481), Radiological Society of North 
      America (grant #EIHD2204), National Institutes of Health (grants 75N92020C00008 
      and 75N920), AIM-AHEAD, DeepLook, Clarity consortium, and GE Edison; received 
      honoraria from the National Bureau of Economic Research; and has leadership roles 
      with SIIM, HL7, and the ACR Advisory Committee. R-EEA is an employee of 
      Massachusetts Medical Society, which owns NEJM Healer (NEJM Healer cases were 
      used in the study). DWB reports grants and personal fees from EarlySense; 
      personal fees from CDI Negev; equity from ValeraHealth, Clew, MDClone, and Guided 
      Clinical Solutions; personal fees and equity from AESOP and Feelbetter; and 
      grants from IBM Watson Health, outside the submitted work. DWB also has a patent 
      pending (PHC-028564US PCT) on intraoperative clinical decision support. AJB is a 
      cofounder and consultant to Personalis and NuMedii; consultant to Mango Tree 
      Corporation and in the recent past, to Samsung, 10x Genomics, Helix, Pathway 
      Genomics, and Verinata (Illumina); has served on paid advisory panels or boards 
      for Geisinger Health, Regenstrief Institute, Gerson Lehman Group, AlphaSights, 
      Covance, Novartis, Genentech, Merck, and Roche; is a shareholder in Personalis 
      and NuMedii; is a minor shareholder in Apple, Meta (Facebook), Alphabet (Google), 
      Microsoft, Amazon, Snap, 10x Genomics, Illumina, Regeneron, Sanofi, Pfizer, 
      Royalty Pharma, Moderna, Sutro, Doximity, BioNtech, Invitae, Pacific Biosciences, 
      Editas Medicine, Nuna Health, Assay Depot, Vet24seven, and several other 
      non-health related companies and mutual funds; and has received honoraria and 
      travel reimbursement for invited talks from Johnson & Johnson, Roche, Genentech, 
      Pfizer, Merck, Lilly, Takeda, Varian, Mars, Siemens, Optum, Abbott, Celgene, 
      AstraZeneca, AbbVie, Westat, and many academic institutions, medical or disease 
      specific foundations and associations, and health systems. AJB also receives 
      royalty payments through Stanford University for several patents and other 
      disclosures licensed to NuMedii and Personalis. AJB's research has been funded by 
      the National Institutes of Health, Peraton (as the prime on a National Institutes 
      of Health contract), Genentech, Johnson & Johnson, US Food and Drug 
      Administration, Robert Wood Johnson Foundation, Leon Lowenstein Foundation, 
      Intervalien Foundation, Priscilla Chan and Mark Zuckerberg, the Barbara and 
      Gerson Bakar Foundation, and in the recent past, the March of Dimes, Juvenile 
      Diabetes Research Foundation, California Governor's Office of Planning and 
      Research, California Institute for Regenerative Medicine, L’Oreal, and Progenity. 
      EA reports personal fees from Canopy Innovations, Fourier Health, and Xyla; and 
      grants from Microsoft Research. None of these entities had any role in the 
      design, execution, evaluation, or writing of this manuscript. All other authors 
      declare no competing interests.
EDAT- 2023/12/21 00:41
MHDA- 2023/12/22 06:42
CRDT- 2023/12/20 21:01
PHST- 2023/07/17 00:00 [received]
PHST- 2023/09/30 00:00 [revised]
PHST- 2023/10/26 00:00 [accepted]
PHST- 2023/12/22 06:42 [medline]
PHST- 2023/12/21 00:41 [pubmed]
PHST- 2023/12/20 21:01 [entrez]
AID - S2589-7500(23)00225-X [pii]
AID - 10.1016/S2589-7500(23)00225-X [doi]
PST - ppublish
SO  - Lancet Digit Health. 2024 Jan;6(1):e12-e22. doi: 10.1016/S2589-7500(23)00225-X.

PMID- 38446502
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240323
IS  - 2562-0959 (Electronic)
IS  - 2562-0959 (Linking)
VI  - 7
DP  - 2024 Mar 6
TI  - Readability and Health Literacy Scores for ChatGPT-Generated Dermatology Public 
      Education Materials: Cross-Sectional Analysis of Sunscreen and Melanoma 
      Questions.
PG  - e50163
LID - 10.2196/50163 [doi]
LID - e50163
FAU - Roster, Katie
AU  - Roster K
AUID- ORCID: 0000-0002-3128-9498
AD  - New York Medical College, New York, NY, United States.
FAU - Kann, Rebecca B
AU  - Kann RB
AUID- ORCID: 0009-0008-7131-6543
AD  - New York Medical College, New York, NY, United States.
FAU - Farabi, Banu
AU  - Farabi B
AUID- ORCID: 0000-0002-4748-1556
AD  - Dermatology Department, NYC Health + Hospital/Metropolitan, New York, NY, United 
      States.
FAU - Gronbeck, Christian
AU  - Gronbeck C
AUID- ORCID: 0000-0002-5146-9904
AD  - Department of Dermatology, University of Connecticut HealthCenter, Framington, 
      CT, United States.
FAU - Brownstone, Nicholas
AU  - Brownstone N
AUID- ORCID: 0000-0002-1187-1712
AD  - Department of Dermatology, Temple University Hospital, Philadelphia, PA, United 
      States.
FAU - Lipner, Shari R
AU  - Lipner SR
AUID- ORCID: 0000-0001-5913-9304
AD  - Department of Dermatology, Weill Cornell Medicine, New York, NY, United States.
LA  - eng
PT  - Journal Article
DEP - 20240306
PL  - Canada
TA  - JMIR Dermatol
JT  - JMIR dermatology
JID - 101770607
PMC - PMC10955394
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - LLMs
OT  - NLP
OT  - artificial intelligence
OT  - comprehensibility
OT  - comprehensible
OT  - dermatology
OT  - disparities
OT  - disparity
OT  - generative
OT  - health disparities
OT  - health education
OT  - health information
OT  - health literacy
OT  - language model
OT  - language models
OT  - large language model
OT  - natural language processing
OT  - online information
OT  - patient education
OT  - public education
OT  - readability
OT  - understandability
COIS- Conflicts of Interest: SRL has served as a consultant for Eli Lilly, Ortho 
      Dermatologics, Moberg Pharmaceuticals, and BelleTorus Corporation.
EDAT- 2024/03/06 12:44
MHDA- 2024/03/06 12:45
PMCR- 2024/03/06
CRDT- 2024/03/06 11:52
PHST- 2023/06/21 00:00 [received]
PHST- 2024/02/06 00:00 [accepted]
PHST- 2024/01/02 00:00 [revised]
PHST- 2024/03/06 12:45 [medline]
PHST- 2024/03/06 12:44 [pubmed]
PHST- 2024/03/06 11:52 [entrez]
PHST- 2024/03/06 00:00 [pmc-release]
AID - v7i1e50163 [pii]
AID - 10.2196/50163 [doi]
PST - epublish
SO  - JMIR Dermatol. 2024 Mar 6;7:e50163. doi: 10.2196/50163.

PMID- 37692694
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240924
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 8
DP  - 2023 Aug
TI  - ChatGPT and Artificial Intelligence in Medical Writing: Concerns and Ethical 
      Considerations.
PG  - e43292
LID - 10.7759/cureus.43292 [doi]
LID - e43292
AB  - Artificial intelligence (AI) language generation models, such as ChatGPT, have 
      the potential to revolutionize the field of medical writing and other natural 
      language processing (NLP) tasks. It is crucial to consider the ethical concerns 
      that come with their use. These include bias, misinformation, privacy, lack of 
      transparency, job displacement, stifling creativity, plagiarism, authorship, and 
      dependence. Therefore, it is essential to develop strategies to understand and 
      address these concerns. Important techniques include common bias and 
      misinformation detection, ensuring privacy, providing transparency, and being 
      mindful of the impact on employment. The AI-generated text must be critically 
      reviewed by medical experts to validate the output generated by these models 
      before being used in any clinical or medical context. By considering these 
      ethical concerns and taking appropriate measures, we can ensure that the benefits 
      of these powerful tools are maximized while minimizing any potential harm. This 
      article focuses on the implications of AI assistants in medical writing and hopes 
      to provide insight into the perceived rapid rate of technological progression 
      from a historical and ethical perspective.
CI  - Copyright © 2023, Doyal et al.
FAU - Doyal, Alexander S
AU  - Doyal AS
AD  - Anesthesiology, University of North Carolina at Chapel Hill School of Medicine, 
      Chapel Hill, USA.
FAU - Sender, David
AU  - Sender D
AD  - Anesthesiology, University of North Carolina at Chapel Hill School of Medicine, 
      Chapel Hill, USA.
FAU - Nanda, Monika
AU  - Nanda M
AD  - Anesthesiology, University of North Carolina at Chapel Hill School of Medicine, 
      Chapel Hill, USA.
FAU - Serrano, Ricardo A
AU  - Serrano RA
AD  - Anesthesiology, University of North Carolina at Chapel Hill School of Medicine, 
      Chapel Hill, USA.
LA  - eng
PT  - Editorial
DEP - 20230810
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10492634
OTO - NOTNLM
OT  - ai & robotics in healthcare
OT  - artificial intelligence (ai)
OT  - ethics
OT  - machine learning
OT  - medical writing
OT  - natural language processing
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/09/11 06:42
MHDA- 2023/09/11 06:43
PMCR- 2023/08/10
CRDT- 2023/09/11 04:41
PHST- 2023/08/10 00:00 [accepted]
PHST- 2023/09/11 06:43 [medline]
PHST- 2023/09/11 06:42 [pubmed]
PHST- 2023/09/11 04:41 [entrez]
PHST- 2023/08/10 00:00 [pmc-release]
AID - 10.7759/cureus.43292 [doi]
PST - epublish
SO  - Cureus. 2023 Aug 10;15(8):e43292. doi: 10.7759/cureus.43292. eCollection 2023 
      Aug.

PMID- 36346105
OWN - NLM
STAT- MEDLINE
DCOM- 20221109
LR  - 20221207
IS  - 1557-9700 (Electronic)
IS  - 1075-2730 (Linking)
VI  - 73
IP  - 11
DP  - 2022 Nov 1
TI  - Discrimination and Suicidality Among Hispanic Mental Health Patients, 2010-2020: 
      A Natural Language Processing Approach.
PG  - 1313-1314
LID - 10.1176/appi.ps.20220240 [doi]
FAU - Goldstein, Evan V
AU  - Goldstein EV
AD  - Department of Population Health Sciences, Spencer Fox Eccles School of Medicine 
      (all authors), College of Social and Behavioral Science (Bailey), and Matheson 
      Center for Health Care Studies (Wilson), University of Utah, Salt Lake City.
FAU - Bailey, Elise V
AU  - Bailey EV
AD  - Department of Population Health Sciences, Spencer Fox Eccles School of Medicine 
      (all authors), College of Social and Behavioral Science (Bailey), and Matheson 
      Center for Health Care Studies (Wilson), University of Utah, Salt Lake City.
FAU - Wilson, Fernando A
AU  - Wilson FA
AD  - Department of Population Health Sciences, Spencer Fox Eccles School of Medicine 
      (all authors), College of Social and Behavioral Science (Bailey), and Matheson 
      Center for Health Care Studies (Wilson), University of Utah, Salt Lake City.
LA  - eng
PT  - Letter
PL  - United States
TA  - Psychiatr Serv
JT  - Psychiatric services (Washington, D.C.)
JID - 9502838
SB  - IM
MH  - Humans
MH  - United States
MH  - *Mental Health
MH  - Natural Language Processing
MH  - Hispanic or Latino
MH  - Suicidal Ideation
MH  - *Suicide Prevention
OTO - NOTNLM
OT  - Racial-ethnic disparities
OT  - Stigma/discrimination
EDAT- 2022/11/09 06:00
MHDA- 2022/11/10 06:00
CRDT- 2022/11/08 07:43
PHST- 2022/11/08 07:43 [entrez]
PHST- 2022/11/09 06:00 [pubmed]
PHST- 2022/11/10 06:00 [medline]
AID - 10.1176/appi.ps.20220240 [doi]
PST - ppublish
SO  - Psychiatr Serv. 2022 Nov 1;73(11):1313-1314. doi: 10.1176/appi.ps.20220240.

PMID- 31241574
OWN - NLM
STAT- MEDLINE
DCOM- 20200212
LR  - 20200212
IS  - 1938-808X (Electronic)
IS  - 1040-2446 (Linking)
VI  - 94
IP  - 7
DP  - 2019 Jul
TI  - Algorithmic Bias and Computer-Assisted Scoring of Patient Notes in the USMLE Step 
      2 Clinical Skills Exam.
PG  - 926
LID - 10.1097/ACM.0000000000002746 [doi]
FAU - Spadafore, Maxwell
AU  - Spadafore M
AD  - Third-year medical student, University of Michigan Medical School, Ann Arbor, 
      Michigan; maxspad@umich.edu; ORCID: http://orcid.org/0000-0001-5927-1428. 
      Assistant dean for assessment, evaluation, and quality improvement and associate 
      professor of internal medicine and learning health sciences, University of 
      Michigan Medical School, Ann Arbor, Michigan; ORCID: 
      http://orcid.org/0000-0002-3374-2989.
FAU - Monrad, Seetha U
AU  - Monrad SU
LA  - eng
PT  - Comment
PT  - Letter
PL  - United States
TA  - Acad Med
JT  - Academic medicine : journal of the Association of American Medical Colleges
JID - 8904605
SB  - IM
CON - Acad Med. 2019 Mar;94(3):314-316. doi: 10.1097/ACM.0000000000002558. PMID: 
      30540567
CIN - Acad Med. 2019 Jul;94(7):926-927. doi: 10.1097/ACM.0000000000002754. PMID: 
      31241575
MH  - Bias
MH  - *Clinical Competence
MH  - Educational Measurement
MH  - Humans
MH  - Licensure, Medical
MH  - *Natural Language Processing
EDAT- 2019/06/27 06:00
MHDA- 2020/02/13 06:00
CRDT- 2019/06/27 06:00
PHST- 2019/06/27 06:00 [entrez]
PHST- 2019/06/27 06:00 [pubmed]
PHST- 2020/02/13 06:00 [medline]
AID - 00001888-201907000-00013 [pii]
AID - 10.1097/ACM.0000000000002746 [doi]
PST - ppublish
SO  - Acad Med. 2019 Jul;94(7):926. doi: 10.1097/ACM.0000000000002746.

PMID- 37644945
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230831
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - Harnessing the Power of Large Language Models (LLMs) for Electronic Health 
      Records (EHRs) Optimization.
PG  - e42634
LID - 10.7759/cureus.42634 [doi]
LID - e42634
AB  - This editorial discusses the potential benefits of integrating large language 
      models (LLMs), such as GPT-4, into electronic health records (EHRs) to optimize 
      patient care, improve clinical decision-making, and promote efficient healthcare 
      management. Artificial intelligence (AI)-driven LLMs can revolutionize healthcare 
      practices by streamlining the data input process, expediting information 
      extraction from unstructured narratives, and facilitating personalized patient 
      communication. However, concerns related to patient privacy, data security, and 
      potential biases must be addressed to ensure equitable healthcare for all. 
      Therefore, we encourage healthcare professionals and researchers to explore 
      innovative solutions that leverage AI capabilities while addressing the 
      challenges associated with privacy and equity.
CI  - Copyright © 2023, Nashwan et al.
FAU - Nashwan, Abdulqadir J
AU  - Nashwan AJ
AD  - Nursing, Hamad Medical Corporation, Doha, QAT.
FAU - AbuJaber, Ahmad A
AU  - AbuJaber AA
AD  - Nursing, Hamad Medical Corporation, Doha, QAT.
LA  - eng
PT  - Editorial
DEP - 20230729
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10461074
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - clinical decision-making
OT  - electronic health records
OT  - gpt-4
OT  - large language models
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/08/30 06:48
MHDA- 2023/08/30 06:49
PMCR- 2023/07/29
CRDT- 2023/08/30 03:44
PHST- 2023/07/28 00:00 [accepted]
PHST- 2023/08/30 06:49 [medline]
PHST- 2023/08/30 06:48 [pubmed]
PHST- 2023/08/30 03:44 [entrez]
PHST- 2023/07/29 00:00 [pmc-release]
AID - 10.7759/cureus.42634 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 29;15(7):e42634. doi: 10.7759/cureus.42634. eCollection 2023 
      Jul.

PMID- 37203482
OWN - NLM
STAT- MEDLINE
DCOM- 20230522
LR  - 20230522
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 302
DP  - 2023 May 18
TI  - Health-Related Content in Transformer-Based Language Models: Exploring Bias in 
      Domain General vs. Domain Specific Training Sets.
PG  - 743-744
LID - 10.3233/SHTI230252 [doi]
AB  - In this communication, we demonstrate that the bias observed in domain general 
      training sets with health-related content is not improved in domain specific 
      health-communication corpora, contra.
FAU - Samo, Giuseppe
AU  - Samo G
AD  - University of Geneva, Switzerland.
AD  - Beijing Language and Culture University, China.
FAU - Bonan, Caterina
AU  - Bonan C
AD  - University of Cambridge, UK.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - *Natural Language Processing
MH  - *Language
MH  - Bias
OTO - NOTNLM
OT  - COVID-19
OT  - Corpora
OT  - Health-content
OT  - Knowledge Reproduction
OT  - Language Models
OT  - Natural Language Processing
EDAT- 2023/05/19 06:42
MHDA- 2023/05/22 06:42
CRDT- 2023/05/19 05:28
PHST- 2023/05/22 06:42 [medline]
PHST- 2023/05/19 06:42 [pubmed]
PHST- 2023/05/19 05:28 [entrez]
AID - SHTI230252 [pii]
AID - 10.3233/SHTI230252 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2023 May 18;302:743-744. doi: 10.3233/SHTI230252.

PMID- 37465807
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230720
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - Harnessing Large Language Models in Nursing Care Planning: Opportunities, 
      Challenges, and Ethical Considerations.
PG  - e40542
LID - 10.7759/cureus.40542 [doi]
LID - e40542
AB  - The rapid progress in artificial intelligence (AI) and the emergence of large 
      language models (LLMs), like GPT-4, create a unique opportunity to transform 
      nursing care planning. In this editorial, we explore the potential applications 
      of AI in the nursing process, with a focus on patient data assessment and 
      interpretation, communication with patients and families, identifying gaps in 
      care plans, and ongoing professional development. We also examine the ethical 
      concerns and challenges associated with AI integration in healthcare, such as 
      data privacy and security, fairness and bias, accountability and responsibility, 
      and the delicate balance between human-AI collaboration. To implement LLMs 
      responsibly and effectively in nursing care planning, we recommend prioritizing 
      robust data security measures, transparent and unbiased algorithms, clear 
      accountability guidelines, and human-AI collaboration. By addressing these 
      issues, we can improve nursing care planning and ensure the best possible care 
      for patients.
CI  - Copyright © 2023, Nashwan et al.
FAU - Nashwan, Abdulqadir J
AU  - Nashwan AJ
AD  - Nursing Department, Hamad Medical Corporation, Doha, QAT.
FAU - Abujaber, Ahmad A
AU  - Abujaber AA
AD  - Nursing Department, Hamad Medical Corporation, Doha, QAT.
LA  - eng
PT  - Editorial
DEP - 20230616
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10350541
OTO - NOTNLM
OT  - artificial intelligence
OT  - ethical considerations
OT  - human-ai collaboration
OT  - large language models
OT  - nursing care planning
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/19 06:43
MHDA- 2023/07/19 06:44
PMCR- 2023/06/16
CRDT- 2023/07/19 04:07
PHST- 2023/06/16 00:00 [accepted]
PHST- 2023/07/19 06:44 [medline]
PHST- 2023/07/19 06:43 [pubmed]
PHST- 2023/07/19 04:07 [entrez]
PHST- 2023/06/16 00:00 [pmc-release]
AID - 10.7759/cureus.40542 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 16;15(6):e40542. doi: 10.7759/cureus.40542. eCollection 2023 
      Jun.

PMID- 37972180
OWN - NLM
STAT- MEDLINE
DCOM- 20231205
LR  - 20231205
IS  - 1095-9203 (Electronic)
IS  - 0036-8075 (Linking)
VI  - 382
IP  - 6672
DP  - 2023 Nov 17
TI  - Humans are biocultural, science should be too.
PG  - eadl1517
LID - 10.1126/science.adl1517 [doi]
AB  - COVID-19 is restructuring societies. Loneliness is a global health threat. Large 
      language models are outputting biased health care information, and 
      human-artificial intelligence (AI) interfaces are reshaping how we live. For most 
      humans, technology, biology, and society are hopelessly entangled. Are the 
      sciences prepared to tackle the contemporary human experience?
FAU - Fuentes, Agustín
AU  - Fuentes A
AUID- ORCID: 0000-0003-0955-8214
AD  - Department of Anthropology, Princeton University, Princeton, NJ, USA. 
      afuentes2@princeton.edu.
LA  - eng
PT  - Editorial
DEP - 20231117
PL  - United States
TA  - Science
JT  - Science (New York, N.Y.)
JID - 0404511
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *COVID-19/psychology
MH  - *Loneliness
MH  - *Culture
EDAT- 2023/11/17 15:28
MHDA- 2023/11/27 12:44
CRDT- 2023/11/16 14:06
PHST- 2023/11/27 12:44 [medline]
PHST- 2023/11/17 15:28 [pubmed]
PHST- 2023/11/16 14:06 [entrez]
AID - 10.1126/science.adl1517 [doi]
PST - ppublish
SO  - Science. 2023 Nov 17;382(6672):eadl1517. doi: 10.1126/science.adl1517. Epub 2023 
      Nov 17.

PMID- 39023885
OWN - NLM
STAT- MEDLINE
DCOM- 20240919
LR  - 20240919
IS  - 2168-6173 (Electronic)
IS  - 2168-6165 (Print)
IS  - 2168-6165 (Linking)
VI  - 142
IP  - 9
DP  - 2024 Sep 1
TI  - Development and Evaluation of a Retrieval-Augmented Large Language Model 
      Framework for Ophthalmology.
PG  - 798-805
LID - 10.1001/jamaophthalmol.2024.2513 [doi]
AB  - IMPORTANCE: Although augmenting large language models (LLMs) with knowledge bases 
      may improve medical domain-specific performance, practical methods are needed for 
      local implementation of LLMs that address privacy concerns and enhance 
      accessibility for health care professionals. OBJECTIVE: To develop an accurate, 
      cost-effective local implementation of an LLM to mitigate privacy concerns and 
      support their practical deployment in health care settings. DESIGN, SETTING, AND 
      PARTICIPANTS: ChatZOC (Sun Yat-Sen University Zhongshan Ophthalmology Center), a 
      retrieval-augmented LLM framework, was developed by enhancing a baseline LLM with 
      a comprehensive ophthalmic dataset and evaluation framework (CODE), which 
      includes over 30 000 pieces of ophthalmic knowledge. This LLM was benchmarked 
      against 10 representative LLMs, including GPT-4 and GPT-3.5 Turbo (OpenAI), 
      across 300 clinical questions in ophthalmology. The evaluation, involving a panel 
      of medical experts and biomedical researchers, focused on accuracy, utility, and 
      safety. A double-masked approach was used to try to minimize bias assessment 
      across all models. The study used a comprehensive knowledge base derived from 
      ophthalmic clinical practice, without directly involving clinical patients. 
      EXPOSURES: LLM response to clinical questions. MAIN OUTCOMES AND MEASURES: 
      Accuracy, utility, and safety of LLMs in responding to clinical questions. 
      RESULTS: The baseline model achieved a human ranking score of 0.48. The 
      retrieval-augmented LLM had a score of 0.60, a difference of 0.12 (95% CI, 
      0.02-0.22; P = .02) from baseline and not different from GPT-4 with a score of 
      0.61 (difference = 0.01; 95% CI, -0.11 to 0.13; P = .89). For scientific 
      consensus, the retrieval-augmented LLM was 84.0% compared with the baseline model 
      of 46.5% (difference = 37.5%; 95% CI, 29.0%-46.0%; P < .001) and not different 
      from GPT-4 with a value of 79.2% (difference = 4.8%; 95% CI, -0.3% to 10.0%; 
      P = .06). CONCLUSIONS AND RELEVANCE: Results of this quality improvement study 
      suggest that the integration of high-quality knowledge bases improved the LLM's 
      performance in medical domains. This study highlights the transformative 
      potential of augmented LLMs in clinical practice by providing reliable, safe, and 
      practical clinical information. Further research is needed to explore the broader 
      application of such frameworks in the real world.
FAU - Luo, Ming-Jie
AU  - Luo MJ
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Pang, Jianyu
AU  - Pang J
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Bi, Shaowei
AU  - Bi S
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Lai, Yunxi
AU  - Lai Y
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Zhao, Jiaman
AU  - Zhao J
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Shang, Yuanrui
AU  - Shang Y
AD  - The Second Affiliated Hospital of Xi'an Jiaotong University, Xi'an, China.
FAU - Cui, Tingxin
AU  - Cui T
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Yang, Yahan
AU  - Yang Y
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Lin, Zhenzhe
AU  - Lin Z
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Zhao, Lanqin
AU  - Zhao L
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Wu, Xiaohang
AU  - Wu X
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Lin, Duoru
AU  - Lin D
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Chen, Jingjing
AU  - Chen J
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
FAU - Lin, Haotian
AU  - Lin H
AD  - State Key Laboratory of Ophthalmology, Zhongshan Ophthalmic Center, Sun Yat-sen 
      University, Guangdong Provincial Key Laboratory of Ophthalmology and Visual 
      Science, Guangdong Provincial Clinical Research Center for Ocular Diseases, 
      Guangzhou, China.
AD  - Center for Precision Medicine and Department of Genetics and Biomedical 
      Informatics, Zhongshan School of Medicine, Sun Yat-sen University, Guangzhou, 
      Guangdong, China.
AD  - Hainan Eye Hospital and Key Laboratory of Ophthalmology, Zhongshan Ophthalmic 
      Center, Sun Yat-sen University, Haikou, China.
LA  - eng
PT  - Comment
PT  - Journal Article
PL  - United States
TA  - JAMA Ophthalmol
JT  - JAMA ophthalmology
JID - 101589539
SB  - IM
CON - JAMA Ophthalmol. 2024 Sep 1;142(9):806-807. doi: 
      10.1001/jamaophthalmol.2024.2738. PMID: 39023863
MH  - Humans
MH  - *Ophthalmology
MH  - Knowledge Bases
PMC - PMC11258636
COIS- Conflict of Interest Disclosures: None reported.
EDAT- 2024/07/18 12:44
MHDA- 2024/09/20 11:30
PMCR- 2024/07/18
CRDT- 2024/07/18 11:33
PHST- 2024/09/20 11:30 [medline]
PHST- 2024/07/18 12:44 [pubmed]
PHST- 2024/07/18 11:33 [entrez]
PHST- 2024/07/18 00:00 [pmc-release]
AID - 2820953 [pii]
AID - eoi240041 [pii]
AID - 10.1001/jamaophthalmol.2024.2513 [doi]
PST - ppublish
SO  - JAMA Ophthalmol. 2024 Sep 1;142(9):798-805. doi: 
      10.1001/jamaophthalmol.2024.2513.

PMID- 38107365
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231219
IS  - 1985-2533 (Print)
IS  - 2232-111X (Electronic)
IS  - 1985-2533 (Linking)
VI  - 17
IP  - 3
DP  - 2023 Nov
TI  - Artificial Intelligence: Impact and Challenges to Authors, Journals and Medical 
      Publishing.
PG  - 1-4
LID - 10.5704/MOJ.2311.001 [doi]
AB  - Artificial intelligence (AI)-assisted technologies are here to stay and cannot be 
      ignored. These tools are able to generate highly-realistic human-like text and 
      perform a wide range of useful language tasks with a wide range of applications. 
      They have the potential to expedite innovation in health care and can aid in 
      promoting equity and diversity in research by overcoming language barriers. When 
      using these AI tools, authors must take responsibility for the output and 
      originality of their work, as publishers expect all content to be generated by 
      human authors unless there is a declaration to the contrary. Authors must 
      disclose how AI tools have been used, and ensure appropriate attribution of all 
      the text, images, and audio-visual material. The responsible use of AI language 
      models and transparent reporting of how these tools were used in the creation of 
      information and publication are vital to promote and protect the credibility and 
      integrity of medical research, and trust in medical knowledge. Educating 
      postgraduate and undergraduate students, researchers and authors on the 
      applications and best usage of AI-assisted technologies, together with the 
      importance of critical thinking, integrity and strict adherence to ethical 
      principles, are key steps that need to be undertaken.
CI  - © 2023 Malaysian Orthopaedic Association (MOA). All Rights Reserved.
FAU - Peh, Wcg
AU  - Peh W
AD  - Department of Diagnostic Radiology, Khoo Teck Puat Hospital, Singapore.
FAU - Saw, A
AU  - Saw A
AD  - Department of Orthopaedic Surgery (NOCERAL), University of Malaya, Kuala Lumpur, 
      Malaysia.
LA  - eng
PT  - Editorial
PL  - Malaysia
TA  - Malays Orthop J
JT  - Malaysian orthopaedic journal
JID - 101564672
PMC - PMC10723007
EDAT- 2023/12/18 06:42
MHDA- 2023/12/18 06:43
PMCR- 2023/11/01
CRDT- 2023/12/18 04:56
PHST- 2023/09/17 00:00 [received]
PHST- 2023/09/20 00:00 [accepted]
PHST- 2023/12/18 06:43 [medline]
PHST- 2023/12/18 06:42 [pubmed]
PHST- 2023/12/18 04:56 [entrez]
PHST- 2023/11/01 00:00 [pmc-release]
AID - 10.5704/MOJ.2311.001 [doi]
PST - ppublish
SO  - Malays Orthop J. 2023 Nov;17(3):1-4. doi: 10.5704/MOJ.2311.001.

PMID- 39359332
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241004
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 10
DP  - 2024 Oct
TI  - OpenAI o1-Preview vs. ChatGPT in Healthcare: A New Frontier in Medical AI 
      Reasoning.
PG  - e70640
LID - 10.7759/cureus.70640 [doi]
LID - e70640
AB  - This editorial explores the recent advancements in generative artificial 
      intelligence with the newly-released OpenAI o1-Preview, comparing its 
      capabilities to the traditional ChatGPT (GPT-4) model, particularly in the 
      context of healthcare. While ChatGPT has shown many applications for general 
      medical advice and patient interactions, OpenAI o1-Preview introduces new 
      features with advanced reasoning skills using a chain of thought processes that 
      could enable users to tackle more complex medical queries such as genetic disease 
      discovery, multi-system or complex disease care, and medical research support. 
      The article explores some of the new model's potential and other aspects that may 
      affect its usage, like slower response times due to its extensive reasoning 
      approach yet highlights its potential for reducing hallucinations and offering 
      more accurate outputs for complex medical problems. Ethical challenges, data 
      diversity, access equity, and transparency are also discussed, identifying key 
      areas for future research, including optimizing the use of both models in tandem 
      for healthcare applications. The editorial concludes by advocating for 
      collaborative exploration of all large language models (LLMs), including the 
      novel OpenAI o1-Preview, to fully utilize their transformative potential in 
      medicine and healthcare delivery. This model, with its advanced reasoning 
      capabilities, presents an opportunity to empower healthcare professionals, 
      policymakers, and computer scientists to work together in transforming patient 
      care, accelerating medical research, and enhancing healthcare outcomes. By 
      optimizing the use of several LLM models in tandem, healthcare systems may 
      enhance efficiency and precision, as well as mitigate previous LLM challenges, 
      such as ethical concerns, access disparities, and technical limitations, steering 
      to a new era of artificial intelligence (AI)-driven healthcare.
CI  - Copyright © 2024, Temsah et al.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - Pediatric Intensive Care Unit, Pediatric Department, College of Medicine, King 
      Saud University Medical City, King Saud University, Riyadh, SAU.
FAU - Jamal, Amr
AU  - Jamal A
AD  - Family and Community Medicine Department, King Saud University, Riyadh, SAU.
FAU - Alhasan, Khalid
AU  - Alhasan K
AD  - Pediatric Nephrology Department, King Saud University, Riyadh, SAU.
FAU - Temsah, Abdulkarim A
AU  - Temsah AA
AD  - Dental Department, Specialized Medical Center Hospital, Riyadh, SAU.
FAU - Malki, Khalid H
AU  - Malki KH
AD  - College of Medicine, King Saud University, Riyadh, SAU.
LA  - eng
PT  - Editorial
DEP - 20241001
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11444422
OTO - NOTNLM
OT  - ai ethics
OT  - artificial intelligence
OT  - chain of thought
OT  - chatgpt
OT  - complex reasoning
OT  - genetic disease discovery
OT  - hallucinations
OT  - healthcare applications
OT  - openai o1-preview
OT  - transparency in ai and llms black box
COIS- Conflicts of interest: In compliance with the ICMJE uniform disclosure form, all 
      authors declare the following: Payment/services info: All authors have declared 
      that no financial support was received from any organization for the submitted 
      work. Financial relationships: All authors have declared that they have no 
      financial relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2024/10/03 11:42
MHDA- 2024/10/03 11:43
PMCR- 2024/10/01
CRDT- 2024/10/03 04:24
PHST- 2024/10/01 00:00 [accepted]
PHST- 2024/10/03 11:43 [medline]
PHST- 2024/10/03 11:42 [pubmed]
PHST- 2024/10/03 04:24 [entrez]
PHST- 2024/10/01 00:00 [pmc-release]
AID - 10.7759/cureus.70640 [doi]
PST - epublish
SO  - Cureus. 2024 Oct 1;16(10):e70640. doi: 10.7759/cureus.70640. eCollection 2024 
      Oct.

PMID- 37268890
OWN - NLM
STAT- MEDLINE
DCOM- 20230605
LR  - 20240919
IS  - 1471-2105 (Electronic)
IS  - 1471-2105 (Linking)
VI  - 24
IP  - 1
DP  - 2023 Jun 2
TI  - An analysis of entity normalization evaluation biases in specialized domains.
PG  - 227
LID - 10.1186/s12859-023-05350-9 [doi]
LID - 227
AB  - BACKGROUND: Entity normalization is an important information extraction task 
      which has recently gained attention, particularly in the clinical/biomedical and 
      life science domains. On several datasets, state-of-the-art methods perform 
      rather well on popular benchmarks. Yet, we argue that the task is far from 
      resolved. RESULTS: We have selected two gold standard corpora and two 
      state-of-the-art methods to highlight some evaluation biases. We present 
      non-exhaustive initial findings on the existence of evaluation problems of the 
      entity normalization task. CONCLUSIONS: Our analysis suggests better evaluation 
      practices to support the methodological research in this field.
CI  - © 2023. The Author(s).
FAU - Ferré, Arnaud
AU  - Ferré A
AD  - MaIAGE, INRAE, Université Paris-Saclay, Jouy-en-Josas, France. 
      arnaud.ferre@inrae.fr.
FAU - Langlais, Philippe
AU  - Langlais P
AD  - RALI, DIRO, Université de Montréal, Montreal, Canada.
LA  - eng
PT  - Journal Article
DEP - 20230602
PL  - England
TA  - BMC Bioinformatics
JT  - BMC bioinformatics
JID - 100965194
SB  - IM
MH  - *Information Storage and Retrieval
MH  - *Biological Science Disciplines
MH  - Research Design
MH  - Bias
MH  - Natural Language Processing
PMC - PMC10236701
OTO - NOTNLM
OT  - Ablation study
OT  - Corpus
OT  - Dataset
OT  - Entity normalization
OT  - Evaluation
COIS- The authors declare that they have no competing interests.
EDAT- 2023/06/03 11:42
MHDA- 2023/06/05 06:42
PMCR- 2023/06/02
CRDT- 2023/06/02 23:31
PHST- 2022/09/06 00:00 [received]
PHST- 2023/05/24 00:00 [accepted]
PHST- 2023/06/05 06:42 [medline]
PHST- 2023/06/03 11:42 [pubmed]
PHST- 2023/06/02 23:31 [entrez]
PHST- 2023/06/02 00:00 [pmc-release]
AID - 10.1186/s12859-023-05350-9 [pii]
AID - 5350 [pii]
AID - 10.1186/s12859-023-05350-9 [doi]
PST - epublish
SO  - BMC Bioinformatics. 2023 Jun 2;24(1):227. doi: 10.1186/s12859-023-05350-9.

PMID- 38712148
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241119
DP  - 2024 Apr 27
TI  - A Systematic Review of ChatGPT and Other Conversational Large Language Models in 
      Healthcare.
LID - 2024.04.26.24306390 [pii]
LID - 10.1101/2024.04.26.24306390 [doi]
AB  - BACKGROUND: The launch of the Chat Generative Pre-trained Transformer (ChatGPT) 
      in November 2022 has attracted public attention and academic interest to large 
      language models (LLMs), facilitating the emergence of many other innovative LLMs. 
      These LLMs have been applied in various fields, including healthcare. Numerous 
      studies have since been conducted regarding how to employ state-of-the-art LLMs 
      in health-related scenarios to assist patients, doctors, and public health 
      administrators. OBJECTIVE: This review aims to summarize the applications and 
      concerns of applying conversational LLMs in healthcare and provide an agenda for 
      future research on LLMs in healthcare. METHODS: We utilized PubMed, ACM, and IEEE 
      digital libraries as primary sources for this review. We followed the guidance of 
      Preferred Reporting Items for Systematic Reviews and Meta-Analyses (PRIMSA) to 
      screen and select peer-reviewed research articles that (1) were related to both 
      healthcare applications and conversational LLMs and (2) were published before 
      September 1(st), 2023, the date when we started paper collection and screening. 
      We investigated these papers and classified them according to their applications 
      and concerns. RESULTS: Our search initially identified 820 papers according to 
      targeted keywords, out of which 65 papers met our criteria and were included in 
      the review. The most popular conversational LLM was ChatGPT from OpenAI (60), 
      followed by Bard from Google (1), Large Language Model Meta AI (LLaMA) from Meta 
      (1), and other LLMs (5). These papers were classified into four categories in 
      terms of their applications: 1) summarization, 2) medical knowledge inquiry, 3) 
      prediction, and 4) administration, and four categories of concerns: 1) 
      reliability, 2) bias, 3) privacy, and 4) public acceptability. There are 49 (75%) 
      research papers using LLMs for summarization and/or medical knowledge inquiry, 
      and 58 (89%) research papers expressing concerns about reliability and/or bias. 
      We found that conversational LLMs exhibit promising results in summarization and 
      providing medical knowledge to patients with a relatively high accuracy. However, 
      conversational LLMs like ChatGPT are not able to provide reliable answers to 
      complex health-related tasks that require specialized domain expertise. 
      Additionally, no experiments in our reviewed papers have been conducted to 
      thoughtfully examine how conversational LLMs lead to bias or privacy issues in 
      healthcare research. CONCLUSIONS: Future studies should focus on improving the 
      reliability of LLM applications in complex health-related tasks, as well as 
      investigating the mechanisms of how LLM applications brought bias and privacy 
      issues. Considering the vast accessibility of LLMs, legal, social, and technical 
      efforts are all needed to address concerns about LLMs to promote, improve, and 
      regularize the application of LLMs in healthcare.
FAU - Wang, Leyao
AU  - Wang L
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA, 37212.
FAU - Wan, Zhiyu
AU  - Wan Z
AUID- ORCID: 0000-0003-3752-5778
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, TN, 
      USA, 37203.
FAU - Ni, Congning
AU  - Ni C
AUID- ORCID: 0000-0001-6950-6948
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA, 37212.
FAU - Song, Qingyuan
AU  - Song Q
AUID- ORCID: 0000-0002-2999-8690
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA, 37212.
FAU - Li, Yang
AU  - Li Y
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA, 37212.
FAU - Clayton, Ellen Wright
AU  - Clayton EW
AUID- ORCID: 0000-0002-0308-4110
AD  - Department of Pediatrics, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA, 37203.
AD  - Center for Biomedical Ethics and Society, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA, 37203.
FAU - Malin, Bradley A
AU  - Malin BA
AUID- ORCID: 0000-0003-3040-5175
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA, 37212.
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, TN, 
      USA, 37203.
AD  - Department of Biostatistics, Vanderbilt University Medical Center, TN, USA, 
      37203.
FAU - Yin, Zhijun
AU  - Yin Z
AUID- ORCID: 0000-0002-3075-1337
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN, USA, 37212.
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, TN, 
      USA, 37203.
LA  - eng
GR  - R37 CA237452/CA/NCI NIH HHS/United States
GR  - RM1 HG009034/HG/NHGRI NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240427
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - J Med Internet Res. 2024 Nov 7;26:e22769. doi: 10.2196/22769. PMID: 39509695
PMC - PMC11071576
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - bias
OT  - healthcare
OT  - large language model
OT  - medical knowledge inquiry
OT  - natural language processing
OT  - privacy
OT  - reliability
OT  - summarization
COIS- Conflicts of Interest None declared.
EDAT- 2024/05/07 06:42
MHDA- 2024/05/07 06:43
PMCR- 2024/05/06
CRDT- 2024/05/07 03:47
PHST- 2024/05/07 06:42 [pubmed]
PHST- 2024/05/07 06:43 [medline]
PHST- 2024/05/07 03:47 [entrez]
PHST- 2024/05/06 00:00 [pmc-release]
AID - 2024.04.26.24306390 [pii]
AID - 10.1101/2024.04.26.24306390 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Apr 27:2024.04.26.24306390. doi: 
      10.1101/2024.04.26.24306390.

PMID- 38231545
OWN - NLM
STAT- MEDLINE
DCOM- 20240118
LR  - 20240203
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Jan 17
TI  - ChatGPT in Medical Education: A Precursor for Automation Bias?
PG  - e50174
LID - 10.2196/50174 [doi]
LID - e50174
AB  - Artificial intelligence (AI) in health care has the promise of providing accurate 
      and efficient results. However, AI can also be a black box, where the logic 
      behind its results is nonrational. There are concerns if these questionable 
      results are used in patient care. As physicians have the duty to provide care 
      based on their clinical judgment in addition to their patients' values and 
      preferences, it is crucial that physicians validate the results from AI. Yet, 
      there are some physicians who exhibit a phenomenon known as automation bias, 
      where there is an assumption from the user that AI is always right. This is a 
      dangerous mindset, as users exhibiting automation bias will not validate the 
      results, given their trust in AI systems. Several factors impact a user's 
      susceptibility to automation bias, such as inexperience or being born in the 
      digital age. In this editorial, I argue that these factors and a lack of AI 
      education in the medical school curriculum cause automation bias. I also explore 
      the harms of automation bias and why prospective physicians need to be vigilant 
      when using AI. Furthermore, it is important to consider what attitudes are being 
      taught to students when introducing ChatGPT, which could be some students' first 
      time using AI, prior to their use of AI in the clinical setting. Therefore, in 
      attempts to avoid the problem of automation bias in the long-term, in addition to 
      incorporating AI education into the curriculum, as is necessary, the use of 
      ChatGPT in medical education should be limited to certain tasks. Otherwise, 
      having no constraints on what ChatGPT should be used for could lead to automation 
      bias.
CI  - ©Tina Nguyen. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 17.01.2024.
FAU - Nguyen, Tina
AU  - Nguyen T
AUID- ORCID: 0000-0002-3021-8161
AD  - The University of Texas Medical Branch, Galveston, TX, United States.
LA  - eng
PT  - Editorial
DEP - 20240117
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Prospective Studies
MH  - Automation
MH  - *Education, Medical
MH  - Educational Status
PMC - PMC10831594
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLMs
OT  - artificial intelligence
OT  - automation bias
OT  - bias
OT  - large language models
OT  - medical education
OT  - medical school curriculum
OT  - medical students
OT  - residents
COIS- Conflicts of Interest: None declared.
EDAT- 2024/01/17 12:43
MHDA- 2024/01/18 06:42
PMCR- 2024/01/17
CRDT- 2024/01/17 11:53
PHST- 2023/06/21 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2024/01/18 06:42 [medline]
PHST- 2024/01/17 12:43 [pubmed]
PHST- 2024/01/17 11:53 [entrez]
PHST- 2024/01/17 00:00 [pmc-release]
AID - v10i1e50174 [pii]
AID - 10.2196/50174 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Jan 17;10:e50174. doi: 10.2196/50174.

PMID- 38144532
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231225
IS  - 2234-943X (Print)
IS  - 2234-943X (Electronic)
IS  - 2234-943X (Linking)
VI  - 13
DP  - 2023
TI  - Corrigendum: Commentary: AI-based online chat and the future of oncology care: a 
      promising technology or a solution in search of a problem?
PG  - 1334176
LID - 10.3389/fonc.2023.1334176 [doi]
LID - 1334176
AB  - [This corrects the article DOI: 10.3389/fonc.2023.1239932.].
CI  - Copyright © 2023 Zhang, Guan, Chen and Tong.
FAU - Zhang, Hui
AU  - Zhang H
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, China.
FAU - Guan, Yongfu
AU  - Guan Y
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, China.
FAU - Chen, Jinping
AU  - Chen J
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, China.
FAU - Tong, Wenting
AU  - Tong W
AD  - Department of Pharmacy, Gannan Healthcare Vocational College, Ganzhou, China.
LA  - eng
PT  - Published Erratum
DEP - 20231207
PL  - Switzerland
TA  - Front Oncol
JT  - Frontiers in oncology
JID - 101568867
EFR - Front Oncol. 2023 Sep 07;13:1239932. doi: 10.3389/fonc.2023.1239932. PMID: 
      37746294
PMC - PMC10746848
OTO - NOTNLM
OT  - ChatGPT
OT  - data privacy
OT  - global healthcare resource allocation
OT  - language bias
OT  - legal and ethical challenges
EDAT- 2023/12/25 06:41
MHDA- 2023/12/25 06:42
PMCR- 2023/12/07
CRDT- 2023/12/25 04:37
PHST- 2023/11/09 00:00 [received]
PHST- 2023/11/24 00:00 [accepted]
PHST- 2023/12/25 06:42 [medline]
PHST- 2023/12/25 06:41 [pubmed]
PHST- 2023/12/25 04:37 [entrez]
PHST- 2023/12/07 00:00 [pmc-release]
AID - 10.3389/fonc.2023.1334176 [doi]
PST - epublish
SO  - Front Oncol. 2023 Dec 7;13:1334176. doi: 10.3389/fonc.2023.1334176. eCollection 
      2023.

PMID- 37904073
OWN - NLM
STAT- MEDLINE
DCOM- 20240228
LR  - 20250202
IS  - 1525-1497 (Electronic)
IS  - 0884-8734 (Print)
IS  - 0884-8734 (Linking)
VI  - 39
IP  - 3
DP  - 2024 Feb
TI  - Chatting Beyond ChatGPT: Advancing Equity Through AI-Driven Language 
      Interpretation.
PG  - 492-495
LID - 10.1007/s11606-023-08497-6 [doi]
AB  - Medical interpretation is an underutilized resource, despite its legal mandate 
      and proven efficacy in improving health outcomes for populations with low English 
      proficiency. This disconnect can often be attributed to the costs and wait-times 
      associated with traditional means of interpretation, making the service 
      inaccessible and burdensome. Technology has improved access to translation 
      through phone and video interpretation; with the acceleration of artificial 
      intelligence (AI) large language models, we have an opportunity to further 
      improve interpreter access through real-time, automated translation. The impetus 
      to utilize this burgeoning tool for improved health equity must be combined with 
      a critical view of the safety, privacy, and clinical decision-making risks 
      involved. Physicians must be active participants and collaborators in both the 
      mobilization of AI tools to improve clinical care and the development of 
      regulations to mitigate harm.
CI  - © 2023. The Author(s), under exclusive licence to Society of General Internal 
      Medicine.
FAU - Bakdash, Leen
AU  - Bakdash L
AUID- ORCID: 0009-0002-3954-2483
AD  - Emory University School of Medicine, Atlanta, GA, 30322, USA. lbakdas@emory.edu.
FAU - Abid, Areeba
AU  - Abid A
AD  - Emory University School of Medicine, Atlanta, GA, 30322, USA.
FAU - Gourisankar, Amritha
AU  - Gourisankar A
AD  - Emory University School of Medicine, Atlanta, GA, 30322, USA.
FAU - Henry, Tracey L
AU  - Henry TL
AD  - Division of General Medicine, Emory University School of Medicine, Atlanta, GA, 
      USA.
LA  - eng
PT  - Editorial
DEP - 20231030
PL  - United States
TA  - J Gen Intern Med
JT  - Journal of general internal medicine
JID - 8605834
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Allied Health Personnel
MH  - Clinical Decision-Making
MH  - *Health Equity
MH  - Language
PMC - PMC10897100
COIS- There are no conflicts of interest for the authors.
EDAT- 2023/10/31 06:42
MHDA- 2024/02/28 06:44
PMCR- 2025/02/01
CRDT- 2023/10/31 00:44
PHST- 2023/07/17 00:00 [received]
PHST- 2023/10/16 00:00 [accepted]
PHST- 2024/02/28 06:44 [medline]
PHST- 2023/10/31 06:42 [pubmed]
PHST- 2023/10/31 00:44 [entrez]
PHST- 2025/02/01 00:00 [pmc-release]
AID - 10.1007/s11606-023-08497-6 [pii]
AID - 8497 [pii]
AID - 10.1007/s11606-023-08497-6 [doi]
PST - ppublish
SO  - J Gen Intern Med. 2024 Feb;39(3):492-495. doi: 10.1007/s11606-023-08497-6. Epub 
      2023 Oct 30.

PMID- 39864170
OWN - NLM
STAT- MEDLINE
DCOM- 20250126
LR  - 20250130
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 12
DP  - 2025 Jan 20
TI  - Responsible Design, Integration, and Use of Generative AI in Mental Health.
PG  - e70439
LID - 10.2196/70439 [doi]
LID - e70439
AB  - Generative artificial intelligence (GenAI) shows potential for personalized care, 
      psychoeducation, and even crisis prediction in mental health, yet responsible use 
      requires ethical consideration and deliberation and perhaps even governance. This 
      is the first published theme issue focused on responsible GenAI in mental health. 
      It brings together evidence and insights on GenAI's capabilities, such as emotion 
      recognition, therapy-session summarization, and risk assessment, while 
      highlighting the sensitive nature of mental health data and the need for rigorous 
      validation. Contributors discuss how bias, alignment with human values, 
      transparency, and empathy must be carefully addressed to ensure ethically 
      grounded, artificial intelligence-assisted care. By proposing conceptual 
      frameworks; best practices; and regulatory approaches, including ethics of care 
      and the preservation of socially important humanistic elements, this theme issue 
      underscores that GenAI can complement, rather than replace, the vital role of 
      human empathy in clinical settings. To achieve this, an ongoing collaboration 
      between researchers, clinicians, policy makers, and technologists is essential.
CI  - © Oren Asman, John Torous, Amir Tal. Originally published in JMIR Mental Health 
      (https://mental.jmir.org).
FAU - Asman, Oren
AU  - Asman O
AUID- ORCID: 0000-0003-2439-6997
AD  - Department of Nursing, Faculty of Medical and Health Sciences, Tel Aviv 
      University, P.O.B 39040, Ramat Aviv, Tel Aviv, 6997801, Israel, 972 547608020.
AD  - The Samueli Initiative for Responsible AI in Medicine, Tel Aviv University, Tel 
      Aviv, Israel.
FAU - Torous, John
AU  - Torous J
AUID- ORCID: 0000-0002-5362-7937
AD  - Department of Psychiatry, Beth Israel Deaconess Medical Center, Harvard Medical 
      School, Cambridge, United States.
FAU - Tal, Amir
AU  - Tal A
AUID- ORCID: 0000-0002-6099-8904
AD  - The Samueli Initiative for Responsible AI in Medicine, Tel Aviv University, Tel 
      Aviv, Israel.
AD  - Faculty of Medical and Health Sciences, Tel Aviv University, Tel Aviv, Israel.
LA  - eng
PT  - Editorial
PT  - Introductory Journal Article
DEP - 20250120
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence/ethics
MH  - Empathy
MH  - Mental Health Services/organization & administration
MH  - Mental Health
MH  - Mental Disorders/therapy
PMC - PMC11769776
OTO - NOTNLM
OT  - AI ethics
OT  - artificial intelligence
OT  - digital mental health ethics
OT  - large language model
OT  - model alignment
OT  - responsible AI in medicine
COIS- AT and OA are authors of the paper “An Ethical Perspective on the Democratization 
      of Mental Health With Generative AI” [20] in this theme issue of JMIR Mental 
      Health. AT and OA are guest editors for this theme issue. JT is the 
      editor-in-chief of JMIR Mental Health.
EDAT- 2025/01/27 00:20
MHDA- 2025/01/27 00:21
PMCR- 2025/01/20
CRDT- 2025/01/26 18:02
PHST- 2024/12/21 00:00 [received]
PHST- 2025/01/04 00:00 [revised]
PHST- 2025/01/06 00:00 [accepted]
PHST- 2025/01/27 00:21 [medline]
PHST- 2025/01/27 00:20 [pubmed]
PHST- 2025/01/26 18:02 [entrez]
PHST- 2025/01/20 00:00 [pmc-release]
AID - v12i1e70439 [pii]
AID - 70439 [pii]
AID - 10.2196/70439 [doi]
PST - epublish
SO  - JMIR Ment Health. 2025 Jan 20;12:e70439. doi: 10.2196/70439.

PMID- 37949485
OWN - NLM
STAT- MEDLINE
DCOM- 20231113
LR  - 20231122
IS  - 2755-9734 (Electronic)
IS  - 2755-9734 (Linking)
VI  - 26
IP  - 1
DP  - 2023 Nov
TI  - ChatGPT and mental healthcare: balancing benefits with risks of harms.
LID - 10.1136/bmjment-2023-300884 [doi]
LID - e300884
AB  - Against the global need for increased access to mental services, health 
      organisations are looking to technological advances to improve the delivery of 
      care and lower costs. Since November 2022, with the public launch of OpenAI's 
      ChatGPT, the field of generative artificial intelligence (AI) has received 
      expanding attention. Although generative AI itself is not new, technical advances 
      and the increased accessibility of large language models (LLMs) (eg, OpenAI's 
      GPT-4 and Google's Bard) suggest use of these tools could be clinically 
      significant. LLMs are an application of generative AI technology that can 
      summarise and generate content based on training on vast data sets. Unlike search 
      engines, which provide internet links in response to typed entries, chatbots that 
      rely on generative language models can simulate dialogue that resembles human 
      conversations. We examine the potential promise and the risks of using LLMs in 
      mental healthcare today, focusing on their scope to impact mental healthcare, 
      including global equity in the delivery of care. Although we caution that LLMs 
      should not be used to disintermediate mental health clinicians, we signal how-if 
      carefully implemented-in the long term these tools could reap benefits for 
      patients and health professionals.
CI  - © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. 
      Published by BMJ.
FAU - Blease, Charlotte
AU  - Blease C
AUID- ORCID: 0000-0002-0205-1165
AD  - Participatory eHealth and Health Data Research Group, Department of Women's and 
      Children's Health, Uppsala Universitet, Uppsala, Sweden charlotte.blease@uu.se.
AD  - Digital Psychiatry, Beth Israel Deaconess Medical Center, Harvard Medical School, 
      Boston, Massachusetts, USA.
FAU - Torous, John
AU  - Torous J
AUID- ORCID: 0000-0002-5362-7937
AD  - Psychiatry, Beth Israel Deaconess Medical Center, Harvard Medical School, Boston, 
      Massachusetts, USA.
LA  - eng
PT  - Journal Article
PL  - England
TA  - BMJ Ment Health
JT  - BMJ mental health
JID - 9918521385306676
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Mental Health
MH  - Communication
MH  - Health Facilities
MH  - *Mental Health Services
PMC - PMC10649440
OTO - NOTNLM
OT  - Adult psychiatry
OT  - Depression & mood disorders
OT  - Machine Learning
COIS- Competing interests: None declared.
EDAT- 2023/11/11 11:43
MHDA- 2023/11/13 06:43
PMCR- 2023/11/10
CRDT- 2023/11/10 20:53
PHST- 2023/09/15 00:00 [received]
PHST- 2023/10/06 00:00 [accepted]
PHST- 2023/11/13 06:43 [medline]
PHST- 2023/11/11 11:43 [pubmed]
PHST- 2023/11/10 20:53 [entrez]
PHST- 2023/11/10 00:00 [pmc-release]
AID - bmjment-2023-300884 [pii]
AID - 10.1136/bmjment-2023-300884 [doi]
PST - ppublish
SO  - BMJ Ment Health. 2023 Nov;26(1):e300884. doi: 10.1136/bmjment-2023-300884.

PMID- 37440696
OWN - NLM
STAT- Publisher
LR  - 20231020
IS  - 1536-0075 (Electronic)
IS  - 1526-5161 (Linking)
VI  - 23
IP  - 10
DP  - 2023 Oct
TI  - What Should ChatGPT Mean for Bioethics?
PG  - 8-16
LID - 10.1080/15265161.2023.2233357 [doi]
AB  - In the last several months, several major disciplines have started their initial 
      reckoning with what ChatGPT and other Large Language Models (LLMs) mean for them 
      - law, medicine, business among other professions. With a heavy dose of humility, 
      given how fast the technology is moving and how uncertain its social implications 
      are, this article attempts to give some early tentative thoughts on what ChatGPT 
      might mean for bioethics. I will first argue that many bioethics issues raised by 
      ChatGPT are similar to those raised by current medical AI - built into devices, 
      decision support tools, data analytics, etc. These include issues of data 
      ownership, consent for data use, data representativeness and bias, and privacy. I 
      describe how these familiar issues appear somewhat differently in the ChatGPT 
      context, but much of the existing bioethical thinking on these issues provides a 
      strong starting point. There are, however, a few "new-ish" issues I highlight - 
      by new-ish I mean issues that while perhaps not truly new seem much more 
      important for it than other forms of medical AI. These include issues about 
      informed consent and the right to know we are dealing with an AI, the problem of 
      medical deepfakes, the risk of oligopoly and inequitable access related to 
      foundational models, environmental effects, and on the positive side 
      opportunities for the democratization of knowledge and empowering patients. I 
      also discuss how races towards dominance (between large companies and between the 
      U.S. and geopolitical rivals like China) risk sidelining ethics.
FAU - Cohen, I Glenn
AU  - Cohen IG
AD  - Petrie-Flom Center for Health Law Policy, Biotechnology & Bioethics, Harvard Law 
      School.
LA  - eng
PT  - Journal Article
DEP - 20230713
PL  - United States
TA  - Am J Bioeth
JT  - The American journal of bioethics : AJOB
JID - 100898738
SB  - IM
CIN - Am J Bioeth. 2023 Oct;23(10):60-63. doi: 10.1080/15265161.2023.2250292. PMID: 
      37812095
CIN - Am J Bioeth. 2023 Oct;23(10):63-65. doi: 10.1080/15265161.2023.2250290. PMID: 
      37812097
CIN - Am J Bioeth. 2023 Oct;23(10):65-68. doi: 10.1080/15265161.2023.2250311. PMID: 
      37812098
CIN - Am J Bioeth. 2023 Oct;23(10):80-82. doi: 10.1080/15265161.2023.2250278. PMID: 
      37812099
CIN - Am J Bioeth. 2023 Oct;23(10):74-77. doi: 10.1080/15265161.2023.2250297. PMID: 
      37812102
CIN - Am J Bioeth. 2023 Oct;23(10):102-104. doi: 10.1080/15265161.2023.2250294. PMID: 
      37812104
CIN - Am J Bioeth. 2023 Oct;23(10):113-115. doi: 10.1080/15265161.2023.2250293. PMID: 
      37812105
CIN - Am J Bioeth. 2023 Oct;23(10):99-102. doi: 10.1080/15265161.2023.2250319. PMID: 
      37812106
CIN - Am J Bioeth. 2023 Oct;23(10):110-113. doi: 10.1080/15265161.2023.2250318. PMID: 
      37812107
CIN - Am J Bioeth. 2023 Oct;23(10):86-88. doi: 10.1080/15265161.2023.2250317. PMID: 
      37812108
CIN - Am J Bioeth. 2023 Oct;23(10):52-54. doi: 10.1080/15265161.2023.2249854. PMID: 
      37812110
CIN - Am J Bioeth. 2023 Oct;23(10):107-110. doi: 10.1080/15265161.2023.2250312. PMID: 
      37812112
CIN - Am J Bioeth. 2023 Oct;23(10):55-57. doi: 10.1080/15265161.2023.2250279. PMID: 
      37812113
CIN - Am J Bioeth. 2023 Oct;23(10):42-44. doi: 10.1080/15265161.2023.2249852. PMID: 
      37812114
CIN - Am J Bioeth. 2023 Oct;23(10):83-85. doi: 10.1080/15265161.2023.2250289. PMID: 
      37812116
CIN - Am J Bioeth. 2023 Oct;23(10):58-60. doi: 10.1080/15265161.2023.2250284. PMID: 
      37812118
CIN - Am J Bioeth. 2023 Oct;23(10):77-80. doi: 10.1080/15265161.2023.2250306. PMID: 
      37812122
CIN - Am J Bioeth. 2023 Oct;23(10):71-73. doi: 10.1080/15265161.2023.2250305. PMID: 
      37812123
CIN - Am J Bioeth. 2023 Oct;23(10):1-5. doi: 10.1080/15265161.2023.2252311. PMID: 
      37831940
OTO - NOTNLM
OT  - ChatGPT
OT  - bias
OT  - environment
OT  - informed consent
OT  - large language model (LLM)
OT  - oligopoly
OT  - privacy
EDAT- 2023/07/13 19:15
MHDA- 2023/07/13 19:15
CRDT- 2023/07/13 14:43
PHST- 2023/07/13 19:15 [pubmed]
PHST- 2023/07/13 19:15 [medline]
PHST- 2023/07/13 14:43 [entrez]
AID - 10.1080/15265161.2023.2233357 [doi]
PST - ppublish
SO  - Am J Bioeth. 2023 Oct;23(10):8-16. doi: 10.1080/15265161.2023.2233357. Epub 2023 
      Jul 13.

PMID- 37494894
OWN - NLM
STAT- MEDLINE
DCOM- 20231127
LR  - 20231127
IS  - 1423-002X (Electronic)
IS  - 0378-7346 (Linking)
VI  - 88
IP  - 5
DP  - 2023
TI  - Diagnostic and Management Performance of ChatGPT in Obstetrics and Gynecology.
PG  - 310-313
LID - 10.1159/000533177 [doi]
AB  - OBJECTIVES: The use of artificial intelligence (AI) in clinical patient 
      management and medical education has been advancing over time. ChatGPT was 
      developed and trained recently, using a large quantity of textual data from the 
      internet. Medical science is expected to be transformed by its use. The present 
      study was conducted to evaluate the diagnostic and management performance of the 
      ChatGPT AI model in obstetrics and gynecology. DESIGN: A cross-sectional study 
      was conducted. PARTICIPANTS/MATERIALS, SETTING, METHODS: This study was conducted 
      in Iran in March 2023. Medical histories and examination results of 30 cases were 
      determined in six areas of obstetrics and gynecology. The cases were presented to 
      a gynecologist and ChatGPT for diagnosis and management. Answers from the 
      gynecologist and ChatGPT were compared, and the diagnostic and management 
      performance of ChatGPT were determined. RESULTS: Ninety percent (27 of 30) of the 
      cases in obstetrics and gynecology were correctly handled by ChatGPT. Its 
      responses were eloquent, informed, and free of a significant number of errors or 
      misinformation. Even when the answers provided by ChatGPT were incorrect, the 
      responses contained a logical explanation about the case as well as information 
      provided in the question stem. LIMITATIONS: The data used in this study were 
      taken from the electronic book and may reflect bias in the diagnosis of ChatGPT. 
      CONCLUSIONS: This is the first evaluation of ChatGPT's performance in diagnosis 
      and management in the field of obstetrics and gynecology. It appears that ChatGPT 
      has potential applications in the practice of medicine and is (currently) free 
      and simple to use. However, several ethical considerations and limitations such 
      as bias, validity, copyright infringement, and plagiarism need to be addressed in 
      future studies.
CI  - © 2023 S. Karger AG, Basel.
FAU - Allahqoli, Leila
AU  - Allahqoli L
AD  - Midwifery Department, Ministry of Health and Medical Education, Tehran, Iran, 
      lallahqoli@gmail.com.
FAU - Ghiasvand, Mohammad Matin
AU  - Ghiasvand MM
AD  - Department of Computer Engineering, Amirkabir University of Technology (AUT), 
      Tehran, Iran.
FAU - Mazidimoradi, Afrooz
AU  - Mazidimoradi A
AD  - Student Research Committee, Shiraz University of Medical Sciences, Shiraz, Iran.
FAU - Salehiniya, Hamid
AU  - Salehiniya H
AD  - Social Determinants of Health Research Center, Birjand University of Medical 
      Sciences, Birjand, Iran.
FAU - Alkatout, Ibrahim
AU  - Alkatout I
AD  - Campus Kiel, Kiel School of Gynaecological Endoscopy, University Hospitals 
      Schleswig-Holstein, Kiel, Germany.
LA  - eng
PT  - News
DEP - 20230726
PL  - Switzerland
TA  - Gynecol Obstet Invest
JT  - Gynecologic and obstetric investigation
JID - 7900587
SB  - IM
MH  - Female
MH  - Pregnancy
MH  - Humans
MH  - *Gynecology
MH  - Artificial Intelligence
MH  - Cross-Sectional Studies
MH  - *Obstetrics
MH  - Gynecologists
OTO - NOTNLM
OT  - Artificial intelligence model
OT  - ChatGPT
OT  - Diagnostic performance
OT  - Gynecology
OT  - Management
OT  - Obstetrics
EDAT- 2023/07/27 01:09
MHDA- 2023/11/27 12:41
CRDT- 2023/07/26 18:23
PHST- 2023/05/19 00:00 [received]
PHST- 2023/07/20 00:00 [accepted]
PHST- 2023/11/27 12:41 [medline]
PHST- 2023/07/27 01:09 [pubmed]
PHST- 2023/07/26 18:23 [entrez]
AID - 000533177 [pii]
AID - 10.1159/000533177 [doi]
PST - ppublish
SO  - Gynecol Obstet Invest. 2023;88(5):310-313. doi: 10.1159/000533177. Epub 2023 Jul 
      26.

PMID- 33989164
OWN - NLM
STAT- MEDLINE
DCOM- 20210531
LR  - 20210629
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 23
IP  - 5
DP  - 2021 May 26
TI  - Authors' Reply to: Minimizing Selection and Classification Biases Comment on 
      "Clinical Characteristics and Prognostic Factors for Intensive Care Unit 
      Admission of Patients With COVID-19: Retrospective Study Using Machine Learning 
      and Natural Language Processing".
PG  - e29405
LID - 10.2196/29405 [doi]
LID - e29405
FAU - Izquierdo, Jose Luis
AU  - Izquierdo JL
AUID- ORCID: 0000-0002-0012-931X
AD  - Universidad de Alcalá, Madrid, Spain.
FAU - Soriano, Joan B
AU  - Soriano JB
AUID- ORCID: 0000-0001-9740-2994
AD  - Hospital Universitario de La Princesa, Madrid, Spain.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20210526
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
CON - J Med Internet Res. 2021 May 26;23(5):e27142. doi: 10.2196/27142. PMID: 33989163
MH  - Bias
MH  - *COVID-19
MH  - Humans
MH  - Intensive Care Units
MH  - Machine Learning
MH  - *Natural Language Processing
MH  - Prognosis
MH  - Retrospective Studies
MH  - SARS-CoV-2
PMC - PMC8190644
OTO - NOTNLM
OT  - COVID-19
OT  - SARS-CoV-2
OT  - artificial intelligence
OT  - big data
OT  - classification bias
OT  - critical care
OT  - electronic health records
OT  - predictive model
OT  - prognosis
OT  - tachypnea
COIS- Conflicts of Interest: None declared.
EDAT- 2021/05/15 06:00
MHDA- 2021/06/01 06:00
PMCR- 2021/05/26
CRDT- 2021/05/14 17:17
PHST- 2021/04/06 00:00 [received]
PHST- 2021/05/13 00:00 [accepted]
PHST- 2021/05/15 06:00 [pubmed]
PHST- 2021/06/01 06:00 [medline]
PHST- 2021/05/14 17:17 [entrez]
PHST- 2021/05/26 00:00 [pmc-release]
AID - v23i5e29405 [pii]
AID - 10.2196/29405 [doi]
PST - epublish
SO  - J Med Internet Res. 2021 May 26;23(5):e29405. doi: 10.2196/29405.

PMID- 33989163
OWN - NLM
STAT- MEDLINE
DCOM- 20210531
LR  - 20210629
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 23
IP  - 5
DP  - 2021 May 26
TI  - Minimizing Selection and Classification Biases. Comment on "Clinical 
      Characteristics and Prognostic Factors for Intensive Care Unit Admission of 
      Patients With COVID-19: Retrospective Study Using Machine Learning and Natural 
      Language Processing".
PG  - e27142
LID - 10.2196/27142 [doi]
LID - e27142
FAU - Martos Pérez, Francisco
AU  - Martos Pérez F
AUID- ORCID: 0000-0003-3660-2743
AD  - Department of Internal Medicine, Hospital Costa del Sol, Marbella, Spain.
FAU - Gomez Huelgas, Ricardo
AU  - Gomez Huelgas R
AUID- ORCID: 0000-0002-9909-3555
AD  - Internal Medicine Department, Hospital Regional de Málaga, Málaga, Spain.
FAU - Martín Escalante, María Dolores
AU  - Martín Escalante MD
AUID- ORCID: 0000-0003-1932-8682
AD  - Department of Internal Medicine, Hospital Costa del Sol, Marbella, Spain.
FAU - Casas Rojo, José Manuel
AU  - Casas Rojo JM
AUID- ORCID: 0000-0002-6649-4301
AD  - Internal Medicine Department, Infanta Cristina University Hospital, Parla 
      (Madrid), Spain.
LA  - eng
PT  - Comment
PT  - Journal Article
DEP - 20210526
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
CON - J Med Internet Res. 2020 Oct 28;22(10):e21801. doi: 10.2196/21801. PMID: 33090964
CIN - J Med Internet Res. 2021 May 26;23(5):e29405. doi: 10.2196/29405. PMID: 33989164
MH  - Bias
MH  - *COVID-19
MH  - Humans
MH  - Intensive Care Units
MH  - Machine Learning
MH  - *Natural Language Processing
MH  - Prognosis
MH  - Retrospective Studies
MH  - SARS-CoV-2
PMC - PMC8190647
OTO - NOTNLM
OT  - COVID-19
OT  - SARS-CoV-2
OT  - artificial intelligence
OT  - big data
OT  - classification bias
OT  - critical care
OT  - electronic health records
OT  - predictive model
OT  - prognosis
OT  - tachypnea
COIS- Conflicts of Interest: None declared.
EDAT- 2021/05/15 06:00
MHDA- 2021/06/01 06:00
PMCR- 2021/05/26
CRDT- 2021/05/14 17:17
PHST- 2021/01/12 00:00 [received]
PHST- 2021/05/13 00:00 [accepted]
PHST- 2021/05/15 06:00 [pubmed]
PHST- 2021/06/01 06:00 [medline]
PHST- 2021/05/14 17:17 [entrez]
PHST- 2021/05/26 00:00 [pmc-release]
AID - v23i5e27142 [pii]
AID - 10.2196/27142 [doi]
PST - epublish
SO  - J Med Internet Res. 2021 May 26;23(5):e27142. doi: 10.2196/27142.

PMID- 35738008
OWN - NLM
STAT- MEDLINE
DCOM- 20220908
LR  - 20231011
IS  - 1745-1701 (Electronic)
IS  - 0586-7614 (Print)
IS  - 0586-7614 (Linking)
VI  - 48
IP  - 5
DP  - 2022 Sep 1
TI  - Natural Language Processing and Psychosis: On the Need for Comprehensive 
      Psychometric Evaluation.
PG  - 939-948
LID - 10.1093/schbul/sbac051 [doi]
AB  - BACKGROUND AND HYPOTHESIS: Despite decades of "proof of concept" findings 
      supporting the use of Natural Language Processing (NLP) in psychosis research, 
      clinical implementation has been slow. One obstacle reflects the lack of 
      comprehensive psychometric evaluation of these measures. There is overwhelming 
      evidence that criterion and content validity can be achieved for many purposes, 
      particularly using machine learning procedures. However, there has been very 
      little evaluation of test-retest reliability, divergent validity (sufficient to 
      address concerns of a "generalized deficit"), and potential biases from 
      demographics and other individual differences. STUDY DESIGN: This article 
      highlights these concerns in development of an NLP measure for tracking 
      clinically rated paranoia from video "selfies" recorded from smartphone devices. 
      Patients with schizophrenia or bipolar disorder were recruited and tracked over a 
      week-long epoch. A small NLP-based feature set from 499 language samples were 
      modeled on clinically rated paranoia using regularized regression. STUDY RESULTS: 
      While test-retest reliability was high, criterion, and convergent/divergent 
      validity were only achieved when considering moderating variables, notably 
      whether a patient was away from home, around strangers, or alone at the time of 
      the recording. Moreover, there were systematic racial and sex biases in the 
      model, in part, reflecting whether patients submitted videos when they were away 
      from home, around strangers, or alone. CONCLUSIONS: Advancing NLP measures for 
      psychosis will require deliberate consideration of test-retest reliability, 
      divergent validity, systematic biases and the potential role of moderators. In 
      our example, a comprehensive psychometric evaluation revealed clear strengths and 
      weaknesses that can be systematically addressed in future research.
CI  - © The Author(s) 2022. Published by Oxford University Press on behalf of the 
      Maryland Psychiatric Research Center. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Cohen, Alex S
AU  - Cohen AS
AUID- ORCID: 0000-0003-4014-6904
AD  - Louisiana State University, Department of Psychology, Baton Rouge, LA, USA.
AD  - Louisiana State University, Center for Computation and Technology, Baton Rouge, 
      LA, USA.
FAU - Rodriguez, Zachary
AU  - Rodriguez Z
AD  - Louisiana State University, Department of Psychology, Baton Rouge, LA, USA.
AD  - Louisiana State University, Center for Computation and Technology, Baton Rouge, 
      LA, USA.
FAU - Warren, Kiara K
AU  - Warren KK
AD  - Louisiana State University, Department of Psychology, Baton Rouge, LA, USA.
FAU - Cowan, Tovah
AU  - Cowan T
AD  - Louisiana State University, Department of Psychology, Baton Rouge, LA, USA.
FAU - Masucci, Michael D
AU  - Masucci MD
AD  - Louisiana State University, Department of Psychology, Baton Rouge, LA, USA.
FAU - Edvard Granrud, Ole
AU  - Edvard Granrud O
AD  - Louisiana State University, Department of Psychology, Baton Rouge, LA, USA.
FAU - Holmlund, Terje B
AU  - Holmlund TB
AUID- ORCID: 0000-0001-5305-5062
AD  - University of Tromsø-The Arctic University of Norway, Tromso, Norway.
FAU - Chandler, Chelsea
AU  - Chandler C
AUID- ORCID: 0000-0002-9409-0937
AD  - University of Colorado, Institute of Cognitive Science, Boulder, CO, USA.
AD  - University of Colorado, Department of Computer Science, Boulder, CO, USA.
FAU - Foltz, Peter W
AU  - Foltz PW
AD  - University of Colorado, Institute of Cognitive Science, Boulder, CO, USA.
AD  - University of Colorado, Department of Computer Science, Boulder, CO, USA.
FAU - Strauss, Gregory P
AU  - Strauss GP
AD  - University of Georgia, Department of Psychology, Athens, GA, USA.
LA  - eng
GR  - R21 MH112925/MH/NIMH NIH HHS/United States
GR  - T34 GM136452/GM/NIGMS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PL  - United States
TA  - Schizophr Bull
JT  - Schizophrenia bulletin
JID - 0236760
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Psychometrics
MH  - *Psychotic Disorders
MH  - Reproducibility of Results
MH  - Surveys and Questionnaires
PMC - PMC9434462
OTO - NOTNLM
OT  - bias
OT  - machine learning
OT  - paranoia
OT  - psychometrics
OT  - psychosis
OT  - reliability
OT  - validity
EDAT- 2022/06/24 06:00
MHDA- 2022/09/09 06:00
PMCR- 2023/06/23
CRDT- 2022/06/23 17:52
PHST- 2022/06/24 06:00 [pubmed]
PHST- 2022/09/09 06:00 [medline]
PHST- 2022/06/23 17:52 [entrez]
PHST- 2023/06/23 00:00 [pmc-release]
AID - 6615341 [pii]
AID - sbac051 [pii]
AID - 10.1093/schbul/sbac051 [doi]
PST - ppublish
SO  - Schizophr Bull. 2022 Sep 1;48(5):939-948. doi: 10.1093/schbul/sbac051.

PMID- 37694729
OWN - NLM
STAT- MEDLINE
DCOM- 20231109
LR  - 20231109
IS  - 1651-2251 (Electronic)
IS  - 0001-6489 (Linking)
VI  - 143
IP  - 9
DP  - 2023 Sep
TI  - Validity of the large language model ChatGPT (GPT4) as a patient information 
      source in otolaryngology by a variety of doctors in a tertiary 
      otorhinolaryngology department.
PG  - 779-782
LID - 10.1080/00016489.2023.2254809 [doi]
AB  - BACKGROUND: A high number of patients seek health information online, and large 
      language models (LLMs) may produce a rising amount of it. AIM: This study 
      evaluates the performance regarding health information provided by ChatGPT, a LLM 
      developed by OpenAI, focusing on its utility as a source for 
      otolaryngology-related patient information. MATERIAL AND METHOD: A variety of 
      doctors from a tertiary otorhinolaryngology department used a Likert scale to 
      assess the chatbot's responses in terms of accuracy, relevance, and depth. The 
      responses were also evaluated by ChatGPT. RESULTS: The composite mean of the 
      three categories was 3.41, with the highest performance noted in the relevance 
      category (mean = 3.71) when evaluated by the respondents. The accuracy and depth 
      categories yielded mean scores of 3.51 and 3.00, respectively. All the categories 
      were rated as 5 when evaluated by ChatGPT. CONCLUSION AND SIGNIFICANCE: Despite 
      its potential in providing relevant and accurate medical information, the 
      chatbot's responses lacked depth and were found to potentially perpetuate biases 
      due to its training on publicly available text. In conclusion, while LLMs show 
      promise in healthcare, further refinement is necessary to enhance response depth 
      and mitigate potential biases.
FAU - Nielsen, Jacob P S
AU  - Nielsen JPS
AD  - Department of Otorhinolaryngology-Head and Neck Surgery and Audiology, Copenhagen 
      University Hospital, Rigshospitalet, Copenhagen, Denmark.
FAU - von Buchwald, Christian
AU  - von Buchwald C
AD  - Department of Otorhinolaryngology-Head and Neck Surgery and Audiology, Copenhagen 
      University Hospital, Rigshospitalet, Copenhagen, Denmark.
FAU - Grønhøj, Christian
AU  - Grønhøj C
AD  - Department of Otorhinolaryngology-Head and Neck Surgery and Audiology, Copenhagen 
      University Hospital, Rigshospitalet, Copenhagen, Denmark.
LA  - eng
PT  - Editorial
DEP - 20230911
PL  - England
TA  - Acta Otolaryngol
JT  - Acta oto-laryngologica
JID - 0370354
SB  - IM
MH  - Humans
MH  - Information Sources
MH  - *Physicians
MH  - Hospital Departments
MH  - Language
MH  - *Otolaryngology
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT4
OT  - chatbots
OT  - ear-nose-throat diseases
OT  - large language model
OT  - otolaryngology
OT  - patient information
OT  - validation study
EDAT- 2023/09/11 12:43
MHDA- 2023/11/09 06:42
CRDT- 2023/09/11 07:02
PHST- 2023/11/09 06:42 [medline]
PHST- 2023/09/11 12:43 [pubmed]
PHST- 2023/09/11 07:02 [entrez]
AID - 10.1080/00016489.2023.2254809 [doi]
PST - ppublish
SO  - Acta Otolaryngol. 2023 Sep;143(9):779-782. doi: 10.1080/00016489.2023.2254809. 
      Epub 2023 Sep 11.

PMID- 37699647
OWN - NLM
STAT- MEDLINE
DCOM- 20231207
LR  - 20231217
IS  - 1535-5675 (Electronic)
IS  - 0091-4916 (Linking)
VI  - 51
IP  - 4
DP  - 2023 Dec 5
TI  - ChatGPT and Patient Information in Nuclear Medicine: GPT-3.5 Versus GPT-4.
PG  - 307-313
LID - 10.2967/jnmt.123.266151 [doi]
AB  - The GPT-3.5-powered ChatGPT was released in late November 2022 powered by the 
      generative pretrained transformer (GPT) version 3.5. It has emerged as a readily 
      accessible source of patient information ahead of medical procedures. Although 
      ChatGPT has purported benefits for supporting patient education and information, 
      actual capability has not been evaluated. Moreover, the March 2023 emergence of 
      paid subscription access to GPT-4 promises further enhanced capabilities 
      requiring evaluation. Methods: ChatGPT was used to generate patient information 
      sheets suitable for gaining informed consent for 7 common procedures in nuclear 
      medicine. Responses were generated independently for both GPT-3.5 and GPT-4 
      architectures. Specific procedures were selected that had a long-standing history 
      of use to avoid any bias associated with the September 2021 learning cutoff that 
      constrains both GPT-3.5 and GPT-4 architectures. Each information sheet was 
      independently evaluated by 3 expert assessors and ranked on the basis of 
      accuracy, appropriateness, currency, and fitness for purpose. Results: ChatGPT 
      powered by GPT-3.5 provided patient information that was appropriate in terms of 
      being patient-facing but lacked accuracy and currency and omitted important 
      information. GPT-3.5 produced patient information deemed not fit for the purpose. 
      GPT-4 provided patient information enhanced across appropriateness, accuracy, and 
      currency, despite some omission of information. GPT-4 produced patient 
      information that was largely fit for the purpose. Conclusion: Although ChatGPT 
      powered by GPT-3.5 is accessible and provides plausible patient information, 
      inaccuracies and omissions present a risk to patients and informed consent. 
      Conversely, GPT-4 is more accurate and fit for the purpose but, at the time of 
      writing, was available only through a paid subscription.
CI  - © 2023 by the Society of Nuclear Medicine and Molecular Imaging.
FAU - Currie, Geoff
AU  - Currie G
AD  - School of Dentistry and Medical Sciences, Charles Sturt University, Wagga Wagga, 
      New South Wales, Australia; gcurrie@csu.edu.au.
FAU - Robbie, Stephanie
AU  - Robbie S
AD  - Queensland X-Ray, St. Andrews Hospital, Toowoomba, Queensland, Australia; and.
FAU - Tually, Peter
AU  - Tually P
AD  - School of Dentistry and Medical Sciences, Charles Sturt University, Wagga Wagga, 
      New South Wales, Australia.
AD  - Telemed Health, Kalgoorlie, Western Australia, Australia.
LA  - eng
PT  - Journal Article
DEP - 20231205
PL  - United States
TA  - J Nucl Med Technol
JT  - Journal of nuclear medicine technology
JID - 0430303
SB  - IM
MH  - Humans
MH  - *Nuclear Medicine
MH  - Radionuclide Imaging
MH  - Learning
MH  - Salaries and Fringe Benefits
MH  - Writing
OTO - NOTNLM
OT  - ChatGPT
OT  - GPT-4
OT  - generative AI
OT  - language model
OT  - patient education
EDAT- 2023/09/13 00:41
MHDA- 2023/12/07 12:42
CRDT- 2023/09/12 20:33
PHST- 2023/06/08 00:00 [received]
PHST- 2023/07/13 00:00 [revised]
PHST- 2023/12/07 12:42 [medline]
PHST- 2023/09/13 00:41 [pubmed]
PHST- 2023/09/12 20:33 [entrez]
AID - jnmt.123.266151 [pii]
AID - 10.2967/jnmt.123.266151 [doi]
PST - epublish
SO  - J Nucl Med Technol. 2023 Dec 5;51(4):307-313. doi: 10.2967/jnmt.123.266151.

PMID- 38188345
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240109
IS  - 2296-858X (Print)
IS  - 2296-858X (Electronic)
IS  - 2296-858X (Linking)
VI  - 10
DP  - 2023
TI  - The opportunities and challenges of adopting ChatGPT in medical research.
PG  - 1259640
LID - 10.3389/fmed.2023.1259640 [doi]
LID - 1259640
AB  - PURPOSE: This study aims to investigate the opportunities and challenges of 
      adopting ChatGPT in medical research. METHODS: A qualitative approach with focus 
      groups is adopted in this study. A total of 62 participants including academic 
      researchers from different streams in medicine and eHealth, participated in this 
      study. RESULTS: A total of five themes with 16 sub-themes related to the 
      opportunities; and a total of five themes with 12 sub-themes related to the 
      challenges were identified. The major opportunities include improved data 
      collection and analysis, improved communication and accessibility, and support 
      for researchers in multiple streams of medical research. The major challenges 
      identified were limitations of training data leading to bias, ethical issues, 
      technical limitations, and limitations in data collection and analysis. 
      CONCLUSION: Although ChatGPT can be used as a potential tool in medical research, 
      there is a need for further evidence to generalize its impact on the different 
      research activities.
CI  - Copyright © 2023 Alsadhan, Al-Anezi, Almohanna, Alnaim, Alzahrani, Shinawi, 
      AboAlsamh, Bakhshwain, Alenazy, Arif, Alyousef, Alhamidi, Alghamdi, AlShrayfi, 
      Rubaian, Alanzi, AlSahli, Alturki and Herzallah.
FAU - Alsadhan, Abeer
AU  - Alsadhan A
AD  - Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
FAU - Al-Anezi, Fahad
AU  - Al-Anezi F
AD  - Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
FAU - Almohanna, Asmaa
AU  - Almohanna A
AD  - Princess Nourah Bint Abdulrahman University, Riyadh, Saudi Arabia.
FAU - Alnaim, Norah
AU  - Alnaim N
AD  - Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
FAU - Alzahrani, Hayat
AU  - Alzahrani H
AD  - Northern Border University, Arar, Saudi Arabia.
FAU - Shinawi, Reem
AU  - Shinawi R
AD  - Eastern Health Cluster, Dammam, Saudi Arabia.
FAU - AboAlsamh, Hoda
AU  - AboAlsamh H
AD  - Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
FAU - Bakhshwain, Amal
AU  - Bakhshwain A
AD  - Ministry of Health, Riyadh, Riyadh, Saudi Arabia.
FAU - Alenazy, Maha
AU  - Alenazy M
AD  - King Saud University, Riyadh, Riyadh, Saudi Arabia.
FAU - Arif, Wejdan
AU  - Arif W
AD  - King Saud University, Riyadh, Riyadh, Saudi Arabia.
FAU - Alyousef, Seham
AU  - Alyousef S
AD  - King Saud University, Riyadh, Riyadh, Saudi Arabia.
FAU - Alhamidi, Sami
AU  - Alhamidi S
AD  - King Saud University, Riyadh, Riyadh, Saudi Arabia.
FAU - Alghamdi, Alya
AU  - Alghamdi A
AD  - King Saud University, Riyadh, Riyadh, Saudi Arabia.
FAU - AlShrayfi, Nour
AU  - AlShrayfi N
AD  - Public Authority for Applied Education and Training, Kuwait City, Kuwait.
FAU - Rubaian, Nouf Bin
AU  - Rubaian NB
AD  - Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
FAU - Alanzi, Turki
AU  - Alanzi T
AD  - Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
FAU - AlSahli, Alaa
AU  - AlSahli A
AD  - King Saud bin Abdulaziz University for Health Sciences, Riyadh, Saudi Arabia.
FAU - Alturki, Rasha
AU  - Alturki R
AD  - Imam Abdulrahman Bin Faisal University, Dammam, Saudi Arabia.
FAU - Herzallah, Nawal
AU  - Herzallah N
AD  - University College London, London, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20231222
PL  - Switzerland
TA  - Front Med (Lausanne)
JT  - Frontiers in medicine
JID - 101648047
PMC - PMC10766839
OTO - NOTNLM
OT  - ChatGPT
OT  - challenges and successes
OT  - healthcare
OT  - medical research
OT  - opportunities and application
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/01/08 06:42
MHDA- 2024/01/08 06:43
PMCR- 2023/12/22
CRDT- 2024/01/08 05:10
PHST- 2023/07/16 00:00 [received]
PHST- 2023/12/07 00:00 [accepted]
PHST- 2024/01/08 06:43 [medline]
PHST- 2024/01/08 06:42 [pubmed]
PHST- 2024/01/08 05:10 [entrez]
PHST- 2023/12/22 00:00 [pmc-release]
AID - 10.3389/fmed.2023.1259640 [doi]
PST - epublish
SO  - Front Med (Lausanne). 2023 Dec 22;10:1259640. doi: 10.3389/fmed.2023.1259640. 
      eCollection 2023.

PMID- 39476977
OWN - NLM
STAT- In-Process
LR  - 20250225
IS  - 1097-6787 (Electronic)
IS  - 0190-9622 (Linking)
VI  - 92
IP  - 3
DP  - 2025 Mar
TI  - Assessing the diagnostic performance of ChatGPT in dermatology across Fitzpatrick 
      phototypes and skin of color.
PG  - 578-579
LID - S0190-9622(24)03053-6 [pii]
LID - 10.1016/j.jaad.2024.10.038 [doi]
FAU - Lau, Charles B
AU  - Lau CB
AD  - Department of Dermatology, Boston University Chobanian & Avedisian School of 
      Medicine, Boston, Massachusetts; Department of Dermatology, Massachusetts General 
      Hospital, Boston, Massachusetts. Electronic address: clau20@bu.edu.
FAU - Kwa, Michael
AU  - Kwa M
AD  - Department of Dermatology, Boston University Chobanian & Avedisian School of 
      Medicine, Boston, Massachusetts.
FAU - Shen, Lisa
AU  - Shen L
AD  - Department of Dermatology, Boston University Chobanian & Avedisian School of 
      Medicine, Boston, Massachusetts.
FAU - Smith, Gideon P
AU  - Smith GP
AD  - Department of Dermatology, Massachusetts General Hospital, Boston, Massachusetts.
LA  - eng
PT  - Journal Article
DEP - 20241028
PL  - United States
TA  - J Am Acad Dermatol
JT  - Journal of the American Academy of Dermatology
JID - 7907132
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Fitzpatrick phototypes
OT  - artificial intelligence
OT  - dermatology
OT  - health care disparities
OT  - skin of color
OT  - skin phototype
COIS- Conflicts of interest None disclosed.
EDAT- 2024/10/31 04:20
MHDA- 2024/10/31 04:20
CRDT- 2024/10/30 20:22
PHST- 2024/04/12 00:00 [received]
PHST- 2024/10/03 00:00 [revised]
PHST- 2024/10/11 00:00 [accepted]
PHST- 2024/10/31 04:20 [pubmed]
PHST- 2024/10/31 04:20 [medline]
PHST- 2024/10/30 20:22 [entrez]
AID - S0190-9622(24)03053-6 [pii]
AID - 10.1016/j.jaad.2024.10.038 [doi]
PST - ppublish
SO  - J Am Acad Dermatol. 2025 Mar;92(3):578-579. doi: 10.1016/j.jaad.2024.10.038. Epub 
      2024 Oct 28.

PMID- 39443582
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241026
IS  - 2397-768X (Print)
IS  - 2397-768X (Electronic)
IS  - 2397-768X (Linking)
VI  - 8
IP  - 1
DP  - 2024 Oct 23
TI  - Large language model use in clinical oncology.
PG  - 240
LID - 10.1038/s41698-024-00733-4 [doi]
LID - 240
AB  - Large language models (LLMs) are undergoing intensive research for various 
      healthcare domains. This systematic review and meta-analysis assesses current 
      applications, methodologies, and the performance of LLMs in clinical oncology. A 
      mixed-methods approach was used to extract, summarize, and compare methodological 
      approaches and outcomes. This review includes 34 studies. LLMs are primarily 
      evaluated on their ability to answer oncologic questions across various domains. 
      The meta-analysis highlights a significant performance variance, influenced by 
      diverse methodologies and evaluation criteria. Furthermore, differences in 
      inherent model capabilities, prompting strategies, and oncological subdomains 
      contribute to heterogeneity. The lack of use of standardized and LLM-specific 
      reporting protocols leads to methodological disparities, which must be addressed 
      to ensure comparability in LLM research and ultimately leverage the reliable 
      integration of LLM technologies into clinical practice.
CI  - © 2024. The Author(s).
FAU - Carl, Nicolas
AU  - Carl N
AD  - Department of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
AD  - Department of Urology and Urological Surgery, University Medical Center Mannheim, 
      Ruprecht-Karls University Heidelberg, Mannheim, Germany.
FAU - Schramm, Franziska
AU  - Schramm F
AD  - Department of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Haggenmüller, Sarah
AU  - Haggenmüller S
AD  - Department of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Kather, Jakob Nikolas
AU  - Kather JN
AD  - Else Kroener Fresenius Center for Digital Health, Medical Faculty Carl Gustav 
      Carus, Technical University Dresden, Dresden, Germany.
FAU - Hetz, Martin J
AU  - Hetz MJ
AD  - Department of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Wies, Christoph
AU  - Wies C
AUID- ORCID: 0000-0001-7136-298X
AD  - Department of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
AD  - Medical Faculty, Ruprecht-Karls University Heidelberg, Heidelberg, Germany.
FAU - Michel, Maurice Stephan
AU  - Michel MS
AD  - Department of Urology and Urological Surgery, University Medical Center Mannheim, 
      Ruprecht-Karls University Heidelberg, Mannheim, Germany.
FAU - Wessels, Frederik
AU  - Wessels F
AUID- ORCID: 0000-0003-4213-8692
AD  - Department of Urology and Urological Surgery, University Medical Center Mannheim, 
      Ruprecht-Karls University Heidelberg, Mannheim, Germany.
FAU - Brinker, Titus J
AU  - Brinker TJ
AUID- ORCID: 0000-0002-3620-5919
AD  - Department of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany. titus.brinker@dkfz.de.
LA  - eng
PT  - Journal Article
DEP - 20241023
PL  - England
TA  - NPJ Precis Oncol
JT  - NPJ precision oncology
JID - 101708166
PMC - PMC11499929
COIS- The authors declare the following financial interests/personal relationships 
      which may be considered as potential competing interests: T.J.B. would like to 
      disclose that he is the owner of Smart Health Heidelberg GmbH (Handschuhsheimer 
      Landstr. 9/1, 69120 Heidelberg, Germany; https://smarthealth.de), outside the 
      submitted work. F.W. would like to disclose that he advises Janssen, AstraZeneca, 
      and Adon Health outside the submitted work. J.N.K. would like to disclose 
      consulting services for Owkin, France; DoMore Diagnostics, Norway; Panakeia, UK; 
      AstraZeneca, UK; Scailyte, Switzerland; Mindpeak, Germany; and MultiplexDx, 
      Slovakia. Furthermore, he holds shares in StratifAI GmbH, Germany, has received a 
      research grant from GSK, and has received honoraria from AstraZeneca, Bayer, 
      Eisai, Janssen, MSD, BMS, Roche, Pfizer and Fresenius. J.N.K. is Deputy Editor at 
      npj Precision Oncology, but did not have a role in the editorial assessment of 
      this article. The other authors have no competing interests to declare.
EDAT- 2024/10/24 16:21
MHDA- 2024/10/24 16:22
PMCR- 2024/10/23
CRDT- 2024/10/24 00:06
PHST- 2024/05/29 00:00 [received]
PHST- 2024/10/12 00:00 [accepted]
PHST- 2024/10/24 16:22 [medline]
PHST- 2024/10/24 16:21 [pubmed]
PHST- 2024/10/24 00:06 [entrez]
PHST- 2024/10/23 00:00 [pmc-release]
AID - 10.1038/s41698-024-00733-4 [pii]
AID - 733 [pii]
AID - 10.1038/s41698-024-00733-4 [doi]
PST - epublish
SO  - NPJ Precis Oncol. 2024 Oct 23;8(1):240. doi: 10.1038/s41698-024-00733-4.

PMID- 37485160
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230725
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 6
DP  - 2023 Jun
TI  - Eyes on AI: ChatGPT's Transformative Potential Impact on Ophthalmology.
PG  - e40765
LID - 10.7759/cureus.40765 [doi]
LID - e40765
AB  - ChatGPT, a large language model by OpenAI, has been adopted in various domains 
      since its release in November 2022, but its application in ophthalmology remains 
      less explored. This editorial assesses ChatGPT's potential applications and 
      limitations in ophthalmology across clinical, educational, and research settings. 
      In clinical settings, ChatGPT can serve as an assistant, offering diagnostic and 
      therapeutic suggestions based on patient data and assisting in patient triage. 
      However, its tendencies to generate inaccurate results and its inability to keep 
      up with recent medical guidelines render it unsuitable for standalone clinical 
      decision-making. Data security and compliance with the Health Insurance 
      Portability and Accountability Act (HIPAA) also pose concerns, given ChatGPT's 
      potential to inadvertently expose sensitive patient information. In education, 
      ChatGPT can generate practice questions, provide explanations, and create patient 
      education materials. However, its performance in answering domain-specific 
      questions is suboptimal. In research, ChatGPT can facilitate literature reviews, 
      data analysis, manuscript development, and peer review, but issues of accuracy, 
      bias, and ethics need careful consideration. Ultimately, ensuring accuracy, 
      ethical integrity, and data privacy is essential when integrating ChatGPT into 
      ophthalmology.
CI  - Copyright © 2023, Dossantos et al.
FAU - Dossantos, Jason
AU  - Dossantos J
AD  - Ophthalmology, George Washington University School of Medicine and Health 
      Sciences, Washington, USA.
FAU - An, Jella
AU  - An J
AD  - Ophthalmology, Johns Hopkins University School of Medicine Wilmer Eye Institute, 
      Baltimore, USA.
FAU - Javan, Ramin
AU  - Javan R
AD  - Radiology, George Washington University School of Medicine and Health Sciences, 
      Washington, USA.
LA  - eng
PT  - Editorial
DEP - 20230621
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10362525
OTO - NOTNLM
OT  - artificial intelligence
OT  - artificial intelligence in medicine
OT  - chatgpt
OT  - large language models
OT  - ophthalmology
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/24 06:42
MHDA- 2023/07/24 06:43
PMCR- 2023/06/21
CRDT- 2023/07/24 04:54
PHST- 2023/06/21 00:00 [accepted]
PHST- 2023/07/24 06:43 [medline]
PHST- 2023/07/24 06:42 [pubmed]
PHST- 2023/07/24 04:54 [entrez]
PHST- 2023/06/21 00:00 [pmc-release]
AID - 10.7759/cureus.40765 [doi]
PST - epublish
SO  - Cureus. 2023 Jun 21;15(6):e40765. doi: 10.7759/cureus.40765. eCollection 2023 
      Jun.

PMID- 31671140
OWN - NLM
STAT- MEDLINE
DCOM- 20200313
LR  - 20231014
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 14
IP  - 10
DP  - 2019
TI  - An exploration of automated narrative analysis via machine learning.
PG  - e0224634
LID - 10.1371/journal.pone.0224634 [doi]
LID - e0224634
AB  - The accuracy of four machine learning methods in predicting narrative 
      macrostructure scores was compared to scores obtained by human raters utilizing a 
      criterion-referenced progress monitoring rubric. The machine learning methods 
      that were explored covered methods that utilized hand-engineered features, as 
      well as those that learn directly from the raw text. The predictive models were 
      trained on a corpus of 414 narratives from a normative sample of school-aged 
      children (5;0-9;11) who were given a standardized measure of narrative 
      proficiency. Performance was measured using Quadratic Weighted Kappa, a metric of 
      inter-rater reliability. The results indicated that one model, BERT, not only 
      achieved significantly higher scoring accuracy than the other methods, but was 
      consistent with scores obtained by human raters using a valid and reliable 
      rubric. The findings from this study suggest that a machine learning method, 
      specifically, BERT, shows promise as a way to automate the scoring of narrative 
      macrostructure for potential use in clinical practice.
FAU - Jones, Sharad
AU  - Jones S
AUID- ORCID: 0000-0002-1119-8660
AD  - Department of Mathematics and Statistics, Utah State University, Logan, Utah, 
      United States of America.
FAU - Fox, Carly
AU  - Fox C
AUID- ORCID: 0000-0003-1344-4965
AD  - Department of Special Education and Rehabilitation, Utah State University, Logan, 
      Utah, United States of America.
FAU - Gillam, Sandra
AU  - Gillam S
AD  - Department of Communication Disorders and Deaf Education, Utah State University, 
      Logan, Utah, United States of America.
FAU - Gillam, Ronald B
AU  - Gillam RB
AD  - Department of Communication Disorders and Deaf Education, Utah State University, 
      Logan, Utah, United States of America.
LA  - eng
PT  - Journal Article
DEP - 20191031
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Child
MH  - Educational Measurement/*methods
MH  - Female
MH  - Humans
MH  - Machine Learning
MH  - Male
MH  - Narration
MH  - Observer Variation
MH  - *Reproducibility of Results
PMC - PMC6822746
COIS- The authors have declared that no competing interests exist.
EDAT- 2019/11/02 06:00
MHDA- 2020/03/14 06:00
PMCR- 2019/10/31
CRDT- 2019/11/01 06:00
PHST- 2019/06/11 00:00 [received]
PHST- 2019/10/17 00:00 [accepted]
PHST- 2019/11/01 06:00 [entrez]
PHST- 2019/11/02 06:00 [pubmed]
PHST- 2020/03/14 06:00 [medline]
PHST- 2019/10/31 00:00 [pmc-release]
AID - PONE-D-19-16347 [pii]
AID - 10.1371/journal.pone.0224634 [doi]
PST - epublish
SO  - PLoS One. 2019 Oct 31;14(10):e0224634. doi: 10.1371/journal.pone.0224634. 
      eCollection 2019.

PMID- 38453475
OWN - NLM
STAT- MEDLINE
DCOM- 20240715
LR  - 20240831
IS  - 1468-330X (Electronic)
IS  - 0022-3050 (Print)
IS  - 0022-3050 (Linking)
VI  - 95
IP  - 8
DP  - 2024 Jul 15
TI  - Central vein sign and trigeminal lesions of multiple sclerosis visualised by 7T 
      MRI.
PG  - 761-766
LID - 10.1136/jnnp-2023-332566 [doi]
AB  - BACKGROUND: Although trigeminal nerve involvement is a characteristic of multiple 
      sclerosis (MS), its prevalence across studies varies greatly due to MRI 
      resolution and cohort selection bias. The mechanism behind the site specificity 
      of trigeminal nerve injury is still unclear. We aim to determine the prevalence 
      of trigeminal nerve involvement in patients with MS in a consecutive 7T brain MRI 
      cohort. METHODS: This observational cohort originates from an ongoing China 
      National Registry of Neuro-Inflammatory Diseases. Inclusion criteria were the 
      following: age 18 years or older, diagnosis of MS according to the 2017 McDonald 
      criteria and no clinical relapse within the preceding 3 months. Each participant 
      underwent 7T MAGNETOM Terra scanner (Siemens, Erlangen, Germany), using a 
      32-channel phased array coil at Beijing Tiantan Hospital. T1-weighted 
      magnetisation-prepared rapid acquisition gradient echoes, fluid-attenuated 
      inversion recovery (FLAIR) and fluid and white matter suppression images were 
      used to identify lesions. FLAIR* and T2* weighted images were used to identify 
      central vein sign (CVS) within the trigeminal lesions. RESULTS: 120 patients 
      underwent 7T MRI scans between December 2021 and May 2023. 19/120 (15.8%) 
      patients had a total of 45 trigeminal lesions, of which 11/19 (57.9%) were 
      bilateral. The linear lesions extended along the trigeminal nerve, from the root 
      entry zone (REZ) (57.8%, 26/45) to the pontine-medullary nucleus (42.2%, 19/45). 
      26.9% (7/26) of the lesions in REZ showed a typical central venous sign. 
      CONCLUSION: In this 7T MRI cohort, the prevalence of trigeminal nerve involvement 
      was 15.8%. Characteristic CVS was detected in 26.9% of lesions in REZ. This 
      suggests an inflammatory demyelination mechanism of trigeminal nerve involvement 
      in MS.
CI  - © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Jing, Jing
AU  - Jing J
AUID- ORCID: 0000-0001-9822-5758
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China.
FAU - Zhang, Zhe
AU  - Zhang Z
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China.
FAU - Su, Lei
AU  - Su L
AD  - Department of Neurology, Tianjin Medical University General Hospital, Tianjin, 
      China.
FAU - Gao, Chenyang
AU  - Gao C
AD  - Department of Neurology, Tianjin Medical University General Hospital, Tianjin, 
      China.
FAU - Guo, Ai
AU  - Guo A
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China.
FAU - Liu, Xinyao
AU  - Liu X
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China.
FAU - Wang, Huabing
AU  - Wang H
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China.
FAU - Zhang, Xinghu
AU  - Zhang X
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China.
FAU - Liu, Yaou
AU  - Liu Y
AUID- ORCID: 0000-0002-8753-0260
AD  - Department of Radiology, Beijing Tiantan Hospital, Capital Medical University, 
      Beijing, China.
FAU - Comi, Giancarlo
AU  - Comi G
AD  - Department of Neurology, Institute of Experimental Neurology, Vita-Salute 
      University and San Raffaele Scientific Institute, Milan, Italy.
FAU - Waubant, Emmanuelle
AU  - Waubant E
AD  - UCSF MS Center, San Francisco, California, USA.
FAU - Shi, Fu-Dong
AU  - Shi FD
AUID- ORCID: 0000-0002-9675-4637
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China.
AD  - Department of Neurology, Tianjin Medical University General Hospital, Tianjin, 
      China.
FAU - Tian, De-Cai
AU  - Tian DC
AUID- ORCID: 0000-0002-5153-2491
AD  - Departments of Neurology, Tiantan Neuroimaging Center of Excellence, China 
      National Clinical Research Center for Neurological Diseases, Beijing Tiantan 
      Hospital, Capital Medical University, Beijing, China decaitian@hotmail.com.
LA  - eng
PT  - Journal Article
PT  - Observational Study
DEP - 20240715
PL  - England
TA  - J Neurol Neurosurg Psychiatry
JT  - Journal of neurology, neurosurgery, and psychiatry
JID - 2985191R
SB  - IM
MH  - Humans
MH  - Male
MH  - Female
MH  - Adult
MH  - *Magnetic Resonance Imaging
MH  - *Multiple Sclerosis/diagnostic imaging/pathology
MH  - Middle Aged
MH  - *Trigeminal Nerve/diagnostic imaging/pathology
MH  - Cohort Studies
MH  - Trigeminal Nerve Diseases/diagnostic imaging
MH  - Young Adult
PMC - PMC11287640
OTO - NOTNLM
OT  - MRI
OT  - MULTIPLE SCLEROSIS
COIS- Competing interests: None declared.
EDAT- 2024/03/08 00:43
MHDA- 2024/07/16 00:42
PMCR- 2024/07/30
CRDT- 2024/03/07 21:38
PHST- 2023/09/11 00:00 [received]
PHST- 2024/01/29 00:00 [accepted]
PHST- 2024/07/16 00:42 [medline]
PHST- 2024/03/08 00:43 [pubmed]
PHST- 2024/03/07 21:38 [entrez]
PHST- 2024/07/30 00:00 [pmc-release]
AID - jnnp-2023-332566 [pii]
AID - 10.1136/jnnp-2023-332566 [doi]
PST - epublish
SO  - J Neurol Neurosurg Psychiatry. 2024 Jul 15;95(8):761-766. doi: 
      10.1136/jnnp-2023-332566.

PMID- 34224606
OWN - NLM
STAT- MEDLINE
DCOM- 20211213
LR  - 20211214
IS  - 1365-2923 (Electronic)
IS  - 0308-0110 (Linking)
VI  - 55
IP  - 12
DP  - 2021 Dec
TI  - Gender bias in resident evaluations: Natural language processing and competency 
      evaluation.
PG  - 1383-1387
LID - 10.1111/medu.14593 [doi]
AB  - BACKGROUND: Research shows that female trainees experience evaluation penalties 
      for gender non-conforming behaviour during medical training. Studies of medical 
      education evaluations and performance scores do reflect a gender bias, though 
      studies are of varying methodology and results have not been consistent. 
      OBJECTIVE: We sought to examine the differences in word use, competency themes 
      and length within written evaluations of internal medicine residents at scale, 
      considering the impact of both faculty and resident gender. We hypothesised that 
      female internal medicine residents receive more negative feedback, and different 
      thematic feedback than male residents. METHODS: This study utilised a corpus of 
      3864 individual responses to positive and negative questions over the course of 
      six years (2012-2018) within Yale University School of Medicine's internal 
      medicine residency. Researchers developed a sentiment model to assess the valence 
      of evaluation responses. We then used natural language processing (NLP) to 
      evaluate whether female versus male residents received more positive or negative 
      feedback and if that feedback focussed on different Accreditation Council for 
      Graduate Medical Education (ACGME) core competencies based on their gender. 
      Evaluator-evaluatee gender dyad was analysed to see how it impacted quantity and 
      quality of feedback. RESULTS: We found that female and male residents did not 
      have substantively different numbers of positive or negative comments. While 
      certain competencies were discussed more than others, gender did not seem to 
      influence which competencies were discussed. Neither gender trainee received more 
      written feedback, though female evaluators tended to write longer evaluations. 
      CONCLUSIONS: We conclude that when examined at scale, quantitative gender 
      differences are not as prevalent as has been seen in qualitative work. We suggest 
      that further investigation of linguistic phenomena (such as context) is warranted 
      to reconcile this finding with prior work.
CI  - © 2021 John Wiley & Sons Ltd and The Association for the Study of Medical 
      Education.
FAU - Andrews, Jane
AU  - Andrews J
AD  - Department of Internal Medicine, The University of Texas Health Science Center at 
      Houston John P and Katherine G McGovern Medical School, Houston, TX, USA.
FAU - Chartash, David
AU  - Chartash D
AUID- ORCID: 0000-0002-0265-330X
AD  - Center for Medical Informatics, Yale University School of Medicine, New Haven, 
      CT, USA.
FAU - Hay, Seonaid
AU  - Hay S
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven, 
      CT, USA.
LA  - eng
PT  - Journal Article
DEP - 20210730
PL  - England
TA  - Med Educ
JT  - Medical education
JID - 7605655
SB  - IM
MH  - Clinical Competence
MH  - Education, Medical, Graduate
MH  - Female
MH  - Humans
MH  - *Internship and Residency
MH  - Male
MH  - Natural Language Processing
MH  - *Sexism
EDAT- 2021/07/06 06:00
MHDA- 2021/12/15 06:00
CRDT- 2021/07/05 17:18
PHST- 2021/06/08 00:00 [revised]
PHST- 2021/03/17 00:00 [received]
PHST- 2021/06/21 00:00 [accepted]
PHST- 2021/07/06 06:00 [pubmed]
PHST- 2021/12/15 06:00 [medline]
PHST- 2021/07/05 17:18 [entrez]
AID - 10.1111/medu.14593 [doi]
PST - ppublish
SO  - Med Educ. 2021 Dec;55(12):1383-1387. doi: 10.1111/medu.14593. Epub 2021 Jul 30.

PMID- 38361805
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241027
IS  - 2398-8835 (Electronic)
IS  - 2398-8835 (Linking)
VI  - 7
IP  - 2
DP  - 2024 Feb
TI  - ChatGPT and mental health: Friends or foes?
PG  - e1912
LID - 10.1002/hsr2.1912 [doi]
LID - e1912
AB  - BACKGROUND: ChatGPT is an artificial intelligence (AI) language model that has 
      gained popularity as a virtual assistant because of its exceptional capacity to 
      solve problems and make decisions. However, there are some ways in which 
      technological misuse and incorrect interpretations can have potentially hazardous 
      consequences for a user's mental health. DISCUSSION: Because it lacks real-time 
      fact-checking capabilities, ChatGPT may create misleading or erroneous 
      information. Considering AI technology has the potential to influence a person's 
      thinking, we anticipate ChatGPT's future repercussions on mental health by 
      considering instances in which inappropriate usage may lead to mental disorders. 
      While several studies have demonstrated how the AI model may transform mental 
      health care and therapy, certain drawbacks, including bias and privacy 
      violations, have also been identified. CONCLUSION: Educating people and 
      organizing workshops on AI technology usage, strengthening privacy measures, and 
      updating ethical standards are crucial initiatives to prevent misuse and 
      resultant dire impacts on mental health. Longitudinal research on the potential 
      of these platforms to impact a variety of mental health problems is recommended 
      in the future.
CI  - © 2024 The Authors. Health Science Reports published by Wiley Periodicals LLC.
FAU - Kalam, Khondoker Tashya
AU  - Kalam KT
AD  - Department of Pharmacy, School of Medicine University of Asia Pacific Dhaka 
      Bangladesh.
FAU - Rahman, Jannatul Mabia
AU  - Rahman JM
AD  - Department of Electrical and Electronic Engineering University of Asia Pacific 
      Dhaka Bangladesh.
FAU - Islam, Md Rabiul
AU  - Islam MR
AUID- ORCID: 0000-0003-2820-3144
AD  - School of Pharmacy BRAC University Dhaka Bangladesh.
FAU - Dewan, Syed Masudur Rahman
AU  - Dewan SMR
AUID- ORCID: 0000-0003-1443-7150
AD  - Department of Pharmacy, School of Medicine University of Asia Pacific Dhaka 
      Bangladesh.
LA  - eng
PT  - Journal Article
DEP - 20240215
PL  - United States
TA  - Health Sci Rep
JT  - Health science reports
JID - 101728855
PMC - PMC10867692
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - depression
OT  - mental health
OT  - suicide
COIS- The authors declare no conflict of interest.
EDAT- 2024/02/16 06:42
MHDA- 2024/02/16 06:43
PMCR- 2024/02/15
CRDT- 2024/02/16 03:48
PHST- 2023/09/12 00:00 [received]
PHST- 2023/11/30 00:00 [revised]
PHST- 2024/01/31 00:00 [accepted]
PHST- 2024/02/16 06:43 [medline]
PHST- 2024/02/16 06:42 [pubmed]
PHST- 2024/02/16 03:48 [entrez]
PHST- 2024/02/15 00:00 [pmc-release]
AID - HSR21912 [pii]
AID - 10.1002/hsr2.1912 [doi]
PST - epublish
SO  - Health Sci Rep. 2024 Feb 15;7(2):e1912. doi: 10.1002/hsr2.1912. eCollection 2024 
      Feb.

PMID- 34709718
OWN - NLM
STAT- MEDLINE
DCOM- 20220511
LR  - 20220731
IS  - 1759-2887 (Electronic)
IS  - 1759-2879 (Print)
IS  - 1759-2879 (Linking)
VI  - 13
IP  - 3
DP  - 2022 May
TI  - Risk of bias assessment in preclinical literature using natural language 
      processing.
PG  - 368-380
LID - 10.1002/jrsm.1533 [doi]
AB  - We sought to apply natural language processing to the task of automatic risk of 
      bias assessment in preclinical literature, which could speed the process of 
      systematic review, provide information to guide research improvement activity, 
      and support translation from preclinical to clinical research. We use 7840 
      full-text publications describing animal experiments with yes/no annotations for 
      five risk of bias items. We implement a series of models including baselines 
      (support vector machine, logistic regression, random forest), neural models 
      (convolutional neural network, recurrent neural network with attention, 
      hierarchical neural network) and models using BERT with two strategies (document 
      chunk pooling and sentence extraction). We tune hyperparameters to obtain the 
      highest F1 scores for each risk of bias item on the validation set and compare 
      evaluation results on the test set to our previous regular expression approach. 
      The F1 scores of best models on test set are 82.0% for random allocation, 81.6% 
      for blinded assessment of outcome, 82.6% for conflict of interests, 91.4% for 
      compliance with animal welfare regulations and 46.6% for reporting animals 
      excluded from analysis. Our models significantly outperform regular expressions 
      for four risk of bias items. For random allocation, blinded assessment of 
      outcome, conflict of interests and animal exclusions, neural models achieve good 
      performance; for animal welfare regulations, BERT model with a sentence 
      extraction strategy works better. Convolutional neural networks are the overall 
      best models. The tool is publicly available which may contribute to the future 
      monitoring of risk of bias reporting for research improvement activities.
CI  - © 2021 The Authors. Research Synthesis Methods published by John Wiley & Sons 
      Ltd.
FAU - Wang, Qianying
AU  - Wang Q
AUID- ORCID: 0000-0002-7779-6815
AD  - Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, UK.
FAU - Liao, Jing
AU  - Liao J
AUID- ORCID: 0000-0002-9591-8070
AD  - Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, UK.
FAU - Lapata, Mirella
AU  - Lapata M
AUID- ORCID: 0000-0002-2107-1516
AD  - School of Informatics, University of Edinburgh, Edinburgh, UK.
FAU - Macleod, Malcolm
AU  - Macleod M
AUID- ORCID: 0000-0001-9187-9839
AD  - Centre for Clinical Brain Sciences, University of Edinburgh, Edinburgh, UK.
LA  - eng
GR  - University of Edinburgh - Edinburgh Global Research Scholarship/
GR  - MR/N015665/1/MRC_/Medical Research Council/United Kingdom
GR  - China Scholarship Council/
GR  - UK Reproducibility Network - John Climax PhD studentship/
GR  - NC/L000970/1/NC3RS_/National Centre for the Replacement, Refinement and Reduction 
      of Animals in Research/United Kingdom
PT  - Journal Article
DEP - 20211105
PL  - England
TA  - Res Synth Methods
JT  - Research synthesis methods
JID - 101543738
SB  - IM
MH  - *Natural Language Processing
MH  - *Neural Networks, Computer
MH  - Support Vector Machine
PMC - PMC9298308
OTO - NOTNLM
OT  - automatic assessment
OT  - natural language processing
OT  - preclinical research synthesis
OT  - risk of bias
COIS- The authors declare that they have no conflict of interests.
EDAT- 2021/10/29 06:00
MHDA- 2022/05/12 06:00
PMCR- 2022/07/20
CRDT- 2021/10/28 12:41
PHST- 2021/10/01 00:00 [revised]
PHST- 2021/07/08 00:00 [received]
PHST- 2021/10/09 00:00 [accepted]
PHST- 2021/10/29 06:00 [pubmed]
PHST- 2022/05/12 06:00 [medline]
PHST- 2021/10/28 12:41 [entrez]
PHST- 2022/07/20 00:00 [pmc-release]
AID - JRSM1533 [pii]
AID - 10.1002/jrsm.1533 [doi]
PST - ppublish
SO  - Res Synth Methods. 2022 May;13(3):368-380. doi: 10.1002/jrsm.1533. Epub 2021 Nov 
      5.

PMID- 38200151
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240210
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 7
IP  - 1
DP  - 2024 Jan 11
TI  - Large language models to identify social determinants of health in electronic 
      health records.
PG  - 6
LID - 10.1038/s41746-023-00970-0 [doi]
LID - 6
AB  - Social determinants of health (SDoH) play a critical role in patient outcomes, 
      yet their documentation is often missing or incomplete in the structured data of 
      electronic health records (EHRs). Large language models (LLMs) could enable 
      high-throughput extraction of SDoH from the EHR to support research and clinical 
      care. However, class imbalance and data limitations present challenges for this 
      sparsely documented yet critical information. Here, we investigated the optimal 
      methods for using LLMs to extract six SDoH categories from narrative text in the 
      EHR: employment, housing, transportation, parental status, relationship, and 
      social support. The best-performing models were fine-tuned Flan-T5 XL for any 
      SDoH mentions (macro-F1 0.71), and Flan-T5 XXL for adverse SDoH mentions 
      (macro-F1 0.70). Adding LLM-generated synthetic data to training varied across 
      models and architecture, but improved the performance of smaller Flan-T5 models 
      (delta F1 + 0.12 to +0.23). Our best-fine-tuned models outperformed zero- and 
      few-shot performance of ChatGPT-family models in the zero- and few-shot setting, 
      except GPT4 with 10-shot prompting for adverse SDoH. Fine-tuned models were less 
      likely than ChatGPT to change their prediction when race/ethnicity and gender 
      descriptors were added to the text, suggesting less algorithmic bias (p < 0.05). 
      Our models identified 93.8% of patients with adverse SDoH, while ICD-10 codes 
      captured 2.0%. These results demonstrate the potential of LLMs in improving 
      real-world evidence on SDoH and assisting in identifying patients who could 
      benefit from resource support.
CI  - © 2024. The Author(s).
FAU - Guevara, Marco
AU  - Guevara M
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Chen, Shan
AU  - Chen S
AUID- ORCID: 0000-0001-7999-7410
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Thomas, Spencer
AU  - Thomas S
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
AD  - Computational Health Informatics Program, Boston Children's Hospital, Harvard 
      Medical School, Boston, MA, USA.
FAU - Chaunzwa, Tafadzwa L
AU  - Chaunzwa TL
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Franco, Idalid
AU  - Franco I
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Kann, Benjamin H
AU  - Kann BH
AUID- ORCID: 0000-0002-4313-2754
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Moningi, Shalini
AU  - Moningi S
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Qian, Jack M
AU  - Qian JM
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Goldstein, Madeleine
AU  - Goldstein M
AD  - Adult Resource Office, Dana-Farber Cancer Institute, Boston, MA, USA.
FAU - Harper, Susan
AU  - Harper S
AD  - Adult Resource Office, Dana-Farber Cancer Institute, Boston, MA, USA.
FAU - Aerts, Hugo J W L
AU  - Aerts HJWL
AUID- ORCID: 0000-0002-2122-2003
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
AD  - Radiology and Nuclear Medicine, GROW & CARIM, Maastricht University, Maastricht, 
      The Netherlands.
FAU - Catalano, Paul J
AU  - Catalano PJ
AD  - Department of Data Science, Dana-Farber Cancer Institute and Department of 
      Biostatistics, Harvard T. H. Chan School of Public Health, Boston, MA, USA.
FAU - Savova, Guergana K
AU  - Savova GK
AD  - Computational Health Informatics Program, Boston Children's Hospital, Harvard 
      Medical School, Boston, MA, USA.
FAU - Mak, Raymond H
AU  - Mak RH
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA.
FAU - Bitterman, Danielle S
AU  - Bitterman DS
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA, USA. Danielle_Bitterman@dfci.harvard.edu.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA, USA. Danielle_Bitterman@dfci.harvard.edu.
LA  - eng
GR  - U54 CA274516/CA/NCI NIH HHS/United States
GR  - R01 CA240582/CA/NCI NIH HHS/United States
GR  - U01 CA209414/CA/NCI NIH HHS/United States
GR  - R01 LM013486/LM/NLM NIH HHS/United States
GR  - U01 CA190234/CA/NCI NIH HHS/United States
GR  - U24 CA194354/CA/NCI NIH HHS/United States
PT  - Journal Article
DEP - 20240111
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC10781957
COIS- M.G., S.C., S.T., T.L.C., I.F., B.H.K., S.M., J.M.Q., M.G., S.H.: none. 
      H.J.W.L.A.: advisory and consulting, unrelated to this work (Onc.AI, Love Health 
      Inc, Sphera, Editas, A.Z., and BMS). P.J.C. and G.K.S.: None. R.H.M.: advisory 
      board (ViewRay, AstraZeneca), Consulting (Varian Medical Systems, Sio Capital 
      Management), Honorarium (Novartis, Springer Nature). D.S.B.: Associate Editor of 
      Radiation Oncology, HemOnc.org (no financial compensation, unrelated to this 
      work); funding from American Association for Cancer Research (unrelated to this 
      work).
EDAT- 2024/01/11 00:41
MHDA- 2024/01/11 00:42
PMCR- 2024/01/11
CRDT- 2024/01/10 23:24
PHST- 2023/08/14 00:00 [received]
PHST- 2023/11/15 00:00 [accepted]
PHST- 2024/01/11 00:42 [medline]
PHST- 2024/01/11 00:41 [pubmed]
PHST- 2024/01/10 23:24 [entrez]
PHST- 2024/01/11 00:00 [pmc-release]
AID - 10.1038/s41746-023-00970-0 [pii]
AID - 970 [pii]
AID - 10.1038/s41746-023-00970-0 [doi]
PST - epublish
SO  - NPJ Digit Med. 2024 Jan 11;7(1):6. doi: 10.1038/s41746-023-00970-0.

PMID- 37352529
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231212
IS  - 1743-9159 (Electronic)
IS  - 1743-9191 (Print)
IS  - 1743-9159 (Linking)
VI  - 109
IP  - 10
DP  - 2023 Oct 1
TI  - ChatGPT encounters multiple opportunities and challenges in neurosurgery.
PG  - 2886-2891
LID - 10.1097/JS9.0000000000000571 [doi]
AB  - BACKGROUND: ChatGPT, powered by the GPT model and Transformer architecture, has 
      demonstrated remarkable performance in the domains of medicine and healthcare, 
      providing customized and informative responses. In our study, we investigated the 
      potential of ChatGPT in the field of neurosurgery, focusing on its applications 
      at the patient, neurosurgery student/resident, and neurosurgeon levels. METHOD: 
      The authors conducted inquiries with ChatGPT from the viewpoints of patients, 
      neurosurgery students/residents, and neurosurgeons, covering a range of topics, 
      such as disease diagnosis, treatment options, prognosis, rehabilitation, and 
      patient care. The authors also explored concepts related to neurosurgery, 
      including fundamental principles and clinical aspects, as well as tools and 
      techniques to enhance the skills of neurosurgery students/residents. 
      Additionally, the authors examined disease-specific medical interventions and the 
      decision-making processes involved in clinical practice. RESULTS: The authors 
      received individual responses from ChatGPT, but they tended to be shallow and 
      repetitive, lacking depth and personalization. Furthermore, ChatGPT may struggle 
      to discern a patient's emotional state, hindering the establishment of rapport 
      and the delivery of appropriate care. The language used in the medical field is 
      influenced by technical and cultural factors, and biases in the training data can 
      result in skewed or inaccurate responses. Additionally, ChatGPT's limitations 
      include the inability to conduct physical examinations or interpret diagnostic 
      images, potentially overlooking complex details and individual nuances in each 
      patient's case. Moreover, its absence in the surgical setting limits its 
      practical utility. CONCLUSION: Although ChatGPT is a powerful language model, it 
      cannot substitute for the expertise and experience of trained medical 
      professionals. It lacks the capability to perform physical examinations, make 
      diagnoses, administer treatments, establish trust, provide emotional support, and 
      assist in the recovery process. Moreover, the implementation of Artificial 
      Intelligence in healthcare necessitates careful consideration of legal and 
      ethical concerns. While recognizing the potential of ChatGPT, additional training 
      with comprehensive data is necessary to fully maximize its capabilities.
CI  - Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc.
FAU - Kuang, Yi-Rui
AU  - Kuang YR
AD  - Department of Spine Surgery, The First Affiliated Hospital, Hengyang medical 
      school, University of South China, Hengyang, China.
AD  - Department of Neurosurgery, Xiangya Hospital, Central South University, Changsha, 
      China.
AD  - National Clinical Research Center for Geriatric Disorders, Xiangya Hospital, 
      Central South University, Changsha, China.
FAU - Zou, Ming-Xiang
AU  - Zou MX
AD  - Department of Spine Surgery, The First Affiliated Hospital, Hengyang medical 
      school, University of South China, Hengyang, China.
FAU - Niu, Hua-Qing
AU  - Niu HQ
AD  - Department of Ophthalmology, The Second Affiliated Hospital of Zhengzhou 
      University, Zhengzhou, China.
FAU - Zheng, Bo-Yv
AU  - Zheng BY
AD  - Department of Orthopedics Surgery, General Hospital of the Central Theater 
      Command, Wuhan, China.
FAU - Zhang, Tao-Lan
AU  - Zhang TL
AD  - Department of Spine Surgery, The First Affiliated Hospital, Hengyang medical 
      school, University of South China, Hengyang, China.
AD  - Department of Pharmacy, The First Affiliated Hospital, Hengyang Medical School, 
      University of South China, Hengyang, China.
FAU - Zheng, Bo-Wen
AU  - Zheng BW
AD  - Department of Musculoskeletal Tumor Center, People's Hospital, Peking University, 
      Beijing Key Laboratory of Musculoskeletal Tumor. Beijing, China.
LA  - eng
PT  - Journal Article
DEP - 20231001
PL  - United States
TA  - Int J Surg
JT  - International journal of surgery (London, England)
JID - 101228232
SB  - IM
MH  - Humans
MH  - *Neurosurgery
MH  - Artificial Intelligence
MH  - Neurosurgical Procedures
MH  - Health Facilities
PMC - PMC10583932
COIS- The authors declare that they have no competing interests.
EDAT- 2023/06/23 19:11
MHDA- 2023/10/23 00:44
PMCR- 2023/10/18
CRDT- 2023/06/23 17:03
PHST- 2023/06/06 00:00 [received]
PHST- 2023/06/10 00:00 [accepted]
PHST- 2023/10/23 00:44 [medline]
PHST- 2023/06/23 19:11 [pubmed]
PHST- 2023/06/23 17:03 [entrez]
PHST- 2023/10/18 00:00 [pmc-release]
AID - 01279778-202310000-00001 [pii]
AID - IJS-D-23-01093 [pii]
AID - 10.1097/JS9.0000000000000571 [doi]
PST - epublish
SO  - Int J Surg. 2023 Oct 1;109(10):2886-2891. doi: 10.1097/JS9.0000000000000571.

PMID- 39541580
OWN - NLM
STAT- MEDLINE
DCOM- 20241114
LR  - 20250111
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Nov 14
TI  - Economics and Equity of Large Language Models: Health Care Perspective.
PG  - e64226
LID - 10.2196/64226 [doi]
LID - e64226
AB  - Large language models (LLMs) continue to exhibit noteworthy capabilities across a 
      spectrum of areas, including emerging proficiencies across the health care 
      continuum. Successful LLM implementation and adoption depend on digital 
      readiness, modern infrastructure, a trained workforce, privacy, and an ethical 
      regulatory landscape. These factors can vary significantly across health care 
      ecosystems, dictating the choice of a particular LLM implementation pathway. This 
      perspective discusses 3 LLM implementation pathways-training from scratch pathway 
      (TSP), fine-tuned pathway (FTP), and out-of-the-box pathway (OBP)-as potential 
      onboarding points for health systems while facilitating equitable adoption. The 
      choice of a particular pathway is governed by needs as well as affordability. 
      Therefore, the risks, benefits, and economics of these pathways across 4 major 
      cloud service providers (Amazon, Microsoft, Google, and Oracle) are presented. 
      While cost comparisons, such as on-demand and spot pricing across the cloud 
      service providers for the 3 pathways, are presented for completeness, the 
      usefulness of managed services and cloud enterprise tools is elucidated. Managed 
      services can complement the traditional workforce and expertise, while enterprise 
      tools, such as federated learning, can overcome sample size challenges when 
      implementing LLMs using health care data. Of the 3 pathways, TSP is expected to 
      be the most resource-intensive regarding infrastructure and workforce while 
      providing maximum customization, enhanced transparency, and performance. Because 
      TSP trains the LLM using enterprise health care data, it is expected to harness 
      the digital signatures of the population served by the health care system with 
      the potential to impact outcomes. The use of pretrained models in FTP is a 
      limitation. It may impact its performance because the training data used in the 
      pretrained model may have hidden bias and may not necessarily be health 
      care-related. However, FTP provides a balance between customization, cost, and 
      performance. While OBP can be rapidly deployed, it provides minimal customization 
      and transparency without guaranteeing long-term availability. OBP may also 
      present challenges in interfacing seamlessly with downstream applications in 
      health care settings with variations in pricing and use over time. Lack of 
      customization in OBP can significantly limit its ability to impact outcomes. 
      Finally, potential applications of LLMs in health care, including conversational 
      artificial intelligence, chatbots, summarization, and machine translation, are 
      highlighted. While the 3 implementation pathways discussed in this perspective 
      have the potential to facilitate equitable adoption and democratization of LLMs, 
      transitions between them may be necessary as the needs of health systems evolve. 
      Understanding the economics and trade-offs of these onboarding pathways can guide 
      their strategic adoption and demonstrate value while impacting health care 
      outcomes favorably.
CI  - ©Radha Nagarajan, Midori Kondo, Franz Salas, Emre Sezgin, Yuan Yao, Vanessa 
      Klotzman, Sandip A Godambe, Naqi Khan, Alfonso Limon, Graham Stephenson, Sharief 
      Taraman, Nephi Walton, Louis Ehwerhemuepha, Jay Pandit, Deepti Pandita, Michael 
      Weiss, Charles Golden, Adam Gold, John Henderson, Angela Shippy, Leo Anthony 
      Celi, William R Hogan, Eric K Oermann, Terence Sanger, Steven Martel. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      14.11.2024.
FAU - Nagarajan, Radha
AU  - Nagarajan R
AUID- ORCID: 0009-0002-3423-6874
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Kondo, Midori
AU  - Kondo M
AUID- ORCID: 0009-0006-0557-7652
AD  - Fred Hutch Patient Care, Seattle, WA, United States.
FAU - Salas, Franz
AU  - Salas F
AUID- ORCID: 0009-0007-2260-5405
AD  - Amazon Web Services, Detroit, MI, United States.
FAU - Sezgin, Emre
AU  - Sezgin E
AUID- ORCID: 0000-0001-8798-9605
AD  - Nationwide Children's Hospital, Columbus, OH, United States.
FAU - Yao, Yuan
AU  - Yao Y
AUID- ORCID: 0009-0005-4896-4786
AD  - Amazon Web Services, San Francisco, CA, United States.
FAU - Klotzman, Vanessa
AU  - Klotzman V
AUID- ORCID: 0000-0001-9834-1927
AD  - University of California Irvine, Irvine, CA, United States.
FAU - Godambe, Sandip A
AU  - Godambe SA
AUID- ORCID: 0000-0001-9033-4159
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Khan, Naqi
AU  - Khan N
AUID- ORCID: 0000-0001-9628-3049
AD  - Amazon Web Services, Seattle, WA, United States.
FAU - Limon, Alfonso
AU  - Limon A
AUID- ORCID: 0000-0003-3654-8353
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Stephenson, Graham
AU  - Stephenson G
AUID- ORCID: 0000-0001-6135-541X
AD  - University of California Irvine Health, Irvine, CA, United States.
FAU - Taraman, Sharief
AU  - Taraman S
AUID- ORCID: 0000-0003-2108-2490
AD  - Cognoa LLC, Palo Alto, CA, United States.
FAU - Walton, Nephi
AU  - Walton N
AUID- ORCID: 0000-0002-9095-7265
AD  - National Institutes of Health, Bethesda, MD, United States.
FAU - Ehwerhemuepha, Louis
AU  - Ehwerhemuepha L
AUID- ORCID: 0000-0003-1369-7954
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Pandit, Jay
AU  - Pandit J
AUID- ORCID: 0000-0003-0119-0881
AD  - Scripps Research Translational Institute, La Jolla, CA, United States.
FAU - Pandita, Deepti
AU  - Pandita D
AUID- ORCID: 0009-0007-2791-2738
AD  - University of California Irvine Health, Irvine, CA, United States.
FAU - Weiss, Michael
AU  - Weiss M
AUID- ORCID: 0000-0002-6580-8532
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Golden, Charles
AU  - Golden C
AUID- ORCID: 0009-0002-3281-0254
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Gold, Adam
AU  - Gold A
AUID- ORCID: 0009-0001-7083-4364
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Henderson, John
AU  - Henderson J
AUID- ORCID: 0009-0001-0739-639X
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Shippy, Angela
AU  - Shippy A
AUID- ORCID: 0009-0006-4976-2331
AD  - Amazon Web Services, Houston, TX, United States.
FAU - Celi, Leo Anthony
AU  - Celi LA
AUID- ORCID: 0000-0001-6712-6626
AD  - Massachusetts Institute of Technology, Cambridge, MA, United States.
FAU - Hogan, William R
AU  - Hogan WR
AUID- ORCID: 0000-0002-9881-1017
AD  - Medical College of Wisconsin, Milwaukee, WI, United States.
FAU - Oermann, Eric K
AU  - Oermann EK
AUID- ORCID: 0000-0002-1876-5963
AD  - NYU Langone Medical Center, New York, NY, United States.
FAU - Sanger, Terence
AU  - Sanger T
AUID- ORCID: 0000-0002-1837-6044
AD  - Children's Hospital of Orange County, Orange, CA, United States.
FAU - Martel, Steven
AU  - Martel S
AUID- ORCID: 0009-0008-5564-3827
AD  - Children's Hospital of Orange County, Orange, CA, United States.
AD  - Physicians Specialty Faculty, Orange, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20241114
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Delivery of Health Care
MH  - Language
PMC - PMC11605263
OTO - NOTNLM
OT  - LLM
OT  - cloud
OT  - cloud service providers
OT  - democratization
OT  - economics
OT  - equity
OT  - health care
OT  - health outcome
OT  - implementation
OT  - large language model
COIS- Conflicts of Interest: ES serves on the editorial board of JMIR Publications.
EDAT- 2024/11/14 18:30
MHDA- 2024/11/14 18:31
PMCR- 2024/11/14
CRDT- 2024/11/14 16:53
PHST- 2024/07/11 00:00 [received]
PHST- 2024/09/16 00:00 [accepted]
PHST- 2024/08/28 00:00 [revised]
PHST- 2024/11/14 18:31 [medline]
PHST- 2024/11/14 18:30 [pubmed]
PHST- 2024/11/14 16:53 [entrez]
PHST- 2024/11/14 00:00 [pmc-release]
AID - v26i1e64226 [pii]
AID - 10.2196/64226 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Nov 14;26:e64226. doi: 10.2196/64226.

PMID- 37128554
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240919
IS  - 2666-6677 (Electronic)
IS  - 2666-6677 (Linking)
VI  - 14
DP  - 2023 Jun
TI  - Natural language processing to identify reasons for sex disparity in statin 
      prescriptions.
PG  - 100496
LID - 10.1016/j.ajpc.2023.100496 [doi]
LID - 100496
AB  - BACKGROUND: Statins are the cornerstone of treatment of patients with 
      atherosclerotic cardiovascular disease (ASCVD). Despite this, multiple studies 
      have shown that women with ASCVD are less likely to be prescribed statins than 
      men. The objective of this study was to use Natural Language Processing (NLP) to 
      elucidate factors contributing to this disparity. METHODS: Our cohort included 
      adult patients with two or more encounters between 2014 and 2021 with an ASCVD 
      diagnosis within a multisite electronic health record (EHR) in Northern 
      California. After reviewing structured EHR prescription data, we used a benchmark 
      deep learning NLP approach, Clinical Bidirectional Encoder Representations from 
      Transformers (BERT), to identify and interpret discussions of statin 
      prescriptions documented in clinical notes. Clinical BERT was evaluated against 
      expert clinician review in 20% test sets. RESULTS: There were 88,913 patients 
      with ASCVD (mean age 67.8±13.1 years) and 35,901 (40.4%) were women. Women with 
      ASCVD were less likely to be prescribed statins compared with men (56.6% vs 
      67.6%, p <0.001), and, when prescribed, less likely to be prescribed 
      guideline-directed high-intensity dosing (41.4% vs 49.8%, p <0.001). These 
      disparities were more pronounced among younger patients, patients with private 
      insurance, and those for whom English is their preferred language. Among those 
      not prescribed statins, women were less likely than men to have statins mentioned 
      in their clinical notes (16.9% vs 19.1%, p <0.001). Women were less likely than 
      men to have statin use reported in clinical notes despite absence of recorded 
      prescription (32.8% vs 42.6%, p <0.001). Women were slightly more likely than men 
      to have statin intolerance documented in structured data or clinical notes 
      (6.0% vs 5.3%, p=0.003). CONCLUSIONS: Women with ASCVD were less likely to be 
      prescribed guideline-directed statins compared with men. NLP identified 
      additional sex-based statin disparities and reasons for statin non-prescription 
      in clinical notes of patients with ASCVD.
CI  - © 2023 The Authors. Published by Elsevier B.V.
FAU - Witting, Celeste
AU  - Witting C
AD  - Stanford University Division of Cardiovascular Medicine and Cardiovascular 
      Institute, Department of Medicine, Stanford University, Center for Academic 
      Medicine, Mail Code 5687, 453 Quarry Road, Palo Alto, Stanford, CA, USA.
FAU - Azizi, Zahra
AU  - Azizi Z
AD  - Stanford University Division of Cardiovascular Medicine and Cardiovascular 
      Institute, Department of Medicine, Stanford University, Center for Academic 
      Medicine, Mail Code 5687, 453 Quarry Road, Palo Alto, Stanford, CA, USA.
AD  - Center for Digital Health, Stanford University, Stanford, CA, USA.
FAU - Gomez, Sofia Elena
AU  - Gomez SE
AD  - Stanford University Division of Cardiovascular Medicine and Cardiovascular 
      Institute, Department of Medicine, Stanford University, Center for Academic 
      Medicine, Mail Code 5687, 453 Quarry Road, Palo Alto, Stanford, CA, USA.
FAU - Zammit, Alban
AU  - Zammit A
AD  - Institute for Computational and Mathematical Engineering, Stanford University, 
      Stanford, CA, USA.
FAU - Sarraju, Ashish
AU  - Sarraju A
AD  - Department of Cardiovascular Medicine, Heart, Vascular & Thoracic Institute, 
      Cleveland Clinic, Cleveland, OH, USA.
FAU - Ngo, Summer
AU  - Ngo S
AD  - Stanford University Division of Cardiovascular Medicine and Cardiovascular 
      Institute, Department of Medicine, Stanford University, Center for Academic 
      Medicine, Mail Code 5687, 453 Quarry Road, Palo Alto, Stanford, CA, USA.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AD  - Department of Medicine, Biomedical Informatics, Stanford University, Stanford, 
      CA, USA.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
AD  - Department of Surgery, Stanford University School of Medicine, Stanford, CA, USA.
FAU - Rodriguez, Fatima
AU  - Rodriguez F
AD  - Stanford University Division of Cardiovascular Medicine and Cardiovascular 
      Institute, Department of Medicine, Stanford University, Center for Academic 
      Medicine, Mail Code 5687, 453 Quarry Road, Palo Alto, Stanford, CA, USA.
LA  - eng
GR  - K01 HL144607/HL/NHLBI NIH HHS/United States
GR  - R01 HL168188/HL/NHLBI NIH HHS/United States
PT  - Journal Article
DEP - 20230411
PL  - Netherlands
TA  - Am J Prev Cardiol
JT  - American journal of preventive cardiology
JID - 101769122
PMC - PMC10147966
OTO - NOTNLM
OT  - Atherosclerotic cardiovascular disease
OT  - Sex
OT  - Statins
COIS- The authors declare the following financial interests/personal relationships 
      which may be considered as potential competing interests.
EDAT- 2023/05/02 06:41
MHDA- 2023/05/02 06:42
PMCR- 2023/04/11
CRDT- 2023/05/02 01:59
PHST- 2022/12/15 00:00 [received]
PHST- 2023/03/27 00:00 [revised]
PHST- 2023/04/10 00:00 [accepted]
PHST- 2023/05/02 06:42 [medline]
PHST- 2023/05/02 06:41 [pubmed]
PHST- 2023/05/02 01:59 [entrez]
PHST- 2023/04/11 00:00 [pmc-release]
AID - S2666-6677(23)00037-5 [pii]
AID - 100496 [pii]
AID - 10.1016/j.ajpc.2023.100496 [doi]
PST - epublish
SO  - Am J Prev Cardiol. 2023 Apr 11;14:100496. doi: 10.1016/j.ajpc.2023.100496. 
      eCollection 2023 Jun.

PMID- 38153778
OWN - NLM
STAT- MEDLINE
DCOM- 20231229
LR  - 20240225
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Dec 28
TI  - Empathy and Equity: Key Considerations for Large Language Model Adoption in 
      Health Care.
PG  - e51199
LID - 10.2196/51199 [doi]
LID - e51199
AB  - The growing presence of large language models (LLMs) in health care applications 
      holds significant promise for innovative advancements in patient care. However, 
      concerns about ethical implications and potential biases have been raised by 
      various stakeholders. Here, we evaluate the ethics of LLMs in medicine along 2 
      key axes: empathy and equity. We outline the importance of these factors in novel 
      models of care and develop frameworks for addressing these alongside LLM 
      deployment.
CI  - ©Erica Koranteng, Arya Rao, Efren Flores, Michael Lev, Adam Landman, Keith 
      Dreyer, Marc Succi. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 28.12.2023.
FAU - Koranteng, Erica
AU  - Koranteng E
AUID- ORCID: 0000-0002-1332-0383
AD  - Harvard Medical School, Boston, MA, United States.
FAU - Rao, Arya
AU  - Rao A
AUID- ORCID: 0000-0003-3007-4812
AD  - Harvard Medical School, Boston, MA, United States.
FAU - Flores, Efren
AU  - Flores E
AUID- ORCID: 0000-0003-1398-0426
AD  - Harvard Medical School, Boston, MA, United States.
FAU - Lev, Michael
AU  - Lev M
AUID- ORCID: 0000-0003-0236-7319
AD  - Harvard Medical School, Boston, MA, United States.
FAU - Landman, Adam
AU  - Landman A
AUID- ORCID: 0000-0002-2166-0521
AD  - Harvard Medical School, Boston, MA, United States.
FAU - Dreyer, Keith
AU  - Dreyer K
AUID- ORCID: 0000-0003-1207-6443
AD  - Harvard Medical School, Boston, MA, United States.
FAU - Succi, Marc
AU  - Succi M
AUID- ORCID: 0000-0002-1518-3984
AD  - Massachusetts General Hospital, Boston, United States.
LA  - eng
GR  - K08 CA270430/CA/NCI NIH HHS/United States
GR  - T32 GM144273/GM/NIGMS NIH HHS/United States
PT  - Journal Article
DEP - 20231228
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Empathy
MH  - Health Facilities
MH  - Language
MH  - *Medicine
MH  - Delivery of Health Care
PMC - PMC10884892
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLMs
OT  - artificial intelligence
OT  - bias
OT  - care
OT  - development
OT  - empathy
OT  - equity
OT  - ethical implication
OT  - ethics
OT  - framework
OT  - health care application
OT  - language model
OT  - large language models
OT  - model
OT  - patient care
COIS- Conflicts of Interest: EF is co-chair of the Radiological Society of North 
      America (RSNA) Health Equity Committee; associate editor and editorial board 
      member of the Journal of the American College of Radiology (JACR); has received 
      speaker honoraria for academic Grand Rounds, from WebMD and from GO2 for Lung 
      Cancer foundation; GO2 Foundation Travel support; grant funding from NCI K08 
      1K08CA270430-01A1. ML is a consultant for GE Healthcare and for Takeda, Roche, 
      and SeaGen Pharma. AL is a consultant for the Abbott Medical Device Cybersecurity 
      Council.
EDAT- 2023/12/28 12:42
MHDA- 2023/12/29 06:43
PMCR- 2023/12/28
CRDT- 2023/12/28 11:53
PHST- 2023/07/24 00:00 [received]
PHST- 2023/10/14 00:00 [accepted]
PHST- 2023/10/01 00:00 [revised]
PHST- 2023/12/29 06:43 [medline]
PHST- 2023/12/28 12:42 [pubmed]
PHST- 2023/12/28 11:53 [entrez]
PHST- 2023/12/28 00:00 [pmc-release]
AID - v9i1e51199 [pii]
AID - 10.2196/51199 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Dec 28;9:e51199. doi: 10.2196/51199.

PMID- 37271011
OWN - NLM
STAT- MEDLINE
DCOM- 20230628
LR  - 20230816
IS  - 1532-2831 (Electronic)
IS  - 1078-8174 (Linking)
VI  - 29
IP  - 4
DP  - 2023 Jul
TI  - ChatGPT in medical imaging higher education.
PG  - 792-799
LID - S1078-8174(23)00117-7 [pii]
LID - 10.1016/j.radi.2023.05.011 [doi]
AB  - INTRODUCTION: Academic integrity among radiographers and nuclear medicine 
      technologists/scientists in both higher education and scientific writing has been 
      challenged by advances in artificial intelligence (AI). The recent release of 
      ChatGPT, a chatbot powered by GPT-3.5 capable of producing accurate and 
      human-like responses to questions in real-time, has redefined the boundaries of 
      academic and scientific writing. These boundaries require objective evaluation. 
      METHOD: ChatGPT was tested against six subjects across the first three years of 
      the medical radiation science undergraduate course for both exams (n = 6) and 
      written assignment tasks (n = 3). ChatGPT submissions were marked against 
      standardised rubrics and results compared to student cohorts. Submissions were 
      also evaluated by Turnitin for similarity and AI scores. RESULTS: ChatGPT powered 
      by GPT-3.5 performed below the average student performance in all written tasks 
      with an increasing disparity as subjects advanced. ChatGPT performed better than 
      the average student in foundation or general subject examinations where shallow 
      responses meet learning outcomes. For discipline specific subjects, ChatGPT 
      lacked the depth, breadth, and currency of insight to provide pass level answers. 
      CONCLUSION: ChatGPT simultaneously poses a risk to academic integrity in writing 
      and assessment while affording a tool for enhanced learning environments. These 
      risks and benefits are likely to be restricted to learning outcomes of lower 
      taxonomies. Both risks and benefits are likely to be constrained by higher order 
      taxonomies. IMPLICATIONS FOR PRACTICE: ChatGPT powered by GPT3.5 has limited 
      capacity to support student cheating, introduces errors and fabricated 
      information, and is readily identified by software as AI generated. Lack of depth 
      of insight and appropriateness for professional communication also limits 
      capacity as a learning enhancement tool.
CI  - Copyright © 2023 The College of Radiographers. Published by Elsevier Ltd. All 
      rights reserved.
FAU - Currie, G
AU  - Currie G
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia. Electronic address: 
      gcurrie@csu.edu.au.
FAU - Singh, C
AU  - Singh C
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia.
FAU - Nelson, T
AU  - Nelson T
AD  - Charles Sturt University, Port Macquarie, NSW, Australia.
FAU - Nabasenja, C
AU  - Nabasenja C
AD  - Charles Sturt University, Port Macquarie, NSW, Australia.
FAU - Al-Hayek, Y
AU  - Al-Hayek Y
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia.
FAU - Spuur, K
AU  - Spuur K
AD  - Charles Sturt University, Wagga Wagga, NSW, Australia.
LA  - eng
PT  - Journal Article
DEP - 20230602
PL  - Netherlands
TA  - Radiography (Lond)
JT  - Radiography (London, England : 1995)
JID - 9604102
SB  - IM
CIN - Radiography (Lond). 2023 Aug;29(5):867. doi: 10.1016/j.radi.2023.06.007. PMID: 
      37413958
CIN - Radiography (Lond). 2023 Aug;29(5):868-869. doi: 10.1016/j.radi.2023.06.012. 
      PMID: 37419046
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Diagnostic Imaging
MH  - Radiography
MH  - Learning
MH  - Software
OTO - NOTNLM
OT  - Academic integrity
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Generative algorithms
OT  - Higher education
OT  - Language model
COIS- Conflict of interest statement None.
EDAT- 2023/06/05 00:41
MHDA- 2023/06/28 06:42
CRDT- 2023/06/04 18:06
PHST- 2023/04/13 00:00 [received]
PHST- 2023/05/17 00:00 [revised]
PHST- 2023/05/17 00:00 [accepted]
PHST- 2023/06/28 06:42 [medline]
PHST- 2023/06/05 00:41 [pubmed]
PHST- 2023/06/04 18:06 [entrez]
AID - S1078-8174(23)00117-7 [pii]
AID - 10.1016/j.radi.2023.05.011 [doi]
PST - ppublish
SO  - Radiography (Lond). 2023 Jul;29(4):792-799. doi: 10.1016/j.radi.2023.05.011. Epub 
      2023 Jun 2.

PMID- 36706848
OWN - NLM
STAT- MEDLINE
DCOM- 20230227
LR  - 20240202
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Print)
IS  - 1532-0464 (Linking)
VI  - 138
DP  - 2023 Feb
TI  - DR.BENCH: Diagnostic Reasoning Benchmark for Clinical Natural Language 
      Processing.
PG  - 104286
LID - S1532-0464(23)00007-2 [pii]
LID - 10.1016/j.jbi.2023.104286 [doi]
AB  - The meaningful use of electronic health records (EHR) continues to progress in 
      the digital era with clinical decision support systems augmented by artificial 
      intelligence. A priority in improving provider experience is to overcome 
      information overload and reduce the cognitive burden so fewer medical errors and 
      cognitive biases are introduced during patient care. One major type of medical 
      error is diagnostic error due to systematic or predictable errors in judgement 
      that rely on heuristics. The potential for clinical natural language processing 
      (cNLP) to model diagnostic reasoning in humans with forward reasoning from data 
      to diagnosis and potentially reduce cognitive burden and medical error has not 
      been investigated. Existing tasks to advance the science in cNLP have largely 
      focused on information extraction and named entity recognition through 
      classification tasks. We introduce a novel suite of tasks coined as Diagnostic 
      Reasoning Benchmarks, Dr.Bench, as a new benchmark for developing and evaluating 
      cNLP models with clinical diagnostic reasoning ability. The suite includes six 
      tasks from ten publicly available datasets addressing clinical text 
      understanding, medical knowledge reasoning, and diagnosis generation. DR.BENCH is 
      the first clinical suite of tasks designed to be a natural language generation 
      framework to evaluate pre-trained language models for diagnostic reasoning. The 
      goal of DR. BENCH is to advance the science in cNLP to support downstream 
      applications in computerized diagnostic decision support and improve the 
      efficiency and accuracy of healthcare providers during patient care. We fine-tune 
      and evaluate the state-of-the-art generative models on DR.BENCH. Experiments show 
      that with domain adaptation pre-training on medical knowledge, the model 
      demonstrated opportunities for improvement when evaluated in DR. BENCH. We share 
      DR. BENCH as a publicly available GitLab repository with a systematic approach to 
      load and evaluate models for the cNLP community. We also discuss the carbon 
      footprint produced during the experiments and encourage future work on DR.BENCH 
      to report the carbon footprint.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Gao, Yanjun
AU  - Gao Y
AD  - ICU Data Science Lab, Department of Medicine, University of Wisconsin Madison, 
      1685 Highland Ave, Madison, 53792, WI, USA. Electronic address: 
      ygao@medicine.wisc.edu.
FAU - Dligach, Dmitriy
AU  - Dligach D
AD  - Department of Computer Science, Loyola University Chicago, 1032 W Sheridan Rd, 
      Chicago, 60660, IL, USA.
FAU - Miller, Timothy
AU  - Miller T
AD  - Boston Children's Hospital, Harvard University, 300 Longwood Ave, Boston, 02115, 
      MA, USA.
FAU - Caskey, John
AU  - Caskey J
AD  - ICU Data Science Lab, Department of Medicine, University of Wisconsin Madison, 
      1685 Highland Ave, Madison, 53792, WI, USA.
FAU - Sharma, Brihat
AU  - Sharma B
AD  - ICU Data Science Lab, Department of Medicine, University of Wisconsin Madison, 
      1685 Highland Ave, Madison, 53792, WI, USA.
FAU - Churpek, Matthew M
AU  - Churpek MM
AD  - ICU Data Science Lab, Department of Medicine, University of Wisconsin Madison, 
      1685 Highland Ave, Madison, 53792, WI, USA.
FAU - Afshar, Majid
AU  - Afshar M
AD  - ICU Data Science Lab, Department of Medicine, University of Wisconsin Madison, 
      1685 Highland Ave, Madison, 53792, WI, USA.
LA  - eng
GR  - R01 DA051464/DA/NIDA NIH HHS/United States
GR  - R01 HL157262/HL/NHLBI NIH HHS/United States
GR  - R01 LM010090/LM/NLM NIH HHS/United States
GR  - R01 LM012973/LM/NLM NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20230125
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Artificial Intelligence
MH  - Benchmarking
MH  - Problem Solving
MH  - Information Storage and Retrieval
PMC - PMC9993808
MID - NIHMS1868157
OTO - NOTNLM
OT  - Clinical diagnostic decision support
OT  - Clinical diagnostic reasoning
OT  - Clinical natural language processing benchmark
OT  - Natural language processing
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/01/28 06:00
MHDA- 2023/03/03 06:00
PMCR- 2024/02/01
CRDT- 2023/01/27 19:22
PHST- 2022/10/19 00:00 [received]
PHST- 2022/12/13 00:00 [revised]
PHST- 2023/01/09 00:00 [accepted]
PHST- 2023/01/28 06:00 [pubmed]
PHST- 2023/03/03 06:00 [medline]
PHST- 2023/01/27 19:22 [entrez]
PHST- 2024/02/01 00:00 [pmc-release]
AID - S1532-0464(23)00007-2 [pii]
AID - 10.1016/j.jbi.2023.104286 [doi]
PST - ppublish
SO  - J Biomed Inform. 2023 Feb;138:104286. doi: 10.1016/j.jbi.2023.104286. Epub 2023 
      Jan 25.

PMID- 39010845
OWN - NLM
STAT- MEDLINE
DCOM- 20241101
LR  - 20241120
IS  - 2042-6984 (Electronic)
IS  - 2042-6976 (Linking)
VI  - 14
IP  - 11
DP  - 2024 Nov
TI  - Gender-based linguistic differences in letters of recommendation for rhinology 
      fellowship over time: A dual-institutional follow-up study using natural language 
      processing and deep learning.
PG  - 1814-1817
LID - 10.1002/alr.23411 [doi]
AB  - This follow-up dual-institutional and longitudinal study further evaluated for 
      underlying gender biases in LORs for rhinology fellowship. Explicit and implicit 
      linguistic gender bias was found, heavily favoring male applicants.
CI  - © 2024 ARS‐AAOA, LLC.
FAU - Vasan, Vikram
AU  - Vasan V
AUID- ORCID: 0000-0003-2754-4107
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
FAU - Cheng, Christopher P
AU  - Cheng CP
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
FAU - Edalati, Shaun
AU  - Edalati S
AUID- ORCID: 0000-0001-9452-3942
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
FAU - Mandloi, Shreya
AU  - Mandloi S
AD  - Department of Otolaryngology, Thomas Jefferson University Hospital, Philadelphia, 
      Pennsylvania, USA.
FAU - Lerner, David K
AU  - Lerner DK
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
AD  - Department of Otolaryngology-Head & Neck Surgery, University of Miami Miller 
      School of Medicine, Miami, Florida, USA.
FAU - Del Signore, Anthony
AU  - Del Signore A
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
FAU - Schaberg, Madeleine
AU  - Schaberg M
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
FAU - Govindaraj, Satish
AU  - Govindaraj S
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
FAU - Rabinowitz, Mindy
AU  - Rabinowitz M
AD  - Department of Otolaryngology, Thomas Jefferson University Hospital, Philadelphia, 
      Pennsylvania, USA.
FAU - Nyquist, Gurston
AU  - Nyquist G
AD  - Department of Otolaryngology, Thomas Jefferson University Hospital, Philadelphia, 
      Pennsylvania, USA.
FAU - Iloreta, Alfred Marc
AU  - Iloreta AM
AD  - Department of Otolaryngology-Head and Neck Surgery, Icahn School of Medicine at 
      Mount Sinai, New York, New York, USA.
LA  - eng
PT  - Journal Article
PT  - Multicenter Study
DEP - 20240716
PL  - United States
TA  - Int Forum Allergy Rhinol
JT  - International forum of allergy & rhinology
JID - 101550261
SB  - IM
MH  - Humans
MH  - Male
MH  - Female
MH  - *Otolaryngology/education
MH  - *Natural Language Processing
MH  - *Fellowships and Scholarships
MH  - Follow-Up Studies
MH  - *Deep Learning
MH  - Sexism
MH  - Longitudinal Studies
MH  - Linguistics
MH  - Sex Factors
MH  - Correspondence as Topic
OTO - NOTNLM
OT  - application process
OT  - gender disparity
OT  - international medical graduate
OT  - letters of recommendation
OT  - personal statements
OT  - rhinology fellowship match
EDAT- 2024/07/16 06:42
MHDA- 2024/11/01 18:22
CRDT- 2024/07/16 04:03
PHST- 2024/05/17 00:00 [revised]
PHST- 2024/03/26 00:00 [received]
PHST- 2024/06/28 00:00 [accepted]
PHST- 2024/11/01 18:22 [medline]
PHST- 2024/07/16 06:42 [pubmed]
PHST- 2024/07/16 04:03 [entrez]
AID - 10.1002/alr.23411 [doi]
PST - ppublish
SO  - Int Forum Allergy Rhinol. 2024 Nov;14(11):1814-1817. doi: 10.1002/alr.23411. Epub 
      2024 Jul 16.

PMID- 37387067
OWN - NLM
STAT- MEDLINE
DCOM- 20231217
LR  - 20231217
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 305
DP  - 2023 Jun 29
TI  - Revolutionizing Healthcare with Foundation AI Models.
PG  - 469-470
LID - 10.3233/SHTI230533 [doi]
AB  - ChatGPT is a foundation Artificial Intelligence (AI) model that has opened up new 
      opportunities in digital healthcare. Particularly, it can serve as a co-pilot 
      tool for doctors in the interpretation, summarization, and completion of reports. 
      Furthermore, it can build upon the ability to access the large literature and 
      knowledge on the internet. So, chatGPT could generate acceptable responses for 
      the medical examination. Hence. It offers the possibility of enhancing healthcare 
      accessibility, expandability, and effectiveness. Nonetheless, chatGPT is 
      vulnerable to inaccuracies, false information, and bias. This paper briefly 
      describes the potential of Foundation AI models to transform future healthcare by 
      presenting ChatGPT as an example tool.
FAU - Ali, Hazrat
AU  - Ali H
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Qatar 
      Foundation, Doha, Qatar.
FAU - Qadir, Junaid
AU  - Qadir J
AD  - Department of Computer Engineering, Qatar University, Doha, Qatar.
FAU - Alam, Tanvir
AU  - Alam T
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Qatar 
      Foundation, Doha, Qatar.
FAU - Househ, Mowafa
AU  - Househ M
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Qatar 
      Foundation, Doha, Qatar.
FAU - Shah, Zubair
AU  - Shah Z
AD  - College of Science and Engineering, Hamad Bin Khalifa University, Qatar 
      Foundation, Doha, Qatar.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - Humans
MH  - *Delivery of Health Care/trends
MH  - *Artificial Intelligence
MH  - Internet
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Foundation AI models
OT  - Healthcare
OT  - Medical AI
EDAT- 2023/06/30 06:42
MHDA- 2023/07/03 06:41
CRDT- 2023/06/30 04:23
PHST- 2023/07/03 06:41 [medline]
PHST- 2023/06/30 06:42 [pubmed]
PHST- 2023/06/30 04:23 [entrez]
AID - SHTI230533 [pii]
AID - 10.3233/SHTI230533 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2023 Jun 29;305:469-470. doi: 10.3233/SHTI230533.

PMID- 39773666
OWN - NLM
STAT- MEDLINE
DCOM- 20250108
LR  - 20250129
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Jan 7
TI  - Revolutionizing Health Care: The Transformative Impact of Large Language Models 
      in Medicine.
PG  - e59069
LID - 10.2196/59069 [doi]
LID - e59069
AB  - Large language models (LLMs) are rapidly advancing medical artificial 
      intelligence, offering revolutionary changes in health care. These models excel 
      in natural language processing (NLP), enhancing clinical support, diagnosis, 
      treatment, and medical research. Breakthroughs, like GPT-4 and BERT 
      (Bidirectional Encoder Representations from Transformer), demonstrate LLMs' 
      evolution through improved computing power and data. However, their high hardware 
      requirements are being addressed through technological advancements. LLMs are 
      unique in processing multimodal data, thereby improving emergency, elder care, 
      and digital medical procedures. Challenges include ensuring their empirical 
      reliability, addressing ethical and societal implications, especially data 
      privacy, and mitigating biases while maintaining privacy and accountability. The 
      paper emphasizes the need for human-centric, bias-free LLMs for personalized 
      medicine and advocates for equitable development and access. LLMs hold promise 
      for transformative impacts in health care.
CI  - ©Kuo Zhang, Xiangbin Meng, Xiangyu Yan, Jiaming Ji, Jingqian Liu, Hua Xu, Heng 
      Zhang, Da Liu, Jingjia Wang, Xuliang Wang, Jun Gao, Yuan-geng-shuo Wang, Chunli 
      Shao, Wenyao Wang, Jiarong Li, Ming-Qi Zheng, Yaodong Yang, Yi-Da Tang. 
      Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 07.01.2025.
FAU - Zhang, Kuo
AU  - Zhang K
AUID- ORCID: 0000-0001-8152-0750
AD  - Department of Cardiology, State Key Laboratory of Cardiovascular Disease, Fuwai 
      Hospital, National Center for Cardiovascular Diseases, Chinese Academy of Medical 
      Sciences and Peking Union Medical College, Beijing, China.
FAU - Meng, Xiangbin
AU  - Meng X
AUID- ORCID: 0000-0002-4252-7869
AD  - Pengcheng Laboratory, Shenzhen, Guangdong, China.
FAU - Yan, Xiangyu
AU  - Yan X
AUID- ORCID: 0000-0002-1496-0358
AD  - School of Disaster and Emergency Medicine, Tianjin University, Tianjin, China.
FAU - Ji, Jiaming
AU  - Ji J
AUID- ORCID: 0000-0002-3769-2077
AD  - Institute for Artificial Intelligence, Peking University, Beijing, China.
FAU - Liu, Jingqian
AU  - Liu J
AUID- ORCID: 0009-0008-8949-9691
AD  - China Telecom, Beijing, China.
FAU - Xu, Hua
AU  - Xu H
AUID- ORCID: 0009-0001-4243-7943
AD  - Division of Emerging Interdisciplinary Areas, Hong Kong University of Science and 
      Technology, Hong Kong, China (Hong Kong).
FAU - Zhang, Heng
AU  - Zhang H
AUID- ORCID: 0009-0000-5148-0743
AD  - Institute for Artificial Intelligence, Hefei University of Technology, Hefei, 
      Anhui, China.
FAU - Liu, Da
AU  - Liu D
AUID- ORCID: 0000-0003-1649-7296
AD  - Department of Cardiology, the First Hospital of Hebei Medical University, 
      Graduate School of Hebei Medical University, Shijiazhuang, Hebei, China.
FAU - Wang, Jingjia
AU  - Wang J
AUID- ORCID: 0000-0003-1556-9315
AD  - Department of Cardiology and Institute of Vascular Medicine, Key Laboratory of 
      Molecular Cardiovascular Science, Ministry of Education, Peking University Third 
      Hospital, Beijing, China.
FAU - Wang, Xuliang
AU  - Wang X
AUID- ORCID: 0000-0001-6520-6948
AD  - Department of Cardiology and Institute of Vascular Medicine, Key Laboratory of 
      Molecular Cardiovascular Science, Ministry of Education, Peking University Third 
      Hospital, Beijing, China.
FAU - Gao, Jun
AU  - Gao J
AUID- ORCID: 0000-0002-8599-4969
AD  - Department of Cardiology and Institute of Vascular Medicine, Key Laboratory of 
      Molecular Cardiovascular Science, Ministry of Education, Peking University Third 
      Hospital, Beijing, China.
FAU - Wang, Yuan-Geng-Shuo
AU  - Wang YG
AUID- ORCID: 0009-0008-9709-9954
AD  - Department of Cardiology and Institute of Vascular Medicine, Key Laboratory of 
      Molecular Cardiovascular Science, Ministry of Education, Peking University Third 
      Hospital, Beijing, China.
FAU - Shao, Chunli
AU  - Shao C
AUID- ORCID: 0000-0001-6366-1285
AD  - Department of Cardiology and Institute of Vascular Medicine, Key Laboratory of 
      Molecular Cardiovascular Science, Ministry of Education, Peking University Third 
      Hospital, Beijing, China.
FAU - Wang, Wenyao
AU  - Wang W
AUID- ORCID: 0000-0002-1296-9324
AD  - Department of Cardiology and Institute of Vascular Medicine, Key Laboratory of 
      Molecular Cardiovascular Science, Ministry of Education, Peking University Third 
      Hospital, Beijing, China.
FAU - Li, Jiarong
AU  - Li J
AUID- ORCID: 0000-0003-0549-5551
AD  - Henley Business School, University of Reading, RG6 6UD, United Kingdom.
FAU - Zheng, Ming-Qi
AU  - Zheng MQ
AUID- ORCID: 0000-0002-4300-0209
AD  - Department of Cardiology, the First Hospital of Hebei Medical University, 
      Graduate School of Hebei Medical University, Shijiazhuang, Hebei, China.
FAU - Yang, Yaodong
AU  - Yang Y
AUID- ORCID: 0000-0001-8132-5613
AD  - Institute for Artificial Intelligence, Peking University, Beijing, China.
FAU - Tang, Yi-Da
AU  - Tang YD
AUID- ORCID: 0000-0002-9712-803X
AD  - Department of Cardiology and Institute of Vascular Medicine, Key Laboratory of 
      Molecular Cardiovascular Science, Ministry of Education, Peking University Third 
      Hospital, Beijing, China.
LA  - eng
PT  - Journal Article
DEP - 20250107
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Artificial Intelligence
MH  - Delivery of Health Care
MH  - Precision Medicine/methods
PMC - PMC11751657
OTO - NOTNLM
OT  - AI
OT  - LLMs
OT  - NLP
OT  - artificial intelligence
OT  - digital health
OT  - large language models
OT  - medical diagnosis
OT  - multimodal data integration
OT  - natural language processing
OT  - technological fairness
OT  - treatment
COIS- Conflicts of Interest: None declared.
EDAT- 2025/01/08 18:21
MHDA- 2025/01/08 18:22
PMCR- 2025/01/07
CRDT- 2025/01/08 15:26
PHST- 2024/04/01 00:00 [received]
PHST- 2024/09/10 00:00 [accepted]
PHST- 2024/08/26 00:00 [revised]
PHST- 2025/01/08 18:22 [medline]
PHST- 2025/01/08 18:21 [pubmed]
PHST- 2025/01/08 15:26 [entrez]
PHST- 2025/01/07 00:00 [pmc-release]
AID - v27i1e59069 [pii]
AID - 10.2196/59069 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Jan 7;27:e59069. doi: 10.2196/59069.

PMID- 34918101
OWN - NLM
STAT- MEDLINE
DCOM- 20220228
LR  - 20221217
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 29
IP  - 3
DP  - 2022 Jan 29
TI  - Gender-sensitive word embeddings for healthcare.
PG  - 415-423
LID - 10.1093/jamia/ocab279 [doi]
AB  - OBJECTIVE: To analyze gender bias in clinical trials, to design an algorithm that 
      mitigates the effects of biases of gender representation on natural-language 
      (NLP) systems trained on text drawn from clinical trials, and to evaluate its 
      performance. MATERIALS AND METHODS: We analyze gender bias in clinical trials 
      described by 16 772 PubMed abstracts (2008-2018). We present a method to augment 
      word embeddings, the core building block of NLP-centric representations, by 
      weighting abstracts by the number of women participants in the trial. We evaluate 
      the resulting gender-sensitive embeddings performance on several clinical 
      prediction tasks: comorbidity classification, hospital length of stay prediction, 
      and intensive care unit (ICU) readmission prediction. RESULTS: For female 
      patients, the gender-sensitive model area under the receiver-operator 
      characteristic (AUROC) is 0.86 versus the baseline of 0.81 for comorbidity 
      classification, mean absolute error 4.59 versus the baseline of 4.66 for length 
      of stay prediction, and AUROC 0.69 versus 0.67 for ICU readmission. All results 
      are statistically significant. DISCUSSION: Women have been underrepresented in 
      clinical trials. Thus, using the broad clinical trials literature as training 
      data for statistical language models could result in biased models, with deficits 
      in knowledge about women. The method presented enables gender-sensitive use of 
      publications as training data for word embeddings. In experiments, the 
      gender-sensitive embeddings show better performance than baseline embeddings for 
      the clinical tasks studied. The results highlight opportunities for recognizing 
      and addressing gender and other representational biases in the clinical trials 
      literature. CONCLUSION: Addressing representational biases in data for training 
      NLP embeddings can lead to better results on downstream tasks for 
      underrepresented populations.
CI  - © The Author(s) 2021. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Agmon, Shunit
AU  - Agmon S
AD  - Computer Science Faculty, Technion - Israel Institute of Technology, Haifa, 
      Israel.
FAU - Gillis, Plia
AU  - Gillis P
AD  - Faculty of Medicine, Tel Aviv University, Tel Aviv, Israel.
FAU - Horvitz, Eric
AU  - Horvitz E
AD  - Microsoft Research, Redmond, WA, USA.
FAU - Radinsky, Kira
AU  - Radinsky K
AD  - Computer Science Faculty, Technion - Israel Institute of Technology, Haifa, 
      Israel.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Clinical Trials as Topic
MH  - *Delivery of Health Care
MH  - Female
MH  - Humans
MH  - Male
MH  - *Natural Language Processing
MH  - PubMed
MH  - *Sexism
PMC - PMC8800511
OTO - NOTNLM
OT  - algorithms
OT  - bias
OT  - gender
OT  - statistical models
OT  - word embeddings
EDAT- 2021/12/18 06:00
MHDA- 2022/03/01 06:00
PMCR- 2022/12/16
CRDT- 2021/12/17 07:09
PHST- 2021/09/04 00:00 [received]
PHST- 2021/11/30 00:00 [revised]
PHST- 2021/12/10 00:00 [accepted]
PHST- 2021/12/18 06:00 [pubmed]
PHST- 2022/03/01 06:00 [medline]
PHST- 2021/12/17 07:09 [entrez]
PHST- 2022/12/16 00:00 [pmc-release]
AID - 6464068 [pii]
AID - ocab279 [pii]
AID - 10.1093/jamia/ocab279 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2022 Jan 29;29(3):415-423. doi: 10.1093/jamia/ocab279.

PMID- 37369892
OWN - NLM
STAT- MEDLINE
DCOM- 20230919
LR  - 20240902
IS  - 1525-1497 (Electronic)
IS  - 0884-8734 (Print)
IS  - 0884-8734 (Linking)
VI  - 38
IP  - 12
DP  - 2023 Sep
TI  - Relief in Sight? Chatbots, In-baskets, and the Overwhelmed Primary Care 
      Clinician.
PG  - 2808-2815
LID - 10.1007/s11606-023-08271-8 [doi]
AB  - The recent emergence of publically facing artificial intelligence (AI) chatbots 
      has generated vigorous discussion in the lay public around the possibilities, 
      liabilities, and uncertainties of the integration of such technology into 
      everyday life. As primary care clinicians continue to struggle against 
      ever-increasing loads of asynchronous, electronic work, the potential for AI to 
      improve the quality and efficiency of this work looms large. In this essay, we 
      discuss the basic premise of open-access AI chatbots such as CHATGPT, review 
      prior applications of AI in healthcare, and preview some possible AI 
      chatbot-assisted in-basket assistance including scenarios of communicating test 
      results with patients, providing patient education, and clinical decision support 
      in history taking, review of prior diagnostic test characteristics, and common 
      management scenarios. We discuss important concerns related to the future 
      adoption of this technology including the transparency of the training data used 
      in developing these models, the level of oversight and trustworthiness of the 
      information generated, and possible impacts on equity, bias, and patient privacy. 
      A stepwise and balanced approach to simultaneously understand the capabilities 
      and address the concerns associated with these tools will be needed before these 
      tools can improve patient care.
CI  - © 2023. The Author(s), under exclusive licence to Society of General Internal 
      Medicine.
FAU - Matulis, John
AU  - Matulis J
AUID- ORCID: 0000-0001-9319-5457
AD  - Division of Community Internal Medicine, Geriatrics and Palliative Care, Mayo 
      Clinic Minnesota, Rochester, MN, USA. Matulis.john@mayo.edu.
FAU - McCoy, Rozalina
AU  - McCoy R
AD  - Division of Community Internal Medicine, Geriatrics and Palliative Care, Mayo 
      Clinic Minnesota, Rochester, MN, USA.
LA  - eng
PT  - Editorial
DEP - 20230627
PL  - United States
TA  - J Gen Intern Med
JT  - Journal of general internal medicine
JID - 8605834
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Electronics
MH  - Technology
MH  - Uncertainty
MH  - Primary Health Care
PMC - PMC10506981
COIS- None.
EDAT- 2023/06/28 01:06
MHDA- 2023/09/19 06:42
PMCR- 2024/09/01
CRDT- 2023/06/27 23:30
PHST- 2023/01/31 00:00 [received]
PHST- 2023/06/07 00:00 [accepted]
PHST- 2023/09/19 06:42 [medline]
PHST- 2023/06/28 01:06 [pubmed]
PHST- 2023/06/27 23:30 [entrez]
PHST- 2024/09/01 00:00 [pmc-release]
AID - 10.1007/s11606-023-08271-8 [pii]
AID - 8271 [pii]
AID - 10.1007/s11606-023-08271-8 [doi]
PST - ppublish
SO  - J Gen Intern Med. 2023 Sep;38(12):2808-2815. doi: 10.1007/s11606-023-08271-8. 
      Epub 2023 Jun 27.

PMID- 38925234
OWN - NLM
STAT- Publisher
LR  - 20240805
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
DP  - 2024 Jun 24
TI  - The Large Language Model ChatGPT-4 Exhibits Excellent Triage Capabilities and 
      Diagnostic Performance for Patients Presenting With Various Causes of Knee Pain.
LID - S0749-8063(24)00456-0 [pii]
LID - 10.1016/j.arthro.2024.06.021 [doi]
AB  - PURPOSE: To provide a proof-of-concept analysis of the appropriateness and 
      performance of ChatGPT-4 to triage, synthesize differential diagnoses, and 
      generate treatment plans concerning common presentations of knee pain. METHODS: 
      Twenty knee complaints warranting triage and expanded scenarios were input into 
      ChatGPT-4, with memory cleared prior to each new input to mitigate bias. For the 
      10 triage complaints, ChatGPT-4 was asked to generate a differential diagnosis 
      that was graded for accuracy and suitability in comparison to a differential 
      created by 2 orthopaedic sports medicine physicians. For the 10 clinical 
      scenarios, ChatGPT-4 was prompted to provide treatment guidance for the patient, 
      which was again graded. To test the higher-order capabilities of ChatGPT-4, 
      further inquiry into these specific management recommendations was performed and 
      graded. RESULTS: All ChatGPT-4 diagnoses were deemed appropriate within the 
      spectrum of potential pathologies on a differential. The top diagnosis on the 
      differential was identical between surgeons and ChatGPT-4 for 70% of scenarios, 
      and the top diagnosis provided by the surgeon appeared as either the first or 
      second diagnosis in 90% of scenarios. Overall, 16 of 30 diagnoses (53.3%) in the 
      differential were identical. When provided with 10 expanded vignettes with a 
      single diagnosis, the accuracy of ChatGPT-4 increased to 100%, with the 
      suitability of management graded as appropriate in 90% of cases. Specific 
      information pertaining to conservative management, surgical approaches, and 
      related treatments was appropriate and accurate in 100% of cases. CONCLUSIONS: 
      ChatGPT-4 provided clinically reasonable diagnoses to triage patient complaints 
      of knee pain due to various underlying conditions that were generally consistent 
      with differentials provided by sports medicine physicians. Diagnostic performance 
      was enhanced when providing additional information, allowing ChatGPT-4 to reach 
      high predictive accuracy for recommendations concerning management and treatment 
      options. However, ChatGPT-4 may show clinically important error rates for 
      diagnosis depending on prompting strategy and information provided; therefore, 
      further refinements are necessary prior to implementation into clinical 
      workflows. CLINICAL RELEVANCE: Although ChatGPT-4 is increasingly being used by 
      patients for health information, the potential for ChatGPT-4 to serve as a 
      clinical support tool is unclear. In this study, we found that ChatGPT-4 was 
      frequently able to diagnose and triage knee complaints appropriately as rated by 
      sports medicine surgeons, suggesting that it may eventually be a useful clinical 
      support tool.
CI  - Copyright © 2024 Arthroscopy Association of North America. Published by Elsevier 
      Inc. All rights reserved.
FAU - Kunze, Kyle N
AU  - Kunze KN
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.; Sports Medicine and Shoulder Service, Hospital for Special Surgery, 
      New York, New York, U.S.A.. Electronic address: kylekunze7@gmail.com.
FAU - Varady, Nathan H
AU  - Varady NH
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.; Sports Medicine and Shoulder Service, Hospital for Special Surgery, 
      New York, New York, U.S.A.
FAU - Mazzucco, Michael
AU  - Mazzucco M
AD  - Weill Cornell College of Medicine, New York, New York, U.S.A.
FAU - Lu, Amy Z
AU  - Lu AZ
AD  - Weill Cornell College of Medicine, New York, New York, U.S.A.
FAU - Chahla, Jorge
AU  - Chahla J
AD  - Department of Orthopaedic Surgery, Rush University Medical Center, Chicago, 
      Illinois, U.S.A.
FAU - Martin, R Kyle
AU  - Martin RK
AD  - Department of Orthopedic Surgery, University of Minnesota, Minneapolis, 
      Minnesota, U.S.A.
FAU - Ranawat, Anil S
AU  - Ranawat AS
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.; Sports Medicine and Shoulder Service, Hospital for Special Surgery, 
      New York, New York, U.S.A.
FAU - Pearle, Andrew D
AU  - Pearle AD
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.; Sports Medicine and Shoulder Service, Hospital for Special Surgery, 
      New York, New York, U.S.A.
FAU - Williams, Riley J 3rd
AU  - Williams RJ 3rd
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.; Sports Medicine and Shoulder Service, Hospital for Special Surgery, 
      New York, New York, U.S.A.
LA  - eng
PT  - Journal Article
DEP - 20240624
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic & related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
COIS- Disclosures The authors declare the following financial interests/personal 
      relationships which may be considered as potential competing interests: K.N.K. is 
      on the editorial board of Arthroscopy and HSSJournal. J.C. is a board or 
      committee member of American Orthopaedic Society for Sports Medicine, Arthroscopy 
      Association of North America, and International Society of Arthroscopy, Knee 
      Surgery & Orthopaedic Sports Medicine (ISAKOS); is a paid consultant for Arthrex, 
      ConMed Linvatec, Ossur, and Smith & Nephew; and is a paid presenter or speaker 
      for Smith & Nephew. R.K.M. is a board or committee member of ISAKOS and is an 
      unpaid consultant for Smith & Nephew. A.S.R. is a board or committee member of 
      American Academy of Orthopaedic Surgeons, American Orthopaedic Society for Sports 
      Medicine, and Eastern Orthopaedic Association; is on the editorial or governing 
      board of American Journal of Sports Medicine, Current Trends in Musculoskeletal 
      Medicine, Journal of Arthroplasty, Saunders/Mosby-Elsevier, and Springer; is a 
      paid consultant for Anika, Bodycad, Cervos, ConMed Linvatec, Moximed, NewClip, 
      Ranfac, and Smith & Nephew; receives research support from DePuy Mitek Synthes; 
      receives intellectual property royalties from DePuy (A Johnson & Johnson 
      Company); and owns stock or stock options in Enhatch. A.D.P. is a paid consultant 
      for DePuy (A Johnson & Johnson Company), Smith & Nephew, and Zimmer; is a board 
      or committee member of ISAKOS; and owns stock or stock options in LinkX, 
      myGemini, myHealthTrack, Ostesys, and Vent Creativity. R.J.W. receives 
      intellectual property royalties from Arthrex; is a paid consultant for Arthrex, 
      JRF Ortho, and Lipogems; owns stock or stock options in BICMD, Cymedica, Engage 
      Surgical, Gramercy Extremity Orthopedics, and Pristine Surgical, and RecoverX; 
      and receives research support from Histogenics. All other authors (N.H.V., M.M., 
      A.Z.L.) declare that they have no known competing financial interests or personal 
      relationships that could have appeared to influence the work reported in this 
      paper.
EDAT- 2024/06/27 00:42
MHDA- 2024/06/27 00:42
CRDT- 2024/06/26 19:24
PHST- 2024/01/25 00:00 [received]
PHST- 2024/05/28 00:00 [revised]
PHST- 2024/06/14 00:00 [accepted]
PHST- 2024/06/27 00:42 [pubmed]
PHST- 2024/06/27 00:42 [medline]
PHST- 2024/06/26 19:24 [entrez]
AID - S0749-8063(24)00456-0 [pii]
AID - 10.1016/j.arthro.2024.06.021 [doi]
PST - aheadofprint
SO  - Arthroscopy. 2024 Jun 24:S0749-8063(24)00456-0. doi: 
      10.1016/j.arthro.2024.06.021.

PMID- 37510487
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231106
IS  - 2227-9032 (Print)
IS  - 2227-9032 (Electronic)
IS  - 2227-9032 (Linking)
VI  - 11
IP  - 14
DP  - 2023 Jul 17
TI  - ChatGPT Knowledge Evaluation in Basic and Clinical Medical Sciences: Multiple 
      Choice Question Examination-Based Performance.
LID - 10.3390/healthcare11142046 [doi]
LID - 2046
AB  - The Chatbot Generative Pre-Trained Transformer (ChatGPT) has garnered great 
      attention from the public, academicians and science communities. It responds with 
      appropriate and articulate answers and explanations across various disciplines. 
      For the use of ChatGPT in education, research and healthcare, different 
      perspectives exist with some level of ambiguity around its acceptability and 
      ideal uses. However, the literature is acutely lacking in establishing a link to 
      assess the intellectual levels of ChatGPT in the medical sciences. Therefore, the 
      present study aimed to investigate the knowledge level of ChatGPT in medical 
      education both in basic and clinical medical sciences, multiple-choice question 
      (MCQs) examination-based performance and its impact on the medical examination 
      system. In this study, initially, a subject-wise question bank was established 
      with a pool of multiple-choice questions (MCQs) from various medical textbooks 
      and university examination pools. The research team members carefully reviewed 
      the MCQ contents and ensured that the MCQs were relevant to the subject's 
      contents. Each question was scenario-based with four sub-stems and had a single 
      correct answer. In this study, 100 MCQs in various disciplines, including basic 
      medical sciences (50 MCQs) and clinical medical sciences (50 MCQs), were randomly 
      selected from the MCQ bank. The MCQs were manually entered one by one, and a 
      fresh ChatGPT session was started for each entry to avoid memory retention bias. 
      The task was given to ChatGPT to assess the response and knowledge level of 
      ChatGPT. The first response obtained was taken as the final response. Based on a 
      pre-determined answer key, scoring was made on a scale of 0 to 1, with zero 
      representing incorrect and one representing the correct answer. The results 
      revealed that out of 100 MCQs in various disciplines of basic and clinical 
      medical sciences, ChatGPT attempted all the MCQs and obtained 37/50 (74%) marks 
      in basic medical sciences and 35/50 (70%) marks in clinical medical sciences, 
      with an overall score of 72/100 (72%) in both basic and clinical medical 
      sciences. It is concluded that ChatGPT obtained a satisfactory score in both 
      basic and clinical medical sciences subjects and demonstrated a degree of 
      understanding and explanation. This study's findings suggest that ChatGPT may be 
      able to assist medical students and faculty in medical education settings since 
      it has potential as an innovation in the framework of medical sciences and 
      education.
FAU - Meo, Sultan Ayoub
AU  - Meo SA
AUID- ORCID: 0000-0001-9820-1852
AD  - Department of Physiology, College of Medicine, King Saud University, Riyadh 
      11461, Saudi Arabia.
FAU - Al-Masri, Abeer A
AU  - Al-Masri AA
AD  - Department of Physiology, College of Medicine, King Saud University, Riyadh 
      11461, Saudi Arabia.
FAU - Alotaibi, Metib
AU  - Alotaibi M
AD  - University Diabetes Unit, Department of Medicine, College of Medicine, King Saud 
      University, Riyadh 11461, Saudi Arabia.
FAU - Meo, Muhammad Zain Sultan
AU  - Meo MZS
AD  - College of Medicine, Alfaisal University, Riyadh 11533, Saudi Arabia.
FAU - Meo, Muhammad Omair Sultan
AU  - Meo MOS
AD  - College of Medicine, Alfaisal University, Riyadh 11533, Saudi Arabia.
LA  - eng
GR  - (IFKSUOR3-4-3)/Deputyship for Research & Innovation, Ministry of Education, Saudi 
      Arabia (IFKSUOR3-4-3./
PT  - Journal Article
DEP - 20230717
PL  - Switzerland
TA  - Healthcare (Basel)
JT  - Healthcare (Basel, Switzerland)
JID - 101666525
PMC - PMC10379728
OTO - NOTNLM
OT  - ChatGPT
OT  - intellect level
OT  - knowledge
OT  - medical education
COIS- The authors declare no conflict of interest.
EDAT- 2023/07/29 11:43
MHDA- 2023/07/29 11:44
PMCR- 2023/07/17
CRDT- 2023/07/29 01:18
PHST- 2023/06/09 00:00 [received]
PHST- 2023/07/12 00:00 [revised]
PHST- 2023/07/14 00:00 [accepted]
PHST- 2023/07/29 11:44 [medline]
PHST- 2023/07/29 11:43 [pubmed]
PHST- 2023/07/29 01:18 [entrez]
PHST- 2023/07/17 00:00 [pmc-release]
AID - healthcare11142046 [pii]
AID - healthcare-11-02046 [pii]
AID - 10.3390/healthcare11142046 [doi]
PST - epublish
SO  - Healthcare (Basel). 2023 Jul 17;11(14):2046. doi: 10.3390/healthcare11142046.

PMID- 40142791
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250329
IS  - 2077-0383 (Print)
IS  - 2077-0383 (Electronic)
IS  - 2077-0383 (Linking)
VI  - 14
IP  - 6
DP  - 2025 Mar 14
TI  - Breaking Bones, Breaking Barriers: ChatGPT, DeepSeek, and Gemini in Hand Fracture 
      Management.
LID - 10.3390/jcm14061983 [doi]
LID - 1983
AB  - Background: Hand fracture management requires precise diagnostic accuracy and 
      complex decision-making. Advances in artificial intelligence (AI) suggest that 
      large language models (LLMs) may assist or even rival traditional clinical 
      approaches. This study evaluates the effectiveness of ChatGPT-4o, DeepSeek-V3, 
      and Gemini 1.5 in diagnosing and recommending treatment strategies for hand 
      fractures compared to experienced surgeons. Methods: A retrospective analysis of 
      58 anonymized hand fracture cases was conducted. Clinical details, including 
      fracture site, displacement, and soft-tissue involvement, were provided to the AI 
      models, which generated management plans. Their recommendations were compared to 
      actual surgeon decisions, assessing accuracy, precision, recall, and F1 score. 
      Results: ChatGPT-4o demonstrated the highest accuracy (98.28%) and recall 
      (91.74%), effectively identifying most correct interventions but occasionally 
      proposing extraneous options (precision 58.48%). DeepSeek-V3 showed moderate 
      accuracy (63.79%), with balanced precision (61.17%) and recall (57.89%), 
      sometimes omitting correct treatments. Gemini 1.5 performed poorly (accuracy 
      18.97%), with low precision and recall, indicating substantial limitations in 
      clinical decision support. Conclusions: AI models can enhance clinical workflows, 
      particularly in radiographic interpretation and triage, but their limitations 
      highlight the irreplaceable role of human expertise in complex hand trauma 
      management. ChatGPT-4o demonstrated promising accuracy but requires refinement. 
      Ethical concerns regarding AI-driven medical decisions, including bias and 
      transparency, must be addressed before widespread clinical implementation.
FAU - Marcaccini, Gianluca
AU  - Marcaccini G
AUID- ORCID: 0000-0002-8621-8216
AD  - Plastic Surgery Unit, Department of Medicine, Surgery and Neuroscience, 
      University of Siena, 53100 Siena, Italy.
FAU - Seth, Ishith
AU  - Seth I
AUID- ORCID: 0000-0001-5444-8925
AD  - Department of Plastic and Reconstructive Surgery, Peninsula Health, Frankston, 
      VIC 3199, Australia.
FAU - Xie, Yi
AU  - Xie Y
AD  - Department of Plastic and Reconstructive Surgery, Peninsula Health, Frankston, 
      VIC 3199, Australia.
FAU - Susini, Pietro
AU  - Susini P
AUID- ORCID: 0009-0000-6168-0853
AD  - Plastic Surgery Unit, Department of Medicine, Surgery and Neuroscience, 
      University of Siena, 53100 Siena, Italy.
FAU - Pozzi, Mirco
AU  - Pozzi M
AUID- ORCID: 0000-0001-6888-2191
AD  - Plastic Surgery Unit, Department of Medicine, Surgery and Neuroscience, 
      University of Siena, 53100 Siena, Italy.
FAU - Cuomo, Roberto
AU  - Cuomo R
AUID- ORCID: 0000-0002-8396-095X
AD  - Plastic Surgery Unit, Department of Medicine, Surgery and Neuroscience, 
      University of Siena, 53100 Siena, Italy.
FAU - Rozen, Warren M
AU  - Rozen WM
AUID- ORCID: 0000-0002-4092-182X
AD  - Department of Plastic and Reconstructive Surgery, Peninsula Health, Frankston, 
      VIC 3199, Australia.
LA  - eng
PT  - Journal Article
DEP - 20250314
PL  - Switzerland
TA  - J Clin Med
JT  - Journal of clinical medicine
JID - 101606588
PMC - PMC11942733
OTO - NOTNLM
OT  - ChatGPT-4o
OT  - DeepSeek-V3
OT  - Gemini 1.5
OT  - artificial intelligence
OT  - hand fractures
OT  - large language models
OT  - surgical decision-making
COIS- The authors declare no conflicts of interest. Ishith Seth serves as the Guest 
      Editor for the Special Issue in which this manuscript is published. However, the 
      editorial process was conducted independently to ensure transparency and 
      integrity.
EDAT- 2025/03/27 06:28
MHDA- 2025/03/27 06:29
PMCR- 2025/03/14
CRDT- 2025/03/27 01:14
PHST- 2025/02/13 00:00 [received]
PHST- 2025/03/01 00:00 [revised]
PHST- 2025/03/13 00:00 [accepted]
PHST- 2025/03/27 06:29 [medline]
PHST- 2025/03/27 06:28 [pubmed]
PHST- 2025/03/27 01:14 [entrez]
PHST- 2025/03/14 00:00 [pmc-release]
AID - jcm14061983 [pii]
AID - jcm-14-01983 [pii]
AID - 10.3390/jcm14061983 [doi]
PST - epublish
SO  - J Clin Med. 2025 Mar 14;14(6):1983. doi: 10.3390/jcm14061983.

PMID- 37254486
OWN - NLM
STAT- MEDLINE
DCOM- 20230725
LR  - 20230727
IS  - 2287-285X (Electronic)
IS  - 2287-2728 (Print)
IS  - 2287-2728 (Linking)
VI  - 29
IP  - 3
DP  - 2023 Jul
TI  - Correspondence on Letter 1 regarding "Assessing the performance of ChatGPT in 
      answering questions regarding cirrhosis and hepatocellular carcinoma".
PG  - 821-822
LID - 10.3350/cmh.2023.0183 [doi]
FAU - Yeo, Yee Hui
AU  - Yeo YH
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Samaan, Jamil S
AU  - Samaan JS
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Ng, Wee Han
AU  - Ng WH
AD  - Bristol Medical School, University of Bristol, Bristol, UK.
LA  - eng
PT  - Comment
PT  - Journal Article
DEP - 20230531
PL  - Korea (South)
TA  - Clin Mol Hepatol
JT  - Clinical and molecular hepatology
JID - 101586730
SB  - IM
CON - Clin Mol Hepatol. 2023 Jul;29(3):813-814. doi: 10.3350/cmh.2023.0120. PMID: 
      37211355
MH  - Humans
MH  - *Carcinoma, Hepatocellular
MH  - *Liver Neoplasms
MH  - Liver Cirrhosis
PMC - PMC10366788
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cancer
OT  - Health equity
OT  - Health literacy
OT  - Liver cirrhosis
COIS- Conflicts of Interest The authors have no conflicts to disclose.
EDAT- 2023/05/31 06:41
MHDA- 2023/07/25 06:43
PMCR- 2023/07/01
CRDT- 2023/05/31 01:49
PHST- 2023/05/27 00:00 [received]
PHST- 2023/05/30 00:00 [accepted]
PHST- 2023/07/25 06:43 [medline]
PHST- 2023/05/31 06:41 [pubmed]
PHST- 2023/05/31 01:49 [entrez]
PHST- 2023/07/01 00:00 [pmc-release]
AID - cmh.2023.0183 [pii]
AID - cmh-2023-0183 [pii]
AID - 10.3350/cmh.2023.0183 [doi]
PST - ppublish
SO  - Clin Mol Hepatol. 2023 Jul;29(3):821-822. doi: 10.3350/cmh.2023.0183. Epub 2023 
      May 31.

PMID- 39715549
OWN - NLM
STAT- In-Process
LR  - 20250117
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Dec 23
TI  - Reassessing AI in Medicine: Exploring the Capabilities of AI in Academic Abstract 
      Synthesis.
PG  - e55920
LID - 10.2196/55920 [doi]
LID - e55920
FAU - Wang, Zijian
AU  - Wang Z
AUID- ORCID: 0009-0008-0388-1129
AD  - Shandong University of Traditional Chinese Medicine, College of Traditional 
      Chinese Medicine, Jinan, China.
FAU - Zhou, Chunyang
AU  - Zhou C
AUID- ORCID: 0000-0003-3535-440X
AD  - Department of Radiation Oncology, Qilu Hospital (Qingdao), Cheeloo College of 
      Medicine, Shandong University, Qingdao, China.
LA  - eng
PT  - Journal Article
DEP - 20241223
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
CON - J Med Internet Res. 25:e51229.
CIN - J Med Internet Res. 26:e65123.
PMC - PMC11734639
OTO - NOTNLM
OT  - AI
OT  - AI-generated scientific content
OT  - ChatGPT
OT  - LLM
OT  - NLP
OT  - abstract
OT  - academic research
OT  - artificial intelligence
OT  - comparative analysis
OT  - extract
OT  - extraction
OT  - generation
OT  - generative
OT  - language model
OT  - natural language processing
OT  - plagiarism
OT  - publication
OT  - reviewer bias
OT  - scientific research
OT  - text
OT  - textual
COIS- Conflicts of Interest: None declared.
EDAT- 2024/12/23 22:58
MHDA- 2024/12/23 22:58
PMCR- 2024/12/23
CRDT- 2024/12/23 16:53
PHST- 2023/12/29 00:00 [received]
PHST- 2024/09/27 00:00 [accepted]
PHST- 2024/01/16 00:00 [revised]
PHST- 2024/12/23 22:58 [medline]
PHST- 2024/12/23 22:58 [pubmed]
PHST- 2024/12/23 16:53 [entrez]
PHST- 2024/12/23 00:00 [pmc-release]
AID - v26i1e55920 [pii]
AID - 10.2196/55920 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Dec 23;26:e55920. doi: 10.2196/55920.

PMID- 37516680
OWN - NLM
STAT- MEDLINE
DCOM- 20240408
LR  - 20240611
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 5
DP  - 2024 May
TI  - ChatGPT and Clinical Decision Support: Scope, Application, and Limitations.
PG  - 1119-1124
LID - 10.1007/s10439-023-03329-4 [doi]
AB  - This study examines ChatGPT's role in clinical decision support, by analyzing its 
      scope, application, and limitations. By analyzing patient data and providing 
      evidence-based recommendations, ChatGPT, an AI language model, can help 
      healthcare professionals make well-informed decisions. This study examines 
      ChatGPT's use in clinical decision support, including diagnosis and treatment 
      planning. However, it acknowledges limitations like biases, lack of contextual 
      understanding, and human oversight and also proposes a framework for the future 
      clinical decision support system. Understanding these factors will allow 
      healthcare professionals to utilize ChatGPT effectively and make accurate 
      clinical decisions. Further research is needed to understand the implications of 
      using ChatGPT in healthcare settings and to develop safeguards for responsible 
      use.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Ferdush, Jannatul
AU  - Ferdush J
AD  - Department of Computer Science and Engineering, Jashore University of Science and 
      Technology, Jashore, 7408, Bangladesh. jannatulferdush@just.edu.bd.
FAU - Begum, Mahbuba
AU  - Begum M
AD  - Department of Computer Science and Engineering, Mawlana Bhasani Science and 
      Technology, Tangail, 1902, Bangladesh.
FAU - Hossain, Sakib Tanvir
AU  - Hossain ST
AD  - Department of Mechanical Engineering, Khulna University of Engineering and 
      Technology, Khulna, 9203, Bangladesh.
LA  - eng
PT  - Letter
DEP - 20230729
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - Health Personnel
MH  - *Artificial Intelligence
MH  - *Decision Support Systems, Clinical
OTO - NOTNLM
OT  - Biasness
OT  - CDS
OT  - ChatGPT
OT  - Ethics
EDAT- 2023/07/30 01:06
MHDA- 2024/04/08 06:44
CRDT- 2023/07/29 23:04
PHST- 2023/07/15 00:00 [received]
PHST- 2023/07/18 00:00 [accepted]
PHST- 2024/04/08 06:44 [medline]
PHST- 2023/07/30 01:06 [pubmed]
PHST- 2023/07/29 23:04 [entrez]
AID - 10.1007/s10439-023-03329-4 [pii]
AID - 10.1007/s10439-023-03329-4 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 May;52(5):1119-1124. doi: 10.1007/s10439-023-03329-4. Epub 
      2023 Jul 29.

PMID- 38942593
OWN - NLM
STAT- MEDLINE
DCOM- 20240628
LR  - 20241206
IS  - 2056-5933 (Electronic)
IS  - 2056-5933 (Linking)
VI  - 10
IP  - 2
DP  - 2024 Jun 28
TI  - Large language model-driven sentiment analysis for facilitating fibromyalgia 
      diagnosis.
LID - 10.1136/rmdopen-2024-004367 [doi]
LID - e004367
AB  - BACKGROUND: Fibromyalgia (FM) is a complex disorder with widespread pain and 
      emotional distress, posing diagnostic challenges. FM patients show altered 
      cognitive and emotional processing, with a preferential allocation of attention 
      to pain-related information. This attentional bias towards pain cues can impair 
      cognitive functions such as inhibitory control, affecting patients' ability to 
      manage and express emotions. Sentiment analysis using large language models 
      (LLMs) can provide insights by detecting nuances in pain expression. This study 
      investigated whether open-source LLM-driven sentiment analysis could aid FM 
      diagnosis. METHODS: 40 patients with FM, according to the 2016 American College 
      of Rheumatology Criteria and 40 non-FM chronic pain controls referred to 
      rheumatology clinics, were enrolled. Transcribed responses to questions on pain 
      and sleep were machine translated to English and analysed by the LLM 
      Mistral-7B-Instruct-v0.2 using prompt engineering targeting FM-associated 
      language nuances for pain expression ('prompt-engineered') or an approach without 
      this targeting ('ablated'). Accuracy, precision, recall, specificity and area 
      under the receiver operating characteristic curve (AUROC) were calculated using 
      rheumatologist diagnosis as ground truth. RESULTS: The prompt-engineered approach 
      demonstrated accuracy of 0.87, precision of 0.92, recall of 0.84, specificity of 
      0.82 and AUROC of 0.86 for distinguishing FM. In comparison, the ablated approach 
      had an accuracy of 0.76, precision of 0.75, recall of 0.77, specificity of 0.75 
      and AUROC of 0.76. The accuracy was superior to the ablated approach (McNemar's 
      test p<0.001). CONCLUSION: This proof-of-concept study suggests LLM-driven 
      sentiment analysis, especially with prompt engineering, may facilitate FM 
      diagnosis by detecting subtle differences in pain expression. Further validation 
      is warranted, particularly the inclusion of secondary FM patients.
CI  - © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Venerito, Vincenzo
AU  - Venerito V
AUID- ORCID: 0000-0002-2573-5930
AD  - Rheumatology Unit - Department of Precision and Regenerative Medicine and Ionian 
      Area, University of Bari "Aldo Moro", Bari, Italy.
FAU - Iannone, Florenzo
AU  - Iannone F
AUID- ORCID: 0000-0003-0474-5344
AD  - Rheumatology Unit - Department of Precision and Regenerative Medicine and Ionian 
      Area, University of Bari "Aldo Moro", Bari, Italy florenzo.iannone@uniba.it.
LA  - eng
PT  - Journal Article
DEP - 20240628
PL  - England
TA  - RMD Open
JT  - RMD open
JID - 101662038
SB  - IM
MH  - Humans
MH  - *Fibromyalgia/diagnosis/psychology
MH  - Female
MH  - Middle Aged
MH  - Male
MH  - Adult
MH  - ROC Curve
MH  - Natural Language Processing
MH  - Language
MH  - Emotions
MH  - Aged
MH  - Chronic Pain/diagnosis/etiology/psychology
PMC - PMC11227845
OTO - NOTNLM
OT  - Fibromyalgia
OT  - Machine Learning
OT  - Outcome Assessment, Health Care
COIS- Competing interests: None declared.
EDAT- 2024/06/29 00:42
MHDA- 2024/06/29 00:43
PMCR- 2024/06/28
CRDT- 2024/06/28 21:02
PHST- 2024/03/27 00:00 [received]
PHST- 2024/05/08 00:00 [accepted]
PHST- 2024/06/29 00:43 [medline]
PHST- 2024/06/29 00:42 [pubmed]
PHST- 2024/06/28 21:02 [entrez]
PHST- 2024/06/28 00:00 [pmc-release]
AID - rmdopen-2024-004367 [pii]
AID - 10.1136/rmdopen-2024-004367 [doi]
PST - epublish
SO  - RMD Open. 2024 Jun 28;10(2):e004367. doi: 10.1136/rmdopen-2024-004367.

PMID- 38726506
OWN - NLM
STAT- MEDLINE
DCOM- 20240510
LR  - 20240510
IS  - 2296-6498 (Print)
IS  - 2296-6498 (Linking)
VI  - 134
IP  - 2
DP  - 2023 Oct 4
TI  - ChatGPT's performance in dentistry and allergyimmunology assessments: a 
      comparative study.
PG  - 1-17
LID - 10.61872/sdj-2024-06-01 [doi]
AB  - Large language models (LLMs) such as ChatGPT have potential applications in 
      healthcare, including dentistry. Priming, the practice of providing LLMs with 
      initial, relevant information, is an approach to improve their output quality. 
      This study aimed to evaluate the performance of ChatGPT 3 and ChatGPT 4 on 
      self-assessment questions for dentistry, through the Swiss Federal Licensing 
      Examination in Dental Medicine (SFLEDM), and allergy and clinical immunology, 
      through the European Examination in Allergy and Clinical Immunology (EEAACI). The 
      second objective was to assess the impact of priming on ChatGPT's performance. 
      The SFLEDM and EEAACI multiple-choice questions from the University of Bern's 
      Institute for Medical Education platform were administered to both ChatGPT 
      versions, with and without priming. Performance was analyzed based on correct 
      responses. The statistical analysis included Wilcoxon rank sum tests 
      (alpha=0.05). The average accuracy rates in the SFLEDM and EEAACI assessments 
      were 63.3% and 79.3%, respectively. Both ChatGPT versions performed better on 
      EEAACI than SFLEDM, with ChatGPT 4 outperforming ChatGPT 3 across all tests. 
      ChatGPT 3's performance exhibited a significant improvement with priming for both 
      EEAACI (p=0.017) and SFLEDM (p=0.024) assessments. For ChatGPT 4, the priming 
      effect was significant only in the SFLEDM assessment (p=0.038). The performance 
      disparity between SFLEDM and EEAACI assessments underscores ChatGPT's varying 
      proficiency across different medical domains, likely tied to the nature and 
      amount of training data available in each field. Priming can be a tool for 
      enhancing output, especially in earlier LLMs. Advancements from ChatGPT 3 to 4 
      highlight the rapid developments in LLM technology. Yet, their use in critical 
      fields such as healthcare must remain cautious owing to LLMs' inherent 
      limitations and risks.
CI  - Copyright 2024 SWISS DENTAL JOURNAL SSO Science and Clinical Topics. License: 
      This work is licensed under a Creative Commons Attribution 4.0 International 
      License.
FAU - Fuchs, Alexander
AU  - Fuchs A
AD  - Department of Periodontology, Endodontology and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland. 
      florin.eggmann@unibas.ch.
FAU - Trachsel, Tina
AU  - Trachsel T
AD  - Division of Allergy, University Children's Hospital Basel, Basel, Switzerland. 
      florin.eggmann@unibas.ch.
FAU - Weiger, Roland
AU  - Weiger R
AD  - Department of Periodontology, Endodontology and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland. 
      florin.eggmann@unibas.ch.
FAU - Eggmann, Florin
AU  - Eggmann F
AD  - Department of Periodontology, Endodontology and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland. 
      florin.eggmann@unibas.ch.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20231004
PL  - Switzerland
TA  - Swiss Dent J
JT  - Swiss dental journal
JID - 101624119
SB  - IM
MH  - Humans
MH  - *Allergy and Immunology/education
MH  - *Educational Measurement
MH  - Switzerland
MH  - Education, Dental
MH  - Clinical Competence
OTO - NOTNLM
OT  - Allergology
OT  - Artificial intelligence
OT  - Clinical immunology
OT  - Dental education
OT  - Machine learning
OT  - Medical informatics applications
COIS- The authors declare no financial or non-financial conflicts of interest related 
      to this work.
EDAT- 2024/05/10 06:42
MHDA- 2024/05/10 06:43
CRDT- 2024/05/10 04:02
PHST- 2024/02/08 00:00 [received]
PHST- 2024/05/10 06:43 [medline]
PHST- 2024/05/10 06:42 [pubmed]
PHST- 2024/05/10 04:02 [entrez]
AID - 10.61872/sdj-2024-06-01 [doi]
PST - epublish
SO  - Swiss Dent J. 2023 Oct 4;134(2):1-17. doi: 10.61872/sdj-2024-06-01.

PMID- 40053403
OWN - NLM
STAT- MEDLINE
DCOM- 20250307
LR  - 20250307
IS  - 1936-2692 (Electronic)
IS  - 1088-0224 (Linking)
VI  - 31
IP  - 3
DP  - 2025 Mar
TI  - Health equity in the era of large language models.
PG  - 112-117
LID - 10.37765/ajmc.2025.89695 [doi]
AB  - This commentary presents a summary of 8 major regulations and guidelines that 
      have direct implications for the equitable design, implementation, and 
      maintenance of health care-focused large language models (LLMs) deployed in the 
      US. We grouped key equity issues for LLMs into 3 domains: (1) linguistic and 
      cultural bias, (2) accessibility and trust, and (3) oversight and quality 
      control. Solutions shared by these regulations and guidelines are to (1) ensure 
      diverse representation in training data and in teams that develop artificial 
      intelligence (AI) tools, (2) develop techniques to evaluate AI-enabled health 
      care tool performance against real-world data, (3) ensure that AI used in health 
      care is free of discrimination and integrates equity principles, (4) take 
      meaningful steps to ensure access for patients with limited English proficiency, 
      (5) apply AI tools to make workplaces more efficient and reduce administrative 
      burdens, (6) require human oversight of AI tools used in health care delivery, 
      and (7) ensure AI tools are safe, accessible, and beneficial while respecting 
      privacy. There is an opportunity to prevent further embedding of existing 
      disparities and issues in the health care system by enhancing health equity 
      through thoughtfully designed and deployed LLMs.
FAU - Tierney, Aaron A
AU  - Tierney AA
AD  - Kaiser Permanente Northern California Division of Research, 4480 Hacienda Dr, 
      Pleasanton, CA 94588. Email: aaron.a.tierney@kp.org.
FAU - Reed, Mary E
AU  - Reed ME
FAU - Grant, Richard W
AU  - Grant RW
FAU - Doo, Florence X
AU  - Doo FX
FAU - Payán, Denise D
AU  - Payán DD
FAU - Liu, Vincent X
AU  - Liu VX
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Am J Manag Care
JT  - The American journal of managed care
JID - 9613960
SB  - IM
MH  - Humans
MH  - *Health Equity
MH  - *Artificial Intelligence
MH  - United States
MH  - Health Services Accessibility
MH  - Language
MH  - Delivery of Health Care/organization & administration
MH  - Trust
EDAT- 2025/03/07 18:22
MHDA- 2025/03/07 18:23
CRDT- 2025/03/07 12:02
PHST- 2025/03/07 18:23 [medline]
PHST- 2025/03/07 18:22 [pubmed]
PHST- 2025/03/07 12:02 [entrez]
AID - 89695 [pii]
AID - 10.37765/ajmc.2025.89695 [doi]
PST - ppublish
SO  - Am J Manag Care. 2025 Mar;31(3):112-117. doi: 10.37765/ajmc.2025.89695.

PMID- 40038550
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250307
IS  - 2730-664X (Electronic)
IS  - 2730-664X (Linking)
VI  - 5
IP  - 1
DP  - 2025 Mar 4
TI  - Physician clinical decision modification and bias assessment in a randomized 
      controlled trial of AI assistance.
PG  - 59
LID - 10.1038/s43856-025-00781-2 [doi]
LID - 59
AB  - BACKGROUND: Artificial intelligence assistance in clinical decision making shows 
      promise, but concerns exist about potential exacerbation of demographic biases in 
      healthcare. This study aims to evaluate how physician clinical decisions and 
      biases are influenced by AI assistance in a chest pain triage scenario. METHODS: 
      A randomized, pre post-intervention study was conducted with 50 US-licensed 
      physicians who reviewed standardized chest pain video vignettes featuring either 
      a white male or Black female patient. Participants answered clinical questions 
      about triage, risk assessment, and treatment before and after receiving GPT-4 
      generated recommendations. Clinical decision accuracy was evaluated against 
      evidence-based guidelines. RESULTS: Here we show that physicians are willing to 
      modify their clinical decisions based on GPT-4 assistance, leading to improved 
      accuracy scores from 47% to 65% in the white male patient group and 63% to 80% in 
      the Black female patient group. The accuracy improvement occurs without 
      introducing or exacerbating demographic biases, with both groups showing similar 
      magnitudes of improvement (18%). A post-study survey indicates that 90% of 
      physicians expect AI tools to play a significant role in future clinical decision 
      making. CONCLUSIONS: Physician clinical decision making can be augmented by AI 
      assistance while maintaining equitable care across patient demographics. These 
      findings suggest a path forward for AI clinical decision support that improves 
      medical care without amplifying healthcare disparities.
CI  - © 2025. The Author(s).
FAU - Goh, Ethan
AU  - Goh E
AUID- ORCID: 0009-0001-7491-4257
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA, USA. 
      ethangoh@stanford.edu.
AD  - Stanford Clinical Excellence Research Center, Stanford University, Stanford, CA, 
      USA. ethangoh@stanford.edu.
FAU - Bunning, Bryan
AU  - Bunning B
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA, USA.
FAU - Khoong, Elaine C
AU  - Khoong EC
AUID- ORCID: 0000-0002-2514-3572
AD  - Division of General Internal Medicine (DGIM) at ZSFG, Department of Medicine, 
      UCSF, San Francisco, CA, USA.
AD  - Division of Clinical Informatics and Digital Transformation, UCSF, San Francisco, 
      CA, USA.
AD  - UCSF Action Research Center for Equity, UCSF, San Francisco, CA, USA.
FAU - Gallo, Robert J
AU  - Gallo RJ
AUID- ORCID: 0000-0002-2601-0173
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA, USA.
AD  - Center for Innovation to Implementation, VA Palo Alto Health Care System, Palo 
      Alto, CA, USA.
FAU - Milstein, Arnold
AU  - Milstein A
AD  - Stanford Clinical Excellence Research Center, Stanford University, Stanford, CA, 
      USA.
FAU - Centola, Damon
AU  - Centola D
AUID- ORCID: 0000-0002-8084-2333
AD  - Communication, Sociology and Engineering, University of Pennsylvania, 
      Pennsylvania, PA, USA.
FAU - Chen, Jonathan H
AU  - Chen JH
AUID- ORCID: 0000-0002-4387-8740
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA, USA.
AD  - Stanford Clinical Excellence Research Center, Stanford University, Stanford, CA, 
      USA.
AD  - Division of Hospital Medicine, Stanford University, Stanford, CA, USA.
LA  - eng
PT  - Journal Article
DEP - 20250304
PL  - England
TA  - Commun Med (Lond)
JT  - Communications medicine
JID - 9918250414506676
PMC - PMC11880198
OAB - Doctors sometimes make different medical decisions for patients based on their 
      race or gender, even when the symptoms are the same and the advice should be 
      similar. New artificial intelligence (AI) tools such as GPT-4 are becoming 
      available to assist doctors when making clinical decisions. Our study looked at 
      whether using AI would impact performance and bias during doctor decision making. 
      We investigated how doctors respond to AI suggestions when evaluating chest pain, 
      a common but serious medical concern. We showed 50 doctors a video of either a 
      white male or Black female patient describing chest pain symptoms, and asked them 
      to make medical decisions. The doctors then received suggestions from an AI 
      system and could change their decisions. We found that doctors were willing to 
      consider the AI’s suggestions and made more accurate medical decisions after 
      receiving this help. This improvement in decision-making happened equally for all 
      patients, regardless of their race or gender, suggesting AI tools could help 
      improve medical care without increasing bias.
OABL- eng
COIS- Competing interests: B.B. discloses funding from the National Library of Medicine 
      (grant No. 2T15LM007033). E.K. discloses funding from the National Heart, Lung, 
      and Blood Institute (grant No. K23HL157750). R.J.G. is supported by a VA Advanced 
      Fellowship in Medical Informatics. A.M. reports uncompensated and compensated 
      relationships with care.coach, Emsana Health, Embold Health, ezPT, FN Advisors, 
      Intermountain Healthcare, JRSL, The Leapfrog Group, the Peterson Center on 
      Healthcare, Prealize Health, and PBGH. D.C. reports support from a Robert Wood 
      Johnson Pioneer Grant. J.H.C. reports cofounding Reaction Explorer, which 
      develops and licenses organic chemistry education software, as well as paid 
      consulting fees from Sutton Pierce, Younker Hyde Macfarlane and Sykes McAllister 
      as a medical expert witness. He receives funding from the National Institutes of 
      Health (NIH)/National Institute of Allergy and Infectious Diseases 
      (1R01AI17812101), NIH/National Institute on Drug Abuse Clinical Trials Network 
      (UG1DA015815—CTN-0136), Stanford Artificial Intelligence in Medicine and 
      Imaging—Human-Centered Artificial Intelligence Partnership Grant, the 
      NIH-NCATS-Clinical & Translational Science Award (UM1TR004921), Stanford Bio-X 
      Interdisciplinary Initiatives Seed Grants Program (IIP) [R12], NIH/Center for 
      Undiagnosed Diseases at Stanford (U01 NS134358) and the American Heart 
      Association—Strategically Focused Research Network—Diversity in Clinical Trials. 
      The other authors declare no competing interests. The funders had no role in 
      study design, data collection and analysis, decision to publish or preparation of 
      the paper.
EDAT- 2025/03/05 00:22
MHDA- 2025/03/05 00:23
PMCR- 2025/03/04
CRDT- 2025/03/04 23:39
PHST- 2024/04/20 00:00 [received]
PHST- 2025/02/21 00:00 [accepted]
PHST- 2025/03/05 00:23 [medline]
PHST- 2025/03/05 00:22 [pubmed]
PHST- 2025/03/04 23:39 [entrez]
PHST- 2025/03/04 00:00 [pmc-release]
AID - 10.1038/s43856-025-00781-2 [pii]
AID - 781 [pii]
AID - 10.1038/s43856-025-00781-2 [doi]
PST - epublish
SO  - Commun Med (Lond). 2025 Mar 4;5(1):59. doi: 10.1038/s43856-025-00781-2.

PMID- 38739445
OWN - NLM
STAT- MEDLINE
DCOM- 20240513
LR  - 20240710
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 May 13
TI  - Potential of Large Language Models in Health Care: Delphi Study.
PG  - e52399
LID - 10.2196/52399 [doi]
LID - e52399
AB  - BACKGROUND: A large language model (LLM) is a machine learning model inferred 
      from text data that captures subtle patterns of language use in context. Modern 
      LLMs are based on neural network architectures that incorporate transformer 
      methods. They allow the model to relate words together through attention to 
      multiple words in a text sequence. LLMs have been shown to be highly effective 
      for a range of tasks in natural language processing (NLP), including 
      classification and information extraction tasks and generative applications. 
      OBJECTIVE: The aim of this adapted Delphi study was to collect researchers' 
      opinions on how LLMs might influence health care and on the strengths, 
      weaknesses, opportunities, and threats of LLM use in health care. METHODS: We 
      invited researchers in the fields of health informatics, nursing informatics, and 
      medical NLP to share their opinions on LLM use in health care. We started the 
      first round with open questions based on our strengths, weaknesses, 
      opportunities, and threats framework. In the second and third round, the 
      participants scored these items. RESULTS: The first, second, and third rounds had 
      28, 23, and 21 participants, respectively. Almost all participants (26/28, 93% in 
      round 1 and 20/21, 95% in round 3) were affiliated with academic institutions. 
      Agreement was reached on 103 items related to use cases, benefits, risks, 
      reliability, adoption aspects, and the future of LLMs in health care. 
      Participants offered several use cases, including supporting clinical tasks, 
      documentation tasks, and medical research and education, and agreed that 
      LLM-based systems will act as health assistants for patient education. The 
      agreed-upon benefits included increased efficiency in data handling and 
      extraction, improved automation of processes, improved quality of health care 
      services and overall health outcomes, provision of personalized care, accelerated 
      diagnosis and treatment processes, and improved interaction between patients and 
      health care professionals. In total, 5 risks to health care in general were 
      identified: cybersecurity breaches, the potential for patient misinformation, 
      ethical concerns, the likelihood of biased decision-making, and the risk 
      associated with inaccurate communication. Overconfidence in LLM-based systems was 
      recognized as a risk to the medical profession. The 6 agreed-upon privacy risks 
      included the use of unregulated cloud services that compromise data security, 
      exposure of sensitive patient data, breaches of confidentiality, fraudulent use 
      of information, vulnerabilities in data storage and communication, and 
      inappropriate access or use of patient data. CONCLUSIONS: Future research related 
      to LLMs should not only focus on testing their possibilities for NLP-related 
      tasks but also consider the workflows the models could contribute to and the 
      requirements regarding quality, integration, and regulations needed for 
      successful implementation in practice.
CI  - ©Kerstin Denecke, Richard May, LLMHealthGroup, Octavio Rivera Romero. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      13.05.2024.
FAU - Denecke, Kerstin
AU  - Denecke K
AUID- ORCID: 0000-0001-6691-396X
AD  - Bern University of Applied Sciences, Biel, Switzerland.
FAU - May, Richard
AU  - May R
AUID- ORCID: 0000-0001-7186-404X
AD  - Harz University of Applied Sciences, Wernigerode, Germany.
CN  - LLMHealthGroup
AD  - see Acknowledgments, .
FAU - Rivera Romero, Octavio
AU  - Rivera Romero O
AUID- ORCID: 0000-0001-7212-9805
AD  - Instituto de Ingeniería Informática (I3US), Universidad de Sevilla, Sevilla, 
      Spain.
AD  - Department of Electronic Technology, Universidad de Sevilla, Sevilla, Spain.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240513
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - *Delphi Technique
MH  - Humans
MH  - *Natural Language Processing
MH  - Machine Learning
MH  - Delivery of Health Care/methods
MH  - Medical Informatics/methods
PMC - PMC11130776
OTO - NOTNLM
OT  - Delphi
OT  - Delphi study
OT  - LLMs
OT  - NLP
OT  - artificial intelligence
OT  - attitude
OT  - attitudes
OT  - experience
OT  - experiences
OT  - future
OT  - health care
OT  - implementation
OT  - informatics
OT  - innovation
OT  - interview
OT  - interviews
OT  - language model
OT  - large language models
OT  - natural language processing
OT  - opinion
OT  - perception
OT  - perceptions
OT  - perspective
OT  - perspectives
COIS- Conflicts of Interest: None declared.
FIR - de Arriba-Muñoz, Antonio
IR  - de Arriba-Muñoz A
FIR - Chapman, Wendy
IR  - Chapman W
FIR - CL Chow, James
IR  - CL Chow J
FIR - Davies, Shauna
IR  - Davies S
FIR - Grainger, Rebecca
IR  - Grainger R
FIR - V Janssen, Boris
IR  - V Janssen B
FIR - Ji, Shaoxiong
IR  - Ji S
FIR - Kreuzthaler, Markus
IR  - Kreuzthaler M
FIR - Lecler, Augustine
IR  - Lecler A
FIR - Paton, Chris
IR  - Paton C
FIR - Petersen, Carolyn
IR  - Petersen C
FIR - Ramón Lacalle, Juan
IR  - Ramón Lacalle J
FIR - Remedios, Denis
IR  - Remedios D
FIR - Ropero, Jorge
IR  - Ropero J
FIR - L Sevillano, Jose
IR  - L Sevillano J
FIR - Sezgin, Emre
IR  - Sezgin E
FIR - Traver, Vincente
IR  - Traver V
FIR - Daniel Trigo, Jesús
IR  - Daniel Trigo J
FIR - Verspoor, Karin
IR  - Verspoor K
EDAT- 2024/05/13 12:52
MHDA- 2024/05/13 18:46
PMCR- 2024/05/13
CRDT- 2024/05/13 11:54
PHST- 2023/09/02 00:00 [received]
PHST- 2024/04/19 00:00 [accepted]
PHST- 2023/10/10 00:00 [revised]
PHST- 2024/05/13 18:46 [medline]
PHST- 2024/05/13 12:52 [pubmed]
PHST- 2024/05/13 11:54 [entrez]
PHST- 2024/05/13 00:00 [pmc-release]
AID - v26i1e52399 [pii]
AID - 10.2196/52399 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 May 13;26:e52399. doi: 10.2196/52399.

PMID- 38717811
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240525
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 8
DP  - 2024 May 8
TI  - ChatGPT as a Tool for Medical Education and Clinical Decision-Making on the 
      Wards: Case Study.
PG  - e51346
LID - 10.2196/51346 [doi]
LID - e51346
AB  - BACKGROUND: Large language models (LLMs) are computational artificial 
      intelligence systems with advanced natural language processing capabilities that 
      have recently been popularized among health care students and educators due to 
      their ability to provide real-time access to a vast amount of medical knowledge. 
      The adoption of LLM technology into medical education and training has varied, 
      and little empirical evidence exists to support its use in clinical teaching 
      environments. OBJECTIVE: The aim of the study is to identify and qualitatively 
      evaluate potential use cases and limitations of LLM technology for real-time 
      ward-based educational contexts. METHODS: A brief, single-site exploratory 
      evaluation of the publicly available ChatGPT-3.5 (OpenAI) was conducted by 
      implementing the tool into the daily attending rounds of a general internal 
      medicine inpatient service at a large urban academic medical center. ChatGPT was 
      integrated into rounds via both structured and organic use, using the web-based 
      "chatbot" style interface to interact with the LLM through conversational 
      free-text and discrete queries. A qualitative approach using phenomenological 
      inquiry was used to identify key insights related to the use of ChatGPT through 
      analysis of ChatGPT conversation logs and associated shorthand notes from the 
      clinical sessions. RESULTS: Identified use cases for ChatGPT integration included 
      addressing medical knowledge gaps through discrete medical knowledge inquiries, 
      building differential diagnoses and engaging dual-process thinking, challenging 
      medical axioms, using cognitive aids to support acute care decision-making, and 
      improving complex care management by facilitating conversations with 
      subspecialties. Potential additional uses included engaging in difficult 
      conversations with patients, exploring ethical challenges and general medical 
      ethics teaching, personal continuing medical education resources, developing 
      ward-based teaching tools, supporting and automating clinical documentation, and 
      supporting productivity and task management. LLM biases, misinformation, ethics, 
      and health equity were identified as areas of concern and potential limitations 
      to clinical and training use. A code of conduct on ethical and appropriate use 
      was also developed to guide team usage on the wards. CONCLUSIONS: Overall, 
      ChatGPT offers a novel tool to enhance ward-based learning through rapid 
      information querying, second-order content exploration, and engaged team 
      discussion regarding generated responses. More research is needed to fully 
      understand contexts for educational use, particularly regarding the risks and 
      limitations of the tool in clinical settings and its impacts on trainee 
      development.
CI  - ©Anthony Skryd, Katharine Lawrence. Originally published in JMIR Formative 
      Research (https://formative.jmir.org), 08.05.2024.
FAU - Skryd, Anthony
AU  - Skryd A
AUID- ORCID: 0009-0009-5230-5029
AD  - Department of Medicine, NYU Langone Health, New York City, NY, United States.
FAU - Lawrence, Katharine
AU  - Lawrence K
AUID- ORCID: 0000-0001-5640-2138
AD  - Department of Population Health, NYU Grossman School of Medicine, New York City, 
      NY, United States.
LA  - eng
PT  - Journal Article
DEP - 20240508
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
PMC - PMC11112466
OTO - NOTNLM
OT  - ChatGPT
OT  - LLMs
OT  - clinical decision-making
OT  - large language models
OT  - medical education
COIS- Conflicts of Interest: None declared.
EDAT- 2024/05/08 12:45
MHDA- 2024/05/08 12:46
PMCR- 2024/05/08
CRDT- 2024/05/08 11:53
PHST- 2023/07/28 00:00 [received]
PHST- 2024/03/21 00:00 [accepted]
PHST- 2023/11/30 00:00 [revised]
PHST- 2024/05/08 12:46 [medline]
PHST- 2024/05/08 12:45 [pubmed]
PHST- 2024/05/08 11:53 [entrez]
PHST- 2024/05/08 00:00 [pmc-release]
AID - v8i1e51346 [pii]
AID - 10.2196/51346 [doi]
PST - epublish
SO  - JMIR Form Res. 2024 May 8;8:e51346. doi: 10.2196/51346.

PMID- 37235847
OWN - NLM
STAT- MEDLINE
DCOM- 20230529
LR  - 20230530
IS  - 2473-4276 (Electronic)
IS  - 2473-4276 (Linking)
VI  - 7
DP  - 2023 May
TI  - Natural Language Processing Methods to Empirically Explore Social Contexts and 
      Needs in Cancer Patient Notes.
PG  - e2200196
LID - 10.1200/CCI.22.00196 [doi]
AB  - PURPOSE: There is an unmet need to empirically explore and understand drivers of 
      cancer disparities, particularly social determinants of health. We explored 
      natural language processing methods to automatically and empirically extract 
      clinical documentation of social contexts and needs that may underlie 
      disparities. METHODS: This was a retrospective analysis of 230,325 clinical notes 
      from 5,285 patients treated with radiotherapy from 2007 to 2019. We compared 
      linguistic features among White versus non-White, low-income insurance versus 
      other insurance, and male versus female patients' notes. Log odds ratios with an 
      informative Dirichlet prior were calculated to compare words over-represented in 
      each group. A variational autoencoder topic model was applied, and topic 
      probability was compared between groups. The presence of machine-learnable bias 
      was explored by developing statistical and neural demographic group classifiers. 
      RESULTS: Terms associated with varied social contexts and needs were identified 
      for all demographic group comparisons. For example, notes of non-White and 
      low-income insurance patients were over-represented with terms associated with 
      housing and transportation, whereas notes of White and other insurance patients 
      were over-represented with terms related to physical activity. Topic models 
      identified a social history topic, and topic probability varied significantly 
      between the demographic group comparisons. Classification models performed poorly 
      at classifying notes of non-White and low-income insurance patients (F1 of 0.30 
      and 0.23, respectively). CONCLUSION: Exploration of linguistic differences in 
      clinical notes between patients of different race/ethnicity, insurance status, 
      and sex identified social contexts and needs in patients with cancer and revealed 
      high-level differences in notes. Future work is needed to validate whether these 
      findings may play a role in cancer disparities.
FAU - Derton, Abigail
AU  - Derton A
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, 
      MA.
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA.
FAU - Guevara, Marco
AU  - Guevara M
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Harvard Medical School, Boston, MA.
FAU - Chen, Shan
AU  - Chen S
AUID- ORCID: 0000-0001-7999-7410
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Harvard Medical School, Boston, MA.
FAU - Moningi, Shalini
AU  - Moningi S
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Harvard Medical School, Boston, MA.
FAU - Kozono, David E
AU  - Kozono DE
AUID- ORCID: 0000-0002-8916-396X
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Harvard Medical School, Boston, MA.
FAU - Liu, Dianbo
AU  - Liu D
AUID- ORCID: 0000-0002-3042-9161
AD  - Mila-Quebec AI Institute, Montreal, QC, Canada.
FAU - Miller, Timothy A
AU  - Miller TA
AD  - Computational Health Informatics Program, Boston Children's Hospital, Boston, MA.
FAU - Savova, Guergana K
AU  - Savova GK
AUID- ORCID: 0000-0002-5887-200X
AD  - Computational Health Informatics Program, Boston Children's Hospital, Boston, MA.
FAU - Mak, Raymond H
AU  - Mak RH
AUID- ORCID: 0000-0002-8754-0565
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Harvard Medical School, Boston, MA.
FAU - Bitterman, Danielle S
AU  - Bitterman DS
AUID- ORCID: 0000-0003-0345-2232
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Harvard Medical School, Boston, MA.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - JCO Clin Cancer Inform
JT  - JCO clinical cancer informatics
JID - 101708809
SB  - IM
MH  - Humans
MH  - Male
MH  - Female
MH  - *Natural Language Processing
MH  - Retrospective Studies
MH  - Social Environment
MH  - *Neoplasms/diagnosis/epidemiology/therapy
EDAT- 2023/05/26 19:14
MHDA- 2023/05/29 06:41
CRDT- 2023/05/26 16:04
PHST- 2023/05/29 06:41 [medline]
PHST- 2023/05/26 19:14 [pubmed]
PHST- 2023/05/26 16:04 [entrez]
AID - 10.1200/CCI.22.00196 [doi]
PST - ppublish
SO  - JCO Clin Cancer Inform. 2023 May;7:e2200196. doi: 10.1200/CCI.22.00196.

PMID- 37693388
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250318
DP  - 2023 Aug 28
TI  - Assessing Racial and Ethnic Bias in Text Generation for Healthcare-Related Tasks 
      by ChatGPT(1).
LID - 2023.08.28.23294730 [pii]
LID - 10.1101/2023.08.28.23294730 [doi]
AB  - Large Language Models (LLM) are AI tools that can respond human-like to voice or 
      free-text commands without training on specific tasks. However, concerns have 
      been raised about their potential racial bias in healthcare tasks. In this study, 
      ChatGPT was used to generate healthcare-related text for patients with HIV, 
      analyzing data from 100 deidentified electronic health record encounters. Each 
      patient's data were fed four times with all information remaining the same except 
      for race/ethnicity (African American, Asian, Hispanic White, Non-Hispanic White). 
      The text output was analyzed for sentiment, subjectivity, reading ease, and most 
      used words by race/ethnicity and insurance type. Results showed that instructions 
      for African American, Asian, Hispanic White, and Non-Hispanic White patients had 
      an average polarity of 0.14, 0.14, 0.15, and 0.14, respectively, with an average 
      subjectivity of 0.46 for all races/ethnicities. The differences in polarity and 
      subjectivity across races/ethnicities were not statistically significant. 
      However, there was a statistically significant difference in word frequency 
      across races/ethnicities and a statistically significant difference in 
      subjectivity across insurance types with commercial insurance eliciting the most 
      subjective responses and Medicare and other payer types the lowest. The study 
      suggests that ChatGPT is relatively invariant to race/ethnicity and insurance 
      type in terms of linguistic and readability measures. Further studies are needed 
      to validate these results and assess their implications.
FAU - Hanna, John J
AU  - Hanna JJ
AD  - Clinical Informatics Center, University of Texas Southwestern, 5323 Harry Hines 
      Blvd, Dallas, TX 75390, USA.
FAU - Wakene, Abdi D
AU  - Wakene AD
AD  - Clinical Informatics Center, University of Texas Southwestern, 5323 Harry Hines 
      Blvd, Dallas, TX 75390, USA.
FAU - Lehmann, Christoph U
AU  - Lehmann CU
AD  - Clinical Informatics Center, University of Texas Southwestern, 5323 Harry Hines 
      Blvd, Dallas, TX 75390, USA.
FAU - Medford, Richard J
AU  - Medford RJ
AD  - Clinical Informatics Center, University of Texas Southwestern, 5323 Harry Hines 
      Blvd, Dallas, TX 75390, USA.
LA  - eng
GR  - UL1 TR003163/TR/NCATS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20230828
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - J Med Internet Res. 2025 Mar 13;27:e57257. doi: 10.2196/57257. PMID: 40080818
PMC - PMC10491360
OTO - NOTNLM
OT  - Large Language Model
OT  - artificial intelligence
OT  - bias
OT  - racism
OT  - reading ease
OT  - sentiment analysis
OT  - word frequency
EDAT- 2023/09/11 06:42
MHDA- 2023/09/11 06:43
PMCR- 2023/09/08
CRDT- 2023/09/11 04:53
PHST- 2023/09/11 06:42 [pubmed]
PHST- 2023/09/11 06:43 [medline]
PHST- 2023/09/11 04:53 [entrez]
PHST- 2023/09/08 00:00 [pmc-release]
AID - 2023.08.28.23294730 [pii]
AID - 10.1101/2023.08.28.23294730 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Aug 28:2023.08.28.23294730. doi: 
      10.1101/2023.08.28.23294730.

PMID- 39749996
OWN - NLM
STAT- MEDLINE
DCOM- 20250123
LR  - 20250123
IS  - 1522-1229 (Electronic)
IS  - 1043-4046 (Linking)
VI  - 49
IP  - 1
DP  - 2025 Mar 1
TI  - Ethical engagement with artificial intelligence in medical education.
PG  - 163-165
LID - 10.1152/advan.00188.2024 [doi]
AB  - The integration of large language models (LLMs) in medical education offers both 
      opportunities and challenges. While these artificial intelligence (AI)-driven 
      tools can enhance access to information and support critical thinking, they also 
      pose risks like potential overreliance and ethical concerns. To ensure ethical 
      use, students and instructors must recognize the limitations of LLMs, maintain 
      academic integrity, and handle data cautiously, and instructors should prioritize 
      content quality over AI detection methods. LLMs can be used as supplementary aids 
      rather than primary educational resources, with a focus on enhancing 
      accessibility and equity and fostering a culture of feedback. Institutions should 
      create guidelines that align with their unique educational values, providing 
      clear frameworks that support responsible LLM usage while addressing risks 
      associated with AI in education. Such guidelines should reflect the institution's 
      pedagogical mission, whether centered on clinical practice, research, or a mix of 
      both, and should be adaptable to evolving educational technologies.
FAU - Mondal, Himel
AU  - Mondal H
AUID- ORCID: 0000-0001-6950-5857
AD  - Department of PhysiologyAll India Institute of Medical Sciences, Deoghar, 
      Jharkhand, India.
LA  - eng
PT  - Editorial
PT  - Journal Article
DEP - 20250103
PL  - United States
TA  - Adv Physiol Educ
JT  - Advances in physiology education
JID - 100913944
SB  - IM
MH  - *Artificial Intelligence/ethics
MH  - Humans
MH  - *Education, Medical/methods/ethics
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - large language model
OT  - medical education
OT  - medical students
EDAT- 2025/01/03 12:21
MHDA- 2025/01/23 12:35
CRDT- 2025/01/03 08:42
PHST- 2025/01/23 12:35 [medline]
PHST- 2025/01/03 12:21 [pubmed]
PHST- 2025/01/03 08:42 [entrez]
AID - 10.1152/advan.00188.2024 [doi]
PST - ppublish
SO  - Adv Physiol Educ. 2025 Mar 1;49(1):163-165. doi: 10.1152/advan.00188.2024. Epub 
      2025 Jan 3.

PMID- 38596779
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240411
IS  - 2163-0402 (Print)
IS  - 2163-0933 (Electronic)
IS  - 2163-0402 (Linking)
VI  - 14
IP  - 3
DP  - 2024 Jun
TI  - GPT-4 Performance for Neurologic Localization.
PG  - e200293
LID - 10.1212/CPJ.0000000000200293 [doi]
LID - e200293
AB  - BACKGROUND AND OBJECTIVES: In health care, large language models such as 
      Generative Pretrained Transformers (GPTs), trained on extensive text datasets, 
      have potential applications in reducing health care disparities across regions 
      and populations. Previous software developed for lesion localization has been 
      limited in scope. This study aims to evaluate the capability of GPT-4 for lesion 
      localization based on clinical presentation. METHODS: GPT-4 was prompted using 
      history and neurologic physical examination (H&P) from published cases of acute 
      stroke followed by questions for clinical reasoning with answering for "single or 
      multiple lesions," "side," and "brain region" using Zero-Shot Chain-of-Thought 
      and Text Classification prompting. GPT-4 output on 3 separate trials for each of 
      46 cases was compared with imaging-based localization. RESULTS: GPT-4 
      successfully processed raw text from H&P to generate accurate neuroanatomical 
      localization and detailed clinical reasoning. Performance metrics across 
      trial-based analysis for specificity, sensitivity, precision, and F1-score were 
      0.87, 0.74, 0.75, and 0.74, respectively, for side; 0.94, 0.85, 0.84, and 0.85, 
      respectively, for brain region. Class labels within the brain region were 
      similarly high for all regions except the cerebellum and were also similar when 
      considering all 3 trials to examine metrics by case. Errors were due to extrinsic 
      causes-inadequate information in the published cases, and intrinsic 
      causes-failures of logic or inadequate knowledge base. DISCUSSION: This study 
      reveals capabilities of GPT-4 in the localization of acute stroke lesions, 
      showing a potential future role as a clinical tool in neurology.
CI  - Copyright © 2024 The Author(s). Published by Wolters Kluwer Health, Inc. on 
      behalf of the American Academy of Neurology.
FAU - Lee, Jung-Hyun
AU  - Lee JH
AUID- ORCID: 0000-0001-7751-792X
AD  - Department of Neurology (J-HL, WWL), State University of New York Downstate 
      Health Sciences University; Department of Neurology (J-HL, WWL), Kings County 
      Hospital; Department of Neurology (J-HL), Maimonides Medical Center, Brooklyn; 
      Department of Internal Medicine (EC), Lincoln Medical Center, Bronx, NY; 
      Department of Biostatistics (RM), Yale School of Public Health; Program in 
      Computational Biology and Bioinformatics (RM); Wu-Tsai Institute (RM); Section of 
      Biomedical Informatics and Data Science (RM), Yale School of Medicine, Yale 
      University, New Haven, CT; and Department of Physiology and Pharmacology (WWL), 
      State University of New York Downstate Health Sciences University, Brooklyn, NY.
FAU - Choi, Eunhee
AU  - Choi E
AUID- ORCID: 0009-0009-9945-1322
AD  - Department of Neurology (J-HL, WWL), State University of New York Downstate 
      Health Sciences University; Department of Neurology (J-HL, WWL), Kings County 
      Hospital; Department of Neurology (J-HL), Maimonides Medical Center, Brooklyn; 
      Department of Internal Medicine (EC), Lincoln Medical Center, Bronx, NY; 
      Department of Biostatistics (RM), Yale School of Public Health; Program in 
      Computational Biology and Bioinformatics (RM); Wu-Tsai Institute (RM); Section of 
      Biomedical Informatics and Data Science (RM), Yale School of Medicine, Yale 
      University, New Haven, CT; and Department of Physiology and Pharmacology (WWL), 
      State University of New York Downstate Health Sciences University, Brooklyn, NY.
FAU - McDougal, Robert
AU  - McDougal R
AUID- ORCID: 0000-0001-6394-3127
AD  - Department of Neurology (J-HL, WWL), State University of New York Downstate 
      Health Sciences University; Department of Neurology (J-HL, WWL), Kings County 
      Hospital; Department of Neurology (J-HL), Maimonides Medical Center, Brooklyn; 
      Department of Internal Medicine (EC), Lincoln Medical Center, Bronx, NY; 
      Department of Biostatistics (RM), Yale School of Public Health; Program in 
      Computational Biology and Bioinformatics (RM); Wu-Tsai Institute (RM); Section of 
      Biomedical Informatics and Data Science (RM), Yale School of Medicine, Yale 
      University, New Haven, CT; and Department of Physiology and Pharmacology (WWL), 
      State University of New York Downstate Health Sciences University, Brooklyn, NY.
FAU - Lytton, William W
AU  - Lytton WW
AUID- ORCID: 0000-0002-3727-2849
AD  - Department of Neurology (J-HL, WWL), State University of New York Downstate 
      Health Sciences University; Department of Neurology (J-HL, WWL), Kings County 
      Hospital; Department of Neurology (J-HL), Maimonides Medical Center, Brooklyn; 
      Department of Internal Medicine (EC), Lincoln Medical Center, Bronx, NY; 
      Department of Biostatistics (RM), Yale School of Public Health; Program in 
      Computational Biology and Bioinformatics (RM); Wu-Tsai Institute (RM); Section of 
      Biomedical Informatics and Data Science (RM), Yale School of Medicine, Yale 
      University, New Haven, CT; and Department of Physiology and Pharmacology (WWL), 
      State University of New York Downstate Health Sciences University, Brooklyn, NY.
LA  - eng
PT  - Journal Article
DEP - 20240327
PL  - United States
TA  - Neurol Clin Pract
JT  - Neurology. Clinical practice
JID - 101577149
CIN - doi: 10.1212/CPJ.0000000000200311
CIN - Neurol Clin Pract. 14:e200311.
PMC - PMC11003355
COIS- The authors report no relevant disclosures. Full disclosure form information 
      provided by the authors is available with the full text of this article at 
      Neurology.org/cp. TAKE-HOME POINTS → GPT-4, a large language model (LLM) with no 
      specific medical training, was able to accurately localize stroke.→ Natural 
      language processing will permit neurologic computer applications to interpret 
      clinical free text.→ Prompt engineering (telling the program what you want) is 
      crucial for obtaining useful results from LLMs in our domain, as in others.→ Our 
      analysis of GPT-4 errors showed that many errors were due to inadequate or 
      contradictory inputs in the cases, while some errors were “logical” or knowledge 
      base errors from GPT-4.→ Our study provides an initial template for future 
      development of LLMs for clinical use, but medicine as a field will need to 
      address multiple issues including patient privacy and safety and ensuring greater 
      LLM accuracy and consistency.
EDAT- 2024/04/10 06:42
MHDA- 2024/04/10 06:43
PMCR- 2024/03/27
CRDT- 2024/04/10 04:15
PHST- 2023/12/21 00:00 [received]
PHST- 2024/01/23 00:00 [accepted]
PHST- 2024/04/10 06:43 [medline]
PHST- 2024/04/10 06:42 [pubmed]
PHST- 2024/04/10 04:15 [entrez]
PHST- 2024/03/27 00:00 [pmc-release]
AID - CPJ-2023-000696 [pii]
AID - 10.1212/CPJ.0000000000200293 [doi]
PST - ppublish
SO  - Neurol Clin Pract. 2024 Jun;14(3):e200293. doi: 10.1212/CPJ.0000000000200293. 
      Epub 2024 Mar 27.

PMID- 37506388
OWN - NLM
STAT- MEDLINE
DCOM- 20231027
LR  - 20231027
IS  - 1938-808X (Electronic)
IS  - 1040-2446 (Linking)
VI  - 98
IP  - 11
DP  - 2023 Nov 1
TI  - Using Natural Language Processing and Machine Learning to Identify Internal 
      Medicine-Pediatrics Residency Values in Applications.
PG  - 1278-1282
LID - 10.1097/ACM.0000000000005352 [doi]
AB  - PROBLEM: Although holistic review has been used successfully in some residency 
      programs to decrease bias, such review is time-consuming and unsustainable for 
      many programs without initial prescreening. The unstructured qualitative data in 
      residency applications, including notable experiences, letters of recommendation, 
      personal statement, and medical student performance evaluations, require 
      extensive time, resources, and metrics to evaluate; therefore, previous applicant 
      screening relied heavily on quantitative metrics, which can be socioeconomically 
      and racially biased. APPROACH: Using residency applications to the University of 
      Utah internal medicine-pediatrics program from 2015 to 2019, the authors 
      extracted relevant snippets of text from the narrative sections of applications. 
      Expert reviewers annotated these snippets into specific values (academic 
      strength; intellectual curiosity; compassion; communication; work ethic; 
      teamwork; leadership; self-awareness; diversity, equity, and inclusion; 
      professionalism; and adaptability) previously identified as associated with 
      resident success. The authors prospectively applied a machine learning model 
      (MLM) to snippets from applications from 2023, and output was compared with a 
      manual holistic review performed without knowledge of MLM results. OUTCOMES: 
      Overall, the MLM had a sensitivity of 0.64, specificity of 0.97, positive 
      predictive value of 0.62, negative predictive value of 0.97, and F1 score of 
      0.63. The mean (SD) total number of annotations per application was significantly 
      correlated with invited for interview status (invited: 208.6 [59.1]; not invited: 
      145.2 [57.2]; P < .001). In addition, 8 of the 10 individual values were 
      significantly predictive of an applicant's invited for interview status. NEXT 
      STEPS: The authors created an MLM that can identify several values important for 
      resident success in internal medicine-pediatrics programs with moderate 
      sensitivity and high specificity. The authors will continue to refine the MLM by 
      increasing the number of annotations, exploring parameter tuning and feature 
      engineering options, and identifying which application sections have the highest 
      correlation with invited for interview status.
CI  - Copyright © 2023 by the Association of American Medical Colleges.
FAU - Drum, Benjamin
AU  - Drum B
AD  - B. Drum is assistant professor, Department of Internal Medicine, and adjunct 
      professor, Department of Pediatrics, University of Utah School of Medicine, Salt 
      Lake City, Utah.
FAU - Shi, Jianlin
AU  - Shi J
AD  - J. Shi is a research associate, Department of Biomedical Informatics, University 
      of Utah, Salt Lake City, Utah.
FAU - Peterson, Bennet
AU  - Peterson B
AD  - B. Peterson is a graduate student, Department of Biomedical Informatics, 
      University of Utah, Salt Lake City, Utah.
FAU - Lamb, Sara
AU  - Lamb S
AD  - S. Lamb is vice dean of education, University of Utah School of Medicine, Salt 
      Lake City, Utah.
FAU - Hurdle, John F
AU  - Hurdle JF
AD  - J.F. Hurdle is professor, Department of Biomedical Informatics, University of 
      Utah, Salt Lake City, Utah.
FAU - Gradick, Casey
AU  - Gradick C
AD  - C. Gradick is assistant professor, Department of Internal Medicine, and adjunct 
      professor, Department of Pediatrics, University of Utah School of Medicine, Salt 
      Lake City, Utah.
LA  - eng
PT  - Journal Article
DEP - 20230727
PL  - United States
TA  - Acad Med
JT  - Academic medicine : journal of the Association of American Medical Colleges
JID - 8904605
SB  - IM
MH  - Humans
MH  - Child
MH  - *Internship and Residency
MH  - Natural Language Processing
MH  - Internal Medicine/education
MH  - Professionalism
MH  - Communication
EDAT- 2023/07/28 19:11
MHDA- 2023/10/27 06:42
CRDT- 2023/07/28 17:13
PHST- 2023/10/27 06:42 [medline]
PHST- 2023/07/28 19:11 [pubmed]
PHST- 2023/07/28 17:13 [entrez]
AID - 00001888-202311000-00020 [pii]
AID - 10.1097/ACM.0000000000005352 [doi]
PST - ppublish
SO  - Acad Med. 2023 Nov 1;98(11):1278-1282. doi: 10.1097/ACM.0000000000005352. Epub 
      2023 Jul 27.

PMID- 39287525
OWN - NLM
STAT- MEDLINE
DCOM- 20240917
LR  - 20240917
IS  - 1527-1315 (Electronic)
IS  - 0033-8419 (Linking)
VI  - 312
IP  - 3
DP  - 2024 Sep
TI  - Constructing a Large Language Model to Generate Impressions from Findings in 
      Radiology Reports.
PG  - e240885
LID - 10.1148/radiol.240885 [doi]
AB  - Background The specialization and complexity of radiology makes the automatic 
      generation of radiologic impressions (ie, a diagnosis with differential diagnosis 
      and management recommendations) challenging. Purpose To develop a large language 
      model (LLM) that generates impressions based on imaging findings and to evaluate 
      its performance in professional and linguistic dimensions. Materials and Methods 
      Six radiologists recorded imaging examination findings from August 2 to 31, 2023, 
      at Shanghai General Hospital and used the developed LLM before routinely writing 
      report impressions for multiple radiologic modalities (CT, MRI, radiography, 
      mammography) and anatomic sites (cranium and face, neck, chest, upper abdomen, 
      lower abdomen, vessels, bone and joint, spine, breast), making necessary 
      corrections and completing the radiologic impression. A subset was defined to 
      investigate cases where the LLM-generated impressions differed from the final 
      radiologist impressions by excluding identical and highly similar cases. An 
      expert panel scored the LLM-generated impressions on a five-point Likert scale (5 
      = strongly agree) based on scientific terminology, coherence, specific diagnosis, 
      differential diagnosis, management recommendations, correctness, 
      comprehensiveness, harmlessness, and lack of bias. Results In this retrospective 
      study, an LLM was pretrained using 20 GB of medical and general-purpose text 
      data. The fine-tuning data set comprised 1.5 GB of data, including 800 radiology 
      reports with paired instructions (describing the output task in natural language) 
      and outputs. Test set 2 included data from 3988 patients (median age, 56 years 
      [IQR, 40-68 years]; 2159 male). The median recall, precision, and F1 score of 
      LLM-generated impressions were 0.775 (IQR, 0.56-1), 0.84 (IQR, 0.611-1), and 
      0.772 (IQR, 0.578-0.957), respectively, using the final impressions as the 
      reference standard. In a subset of 1014 patients (median age, 57 years [IQR, 
      42-69 years]; 528 male), the overall median expert panel score for LLM-generated 
      impressions was 5 (IQR, 5-5), ranging from 4 (IQR, 3-5) to 5 (IQR, 5-5). 
      Conclusion The developed LLM generated radiologic impressions that were 
      professionally and linguistically appropriate for a full spectrum of radiology 
      examinations. © RSNA, 2024 Supplemental material is available for this article.
FAU - Zhang, Lu
AU  - Zhang L
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Liu, Mingqian
AU  - Liu M
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Wang, Lingyun
AU  - Wang L
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Zhang, Yaping
AU  - Zhang Y
AUID- ORCID: 0000-0003-0034-2484
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Xu, Xiangjun
AU  - Xu X
AUID- ORCID: 0009-0002-0326-0329
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Pan, Zhijun
AU  - Pan Z
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Feng, Yan
AU  - Feng Y
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Zhao, Jue
AU  - Zhao J
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Zhang, Lin
AU  - Zhang L
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Yao, Gehong
AU  - Yao G
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Chen, Xu
AU  - Chen X
AUID- ORCID: 0009-0005-9933-2754
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
FAU - Xie, Xueqian
AU  - Xie X
AUID- ORCID: 0000-0002-6669-0097
AD  - From the Department of Radiology, Shanghai General Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, China (Lu Zhang, L.W., Y.Z., Y.F., J.Z., 
      Lin Zhang, G.Y., X. Xie); Winning Health Technology, Shanghai, China (M.L., X. 
      Xu, Z.P., X.C.); and Department of Radiology, Shanghai Tenth People's Hospital, 
      Tongji University School of Medicine, Yan Chang Zhong Rd 301, Shanghai 200040, 
      China (X. Xie).
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Radiology
JT  - Radiology
JID - 0401260
SB  - IM
MH  - Humans
MH  - Retrospective Studies
MH  - Male
MH  - Female
MH  - Middle Aged
MH  - Adult
MH  - Aged
MH  - Diagnosis, Differential
MH  - *Diagnostic Imaging/methods
MH  - Natural Language Processing
EDAT- 2024/09/17 21:47
MHDA- 2024/09/17 21:48
CRDT- 2024/09/17 10:02
PHST- 2024/09/17 21:48 [medline]
PHST- 2024/09/17 21:47 [pubmed]
PHST- 2024/09/17 10:02 [entrez]
AID - 10.1148/radiol.240885 [doi]
PST - ppublish
SO  - Radiology. 2024 Sep;312(3):e240885. doi: 10.1148/radiol.240885.

PMID- 38552383
OWN - NLM
STAT- MEDLINE
DCOM- 20240417
LR  - 20240417
IS  - 1873-4499 (Electronic)
IS  - 0899-7071 (Linking)
VI  - 109
DP  - 2024 May
TI  - Even with ChatGPT, race matters.
PG  - 110113
LID - S0899-7071(24)00043-3 [pii]
LID - 10.1016/j.clinimag.2024.110113 [doi]
AB  - BACKGROUND: Applications of large language models such as ChatGPT are 
      increasingly being studied. Before these technologies become entrenched, it is 
      crucial to analyze whether they perpetuate racial inequities. METHODS: We asked 
      Open AI's ChatGPT-3.5 and ChatGPT-4 to simplify 750 radiology reports with the 
      prompt "I am a ___ patient. Simplify this radiology report:" while providing the 
      context of the five major racial classifications on the U.S. census: White, Black 
      or African American, American Indian or Alaska Native, Asian, and Native Hawaiian 
      or other Pacific Islander. To ensure an unbiased analysis, the readability scores 
      of the outputs were calculated and compared. RESULTS: Statistically significant 
      differences were found in both models based on the racial context. For 
      ChatGPT-3.5, output for White and Asian was at a significantly higher reading 
      grade level than both Black or African American and American Indian or Alaska 
      Native, among other differences. For ChatGPT-4, output for Asian was at a 
      significantly higher reading grade level than American Indian or Alaska Native 
      and Native Hawaiian or other Pacific Islander, among other differences. 
      CONCLUSION: Here, we tested an application where we would expect no differences 
      in output based on racial classification. Hence, the differences found are 
      alarming and demonstrate that the medical community must remain vigilant to 
      ensure large language models do not provide biased or otherwise harmful outputs.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Amin, Kanhai S
AU  - Amin KS
AD  - Yale College, New Haven, CT, USA.
FAU - Forman, Howard P
AU  - Forman HP
AD  - Department of Radiology and Biomedical Imaging, Yale School of Medicine, New 
      Haven, CT, USA.
FAU - Davis, Melissa A
AU  - Davis MA
AD  - Department of Radiology and Biomedical Imaging, Yale School of Medicine, New 
      Haven, CT, USA. Electronic address: melissa.a.davis@yale.edu.
LA  - eng
PT  - Journal Article
DEP - 20240302
PL  - United States
TA  - Clin Imaging
JT  - Clinical imaging
JID - 8911831
SB  - IM
MH  - Humans
MH  - United States
MH  - *Language
MH  - *Radiology
OTO - NOTNLM
OT  - ChatGPT
OT  - Health equity
OT  - Implicit bias
OT  - Large language models
OT  - Radiology report
COIS- Declaration of competing interest None.
EDAT- 2024/03/30 11:45
MHDA- 2024/04/17 06:42
CRDT- 2024/03/29 19:08
PHST- 2023/11/03 00:00 [received]
PHST- 2024/02/15 00:00 [revised]
PHST- 2024/02/24 00:00 [accepted]
PHST- 2024/04/17 06:42 [medline]
PHST- 2024/03/30 11:45 [pubmed]
PHST- 2024/03/29 19:08 [entrez]
AID - S0899-7071(24)00043-3 [pii]
AID - 10.1016/j.clinimag.2024.110113 [doi]
PST - ppublish
SO  - Clin Imaging. 2024 May;109:110113. doi: 10.1016/j.clinimag.2024.110113. Epub 2024 
      Mar 2.

PMID- 38065720
OWN - NLM
STAT- MEDLINE
DCOM- 20240301
LR  - 20250203
IS  - 1879-1883 (Electronic)
IS  - 0002-9610 (Linking)
VI  - 229
DP  - 2024 Mar
TI  - Decoding medical school narrative evaluations: Is natural language processing an 
      antidote to the leniency bias?
PG  - 191-192
LID - S0002-9610(23)00633-5 [pii]
LID - 10.1016/j.amjsurg.2023.11.028 [doi]
AB  - Observational assessments in the clinical context are a cornerstone of evaluation 
      in medical education. Leniency bias, described in performance management in the 
      business arena appears to widely impact these assessments with medical training. 
      Natural language processing provides a potential tool that medical educators may 
      leverage to decipher underlying meaning in narrative assessment. A 
      "proof-of-concept" study at the Cumming School of Medicine supports this notion 
      and suggests further work would be a worthwhile pursuit in this field.
CI  - Copyright © 2023 Elsevier Inc. All rights reserved.
FAU - Harvey, Adrian
AU  - Harvey A
AD  - Departments of Surgery & Oncology, Cumming School of Medicine, University of 
      Calgary, Canada. Electronic address: adrian.harvey@albertahealthservices.ca.
LA  - eng
PT  - Editorial
DEP - 20231201
PL  - United States
TA  - Am J Surg
JT  - American journal of surgery
JID - 0370473
RN  - 0 (Antidotes)
SB  - IM
MH  - Humans
MH  - *Antidotes
MH  - Schools, Medical
MH  - Natural Language Processing
MH  - Narration
MH  - *Education, Medical
COIS- Declaration of competing interest I have no disclosures, financial, personal or 
      otherwise that would serve to bias my submitted work.
EDAT- 2023/12/09 05:43
MHDA- 2024/03/01 06:43
CRDT- 2023/12/08 21:57
PHST- 2023/10/26 00:00 [received]
PHST- 2023/11/19 00:00 [revised]
PHST- 2023/11/24 00:00 [accepted]
PHST- 2024/03/01 06:43 [medline]
PHST- 2023/12/09 05:43 [pubmed]
PHST- 2023/12/08 21:57 [entrez]
AID - S0002-9610(23)00633-5 [pii]
AID - 10.1016/j.amjsurg.2023.11.028 [doi]
PST - ppublish
SO  - Am J Surg. 2024 Mar;229:191-192. doi: 10.1016/j.amjsurg.2023.11.028. Epub 2023 
      Dec 1.

PMID- 39232225
OWN - NLM
STAT- Publisher
LR  - 20240904
IS  - 1476-4687 (Electronic)
IS  - 0028-0836 (Linking)
DP  - 2024 Sep 4
TI  - Why I'm committed to breaking the bias in large language models.
LID - 10.1038/d41586-024-02839-y [doi]
FAU - Rajaratnam, Vaikunthan
AU  - Rajaratnam V
LA  - eng
PT  - News
DEP - 20240904
PL  - England
TA  - Nature
JT  - Nature
JID - 0410462
SB  - IM
OTO - NOTNLM
OT  - Ethics
OT  - Health care
OT  - Machine learning
OT  - Research management
EDAT- 2024/09/05 00:49
MHDA- 2024/09/05 00:49
CRDT- 2024/09/04 23:41
PHST- 2024/09/05 00:49 [medline]
PHST- 2024/09/05 00:49 [pubmed]
PHST- 2024/09/04 23:41 [entrez]
AID - 10.1038/d41586-024-02839-y [pii]
AID - 10.1038/d41586-024-02839-y [doi]
PST - aheadofprint
SO  - Nature. 2024 Sep 4. doi: 10.1038/d41586-024-02839-y.

PMID- 38460841
OWN - NLM
STAT- MEDLINE
DCOM- 20240610
LR  - 20241127
IS  - 1532-429X (Electronic)
IS  - 1097-6647 (Print)
IS  - 1097-6647 (Linking)
VI  - 26
IP  - 1
DP  - 2024 Summer
TI  - Generative Pre-trained Transformer 4 makes cardiovascular magnetic resonance 
      reports easy to understand.
PG  - 101035
LID - S1097-6647(24)01026-3 [pii]
LID - 10.1016/j.jocmr.2024.101035 [doi]
LID - 101035
AB  - BACKGROUND: Patients are increasingly using Generative Pre-trained Transformer 4 
      (GPT-4) to better understand their own radiology findings. PURPOSE: To evaluate 
      the performance of GPT-4 in transforming cardiovascular magnetic resonance (CMR) 
      reports into text that is comprehensible to medical laypersons. METHODS: ChatGPT 
      with GPT-4 architecture was used to generate three different explained versions 
      of 20 various CMR reports (n = 60) using the same prompt: "Explain the radiology 
      report in a language understandable to a medical layperson". Two cardiovascular 
      radiologists evaluated understandability, factual correctness, completeness of 
      relevant findings, and lack of potential harm, while 13 medical laypersons 
      evaluated the understandability of the original and the GPT-4 reports on a Likert 
      scale (1 "strongly disagree", 5 "strongly agree"). Readability was measured using 
      the Automated Readability Index (ARI). Linear mixed-effects models (values given 
      as median [interquartile range]) and intraclass correlation coefficient (ICC) 
      were used for statistical analysis. RESULTS: GPT-4 reports were generated on 
      average in 52 s ± 13. GPT-4 reports achieved a lower ARI score (10 [9-12] vs 5 
      [4-6]; p < 0.001) and were subjectively easier to understand for laypersons than 
      original reports (1 [1] vs 4 [4,5]; p < 0.001). Eighteen out of 20 (90%) standard 
      CMR reports and 2/60 (3%) GPT-generated reports had an ARI score corresponding to 
      the 8th grade level or higher. Radiologists' ratings of the GPT-4 reports reached 
      high levels for correctness (5 [4, 5]), completeness (5 [5]), and lack of 
      potential harm (5 [5]); with "strong agreement" for factual correctness in 94% 
      (113/120) and completeness of relevant findings in 81% (97/120) of reports. 
      Test-retest agreement for layperson understandability ratings between the three 
      simplified reports generated from the same original report was substantial (ICC: 
      0.62; p < 0.001). Interrater agreement between radiologists was almost perfect 
      for lack of potential harm (ICC: 0.93, p < 0.001) and moderate to substantial for 
      completeness (ICC: 0.76, p < 0.001) and factual correctness (ICC: 0.55, 
      p < 0.001). CONCLUSION: GPT-4 can reliably transform complex CMR reports into 
      more understandable, layperson-friendly language while largely maintaining 
      factual correctness and completeness, and can thus help convey patient-relevant 
      radiology information in an easy-to-understand manner.
CI  - Copyright © 2024 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Salam, Babak
AU  - Salam B
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Kravchenko, Dmitrij
AU  - Kravchenko D
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Nowak, Sebastian
AU  - Nowak S
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Sprinkart, Alois M
AU  - Sprinkart AM
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Weinhold, Leonie
AU  - Weinhold L
AD  - University Hospital Bonn, Department of Medical Biometry, Informatics, and 
      Epidemiology, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Odenthal, Anna
AU  - Odenthal A
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Mesropyan, Narine
AU  - Mesropyan N
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Bischoff, Leon M
AU  - Bischoff LM
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Attenberger, Ulrike
AU  - Attenberger U
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Kuetting, Daniel L
AU  - Kuetting DL
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Luetkens, Julian A
AU  - Luetkens JA
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany.
FAU - Isaak, Alexander
AU  - Isaak A
AD  - Department of Diagnostic and Interventional Radiology, University Hospital Bonn, 
      Venusberg-Campus 1, 53127 Bonn, Germany; Quantitative Imaging Lab Bonn (QILaB), 
      University Hospital Bonn, Venusberg-Campus 1, 53127 Bonn, Germany. Electronic 
      address: alexander.isaak@ukbonn.de.
LA  - eng
PT  - Evaluation Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240307
PL  - England
TA  - J Cardiovasc Magn Reson
JT  - Journal of cardiovascular magnetic resonance : official journal of the Society 
      for Cardiovascular Magnetic Resonance
JID - 9815616
SB  - IM
MH  - Humans
MH  - *Predictive Value of Tests
MH  - *Comprehension
MH  - *Magnetic Resonance Imaging
MH  - Reproducibility of Results
MH  - Observer Variation
MH  - Health Literacy
MH  - Patient Education as Topic
MH  - Cardiovascular Diseases/diagnostic imaging
MH  - Female
MH  - Male
PMC - PMC10981113
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cardiovascular magnetic resonance
OT  - Generative Pre-trained Transformers
OT  - Large language models
OT  - Text simplification
COIS- Declaration of competing interests The authors declare the following financial 
      interests/personal relationships which may be considered as potential competing 
      interests: Alexander Isaak reports financial support was provided by BONFOR 
      Research Commission of the Medical Faculty Bonn. The other authors declare that 
      they have no known competing financial interests or personal relationships that 
      could have appeared to influence the work reported in this paper.
EDAT- 2024/03/10 00:42
MHDA- 2024/06/11 00:42
PMCR- 2024/03/07
CRDT- 2024/03/09 19:19
PHST- 2023/11/24 00:00 [received]
PHST- 2024/02/19 00:00 [revised]
PHST- 2024/03/05 00:00 [accepted]
PHST- 2024/06/11 00:42 [medline]
PHST- 2024/03/10 00:42 [pubmed]
PHST- 2024/03/09 19:19 [entrez]
PHST- 2024/03/07 00:00 [pmc-release]
AID - S1097-6647(24)01026-3 [pii]
AID - 101035 [pii]
AID - 10.1016/j.jocmr.2024.101035 [doi]
PST - ppublish
SO  - J Cardiovasc Magn Reson. 2024 Summer;26(1):101035. doi: 
      10.1016/j.jocmr.2024.101035. Epub 2024 Mar 7.

PMID- 38645190
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241119
DP  - 2024 Sep 16
TI  - Simulated Misuse of Large Language Models and Clinical Credit Systems.
LID - 2024.04.10.24305470 [pii]
LID - 10.1101/2024.04.10.24305470 [doi]
AB  - Large language models (LLMs) have been proposed to support many healthcare tasks, 
      including disease diagnostics and treatment personalization. While AI may be 
      applied to assist or enhance the delivery of healthcare, there is also a risk of 
      misuse. LLMs could be used to allocate resources via unfair, unjust, or 
      inaccurate criteria. For example, a social credit system uses big data to assess 
      "trustworthiness" in society, penalizing those who score poorly based on 
      evaluation metrics defined only by a power structure (e.g., a corporate entity or 
      governing body). Such a system may be amplified by powerful LLMs which can 
      evaluate individuals based on multimodal data - financial transactions, internet 
      activity, and other behavioral inputs. Healthcare data is perhaps the most 
      sensitive information which can be collected and could potentially be used to 
      violate civil liberty or other rights via a "clinical credit system", which may 
      include limiting access to care. The results of this study show that LLMs may be 
      biased in favor of collective or systemic benefit over protecting individual 
      rights, potentially enabling this type of future misuse. Moreover, experiments in 
      this report simulate how clinical datasets might be exploited with current LLMs, 
      demonstrating the urgency of addressing these ethical dangers. Finally, 
      strategies are proposed to mitigate the risk of developing large AI models for 
      healthcare.
FAU - Anibal, James
AU  - Anibal J
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health (NIH), Bethesda, Maryland, USA.
FAU - Huth, Hannah
AU  - Huth H
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health (NIH), Bethesda, Maryland, USA.
FAU - Gunkel, Jasmine
AU  - Gunkel J
AD  - Department of Bioethics, National Institutes of Health (NIH), Bethesda, Maryland, 
      USA.
FAU - Gregurick, Susan
AU  - Gregurick S
AD  - Office of the Director, National Institutes of Health (NIH), Bethesda, Maryland, 
      USA.
FAU - Wood, Bradford
AU  - Wood B
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health (NIH), Bethesda, Maryland, USA.
LA  - eng
GR  - ZIA CL040015/ImNIH/Intramural NIH HHS/United States
GR  - ZID BC011242/ImNIH/Intramural NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240916
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - NPJ Digit Med. 2024 Nov 11;7(1):317. doi: 10.1038/s41746-024-01306-2. PMID: 
      39528596
PMC - PMC11030492
COIS- Disclosures / Conflicts of Interest: The content of this manuscript does not 
      necessarily reflect the views, policies, or opinions of the National Institutes 
      of Health (NIH), the U.S. Government, nor the U.S. Department of Health and Human 
      Services. The mention of commercial products, their source, or their use in 
      connection with material reported herein is not to be construed as an actual or 
      implied endorsement by the U.S. government nor the NIH.
EDAT- 2024/04/22 06:43
MHDA- 2024/04/22 06:44
PMCR- 2024/09/25
CRDT- 2024/04/22 03:59
PHST- 2024/04/22 06:43 [pubmed]
PHST- 2024/04/22 06:44 [medline]
PHST- 2024/04/22 03:59 [entrez]
PHST- 2024/09/25 00:00 [pmc-release]
AID - 2024.04.10.24305470 [pii]
AID - 10.1101/2024.04.10.24305470 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Sep 16:2024.04.10.24305470. doi: 
      10.1101/2024.04.10.24305470.

PMID- 38527823
OWN - NLM
STAT- MEDLINE
DCOM- 20240327
LR  - 20240714
IS  - 1544-1717 (Electronic)
IS  - 1544-1709 (Print)
IS  - 1544-1709 (Linking)
VI  - 22
IP  - 2
DP  - 2024 Mar-Apr
TI  - Quality, Accuracy, and Bias in ChatGPT-Based Summarization of Medical Abstracts.
PG  - 113-120
LID - 10.1370/afm.3075 [doi]
AB  - PURPOSE: Worldwide clinical knowledge is expanding rapidly, but physicians have 
      sparse time to review scientific literature. Large language models (eg, Chat 
      Generative Pretrained Transformer [ChatGPT]), might help summarize and prioritize 
      research articles to review. However, large language models sometimes 
      "hallucinate" incorrect information. METHODS: We evaluated ChatGPT's ability to 
      summarize 140 peer-reviewed abstracts from 14 journals. Physicians rated the 
      quality, accuracy, and bias of the ChatGPT summaries. We also compared human 
      ratings of relevance to various areas of medicine to ChatGPT relevance ratings. 
      RESULTS: ChatGPT produced summaries that were 70% shorter (mean abstract length 
      of 2,438 characters decreased to 739 characters). Summaries were nevertheless 
      rated as high quality (median score 90, interquartile range [IQR] 87.0-92.5; 
      scale 0-100), high accuracy (median 92.5, IQR 89.0-95.0), and low bias (median 0, 
      IQR 0-7.5). Serious inaccuracies and hallucinations were uncommon. Classification 
      of the relevance of entire journals to various fields of medicine closely 
      mirrored physician classifications (nonlinear standard error of the regression 
      [SER] 8.6 on a scale of 0-100). However, relevance classification for individual 
      articles was much more modest (SER 22.3). CONCLUSIONS: Summaries generated by 
      ChatGPT were 70% shorter than mean abstract length and were characterized by high 
      quality, high accuracy, and low bias. Conversely, ChatGPT had modest ability to 
      classify the relevance of articles to medical specialties. We suggest that 
      ChatGPT can help family physicians accelerate review of the scientific literature 
      and have developed software (pyJournalWatch) to support this application. 
      Life-critical medical decisions should remain based on full, critical, and 
      thoughtful evaluation of the full text of research articles in context with 
      clinical guidelines.
CI  - © 2024 Annals of Family Medicine, Inc.
FAU - Hake, Joel
AU  - Hake J
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Crowley, Miles
AU  - Crowley M
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Coy, Allison
AU  - Coy A
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Shanks, Denton
AU  - Shanks D
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Eoff, Aundria
AU  - Eoff A
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Kirmer-Voss, Kalee
AU  - Kirmer-Voss K
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Dhanda, Gurpreet
AU  - Dhanda G
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas.
FAU - Parente, Daniel J
AU  - Parente DJ
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, Kansas dparente@kumc.edu.
LA  - eng
GR  - UL1 TR002366/TR/NCATS NIH HHS/United States
PT  - Journal Article
PL  - United States
TA  - Ann Fam Med
JT  - Annals of family medicine
JID - 101167762
SB  - IM
MH  - Humans
MH  - *Medicine
MH  - Physicians, Family
PMC - PMC11237196
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - bias
OT  - critical assessment of scientific literature
OT  - large language models
OT  - primary care research
OT  - text analysis
OT  - text mining
EDAT- 2024/03/26 00:42
MHDA- 2024/03/27 06:44
PMCR- 2024/03/01
CRDT- 2024/03/25 21:23
PHST- 2023/04/21 00:00 [received]
PHST- 2023/10/13 00:00 [revised]
PHST- 2023/11/17 00:00 [accepted]
PHST- 2024/03/27 06:44 [medline]
PHST- 2024/03/26 00:42 [pubmed]
PHST- 2024/03/25 21:23 [entrez]
PHST- 2024/03/01 00:00 [pmc-release]
AID - 22/2/113 [pii]
AID - 10.1370/afm.3075 [doi]
PST - ppublish
SO  - Ann Fam Med. 2024 Mar-Apr;22(2):113-120. doi: 10.1370/afm.3075.

PMID- 39588809
OWN - NLM
STAT- MEDLINE
DCOM- 20241231
LR  - 20250104
IS  - 1533-2500 (Electronic)
IS  - 1530-7085 (Print)
IS  - 1530-7085 (Linking)
VI  - 25
IP  - 1
DP  - 2025 Jan
TI  - Artificial intelligence and pain medicine education: Benefits and pitfalls for 
      the medical trainee.
PG  - e13428
LID - 10.1111/papr.13428 [doi]
LID - e13428
AB  - OBJECTIVES: Artificial intelligence (AI) represents an exciting and evolving 
      technology that is increasingly being utilized across pain medicine. Large 
      language models (LLMs) are one type of AI that has become particularly popular. 
      Currently, there is a paucity of literature analyzing the impact that AI may have 
      on trainee education. As such, we sought to assess the benefits and pitfalls that 
      AI may have on pain medicine trainee education. Given the rapidly increasing 
      popularity of LLMs, we particularly assessed how these LLMs may promote and 
      hinder trainee education through a pilot quality improvement project. MATERIALS 
      AND METHODS: A comprehensive search of the existing literature regarding AI 
      within medicine was performed to identify its potential benefits and pitfalls 
      within pain medicine. The pilot project was approved by UPMC Quality Improvement 
      Review Committee (#4547). Three of the most commonly utilized LLMs at the 
      initiation of this pilot study - ChatGPT Plus, Google Bard, and Bing AI - were 
      asked a series of multiple choice questions to evaluate their ability to assist 
      in learner education within pain medicine. RESULTS: Potential benefits of AI 
      within pain medicine trainee education include ease of use, imaging 
      interpretation, procedural/surgical skills training, learner assessment, 
      personalized learning experiences, ability to summarize vast amounts of 
      knowledge, and preparation for the future of pain medicine. Potential pitfalls 
      include discrepancies between AI devices and associated cost-differences, 
      correlating radiographic findings to clinical significance, 
      interpersonal/communication skills, educational disparities, 
      bias/plagiarism/cheating concerns, lack of incorporation of private domain 
      literature, and absence of training specifically for pain medicine education. 
      Regarding the quality improvement project, ChatGPT Plus answered the highest 
      percentage of all questions correctly (16/17). Lowest correctness scores by LLMs 
      were in answering first-order questions, with Google Bard and Bing AI answering 
      4/9 and 3/9 first-order questions correctly, respectively. Qualitative evaluation 
      of these LLM-provided explanations in answering second- and third-order questions 
      revealed some reasoning inconsistencies (e.g., providing flawed information in 
      selecting the correct answer). CONCLUSIONS: AI represents a continually evolving 
      and promising modality to assist trainees pursuing a career in pain medicine. 
      Still, limitations currently exist that may hinder their independent use in this 
      setting. Future research exploring how AI may overcome these challenges is thus 
      required. Until then, AI should be utilized as supplementary tool within pain 
      medicine trainee education and with caution.
CI  - © 2024 The Author(s). Pain Practice published by Wiley Periodicals LLC on behalf 
      of World Institute of Pain.
FAU - Glicksman, Michael
AU  - Glicksman M
AUID- ORCID: 0000-0002-4882-6851
AD  - Department of Physical Medicine and Rehabilitation, University of Pittsburgh 
      Medical Center (UPMC), Pittsburgh, Pennsylvania, USA.
FAU - Wang, Sheri
AU  - Wang S
AD  - Department of Anesthesiology and Perioperative Medicine, University of Pittsburgh 
      Medical Center (UPMC), Pittsburgh, Pennsylvania, USA.
FAU - Yellapragada, Samir
AU  - Yellapragada S
AD  - University of Pittsburgh School of Medicine, Pittsburgh, Pennsylvania, USA.
FAU - Robinson, Christopher
AU  - Robinson C
AUID- ORCID: 0000-0002-6276-9056
AD  - Department of Anesthesiology, Perioperative, and Pain Medicine, Harvard Medical 
      School, Brigham and Women's Hospital, Boston, Massachusetts, USA.
FAU - Orhurhu, Vwaire
AU  - Orhurhu V
AD  - University of Pittsburgh Medical Center (UPMC), Susquehanna, Williamsport, 
      Pennsylvania, USA.
AD  - MVM Health, East Stroudsburg, Pennsylvania, USA.
FAU - Emerick, Trent
AU  - Emerick T
AUID- ORCID: 0000-0002-3802-5946
AD  - Department of Anesthesiology and Perioperative Medicine, Chronic Pain Division, 
      University of Pittsburgh Medical Center (UPMC), Pittsburgh, Pennsylvania, USA.
LA  - eng
PT  - Journal Article
DEP - 20241126
PL  - United States
TA  - Pain Pract
JT  - Pain practice : the official journal of World Institute of Pain
JID - 101130835
SB  - IM
MH  - *Artificial Intelligence
MH  - Humans
MH  - Pilot Projects
MH  - *Pain Management/methods
MH  - Clinical Competence/standards
MH  - Education, Medical/methods
PMC - PMC11683517
OTO - NOTNLM
OT  - pain
OT  - pain assessment
COIS- Trent Emerick holds stock/equity at Vanish Therapeutics, Inc. Michael Glicksman, 
      Sheri Wang, Samir Yellapragada, Christopher Robinson, and Vwaire Orhurhu report 
      no conflicts of interest.
EDAT- 2024/11/26 12:30
MHDA- 2024/12/31 12:21
PMCR- 2024/12/30
CRDT- 2024/11/26 06:43
PHST- 2024/12/31 12:21 [medline]
PHST- 2024/11/26 12:30 [pubmed]
PHST- 2024/11/26 06:43 [entrez]
PHST- 2024/12/30 00:00 [pmc-release]
AID - PAPR13428 [pii]
AID - 10.1111/papr.13428 [doi]
PST - ppublish
SO  - Pain Pract. 2025 Jan;25(1):e13428. doi: 10.1111/papr.13428. Epub 2024 Nov 26.

PMID- 40055532
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250312
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 8
IP  - 1
DP  - 2025 Mar 7
TI  - Red teaming ChatGPT in medicine to yield real-world insights on model behavior.
PG  - 149
LID - 10.1038/s41746-025-01542-0 [doi]
LID - 149
AB  - Red teaming, the practice of adversarially exposing unexpected or undesired model 
      behaviors, is critical towards improving equity and accuracy of large language 
      models, but non-model creator-affiliated red teaming is scant in healthcare. We 
      convened teams of clinicians, medical and engineering students, and technical 
      professionals (80 participants total) to stress-test models with real-world 
      clinical cases and categorize inappropriate responses along axes of safety, 
      privacy, hallucinations/accuracy, and bias. Six medically-trained reviewers 
      re-analyzed prompt-response pairs and added qualitative annotations. Of 376 
      unique prompts (1504 responses), 20.1% were inappropriate (GPT-3.5: 25.8%; 
      GPT-4.0: 16%; GPT-4.0 with Internet: 17.8%). Subsequently, we show the utility of 
      our benchmark by testing GPT-4o, a model released after our event (20.4% 
      inappropriate). 21.5% of responses appropriate with GPT-3.5 were inappropriate in 
      updated models. We share insights for constructing red teaming prompts, and 
      present our benchmark for iterative model assessments.
CI  - © 2025. The Author(s).
FAU - Chang, Crystal T
AU  - Chang CT
AUID- ORCID: 0000-0002-0647-7040
AD  - Department of Dermatology, Stanford University, Stanford, USA.
AD  - Clinical Excellence Research Center, School of Medicine, Stanford University, 
      Palo Alto, CA, USA.
FAU - Farah, Hodan
AU  - Farah H
AD  - Department of Dermatology, Stanford University, Stanford, USA.
FAU - Gui, Haiwen
AU  - Gui H
AUID- ORCID: 0000-0003-0564-940X
AD  - Department of Dermatology, Stanford University, Stanford, USA.
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Rezaei, Shawheen Justin
AU  - Rezaei SJ
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Bou-Khalil, Charbel
AU  - Bou-Khalil C
AUID- ORCID: 0000-0002-5497-9037
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Park, Ye-Jean
AU  - Park YJ
AD  - Temerty Faculty of Medicine, Toronto, ON, Canada.
FAU - Swaminathan, Akshay
AU  - Swaminathan A
AUID- ORCID: 0000-0003-3426-9289
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Omiye, Jesutofunmi A
AU  - Omiye JA
AD  - Department of Dermatology, Stanford University, Stanford, USA.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Kolluri, Akaash
AU  - Kolluri A
AD  - Stanford University, Stanford, CA, USA.
FAU - Chaurasia, Akash
AU  - Chaurasia A
AUID- ORCID: 0000-0003-3438-3313
AD  - Department of Computer Science, Stanford University, Stanford, CA, USA.
AD  - Center for Biomedical Informatics Research, Stanford University, Stanford, CA, 
      USA.
FAU - Lozano, Alejandro
AU  - Lozano A
AUID- ORCID: 0000-0002-6952-289X
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Heiman, Alice
AU  - Heiman A
AD  - Stanford University, Stanford, CA, USA.
FAU - Jia, Allison Sihan
AU  - Jia AS
AD  - Stanford University, Stanford, CA, USA.
FAU - Kaushal, Amit
AU  - Kaushal A
AD  - Department of Bioengineering, Stanford University, Stanford, CA, USA.
FAU - Jia, Angela
AU  - Jia A
AD  - Stanford University, Stanford, CA, USA.
FAU - Iacovelli, Angelica
AU  - Iacovelli A
AUID- ORCID: 0009-0004-1327-2184
AD  - Department of Pediatrics, Stanford University, Stanford, CA, USA.
FAU - Yang, Archer
AU  - Yang A
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
AD  - Department of Mathematics and Statistics, McGill University, Montreal, QC, 
      Canada.
FAU - Salles, Arghavan
AU  - Salles A
AD  - Stanford University, Stanford, CA, USA.
FAU - Singhal, Arpita
AU  - Singhal A
AD  - Department of Computer Science, Stanford University, Stanford, CA, USA.
FAU - Narasimhan, Balasubramanian
AU  - Narasimhan B
AD  - Stanford University, Stanford, CA, USA.
FAU - Belai, Benjamin
AU  - Belai B
AD  - Department of Psychiatry, Stanford University, Stanford, CA, USA.
FAU - Jacobson, Benjamin H
AU  - Jacobson BH
AUID- ORCID: 0000-0002-5550-3559
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Li, Binglan
AU  - Li B
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Poe, Celeste H
AU  - Poe CH
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Sanghera, Chandan
AU  - Sanghera C
AD  - Stanford University, Stanford, CA, USA.
FAU - Zheng, Chenming
AU  - Zheng C
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Messer, Conor
AU  - Messer C
AD  - Stanford University, Stanford, CA, USA.
FAU - Kettud, Damien Varid
AU  - Kettud DV
AD  - Stanford University, Stanford, CA, USA.
FAU - Pandya, Deven
AU  - Pandya D
AD  - Stanford University, Stanford, CA, USA.
FAU - Kaur, Dhamanpreet
AU  - Kaur D
AUID- ORCID: 0000-0001-6123-7499
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Hla, Diana
AU  - Hla D
AD  - Mayo Clinic Alix School of Medicine, Rochester, NY, USA.
FAU - Dindoust, Diba
AU  - Dindoust D
AD  - Stanford University, Stanford, CA, USA.
FAU - Moehrle, Dominik
AU  - Moehrle D
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Ross, Duncan
AU  - Ross D
AD  - Department of Statistics, Stanford University, Stanford, CA, USA.
FAU - Chou, Ellaine
AU  - Chou E
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Lin, Eric
AU  - Lin E
AD  - Veterans Affairs Medical Center, Palo Alto, CA, USA.
FAU - Haredasht, Fateme Nateghi
AU  - Haredasht FN
AD  - Center for Biomedical Informatics Research, Stanford University, Stanford, CA, 
      USA.
FAU - Cheng, Ge
AU  - Cheng G
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Gao, Irena
AU  - Gao I
AD  - Stanford University, Stanford, CA, USA.
FAU - Chang, Jacob
AU  - Chang J
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Silberg, Jake
AU  - Silberg J
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Fries, Jason A
AU  - Fries JA
AUID- ORCID: 0000-0001-9316-5768
AD  - Center for Biomedical Informatics Research, Stanford University, Stanford, CA, 
      USA.
FAU - Xu, Jiapeng
AU  - Xu J
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Jamison, Joe
AU  - Jamison J
AD  - Department of Statistics, Stanford University, Stanford, CA, USA.
FAU - Tamaresis, John S
AU  - Tamaresis JS
AUID- ORCID: 0000-0002-9868-2366
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Chen, Jonathan H
AU  - Chen JH
AUID- ORCID: 0000-0002-4387-8740
AD  - Clinical Excellence Research Center, School of Medicine, Stanford University, 
      Palo Alto, CA, USA.
AD  - Center for Biomedical Informatics Research, Stanford University, Stanford, CA, 
      USA.
AD  - Department of Medicine, Stanford University, Stanford, CA, USA.
FAU - Lazaro, Joshua
AU  - Lazaro J
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Banda, Juan M
AU  - Banda JM
AD  - Technology and Digital Solutions, Stanford Health Care, Palo Alto, CA, USA.
FAU - Lee, Julie J
AU  - Lee JJ
AD  - Department of Pediatrics, Stanford University, Stanford, CA, USA.
FAU - Matthys, Karen Ebert
AU  - Matthys KE
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Steffner, Kirsten R
AU  - Steffner KR
AUID- ORCID: 0000-0001-9759-616X
AD  - Department of Anesthesiology, Stanford University, Stanford, CA, USA.
FAU - Tian, Lu
AU  - Tian L
AD  - Stanford University, Stanford, CA, USA.
FAU - Pegolotti, Luca
AU  - Pegolotti L
AD  - Department of Pediatrics, Stanford University, Stanford, CA, USA.
FAU - Srinivasan, Malathi
AU  - Srinivasan M
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Manimaran, Maniragav
AU  - Manimaran M
AD  - Graduate School of Business, Stanford University, Stanford, CA, USA.
FAU - Schwede, Matthew
AU  - Schwede M
AD  - Department of Medicine, Stanford University, Stanford, CA, USA.
FAU - Zhang, Minghe
AU  - Zhang M
AD  - Department of Statistics, Stanford University, Stanford, CA, USA.
FAU - Nguyen, Minh
AU  - Nguyen M
AUID- ORCID: 0000-0001-7149-849X
AD  - Stanford University, Stanford, CA, USA.
FAU - Fathzadeh, Mohsen
AU  - Fathzadeh M
AUID- ORCID: 0000-0002-7962-9148
AD  - Department of Epidemiology and Population Health, Stanford University, Stanford, 
      CA, USA.
FAU - Zhao, Qian
AU  - Zhao Q
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Bajra, Rika
AU  - Bajra R
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
FAU - Khurana, Rohit
AU  - Khurana R
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Azam, Ruhana
AU  - Azam R
AD  - Stanford University, Stanford, CA, USA.
FAU - Bartlett, Rush
AU  - Bartlett R
AD  - Stanford BioDesign, Stanford University, Stanford, CA, USA.
FAU - Truong, Sang T
AU  - Truong ST
AD  - Department of Computer Science, Stanford University, Stanford, CA, USA.
FAU - Fleming, Scott L
AU  - Fleming SL
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Raj, Shriti
AU  - Raj S
AD  - Center for Biomedical Informatics Research, Stanford University, Stanford, CA, 
      USA.
FAU - Behr, Solveig
AU  - Behr S
AD  - Department of Education and Psychology, Freie Universität Berlin, Berlin, 
      Germany.
FAU - Onyeka, Sonia
AU  - Onyeka S
AD  - Department of Dermatology, Stanford University, Stanford, USA.
FAU - Muppidi, Sri
AU  - Muppidi S
AD  - Stanford University, Stanford, CA, USA.
FAU - Bandali, Tarek
AU  - Bandali T
AD  - Stanford University, Stanford, CA, USA.
FAU - Eulalio, Tiffany Y
AU  - Eulalio TY
AUID- ORCID: 0000-0002-7084-9646
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Chen, Wenyuan
AU  - Chen W
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Zhou, Xuanyu
AU  - Zhou X
AD  - Department of Epidemiology and Population Health, Stanford University, Stanford, 
      CA, USA.
FAU - Ding, Yanan
AU  - Ding Y
AUID- ORCID: 0009-0002-8967-2139
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
AD  - Department of Genetics, Stanford School of Medicine, Stanford, CA, USA.
AD  - Department of Clinical and Translational Science, Harvard Medical School, Boston, 
      MA, USA.
FAU - Cui, Ying
AU  - Cui Y
AUID- ORCID: 0000-0002-3697-5155
AD  - Stanford University, Stanford, CA, USA.
FAU - Tan, Yuqi
AU  - Tan Y
AUID- ORCID: 0000-0002-7200-3222
AD  - Department of Pathology, Stanford University, Stanford, CA, USA.
FAU - Liu, Yutong
AU  - Liu Y
AUID- ORCID: 0009-0003-6695-8991
AD  - Department of Epidemiology and Population Health, Stanford University, Stanford, 
      CA, USA.
FAU - Shah, Nigam
AU  - Shah N
AUID- ORCID: 0000-0001-9385-7158
AD  - School of Medicine, Stanford University, Stanford, CA, USA.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, USA.
FAU - Daneshjou, Roxana
AU  - Daneshjou R
AUID- ORCID: 0000-0001-7988-9356
AD  - Department of Dermatology, Stanford University, Stanford, USA. 
      roxanad@stanford.edu.
AD  - School of Medicine, Stanford University, Stanford, CA, USA. roxanad@stanford.edu.
LA  - eng
PT  - Journal Article
DEP - 20250307
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC11889229
COIS- Competing interests: RD has served as an advisor to MDAlgorithms and Revea and 
      received. consulting fees from Pfizer, L’Oreal, Frazier Healthcare Partners, and 
      DWA, and research funding from UCB and declares no non-financial competing 
      interests. All other authors declare no financial or non-financial competing 
      interests.
EDAT- 2025/03/09 15:11
MHDA- 2025/03/09 15:12
PMCR- 2025/03/07
CRDT- 2025/03/07 23:39
PHST- 2024/05/16 00:00 [received]
PHST- 2025/02/26 00:00 [accepted]
PHST- 2025/03/09 15:12 [medline]
PHST- 2025/03/09 15:11 [pubmed]
PHST- 2025/03/07 23:39 [entrez]
PHST- 2025/03/07 00:00 [pmc-release]
AID - 10.1038/s41746-025-01542-0 [pii]
AID - 1542 [pii]
AID - 10.1038/s41746-025-01542-0 [doi]
PST - epublish
SO  - NPJ Digit Med. 2025 Mar 7;8(1):149. doi: 10.1038/s41746-025-01542-0.

PMID- 39715539
OWN - NLM
STAT- In-Process
LR  - 20250109
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Dec 23
TI  - Authors' Reply: Reassessing AI in Medicine: Exploring the Capabilities of AI in 
      Academic Abstract Synthesis.
PG  - e65123
LID - 10.2196/65123 [doi]
LID - e65123
FAU - Hsu, Tien-Wei
AU  - Hsu TW
AUID- ORCID: 0000-0003-4136-1251
AD  - Department of Psychiatry, E-Da Dachang Hospital, I-Shou University, Kaohsiung, 
      Taiwan.
AD  - Department of Psychiatry, E-Da Hospital, I-Shou University, Kaohsiung, Taiwan.
FAU - Liang, Chih-Sung
AU  - Liang CS
AUID- ORCID: 0000-0003-1138-5586
AD  - Department of Psychiatry, Tri-service Hospital, Beitou Branch, Taipei, Taiwan.
AD  - Department of Psychiatry, National Defense Medical Center, Taipei, Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20241223
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
CON - J Med Internet Res. 26:e55920.
CON - J Med Internet Res. 25:e51229.
PMC - PMC11704654
OTO - NOTNLM
OT  - AI
OT  - AI-generated scientific content
OT  - ChatGPT
OT  - LLM
OT  - NLP
OT  - abstract
OT  - academic research
OT  - artificial intelligence
OT  - comparative analysis
OT  - extract
OT  - extraction
OT  - generation
OT  - generative
OT  - language model
OT  - natural language processing
OT  - plagiarism
OT  - publication
OT  - reviewer bias
OT  - scientific research
OT  - text
OT  - textual
COIS- Conflicts of Interest: None declared.
EDAT- 2024/12/23 22:58
MHDA- 2024/12/23 22:58
PMCR- 2024/12/23
CRDT- 2024/12/23 16:53
PHST- 2024/08/05 00:00 [received]
PHST- 2024/09/27 00:00 [accepted]
PHST- 2024/09/13 00:00 [revised]
PHST- 2024/12/23 22:58 [medline]
PHST- 2024/12/23 22:58 [pubmed]
PHST- 2024/12/23 16:53 [entrez]
PHST- 2024/12/23 00:00 [pmc-release]
AID - v26i1e65123 [pii]
AID - 10.2196/65123 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Dec 23;26:e65123. doi: 10.2196/65123.

PMID- 37392712
OWN - NLM
STAT- MEDLINE
DCOM- 20230814
LR  - 20241106
IS  - 1872-8243 (Electronic)
IS  - 1386-5056 (Print)
IS  - 1386-5056 (Linking)
VI  - 177
DP  - 2023 Sep
TI  - Leveraging natural language processing to identify eligible lung cancer screening 
      patients with the electronic health record.
PG  - 105136
LID - S1386-5056(23)00154-5 [pii]
LID - 10.1016/j.ijmedinf.2023.105136 [doi]
AB  - OBJECTIVE: To develop and validate an approach that identifies patients eligible 
      for lung cancer screening (LCS) by combining structured and unstructured smoking 
      data from the electronic health record (EHR). METHODS: We identified patients 
      aged 50-80 years who had at least one encounter in a primary care clinic at 
      Vanderbilt University Medical Center (VUMC) between 2019 and 2022. We fine-tuned 
      an existing natural language processing (NLP) tool to extract quantitative 
      smoking information using clinical notes collected from VUMC. Then, we developed 
      an approach to identify patients who are eligible for LCS by combining smoking 
      information from structured data and clinical narratives. We compared this method 
      with two approaches to identify LCS eligibility only using smoking information 
      from structured EHR. We used 50 patients with a documented history of tobacco use 
      for comparison and validation. RESULTS: 102,475 patients were included. The 
      NLP-based approach achieved an F1-score of 0.909, and accuracy of 0.96. The 
      baseline approach could identify 5,887 patients. Compared to the baseline 
      approach, the number of identified patients using all structured data and the 
      NLP-based algorithm was 7,194 (22.2 %) and 10,231 (73.8 %), respectively. The 
      NLP-based approach identified 589 Black/African Americans, a significant increase 
      of 119 %. CONCLUSION: We present a feasible NLP-based approach to identify LCS 
      eligible patients. It provides a technical basis for the development of clinical 
      decision support tools to potentially improve the utilization of LCS and diminish 
      healthcare disparities.
CI  - Copyright © 2023 The Author(s). Published by Elsevier B.V. All rights reserved.
FAU - Liu, Siru
AU  - Liu S
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA. Electronic address: siru.liu@vumc.org.
FAU - McCoy, Allison B
AU  - McCoy AB
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
FAU - Aldrich, Melinda C
AU  - Aldrich MC
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA; Division of Genetic Medicine, Department of Medicine, 
      Vanderbilt University Medical Center, Nashville, TN, USA; Department of Thoracic 
      Surgery, Vanderbilt University Medical Center, Nashville, TN, USA.
FAU - Sandler, Kim L
AU  - Sandler KL
AD  - Department of Radiology and Radiological Sciences, Vanderbilt University Medical 
      Center, Nashville, TN, USA.
FAU - Reese, Thomas J
AU  - Reese TJ
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
FAU - Steitz, Bryan
AU  - Steitz B
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
FAU - Bian, Jiang
AU  - Bian J
AD  - Department of Health Outcomes and Biomedical Informatics, University of Florida, 
      Gainesville, FL, USA.
FAU - Wu, Yonghui
AU  - Wu Y
AD  - Department of Health Outcomes and Biomedical Informatics, University of Florida, 
      Gainesville, FL, USA.
FAU - Russo, Elise
AU  - Russo E
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
FAU - Wright, Adam
AU  - Wright A
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN, USA.
LA  - eng
GR  - K99 LM014097/LM/NLM NIH HHS/United States
GR  - R01 AG062499/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20230626
PL  - Ireland
TA  - Int J Med Inform
JT  - International journal of medical informatics
JID - 9711057
SB  - IM
MH  - Humans
MH  - *Lung Neoplasms/diagnosis/epidemiology
MH  - Early Detection of Cancer
MH  - Electronic Health Records
MH  - Natural Language Processing
MH  - Smoking/epidemiology
PMC - PMC11537206
MID - NIHMS1915049
OTO - NOTNLM
OT  - Electronic health record
OT  - Lung cancer screening
OT  - Natural language processing
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/07/02 01:10
MHDA- 2023/08/14 06:42
PMCR- 2024/11/05
CRDT- 2023/07/01 18:08
PHST- 2023/02/01 00:00 [received]
PHST- 2023/05/27 00:00 [revised]
PHST- 2023/06/25 00:00 [accepted]
PHST- 2023/08/14 06:42 [medline]
PHST- 2023/07/02 01:10 [pubmed]
PHST- 2023/07/01 18:08 [entrez]
PHST- 2024/11/05 00:00 [pmc-release]
AID - S1386-5056(23)00154-5 [pii]
AID - 10.1016/j.ijmedinf.2023.105136 [doi]
PST - ppublish
SO  - Int J Med Inform. 2023 Sep;177:105136. doi: 10.1016/j.ijmedinf.2023.105136. Epub 
      2023 Jun 26.

PMID- 35430230
OWN - NLM
STAT- MEDLINE
DCOM- 20220829
LR  - 20220912
IS  - 1097-6868 (Electronic)
IS  - 0002-9378 (Linking)
VI  - 227
IP  - 3
DP  - 2022 Sep
TI  - Natural language processing of admission notes to predict severe maternal 
      morbidity during the delivery encounter.
PG  - 511.e1-511.e8
LID - S0002-9378(22)00280-0 [pii]
LID - 10.1016/j.ajog.2022.04.008 [doi]
AB  - BACKGROUND: Severe maternal morbidity and mortality remain public health 
      priorities in the United States, given their high rates relative to other 
      high-income countries and the notable racial and ethnic disparities that exist. 
      In general, accurate risk stratification methods are needed to help patients, 
      providers, hospitals, and health systems plan for and potentially avert adverse 
      outcomes. OBJECTIVE: Our objective was to understand if machine learning methods 
      with natural language processing of history and physical notes could identify a 
      group of patients at high risk of maternal morbidity on admission for delivery 
      without relying on any additional patient information (eg, demographics and 
      diagnosis codes). STUDY DESIGN: This was a retrospective study of people admitted 
      for delivery at 2 hospitals (hospitals A and B) in a single healthcare system 
      between July 1, 2016, and June 30, 2020. The primary outcome was severe maternal 
      morbidity, as defined by the Centers for Disease Control and Prevention; 
      furthermore, we examined nontransfusion severe maternal morbidity. Clinician 
      documents designated as history and physical notes were extracted from the 
      electronic health record for processing and analysis. A bag-of-words approach was 
      used for this natural language processing analysis (ie, each history or physical 
      note was converted into a matrix of counts of individual words (or phrases) that 
      occurred within the document). The least absolute shrinkage and selection 
      operator models were used to generate prediction probabilities for severe 
      maternal morbidity and nontransfusion severe maternal morbidity for each note. 
      Model discrimination was assessed via the area under the receiver operating 
      curve. Discrimination was compared between models using the DeLong test. 
      Calibration plots were generated to assess model calibration. Moreover, the 
      natural language processing models with history and physical note texts were 
      compared with validated obstetrical comorbidity risk scores based on diagnosis 
      codes. RESULTS: There were 13,572 delivery encounters with history and physical 
      notes from hospital A, split between training (A(train), n=10,250) and testing 
      (A(test), n=3,322) datasets for model derivation and internal validation. There 
      were 23,397 delivery encounters with history and physical notes from hospital B 
      (B(valid)) used for external validation. For the outcome of severe maternal 
      morbidity, the natural language processing model had an area under the receiver 
      operating curve of 0.67 (95% confidence interval, 0.63-0.72) and 0.72 (95% 
      confidence interval, 0.70-0.74) in the A(test) and B(valid) datasets, 
      respectively. For the outcome of nontransfusion severe maternal morbidity, the 
      area under the receiver operating curve was 0.72 (95% confidence interval, 
      0.65-0.80) and 0.76 (95% confidence interval, 0.73-0.79) in the A(test) and 
      B(valid) datasets, respectively. The calibration plots demonstrated the 
      bag-of-words model's ability to distinguish a group of individuals at a 
      substantially higher risk of severe maternal morbidity and nontransfusion severe 
      maternal morbidity, notably those in the top deciles of predicted risk. Areas 
      under the receiver operating curve in the natural language processing-based 
      models were similar to those generated using a validated, retrospectively 
      derived, diagnosis code-based comorbidity score. CONCLUSION: In this practical 
      application of machine learning, we demonstrated the capabilities of natural 
      language processing for the prediction of severe maternal morbidity based on 
      provider documentation inherently generated at the time of admission. This work 
      should serve as a catalyst for providers, hospitals, and electronic health record 
      systems to explore ways that artificial intelligence can be incorporated into 
      clinical practice and evaluated rigorously for their ability to improve health.
CI  - Copyright © 2022 Elsevier Inc. All rights reserved.
FAU - Clapp, Mark A
AU  - Clapp MA
AD  - Department of Obstetrics and Gynecology, Massachusetts General Hospital, Boston, 
      MA. Electronic address: mark.clapp@mgh.harvard.edu.
FAU - Kim, Ellen
AU  - Kim E
AD  - Department of Radiation Oncology, Brigham and Women's Hospital, Boston, MA.
FAU - James, Kaitlyn E
AU  - James KE
AD  - Department of Obstetrics and Gynecology, Massachusetts General Hospital, Boston, 
      MA.
FAU - Perlis, Roy H
AU  - Perlis RH
AD  - Center for Quantitative Health, Massachusetts General Hospital, Boston, MA; 
      Department of Psychiatry, Massachusetts General Hospital, Boston, MA.
FAU - Kaimal, Anjali J
AU  - Kaimal AJ
AD  - Department of Obstetrics and Gynecology, Massachusetts General Hospital, Boston, 
      MA; Department of Population Medicine, Harvard Medical School, Boston, MA.
FAU - McCoy, Thomas H Jr
AU  - McCoy TH Jr
AD  - Center for Quantitative Health, Massachusetts General Hospital, Boston, MA; 
      Department of Psychiatry, Massachusetts General Hospital, Boston, MA.
LA  - eng
GR  - T15 LM007092/LM/NLM NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20220414
PL  - United States
TA  - Am J Obstet Gynecol
JT  - American journal of obstetrics and gynecology
JID - 0370476
SB  - IM
MH  - *Artificial Intelligence
MH  - Electronic Health Records
MH  - Female
MH  - Humans
MH  - Machine Learning
MH  - *Natural Language Processing
MH  - Pregnancy
MH  - Retrospective Studies
OTO - NOTNLM
OT  - complications
OT  - labor and delivery
OT  - machine learning
OT  - maternal morbidity
OT  - natural language processing
OT  - risk prediction
EDAT- 2022/04/18 06:00
MHDA- 2022/08/30 06:00
CRDT- 2022/04/17 20:17
PHST- 2021/10/27 00:00 [received]
PHST- 2022/03/31 00:00 [revised]
PHST- 2022/04/09 00:00 [accepted]
PHST- 2022/04/18 06:00 [pubmed]
PHST- 2022/08/30 06:00 [medline]
PHST- 2022/04/17 20:17 [entrez]
AID - S0002-9378(22)00280-0 [pii]
AID - 10.1016/j.ajog.2022.04.008 [doi]
PST - ppublish
SO  - Am J Obstet Gynecol. 2022 Sep;227(3):511.e1-511.e8. doi: 
      10.1016/j.ajog.2022.04.008. Epub 2022 Apr 14.

PMID- 38450035
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240308
IS  - 2807-2618 (Electronic)
IS  - 2807-2618 (Linking)
VI  - 3
IP  - 1
DP  - 2023 Apr
TI  - ChatGPT applications in medical, dental, pharmacy, and public health education: A 
      descriptive study highlighting the advantages and limitations.
PG  - e103
LID - 10.52225/narra.v3i1.103 [doi]
LID - e103
AB  - Since its public release in November 2022, ChatGPT has gained a widespread 
      attention and received mixed responses in the academia. Promising applications of 
      ChatGPT in university education has been suggested; however, several concerns 
      were raised. The aim of this descriptive study was to investigate the pros and 
      cons of ChatGPT use in medical, dental, pharmacy, and public health education. 
      Based on expert panel discussion and review of the existing literature, specific 
      and concise ChatGPT prompts were constructed and the responses were generated on 
      25 February 2023. Out data suggested that in medical education, ChatGPT benefits 
      included the possibility of improving personalized learning, clinical reasoning 
      and understanding of complex medical concepts. The benefits listed in the context 
      of dental education included improved skills through step- by-step instructions 
      and interactive content, with instant feedback on student techniques. In pharmacy 
      education, the advantages included possible explanations of complex subjects and 
      the deployment of interactive tools aiding to develop skills for patient 
      counselling. In public health education, the listed benefits included providing 
      explanations and case scenarios, besides improved skills in data analysis and 
      literature review. The limitations listed based on ChatGPT-generated content were 
      common across all of the investigated healthcare disciplines and included data 
      privacy issues, risk of generating biased and inaccurate content, and the risk of 
      deterioration of critical thinking and communication skills among healthcare 
      students. The ChatGPT-generated content in the context of healthcare education 
      was deemed partially helpful by the expert panel. However, several important 
      points regarding the pros and cons of ChatGPT use in medical, dental, pharmacy 
      and public health education were missed by ChatGPT- generated content including: 
      the risk of plagiarism, copyright issues, the risk of academic dishonesty, and 
      the lack of personal and emotional interactions necessary for developing proper 
      communication skills in healthcare education. In conclusion, despite the 
      promising prospects of ChatGPT in healthcare education, several drawbacks should 
      be addressed with implementation of guidelines for proper use to ensure 
      exploiting the benefits of this innovative technology.
CI  - © 2023 The Author(s).
FAU - Sallam, Malik
AU  - Sallam M
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, Jordan.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Amman, Jordan.
AD  - Department of Translational Medicine, Faculty of Medicine, Lund University, 
      Malmö, Sweden.
FAU - Salim, Nesreen A
AU  - Salim NA
AD  - Department of Prosthodontic, School of Dentistry, The University of Jordan, 
      Amman, Jordan.
AD  - Department of Prosthodontic, Jordan University Hospital, Amman, Jordan.
FAU - Barakat, Muna
AU  - Barakat M
AD  - Department of Clinical Pharmacy and Therapeutics, Faculty of Pharmacy, Applied 
      Science Private University, Amman, Jordan.
FAU - Al-Tammemi, Ala'a B
AU  - Al-Tammemi AB
AD  - Migration Health Division, International Organization for Migration (IOM), The UN 
      Migration Agency, Amman, Jordan.
LA  - eng
PT  - Journal Article
DEP - 20230329
PL  - Indonesia
TA  - Narra J
JT  - Narra J
JID - 9918625888906676
PMC - PMC10914078
OTO - NOTNLM
OT  - Artificial intelligence
OT  - education
OT  - healthcare
OT  - machine learning
OT  - technology
COIS- All the authors declare that there are no conflicts of interest.
EDAT- 2024/03/07 06:43
MHDA- 2024/03/07 06:44
PMCR- 2023/03/29
CRDT- 2024/03/07 04:13
PHST- 2023/03/04 00:00 [received]
PHST- 2023/03/28 00:00 [accepted]
PHST- 2024/03/07 06:44 [medline]
PHST- 2024/03/07 06:43 [pubmed]
PHST- 2024/03/07 04:13 [entrez]
PHST- 2023/03/29 00:00 [pmc-release]
AID - NarraJ-3-e103 [pii]
AID - 10.52225/narra.v3i1.103 [doi]
PST - ppublish
SO  - Narra J. 2023 Apr;3(1):e103. doi: 10.52225/narra.v3i1.103. Epub 2023 Mar 29.

PMID- 38691911
OWN - NLM
STAT- MEDLINE
DCOM- 20240513
LR  - 20240513
IS  - 1873-4499 (Electronic)
IS  - 0899-7071 (Linking)
VI  - 110
DP  - 2024 Jun
TI  - Use of natural language processing to uncover racial bias in obstetrical 
      documentation.
PG  - 110164
LID - S0899-7071(24)00094-9 [pii]
LID - 10.1016/j.clinimag.2024.110164 [doi]
AB  - Natural Language Processing (NLP), a form of Artificial Intelligence, allows 
      free-text based clinical documentation to be integrated in ways that facilitate 
      data analysis, data interpretation and formation of individualized medical and 
      obstetrical care. In this cross-sectional study, we identified all births during 
      the study period carrying the radiology-confirmed diagnosis of fibroid uterus in 
      pregnancy (defined as size of largest diameter of >5 cm) by using an NLP platform 
      and compared it to non-NLP derived data using ICD10 codes of the same diagnosis. 
      We then compared the two sets of data and stratified documentation gaps by race. 
      Using fibroid uterus in pregnancy as a marker, we found that Black patients were 
      more likely to have the diagnosis entered late into the patient's chart or had 
      missing documentation of the diagnosis. With appropriate algorithm definitions, 
      cross referencing and thorough validation steps, NLP can contribute to 
      identifying areas of documentation gaps and improve quality of care.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Futterman, Itamar D
AU  - Futterman ID
AD  - Department of Obstetrics and Gynecology, Division of Maternal Fetal Medicine, 
      Maimonides Medical Center, Brooklyn, NY, United States of America. Electronic 
      address: ifutterman@maimo.org.
FAU - Friedmann, Hila
AU  - Friedmann H
AD  - Gynisus Inc., Santa Monica, CA, United States of America.
FAU - Shpanel-Yukhta, Oleksii
AU  - Shpanel-Yukhta O
AD  - Gynisus Inc., Santa Monica, CA, United States of America.
FAU - Minkoff, Howard
AU  - Minkoff H
AD  - Department of Obstetrics and Gynecology, Division of Maternal Fetal Medicine, 
      Maimonides Medical Center, Brooklyn, NY, United States of America.
FAU - Haberman, Shoshana
AU  - Haberman S
AD  - Department of Obstetrics and Gynecology, Division of Maternal Fetal Medicine, 
      Maimonides Medical Center, Brooklyn, NY, United States of America.
LA  - eng
PT  - Journal Article
DEP - 20240421
PL  - United States
TA  - Clin Imaging
JT  - Clinical imaging
JID - 8911831
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Female
MH  - Pregnancy
MH  - Cross-Sectional Studies
MH  - *Documentation/standards/statistics & numerical data
MH  - *Uterine Neoplasms/diagnostic imaging
MH  - Racism
MH  - Leiomyoma/diagnostic imaging
MH  - Adult
MH  - Obstetrics
MH  - Pregnancy Complications, Neoplastic/diagnostic imaging
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Fibroids
OT  - Natural language processing
OT  - Racial bias
COIS- Declaration of competing interest H.F. and O.S.Y. Are employed by Gynisus Inc. 
      All other authors report no conflict of interest.
EDAT- 2024/05/02 00:49
MHDA- 2024/05/14 00:43
CRDT- 2024/05/01 18:01
PHST- 2023/09/09 00:00 [received]
PHST- 2024/04/09 00:00 [revised]
PHST- 2024/04/14 00:00 [accepted]
PHST- 2024/05/14 00:43 [medline]
PHST- 2024/05/02 00:49 [pubmed]
PHST- 2024/05/01 18:01 [entrez]
AID - S0899-7071(24)00094-9 [pii]
AID - 10.1016/j.clinimag.2024.110164 [doi]
PST - ppublish
SO  - Clin Imaging. 2024 Jun;110:110164. doi: 10.1016/j.clinimag.2024.110164. Epub 2024 
      Apr 21.

PMID- 38975242
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240709
IS  - 2772-6096 (Electronic)
IS  - 2772-6096 (Linking)
VI  - 10
DP  - 2024 Jun
TI  - A comparative study of English and Japanese ChatGPT responses to 
      anaesthesia-related medical questions.
PG  - 100296
LID - 10.1016/j.bjao.2024.100296 [doi]
LID - 100296
AB  - BACKGROUND: The expansion of artificial intelligence (AI) within large language 
      models (LLMs) has the potential to streamline healthcare delivery. Despite the 
      increased use of LLMs, disparities in their performance particularly in different 
      languages, remain underexplored. This study examines the quality of ChatGPT 
      responses in English and Japanese, specifically to questions related to 
      anaesthesiology. METHODS: Anaesthesiologists proficient in both languages were 
      recruited as experts in this study. Ten frequently asked questions in anaesthesia 
      were selected and translated for evaluation. Three non-sequential responses from 
      ChatGPT were assessed for content quality (accuracy, comprehensiveness, and 
      safety) and communication quality (understanding, empathy/tone, and ethics) by 
      expert evaluators. RESULTS: Eight anaesthesiologists evaluated English and 
      Japanese LLM responses. The overall quality for all questions combined was higher 
      in English compared with Japanese responses. Content and communication quality 
      were significantly higher in English compared with Japanese LLMs responses (both 
      P<0.001) in all three responses. Comprehensiveness, safety, and understanding 
      were higher scores in English LLM responses. In all three responses, more than 
      half of the evaluators marked overall English responses as better than Japanese 
      responses. CONCLUSIONS: English LLM responses to anaesthesia-related frequently 
      asked questions were superior in quality to Japanese responses when assessed by 
      bilingual anaesthesia experts in this report. This study highlights the potential 
      for language-related disparities in healthcare information and the need to 
      improve the quality of AI responses in underrepresented languages. Future studies 
      are needed to explore these disparities in other commonly spoken languages and to 
      compare the performance of different LLMs.
CI  - © 2024 The Author(s).
FAU - Ando, Kazuo
AU  - Ando K
AD  - Department of Anesthesiology, Perioperative and Pain Medicine. Stanford 
      University School of Medicine, Stanford, CA, USA.
FAU - Sato, Masaki
AU  - Sato M
AD  - Department of Anesthesiology, Perioperative and Pain Medicine. Stanford 
      University School of Medicine, Stanford, CA, USA.
FAU - Wakatsuki, Shin
AU  - Wakatsuki S
AD  - Private Practice Group, Pacific Anesthesia Inc., Honolulu, HI, USA.
FAU - Nagai, Ryotaro
AU  - Nagai R
AD  - Private Practice Group, Pacific Anesthesia Inc., Honolulu, HI, USA.
FAU - Chino, Kumiko
AU  - Chino K
AD  - University of Pittsburgh Medical Center, Magee-Women's Hospital, PA, USA.
FAU - Kai, Hinata
AU  - Kai H
AD  - Department of Anesthesiology, Indiana University School of Medicine, 
      Indianapolis, IN, USA.
FAU - Sasaki, Tomomi
AU  - Sasaki T
AD  - Department of Anesthesiology, Showa University School of Medicine, Tokyo, Japan.
FAU - Kato, Rie
AU  - Kato R
AD  - Department of Anesthesiology, Showa University School of Medicine, Tokyo, Japan.
FAU - Nguyen, Teresa Phuongtram
AU  - Nguyen TP
AD  - Department of Anesthesiology, Perioperative and Pain Medicine. Stanford 
      University School of Medicine, Stanford, CA, USA.
FAU - Guo, Nan
AU  - Guo N
AD  - Department of Anesthesiology, Perioperative and Pain Medicine. Stanford 
      University School of Medicine, Stanford, CA, USA.
FAU - Sultan, Pervez
AU  - Sultan P
AD  - Department of Anesthesiology, Perioperative and Pain Medicine. Stanford 
      University School of Medicine, Stanford, CA, USA.
LA  - eng
PT  - Journal Article
DEP - 20240614
PL  - England
TA  - BJA Open
JT  - BJA open
JID - 9918419157906676
PMC - PMC11225650
OTO - NOTNLM
OT  - ChatGPT
OT  - anaesthesia
OT  - artificial intelligence
OT  - digital health
EDAT- 2024/07/08 12:42
MHDA- 2024/07/08 12:43
PMCR- 2024/06/14
CRDT- 2024/07/08 07:44
PHST- 2024/01/13 00:00 [received]
PHST- 2024/05/06 00:00 [revised]
PHST- 2024/05/24 00:00 [accepted]
PHST- 2024/07/08 12:43 [medline]
PHST- 2024/07/08 12:42 [pubmed]
PHST- 2024/07/08 07:44 [entrez]
PHST- 2024/06/14 00:00 [pmc-release]
AID - S2772-6096(24)00040-6 [pii]
AID - 100296 [pii]
AID - 10.1016/j.bjao.2024.100296 [doi]
PST - epublish
SO  - BJA Open. 2024 Jun 14;10:100296. doi: 10.1016/j.bjao.2024.100296. eCollection 
      2024 Jun.

PMID- 39914854
OWN - NLM
STAT- In-Process
LR  - 20250208
IS  - 2632-1009 (Electronic)
IS  - 2632-1009 (Linking)
VI  - 32
IP  - 1
DP  - 2025 Feb 5
TI  - Biodesign in the generative AI era: enhancing innovation and equity with NLP and 
      LLM tools.
LID - 10.1136/bmjhci-2024-101409 [doi]
LID - e101409
FAU - Tani, Jowy
AU  - Tani J
AUID- ORCID: 0000-0002-9979-6779
AD  - Department of Neurology, School of Medicine, College of Medicine, Taipei Medical 
      University, Taipei, Taiwan jowytani@tmu.edu.tw.
AD  - Department of Neurology, Wan Fang Hospital, Taipei Medical University, Taipei, 
      Taiwan.
LA  - eng
PT  - Editorial
DEP - 20250205
PL  - England
TA  - BMJ Health Care Inform
JT  - BMJ health & care informatics
JID - 101745500
SB  - IM
PMC - PMC11800217
OTO - NOTNLM
OT  - Artificial intelligence
OT  - BMJ Health Informatics
OT  - Health Equity
OT  - Software Design
OT  - User-Centred Design
COIS- Competing interests: None declared.
EDAT- 2025/02/07 00:20
MHDA- 2025/02/07 00:20
PMCR- 2025/02/05
CRDT- 2025/02/06 20:43
PHST- 2024/12/12 00:00 [received]
PHST- 2025/01/27 00:00 [accepted]
PHST- 2025/02/07 00:20 [medline]
PHST- 2025/02/07 00:20 [pubmed]
PHST- 2025/02/06 20:43 [entrez]
PHST- 2025/02/05 00:00 [pmc-release]
AID - bmjhci-2024-101409 [pii]
AID - 10.1136/bmjhci-2024-101409 [doi]
PST - epublish
SO  - BMJ Health Care Inform. 2025 Feb 5;32(1):e101409. doi: 
      10.1136/bmjhci-2024-101409.

PMID- 39150707
OWN - NLM
STAT- MEDLINE
DCOM- 20240816
LR  - 20250304
IS  - 2574-3805 (Electronic)
IS  - 2574-3805 (Linking)
VI  - 7
IP  - 8
DP  - 2024 Aug 1
TI  - Enhancing Postmarketing Surveillance of Medical Products With Large Language 
      Models.
PG  - e2428276
LID - 10.1001/jamanetworkopen.2024.28276 [doi]
AB  - IMPORTANCE: The Sentinel System is a key component of the US Food and Drug 
      Administration (FDA) postmarketing safety surveillance commitment and uses 
      clinical health care data to conduct analyses to inform drug labeling and safety 
      communications, FDA advisory committee meetings, and other regulatory decisions. 
      However, observational data are frequently deemed insufficient for reliable 
      evaluation of safety concerns owing to limitations in underlying data or 
      methodology. Advances in large language models (LLMs) provide new opportunities 
      to address some of these limitations. However, careful consideration is necessary 
      for how and where LLMs can be effectively deployed for these purposes. 
      OBSERVATIONS: LLMs may provide new avenues to support signal-identification 
      activities to identify novel adverse event signals from narrative text of 
      electronic health records. These algorithms may be used to support epidemiologic 
      investigations examining the causal relationship between exposure to a medical 
      product and an adverse event through development of probabilistic phenotyping of 
      health outcomes of interest and extraction of information related to important 
      confounding factors. LLMs may perform like traditional natural language 
      processing tools by annotating text with controlled vocabularies with additional 
      tailored training activities. LLMs offer opportunities for enhancing information 
      extraction from adverse event reports, medical literature, and other biomedical 
      knowledge sources. There are several challenges that must be considered when 
      leveraging LLMs for postmarket surveillance. Prompt engineering is needed to 
      ensure that LLM-extracted associations are accurate and specific. LLMs require 
      extensive infrastructure to use, which many health care systems lack, and this 
      can impact diversity, equity, and inclusion, and result in obscuring significant 
      adverse event patterns in some populations. LLMs are known to generate nonfactual 
      statements, which could lead to false positive signals and downstream evaluation 
      activities by the FDA and other entities, incurring substantial cost. CONCLUSIONS 
      AND RELEVANCE: LLMs represent a novel paradigm that may facilitate generation of 
      information to support medical product postmarket surveillance activities that 
      have not been possible. However, additional work is required to ensure LLMs can 
      be used in a fair and equitable manner, minimize false positive findings, and 
      support the necessary rigor of signal detection needed for regulatory activities.
FAU - Matheny, Michael E
AU  - Matheny ME
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
AD  - Department of Medicine, Vanderbilt University Medical Center, Nashville, 
      Tennessee.
AD  - Department of Biostatistics, Vanderbilt University Medical Center, Nashville, 
      Tennessee.
AD  - Geriatric Research Education and Clinical Care Service, Tennessee Valley 
      Healthcare System VA, Nashville.
FAU - Yang, Jie
AU  - Yang J
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital and Harvard Medical School, Boston, Massachusetts.
FAU - Smith, Joshua C
AU  - Smith JC
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
FAU - Walsh, Colin G
AU  - Walsh CG
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
AD  - Department of Medicine, Vanderbilt University Medical Center, Nashville, 
      Tennessee.
AD  - Department of Psychiatry, Vanderbilt University Medical Center, Nashville, 
      Tennessee.
FAU - Al-Garadi, Mohammed A
AU  - Al-Garadi MA
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
FAU - Davis, Sharon E
AU  - Davis SE
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
FAU - Marsolo, Keith A
AU  - Marsolo KA
AD  - Department of Population Health Sciences, Duke University School of Medicine, 
      Durham, North Carolina.
FAU - Fabbri, Daniel
AU  - Fabbri D
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
AD  - Department of Computer Science, Vanderbilt University, Nashville, Tennessee.
FAU - Reeves, Ruth R
AU  - Reeves RR
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
AD  - Geriatric Research Education and Clinical Care Service, Tennessee Valley 
      Healthcare System VA, Nashville.
FAU - Johnson, Kevin B
AU  - Johnson KB
AD  - Department of Epidemiology and Informatics, University of Pennsylvania, 
      Philadelphia.
AD  - Department of Pediatrics, University of Pennsylvania, Philadelphia.
FAU - Dal Pan, Gerald J
AU  - Dal Pan GJ
AD  - Office of Surveillance and Epidemiology, Center for Drug Evaluation and Research, 
      US Food and Drug Administration, Silver Spring, Maryland.
FAU - Ball, Robert
AU  - Ball R
AD  - Office of Surveillance and Epidemiology, Center for Drug Evaluation and Research, 
      US Food and Drug Administration, Silver Spring, Maryland.
FAU - Desai, Rishi J
AU  - Desai RJ
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital and Harvard Medical School, Boston, Massachusetts.
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, P.H.S.
DEP - 20240801
PL  - United States
TA  - JAMA Netw Open
JT  - JAMA network open
JID - 101729235
SB  - IM
MH  - *Product Surveillance, Postmarketing/methods
MH  - Humans
MH  - United States
MH  - *United States Food and Drug Administration
MH  - *Natural Language Processing
MH  - Electronic Health Records
EDAT- 2024/08/16 13:42
MHDA- 2024/08/16 13:43
CRDT- 2024/08/16 11:33
PHST- 2024/08/16 13:43 [medline]
PHST- 2024/08/16 13:42 [pubmed]
PHST- 2024/08/16 11:33 [entrez]
AID - 2822418 [pii]
AID - 10.1001/jamanetworkopen.2024.28276 [doi]
PST - epublish
SO  - JAMA Netw Open. 2024 Aug 1;7(8):e2428276. doi: 
      10.1001/jamanetworkopen.2024.28276.

PMID- 39313595
OWN - NLM
STAT- MEDLINE
DCOM- 20241213
LR  - 20250108
IS  - 1546-170X (Electronic)
IS  - 1078-8956 (Print)
IS  - 1078-8956 (Linking)
VI  - 30
IP  - 12
DP  - 2024 Dec
TI  - A toolbox for surfacing health equity harms and biases in large language models.
PG  - 3590-3600
LID - 10.1038/s41591-024-03258-2 [doi]
AB  - Large language models (LLMs) hold promise to serve complex health information 
      needs but also have the potential to introduce harm and exacerbate health 
      disparities. Reliably evaluating equity-related model failures is a critical step 
      toward developing systems that promote health equity. We present resources and 
      methodologies for surfacing biases with potential to precipitate equity-related 
      harms in long-form, LLM-generated answers to medical questions and conduct a 
      large-scale empirical case study with the Med-PaLM 2 LLM. Our contributions 
      include a multifactorial framework for human assessment of LLM-generated answers 
      for biases and EquityMedQA, a collection of seven datasets enriched for 
      adversarial queries. Both our human assessment framework and our dataset design 
      process are grounded in an iterative participatory approach and review of 
      Med-PaLM 2 answers. Through our empirical study, we find that our approach 
      surfaces biases that may be missed by narrower evaluation approaches. Our 
      experience underscores the importance of using diverse assessment methodologies 
      and involving raters of varying backgrounds and expertise. While our approach is 
      not sufficient to holistically assess whether the deployment of an artificial 
      intelligence (AI) system promotes equitable health outcomes, we hope that it can 
      be leveraged and built upon toward a shared goal of LLMs that promote accessible 
      and equitable healthcare.
CI  - © 2024. The Author(s).
FAU - Pfohl, Stephen R
AU  - Pfohl SR
AUID- ORCID: 0000-0003-0551-9664
AD  - Google Research, Mountain View, CA, USA. spfohl@google.com.
FAU - Cole-Lewis, Heather
AU  - Cole-Lewis H
AUID- ORCID: 0000-0002-7275-1810
AD  - Google Research, Mountain View, CA, USA. hcolelewis@google.com.
FAU - Sayres, Rory
AU  - Sayres R
AD  - Google Research, Mountain View, CA, USA.
FAU - Neal, Darlene
AU  - Neal D
AD  - Google Research, Mountain View, CA, USA.
FAU - Asiedu, Mercy
AU  - Asiedu M
AD  - Google Research, Mountain View, CA, USA.
FAU - Dieng, Awa
AU  - Dieng A
AD  - Google DeepMind, Mountain View, CA, USA.
FAU - Tomasev, Nenad
AU  - Tomasev N
AD  - Google DeepMind, Mountain View, CA, USA.
FAU - Rashid, Qazi Mamunur
AU  - Rashid QM
AD  - Google Research, Mountain View, CA, USA.
FAU - Azizi, Shekoofeh
AU  - Azizi S
AUID- ORCID: 0000-0002-7447-6031
AD  - Google DeepMind, Mountain View, CA, USA.
FAU - Rostamzadeh, Negar
AU  - Rostamzadeh N
AD  - Google Research, Mountain View, CA, USA.
FAU - McCoy, Liam G
AU  - McCoy LG
AD  - University of Alberta, Edmonton, Alberta, Canada.
FAU - Celi, Leo Anthony
AU  - Celi LA
AUID- ORCID: 0000-0001-6712-6626
AD  - Laboratory for Computational Physiology, Massachusetts Institute of Technology, 
      Cambridge, MA, USA.
AD  - Division of Pulmonary, Critical Care and Sleep Medicine, Beth Israel Deaconess 
      Medical Center, Boston, MA, USA.
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Boston, 
      MA, USA.
FAU - Liu, Yun
AU  - Liu Y
AUID- ORCID: 0000-0003-4079-8275
AD  - Google Research, Mountain View, CA, USA.
FAU - Schaekermann, Mike
AU  - Schaekermann M
AUID- ORCID: 0000-0002-1735-9680
AD  - Google Research, Mountain View, CA, USA.
FAU - Walton, Alanna
AU  - Walton A
AD  - Google DeepMind, Mountain View, CA, USA.
FAU - Parrish, Alicia
AU  - Parrish A
AUID- ORCID: 0000-0002-1054-0516
AD  - Google DeepMind, Mountain View, CA, USA.
FAU - Nagpal, Chirag
AU  - Nagpal C
AD  - Google Research, Mountain View, CA, USA.
FAU - Singh, Preeti
AU  - Singh P
AD  - Google Research, Mountain View, CA, USA.
FAU - Dewitt, Akeiylah
AU  - Dewitt A
AD  - Google Research, Mountain View, CA, USA.
FAU - Mansfield, Philip
AU  - Mansfield P
AUID- ORCID: 0000-0003-4969-0543
AD  - Google DeepMind, Mountain View, CA, USA.
FAU - Prakash, Sushant
AU  - Prakash S
AD  - Google Research, Mountain View, CA, USA.
FAU - Heller, Katherine
AU  - Heller K
AD  - Google Research, Mountain View, CA, USA.
FAU - Karthikesalingam, Alan
AU  - Karthikesalingam A
AUID- ORCID: 0009-0000-4958-5976
AD  - Google Research, Mountain View, CA, USA.
FAU - Semturs, Christopher
AU  - Semturs C
AUID- ORCID: 0000-0001-6108-2773
AD  - Google Research, Mountain View, CA, USA.
FAU - Barral, Joelle
AU  - Barral J
AD  - Google DeepMind, Mountain View, CA, USA.
FAU - Corrado, Greg
AU  - Corrado G
AD  - Google Research, Mountain View, CA, USA.
FAU - Matias, Yossi
AU  - Matias Y
AUID- ORCID: 0000-0003-3960-6002
AD  - Google Research, Mountain View, CA, USA.
FAU - Smith-Loud, Jamila
AU  - Smith-Loud J
AD  - Google Research, Mountain View, CA, USA.
FAU - Horn, Ivor
AU  - Horn I
AD  - Google Research, Mountain View, CA, USA.
FAU - Singhal, Karan
AU  - Singhal K
AUID- ORCID: 0009-0001-0286-609X
AD  - Google Research, Mountain View, CA, USA.
LA  - eng
GR  - OT2 OD032701/OD/NIH HHS/United States
GR  - R01 EB017205/EB/NIBIB NIH HHS/United States
GR  - U54 TW012043/TW/FIC NIH HHS/United States
PT  - Journal Article
DEP - 20240923
PL  - United States
TA  - Nat Med
JT  - Nature medicine
JID - 9502015
SB  - IM
MH  - *Health Equity
MH  - Humans
MH  - Language
MH  - Bias
MH  - Artificial Intelligence
MH  - Healthcare Disparities
PMC - PMC11645264
COIS- Competing interests: This study was funded by Google LLC and/or its subsidiary 
      (Google). S.R.P., H.C.-L., R.S., D.N., M.A., A. Dieng, N.T., Q.M.R., S.A., N.R., 
      Y.L., M.S., A.W., A.P., C.N., P.S., A. Dewitt, P.M., S.P., K.H., A.K., C.S., 
      J.B., G.C., Y.M., J.S.-L., I.H. and K.S. are employees of Google and may own 
      stock as a part of a standard compensation package. The other authors declare no 
      competing interests.
EDAT- 2024/09/24 00:42
MHDA- 2024/12/14 00:24
PMCR- 2024/09/23
CRDT- 2024/09/23 23:19
PHST- 2024/03/26 00:00 [received]
PHST- 2024/08/20 00:00 [accepted]
PHST- 2024/12/14 00:24 [medline]
PHST- 2024/09/24 00:42 [pubmed]
PHST- 2024/09/23 23:19 [entrez]
PHST- 2024/09/23 00:00 [pmc-release]
AID - 10.1038/s41591-024-03258-2 [pii]
AID - 3258 [pii]
AID - 10.1038/s41591-024-03258-2 [doi]
PST - ppublish
SO  - Nat Med. 2024 Dec;30(12):3590-3600. doi: 10.1038/s41591-024-03258-2. Epub 2024 
      Sep 23.

PMID- 38165624
OWN - NLM
STAT- MEDLINE
DCOM- 20240104
LR  - 20240104
IS  - 1940-6029 (Electronic)
IS  - 1064-3745 (Linking)
VI  - 2742
DP  - 2024
TI  - Applying BERT and ChatGPT for Sentiment Analysis of Lyme Disease in Scientific 
      Literature.
PG  - 173-183
LID - 10.1007/978-1-0716-3561-2_14 [doi]
AB  - This chapter presents a practical guide for conducting sentiment analysis using 
      Natural Language Processing (NLP) techniques in the domain of tick-borne disease 
      text. The aim is to demonstrate the process of how the presence of bias in the 
      discourse surrounding chronic manifestations of the disease can be evaluated. The 
      goal is to use a dataset of 5643 abstracts collected from scientific journals on 
      the topic of chronic Lyme disease to demonstrate using Python, the steps for 
      conducting sentiment analysis using pretrained language models and the process of 
      validating the preliminary results using both interpretable machine learning 
      tools, as well as a novel methodology of leveraging emerging state-of-the-art 
      large language models like ChatGPT. This serves as a useful resource for 
      researchers and practitioners interested in using NLP techniques for sentiment 
      analysis in the medical domain.
CI  - © 2024. The Author(s), under exclusive license to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Susnjak, Teo
AU  - Susnjak T
AD  - School of Mathematical and Computational Sciences, Massey University, Auckland, 
      New Zealand. t.susnjak@massey.ac.nz.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Methods Mol Biol
JT  - Methods in molecular biology (Clifton, N.J.)
JID - 9214969
SB  - IM
MH  - Humans
MH  - *Sentiment Analysis
MH  - *Lyme Disease
MH  - Publications
MH  - Language
MH  - Machine Learning
OTO - NOTNLM
OT  - BERT
OT  - ChatGPT
OT  - Explainable AI
OT  - Language models
OT  - Lyme disease text analysis
OT  - NLP
OT  - SHAP
OT  - Sentiment analysis
EDAT- 2024/01/02 12:41
MHDA- 2024/01/04 11:43
CRDT- 2024/01/02 11:13
PHST- 2024/01/04 11:43 [medline]
PHST- 2024/01/02 12:41 [pubmed]
PHST- 2024/01/02 11:13 [entrez]
AID - 10.1007/978-1-0716-3561-2_14 [doi]
PST - ppublish
SO  - Methods Mol Biol. 2024;2742:173-183. doi: 10.1007/978-1-0716-3561-2_14.

PMID- 39890970
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250204
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 8
IP  - 1
DP  - 2025 Jan 31
TI  - Language models for data extraction and risk of bias assessment in complementary 
      medicine.
PG  - 74
LID - 10.1038/s41746-025-01457-w [doi]
LID - 74
AB  - Large language models (LLMs) have the potential to enhance evidence synthesis 
      efficiency and accuracy. This study assessed LLM-only and LLM-assisted methods in 
      data extraction and risk of bias assessment for 107 trials on complementary 
      medicine. Moonshot-v1-128k and Claude-3.5-sonnet achieved high accuracy (≥95%), 
      with LLM-assisted methods performing better (≥97%). LLM-assisted methods 
      significantly reduced processing time (14.7 and 5.9 min vs. 86.9 and 10.4 min for 
      conventional methods). These findings highlight LLMs' potential when integrated 
      with human expertise.
CI  - © 2025. The Author(s).
FAU - Lai, Honghao
AU  - Lai H
AUID- ORCID: 0000-0001-7913-6207
AD  - Department of Health Policy and Health Management, School of Public Health, 
      Lanzhou University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Liu, Jiayi
AU  - Liu J
AD  - Department of Health Policy and Health Management, School of Public Health, 
      Lanzhou University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Bai, Chunyang
AU  - Bai C
AD  - School of Nursing, Southern Medical University, Guangzhou, China.
FAU - Liu, Hui
AU  - Liu H
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
FAU - Pan, Bei
AU  - Pan B
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
FAU - Luo, Xufei
AU  - Luo X
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Research Unit of Evidence-Based Evaluation and Guidelines, Chinese Academy of 
      Medical Science, School of Basic Medical Sciences, Lanzhou University, Lanzhou, 
      China.
AD  - Key Laboratory of Evidence-Based Medicine of Gansu Province, Lanzhou University, 
      Lanzhou, China.
FAU - Hou, Liangying
AU  - Hou L
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Department of Health Research Methods, Evidence, and Impact, McMaster University, 
      Ontario, Canada.
FAU - Zhao, Weilong
AU  - Zhao W
AD  - Department of Health Policy and Health Management, School of Public Health, 
      Lanzhou University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Xia, Danni
AU  - Xia D
AD  - Department of Health Policy and Health Management, School of Public Health, 
      Lanzhou University, Lanzhou, China.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China.
FAU - Tian, Jinhui
AU  - Tian J
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Key Laboratory of Evidence-Based Medicine of Gansu Province, Lanzhou University, 
      Lanzhou, China.
AD  - WHO Collaborating Center for Guideline Implementation and Knowledge Translation, 
      Lanzhou, China.
FAU - Chen, Yaolong
AU  - Chen Y
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Key Laboratory of Evidence-Based Medicine of Gansu Province, Lanzhou University, 
      Lanzhou, China.
AD  - WHO Collaborating Center for Guideline Implementation and Knowledge Translation, 
      Lanzhou, China.
FAU - Zhang, Lu
AU  - Zhang L
AD  - Department of Computer Science, Hong Kong Baptist University, Hong Kong SAR, 
      China.
FAU - Estill, Janne
AU  - Estill J
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Institute of Global Health, University of Geneva, Geneva, Switzerland.
FAU - Liu, Jie
AU  - Liu J
AD  - Department of Oncology, Guang' anmen Hospital, China Academy of Chinese Medical 
      Sciences, Beijing, China.
FAU - Liao, Xing
AU  - Liao X
AD  - Institute of Basic Research of Clinical Medicine, China Academy of Chinese 
      Medical Sciences, Beijing, China.
FAU - Shi, Nannan
AU  - Shi N
AD  - Institute of Basic Research of Clinical Medicine, China Academy of Chinese 
      Medical Sciences, Beijing, China.
FAU - Sun, Xin
AU  - Sun X
AD  - Chinese Evidence-Based Medicine Center, West China Hospital, Sichuan University, 
      Chengdu, China.
FAU - Shang, Hongcai
AU  - Shang H
AD  - Dongzhimen Hospital, Beijing University of Chinese Medicine, Beijing, China.
FAU - Bian, Zhaoxiang
AU  - Bian Z
AD  - School of Chinese Medicine, Hong Kong Baptist University, Hong Kong SAR, China.
FAU - Yang, Kehu
AU  - Yang K
AD  - Evidence-Based Medicine Center, School of Basic Medical Sciences, Lanzhou 
      University, Lanzhou, China.
AD  - Key Laboratory of Evidence-Based Medicine of Gansu Province, Lanzhou University, 
      Lanzhou, China.
AD  - WHO Collaborating Center for Guideline Implementation and Knowledge Translation, 
      Lanzhou, China.
FAU - Huang, Luqi
AU  - Huang L
AD  - China Center for Evidence Based Traditional Chinese Medicine, China Academy of 
      Chinese Medical Sciences, Beijing, China. huanglugi01@126.com.
AD  - National Resource Center for Chinese Materia Medica, China Academy of Chinese 
      Medical Sciences, Beijing, China. huanglugi01@126.com.
FAU - Ge, Long
AU  - Ge L
AUID- ORCID: 0000-0002-3555-1107
AD  - Department of Health Policy and Health Management, School of Public Health, 
      Lanzhou University, Lanzhou, China. gelong2009@163.com.
AD  - Evidence-Based Social Science Research Center, School of Public Health, Lanzhou 
      University, Lanzhou, China. gelong2009@163.com.
AD  - WHO Collaborating Center for Guideline Implementation and Knowledge Translation, 
      Lanzhou, China. gelong2009@163.com.
CN  - ADVANCED Working Group
LA  - eng
PT  - Journal Article
DEP - 20250131
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC11785717
COIS- Competing interests: The authors declare no competing interests.
FIR - Li, Haodong
IR  - Li H
FIR - Wang, Ye
IR  - Wang Y
FIR - Zhang, Huayu
IR  - Zhang H
FIR - Zhu, Di
IR  - Zhu D
FIR - Peng, Dongrui
IR  - Peng D
FIR - Wang, Fan
IR  - Wang F
FIR - Li, Yueyan
IR  - Li Y
FIR - Tang, Shilin
IR  - Tang S
FIR - Liu, Hanxiang
IR  - Liu H
FIR - Li, Zeming
IR  - Li Z
FIR - Yang, Zhenhua
IR  - Yang Z
FIR - Yu, Xuan
IR  - Yu X
FIR - Qin, Yishan
IR  - Qin Y
EDAT- 2025/02/01 20:42
MHDA- 2025/02/01 20:43
PMCR- 2025/01/31
CRDT- 2025/01/31 23:31
PHST- 2024/07/02 00:00 [received]
PHST- 2025/01/15 00:00 [accepted]
PHST- 2025/02/01 20:43 [medline]
PHST- 2025/02/01 20:42 [pubmed]
PHST- 2025/01/31 23:31 [entrez]
PHST- 2025/01/31 00:00 [pmc-release]
AID - 10.1038/s41746-025-01457-w [pii]
AID - 1457 [pii]
AID - 10.1038/s41746-025-01457-w [doi]
PST - epublish
SO  - NPJ Digit Med. 2025 Jan 31;8(1):74. doi: 10.1038/s41746-025-01457-w.

PMID- 39352738
OWN - NLM
STAT- MEDLINE
DCOM- 20241001
LR  - 20241019
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Oct 1
TI  - "Doctor ChatGPT, Can You Help Me?" The Patient's Perspective: Cross-Sectional 
      Study.
PG  - e58831
LID - 10.2196/58831 [doi]
LID - e58831
AB  - BACKGROUND: Artificial intelligence and the language models derived from it, such 
      as ChatGPT, offer immense possibilities, particularly in the field of medicine. 
      It is already evident that ChatGPT can provide adequate and, in some cases, 
      expert-level responses to health-related queries and advice for patients. 
      However, it is currently unknown how patients perceive these capabilities, 
      whether they can derive benefit from them, and whether potential risks, such as 
      harmful suggestions, are detected by patients. OBJECTIVE: This study aims to 
      clarify whether patients can get useful and safe health care advice from an 
      artificial intelligence chatbot assistant. METHODS: This cross-sectional study 
      was conducted using 100 publicly available health-related questions from 5 
      medical specialties (trauma, general surgery, otolaryngology, pediatrics, and 
      internal medicine) from a web-based platform for patients. Responses generated by 
      ChatGPT-4.0 and by an expert panel (EP) of experienced physicians from the 
      aforementioned web-based platform were packed into 10 sets consisting of 10 
      questions each. The blinded evaluation was carried out by patients regarding 
      empathy and usefulness (assessed through the question: "Would this answer have 
      helped you?") on a scale from 1 to 5. As a control, evaluation was also performed 
      by 3 physicians in each respective medical specialty, who were additionally asked 
      about the potential harm of the response and its correctness. RESULTS: In total, 
      200 sets of questions were submitted by 64 patients (mean 45.7, SD 15.9 years; 
      29/64, 45.3% male), resulting in 2000 evaluated answers of ChatGPT and the EP 
      each. ChatGPT scored higher in terms of empathy (4.18 vs 2.7; P<.001) and 
      usefulness (4.04 vs 2.98; P<.001). Subanalysis revealed a small bias in terms of 
      levels of empathy given by women in comparison with men (4.46 vs 4.14; P=.049). 
      Ratings of ChatGPT were high regardless of the participant's age. The same highly 
      significant results were observed in the evaluation of the respective specialist 
      physicians. ChatGPT outperformed significantly in correctness (4.51 vs 3.55; 
      P<.001). Specialists rated the usefulness (3.93 vs 4.59) and correctness (4.62 vs 
      3.84) significantly lower in potentially harmful responses from ChatGPT (P<.001). 
      This was not the case among patients. CONCLUSIONS: The results indicate that 
      ChatGPT is capable of supporting patients in health-related queries better than 
      physicians, at least in terms of written advice through a web-based platform. In 
      this study, ChatGPT's responses had a lower percentage of potentially harmful 
      advice than the web-based EP. However, it is crucial to note that this finding is 
      based on a specific study design and may not generalize to all health care 
      settings. Alarmingly, patients are not able to independently recognize these 
      potential dangers.
CI  - ©Jonas Armbruster, Florian Bussmann, Catharina Rothhaas, Nadine Titze, Paul 
      Alfred Grützner, Holger Freischmidt. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 01.10.2024.
FAU - Armbruster, Jonas
AU  - Armbruster J
AUID- ORCID: 0009-0007-2486-665X
AD  - Department of Trauma and Orthopedic Surgery, BG Klinik Ludwigshafen, Ludwigshafen 
      am Rhein, Germany.
FAU - Bussmann, Florian
AU  - Bussmann F
AUID- ORCID: 0009-0007-1494-0895
AD  - Department of Trauma and Orthopedic Surgery, BG Klinik Ludwigshafen, Ludwigshafen 
      am Rhein, Germany.
FAU - Rothhaas, Catharina
AU  - Rothhaas C
AUID- ORCID: 0009-0003-7555-8447
AD  - Department of Trauma and Orthopedic Surgery, BG Klinik Ludwigshafen, Ludwigshafen 
      am Rhein, Germany.
FAU - Titze, Nadine
AU  - Titze N
AUID- ORCID: 0009-0007-9472-4921
AD  - Department of Trauma and Orthopedic Surgery, BG Klinik Ludwigshafen, Ludwigshafen 
      am Rhein, Germany.
FAU - Grützner, Paul Alfred
AU  - Grützner PA
AUID- ORCID: 0000-0002-0730-4782
AD  - Department of Trauma and Orthopedic Surgery, BG Klinik Ludwigshafen, Ludwigshafen 
      am Rhein, Germany.
FAU - Freischmidt, Holger
AU  - Freischmidt H
AUID- ORCID: 0000-0001-7309-478X
AD  - Department of Trauma and Orthopedic Surgery, BG Klinik Ludwigshafen, Ludwigshafen 
      am Rhein, Germany.
LA  - eng
PT  - Journal Article
DEP - 20241001
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - Male
MH  - Female
MH  - *Physician-Patient Relations
MH  - Adult
MH  - Middle Aged
MH  - Artificial Intelligence
MH  - Physicians/psychology
MH  - Internet
MH  - Empathy
MH  - Surveys and Questionnaires
PMC - PMC11480680
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - artificial intelligence
OT  - chatbot
OT  - chatbots
OT  - empathy
OT  - large language models
OT  - patient education
OT  - patient information
OT  - patient perceptions
COIS- Conflicts of Interest: None declared.
EDAT- 2024/10/01 12:44
MHDA- 2024/10/02 07:20
PMCR- 2024/10/01
CRDT- 2024/10/01 11:53
PHST- 2024/03/27 00:00 [received]
PHST- 2024/08/01 00:00 [accepted]
PHST- 2024/07/12 00:00 [revised]
PHST- 2024/10/02 07:20 [medline]
PHST- 2024/10/01 12:44 [pubmed]
PHST- 2024/10/01 11:53 [entrez]
PHST- 2024/10/01 00:00 [pmc-release]
AID - v26i1e58831 [pii]
AID - 10.2196/58831 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Oct 1;26:e58831. doi: 10.2196/58831.

PMID- 38664340
OWN - NLM
STAT- MEDLINE
DCOM- 20240829
LR  - 20241031
IS  - 1554-3528 (Electronic)
IS  - 1554-351X (Print)
IS  - 1554-351X (Linking)
VI  - 56
IP  - 7
DP  - 2024 Oct
TI  - A natural language model to automate scoring of autobiographical memories.
PG  - 6707-6720
LID - 10.3758/s13428-024-02385-5 [doi]
AB  - Biases in the retrieval of personal, autobiographical memories are a core feature 
      of multiple mental health disorders, and are associated with poor clinical 
      prognosis. However, current assessments of memory bias are either reliant on 
      human scoring, restricting their administration in clinical settings, or when 
      computerized, are only able to identify one memory type. Here, we developed a 
      natural language model able to classify text-based memories as one of five 
      different autobiographical memory types (specific, categoric, extended, semantic 
      associate, omission), allowing easy assessment of a wider range of memory biases, 
      including reduced memory specificity and impaired memory flexibility. Our model 
      was trained on 17,632 text-based, human-scored memories obtained from individuals 
      with and without experience of memory bias and mental health challenges, which 
      was then tested on a dataset of 5880 memories. We used 20-fold cross-validation 
      setup, and the model was fine-tuned over BERT. Relative to benchmarking and an 
      existing support vector model, our model achieved high accuracy (95.7%) and 
      precision (91.0%). We provide an open-source version of the model which is able 
      to be used without further coding, by those with no coding experience, to 
      facilitate the assessment of autobiographical memory bias in clinical settings, 
      and aid implementation of memory-based interventions within treatment services.
CI  - © 2024. The Author(s).
FAU - Mistica, Meladel
AU  - Mistica M
AD  - Melbourne Data Analytics Platform (MDAP), University of Melbourne, Melbourne 
      Connect, Carlton, 3053, Victoria, Australia. misticam@unimelb.edu.au.
FAU - Haylock, Patrick
AU  - Haylock P
AD  - Melbourne School of Psychological Sciences, University of Melbourne, Tin Alley, 
      Parkville, 3010, Victoria, Australia.
FAU - Michalewicz, Aleksandra
AU  - Michalewicz A
AD  - Melbourne Data Analytics Platform (MDAP), University of Melbourne, Melbourne 
      Connect, Carlton, 3053, Victoria, Australia.
FAU - Raad, Steph
AU  - Raad S
AD  - Melbourne School of Psychological Sciences, University of Melbourne, Tin Alley, 
      Parkville, 3010, Victoria, Australia.
FAU - Fitzgerald, Emily
AU  - Fitzgerald E
AD  - Melbourne Data Analytics Platform (MDAP), University of Melbourne, Melbourne 
      Connect, Carlton, 3053, Victoria, Australia.
FAU - Hitchcock, Caitlin
AU  - Hitchcock C
AUID- ORCID: 0000-0002-2435-0713
AD  - Melbourne School of Psychological Sciences, University of Melbourne, Tin Alley, 
      Parkville, 3010, Victoria, Australia. caitlin.hitchcock@unimelb.edu.au.
LA  - eng
GR  - DE200100043/Australian Research Council/
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240425
PL  - United States
TA  - Behav Res Methods
JT  - Behavior research methods
JID - 101244316
SB  - IM
MH  - Humans
MH  - *Memory, Episodic
MH  - Mental Recall/physiology
MH  - Female
MH  - Male
MH  - Adult
MH  - Natural Language Processing
MH  - Models, Psychological
MH  - Young Adult
PMC - PMC11362422
OTO - NOTNLM
OT  - AMT
OT  - Autobiographical memory task
OT  - Large language models
OT  - Natural language processing
EDAT- 2024/04/26 00:51
MHDA- 2024/08/31 09:45
PMCR- 2024/04/25
CRDT- 2024/04/25 23:18
PHST- 2024/02/26 00:00 [accepted]
PHST- 2024/08/31 09:45 [medline]
PHST- 2024/04/26 00:51 [pubmed]
PHST- 2024/04/25 23:18 [entrez]
PHST- 2024/04/25 00:00 [pmc-release]
AID - 10.3758/s13428-024-02385-5 [pii]
AID - 2385 [pii]
AID - 10.3758/s13428-024-02385-5 [doi]
PST - ppublish
SO  - Behav Res Methods. 2024 Oct;56(7):6707-6720. doi: 10.3758/s13428-024-02385-5. 
      Epub 2024 Apr 25.

PMID- 39937483
OWN - NLM
STAT- In-Process
LR  - 20250218
IS  - 2574-3805 (Electronic)
IS  - 2574-3805 (Linking)
VI  - 8
IP  - 2
DP  - 2025 Feb 3
TI  - Characterizing Spin in Psychiatric Clinical Research Literature Using Large 
      Language Models.
PG  - e2459500
LID - 10.1001/jamanetworkopen.2024.59500 [doi]
LID - e2459500
FAU - Perlis, Roy H
AU  - Perlis RH
AD  - Center for Quantitative Health, Massachusetts General Hospital, Boston.
AD  - Department of Psychiatry, Harvard Medical School, Boston, Massachusetts.
AD  - Associate Editor, JAMA Network Open.
LA  - eng
PT  - Journal Article
DEP - 20250203
PL  - United States
TA  - JAMA Netw Open
JT  - JAMA network open
JID - 101729235
SB  - IM
UOF - medRxiv. 2024 Jul 01:2024.06.30.24309737. doi: 10.1101/2024.06.30.24309737. PMID: 
      39006438
PMC - PMC11822530
OAB - This quality improvement study describes the use of a large language model (LLM) 
      to detect biased reporting in abstracts of psychiatric clinical research.
OABL- eng
COIS- Conflict of Interest Disclosures: Dr Perlis reported receiving personal fees from 
      Psy Therapeutics, Circular Genomics, Genomind, and Alkermes outside the submitted 
      work and being Editor in Chief of JAMA+ AI and Associate Editor of JAMA Network 
      Open. No other disclosures were reported.
EDAT- 2025/02/12 12:25
MHDA- 2025/02/12 12:25
PMCR- 2025/02/12
CRDT- 2025/02/12 11:33
PHST- 2025/02/12 12:25 [medline]
PHST- 2025/02/12 12:25 [pubmed]
PHST- 2025/02/12 11:33 [entrez]
PHST- 2025/02/12 00:00 [pmc-release]
AID - 2830120 [pii]
AID - zld240309 [pii]
AID - 10.1001/jamanetworkopen.2024.59500 [doi]
PST - epublish
SO  - JAMA Netw Open. 2025 Feb 3;8(2):e2459500. doi: 
      10.1001/jamanetworkopen.2024.59500.

PMID- 39436298
OWN - NLM
STAT- MEDLINE
DCOM- 20241022
LR  - 20241107
IS  - 1527-1315 (Electronic)
IS  - 0033-8419 (Print)
IS  - 0033-8419 (Linking)
VI  - 313
IP  - 1
DP  - 2024 Oct
TI  - Evaluating the Performance and Bias of Natural Language Processing Tools in 
      Labeling Chest Radiograph Reports.
PG  - e232746
LID - 10.1148/radiol.232746 [doi]
LID - e232746
AB  - Background Natural language processing (NLP) is commonly used to annotate 
      radiology datasets for training deep learning (DL) models. However, the accuracy 
      and potential biases of these NLP methods have not been thoroughly investigated, 
      particularly across different demographic groups. Purpose To evaluate the 
      accuracy and demographic bias of four NLP radiology report labeling tools on two 
      chest radiograph datasets. Materials and Methods This retrospective study, 
      performed between April 2022 and April 2024, evaluated chest radiograph report 
      labeling using four NLP tools (CheXpert [rule-based], RadReportAnnotator [RRA; 
      DL-based], OpenAI's GPT-4 [DL-based], cTAKES [hybrid]) on a subset of the Medical 
      Information Mart for Intensive Care (MIMIC) chest radiograph dataset balanced for 
      representation of age, sex, and race and ethnicity (n = 692) and the entire 
      Indiana University (IU) chest radiograph dataset (n = 3665). Three 
      board-certified radiologists annotated the chest radiograph reports for 14 
      thoracic disease labels. NLP tool performance was evaluated using several 
      metrics, including accuracy and error rate. Bias was evaluated by comparing 
      performance between demographic subgroups using the Pearson χ(2) test. Results 
      The IU dataset included 3665 patients (mean age, 49.7 years ± 17 [SD]; 1963 
      female), while the MIMIC dataset included 692 patients (mean age, 54.1 years ± 
      23.1; 357 female). All four NLP tools demonstrated high accuracy across findings 
      in the IU and MIMIC datasets, as follows: CheXpert (92.6% [47 516 of 51 310], 
      90.2% [8742 of 9688]), RRA (82.9% [19 746 of 23 829], 92.2% [2870 of 3114]), 
      GPT-4 (94.3% [45 586 of 48 342], 91.6% [6721 of 7336]), and cTAKES (84.7% [43 436 
      of 51 310], 88.7% [8597 of 9688]). RRA and cTAKES had higher accuracy (P < .001) 
      on the MIMIC dataset, while CheXpert and GPT-4 had higher accuracy on the IU 
      dataset. Differences (P < .001) in error rates were observed across age groups 
      for all NLP tools except RRA on the MIMIC dataset, with the highest error rates 
      for CheXpert, RRA, and cTAKES in patients older than 80 years (mean, 15.8% ± 5.0) 
      and the highest error rate for GPT-4 in patients 60-80 years of age (8.3%). 
      Conclusion Although commonly used NLP tools for chest radiograph report 
      annotation are accurate when evaluating reports in aggregate, demographic 
      subanalyses showed significant bias, with poorer performance in older patients. © 
      RSNA, 2024 Supplemental material is available for this article. See also the 
      editorial by Cai in this issue.
FAU - Santomartino, Samantha M
AU  - Santomartino SM
AUID- ORCID: 0000-0001-5229-2576
AD  - From Drexel University College of Medicine, Philadelphia, Pa (S.M.S.); Department 
      of Radiology, Columbia University Irving Medical Center, New York, NY (J.R.Z.); 
      Department of Radiology, Wake Forest University Health Sciences Center, 
      Winston-Salem, NC (K.H.); Department of Diagnostic Radiology and Nuclear 
      Medicine, University of Maryland School of Medicine, Baltimore, Md (J.J., V.P.); 
      and Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 262 
      Danny Thomas Plc, Memphis, TN 38105-3678 (P.H.Y.).
FAU - Zech, John R
AU  - Zech JR
AUID- ORCID: 0000-0003-1317-8951
AD  - From Drexel University College of Medicine, Philadelphia, Pa (S.M.S.); Department 
      of Radiology, Columbia University Irving Medical Center, New York, NY (J.R.Z.); 
      Department of Radiology, Wake Forest University Health Sciences Center, 
      Winston-Salem, NC (K.H.); Department of Diagnostic Radiology and Nuclear 
      Medicine, University of Maryland School of Medicine, Baltimore, Md (J.J., V.P.); 
      and Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 262 
      Danny Thomas Plc, Memphis, TN 38105-3678 (P.H.Y.).
FAU - Hall, Kent
AU  - Hall K
AD  - From Drexel University College of Medicine, Philadelphia, Pa (S.M.S.); Department 
      of Radiology, Columbia University Irving Medical Center, New York, NY (J.R.Z.); 
      Department of Radiology, Wake Forest University Health Sciences Center, 
      Winston-Salem, NC (K.H.); Department of Diagnostic Radiology and Nuclear 
      Medicine, University of Maryland School of Medicine, Baltimore, Md (J.J., V.P.); 
      and Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 262 
      Danny Thomas Plc, Memphis, TN 38105-3678 (P.H.Y.).
FAU - Jeudy, Jean
AU  - Jeudy J
AUID- ORCID: 0000-0002-6028-459X
AD  - From Drexel University College of Medicine, Philadelphia, Pa (S.M.S.); Department 
      of Radiology, Columbia University Irving Medical Center, New York, NY (J.R.Z.); 
      Department of Radiology, Wake Forest University Health Sciences Center, 
      Winston-Salem, NC (K.H.); Department of Diagnostic Radiology and Nuclear 
      Medicine, University of Maryland School of Medicine, Baltimore, Md (J.J., V.P.); 
      and Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 262 
      Danny Thomas Plc, Memphis, TN 38105-3678 (P.H.Y.).
FAU - Parekh, Vishwa
AU  - Parekh V
AD  - From Drexel University College of Medicine, Philadelphia, Pa (S.M.S.); Department 
      of Radiology, Columbia University Irving Medical Center, New York, NY (J.R.Z.); 
      Department of Radiology, Wake Forest University Health Sciences Center, 
      Winston-Salem, NC (K.H.); Department of Diagnostic Radiology and Nuclear 
      Medicine, University of Maryland School of Medicine, Baltimore, Md (J.J., V.P.); 
      and Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 262 
      Danny Thomas Plc, Memphis, TN 38105-3678 (P.H.Y.).
FAU - Yi, Paul H
AU  - Yi PH
AUID- ORCID: 0000-0001-9433-8093
AD  - From Drexel University College of Medicine, Philadelphia, Pa (S.M.S.); Department 
      of Radiology, Columbia University Irving Medical Center, New York, NY (J.R.Z.); 
      Department of Radiology, Wake Forest University Health Sciences Center, 
      Winston-Salem, NC (K.H.); Department of Diagnostic Radiology and Nuclear 
      Medicine, University of Maryland School of Medicine, Baltimore, Md (J.J., V.P.); 
      and Department of Diagnostic Imaging, St. Jude Children's Research Hospital, 262 
      Danny Thomas Plc, Memphis, TN 38105-3678 (P.H.Y.).
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Radiology
JT  - Radiology
JID - 0401260
SB  - IM
MH  - *Natural Language Processing
MH  - Humans
MH  - *Radiography, Thoracic/methods
MH  - Male
MH  - Female
MH  - Retrospective Studies
MH  - Middle Aged
MH  - Aged
MH  - Adult
MH  - Deep Learning
MH  - Bias
PMC - PMC11535863
COIS- Disclosures of conflicts of interest: S.M.S. No relevant relationships. J.R.Z. 
      Grant from RSNA R&E Foundation; editorial board member, Radiology: Artificial 
      Intelligence. K.H. No relevant relationships. J.J. No relevant relationships. 
      V.P. No relevant relationships. P.H.Y. Grants or contracts from National 
      Institutes of Health–National Cancer Institute, American College of Radiology 
      (ACR), RSNA, Johns Hopkins University, and University of Maryland; meeting 
      attendance support from Society for Imaging Informatics in Medicine (SIIM) and 
      Society of Nuclear Medicine and Molecular Imaging; vice chair of Program Planning 
      Committee, SIIM; Informatics Commission, ACR; stock or stock options in 
      Bunkerhill Health; editorial board member, Radiology: Artificial Intelligence.
EDAT- 2024/10/22 16:24
MHDA- 2024/10/22 16:25
PMCR- 2025/10/01
CRDT- 2024/10/22 10:03
PHST- 2025/10/01 00:00 [pmc-release]
PHST- 2024/10/22 16:25 [medline]
PHST- 2024/10/22 16:24 [pubmed]
PHST- 2024/10/22 10:03 [entrez]
AID - 10.1148/radiol.232746 [doi]
PST - ppublish
SO  - Radiology. 2024 Oct;313(1):e232746. doi: 10.1148/radiol.232746.

PMID- 35811026
OWN - NLM
STAT- MEDLINE
DCOM- 20220815
LR  - 20240902
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Print)
IS  - 1532-0464 (Linking)
VI  - 132
DP  - 2022 Aug
TI  - Trustworthy assertion classification through prompting.
PG  - 104139
LID - S1532-0464(22)00153-8 [pii]
LID - 10.1016/j.jbi.2022.104139 [doi]
AB  - Accurate identification of the presence, absence or possibility of relevant 
      entities in clinical notes is important for healthcare professionals to quickly 
      understand crucial clinical information. This introduces the task of assertion 
      classification - to correctly identify the assertion status of an entity in the 
      unstructured clinical notes. Recent rule-based and machine-learning approaches 
      suffer from labor-intensive pattern engineering and severe class bias toward 
      majority classes. To solve this problem, in this study, we propose a prompt-based 
      learning approach, which treats the assertion classification task as a masked 
      language auto-completion problem. We evaluated the model on six datasets. Our 
      prompt-based method achieved a micro-averaged F-1 of 0.954 on the i2b2 2010 
      assertion dataset, with ∼1.8% improvements over previous works. In particular, 
      our model showed excellence in detecting classes with few instances (few-shot). 
      Evaluations on five external datasets showcase the outstanding generalizability 
      of the prompt-based method to unseen data. To examine the rationality of our 
      model, we further introduced two rationale faithfulness metrics: 
      comprehensiveness and sufficiency. The results reveal that compared to the 
      "pre-train, fine-tune" procedure, our prompt-based model has a stronger 
      capability of identifying the comprehensive (∼63.93%) and sufficient (∼11.75%) 
      linguistic features from free text. We further evaluated the model-agnostic 
      explanations using LIME. The results imply a better rationale agreement between 
      our model and human beings (∼71.93% in average F-1), which demonstrates the 
      superior trustworthiness of our model.
CI  - Copyright © 2022 Elsevier Inc. All rights reserved.
FAU - Wang, Song
AU  - Wang S
AD  - School of Information, University of Texas at Austin, Austin, TX, USA.
FAU - Tang, Liyan
AU  - Tang L
AD  - School of Information, University of Texas at Austin, Austin, TX, USA.
FAU - Majety, Akash
AU  - Majety A
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      USA.
FAU - Rousseau, Justin F
AU  - Rousseau JF
AD  - Departments of Population Health and Neurology, Dell Medical School, Austin, TX, 
      USA.
FAU - Shih, George
AU  - Shih G
AD  - Department of Radiology, Weill Cornell Medicine, New York, NY, USA.
FAU - Ding, Ying
AU  - Ding Y
AD  - School of Information, University of Texas at Austin, Austin, TX, USA.
FAU - Peng, Yifan
AU  - Peng Y
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      USA. Electronic address: yip4002@med.cornell.edu.
LA  - eng
GR  - R00 LM013001/LM/NLM NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
DEP - 20220708
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - *Electronic Health Records
MH  - Humans
MH  - Linguistics
MH  - Machine Learning
MH  - *Natural Language Processing
PMC - PMC9378721
MID - NIHMS1823665
OTO - NOTNLM
OT  - Concept assertion
OT  - Deep learning
OT  - NLP
OT  - Prompt-based learning
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2022/07/11 06:00
MHDA- 2022/08/16 06:00
PMCR- 2022/08/16
CRDT- 2022/07/10 19:27
PHST- 2022/04/19 00:00 [received]
PHST- 2022/07/01 00:00 [revised]
PHST- 2022/07/05 00:00 [accepted]
PHST- 2022/07/11 06:00 [pubmed]
PHST- 2022/08/16 06:00 [medline]
PHST- 2022/07/10 19:27 [entrez]
PHST- 2022/08/16 00:00 [pmc-release]
AID - S1532-0464(22)00153-8 [pii]
AID - 10.1016/j.jbi.2022.104139 [doi]
PST - ppublish
SO  - J Biomed Inform. 2022 Aug;132:104139. doi: 10.1016/j.jbi.2022.104139. Epub 2022 
      Jul 8.

PMID- 39105570
OWN - NLM
STAT- MEDLINE
DCOM- 20240806
LR  - 20250124
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 11
DP  - 2024 Jul 29
TI  - The Opportunities and Risks of Large Language Models in Mental Health.
PG  - e59479
LID - 10.2196/59479 [doi]
LID - e59479
AB  - Global rates of mental health concerns are rising, and there is increasing 
      realization that existing models of mental health care will not adequately expand 
      to meet the demand. With the emergence of large language models (LLMs) has come 
      great optimism regarding their promise to create novel, large-scale solutions to 
      support mental health. Despite their nascence, LLMs have already been applied to 
      mental health-related tasks. In this paper, we summarize the extant literature on 
      efforts to use LLMs to provide mental health education, assessment, and 
      intervention and highlight key opportunities for positive impact in each area. We 
      then highlight risks associated with LLMs' application to mental health and 
      encourage the adoption of strategies to mitigate these risks. The urgent need for 
      mental health support must be balanced with responsible development, testing, and 
      deployment of mental health LLMs. It is especially critical to ensure that mental 
      health LLMs are fine-tuned for mental health, enhance mental health equity, and 
      adhere to ethical standards and that people, including those with lived 
      experience with mental health concerns, are involved in all stages from 
      development through deployment. Prioritizing these efforts will minimize 
      potential harms to mental health and maximize the likelihood that LLMs will 
      positively impact mental health globally.
CI  - © Hannah R Lawrence, Renee A Schneider, Susan B Rubin, Maja J Matarić, Daniel J 
      McDuff, Megan Jones Bell. Originally published in JMIR Mental Health 
      (https://mental.jmir.org).
FAU - Lawrence, Hannah R
AU  - Lawrence HR
AUID- ORCID: 0000-0001-6976-3426
AD  - Google via Magnit, Folsom, CA, United States.
FAU - Schneider, Renee A
AU  - Schneider RA
AUID- ORCID: 0009-0001-3073-4369
AD  - Google LLC, Mountain View, CA, 90291, United States, 13103106000.
FAU - Rubin, Susan B
AU  - Rubin SB
AUID- ORCID: 0009-0006-8413-6897
AD  - Google via Magnit, Folsom, CA, United States.
FAU - Matarić, Maja J
AU  - Matarić MJ
AUID- ORCID: 0000-0001-8958-6666
AD  - Google LLC, Mountain View, CA, 90291, United States, 13103106000.
FAU - McDuff, Daniel J
AU  - McDuff DJ
AUID- ORCID: 0000-0001-7313-0082
AD  - Google LLC, Mountain View, CA, 90291, United States, 13103106000.
FAU - Jones Bell, Megan
AU  - Jones Bell M
AUID- ORCID: 0000-0002-0514-5888
AD  - Google LLC, Mountain View, CA, 90291, United States, 13103106000.
LA  - eng
PT  - Journal Article
DEP - 20240729
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - Language
MH  - Mental Disorders/epidemiology
MH  - Mental Health
MH  - *Mental Health Services
PMC - PMC11301767
OTO - NOTNLM
OT  - AI
OT  - artificial intelligence
OT  - deployment
OT  - development
OT  - ethical
OT  - generative AI
OT  - health equity
OT  - language model
OT  - large language models
OT  - mental health
OT  - mental health care
OT  - mental health education
COIS- RAS, MJM, DJM, and MJB are employees of Google and receive monetary compensation 
      from Google and equity in Google's parent company, Alphabet. HRL and SBR are 
      employees of, and receive compensation from, Magnit and are contracted for work 
      at Google. In addition, MJB is a shareholder in Meeno Technologies, Inc and The 
      Orange Dot (Headspace Health). RAS is a shareholder in Lyra Health and Trek 
      Health, and she consults with Understood.
EDAT- 2024/08/06 12:43
MHDA- 2024/08/06 12:44
PMCR- 2024/07/29
CRDT- 2024/08/06 08:43
PHST- 2024/04/13 00:00 [received]
PHST- 2024/05/31 00:00 [revised]
PHST- 2024/06/01 00:00 [accepted]
PHST- 2024/08/06 12:44 [medline]
PHST- 2024/08/06 12:43 [pubmed]
PHST- 2024/08/06 08:43 [entrez]
PHST- 2024/07/29 00:00 [pmc-release]
AID - v11i1e59479 [pii]
AID - 59479 [pii]
AID - 10.2196/59479 [doi]
PST - epublish
SO  - JMIR Ment Health. 2024 Jul 29;11:e59479. doi: 10.2196/59479.

PMID- 38511501
OWN - NLM
STAT- MEDLINE
DCOM- 20240822
LR  - 20250321
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 9
DP  - 2024 Sep 1
TI  - Leveraging large language models to foster equity in healthcare.
PG  - 2147-2150
LID - 10.1093/jamia/ocae055 [doi]
AB  - OBJECTIVES: Large language models (LLMs) are poised to change care delivery, but 
      their impact on health equity is unclear. While marginalized populations have 
      been historically excluded from early technology developments, LLMs present an 
      opportunity to change our approach to developing, evaluating, and implementing 
      new technologies. In this perspective, we describe the role of LLMs in supporting 
      health equity. MATERIALS AND METHODS: We apply the National Institute on Minority 
      Health and Health Disparities (NIMHD) research framework to explore the use of 
      LLMs for health equity. RESULTS: We present opportunities for how LLMs can 
      improve health equity across individual, family and organizational, community, 
      and population health. We describe emerging concerns including biased data, 
      limited technology diffusion, and privacy. Finally, we highlight recommendations 
      focused on prompt engineering, retrieval augmentation, digital inclusion, 
      transparency, and bias mitigation. CONCLUSION: The potential of LLMs to support 
      health equity depends on making health equity a focus from the start.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Rodriguez, Jorge A
AU  - Rodriguez JA
AUID- ORCID: 0000-0002-1833-6819
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, MA 02115, United States.
AD  - Harvard Medical School, Boston, MA 02115, United States.
FAU - Alsentzer, Emily
AU  - Alsentzer E
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, MA 02115, United States.
AD  - Harvard Medical School, Boston, MA 02115, United States.
FAU - Bates, David W
AU  - Bates DW
AUID- ORCID: 0000-0001-6268-1540
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, MA 02115, United States.
AD  - Harvard Medical School, Boston, MA 02115, United States.
LA  - eng
GR  - K23 MD016439/MD/NIMHD NIH HHS/United States
GR  - K23MD016439/National Institute of Minority Health and Health Disparities/
GR  - NH/NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - *Health Equity
MH  - Humans
MH  - United States
MH  - Delivery of Health Care
MH  - Healthcare Disparities
MH  - Language
PMC - PMC11339521
OTO - NOTNLM
OT  - artificial intelligence
OT  - digital inclusion
OT  - health disparities
OT  - health equity
COIS- D.W.B. reports grants and personal fees from EarlySense, personal fees from CDI 
      Negev, equity from ValeraHealth, equity from Clew, equity from MDClone, personal 
      fees and equity from AESOP, personal fees and equity from FeelBetter, personal 
      fees and equity from Guided Clinical Solutions, and grants from IBM Watson 
      Health, outside the submitted work. Additional authors do not have competing 
      interests to declare.
EDAT- 2024/03/21 12:45
MHDA- 2024/08/22 06:42
PMCR- 2025/03/20
CRDT- 2024/03/21 06:13
PHST- 2023/11/28 00:00 [received]
PHST- 2024/02/08 00:00 [revised]
PHST- 2024/02/28 00:00 [accepted]
PHST- 2024/08/22 06:42 [medline]
PHST- 2024/03/21 12:45 [pubmed]
PHST- 2024/03/21 06:13 [entrez]
PHST- 2025/03/20 00:00 [pmc-release]
AID - 7632598 [pii]
AID - ocae055 [pii]
AID - 10.1093/jamia/ocae055 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Sep 1;31(9):2147-2150. doi: 10.1093/jamia/ocae055.

PMID- 39283333
OWN - NLM
STAT- MEDLINE
DCOM- 20250210
LR  - 20250314
IS  - 1872-6623 (Electronic)
IS  - 0304-3959 (Linking)
VI  - 166
IP  - 3
DP  - 2025 Mar 1
TI  - Racial, ethnic, and sex bias in large language model opioid recommendations for 
      pain management.
PG  - 511-517
LID - 10.1097/j.pain.0000000000003388 [doi]
AB  - Understanding how large language model (LLM) recommendations vary with patient 
      race/ethnicity provides insight into how LLMs may counter or compound bias in 
      opioid prescription. Forty real-world patient cases were sourced from the 
      MIMIC-IV Note dataset with chief complaints of abdominal pain, back pain, 
      headache, or musculoskeletal pain and amended to include all combinations of 
      race/ethnicity and sex. Large language models were instructed to provide a 
      subjective pain rating and comprehensive pain management recommendation. 
      Univariate analyses were performed to evaluate the association between 
      racial/ethnic group or sex and the specified outcome measures-subjective pain 
      rating, opioid name, order, and dosage recommendations-suggested by 2 LLMs (GPT-4 
      and Gemini). Four hundred eighty real-world patient cases were provided to each 
      LLM, and responses included pharmacologic and nonpharmacologic interventions. 
      Tramadol was the most recommended weak opioid in 55.4% of cases, while oxycodone 
      was the most frequently recommended strong opioid in 33.2% of cases. Relative to 
      GPT-4, Gemini was more likely to rate a patient's pain as "severe" (OR: 0.57 95% 
      CI: [0.54, 0.60]; P < 0.001), recommend strong opioids (OR: 2.05 95% CI: [1.59, 
      2.66]; P < 0.001), and recommend opioids later (OR: 1.41 95% CI: [1.22, 1.62]; P 
      < 0.001). Race/ethnicity and sex did not influence LLM recommendations. This 
      study suggests that LLMs do not preferentially recommend opioid treatment for one 
      group over another. Given that prior research shows race-based disparities in 
      pain perception and treatment by healthcare providers, LLMs may offer physicians 
      a helpful tool to guide their pain management and ensure equitable treatment 
      across patient groups.
CI  - Copyright © 2024 International Association for the Study of Pain.
FAU - Young, Cameron C
AU  - Young CC
AUID- ORCID: 0000-0001-7323-4834
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Mass General Brigham, Boston, MA, United States.
FAU - Enichen, Elizabeth
AU  - Enichen E
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Mass General Brigham, Boston, MA, United States.
FAU - Rao, Arya
AU  - Rao A
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Mass General Brigham, Boston, MA, United States.
FAU - Succi, Marc D
AU  - Succi MD
AUID- ORCID: 0000-0002-1518-3984
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Mass General Brigham, Boston, MA, United States.
AD  - Department of Radiology, Massachusetts General Hospital, Boston, MA, United 
      States.
AD  - Enterprise Radiology, Mass General Brigham, Boston, MA, United States.
LA  - eng
GR  - T32 GM144273/GM/NIGMS NIH HHS/United States
GR  - T32GM144273/GM/NIGMS NIH HHS/United States
PT  - Journal Article
DEP - 20240906
PL  - United States
TA  - Pain
JT  - Pain
JID - 7508686
RN  - 0 (Analgesics, Opioid)
SB  - IM
MH  - Humans
MH  - *Analgesics, Opioid/therapeutic use
MH  - Female
MH  - Male
MH  - *Pain Management/methods
MH  - Middle Aged
MH  - Sexism
MH  - Adult
MH  - Ethnicity
MH  - Pain Measurement/methods
MH  - Aged
MH  - Language
MH  - Pain/drug therapy/ethnology
MH  - Practice Patterns, Physicians'/statistics & numerical data
EDAT- 2024/09/17 10:43
MHDA- 2025/02/10 18:16
CRDT- 2024/09/16 11:03
PHST- 2024/04/30 00:00 [received]
PHST- 2024/07/09 00:00 [accepted]
PHST- 2025/02/10 18:16 [medline]
PHST- 2024/09/17 10:43 [pubmed]
PHST- 2024/09/16 11:03 [entrez]
AID - 00006396-990000000-00700 [pii]
AID - 10.1097/j.pain.0000000000003388 [doi]
PST - ppublish
SO  - Pain. 2025 Mar 1;166(3):511-517. doi: 10.1097/j.pain.0000000000003388. Epub 2024 
      Sep 6.

PMID- 38290759
OWN - NLM
STAT- MEDLINE
DCOM- 20240201
LR  - 20241023
IS  - 2009-8774 (Electronic)
IS  - 2305-6983 (Print)
IS  - 2305-6983 (Linking)
VI  - 12
IP  - Suppl 1
DP  - 2024 Jan 30
TI  - Potential applications and implications of large language models in primary care.
LID - 10.1136/fmch-2023-002602 [doi]
LID - e002602
AB  - The recent release of highly advanced generative artificial intelligence (AI) 
      chatbots, including ChatGPT and Bard, which are powered by large language models 
      (LLMs), has attracted growing mainstream interest over its diverse applications 
      in clinical practice, including in health and healthcare. The potential 
      applications of LLM-based programmes in the medical field range from assisting 
      medical practitioners in improving their clinical decision-making and 
      streamlining administrative paperwork to empowering patients to take charge of 
      their own health. However, despite the broad range of benefits, the use of such 
      AI tools also comes with several limitations and ethical concerns that warrant 
      further consideration, encompassing issues related to privacy, data bias, and the 
      accuracy and reliability of information generated by AI. The focus of prior 
      research has primarily centred on the broad applications of LLMs in medicine. To 
      the author's knowledge, this is, the first article that consolidates current and 
      pertinent literature on LLMs to examine its potential in primary care. The 
      objectives of this paper are not only to summarise the potential benefits, risks 
      and challenges of using LLMs in primary care, but also to offer insights into 
      considerations that primary care clinicians should take into account when 
      deciding to adopt and integrate such technologies into their clinical practice.
CI  - © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Andrew, Albert
AU  - Andrew A
AUID- ORCID: 0000-0002-9451-4533
AD  - Medical Student, The University of Auckland School of Medicine, Auckland, New 
      Zealand albertandrew@hotmail.co.nz aand273@aucklanduni.ac.nz.
LA  - eng
PT  - Journal Article
DEP - 20240130
PL  - England
TA  - Fam Med Community Health
JT  - Family medicine and community health
JID - 101700650
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Clinical Decision-Making
MH  - Language
MH  - Primary Health Care
PMC - PMC10828839
OTO - NOTNLM
OT  - Delivery of Health Care, Integrated
OT  - Family Medicine
OT  - General Practice
OT  - Health Services Research
COIS- Competing interests: None declared.
EDAT- 2024/01/31 00:42
MHDA- 2024/02/01 06:42
PMCR- 2024/01/30
CRDT- 2024/01/30 21:03
PHST- 2023/10/26 00:00 [received]
PHST- 2024/01/16 00:00 [accepted]
PHST- 2024/02/01 06:42 [medline]
PHST- 2024/01/31 00:42 [pubmed]
PHST- 2024/01/30 21:03 [entrez]
PHST- 2024/01/30 00:00 [pmc-release]
AID - fmch-2023-002602 [pii]
AID - 10.1136/fmch-2023-002602 [doi]
PST - epublish
SO  - Fam Med Community Health. 2024 Jan 30;12(Suppl 1):e002602. doi: 
      10.1136/fmch-2023-002602.

PMID- 34004017
OWN - NLM
STAT- MEDLINE
DCOM- 20210809
LR  - 20210809
IS  - 1520-6629 (Electronic)
IS  - 0090-4392 (Linking)
VI  - 49
IP  - 6
DP  - 2021 Aug
TI  - Examining the concept of equity in community psychology with natural language 
      processing.
PG  - 1718-1731
LID - 10.1002/jcop.22603 [doi]
AB  - Large amounts of text-based data, like study abstracts, often go unanalyzed 
      because the task is laborious. Natural language processing (NLP) uses 
      computer-based algorithms not traditionally implemented in community psychology 
      to effectively and efficiently process text. These methods include examining the 
      frequency of words and phrases, the clustering of topics, and the 
      interrelationships of words. This article applied NLP to explore the concept of 
      equity in community psychology. The COVID-19 crisis has made pre-existing health 
      equity gaps even more salient. Community psychology has a specific interest in 
      working with organizations, systems, and communities to address social 
      determinants that perpetuate inequities by refocusing interventions around 
      achieving health and wellness for all. This article examines how community 
      psychology has discussed equity thus far to identify strengths and gaps for 
      future research and practice. The results showed the prominence of 
      community-based participatory research and the diversity of settings researchers 
      work in. However, the total number of abstracts with equity concepts was lower 
      than expected, which suggests there is a need for a continued focus on equity.
CI  - © 2021 Wiley Periodicals LLC.
FAU - Scaccia, Jonathan P
AU  - Scaccia JP
AUID- ORCID: 0000-0001-6800-1286
AD  - Research and Evaluation, Dawn Chorus Group, Reading, Pennsylvania, USA.
LA  - eng
PT  - Journal Article
DEP - 20210518
PL  - United States
TA  - J Community Psychol
JT  - Journal of community psychology
JID - 0367033
SB  - IM
MH  - Community Psychiatry/*methods
MH  - Community-Based Participatory Research/*methods
MH  - Health Equity/*statistics & numerical data
MH  - Humans
MH  - Knowledge Discovery/*methods
MH  - *Natural Language Processing
MH  - Periodicals as Topic
MH  - Social Determinants of Health/*statistics & numerical data
OTO - NOTNLM
OT  - community-based participatory research
OT  - equity
OT  - natural language processing
OT  - synthesis
OT  - text-mining
EDAT- 2021/05/19 06:00
MHDA- 2021/08/10 06:00
CRDT- 2021/05/18 17:23
PHST- 2021/03/31 00:00 [revised]
PHST- 2020/12/01 00:00 [received]
PHST- 2021/04/30 00:00 [accepted]
PHST- 2021/05/19 06:00 [pubmed]
PHST- 2021/08/10 06:00 [medline]
PHST- 2021/05/18 17:23 [entrez]
AID - 10.1002/jcop.22603 [doi]
PST - ppublish
SO  - J Community Psychol. 2021 Aug;49(6):1718-1731. doi: 10.1002/jcop.22603. Epub 2021 
      May 18.

PMID- 37151853
OWN - NLM
STAT- MEDLINE
DCOM- 20230509
LR  - 20230602
IS  - 2212-277X (Electronic)
IS  - 2212-2761 (Print)
IS  - 2212-2761 (Linking)
VI  - 12
IP  - 1
DP  - 2023
TI  - Utilizing Natural Language Processing of Narrative Feedback to Develop a 
      Predictive Model of Pre-Clerkship Performance: Lessons Learned.
PG  - 141-148
LID - 10.5334/pme.40 [doi]
AB  - BACKGROUND: Natural language processing is a promising technique that can be used 
      to create efficiencies in the review of narrative feedback to learners. The 
      Feinberg School of Medicine has implemented formal review of pre-clerkship 
      narrative feedback since 2014 through its portfolio assessment system but this 
      process requires considerable time and effort. This article describes how natural 
      language processing was used to build a predictive model of pre-clerkship student 
      performance that can be utilized to assist competency committee reviews. 
      APPROACH: The authors took an iterative and inductive approach to the analysis, 
      which allowed them to identify characteristics of narrative feedback that are 
      both predictive of performance and useful to faculty reviewers. Words and phrases 
      were manually grouped into topics that represented concepts illustrating student 
      performance. Topics were reviewed by experienced reviewers, tested for 
      consistency across time, and checked to ensure they did not demonstrate bias. 
      OUTCOMES: Sixteen topic groups of words and phrases were found to be predictive 
      of performance. The best-fitting model used a combination of topic groups, word 
      counts, and categorical ratings. The model had an AUC value of 0.92 on the 
      training data and 0.88 on the test data. REFLECTION: A thoughtful, careful 
      approach to using natural language processing was essential. Given the 
      idiosyncrasies of narrative feedback in medical education, standard natural 
      language processing packages were not adequate for predicting student outcomes. 
      Rather, employing qualitative techniques including repeated member checking and 
      iterative revision resulted in a useful and salient predictive model.
CI  - Copyright: © 2023 The Author(s).
FAU - Maimone, Christina
AU  - Maimone C
AUID- ORCID: 0000-0002-0402-6297
AD  - Associate director of research data services, Northwestern IT Research Computing 
      Services, Northwestern University, Evanston, Illinois, USA.
FAU - Dolan, Brigid M
AU  - Dolan BM
AUID- ORCID: 0000-0002-3241-6778
AD  - Associate professor of medicine and medical education and director of assessment, 
      Northwestern University Feinberg School of Medicine, Chicago, Illinois, USA.
FAU - Green, Marianne M
AU  - Green MM
AUID- ORCID: 0000-0002-0721-2095
AD  - Raymond H. Curry, MD Professor of Medical Education, professor of medicine, and 
      vice dean for education, Northwestern University Feinberg School of Medicine, 
      Chicago, Illinois, USA.
FAU - Sanguino, Sandra M
AU  - Sanguino SM
AUID- ORCID: 0009-0003-1425-1548
AD  - Associate professor of pediatrics and senior associate dean of medical education, 
      Northwestern University Feinberg School of Medicine, Chicago, Illinois, USA.
FAU - Garcia, Patricia M
AU  - Garcia PM
AUID- ORCID: 0000-0001-5676-5983
AD  - Professor of obstetrics and gynecology and medical education, Northwestern 
      University Feinberg School of Medicine, Chicago, Illinois, USA.
FAU - O'Brien, Celia Laird
AU  - O'Brien CL
AUID- ORCID: 0000-0001-9352-4417
AD  - Assistant professor of medical education and assistant dean of program evaluation 
      and accreditation, Northwestern University Feinberg School of Medicine, Chicago, 
      Illinois, USA.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230503
PL  - Netherlands
TA  - Perspect Med Educ
JT  - Perspectives on medical education
JID - 101590643
SB  - IM
MH  - Humans
MH  - Natural Language Processing
MH  - Feedback
MH  - *Education, Medical
MH  - Narration
MH  - *Students, Medical
PMC - PMC10162355
COIS- The authors have no competing interests to declare.
EDAT- 2023/05/08 06:41
MHDA- 2023/05/09 06:42
PMCR- 2023/05/03
CRDT- 2023/05/08 03:54
PHST- 2022/10/20 00:00 [received]
PHST- 2023/04/19 00:00 [accepted]
PHST- 2023/05/09 06:42 [medline]
PHST- 2023/05/08 06:41 [pubmed]
PHST- 2023/05/08 03:54 [entrez]
PHST- 2023/05/03 00:00 [pmc-release]
AID - 10.5334/pme.40 [doi]
PST - epublish
SO  - Perspect Med Educ. 2023 May 3;12(1):141-148. doi: 10.5334/pme.40. eCollection 
      2023.

PMID- 38047012
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231205
IS  - 1441-2772 (Print)
IS  - 2652-9335 (Electronic)
IS  - 1441-2772 (Linking)
VI  - 24
IP  - 4
DP  - 2022 Dec 5
TI  - Study protocol and statistical analysis plan for the 20% Human Albumin Solution 
      Fluid Bolus Administration Therapy in Patients after Cardiac Surgery-ll (HAS 
      FLAIR-II) trial.
PG  - 309-318
LID - 10.51893/2022.4.OA1 [doi]
AB  - Background: Fluid bolus therapy with 20% albumin may shorten the duration of 
      vasopressor therapy in patients after cardiac surgery. Objective: To describe the 
      study protocol and statistical analysis plan for the 20% Human Albumin Solution 
      Fluid Bolus Administration Therapy in Patients after Cardiac Surgery-II (HAS 
      FLAIR-II) trial. Design, setting, participants and intervention: HAS FLAIR-II is 
      a phase 2b, multicentre, parallel group, openlabel, randomised controlled trial 
      that will be conducted at six Australian intensive care units. Patients requiring 
      fluid bolus therapy after cardiac surgery will be randomly assigned in a 1:1 
      ratio to the intervention of fluid bolus therapy with 20% albumin or a comparator 
      of fluid bolus therapy with a crystalloid solution. Main outcome measures: The 
      primary outcome measure is the cumulative duration of vasopressor therapy. 
      Secondary outcomes include vasopressor use, service utilisation, and mortality. 
      All analyses will be conducted on an intention-to-treat basis. Results and 
      conclusion: The study protocol and statistical analysis plan will guide the 
      conduct and analysis of the HAS FLAIR-II trial, such that analytical and 
      reporting biases are minimised. Trial registration: This trial has been 
      registered with the Australian New Zealand Clinical Trials Registry (ACTRN No. 
      12620000137998).
CI  - © 2022 College of Intensive Care Medicine of Australia and New Zealand.
FAU - Wigmore, Geoffrey
AU  - Wigmore G
AD  - Department of Anaesthesia, Western Health, Melbourne, VIC, Australia.
AD  - Department of Critical Care, University of Melbourne, Melbourne, VIC, Australia.
FAU - Deane, Adam M
AU  - Deane AM
AD  - Department of Critical Care, University of Melbourne, Melbourne, VIC, Australia.
AD  - Department of Intensive Care, Royal Melbourne Hospital, Melbourne, VIC, 
      Australia.
FAU - Anstey, James
AU  - Anstey J
AD  - Department of Critical Care, University of Melbourne, Melbourne, VIC, Australia.
AD  - Department of Intensive Care, Royal Melbourne Hospital, Melbourne, VIC, 
      Australia.
FAU - Bailey, Michael
AU  - Bailey M
AD  - Australian and New Zealand Intensive Care Research Centre (ANZIC-RC), School of 
      Public Health and Preventative Medicine, Monash University, Melbourne, VIC, 
      Australia.
FAU - Bihari, Shailesh
AU  - Bihari S
AD  - Department of Intensive and Critical Care Medicine, Flinders Medical Centre, 
      Adelaide, SA, Australia.
FAU - Eastwood, Glenn
AU  - Eastwood G
AD  - Department of Intensive Care, Austin Hospital, Melbourne, VIC, Australia.
FAU - Ghanpur, Rashmi
AU  - Ghanpur R
AD  - Department of Intensive Care, Austin Hospital, Melbourne, VIC, Australia.
AD  - Intensive care Unit, Warringal Private hospital, Melbourne, VIC, Australia.
FAU - Maiden, Matthew J
AU  - Maiden MJ
AD  - Discipline of Acute Care Medicine, University of Adelaide, Adelaide, SA, 
      Australia.
AD  - Intensive Care Unit, Royal Adelaide Hospital, Adelaide, SA, Australia.
AD  - Intensive Care Unit, Barwon Health, Geelong, VIC, Australia.
FAU - Presneill, Jeffrey J
AU  - Presneill JJ
AD  - Department of Critical Care, University of Melbourne, Melbourne, VIC, Australia.
AD  - Department of Intensive Care, Royal Melbourne Hospital, Melbourne, VIC, 
      Australia.
AD  - Australian and New Zealand Intensive Care Research Centre (ANZIC-RC), School of 
      Public Health and Preventative Medicine, Monash University, Melbourne, VIC, 
      Australia.
FAU - Raman, Jaishankar
AU  - Raman J
AD  - University of Melbourne, Melbourne, VIC, Australia.
AD  - St Vincent's Hospital Melbourne, Melbourne, VIC, Australia.
AD  - Deakin University, Melbourne, VIC, Australia.
AD  - University of Illinois at Urbana-Champaign, Urbana (IL), USA.
FAU - Bellomo, Rinaldo
AU  - Bellomo R
AD  - Department of Critical Care, University of Melbourne, Melbourne, VIC, Australia.
AD  - Department of Intensive Care, Austin Hospital, Melbourne, VIC, Australia.
CN  - HAS FLAIR-II trial investigators
LA  - eng
PT  - Journal Article
DEP - 20231016
PL  - Netherlands
TA  - Crit Care Resusc
JT  - Critical care and resuscitation : journal of the Australasian Academy of Critical 
      Care Medicine
JID - 100888170
PMC - PMC10692638
COIS- All authors declare that they do not have any potential conflict of interest in 
      relation to this manuscript.
EDAT- 2023/12/04 06:42
MHDA- 2023/12/04 06:43
PMCR- 2022/12/05
CRDT- 2023/12/04 05:15
PHST- 2023/12/04 06:43 [medline]
PHST- 2023/12/04 06:42 [pubmed]
PHST- 2023/12/04 05:15 [entrez]
PHST- 2022/12/05 00:00 [pmc-release]
AID - S1441-2772(23)00037-6 [pii]
AID - 10.51893/2022.4.OA1 [doi]
PST - epublish
SO  - Crit Care Resusc. 2023 Oct 16;24(4):309-318. doi: 10.51893/2022.4.OA1. 
      eCollection 2022 Dec 5.

PMID- 39350878
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241003
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 8
DP  - 2024 Aug
TI  - GPT-4 Vision: Multi-Modal Evolution of ChatGPT and Potential Role in Radiology.
PG  - e68298
LID - 10.7759/cureus.68298 [doi]
LID - e68298
AB  - GPT-4 Vision (GPT-4V) represents a significant advancement in multimodal 
      artificial intelligence, enabling text generation from images without specialized 
      training. This marks the transformation of ChatGPT as a large language model 
      (LLM) into GPT-4's promised large multimodal model (LMM). As these AI models 
      continue to advance, they may enhance radiology workflow and aid with decision 
      support. This technical note explores potential GPT-4V applications in radiology 
      and evaluates performance for sample tasks. GPT-4V capabilities were tested using 
      images from the web, personal and institutional teaching files, and hand-drawn 
      sketches. Prompts evaluated scientific figure analysis, radiologic image 
      reporting, image comparison, handwriting interpretation, sketch-to-code, and 
      artistic expression. In this limited demonstration of GPT-4V's capabilities, it 
      showed promise in classifying images, counting entities, comparing images, and 
      deciphering handwriting and sketches. However, it exhibited limitations in 
      detecting some fractures, discerning a change in size of lesions, accurately 
      interpreting complex diagrams, and consistently characterizing radiologic 
      findings. Artistic expression responses were coherent. WhileGPT-4V may eventually 
      assist with tasks related to radiology, current reliability gaps highlight the 
      need for continued training and improvement before consideration for any medical 
      use by the general public and ultimately clinical integration. Future iterations 
      could enable a virtual assistant to discuss findings, improve reports, extract 
      data from images, provide decision support based on guidelines, white papers, and 
      appropriateness criteria. Human expertise remain essential for safe practice and 
      partnerships between physicians, researchers, and technology leaders are 
      necessary to safeguard against risks like bias and privacy concerns.
CI  - Copyright © 2024, Javan et al.
FAU - Javan, Ramin
AU  - Javan R
AD  - Department of Radiology, George Washington University School of Medicine and 
      Health Sciences, Washington, USA.
FAU - Kim, Theodore
AU  - Kim T
AD  - Department of Radiology, George Washington University School of Medicine and 
      Health Sciences, Washington, USA.
FAU - Mostaghni, Navid
AU  - Mostaghni N
AD  - College of Medicine, California University of Science and Medicine, Colton, USA.
LA  - eng
PT  - Journal Article
DEP - 20240831
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11441350
OTO - NOTNLM
OT  - chatgpt
OT  - gpt-4
OT  - gpt-4 vision
OT  - large language models (llms)
OT  - large multimodal model
OT  - lmm
OT  - multimodal ai
COIS- Human subjects: All authors have confirmed that this study did not involve human 
      participants or tissue. Animal subjects: All authors have confirmed that this 
      study did not involve animal subjects or tissue. Conflicts of interest: In 
      compliance with the ICMJE uniform disclosure form, all authors declare the 
      following: Payment/services info: All authors have declared that no financial 
      support was received from any organization for the submitted work. Financial 
      relationships: All authors have declared that they have no financial 
      relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2024/10/01 06:55
MHDA- 2024/10/01 06:56
PMCR- 2024/08/31
CRDT- 2024/10/01 04:15
PHST- 2024/08/31 00:00 [accepted]
PHST- 2024/10/01 06:56 [medline]
PHST- 2024/10/01 06:55 [pubmed]
PHST- 2024/10/01 04:15 [entrez]
PHST- 2024/08/31 00:00 [pmc-release]
AID - 10.7759/cureus.68298 [doi]
PST - epublish
SO  - Cureus. 2024 Aug 31;16(8):e68298. doi: 10.7759/cureus.68298. eCollection 2024 
      Aug.

PMID- 39256622
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240924
IS  - 2730-664X (Electronic)
IS  - 2730-664X (Linking)
VI  - 4
IP  - 1
DP  - 2024 Sep 10
TI  - Unmasking and quantifying racial bias of large language models in medical report 
      generation.
PG  - 176
LID - 10.1038/s43856-024-00601-z [doi]
LID - 176
AB  - BACKGROUND: Large language models like GPT-3.5-turbo and GPT-4 hold promise for 
      healthcare professionals, but they may inadvertently inherit biases during their 
      training, potentially affecting their utility in medical applications. Despite 
      few attempts in the past, the precise impact and extent of these biases remain 
      uncertain. METHODS: We use LLMs to generate responses that predict 
      hospitalization, cost and mortality based on real patient cases. We manually 
      examine the generated responses to identify biases. RESULTS: We find that these 
      models tend to project higher costs and longer hospitalizations for white 
      populations and exhibit optimistic views in challenging medical scenarios with 
      much higher survival rates. These biases, which mirror real-world healthcare 
      disparities, are evident in the generation of patient backgrounds, the 
      association of specific diseases with certain racial and ethnic groups, and 
      disparities in treatment recommendations, etc. CONCLUSIONS: Our findings 
      underscore the critical need for future research to address and mitigate biases 
      in language models, especially in critical healthcare applications, to ensure 
      fair and accurate outcomes for all patients.
CI  - © 2024. This is a U.S. Government work and not under copyright protection in the 
      US; foreign copyright protection may apply.
FAU - Yang, Yifan
AU  - Yang Y
AUID- ORCID: 0000-0003-4414-9176
AD  - National Institutes of Health (NIH), National Library of Medicine (NLM), National 
      Center for Biotechnology Information (NCBI), Bethesda, MD, 20894, USA.
AD  - University of Maryland at College Park, Department of Computer Science, College 
      Park, MD, 20742, USA.
FAU - Liu, Xiaoyu
AU  - Liu X
AD  - University of Maryland at College Park, Department of Computer Science, College 
      Park, MD, 20742, USA.
FAU - Jin, Qiao
AU  - Jin Q
AUID- ORCID: 0000-0002-1268-7239
AD  - National Institutes of Health (NIH), National Library of Medicine (NLM), National 
      Center for Biotechnology Information (NCBI), Bethesda, MD, 20894, USA.
FAU - Huang, Furong
AU  - Huang F
AD  - University of Maryland at College Park, Department of Computer Science, College 
      Park, MD, 20742, USA.
FAU - Lu, Zhiyong
AU  - Lu Z
AUID- ORCID: 0000-0001-9998-916X
AD  - National Institutes of Health (NIH), National Library of Medicine (NLM), National 
      Center for Biotechnology Information (NCBI), Bethesda, MD, 20894, USA. 
      zhiyong.lu@nih.gov.
LA  - eng
PT  - Journal Article
DEP - 20240910
PL  - England
TA  - Commun Med (Lond)
JT  - Communications medicine
JID - 9918250414506676
UOF - ArXiv. 2024 Jan 25:arXiv:2401.13867v1. PMID: 38410650
PMC - PMC11387737
OAB - Large language models (LLMs) such as GPT-3.5-turbo and GPT-4 are advanced 
      computer programs that can understand and generate text. They have the potential 
      to help doctors and other healthcare professionals to improve patient care. We 
      looked at how well these models predicted the cost of healthcare for patients, 
      and the chances of them being hospitalized or dying. We found that these models 
      often projected higher costs and longer hospital stays for white people than 
      people from other racial or ethnicity groups. These biases mirror the disparities 
      in real-world healthcare. Our findings show the need for more research to ensure 
      that inappropriate biases are removed from LLMs to ensure fair and accurate 
      healthcare predictions of possible outcomes for all patients. This will help 
      ensure that these tools can be used effectively to improve healthcare for 
      everyone.
OABL- eng
COIS- The authors declare no competing interests.
EDAT- 2024/09/11 00:42
MHDA- 2024/09/11 00:43
PMCR- 2024/09/10
CRDT- 2024/09/10 23:42
PHST- 2024/02/02 00:00 [received]
PHST- 2024/08/30 00:00 [accepted]
PHST- 2024/09/11 00:43 [medline]
PHST- 2024/09/11 00:42 [pubmed]
PHST- 2024/09/10 23:42 [entrez]
PHST- 2024/09/10 00:00 [pmc-release]
AID - 10.1038/s43856-024-00601-z [pii]
AID - 601 [pii]
AID - 10.1038/s43856-024-00601-z [doi]
PST - epublish
SO  - Commun Med (Lond). 2024 Sep 10;4(1):176. doi: 10.1038/s43856-024-00601-z.

PMID- 40157559
OWN - NLM
STAT- Publisher
LR  - 20250329
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
DP  - 2025 Mar 27
TI  - Artificial Intelligence and Language Learning Models Can Be Improved By Curated 
      Input of Medical Training Data But Still Face The Limitations of Available 
      Literature And Require Continued Human Oversight.
LID - S0749-8063(25)00238-5 [pii]
LID - 10.1016/j.arthro.2025.03.042 [doi]
AB  - Artificial intelligence (AI) and Language Learning Models (LLM) are rapidly 
      evolving. Several popular and easily accessible platforms, like ChatGPT and 
      Gemini, are increasingly being explored by clinicians and patients for their 
      utility in clinical decision-making. While these tools provide rapid access to 
      information, their inconsistent adherence to evidence-based guidelines raises 
      concerns. A potential solution is to generate more specialized LLM's for 
      orthopaedics. A curated database of validated orthoapediic literature can be used 
      as input, in order to address concerns about the quality of input data. However, 
      a curated LLM may still have limitations of selection bias and limited 
      high-quality literature. In additionally, patients using these models may possess 
      limited health literacy. LLM's represent an advancement and potentially powerful 
      clinical tool but still require ongoing evaluation, refinement, and validation. 
      AI should continued to be viewed as an evolving resource rather than a 
      replacement for clinical judgment.
CI  - Copyright © 2025. Published by Elsevier Inc.
FAU - Selman, Farah
AU  - Selman F
AD  - Department of Orthopaedic Surgery, Balgrist University Hospital, University of 
      Zurich, Zurich, Switzerland.
FAU - Obletz, Kristine
AU  - Obletz K
AD  - Department of Orthopaedic Surgery, Naval Medical Center San Diego, San Diego, CA, 
      USA.
FAU - Vismara, Valeria
AU  - Vismara V
AD  - Department of Orthopeadic Surgery, Univeristà degli studi di Milano, Milan, 
      Italy.
FAU - Putko, Robert
AU  - Putko R
AD  - Department of Orthopaedic Surgery, Naval Medical Center San Diego, San Diego, CA, 
      USA.
FAU - Perry, Nicholas P J
AU  - Perry NPJ
AD  - Department of Orthopaedic Surgery, Naval Medical Center San Diego, San Diego, CA, 
      USA.
LA  - eng
PT  - Editorial
DEP - 20250327
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic & related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
EDAT- 2025/03/30 23:02
MHDA- 2025/03/30 23:02
CRDT- 2025/03/29 20:38
PHST- 2025/03/30 23:02 [medline]
PHST- 2025/03/30 23:02 [pubmed]
PHST- 2025/03/19 00:00 [received]
PHST- 2025/03/21 00:00 [revised]
PHST- 2025/03/21 00:00 [accepted]
PHST- 2025/03/29 20:38 [entrez]
AID - S0749-8063(25)00238-5 [pii]
AID - 10.1016/j.arthro.2025.03.042 [doi]
PST - aheadofprint
SO  - Arthroscopy. 2025 Mar 27:S0749-8063(25)00238-5. doi: 
      10.1016/j.arthro.2025.03.042.

PMID- 37652162
OWN - NLM
STAT- MEDLINE
DCOM- 20240115
LR  - 20250104
IS  - 1876-2867 (Electronic)
IS  - 1876-2859 (Print)
IS  - 1876-2859 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Jan-Feb
TI  - Natural Language Processing - A Surveillance Stepping Stone to Identify Child 
      Abuse.
PG  - 92-96
LID - S1876-2859(23)00342-X [pii]
LID - 10.1016/j.acap.2023.08.015 [doi]
AB  - OBJECTIVE: We aimed to refine a natural language processing (NLP) algorithm that 
      identified injuries associated with child abuse and identify areas in which 
      integration into a real-time clinical decision support (CDS) tool may improve 
      clinical care. METHODS: We applied an NLP algorithm in "silent mode" to all 
      emergency department (ED) provider notes between July 2021 and December 2022 
      (n = 353) at 1 pediatric and 8 general EDs. We refined triggers for the NLP, 
      assessed adherence to clinical guidelines, and evaluated disparities in degree of 
      evaluation by examining associations between demographic variables and abuse 
      evaluation or reporting to child protective services. RESULTS: Seventy-three 
      cases falsely triggered the NLP, often due to errors in interpreting linguistic 
      context. We identified common false-positive scenarios and refined the algorithm 
      to improve NLP specificity. Adherence to recommended evaluation standards for 
      injuries defined by nationally accepted clinical guidelines was 63%. There were 
      significant demographic differences in evaluation and reporting based on 
      presenting ED type, insurance status, and race and ethnicity. CONCLUSIONS: 
      Analysis of an NLP algorithm in "silent mode" allowed for refinement of the 
      algorithm and highlighted areas in which real-time CDS may help ED providers 
      identify and pursue appropriate evaluation of injuries associated with child 
      physical abuse.
CI  - Copyright © 2024 Academic Pediatric Association. Published by Elsevier Inc. All 
      rights reserved.
FAU - Shum, May
AU  - Shum M
AD  - Department of Pediatrics (M Shum, A Hsiao, A Asnes, and G Tiyyagura), Yale 
      University School of Medicine, New Haven, Conn. Electronic address: 
      shumm@chop.edu.
FAU - Hsiao, Allen
AU  - Hsiao A
AD  - Department of Pediatrics (M Shum, A Hsiao, A Asnes, and G Tiyyagura), Yale 
      University School of Medicine, New Haven, Conn.
FAU - Teng, Wei
AU  - Teng W
AD  - Yale New Haven Hospital (W Teng), Joint Data Analytics Team, Conn.
FAU - Asnes, Andrea
AU  - Asnes A
AD  - Department of Pediatrics (M Shum, A Hsiao, A Asnes, and G Tiyyagura), Yale 
      University School of Medicine, New Haven, Conn.
FAU - Amrhein, Joshua
AU  - Amrhein J
AD  - 3M Health Information Systems (J Amrhein), Implementation/Adoption Services, 
      Pittsburgh, Pa.
FAU - Tiyyagura, Gunjan
AU  - Tiyyagura G
AD  - Department of Pediatrics (M Shum, A Hsiao, A Asnes, and G Tiyyagura), Yale 
      University School of Medicine, New Haven, Conn.
LA  - eng
GR  - K23 HD107178/HD/NICHD NIH HHS/United States
GR  - UL1 TR001863/TR/NCATS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20230829
PL  - United States
TA  - Acad Pediatr
JT  - Academic pediatrics
JID - 101499145
SB  - IM
MH  - Humans
MH  - Child
MH  - Natural Language Processing
MH  - *Child Abuse/diagnosis
MH  - Algorithms
MH  - Emergency Service, Hospital
MH  - *Decision Support Systems, Clinical
MH  - Electronic Health Records
PMC - PMC10840716
MID - NIHMS1929339
OTO - NOTNLM
OT  - bias
OT  - child protection team
OT  - clinical decision support
OT  - guideline adherence
OT  - natural language processing
COIS- Declaration of Competing Interest The authors report no financial or ethical 
      conflicts of interest. There are no prior publications or submissions with any 
      overlapping information, including studies and patients.
EDAT- 2023/09/01 00:41
MHDA- 2024/01/15 12:43
PMCR- 2025/01/01
CRDT- 2023/08/31 19:24
PHST- 2023/05/23 00:00 [received]
PHST- 2023/08/18 00:00 [revised]
PHST- 2023/08/25 00:00 [accepted]
PHST- 2024/01/15 12:43 [medline]
PHST- 2023/09/01 00:41 [pubmed]
PHST- 2023/08/31 19:24 [entrez]
PHST- 2025/01/01 00:00 [pmc-release]
AID - S1876-2859(23)00342-X [pii]
AID - 10.1016/j.acap.2023.08.015 [doi]
PST - ppublish
SO  - Acad Pediatr. 2024 Jan-Feb;24(1):92-96. doi: 10.1016/j.acap.2023.08.015. Epub 
      2023 Aug 29.

PMID- 38310159
OWN - NLM
STAT- MEDLINE
DCOM- 20240714
LR  - 20240917
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 8
DP  - 2024 Aug
TI  - Large Language Models and Healthcare Alliance: Potential and Challenges of Two 
      Representative Use Cases.
PG  - 1928-1931
LID - 10.1007/s10439-024-03454-8 [doi]
AB  - Large language models (LLMS) emerge as the most promising Natural Language 
      Processing approach for clinical practice acceleration (i.e., diagnosis, 
      prevention and treatment procedures). Similarly, intelligent conversational 
      systems that leverage LLMS have disruptively become the future of therapy in the 
      era of ChatGPT. Accordingly, this research addresses the application of LLMS in 
      healthcare, paying particular attention to two relevant use cases: cognitive 
      decline and depression, more specifically, postpartum depression. In the end, the 
      most promising opportunities they represent (e.g., clinical tasks augmentation, 
      personalized healthcare, etc.) and related concerns (e.g., data privacy and 
      quality, fairness, etc.) are discussed to contribute to the global debate on 
      their integration in the sanitary system.
CI  - © 2024. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - García-Méndez, Silvia
AU  - García-Méndez S
AD  - Information Technologies Group, atlanTTic, University of Vigo, Vigo, Spain.
FAU - de Arriba-Pérez, Francisco
AU  - de Arriba-Pérez F
AUID- ORCID: 0000-0002-1140-679X
AD  - Information Technologies Group, atlanTTic, University of Vigo, Vigo, Spain. 
      farriba@gti.uvigo.es.
LA  - eng
GR  - ED481B-2021-118/Xunta de Galicia/
GR  - ED481B-2022-093/Xunta de Galicia/
PT  - Letter
DEP - 20240203
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - Female
MH  - *Natural Language Processing
MH  - Depression, Postpartum/therapy
MH  - Cognitive Dysfunction/therapy
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cognitive decline
OT  - Intelligent conversational assistants
OT  - Large language models
OT  - Natural language processing
OT  - Postpartum depression
EDAT- 2024/02/04 00:42
MHDA- 2024/07/15 00:41
CRDT- 2024/02/03 23:17
PHST- 2023/11/23 00:00 [received]
PHST- 2024/01/15 00:00 [accepted]
PHST- 2024/07/15 00:41 [medline]
PHST- 2024/02/04 00:42 [pubmed]
PHST- 2024/02/03 23:17 [entrez]
AID - 10.1007/s10439-024-03454-8 [pii]
AID - 10.1007/s10439-024-03454-8 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Aug;52(8):1928-1931. doi: 10.1007/s10439-024-03454-8. Epub 
      2024 Feb 3.

PMID- 37553556
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240716
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 4
DP  - 2024 Apr
TI  - Enhancing Diabetes Self-management and Education: A Critical Analysis of 
      ChatGPT's Role.
PG  - 741-744
LID - 10.1007/s10439-023-03317-8 [doi]
AB  - ChatGPT, an advanced natural language processing model, holds significant promise 
      in diabetes self-management and education. ChatGPT excels in providing 
      personalized educational experiences by tailoring information to meet individual 
      patient needs and preferences. It aids patients in developing self-management 
      skills and strategies, fostering proactive disease management. Additionally, 
      ChatGPT addresses healthcare access disparities by enabling patients to access 
      educational resources irrespective of their geographic location or physical 
      limitations. However, it is important to acknowledge and address the deficiencies 
      of ChatGPT, such as its limited medical expertise, contextual understanding, and 
      emotional support capabilities. Strategies for optimizing ChatGPT include regular 
      training and updating, integration of healthcare professionals' expertise, 
      improvement in contextual comprehension, and enhancing emotional support. By 
      addressing these limitations and striking a balance between the benefits and 
      limitations, ChatGPT can play a significant role in empowering patients to better 
      understand and manage diabetes. Further research and development are needed to 
      refine ChatGPT's capabilities and address ethical considerations, but its 
      integration in patient education holds the potential to transform healthcare 
      delivery and create a more informed and engaged patient population.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Zheng, Yue
AU  - Zheng Y
AUID- ORCID: 0000-0003-3865-7051
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, 
      China.
FAU - Wu, Yijun
AU  - Wu Y
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, 
      China.
FAU - Feng, Baijie
AU  - Feng B
AD  - West China School of Medicine, Sichuan University, Chengdu, 610041, China.
FAU - Wang, Laduona
AU  - Wang L
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, 
      China.
FAU - Kang, Kai
AU  - Kang K
AD  - Cancer Center, West China Hospital, Sichuan University, Chengdu, 610041, Sichuan, 
      China. kaikang@wchscu.cn.
FAU - Zhao, Ailin
AU  - Zhao A
AD  - Department of Hematology, West China Hospital, Sichuan University, Chengdu, 
      610041, Sichuan, China. irenez20@outlook.com.
LA  - eng
GR  - 2023NSFSC1885/Natural Science Foundation of Sichuan Province/
GR  - 2022SCUH0025/"from zero to one" Innovation Research Project of Sichuan 
      University/
GR  - 2022-YF05-01443-SN/Chengdu Science and Technology Program/
GR  - 23ZDYF2836/Key Research and Development Program of Sichuan Province/
GR  - 2021M692310/China Postdoctoral Science Foundation/
GR  - 82204490/National Natural Science Foundation of China/
PT  - Letter
DEP - 20230808
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Self-Management
MH  - Disease Management
MH  - Health Personnel
MH  - Healthcare Disparities
MH  - *Diabetes Mellitus/therapy
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Diabetes self-management and education
EDAT- 2023/08/09 01:05
MHDA- 2024/03/15 06:44
CRDT- 2023/08/08 23:30
PHST- 2023/07/06 00:00 [received]
PHST- 2023/07/10 00:00 [accepted]
PHST- 2024/03/15 06:44 [medline]
PHST- 2023/08/09 01:05 [pubmed]
PHST- 2023/08/08 23:30 [entrez]
AID - 10.1007/s10439-023-03317-8 [pii]
AID - 10.1007/s10439-023-03317-8 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Apr;52(4):741-744. doi: 10.1007/s10439-023-03317-8. Epub 
      2023 Aug 8.

PMID- 37885556
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231028
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 9
DP  - 2023 Sep
TI  - Bias and Inaccuracy in AI Chatbot Ophthalmologist Recommendations.
PG  - e45911
LID - 10.7759/cureus.45911 [doi]
LID - e45911
AB  - PURPOSE AND DESIGN: To evaluate the accuracy and bias of ophthalmologist 
      recommendations made by three AI chatbots, namely ChatGPT 3.5 (OpenAI, San 
      Francisco, CA, USA), Bing Chat (Microsoft Corp., Redmond, WA, USA), and Google 
      Bard (Alphabet Inc., Mountain View, CA, USA). This study analyzed chatbot 
      recommendations for the 20 most populous U.S. cities. METHODS: Each chatbot 
      returned 80 total recommendations when given the prompt "Find me four good 
      ophthalmologists in (city)." Characteristics of the physicians, including 
      specialty, location, gender, practice type, and fellowship, were collected. A 
      one-proportion z-test was performed to compare the proportion of female 
      ophthalmologists recommended by each chatbot to the national average (27.2% per 
      the Association of American Medical Colleges (AAMC)). Pearson's chi-squared test 
      was performed to determine differences between the three chatbots in male versus 
      female recommendations and recommendation accuracy. RESULTS: Female 
      ophthalmologists recommended by Bing Chat (1.61%) and Bard (8.0%) were 
      significantly less than the national proportion of 27.2% practicing female 
      ophthalmologists (p<0.001, p<0.01, respectively). ChatGPT recommended fewer 
      female (29.5%) than male ophthalmologists (p<0.722). ChatGPT (73.8%), Bing Chat 
      (67.5%), and Bard (62.5%) gave high rates of inaccurate recommendations. Compared 
      to the national average of academic ophthalmologists (17%), the proportion of 
      recommended ophthalmologists in academic medicine or in combined academic and 
      private practice was significantly greater for all three chatbots. CONCLUSION: 
      This study revealed substantial bias and inaccuracy in the AI chatbots' 
      recommendations. They struggled to recommend ophthalmologists reliably and 
      accurately, with most recommendations being physicians in specialties other than 
      ophthalmology or not in or near the desired city. Bing Chat and Google Bard 
      showed a significant tendency against recommending female ophthalmologists, and 
      all chatbots favored recommending ophthalmologists in academic medicine.
CI  - Copyright © 2023, Oca et al.
FAU - Oca, Michael C
AU  - Oca MC
AD  - Orthopedic Surgery, Shiley Eye Institute, University of California (UC) San Diego 
      Health, La Jolla, USA.
FAU - Meller, Leo
AU  - Meller L
AD  - Orthopedic Surgery, Shiley Eye Institute, University of California (UC) San Diego 
      Health, La Jolla, USA.
FAU - Wilson, Katherine
AU  - Wilson K
AD  - Orthopedic Surgery, Shiley Eye Institute, University of California (UC) San Diego 
      Health, La Jolla, USA.
FAU - Parikh, Alomi O
AU  - Parikh AO
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Keck 
      School of Medicine of University of Southern California, Los Angeles, USA.
FAU - McCoy, Allison
AU  - McCoy A
AD  - Plastic Surgery, Del Mar Plastic Surgery, San Diego, USA.
FAU - Chang, Jessica
AU  - Chang J
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Keck 
      School of Medicine of University of Southern California, Los Angeles, USA.
FAU - Sudharshan, Rasika
AU  - Sudharshan R
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Keck 
      School of Medicine of University of Southern California, Los Angeles, USA.
FAU - Gupta, Shreya
AU  - Gupta S
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Keck 
      School of Medicine of University of Southern California, Los Angeles, USA.
FAU - Zhang-Nunes, Sandy
AU  - Zhang-Nunes S
AD  - Ophthalmology, University of Southern California (USC) Roski Eye Institute, Keck 
      School of Medicine of University of Southern California, Los Angeles, USA.
LA  - eng
PT  - Journal Article
DEP - 20230925
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10599183
OTO - NOTNLM
OT  - ai chatbot
OT  - artificial intelligence (ai) in medicine
OT  - artificial intelligence in health care
OT  - artificial intelligence in medicine
OT  - gender bias
OT  - patient education
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/10/27 06:42
MHDA- 2023/10/27 06:43
PMCR- 2023/09/25
CRDT- 2023/10/27 04:19
PHST- 2023/09/25 00:00 [accepted]
PHST- 2023/10/27 06:43 [medline]
PHST- 2023/10/27 06:42 [pubmed]
PHST- 2023/10/27 04:19 [entrez]
PHST- 2023/09/25 00:00 [pmc-release]
AID - 10.7759/cureus.45911 [doi]
PST - epublish
SO  - Cureus. 2023 Sep 25;15(9):e45911. doi: 10.7759/cureus.45911. eCollection 2023 
      Sep.

PMID- 37734067
OWN - NLM
STAT- MEDLINE
DCOM- 20231229
LR  - 20240106
IS  - 0034-8376 (Print)
IS  - 0034-8376 (Linking)
VI  - 75
IP  - 6
DP  - 2023 Dec 18
TI  - Is generative artificial intelligence the next step toward a personalized 
      hemodialysis?
PG  - 309-317
LID - 10.24875/RIC.23000162 [doi]
AB  - Artificial intelligence (AI) generative models driven by the integration of AI 
      and natural language processing technologies, such as OpenAI's chatbot generative 
      pre-trained transformer large language model (LLM), are receiving much public 
      attention and have the potential to transform personalized medicine. Dialysis 
      patients are highly dependent on technology and their treatment generates a 
      challenging large volume of data that has to be analyzed for knowledge 
      extraction. We argue that, by integrating the data acquired from hemodialysis 
      treatments with the powerful conversational capabilities of LLMs, nephrologists 
      could personalize treatments adapted to patients' lifestyles and preferences. We 
      also argue that this new conversational AI integrated with a personalized 
      patient-computer interface will enhance patients' engagement and self-care by 
      providing them with a more personalized experience. However, generative AI models 
      require continuous and accurate updates of data, and expert supervision and must 
      address potential biases and limitations. Dialysis patients can also benefit from 
      other new emerging technologies such as Digital Twins with which patients' care 
      can also be addressed from a personalized medicine perspective. In this paper, we 
      will revise LLMs potential strengths in terms of their contribution to 
      personalized medicine, and, in particular, their potential impact, and 
      limitations in nephrology. Nephrologists' collaboration with AI academia and 
      companies, to develop algorithms and models that are more transparent, 
      understandable, and trustworthy, will be crucial for the next generation of 
      dialysis patients. The combination of technology, patient-specific data, and AI 
      should contribute to create a more personalized and interactive dialysis process, 
      improving patients' quality of life.
FAU - Hueso, Miguel
AU  - Hueso M
AD  - Department of Nephrology, Hospital Universitari Bellvitge and Institut 
      d'Investigació Biomèdica de Bellvitge-IDIBELL, Barcelona, Spain.
AD  - BigData and Artificial Intelligence Group (BigSEN Working Group), Spanish Society 
      of Nephrology (SENEFRO), Santander, España.
FAU - Álvarez, Rafael
AU  - Álvarez R
AD  - Department of Nephrology, Hospital Universitari Bellvitge and Institut 
      d'Investigació Biomèdica de Bellvitge-IDIBELL, Barcelona, Spain.
FAU - Marí, David
AU  - Marí D
AD  - Digital Health Unit, Eurecat - Centre Tecnològic de Catalunya, Barcelona, Spain.
FAU - Ribas-Ripoll, Vicent
AU  - Ribas-Ripoll V
AD  - Digital Health Unit, Eurecat - Centre Tecnològic de Catalunya, Barcelona, Spain.
FAU - Lekadir, Karim
AU  - Lekadir K
AD  - Artificial Intelligence in Medicine Lab (BCN-AIM), Department of Mathematics and 
      Computer Science, University of Barcelona, Barcelona, Spain.
FAU - Vellido, Alfredo
AU  - Vellido A
AD  - Intelligent Data Science and Artificial Intelligence Research Center, Universitat 
      Politècnica de Catalunya, (IDEAI-UPC), Barcelona, Spain.
AD  - Centro de Investigación Biomédica en Red (CIBER), Barcelona, Spain.
LA  - eng
PT  - Journal Article
DEP - 20231218
PL  - Mexico
TA  - Rev Invest Clin
JT  - Revista de investigacion clinica; organo del Hospital de Enfermedades de la 
      Nutricion
JID - 9421552
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Quality of Life
MH  - Algorithms
MH  - Software
MH  - Renal Dialysis
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Large Language Models
OT  - Natural language processing
OT  - Personalized hemodialysis
EDAT- 2023/09/21 18:42
MHDA- 2023/12/29 06:42
CRDT- 2023/09/21 17:01
PHST- 2023/12/29 06:42 [medline]
PHST- 2023/09/21 18:42 [pubmed]
PHST- 2023/09/21 17:01 [entrez]
AID - 10.24875/RIC.23000162 [doi]
PST - epublish
SO  - Rev Invest Clin. 2023 Dec 18;75(6):309-317. doi: 10.24875/RIC.23000162.

PMID- 37971399
OWN - NLM
STAT- MEDLINE
DCOM- 20240412
LR  - 20250225
IS  - 1537-6591 (Electronic)
IS  - 1058-4838 (Print)
IS  - 1058-4838 (Linking)
VI  - 78
IP  - 4
DP  - 2024 Apr 10
TI  - Black Box Warning: Large Language Models and the Future of Infectious Diseases 
      Consultation.
PG  - 860-866
LID - 10.1093/cid/ciad633 [doi]
AB  - Large language models (LLMs) are artificial intelligence systems trained by deep 
      learning algorithms to process natural language and generate text responses to 
      user prompts. Some approach physician performance on a range of medical 
      challenges, leading some proponents to advocate for their potential use in 
      clinical consultation and prompting some consternation about the future of 
      cognitive specialties. However, LLMs currently have limitations that preclude 
      safe clinical deployment in performing specialist consultations, including 
      frequent confabulations, lack of contextual awareness crucial for nuanced 
      diagnostic and treatment plans, inscrutable and unexplainable training data and 
      methods, and propensity to recapitulate biases. Nonetheless, considering the 
      rapid improvement in this technology, growing calls for clinical integration, and 
      healthcare systems that chronically undervalue cognitive specialties, it is 
      critical that infectious diseases clinicians engage with LLMs to enable informed 
      advocacy for how they should-and shouldn't-be used to augment specialist care.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of 
      Infectious Diseases Society of America.
FAU - Schwartz, Ilan S
AU  - Schwartz IS
AUID- ORCID: 0000-0002-7522-0281
AD  - Division of Infectious Diseases, Department of Medicine, Duke University School 
      of Medicine, Durham, North Carolina, USA.
FAU - Link, Katherine E
AU  - Link KE
AD  - Department of Medical Education, Icahn School of Medicine at Mount Sinai, 
      NewYork, New York, USA.
AD  - Healthcare & Life Sciences Division, Hugging Face, Brooklyn, NewYork, USA.
FAU - Daneshjou, Roxana
AU  - Daneshjou R
AD  - Department of Dermatology, Stanford School of Medicine, Stanford, California, 
      USA.
AD  - Department of Biomedical Data Science, Stanford School of Medicine, Stanford, 
      California, USA.
FAU - Cortés-Penfield, Nicolás
AU  - Cortés-Penfield N
AD  - Division of Infectious Diseases, University of Nebraska Medical Center, Omaha, 
      Nebraska, USA.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Clin Infect Dis
JT  - Clinical infectious diseases : an official publication of the Infectious Diseases 
      Society of America
JID - 9203213
SB  - IM
CIN - Clin Infect Dis. 2024 Apr 10;78(4):867-869. doi: 10.1093/cid/ciad635. PMID: 
      37963099
MH  - Humans
MH  - *Drug Labeling
MH  - Artificial Intelligence
MH  - *Communicable Diseases/diagnosis
MH  - Language
MH  - Referral and Consultation
PMC - PMC11006107
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - chatbot
OT  - natural language processing
OT  - workforce
COIS- Potential conflicts of interest. I. S. S. reports an unpaid role as the Secretary 
      for the Mycoses Study Group Education & Research Consortium Board of Directors, 
      unrelated to this work. K. E. L. reports institutional grants from the 
      Neurosurgical Research & Educational Foundation (NREF) and the Radiological 
      Society of North America (RSNA); is a former employment at NYU Langone; had a 
      former internship at Google, Inc; holds a patent (16/902422) related to 
      personalized questionnaire development, a pending patent (16/891757) related to 
      understanding the underlying relationships between mental health symptoms, and a 
      pending patent (17/007193) related to processing electroencephalography data; and 
      is currently an employee of Hugging Face, a platform for open-source machine 
      learning, for which they receive stock options. R. D. has received personal fees 
      from DWA, Pfizer, L’Oreal, and VisualDx; stock options from MDAlgorithms and 
      Revea; a role on the American Academy of Dermatology Al Committee; holds a patent 
      pending for TrueImage (17/937714), a machine-learning algorithm for detecting 
      skin disease; and support from grant number 5T32AR007422-38, all outside the 
      submitted work. N.C.-P. reports no potential conflicts. All authors have 
      submitted the ICMJE Form for Disclosure of Potential Conflicts of Interest. 
      Conflicts that the editors consider relevant to the content of the manuscript 
      have been disclosed.
EDAT- 2023/11/17 15:32
MHDA- 2024/04/12 06:44
PMCR- 2023/11/16
CRDT- 2023/11/16 10:23
PHST- 2023/05/27 00:00 [received]
PHST- 2024/04/12 06:44 [medline]
PHST- 2023/11/17 15:32 [pubmed]
PHST- 2023/11/16 10:23 [entrez]
PHST- 2023/11/16 00:00 [pmc-release]
AID - 7424520 [pii]
AID - ciad633 [pii]
AID - 10.1093/cid/ciad633 [doi]
PST - ppublish
SO  - Clin Infect Dis. 2024 Apr 10;78(4):860-866. doi: 10.1093/cid/ciad633.

PMID- 37355478
OWN - NLM
STAT- MEDLINE
DCOM- 20230809
LR  - 20230809
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Linking)
VI  - 51
IP  - 9
DP  - 2023 Sep
TI  - GPT Technology to Help Address Longstanding Barriers to Care in Free Medical 
      Clinics.
PG  - 1906-1909
LID - 10.1007/s10439-023-03256-4 [doi]
AB  - The implementation of technology in healthcare has revolutionized 
      patient-centered decision making by providing contextualized information about a 
      patient's healthcare journey, leading to increased efficiency (Keyworth et al. in 
      BMC Med Inform Decis Mak 18:93, 2018, https://doi.org/10.1186/s12911-018-0661-3 
      ). Artificial intelligence has been integrated within Electronic Health Records 
      (EHR) to prompt screenings or diagnostic tests based on a patient's holistic 
      health profile. While larger hospitals have already widely adopted these 
      technologies, free clinics hold lower utilization of these advanced capability 
      EHRs. The patient population at a free clinic faces a multitude of factors that 
      limits their access to comprehensive care, thus requiring necessary efforts and 
      measures to close the gap in healthcare disparities. Emerging Artificial 
      Intelligence (AI) technology, such as OpenAI's ChatGPT, GPT-4, and other large 
      language models (LLMs) have remarkable potential to improve patient care 
      outcomes, promote health equity, and enhance comprehensive and holistic care in 
      resource-limited settings. This paper aims to identify areas in which integrating 
      these LLM AI advancements into free clinics operations can optimize and 
      streamline healthcare delivery to underserved patient populations. This paper 
      also identifies areas of improvements in GPT that are necessary to deliver those 
      services.
CI  - © 2023. The Author(s) under exclusive licence to Biomedical Engineering Society.
FAU - Ong, Hannah
AU  - Ong H
AUID- ORCID: 0000-0002-6041-0322
AD  - College of Medicine, The Ohio State University, Columbus, OH, 43210, USA. 
      Hannah.ong@osumc.edu.
FAU - Ong, Joshua
AU  - Ong J
AD  - Michigan Medicine, University of Michigan, Ann Arbor, MI, USA.
FAU - Cheng, Rebekah
AU  - Cheng R
AD  - Department of Physical Therapy, Virginia Commonwealth University, Richmond, VA, 
      USA.
FAU - Wang, Calvin
AU  - Wang C
AD  - College of Medicine - Robert Wood Johnson, Rutgers University, New Brunswick, NJ, 
      USA.
FAU - Lin, Murong
AU  - Lin M
AD  - Distinguished Engineer, Verizon, San Jose, CA, USA.
FAU - Ong, Dennis
AU  - Ong D
AD  - Amazon Web Services, Amazon, Seattle, WA, USA.
LA  - eng
PT  - Letter
DEP - 20230624
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Health Promotion
MH  - Hospitals
MH  - Technology
MH  - Health Services Accessibility
OTO - NOTNLM
OT  - Barriers to care
OT  - Electronic Health Records
OT  - Free medical clinic
OT  - GPT
EDAT- 2023/06/25 01:08
MHDA- 2023/08/09 06:43
CRDT- 2023/06/24 23:03
PHST- 2023/05/23 00:00 [received]
PHST- 2023/05/25 00:00 [accepted]
PHST- 2023/08/09 06:43 [medline]
PHST- 2023/06/25 01:08 [pubmed]
PHST- 2023/06/24 23:03 [entrez]
AID - 10.1007/s10439-023-03256-4 [pii]
AID - 10.1007/s10439-023-03256-4 [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2023 Sep;51(9):1906-1909. doi: 10.1007/s10439-023-03256-4. Epub 
      2023 Jun 24.

PMID- 38410650
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240924
IS  - 2331-8422 (Electronic)
IS  - 2331-8422 (Linking)
DP  - 2024 Jan 25
TI  - Unmasking and Quantifying Racial Bias of Large Language Models in Medical Report 
      Generation.
LID - arXiv:2401.13867v1
AB  - Large language models like GPT-3.5-turbo and GPT-4 hold promise for healthcare 
      professionals, but they may inadvertently inherit biases during their training, 
      potentially affecting their utility in medical applications. Despite few attempts 
      in the past, the precise impact and extent of these biases remain uncertain. 
      Through both qualitative and quantitative analyses, we find that these models 
      tend to project higher costs and longer hospitalizations for White populations 
      and exhibit optimistic views in challenging medical scenarios with much higher 
      survival rates. These biases, which mirror real-world healthcare disparities, are 
      evident in the generation of patient backgrounds, the association of specific 
      diseases with certain races, and disparities in treatment recommendations, etc. 
      Our findings underscore the critical need for future research to address and 
      mitigate biases in language models, especially in critical healthcare 
      applications, to ensure fair and accurate outcomes for all patients.
FAU - Yang, Yifan
AU  - Yang Y
AD  - National Institutes of Health (NIH), National Library of Medicine (NLM), National 
      Center for Biotechnology Information (NCBI), Bethesda, MD 20894, USA.
AD  - University of Maryland at College Park, Department of Computer Science, College 
      Park, MD 20742, USA.
FAU - Liu, Xiaoyu
AU  - Liu X
AD  - University of Maryland at College Park, Department of Computer Science, College 
      Park, MD 20742, USA.
FAU - Jin, Qiao
AU  - Jin Q
AD  - National Institutes of Health (NIH), National Library of Medicine (NLM), National 
      Center for Biotechnology Information (NCBI), Bethesda, MD 20894, USA.
FAU - Huang, Furong
AU  - Huang F
AD  - University of Maryland at College Park, Department of Computer Science, College 
      Park, MD 20742, USA.
FAU - Lu, Zhiyong
AU  - Lu Z
AD  - National Institutes of Health (NIH), National Library of Medicine (NLM), National 
      Center for Biotechnology Information (NCBI), Bethesda, MD 20894, USA.
LA  - eng
PT  - Journal Article
PT  - Preprint
DEP - 20240125
PL  - United States
TA  - ArXiv
JT  - ArXiv
JID - 101759493
UIN - Commun Med (Lond). 2024 Sep 10;4(1):176. doi: 10.1038/s43856-024-00601-z. PMID: 
      39256622
PMC - PMC10896353
COIS- Competing Interests Authors declare no competing interests.
EDAT- 2024/02/27 06:44
MHDA- 2024/02/27 06:45
PMCR- 2024/01/25
CRDT- 2024/02/27 03:42
PHST- 2024/02/27 06:44 [pubmed]
PHST- 2024/02/27 06:45 [medline]
PHST- 2024/02/27 03:42 [entrez]
PHST- 2024/01/25 00:00 [pmc-release]
AID - 2401.13867 [pii]
PST - epublish
SO  - ArXiv [Preprint]. 2024 Jan 25:arXiv:2401.13867v1.

PMID- 37816646
OWN - NLM
STAT- MEDLINE
DCOM- 20231206
LR  - 20240121
IS  - 1526-632X (Electronic)
IS  - 0028-3878 (Print)
IS  - 0028-3878 (Linking)
VI  - 101
IP  - 23
DP  - 2023 Dec 4
TI  - Large Language Models in Neurology Research and Future Practice.
PG  - 1058-1067
LID - 10.1212/WNL.0000000000207967 [doi]
AB  - Recent advancements in generative artificial intelligence, particularly using 
      large language models (LLMs), are gaining increased public attention. We provide 
      a perspective on the potential of LLMs to analyze enormous amounts of data from 
      medical records and gain insights on specific topics in neurology. In addition, 
      we explore use cases for LLMs, such as early diagnosis, supporting patient and 
      caregivers, and acting as an assistant for clinicians. We point to the potential 
      ethical and technical challenges raised by LLMs, such as concerns about privacy 
      and data security, potential biases in the data for model training, and the need 
      for careful validation of results. Researchers must consider these challenges and 
      take steps to address them to ensure that their work is conducted in a safe and 
      responsible manner. Despite these challenges, LLMs offer promising opportunities 
      for improving care and treatment of various neurologic disorders.
CI  - Copyright © 2023 The Author(s). Published by Wolters Kluwer Health, Inc. on 
      behalf of the American Academy of Neurology.
FAU - Romano, Michael F
AU  - Romano MF
AUID- ORCID: 0000-0002-7022-9252
AD  - From the Department of Medicine (M.F.R., R.A., V.B.K.), Boston University 
      Chobanian & Avedisian School of Medicine, MA; Department of Radiology and 
      Biomedical Imaging (M.F.R.), University of California, San Francisco; Department 
      of Neurology (L.C.S., R.A.), Boston University Chobanian & Avedisian School of 
      Medicine; Department of Electrical and Computer Engineering (I.C.P.), Division of 
      Systems Engineering, and Department of Biomedical Engineering; Faculty of 
      Computing and Data Sciences (I.C.P., V.B.K.), Boston University; Department of 
      Anatomy and Neurobiology (R.A.); The Framingham Heart Study, Boston University 
      Chobanian & Avedisian School of Medicine; Department of Epidemiology, Boston 
      University School of Public Health; Boston University Alzheimer's Disease 
      Research Center (R.A.); and Department of Computer Science (V.B.K.), Boston 
      University, MA.
FAU - Shih, Ludy C
AU  - Shih LC
AUID- ORCID: 0000-0002-6590-8365
AD  - From the Department of Medicine (M.F.R., R.A., V.B.K.), Boston University 
      Chobanian & Avedisian School of Medicine, MA; Department of Radiology and 
      Biomedical Imaging (M.F.R.), University of California, San Francisco; Department 
      of Neurology (L.C.S., R.A.), Boston University Chobanian & Avedisian School of 
      Medicine; Department of Electrical and Computer Engineering (I.C.P.), Division of 
      Systems Engineering, and Department of Biomedical Engineering; Faculty of 
      Computing and Data Sciences (I.C.P., V.B.K.), Boston University; Department of 
      Anatomy and Neurobiology (R.A.); The Framingham Heart Study, Boston University 
      Chobanian & Avedisian School of Medicine; Department of Epidemiology, Boston 
      University School of Public Health; Boston University Alzheimer's Disease 
      Research Center (R.A.); and Department of Computer Science (V.B.K.), Boston 
      University, MA.
FAU - Paschalidis, Ioannis C
AU  - Paschalidis IC
AUID- ORCID: 0000-0002-3343-2913
AD  - From the Department of Medicine (M.F.R., R.A., V.B.K.), Boston University 
      Chobanian & Avedisian School of Medicine, MA; Department of Radiology and 
      Biomedical Imaging (M.F.R.), University of California, San Francisco; Department 
      of Neurology (L.C.S., R.A.), Boston University Chobanian & Avedisian School of 
      Medicine; Department of Electrical and Computer Engineering (I.C.P.), Division of 
      Systems Engineering, and Department of Biomedical Engineering; Faculty of 
      Computing and Data Sciences (I.C.P., V.B.K.), Boston University; Department of 
      Anatomy and Neurobiology (R.A.); The Framingham Heart Study, Boston University 
      Chobanian & Avedisian School of Medicine; Department of Epidemiology, Boston 
      University School of Public Health; Boston University Alzheimer's Disease 
      Research Center (R.A.); and Department of Computer Science (V.B.K.), Boston 
      University, MA.
FAU - Au, Rhoda
AU  - Au R
AUID- ORCID: 0000-0001-7742-4491
AD  - From the Department of Medicine (M.F.R., R.A., V.B.K.), Boston University 
      Chobanian & Avedisian School of Medicine, MA; Department of Radiology and 
      Biomedical Imaging (M.F.R.), University of California, San Francisco; Department 
      of Neurology (L.C.S., R.A.), Boston University Chobanian & Avedisian School of 
      Medicine; Department of Electrical and Computer Engineering (I.C.P.), Division of 
      Systems Engineering, and Department of Biomedical Engineering; Faculty of 
      Computing and Data Sciences (I.C.P., V.B.K.), Boston University; Department of 
      Anatomy and Neurobiology (R.A.); The Framingham Heart Study, Boston University 
      Chobanian & Avedisian School of Medicine; Department of Epidemiology, Boston 
      University School of Public Health; Boston University Alzheimer's Disease 
      Research Center (R.A.); and Department of Computer Science (V.B.K.), Boston 
      University, MA.
FAU - Kolachalama, Vijaya B
AU  - Kolachalama VB
AUID- ORCID: 0000-0002-5312-8644
AD  - From the Department of Medicine (M.F.R., R.A., V.B.K.), Boston University 
      Chobanian & Avedisian School of Medicine, MA; Department of Radiology and 
      Biomedical Imaging (M.F.R.), University of California, San Francisco; Department 
      of Neurology (L.C.S., R.A.), Boston University Chobanian & Avedisian School of 
      Medicine; Department of Electrical and Computer Engineering (I.C.P.), Division of 
      Systems Engineering, and Department of Biomedical Engineering; Faculty of 
      Computing and Data Sciences (I.C.P., V.B.K.), Boston University; Department of 
      Anatomy and Neurobiology (R.A.); The Framingham Heart Study, Boston University 
      Chobanian & Avedisian School of Medicine; Department of Epidemiology, Boston 
      University School of Public Health; Boston University Alzheimer's Disease 
      Research Center (R.A.); and Department of Computer Science (V.B.K.), Boston 
      University, MA. vkola@bu.edu.
LA  - eng
PT  - Journal Article
DEP - 20231204
PL  - United States
TA  - Neurology
JT  - Neurology
JID - 0401060
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Neurology
MH  - Language
MH  - Medical Records
MH  - Research Personnel
PMC - PMC10752640
COIS- The authors report no relevant disclosures. Go to Neurology.org/N for full 
      disclosures.
EDAT- 2023/10/11 00:42
MHDA- 2023/12/06 06:42
PMCR- 2023/12/05
CRDT- 2023/10/10 21:38
PHST- 2023/06/01 00:00 [received]
PHST- 2023/09/06 00:00 [accepted]
PHST- 2023/12/06 06:42 [medline]
PHST- 2023/10/11 00:42 [pubmed]
PHST- 2023/10/10 21:38 [entrez]
PHST- 2023/12/05 00:00 [pmc-release]
AID - WNL.0000000000207967 [pii]
AID - WNL-2023-002389DN [pii]
AID - 10.1212/WNL.0000000000207967 [doi]
PST - epublish
SO  - Neurology. 2023 Dec 4;101(23):1058-1067. doi: 10.1212/WNL.0000000000207967.

PMID- 39533849
OWN - NLM
STAT- MEDLINE
DCOM- 20250131
LR  - 20250131
IS  - 1525-1470 (Electronic)
IS  - 0736-8046 (Linking)
VI  - 42
IP  - 1
DP  - 2025 Jan-Feb
TI  - Enhancing Spanish Patient Education Materials: Comparing the Readability of 
      Artificial Intelligence-Generated Spanish Patient Education Materials to the 
      Society of Pediatric Dermatology Spanish Patient Brochures.
PG  - 106-108
LID - 10.1111/pde.15805 [doi]
AB  - Patient education materials (PEMs) are crucial for improving patient adherence 
      and outcomes; however, they may not be accessible due to high reading levels. Our 
      study used seven readability measures to compare the readability of 
      Spanish PEMs from the Society of Pediatric Dermatology (SPD) with those generated 
      by Open-AI's ChatGPT 4.0 and Google Gemini. Our results showed that when prompted 
      to produce material at a 6th grade level, both AI ChatBots generated 
      significantly improved readability scores when compared to the SPD handouts. 
      These findings suggest that AI-generated PEMs could better meet readability 
      standards and potentially improve patient outcomes, although further studies are 
      needed to confirm this.
CI  - © 2024 Wiley Periodicals LLC.
FAU - Duran, Sabrina
AU  - Duran S
AUID- ORCID: 0009-0009-4448-4960
AD  - School of Medicine, West Virginia University, Morgantown, West Virginia, USA.
FAU - Gonzalez, Andrea Medina
AU  - Gonzalez AM
AD  - Department of Dermatology, West Virginia University, Morgantown, West Virginia, 
      USA.
FAU - Nguyen, Kevin
AU  - Nguyen K
AD  - Department of Dermatology, West Virginia University, Morgantown, West Virginia, 
      USA.
FAU - Nguyen, John
AU  - Nguyen J
AD  - Department of Ophthalmology, West Virginia University, Morgantown, West Virginia, 
      USA.
FAU - Zinn, Zachary
AU  - Zinn Z
AD  - Department of Dermatology, West Virginia University, Morgantown, West Virginia, 
      USA.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20241112
PL  - United States
TA  - Pediatr Dermatol
JT  - Pediatric dermatology
JID - 8406799
SB  - IM
MH  - Humans
MH  - *Dermatology
MH  - *Comprehension
MH  - *Patient Education as Topic/methods
MH  - *Artificial Intelligence
MH  - *Pamphlets
MH  - Societies, Medical
MH  - Pediatrics
MH  - Spain
MH  - Health Literacy
MH  - Child
OTO - NOTNLM
OT  - artificial intelligence
OT  - health literacy
OT  - healthcare equity
OT  - patient education
OT  - readability
EDAT- 2024/11/13 14:00
MHDA- 2025/01/31 12:23
CRDT- 2024/11/13 02:54
PHST- 2024/10/07 00:00 [revised]
PHST- 2024/07/15 00:00 [received]
PHST- 2024/10/19 00:00 [accepted]
PHST- 2025/01/31 12:23 [medline]
PHST- 2024/11/13 14:00 [pubmed]
PHST- 2024/11/13 02:54 [entrez]
AID - 10.1111/pde.15805 [doi]
PST - ppublish
SO  - Pediatr Dermatol. 2025 Jan-Feb;42(1):106-108. doi: 10.1111/pde.15805. Epub 2024 
      Nov 12.

PMID- 39729356
OWN - NLM
STAT- MEDLINE
DCOM- 20241227
LR  - 20250113
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Dec 27
TI  - Large Language Models in Worldwide Medical Exams: Platform Development and 
      Comprehensive Analysis.
PG  - e66114
LID - 10.2196/66114 [doi]
LID - e66114
AB  - BACKGROUND: Large language models (LLMs) are increasingly integrated into medical 
      education, with transformative potential for learning and assessment. However, 
      their performance across diverse medical exams globally has remained 
      underexplored. OBJECTIVE: This study aims to introduce MedExamLLM, a 
      comprehensive platform designed to systematically evaluate the performance of 
      LLMs on medical exams worldwide. Specifically, the platform seeks to (1) compile 
      and curate performance data for diverse LLMs on worldwide medical exams; (2) 
      analyze trends and disparities in LLM capabilities across geographic regions, 
      languages, and contexts; and (3) provide a resource for researchers, educators, 
      and developers to explore and advance the integration of artificial intelligence 
      in medical education. METHODS: A systematic search was conducted on April 25, 
      2024, in the PubMed database to identify relevant publications. Inclusion 
      criteria encompassed peer-reviewed, English-language, original research articles 
      that evaluated at least one LLM on medical exams. Exclusion criteria included 
      review articles, non-English publications, preprints, and studies without 
      relevant data on LLM performance. The screening process for candidate 
      publications was independently conducted by 2 researchers to ensure accuracy and 
      reliability. Data, including exam information, data process information, model 
      performance, data availability, and references, were manually curated, 
      standardized, and organized. These curated data were integrated into the 
      MedExamLLM platform, enabling its functionality to visualize and analyze LLM 
      performance across geographic, linguistic, and exam characteristics. The web 
      platform was developed with a focus on accessibility, interactivity, and 
      scalability to support continuous data updates and user engagement. RESULTS: A 
      total of 193 articles were included for final analysis. MedExamLLM comprised 
      information for 16 LLMs on 198 medical exams conducted in 28 countries across 15 
      languages from the year 2009 to the year 2023. The United States accounted for 
      the highest number of medical exams and related publications, with English being 
      the dominant language used in these exams. The Generative Pretrained Transformer 
      (GPT) series models, especially GPT-4, demonstrated superior performance, 
      achieving pass rates significantly higher than other LLMs. The analysis revealed 
      significant variability in the capabilities of LLMs across different geographic 
      and linguistic contexts. CONCLUSIONS: MedExamLLM is an open-source, freely 
      accessible, and publicly available online platform providing comprehensive 
      performance evaluation information and evidence knowledge about LLMs on medical 
      exams around the world. The MedExamLLM platform serves as a valuable resource for 
      educators, researchers, and developers in the fields of clinical medicine and 
      artificial intelligence. By synthesizing evidence on LLM capabilities, the 
      platform provides valuable insights to support the integration of artificial 
      intelligence into medical education. Limitations include potential biases in the 
      data source and the exclusion of non-English literature. Future research should 
      address these gaps and explore methods to enhance LLM performance in diverse 
      contexts.
CI  - ©Hui Zong, Rongrong Wu, Jiaxue Cha, Jiao Wang, Erman Wu, Jiakun Li, Yi Zhou, Chi 
      Zhang, Weizhe Feng, Bairong Shen. Originally published in the Journal of Medical 
      Internet Research (https://www.jmir.org), 27.12.2024.
FAU - Zong, Hui
AU  - Zong H
AUID- ORCID: 0000-0002-9142-5017
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
FAU - Wu, Rongrong
AU  - Wu R
AUID- ORCID: 0000-0003-3876-1609
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
FAU - Cha, Jiaxue
AU  - Cha J
AUID- ORCID: 0000-0002-5917-5441
AD  - Shanghai Key Laboratory of Signaling and Disease Research, School of Life 
      Sciences and Technology, Tongji University, Shanghai, China.
FAU - Wang, Jiao
AU  - Wang J
AUID- ORCID: 0000-0003-2790-7828
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
FAU - Wu, Erman
AU  - Wu E
AUID- ORCID: 0000-0002-2363-3738
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
AD  - Department of Neurosurgery, First Affiliated Hospital of Xinjiang Medical 
      University, Urumqi, China.
FAU - Li, Jiakun
AU  - Li J
AUID- ORCID: 0000-0003-4996-9907
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
AD  - Department of Urology, West China Hospital, Sichuan University, Chengdu, China.
FAU - Zhou, Yi
AU  - Zhou Y
AUID- ORCID: 0000-0002-9912-581X
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
FAU - Zhang, Chi
AU  - Zhang C
AUID- ORCID: 0009-0000-7838-9114
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
FAU - Feng, Weizhe
AU  - Feng W
AUID- ORCID: 0009-0008-8884-0114
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
FAU - Shen, Bairong
AU  - Shen B
AUID- ORCID: 0000-0003-2899-1531
AD  - Joint Laboratory of Artificial Intelligence for Critical Care Medicine, 
      Department of Critical Care Medicine and Institutes for Systems Genetics, 
      Frontiers Science Center for Disease-related Molecular Network, West China 
      Hospital, Sichuan University, Chengdu, China.
AD  - West China Tianfu Hospital, Sichuan University, Chengdu, China.
LA  - eng
PT  - Journal Article
DEP - 20241227
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Artificial Intelligence
MH  - *Education, Medical/methods
MH  - Language
PMC - PMC11724220
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLMs
OT  - artifical intelligence
OT  - generative pretrained transformer
OT  - large language models
OT  - medical education
OT  - medical exam
COIS- Conflicts of Interest: None declared.
EDAT- 2024/12/27 12:20
MHDA- 2024/12/27 18:21
PMCR- 2024/12/27
CRDT- 2024/12/27 11:53
PHST- 2024/09/04 00:00 [received]
PHST- 2024/12/10 00:00 [accepted]
PHST- 2024/11/06 00:00 [revised]
PHST- 2024/12/27 18:21 [medline]
PHST- 2024/12/27 12:20 [pubmed]
PHST- 2024/12/27 11:53 [entrez]
PHST- 2024/12/27 00:00 [pmc-release]
AID - v26i1e66114 [pii]
AID - 10.2196/66114 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Dec 27;26:e66114. doi: 10.2196/66114.

PMID- 37223340
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230525
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 5
DP  - 2023 May
TI  - ChatGPT-4 and the Global Burden of Disease Study: Advancing Personalized 
      Healthcare Through Artificial Intelligence in Clinical and Translational 
      Medicine.
PG  - e39384
LID - 10.7759/cureus.39384 [doi]
LID - e39384
AB  - The fusion of insights from the comprehensive global burden of disease (GBD) 
      study and the advanced artificial intelligence of open artificial intelligence 
      (AI) chat generative pre-trained transformer version 4 (ChatGPT-4) brings the 
      potential to transform personalized healthcare planning. By integrating the 
      data-driven findings of the GBD study with the powerful conversational 
      capabilities of ChatGPT-4, healthcare professionals can devise customized 
      healthcare plans that are adapted to patients' lifestyles and preferences. We 
      propose that this innovative partnership can lead to the creation of a novel 
      AI-assisted personalized disease burden (AI-PDB) assessment and planning tool. 
      For the successful implementation of this unconventional technology, it is 
      crucial to ensure continuous and accurate updates, expert supervision, and 
      address potential biases and limitations. Healthcare professionals and 
      stakeholders should have a balanced and dynamic approach, emphasizing 
      interdisciplinary collaborations, data accuracy, transparency, ethical 
      compliance, and ongoing training. By investing in the unique strengths of both 
      ChatGPT-4, especially its newly introduced features such as live internet 
      browsing or plugins, and the GBD study, we may enhance personalized healthcare 
      planning. This innovative approach has the potential to improve patient outcomes 
      and optimize resource utilization, as well as pave the way for the worldwide 
      implementation of precision medicine, thereby revolutionizing the existing 
      healthcare landscape. However, to fully harness these benefits at both the global 
      and individual levels, further research and development are warranted. This will 
      ensure that we effectively tap into the potential of this synergy, bringing 
      societies closer to a future where personalized healthcare is the norm rather 
      than the exception.
CI  - Copyright © 2023, Temsah et al.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - Pediatric Intensive Care Unit, Department of Pediatrics, King Saud University 
      Medical City, College of Medicine, King Saud University, Riyadh, SAU.
FAU - Jamal, Amr
AU  - Jamal A
AD  - Department of Family and Community Medicine, College of Medicine, King Saud 
      University, Riyadh, SAU.
AD  - Evidence-Based Health Care & Knowledge Translation Research Chair, Department of 
      Family and Community Medicine, College of Medicine, King Saud University, Riyadh, 
      SAU.
FAU - Aljamaan, Fadi
AU  - Aljamaan F
AD  - Department of Critical Care, College of Medicine, King Saud University, Riyadh, 
      SAU.
FAU - Al-Tawfiq, Jaffar A
AU  - Al-Tawfiq JA
AD  - Department of Specialty Internal Medicine and Quality, Johns Hopkins Aramco 
      Healthcare, Dhahran, SAU.
AD  - Infectious Disease Division, Department of Medicine, Indiana University School of 
      Medicine, Indianapolis, USA.
AD  - Infectious Disease Division, Department of Medicine, Johns Hopkins University 
      School of Medicine, Baltimore, USA.
FAU - Al-Eyadhy, Ayman
AU  - Al-Eyadhy A
AD  - Pediatric Intensive Care Unit, Department of Pediatrics, College of Medicine, 
      King Saud University, Riyadh, SAU.
AD  - Pediatric Intensive Care Unit, King Saud University Medical City, Riyadh, SAU.
LA  - eng
PT  - Editorial
DEP - 20230523
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10204616
OTO - NOTNLM
OT  - ai-assisted personalized disease burden
OT  - chatbots
OT  - chatgpt-4
OT  - global burden of disease (gbd)
OT  - personalized healthcare plan
OT  - precision medicine
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/05/24 13:08
MHDA- 2023/05/24 13:09
PMCR- 2023/05/23
CRDT- 2023/05/24 11:46
PHST- 2023/05/23 00:00 [accepted]
PHST- 2023/05/24 13:09 [medline]
PHST- 2023/05/24 13:08 [pubmed]
PHST- 2023/05/24 11:46 [entrez]
PHST- 2023/05/23 00:00 [pmc-release]
AID - 10.7759/cureus.39384 [doi]
PST - epublish
SO  - Cureus. 2023 May 23;15(5):e39384. doi: 10.7759/cureus.39384. eCollection 2023 
      May.

PMID- 37948100
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231127
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 7
DP  - 2023 Nov 10
TI  - Strengths and Weaknesses of ChatGPT Models for Scientific Writing About Medical 
      Vitamin B12: Mixed Methods Study.
PG  - e49459
LID - 10.2196/49459 [doi]
LID - e49459
AB  - BACKGROUND: ChatGPT is a large language model developed by OpenAI designed to 
      generate human-like responses to prompts. OBJECTIVE: This study aims to evaluate 
      the ability of GPT-4 to generate scientific content and assist in scientific 
      writing using medical vitamin B12 as the topic. Furthermore, the study will 
      compare the performance of GPT-4 to its predecessor, GPT-3.5. METHODS: The study 
      examined responses from GPT-4 and GPT-3.5 to vitamin B12-related prompts, 
      focusing on their quality and characteristics and comparing them to established 
      scientific literature. RESULTS: The results indicated that GPT-4 can potentially 
      streamline scientific writing through its ability to edit language and write 
      abstracts, keywords, and abbreviation lists. However, significant limitations of 
      ChatGPT were revealed, including its inability to identify and address bias, 
      inability to include recent information, lack of transparency, and inclusion of 
      inaccurate information. Additionally, it cannot check for plagiarism or provide 
      proper references. The accuracy of GPT-4's answers was found to be superior to 
      GPT-3.5. CONCLUSIONS: ChatGPT can be considered a helpful assistant in the 
      writing process but not a replacement for a scientist's expertise. Researchers 
      must remain aware of its limitations and use it appropriately. The improvements 
      in consecutive ChatGPT versions suggest the possibility of overcoming some 
      present limitations in the near future.
CI  - ©Omar Abuyaman. Originally published in JMIR Formative Research 
      (https://formative.jmir.org), 10.11.2023.
FAU - Abuyaman, Omar
AU  - Abuyaman O
AUID- ORCID: 0000-0002-7694-7941
AD  - Department of Medical Laboratory Sciences, Faculty of Applied Medical Sciences, 
      The Hashemite University, Zarqa, 13133, Jordan.
LA  - eng
PT  - Journal Article
DEP - 20231110
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
PMC - PMC10674142
OTO - NOTNLM
OT  - AI
OT  - AI solutions
OT  - ChatGPT
OT  - GPT-3.5
OT  - GPT-4
OT  - artificial intelligence
OT  - language editing
OT  - scientific content
OT  - vitamin B12
OT  - wide range information
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/10 12:45
MHDA- 2023/11/10 12:46
PMCR- 2023/11/10
CRDT- 2023/11/10 11:53
PHST- 2023/05/30 00:00 [received]
PHST- 2023/10/29 00:00 [accepted]
PHST- 2023/08/17 00:00 [revised]
PHST- 2023/11/10 12:46 [medline]
PHST- 2023/11/10 12:45 [pubmed]
PHST- 2023/11/10 11:53 [entrez]
PHST- 2023/11/10 00:00 [pmc-release]
AID - v7i1e49459 [pii]
AID - 10.2196/49459 [doi]
PST - epublish
SO  - JMIR Form Res. 2023 Nov 10;7:e49459. doi: 10.2196/49459.

PMID- 35322976
OWN - NLM
STAT- MEDLINE
DCOM- 20220418
LR  - 20220418
IS  - 2150-1149 (Electronic)
IS  - 1533-3159 (Linking)
VI  - 25
IP  - 2
DP  - 2022 Mar
TI  - Automated Extraction of Pain Symptoms: A Natural Language Approach using 
      Electronic Health Records.
PG  - E245-E254
AB  - BACKGROUND: Pain costs more than $600 billion annually and affects more than 100 
      million Americans, but is still a poorly understood problem and one for which 
      there is very often limited effective treatment. Electronic health records (EHRs) 
      are the only databases with a high volume of granular pain information that 
      allows for documentation of detailed clinical notes on a patient's subjective 
      experience. OBJECTIVES: This study applied natural language processing (NLP) 
      technology to an EHR dataset as part of a pilot study to capture pain information 
      from clinical notes and prove its feasibility as an efficient method. STUDY 
      DESIGN: Retrospective study. SETTING: All data were from UConn Health John 
      Dempsey Hospital (JDH) in Farmington, CT. METHODS: The JDH EHR dataset contains 
      611,355 clinical narratives from 359,854 patients from diverse demographic 
      backgrounds from 2010 through 2019. These data were processed through a 
      customized NLP pipeline. A training set of 100 notes was annotated based on focus 
      group-generated ontology and used to generate and evaluate an NLP model that was 
      later tested on the remaining notes. Validation of the model was evaluated 
      externally and performance was analyzed. RESULTS: The model identified back pain 
      as the most common location of experienced pain with 40,369 term frequencies. 
      Patients most commonly experienced decreased mobility with their pain with 7,375 
      term frequencies. Pain was most commonly found to be radiating with 26,967 term 
      frequencies and patients most commonly rated their pain as 8/10 with 2,375 term 
      frequencies. All parameters studied had statistical F-scores greater than 0.85. 
      LIMITATIONS: A single-center, pilot study subject to reporting bias, recording 
      bias, and missing patient data. CONCLUSIONS: Our customized NLP model 
      demonstrated good and successful performance in extracting granular pain 
      information from clinical notes in electronic health records.
FAU - Dave, Amisha D
AU  - Dave AD
AD  - University of Connecticut School of Medicine, Farmington, CT.
FAU - Ruano, Gualberto
AU  - Ruano G
AD  - University of Connecticut School of Medicine, Farmington, CT; Institute of Living 
      at Hartford Hospital, Hartford, CT.
FAU - Kost, Jonathan
AU  - Kost J
AD  - Hartford Hospital Pain Treatment Center, West Hartford, CT.
FAU - Wang, Xiaoyan
AU  - Wang X
AD  - Mount Sinai Genomics Incorporation, Stamford, CT.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Pain Physician
JT  - Pain physician
JID - 100954394
SB  - IM
MH  - *Electronic Health Records
MH  - Humans
MH  - *Natural Language Processing
MH  - Pain
MH  - Pilot Projects
MH  - Retrospective Studies
OTO - NOTNLM
OT  - automation
OT  - electronic health records
OT  - natural language processing
OT  - pain location
OT  - pain quality
OT  - pain quantity
OT  - pain symptoms
OT  - Pain ontology
EDAT- 2022/03/25 06:00
MHDA- 2022/04/19 06:00
CRDT- 2022/03/24 11:33
PHST- 2022/03/24 11:33 [entrez]
PHST- 2022/03/25 06:00 [pubmed]
PHST- 2022/04/19 06:00 [medline]
PST - ppublish
SO  - Pain Physician. 2022 Mar;25(2):E245-E254.

PMID- 39280327
OWN - NLM
STAT- MEDLINE
DCOM- 20240916
LR  - 20240919
IS  - 2807-2618 (Electronic)
IS  - 2807-2618 (Linking)
VI  - 4
IP  - 2
DP  - 2024 Aug
TI  - Bibliometric top ten healthcare-related ChatGPT publications in the first ChatGPT 
      anniversary.
PG  - e917
LID - 10.52225/narra.v4i2.917 [doi]
LID - e917
AB  - Since its public release on November 30, 2022, ChatGPT has shown promising 
      potential in diverse healthcare applications despite ethical challenges, privacy 
      issues, and possible biases. The aim of this study was to identify and assess the 
      most influential publications in the field of ChatGPT utility in healthcare using 
      bibliometric analysis. The study employed an advanced search on three databases, 
      Scopus, Web of Science, and Google Scholar, to identify ChatGPT-related records 
      in healthcare education, research, and practice between November 27 and 30, 2023. 
      The ranking was based on the retrieved citation count in each database. The 
      additional alternative metrics that were evaluated included (1) Semantic Scholar 
      highly influential citations, (2) PlumX captures, (3) PlumX mentions, (4) PlumX 
      social media and (5) Altmetric Attention Scores (AASs). A total of 22 unique 
      records published in 17 different scientific journals from 14 different 
      publishers were identified in the three databases. Only two publications were in 
      the top 10 list across the three databases. Variable publication types were 
      identified, with the most common being editorial/commentary publications (n=8/22, 
      36.4%). Nine of the 22 records had corresponding authors affiliated with 
      institutions in the United States (40.9%). The range of citation count varied per 
      database, with the highest range identified in Google Scholar (1019-121), 
      followed by Scopus (242-88), and Web of Science (171-23). Google Scholar 
      citations were correlated significantly with the following metrics: Semantic 
      Scholar highly influential citations (Spearman's correlation coefficient ρ=0.840, 
      p<0.001), PlumX captures (ρ=0.831, p<0.001), PlumX mentions (ρ=0.609, p=0.004), 
      and AASs (ρ=0.542, p=0.009). In conclusion, despite several acknowledged 
      limitations, this study showed the evolving landscape of ChatGPT utility in 
      healthcare. There is an urgent need for collaborative initiatives by all 
      stakeholders involved to establish guidelines for ethical, transparent, and 
      responsible use of ChatGPT in healthcare. The study revealed the correlation 
      between citations and alternative metrics, highlighting its usefulness as a 
      supplement to gauge the impact of publications, even in a rapidly growing 
      research field.
CI  - © 2024 The Author(s).
FAU - Sallam, Malik
AU  - Sallam M
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, Jordan.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Amman, Jordan.
AD  - Department of Translational Medicine, Faculty of Medicine, Lund University, 
      Malmö, Sweden.
LA  - eng
PT  - Journal Article
DEP - 20240805
PL  - Indonesia
TA  - Narra J
JT  - Narra J
JID - 9918625888906676
SB  - IM
MH  - *Bibliometrics
MH  - Humans
MH  - Social Media
MH  - Anniversaries and Special Events
PMC - PMC11391998
OTO - NOTNLM
OT  - ChatGPT in healthcare
OT  - bibliometric analysis
OT  - citation metric
OT  - generative AI in healthcare
OT  - publication impact
COIS- The authors declare that there are no conflicts of interest.
EDAT- 2024/09/17 10:46
MHDA- 2024/09/17 10:47
PMCR- 2024/08/05
CRDT- 2024/09/16 06:01
PHST- 2024/05/29 00:00 [received]
PHST- 2024/07/29 00:00 [accepted]
PHST- 2024/09/17 10:47 [medline]
PHST- 2024/09/17 10:46 [pubmed]
PHST- 2024/09/16 06:01 [entrez]
PHST- 2024/08/05 00:00 [pmc-release]
AID - NarraJ-4-e917 [pii]
AID - 10.52225/narra.v4i2.917 [doi]
PST - ppublish
SO  - Narra J. 2024 Aug;4(2):e917. doi: 10.52225/narra.v4i2.917. Epub 2024 Aug 5.

PMID- 38147277
OWN - NLM
STAT- MEDLINE
DCOM- 20240306
LR  - 20240306
IS  - 1573-6628 (Electronic)
IS  - 1092-7875 (Linking)
VI  - 28
IP  - 3
DP  - 2024 Mar
TI  - Using Natural Language Processing to Identify Stigmatizing Language in Labor and 
      Birth Clinical Notes.
PG  - 578-586
LID - 10.1007/s10995-023-03857-4 [doi]
AB  - INTRODUCTION: Stigma and bias related to race and other minoritized statuses may 
      underlie disparities in pregnancy and birth outcomes. One emerging method to 
      identify bias is the study of stigmatizing language in the electronic health 
      record. The objective of our study was to develop automated natural language 
      processing (NLP) methods to identify two types of stigmatizing language: 
      marginalizing language and its complement, power/privilege language, accurately 
      and automatically in labor and birth notes. METHODS: We analyzed notes for all 
      birthing people > 20 weeks' gestation admitted for labor and birth at two 
      hospitals during 2017. We then employed text preprocessing techniques, 
      specifically using TF-IDF values as inputs, and tested machine learning 
      classification algorithms to identify stigmatizing and power/privilege language 
      in clinical notes. The algorithms assessed included Decision Trees, Random 
      Forest, and Support Vector Machines. Additionally, we applied a feature 
      importance evaluation method (InfoGain) to discern words that are highly 
      correlated with these language categories. RESULTS: For marginalizing language, 
      Decision Trees yielded the best classification with an F-score of 0.73. For 
      power/privilege language, Support Vector Machines performed optimally, achieving 
      an F-score of 0.91. These results demonstrate the effectiveness of the selected 
      machine learning methods in classifying language categories in clinical notes. 
      CONCLUSION: We identified well-performing machine learning methods to 
      automatically detect stigmatizing language in clinical notes. To our knowledge, 
      this is the first study to use NLP performance metrics to evaluate the 
      performance of machine learning methods in discerning stigmatizing language. 
      Future studies should delve deeper into refining and evaluating NLP methods, 
      incorporating the latest algorithms rooted in deep learning.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Barcelona, Veronica
AU  - Barcelona V
AUID- ORCID: 0000-0003-3070-1716
AD  - School of Nursing, Columbia University, 560 West 168th St, Mail Code 6, New York, 
      NY, 10032, USA. vb2534@cumc.columbia.edu.
FAU - Scharp, Danielle
AU  - Scharp D
AD  - School of Nursing, Columbia University, 560 West 168th St, Mail Code 6, New York, 
      NY, 10032, USA.
FAU - Moen, Hans
AU  - Moen H
AD  - Department of Computer Science, Aalto University, Espoo, Finland.
FAU - Davoudi, Anahita
AU  - Davoudi A
AD  - VNS Health, New York, NY, USA.
FAU - Idnay, Betina R
AU  - Idnay BR
AD  - Department of Biomedical Informatics, Columbia University, New York, NY, USA.
FAU - Cato, Kenrick
AU  - Cato K
AD  - School of Nursing, Columbia University, 560 West 168th St, Mail Code 6, New York, 
      NY, 10032, USA.
AD  - University of Pennsylvania, Philadelphia, PA, USA.
FAU - Topaz, Maxim
AU  - Topaz M
AD  - School of Nursing, Columbia University, 560 West 168th St, Mail Code 6, New York, 
      NY, 10032, USA.
LA  - eng
GR  - GBMF9048/Gordon and Betty Moore Foundation/
GR  - Data Science Institute, Columbia University/Data Science Institute, Columbia 
      University/
PT  - Journal Article
DEP - 20231226
PL  - United States
TA  - Matern Child Health J
JT  - Maternal and child health journal
JID - 9715672
SB  - IM
MH  - Female
MH  - Humans
MH  - *Natural Language Processing
MH  - *Algorithms
MH  - Electronic Health Records
MH  - Machine Learning
MH  - Language
OTO - NOTNLM
OT  - Bias
OT  - Electronic health records
OT  - Natural language processing
EDAT- 2023/12/26 12:42
MHDA- 2024/03/06 06:44
CRDT- 2023/12/26 11:11
PHST- 2023/12/10 00:00 [accepted]
PHST- 2024/03/06 06:44 [medline]
PHST- 2023/12/26 12:42 [pubmed]
PHST- 2023/12/26 11:11 [entrez]
AID - 10.1007/s10995-023-03857-4 [pii]
AID - 10.1007/s10995-023-03857-4 [doi]
PST - ppublish
SO  - Matern Child Health J. 2024 Mar;28(3):578-586. doi: 10.1007/s10995-023-03857-4. 
      Epub 2023 Dec 26.

PMID- 38335017
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240227
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Feb 9
TI  - Performance of ChatGPT on the Chinese Postgraduate Examination for Clinical 
      Medicine: Survey Study.
PG  - e48514
LID - 10.2196/48514 [doi]
LID - e48514
AB  - BACKGROUND: ChatGPT, an artificial intelligence (AI) based on large-scale 
      language models, has sparked interest in the field of health care. Nonetheless, 
      the capabilities of AI in text comprehension and generation are constrained by 
      the quality and volume of available training data for a specific language, and 
      the performance of AI across different languages requires further investigation. 
      While AI harbors substantial potential in medicine, it is imperative to tackle 
      challenges such as the formulation of clinical care standards; facilitating 
      cultural transitions in medical education and practice; and managing ethical 
      issues including data privacy, consent, and bias. OBJECTIVE: The study aimed to 
      evaluate ChatGPT's performance in processing Chinese Postgraduate Examination for 
      Clinical Medicine questions, assess its clinical reasoning ability, investigate 
      potential limitations with the Chinese language, and explore its potential as a 
      valuable tool for medical professionals in the Chinese context. METHODS: A data 
      set of Chinese Postgraduate Examination for Clinical Medicine questions was used 
      to assess the effectiveness of ChatGPT's (version 3.5) medical knowledge in the 
      Chinese language, which has a data set of 165 medical questions that were divided 
      into three categories: (1) common questions (n=90) assessing basic medical 
      knowledge, (2) case analysis questions (n=45) focusing on clinical 
      decision-making through patient case evaluations, and (3) multichoice questions 
      (n=30) requiring the selection of multiple correct answers. First of all, we 
      assessed whether ChatGPT could meet the stringent cutoff score defined by the 
      government agency, which requires a performance within the top 20% of candidates. 
      Additionally, in our evaluation of ChatGPT's performance on both original and 
      encoded medical questions, 3 primary indicators were used: accuracy, concordance 
      (which validates the answer), and the frequency of insights. RESULTS: Our 
      evaluation revealed that ChatGPT scored 153.5 out of 300 for original questions 
      in Chinese, which signifies the minimum score set to ensure that at least 20% 
      more candidates pass than the enrollment quota. However, ChatGPT had low accuracy 
      in answering open-ended medical questions, with only 31.5% total accuracy. The 
      accuracy for common questions, multichoice questions, and case analysis questions 
      was 42%, 37%, and 17%, respectively. ChatGPT achieved a 90% concordance across 
      all questions. Among correct responses, the concordance was 100%, significantly 
      exceeding that of incorrect responses (n=57, 50%; P<.001). ChatGPT provided 
      innovative insights for 80% (n=132) of all questions, with an average of 2.95 
      insights per accurate response. CONCLUSIONS: Although ChatGPT surpassed the 
      passing threshold for the Chinese Postgraduate Examination for Clinical Medicine, 
      its performance in answering open-ended medical questions was suboptimal. 
      Nonetheless, ChatGPT exhibited high internal concordance and the ability to 
      generate multiple insights in the Chinese language. Future research should 
      investigate the language-based discrepancies in ChatGPT's performance within the 
      health care context.
CI  - ©Peng Yu, Changchang Fang, Xiaolin Liu, Wanying Fu, Jitao Ling, Zhiwei Yan, Yuan 
      Jiang, Zhengyu Cao, Maoxiong Wu, Zhiteng Chen, Wengen Zhu, Yuling Zhang, Ayiguli 
      Abudukeremu, Yue Wang, Xiao Liu, Jingfeng Wang. Originally published in JMIR 
      Medical Education (https://mededu.jmir.org), 09.02.2024.
FAU - Yu, Peng
AU  - Yu P
AUID- ORCID: 0009-0008-0345-5787
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Fang, Changchang
AU  - Fang C
AUID- ORCID: 0009-0006-0794-4188
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Liu, Xiaolin
AU  - Liu X
AUID- ORCID: 0009-0000-4824-8820
AD  - Department of Cardiology, The Eighth Affiliated Hospital of Sun Yat-sen 
      University, Shenzhen, China.
FAU - Fu, Wanying
AU  - Fu W
AUID- ORCID: 0009-0003-7778-7219
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Ling, Jitao
AU  - Ling J
AUID- ORCID: 0000-0002-1720-8620
AD  - Department of Endocrine, The Second Affiliated Hospital of Nanchang University, 
      Jiangxi, China.
FAU - Yan, Zhiwei
AU  - Yan Z
AUID- ORCID: 0000-0002-1754-9126
AD  - College of Kinesiology, Shenyang Sport University, Shenyang, China.
FAU - Jiang, Yuan
AU  - Jiang Y
AUID- ORCID: 0000-0001-8704-3676
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Cao, Zhengyu
AU  - Cao Z
AUID- ORCID: 0000-0002-8372-3735
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Wu, Maoxiong
AU  - Wu M
AUID- ORCID: 0000-0002-6943-2763
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Chen, Zhiteng
AU  - Chen Z
AUID- ORCID: 0000-0002-0322-323X
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Zhu, Wengen
AU  - Zhu W
AUID- ORCID: 0000-0002-1280-0158
AD  - Department of Cardiology, The First Affiliated Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Zhang, Yuling
AU  - Zhang Y
AUID- ORCID: 0000-0002-9071-3148
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Abudukeremu, Ayiguli
AU  - Abudukeremu A
AUID- ORCID: 0009-0004-7895-9761
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Wang, Yue
AU  - Wang Y
AUID- ORCID: 0009-0006-3194-5375
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Liu, Xiao
AU  - Liu X
AUID- ORCID: 0000-0002-5570-289X
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
FAU - Wang, Jingfeng
AU  - Wang J
AUID- ORCID: 0009-0005-7309-6984
AD  - Department of Cardiology, Sun Yat-sen Memorial Hospital of Sun Yat-sen 
      University, Guangzhou, China.
LA  - eng
PT  - Journal Article
DEP - 20240209
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - *Artificial Intelligence
MH  - *Clinical Medicine
MH  - Language
MH  - *Educational Measurement
PMC - PMC10891494
OTO - NOTNLM
OT  - ChatGPT
OT  - Chinese Postgraduate Examination for Clinical Medicine
OT  - artificial intelligence
OT  - clinical decision-making
OT  - medical care
OT  - medical education
OT  - medical student
OT  - performance
OT  - qualitative feedback
COIS- Conflicts of Interest: None declared.
EDAT- 2024/02/09 12:44
MHDA- 2024/02/10 22:54
PMCR- 2024/02/09
CRDT- 2024/02/09 11:53
PHST- 2023/04/26 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/10/04 00:00 [revised]
PHST- 2024/02/10 22:54 [medline]
PHST- 2024/02/09 12:44 [pubmed]
PHST- 2024/02/09 11:53 [entrez]
PHST- 2024/02/09 00:00 [pmc-release]
AID - v10i1e48514 [pii]
AID - 10.2196/48514 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Feb 9;10:e48514. doi: 10.2196/48514.

PMID- 39433945
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241024
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 7
IP  - 1
DP  - 2024 Oct 21
TI  - Evaluation and mitigation of cognitive biases in medical language models.
PG  - 295
LID - 10.1038/s41746-024-01283-6 [doi]
LID - 295
AB  - Increasing interest in applying large language models (LLMs) to medicine is due 
      in part to their impressive performance on medical exam questions. However, these 
      exams do not capture the complexity of real patient-doctor interactions because 
      of factors like patient compliance, experience, and cognitive bias. We 
      hypothesized that LLMs would produce less accurate responses when faced with 
      clinically biased questions as compared to unbiased ones. To test this, we 
      developed the BiasMedQA dataset, which consists of 1273 USMLE questions modified 
      to replicate common clinically relevant cognitive biases. We assessed six LLMs on 
      BiasMedQA and found that GPT-4 stood out for its resilience to bias, in contrast 
      to Llama 2 70B-chat and PMC Llama 13B, which showed large drops in performance. 
      Additionally, we introduced three bias mitigation strategies, which improved but 
      did not fully restore accuracy. Our findings highlight the need to improve LLMs' 
      robustness to cognitive biases, in order to achieve more reliable applications of 
      LLMs in healthcare.
CI  - © 2024. The Author(s).
FAU - Schmidgall, Samuel
AU  - Schmidgall S
AD  - Department of Electrical and Computer Engineering, Johns Hopkins University, 
      Baltimore, MD, USA. sschmi46@jhu.edu.
FAU - Harris, Carl
AU  - Harris C
AD  - Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, 
      USA.
FAU - Essien, Ime
AU  - Essien I
AD  - Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, 
      USA.
FAU - Olshvang, Daniel
AU  - Olshvang D
AD  - Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, 
      USA.
FAU - Rahman, Tawsifur
AU  - Rahman T
AD  - Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, 
      USA.
FAU - Kim, Ji Woong
AU  - Kim JW
AD  - Department of Mechanical Engineering, Johns Hopkins University, Baltimore, MD, 
      USA.
FAU - Ziaei, Rojin
AU  - Ziaei R
AD  - Department of Computer Science, University of Maryland, College Park, MD, USA.
FAU - Eshraghian, Jason
AU  - Eshraghian J
AD  - Department of Electrical and Computer Engineering, University of California, 
      Santa Cruz, CA, USA.
FAU - Abadir, Peter
AU  - Abadir P
AD  - Division of Geriatric Medicine and Gerontology, Johns Hopkins University School 
      of Medicine, Baltimore, MD, USA.
FAU - Chellappa, Rama
AU  - Chellappa R
AD  - Department of Electrical and Computer Engineering, Johns Hopkins University, 
      Baltimore, MD, USA.
AD  - Department of Biomedical Engineering, Johns Hopkins University, Baltimore, MD, 
      USA.
LA  - eng
GR  - P30 AG073104/AG/NIA NIH HHS/United States
GR  - 2139757/National Science Foundation (NSF)/
GR  - P30AG073104/U.S. Department of Health & Human Services | NIH | National Institute 
      on Aging (U.S. National Institute on Aging)/
PT  - Journal Article
DEP - 20241021
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC11494053
COIS- The authors declare no competing interests.
EDAT- 2024/10/22 00:21
MHDA- 2024/10/22 00:22
PMCR- 2024/10/21
CRDT- 2024/10/21 23:41
PHST- 2024/05/15 00:00 [received]
PHST- 2024/10/02 00:00 [accepted]
PHST- 2024/10/22 00:22 [medline]
PHST- 2024/10/22 00:21 [pubmed]
PHST- 2024/10/21 23:41 [entrez]
PHST- 2024/10/21 00:00 [pmc-release]
AID - 10.1038/s41746-024-01283-6 [pii]
AID - 1283 [pii]
AID - 10.1038/s41746-024-01283-6 [doi]
PST - epublish
SO  - NPJ Digit Med. 2024 Oct 21;7(1):295. doi: 10.1038/s41746-024-01283-6.

PMID- 39720391
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 11
DP  - 2024 Nov
TI  - ChatGPT-4 Turbo and Meta's LLaMA 3.1: A Relative Analysis of Answering Radiology 
      Text-Based Questions.
PG  - e74359
LID - 10.7759/cureus.74359 [doi]
LID - e74359
AB  - AIMS AND OBJECTIVES: This study aimed to compare the accuracy of two AI models - 
      OpenAI's GPT-4 Turbo (San Francisco, CA) and Meta's LLaMA 3.1 (Menlo Park, CA) - 
      when answering a standardized set of pediatric radiology questions. The primary 
      objective was to evaluate the overall accuracy of each model, while the secondary 
      objective was to assess their performance within subsections. METHODS AND 
      MATERIALS: A total of 79 text-based pediatric radiology questions were selected 
      out of 302 total questions for this comparison. The questions covered seven 
      subsections, including musculoskeletal, chest, and neuroradiology, among others. 
      Image-based questions were excluded to focus on text interpretation and to 
      minimize the sampling bias within each model. Each model was tested independently 
      on the same question set, and the percent accuracy was calculated for both 
      overall performance as well as individual subsections. RESULTS: GPT-4 Turbo 
      performed at an overall accuracy of 88.6% (70/79 questions), outperforming LLaMA 
      3.1's 77.2% (61/79). Within subsections, GPT-4 Turbo had higher accuracy in most 
      areas, except for equal accuracy in the neuroradiology section. The subsections 
      with the greatest accuracy for GPT-4 Turbo, in descending order, were chest and 
      cardiac radiology (100%), musculoskeletal system (93.3%), and genitourinary 
      system (92.9%). LLaMA 3.1's highest performance was 86.7% in the musculoskeletal 
      system, while its lowest was 50.0% in chest radiology. CONCLUSION: GPT-4 Turbo 
      consistently outperformed LLaMA 3.1 in answering pediatric radiology questions, 
      both overall and within most subsections. These findings suggest that GPT-4 Turbo 
      may offer more accurate responses in specialized medical education, in contrast 
      to LLaMA 3.1's efficient performance, although future research should further 
      evaluate AI models' performance within other fields.
CI  - Copyright © 2024, Abdul Sami et al.
FAU - Abdul Sami, Mohammed
AU  - Abdul Sami M
AD  - Department of Diagnostic Radiology and Nuclear Medicine, Rush University Medical 
      Center, Chicago, USA.
FAU - Abdul Samad, Mohammed
AU  - Abdul Samad M
AD  - Department of Osteopathic Medicine, Des Moines University College of Osteopathic 
      Medicine, West Des Moines, USA.
FAU - Parekh, Keyur
AU  - Parekh K
AD  - Department of Diagnostic Radiology and Nuclear Medicine, Rush University Medical 
      Center, Chicago, USA.
FAU - Suthar, Pokhraj P
AU  - Suthar PP
AD  - Department of Diagnostic Radiology and Nuclear Medicine, Rush University Medical 
      Center, Chicago, USA.
LA  - eng
PT  - Journal Article
DEP - 20241124
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11668536
OTO - NOTNLM
OT  - ai in medical education
OT  - chatgpt
OT  - large language models (llms)
OT  - llama
OT  - pediatric radiology
COIS- Human subjects: All authors have confirmed that this study did not involve human 
      participants or tissue. Animal subjects: All authors have confirmed that this 
      study did not involve animal subjects or tissue. Conflicts of interest: In 
      compliance with the ICMJE uniform disclosure form, all authors declare the 
      following: Payment/services info: All authors have declared that no financial 
      support was received from any organization for the submitted work. Financial 
      relationships: All authors have declared that they have no financial 
      relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2024/12/25 06:20
MHDA- 2024/12/25 06:21
PMCR- 2024/11/24
CRDT- 2024/12/25 04:23
PHST- 2024/11/23 00:00 [accepted]
PHST- 2024/12/25 06:21 [medline]
PHST- 2024/12/25 06:20 [pubmed]
PHST- 2024/12/25 04:23 [entrez]
PHST- 2024/11/24 00:00 [pmc-release]
AID - 10.7759/cureus.74359 [doi]
PST - epublish
SO  - Cureus. 2024 Nov 24;16(11):e74359. doi: 10.7759/cureus.74359. eCollection 2024 
      Nov.

PMID- 39078641
OWN - NLM
STAT- MEDLINE
DCOM- 20240730
LR  - 20240730
IS  - 1523-5378 (Electronic)
IS  - 1083-4389 (Linking)
VI  - 29
IP  - 1
DP  - 2024 Jan-Feb
TI  - Comparative analysis of large language models in medical counseling: A focus on 
      Helicobacter pylori infection.
PG  - e13055
LID - 10.1111/hel.13055 [doi]
AB  - BACKGROUND: Large language models (LLMs) are promising medical counseling tools, 
      but the reliability of responses remains unclear. We aimed to assess the 
      feasibility of three popular LLMs as counseling tools for Helicobacter pylori 
      infection in different counseling languages. MATERIALS AND METHODS: This study 
      was conducted between November 20 and December 1, 2023. Three large language 
      models (ChatGPT 4.0 [LLM1], ChatGPT 3.5 [LLM2], and ERNIE Bot 4.0 [LLM3]) were 
      input 15 H. pylori related questions each, once in English and once in Chinese. 
      Each chat was conducted using the "New Chat" function to avoid bias from 
      correlation interference. Responses were recorded and blindly assigned to three 
      reviewers for scoring on three established Likert scales: accuracy (ranged 1-6 
      point), completeness (ranged 1-3 point), and comprehensibility (ranged 1-3 
      point). The acceptable thresholds for the scales were set at a minimum of 4, 2, 
      and 2, respectively. Final various source and interlanguage comparisons were 
      made. RESULTS: The overall mean (SD) accuracy score was 4.80 (1.02), while 1.82 
      (0.78) for completeness score and 2.90 (0.36) for comprehensibility score. The 
      acceptable proportions for the accuracy, completeness, and comprehensibility of 
      the responses were 90%, 45.6%, and 100%, respectively. The acceptable proportion 
      of overall completeness score for English responses was better than for Chinese 
      responses (p = 0.034). For accuracy, the English responses of LLM3 were better 
      than the Chinese responses (p = 0.0055). As for completeness, the English 
      responses of LLM1 was better than the Chinese responses (p = 0.0257). For 
      comprehensibility, the English responses of LLM1 was better than the Chinese 
      responses (p = 0.0496). No differences were found between the various LLMs. 
      CONCLUSIONS: The LLMs responded satisfactorily to questions related to H. pylori 
      infection. But further improving completeness and reliability, along with 
      considering language nuances, is crucial for optimizing overall performance.
CI  - © 2024 John Wiley & Sons Ltd.
FAU - Kong, Qing-Zhou
AU  - Kong QZ
AUID- ORCID: 0000-0002-4744-3269
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
FAU - Ju, Kun-Ping
AU  - Ju KP
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
FAU - Wan, Meng
AU  - Wan M
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
FAU - Liu, Jing
AU  - Liu J
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
FAU - Wu, Xiao-Qi
AU  - Wu XQ
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
FAU - Li, Yue-Yue
AU  - Li YY
AUID- ORCID: 0000-0001-7042-9695
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
FAU - Zuo, Xiu-Li
AU  - Zuo XL
AUID- ORCID: 0000-0001-9556-8771
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
FAU - Li, Yan-Qing
AU  - Li YQ
AUID- ORCID: 0000-0001-9325-4808
AD  - Department of Gastroenterology, Qilu Hospital of Shandong University, Jinan, 
      Shandong, China.
AD  - Shandong Provincial Clinical Research Center for Digestive Disease, Jinan, 
      Shandong, China.
AD  - Laboratory of Translational Gastroenterology, Qilu Hospital of Shandong 
      University, Jinan, Shandong, China.
AD  - Robot Engineering Laboratory for Precise Diagnosis and Therapy of GI Tumor, Qilu 
      Hospital of Shandong University, Jinan, Shandong, China.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PL  - England
TA  - Helicobacter
JT  - Helicobacter
JID - 9605411
SB  - IM
MH  - Humans
MH  - *Helicobacter Infections/diagnosis
MH  - *Counseling
MH  - *Helicobacter pylori
MH  - *Language
MH  - Reproducibility of Results
MH  - Surveys and Questionnaires
OTO - NOTNLM
OT  - Helicobacter pylori
OT  - counseling tool
OT  - language model
OT  - reliability
EDAT- 2024/07/30 12:43
MHDA- 2024/07/30 12:44
CRDT- 2024/07/30 11:33
PHST- 2024/01/11 00:00 [revised]
PHST- 2023/12/14 00:00 [received]
PHST- 2024/01/24 00:00 [accepted]
PHST- 2024/07/30 12:44 [medline]
PHST- 2024/07/30 12:43 [pubmed]
PHST- 2024/07/30 11:33 [entrez]
AID - 10.1111/hel.13055 [doi]
PST - ppublish
SO  - Helicobacter. 2024 Jan-Feb;29(1):e13055. doi: 10.1111/hel.13055.

PMID- 38965411
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240707
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 7
IP  - 1
DP  - 2024 Jul 4
TI  - The long but necessary road to responsible use of large language models in 
      healthcare research.
PG  - 177
LID - 10.1038/s41746-024-01180-y [doi]
LID - 177
AB  - Large language models (LLMs) have shown promise in reducing time, costs, and 
      errors associated with manual data extraction. A recent study demonstrated that 
      LLMs outperformed natural language processing approaches in abstracting pathology 
      report information. However, challenges include the risks of weakening critical 
      thinking, propagating biases, and hallucinations, which may undermine the 
      scientific method and disseminate inaccurate information. Incorporating suitable 
      guidelines (e.g., CANGARU), should be encouraged to ensure responsible LLM use.
FAU - Kwong, Jethro C C
AU  - Kwong JCC
AUID- ORCID: 0000-0003-4728-1025
AD  - Division of Urology, Department of Surgery, University of Toronto, Toronto, ON, 
      Canada. jethro.kwong@mail.utoronto.ca.
AD  - Temerty Centre for AI Research and Education in Medicine, University of Toronto, 
      Toronto, ON, Canada. jethro.kwong@mail.utoronto.ca.
FAU - Wang, Serena C Y
AU  - Wang SCY
AUID- ORCID: 0000-0002-5532-071X
AD  - Harvard Medical School, Boston, MA, USA.
FAU - Nickel, Grace C
AU  - Nickel GC
AD  - Harvard Medical School, Boston, MA, USA.
FAU - Cacciamani, Giovanni E
AU  - Cacciamani GE
AD  - USC Institute of Urology and Catherine and Joseph Aresty Department of Urology, 
      Keck School of Medicine, University of Southern California, Los Angeles, CA, USA.
AD  - AI Center, USC Institute of Urology, University of Southern California, Los 
      Angeles, CA, USA.
FAU - Kvedar, Joseph C
AU  - Kvedar JC
AD  - Harvard Medical School, Boston, MA, USA.
LA  - eng
PT  - Editorial
DEP - 20240704
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC11224331
COIS- JCK is the Editor-in-Chief of npj Digital Medicine. All other authors declare no 
      competing interests.
EDAT- 2024/07/05 00:41
MHDA- 2024/07/05 00:42
PMCR- 2024/07/04
CRDT- 2024/07/04 23:37
PHST- 2024/05/06 00:00 [received]
PHST- 2024/06/26 00:00 [accepted]
PHST- 2024/07/05 00:42 [medline]
PHST- 2024/07/05 00:41 [pubmed]
PHST- 2024/07/04 23:37 [entrez]
PHST- 2024/07/04 00:00 [pmc-release]
AID - 10.1038/s41746-024-01180-y [pii]
AID - 1180 [pii]
AID - 10.1038/s41746-024-01180-y [doi]
PST - epublish
SO  - NPJ Digit Med. 2024 Jul 4;7(1):177. doi: 10.1038/s41746-024-01180-y.

PMID- 40110561
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250321
IS  - 2635-0041 (Electronic)
IS  - 2635-0041 (Linking)
VI  - 5
IP  - 1
DP  - 2025
TI  - Drug target assessments: classifying target modulation and associated health 
      effects using multi-level BERT-based classification models.
PG  - vbaf043
LID - 10.1093/bioadv/vbaf043 [doi]
LID - vbaf043
AB  - MOTIVATION: Drug target selection determines the success of the drug development 
      pipeline. Therefore, novel drug targets need to be assessed for their therapeutic 
      benefits/risks at the earliest stage possible. Where manual risk/benefit analyses 
      are often user-biased and time-consuming, Large Language Models can offer a 
      systematic and efficient approach to curating and analysing literature. 
      Currently, publicly available Large Language Models are lacking for this task, 
      while public platforms for target assessments are limited to co-occurrences. 
      RESULTS: BERT-models for multi-level classification of drug target-health effect 
      relationships described in PubMed were developed. Relationships were classified 
      based on (i) causality; (ii) direction of target modulation; (iii) direction of 
      the associated health effect. The models showed competitive performances with F1 
      scores between 0.86 and 0.92 and their applicability was demonstrated using 
      ADAM33 and OSM as case study. The developed classification pipeline is the first 
      to allow detailed classification of drug target-health effect relationships. The 
      models provide mechanistic insight into how target modulation affects health and 
      disease, both from an efficacy and safety perspective. The models, deployed on 
      the whole of PubMed and available through the TargetTri platform, are expected to 
      offer a significant advancement in artificial intelligence-assisted target 
      identification and evaluation. AVAILABILITY AND IMPLEMENTATION: 
      https://www.targettri.com.
CI  - © The Author(s) 2025. Published by Oxford University Press.
FAU - Venhorst, Jennifer
AU  - Venhorst J
AUID- ORCID: 0000-0001-6383-9776
AD  - Biomedical and Digital Health, The Netherlands Organization for Applied 
      Scientific Research (TNO), Utrecht 3584 CB, The Netherlands.
FAU - Kalkman, Gino
AU  - Kalkman G
AD  - Biomedical and Digital Health, The Netherlands Organization for Applied 
      Scientific Research (TNO), Utrecht 3584 CB, The Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20250308
PL  - England
TA  - Bioinform Adv
JT  - Bioinformatics advances
JID - 9918282081306676
PMC - PMC11919816
COIS- None declared.
EDAT- 2025/03/20 11:15
MHDA- 2025/03/20 11:16
PMCR- 2025/03/08
CRDT- 2025/03/20 05:19
PHST- 2024/08/25 00:00 [received]
PHST- 2025/01/10 00:00 [revised]
PHST- 2025/03/04 00:00 [accepted]
PHST- 2025/03/20 11:16 [medline]
PHST- 2025/03/20 11:15 [pubmed]
PHST- 2025/03/20 05:19 [entrez]
PHST- 2025/03/08 00:00 [pmc-release]
AID - vbaf043 [pii]
AID - 10.1093/bioadv/vbaf043 [doi]
PST - epublish
SO  - Bioinform Adv. 2025 Mar 8;5(1):vbaf043. doi: 10.1093/bioadv/vbaf043. eCollection 
      2025.

PMID- 37484787
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230725
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 7
DP  - 2023 Jul
TI  - ChatGPT's Ability to Assess Quality and Readability of Online Medical 
      Information: Evidence From a Cross-Sectional Study.
PG  - e42214
LID - 10.7759/cureus.42214 [doi]
LID - e42214
AB  - Introduction Artificial Intelligence (AI) platforms have gained widespread 
      attention for their distinct ability to generate automated responses to various 
      prompts. However, its role in assessing the quality and readability of a provided 
      text remains unclear. Thus, the purpose of this study is to evaluate the 
      proficiency of the conversational generative pre-trained transformer (ChatGPT) in 
      utilizing the DISCERN tool to evaluate the quality of online content regarding 
      shock wave therapy for erectile dysfunction. Methods Websites were generated 
      using a Google search of "shock wave therapy for erectile dysfunction" with 
      location filters disabled. Readability was analyzed using Readable software 
      (Readable.com, Horsham, United Kingdom). Quality was assessed independently by 
      three reviewers using the DISCERN tool. The same plain text files collected were 
      inputted into ChatGPT to determine whether they produced comparable metrics for 
      readability and quality. Results The study results revealed a notable disparity 
      between ChatGPT's readability assessment and that obtained from a reliable tool, 
      Readable.com (p<0.05). This indicates a lack of alignment between ChatGPT's 
      algorithm and that of established tools, such as Readable.com. Similarly, the 
      DISCERN score generated by ChatGPT differed significantly from the scores 
      generated manually by human evaluators (p<0.05), suggesting that ChatGPT may not 
      be capable of accurately identifying poor-quality information sources regarding 
      shock wave therapy as a treatment for erectile dysfunction. Conclusion ChatGPT's 
      evaluation of the quality and readability of online text regarding shockwave 
      therapy for erectile dysfunction differs from that of human raters and trusted 
      tools. Therefore, ChatGPT's current capabilities were not sufficient for reliably 
      assessing the quality and readability of textual content. Further research is 
      needed to elucidate the role of AI in the objective evaluation of online medical 
      content in other fields. Continued development in AI and incorporation of tools 
      such as DISCERN into AI software may enhance the way patients navigate the web in 
      search of high-quality medical content in the future.
CI  - Copyright © 2023, Golan et al.
FAU - Golan, Roei
AU  - Golan R
AD  - Department of Clinical Sciences, Florida State University College of Medicine, 
      Tallahassee, USA.
FAU - Ripps, Sarah J
AU  - Ripps SJ
AD  - Department of Clinical Sciences, Florida State University College of Medicine, 
      Tallahassee, USA.
FAU - Reddy, Raghuram
AU  - Reddy R
AD  - Herbert Wertheim College of Medicine, Florida International University, Miami, 
      USA.
FAU - Loloi, Justin
AU  - Loloi J
AD  - Department of Urology, Montefiore Medical Center, Bronx, USA.
FAU - Bernstein, Ari P
AU  - Bernstein AP
AD  - Department of Urology, New York University Langone Health, New York, USA.
FAU - Connelly, Zachary M
AU  - Connelly ZM
AD  - Department of Surgery, Louisiana State University Health Shreveport, Shreveport, 
      USA.
FAU - Golan, Noa S
AU  - Golan NS
AD  - Department of Psychology, University of Florida, Gainesville, USA.
FAU - Ramasamy, Ranjith
AU  - Ramasamy R
AD  - Department of Urology, Desai Sethi Urology Institute, Miami, USA.
LA  - eng
PT  - Journal Article
DEP - 20230720
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10362474
OTO - NOTNLM
OT  - artificial intelligence in medicine
OT  - chatgpt
OT  - healthcare ai and robotics
OT  - online medical information
OT  - readability
OT  - shock wave therapy
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/07/24 06:42
MHDA- 2023/07/24 06:43
PMCR- 2023/07/20
CRDT- 2023/07/24 04:48
PHST- 2023/05/16 00:00 [received]
PHST- 2023/07/20 00:00 [accepted]
PHST- 2023/07/24 06:43 [medline]
PHST- 2023/07/24 06:42 [pubmed]
PHST- 2023/07/24 04:48 [entrez]
PHST- 2023/07/20 00:00 [pmc-release]
AID - 10.7759/cureus.42214 [doi]
PST - epublish
SO  - Cureus. 2023 Jul 20;15(7):e42214. doi: 10.7759/cureus.42214. eCollection 2023 
      Jul.

PMID- 37746684
OWN - NLM
STAT- MEDLINE
DCOM- 20230926
LR  - 20230926
IS  - 1747-4892 (Electronic)
IS  - 1747-4884 (Linking)
VI  - 22
IP  - 3
DP  - 2023
TI  - Artificial Intelligence: its Future and Impact on Acute Medicine.
PG  - 150-153
AB  - This commentary explores the potential impact of artificial intelligence (AI) in 
      acute medicine, considering its possibilities and challenges. With its ability to 
      simulate human intelligence, AI holds the promise for supporting timely 
      decision-making and interventions in acute care. While AI has significantly 
      contributed to improvements in various sectors, its implementation in healthcare 
      remains limited. The development of AI tools tailored to acute medicine can 
      improve clinical decision-making, and AI's role in streamlining administrative 
      tasks, exemplified by ChatGPT, may offer immediate benefits. However, challenges 
      include uniform data collection, privacy, bias, and preserving the doctor-patient 
      relationship. Collaboration among AI researchers, healthcare professionals, and 
      policymakers is crucial to harness the potential of AI in acute medicine and 
      create a future where advanced technologies synergistically enhance human 
      expertise.
FAU - Schinkel, M
AU  - Schinkel M
AD  - PhD, Center for Experimental and Molecular Medicine (CEMM), Amsterdam UMC, 
      University of Amsterdam, Amsterdam, The Netherlands.
FAU - Paranjape, K
AU  - Paranjape K
AD  - PhD, Department of Internal Medicine, Division of Acute Medicine, Amsterdam UMC, 
      VU University, Amsterdam, The Netherlands.
FAU - Bhagirath, S C
AU  - Bhagirath SC
AD  - MD, Department of Internal Medicine, Division of Acute Medicine, Amsterdam UMC, 
      VU University, Amsterdam, The Netherlands.
FAU - Nanayakkara, Pwb
AU  - Nanayakkara P
AD  - PhD, Department of Internal Medicine, Division of Acute Medicine, Amsterdam UMC, 
      VU University, Amsterdam, The Netherlands.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Acute Med
JT  - Acute medicine
JID - 101553725
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Physician-Patient Relations
MH  - Clinical Decision-Making
MH  - Critical Care
MH  - Data Collection
EDAT- 2023/09/25 06:41
MHDA- 2023/09/26 13:42
CRDT- 2023/09/25 05:19
PHST- 2023/09/26 13:42 [medline]
PHST- 2023/09/25 06:41 [pubmed]
PHST- 2023/09/25 05:19 [entrez]
PST - ppublish
SO  - Acute Med. 2023;22(3):150-153.

PMID- 40095575
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250319
IS  - 2077-0383 (Print)
IS  - 2077-0383 (Electronic)
IS  - 2077-0383 (Linking)
VI  - 14
IP  - 5
DP  - 2025 Feb 27
TI  - Shaping the Future of Healthcare: Ethical Clinical Challenges and Pathways to 
      Trustworthy AI.
LID - 10.3390/jcm14051605 [doi]
LID - 1605
AB  - Background/Objectives: Artificial intelligence (AI) is transforming healthcare, 
      enabling advances in diagnostics, treatment optimization, and patient care. Yet, 
      its integration raises ethical, regulatory, and societal challenges. Key concerns 
      include data privacy risks, algorithmic bias, and regulatory gaps that struggle 
      to keep pace with AI advancements. This study aims to synthesize a 
      multidisciplinary framework for trustworthy AI in healthcare, focusing on 
      transparency, accountability, fairness, sustainability, and global collaboration. 
      It moves beyond high-level ethical discussions to provide actionable strategies 
      for implementing trustworthy AI in clinical contexts. Methods: A structured 
      literature review was conducted using PubMed, Scopus, and Web of Science. Studies 
      were selected based on relevance to AI ethics, governance, and policy in 
      healthcare, prioritizing peer-reviewed articles, policy analyses, case studies, 
      and ethical guidelines from authoritative sources published within the last 
      decade. The conceptual approach integrates perspectives from clinicians, 
      ethicists, policymakers, and technologists, offering a holistic "ecosystem" view 
      of AI. No clinical trials or patient-level interventions were conducted. Results: 
      The analysis identifies key gaps in current AI governance and introduces the 
      Regulatory Genome-an adaptive AI oversight framework aligned with global policy 
      trends and Sustainable Development Goals. It introduces quantifiable 
      trustworthiness metrics, a comparative analysis of AI categories for clinical 
      applications, and bias mitigation strategies. Additionally, it presents 
      interdisciplinary policy recommendations for aligning AI deployment with ethical, 
      regulatory, and environmental sustainability goals. This study emphasizes 
      measurable standards, multi-stakeholder engagement strategies, and global 
      partnerships to ensure that future AI innovations meet ethical and practical 
      healthcare needs. Conclusions: Trustworthy AI in healthcare requires more than 
      technical advancements-it demands robust ethical safeguards, proactive 
      regulation, and continuous collaboration. By adopting the recommended roadmap, 
      stakeholders can foster responsible innovation, improve patient outcomes, and 
      maintain public trust in AI-driven healthcare.
FAU - Goktas, Polat
AU  - Goktas P
AUID- ORCID: 0000-0001-7183-6890
AD  - UCD School of Computer Science, University College Dublin, D04 V1W8 Dublin, 
      Ireland.
FAU - Grzybowski, Andrzej
AU  - Grzybowski A
AUID- ORCID: 0000-0002-3724-2391
AD  - Department of Ophthalmology, University of Warmia and Mazury, 10-719 Olsztyn, 
      Poland.
AD  - Institute for Research in Ophthalmology, Foundation for Ophthalmology 
      Development, 61-553 Poznan, Poland.
LA  - eng
PT  - Journal Article
DEP - 20250227
PL  - Switzerland
TA  - J Clin Med
JT  - Journal of clinical medicine
JID - 101606588
PMC - PMC11900311
OTO - NOTNLM
OT  - artificial intelligence
OT  - bias
OT  - ethics
OT  - health policy
OT  - large language model
OT  - machine learning
OT  - natural language processing
OT  - privacy
OT  - regulation
COIS- The authors declare no conflicts of interest.
EDAT- 2025/03/17 18:30
MHDA- 2025/03/17 18:31
PMCR- 2025/02/27
CRDT- 2025/03/17 12:39
PHST- 2025/01/07 00:00 [received]
PHST- 2025/02/06 00:00 [revised]
PHST- 2025/02/22 00:00 [accepted]
PHST- 2025/03/17 18:31 [medline]
PHST- 2025/03/17 18:30 [pubmed]
PHST- 2025/03/17 12:39 [entrez]
PHST- 2025/02/27 00:00 [pmc-release]
AID - jcm14051605 [pii]
AID - jcm-14-01605 [pii]
AID - 10.3390/jcm14051605 [doi]
PST - epublish
SO  - J Clin Med. 2025 Feb 27;14(5):1605. doi: 10.3390/jcm14051605.

PMID- 39679140
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 2949-7612 (Electronic)
IS  - 2949-7612 (Linking)
VI  - 2
IP  - 4
DP  - 2024 Dec
TI  - Evaluating Large Language Model-Supported Instructions for Medication Use: First 
      Steps Toward a Comprehensive Model.
PG  - 632-644
LID - 10.1016/j.mcpdig.2024.09.006 [doi]
AB  - OBJECTIVE: To assess the support of large language models (LLMs) in generating 
      clearer and more personalized medication instructions to enhance e-prescription. 
      PATIENTS AND METHODS: We established patient-centered guidelines for adequate, 
      acceptable, and personalized directions to enhance e-prescription. A dataset 
      comprising 104 outpatient scenarios, with an array of medications, administration 
      routes, and patient conditions, was developed following the Brazilian national 
      e-prescribing standard. Three prompts were submitted to a closed-source LLM. The 
      first prompt involved a generic command, the second one was calibrated for 
      content enhancement and personalization, and the third one requested bias 
      mitigation. The third prompt was submitted to an open-source LLM. Outputs were 
      assessed using automated metrics and human evaluation. We conducted the study 
      between March 1, 2024 and September 10, 2024. RESULTS: Adequacy scores of our 
      closed-source LLM's output showed the third prompt outperforming the first and 
      second one. Full and partial acceptability was achieved in 94.3% of texts with 
      the third prompt. Personalization was rated highly, especially with the second 
      and third prompts. The 2 LLMs showed similar adequacy results. Lack of scientific 
      evidence and factual errors were infrequent and unrelated to a particular prompt 
      or LLM. The frequency of hallucinations was different for each LLM and concerned 
      prescriptions issued upon symptom manifestation and medications requiring dosage 
      adjustment or involving intermittent use. Gender bias was found in our 
      closed-source LLM's output for the first and second prompts, with the third one 
      being bias-free. The second LLM's output was bias-free. CONCLUSION: This study 
      demonstrates the potential of LLM-supported generation to produce prescription 
      directions and improve communication between health professionals and patients 
      within the e-prescribing system.
CI  - © 2024 The Authors.
FAU - Reis, Zilma Silveira Nogueira
AU  - Reis ZSN
AD  - Health Informatics Center, Faculty of Medicine, Universidade Federal de Minas 
      Gerais, Belo Horizonte, Minas Gerais, Brazil.
FAU - Pagano, Adriana Silvina
AU  - Pagano AS
AD  - Arts Faculty, Universidade Federal de Minas Gerais, Belo Horizonte, Minas Gerais, 
      Brazil.
FAU - Ramos de Oliveira, Isaias Jose
AU  - Ramos de Oliveira IJ
AD  - Health Informatics Center, Faculty of Medicine, Universidade Federal de Minas 
      Gerais, Belo Horizonte, Minas Gerais, Brazil.
FAU - Dias, Cristiane Dos Santos
AU  - Dias CDS
AD  - Department of Pediatrics, Faculty of Medicine, Universidade Federal de Minas 
      Gerais, Belo Horizonte, Minas Gerais, Brazil.
FAU - Lage, Eura Martins
AU  - Lage EM
AD  - Health Informatics Center, Faculty of Medicine, Universidade Federal de Minas 
      Gerais, Belo Horizonte, Minas Gerais, Brazil.
FAU - Mineiro, Erico Franco
AU  - Mineiro EF
AD  - Department of Design Technology, School of Architecture, Universidade Federal de 
      Minas Gerais, Belo Horizonte, Minas Gerais, Brazil.
FAU - Varella Pereira, Glaucia Miranda
AU  - Varella Pereira GM
AD  - Department of Obstetrics and Gynecology, Faculty of Medical Sciences, 
      Universidade Estadual de Campinas, Campinas, São Paulo, Brazil.
FAU - de Carvalho Gomes, Igor
AU  - de Carvalho Gomes I
AD  - Departamento de Medicina da Comunidade Informação e Decisão em Saúde, National 
      Secretary of Primary Care of the Brazilian Ministry of Health, Brasília, Brazil.
FAU - Basilio, Vinicius Araujo
AU  - Basilio VA
AD  - Health Informatics Center, Faculty of Medicine, Universidade Federal de Minas 
      Gerais, Belo Horizonte, Minas Gerais, Brazil.
FAU - Cruz-Correia, Ricardo João
AU  - Cruz-Correia RJ
AD  - MEDCIDS, Porto University, Porto, Portugal.
FAU - de Jesus, Davi Dos Reis
AU  - de Jesus DDR
AD  - Department of Computer Science, Universidade Federal de São João Del Rei, São 
      João del Rei, Minas Gerais, Brazil.
FAU - de Souza Júnior, Antônio Pereira
AU  - de Souza Júnior AP
AD  - Department of Computer Science, Universidade Federal de São João Del Rei, São 
      João del Rei, Minas Gerais, Brazil.
FAU - da Rocha, Leonardo Chaves Dutra
AU  - da Rocha LCD
AD  - Department of Computer Science, Universidade Federal de São João Del Rei, São 
      João del Rei, Minas Gerais, Brazil.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Mayo Clin Proc Digit Health
JT  - Mayo Clinic proceedings. Digital health
JID - 9918662584506676
PMC - PMC11638470
COIS- The authors report no competing interests.
EDAT- 2024/12/16 17:25
MHDA- 2024/12/16 17:26
PMCR- 2024/12/01
CRDT- 2024/12/16 07:25
PHST- 2024/12/16 17:26 [medline]
PHST- 2024/12/16 17:25 [pubmed]
PHST- 2024/12/16 07:25 [entrez]
PHST- 2024/12/01 00:00 [pmc-release]
AID - S2949-7612(24)00103-2 [pii]
AID - 10.1016/j.mcpdig.2024.09.006 [doi]
PST - ppublish
SO  - Mayo Clin Proc Digit Health. 2024 Dec;2(4):632-644. doi: 
      10.1016/j.mcpdig.2024.09.006.

PMID- 37799027
OWN - NLM
STAT- Publisher
LR  - 20231006
IS  - 2296-6498 (Print)
IS  - 2296-6498 (Linking)
VI  - 134
IP  - 5
DP  - 2023 Oct 6
TI  - ChatGPT's performance in dentistry and allergy-immunology assessments: a 
      comparative study.
AB  - Large language models (LLMs) such as ChatGPT have potential applications in 
      healthcare, including dentistry. Priming, the practice of providing LLMs with 
      initial, relevant information, is an approach to improve their output quality. 
      This study aimed to evaluate the performance of ChatGPT 3 and ChatGPT 4 on 
      self-assessment questions for dentistry, through the Swiss Federal Licensing 
      Examination in Dental Medicine (SFLEDM), and allergy and clinical immunology, 
      through the European Examination in Allergy and Clinical Immunology (EEAACI). The 
      second objective was to assess the impact of priming on ChatGPT's performance. 
      The SFLEDM and EEAACI multiple-choice questions from the University of Bern's 
      Institute for Medical Education platform were administered to both ChatGPT 
      versions, with and without priming. Performance was analyzed based on correct 
      responses. The statistical analysis included Wilcoxon rank sum tests (α=0.05). 
      The average accuracy rates in the SFLEDM and EEAACI assessments were 63.3% and 
      79.3%, respectively. Both ChatGPT versions performed better on EEAACI than 
      SFLEDM, with ChatGPT 4 outperforming ChatGPT 3 across all tests. ChatGPT 3's 
      performance exhibited a significant improvement with priming for both EEAACI 
      (p=0.017) and SFLEDM (p=0.024) assessments. For ChatGPT 4, the priming effect was 
      significant only in the SFLEDM assessment (p=0.038). The performance disparity 
      between SFLEDM and EEAACI assessments underscores ChatGPT's varying proficiency 
      across different medical domains, likely tied to the nature and amount of 
      training data available in each field. Priming can be a tool for enhancing 
      output, especially in earlier LLMs. Advancements from ChatGPT 3 to 4 highlight 
      the rapid developments in LLM technology. Yet, their use in critical fields such 
      as healthcare must remain cautious owing to LLMs' inherent limitations and risks.
FAU - Fuchs, Alexander
AU  - Fuchs A
AD  - Department of Periodontology, Endodontology, and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland.
FAU - Trachsel, Tina
AU  - Trachsel T
AD  - Division of Allergy, University Children's Hospital Basel, Basel, Switzerland.
FAU - Weiger, Roland
AU  - Weiger R
AD  - Department of Periodontology, Endodontology, and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland.
FAU - Eggmann, Florin
AU  - Eggmann F
AD  - Department of Periodontology, Endodontology, and Cariology, University Center for 
      Dental Medicine Basel UZB, University of Basel, Basel, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20231006
PL  - Switzerland
TA  - Swiss Dent J
JT  - Swiss dental journal
JID - 101624119
SB  - IM
OTO - NOTNLM
OT  - allergology
OT  - artificial intelligence
OT  - clinical immunology
OT  - dental education
OT  - machine learning
OT  - medical informatics applications
EDAT- 2023/10/06 06:43
MHDA- 2023/10/06 06:43
CRDT- 2023/10/06 03:02
PHST- 2023/10/06 06:43 [medline]
PHST- 2023/10/06 06:43 [pubmed]
PHST- 2023/10/06 03:02 [entrez]
AID - sdj-2024-05-01 [pii]
PST - aheadofprint
SO  - Swiss Dent J. 2023 Oct 6;134(5).

PMID- 37885755
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240927
IS  - 2666-9145 (Electronic)
IS  - 2666-9145 (Linking)
VI  - 3
IP  - 4
DP  - 2023 Dec
TI  - Generative Artificial Intelligence Through ChatGPT and Other Large Language 
      Models in Ophthalmology: Clinical Applications and Challenges.
PG  - 100394
LID - 10.1016/j.xops.2023.100394 [doi]
LID - 100394
AB  - The rapid progress of large language models (LLMs) driving generative artificial 
      intelligence applications heralds the potential of opportunities in health care. 
      We conducted a review up to April 2023 on Google Scholar, Embase, MEDLINE, and 
      Scopus using the following terms: "large language models," "generative artificial 
      intelligence," "ophthalmology," "ChatGPT," and "eye," based on relevance to this 
      review. From a clinical viewpoint specific to ophthalmologists, we explore from 
      the different stakeholders' perspectives-including patients, physicians, and 
      policymakers-the potential LLM applications in education, research, and clinical 
      domains specific to ophthalmology. We also highlight the foreseeable challenges 
      of LLM implementation into clinical practice, including the concerns of accuracy, 
      interpretability, perpetuating bias, and data security. As LLMs continue to 
      mature, it is essential for stakeholders to jointly establish standards for best 
      practices to safeguard patient safety. FINANCIAL DISCLOSURES: Proprietary or 
      commercial disclosure may be found in the Footnotes and Disclosures at the end of 
      this article.
CI  - © 2023 by the American Academy of Ophthalmology.
FAU - Tan, Ting Fang
AU  - Tan TF
AD  - Singapore Eye Research Institute, Singapore National Eye Centre, Singapore.
FAU - Thirunavukarasu, Arun James
AU  - Thirunavukarasu AJ
AD  - University of Cambridge School of Clinical Medicine, Cambridge, United Kingdom.
AD  - Corpus Christi College, University of Cambridge, Cambridge, United Kingdom.
FAU - Campbell, J Peter
AU  - Campbell JP
AD  - Department of Ophthalmology, Casey Eye Institute, Oregon Health and Science 
      University, Portland, Oregon.
FAU - Keane, Pearse A
AU  - Keane PA
AD  - Moorfields Eye Hospital, University of College London, London, United Kingdom.
FAU - Pasquale, Louis R
AU  - Pasquale LR
AD  - Department of Ophthalmology, Icahn School of Medicine at Mount Sinai, New York 
      City, New York.
FAU - Abramoff, Michael D
AU  - Abramoff MD
AD  - American Medical Association's Digital Medicine Payment Advisory Group (DMPAG) 
      Artificial Intelligence Workgroup, American Medical Association, Chicago, 
      Illinois.
AD  - Department of Ophthalmology, University of Iowa, Iowa City, Iowa.
AD  - Digital Diagnostics, Inc, Coralville, Iowa.
FAU - Kalpathy-Cramer, Jayashree
AU  - Kalpathy-Cramer J
AD  - Department of Ophthalmology, University of Colorado Anschutz Medical Campus, 
      Aurora, Colorado.
FAU - Lum, Flora
AU  - Lum F
AD  - American Academy of Ophthalmology, San Francisco, California.
FAU - Kim, Judy E
AU  - Kim JE
AD  - Department of Ophthalmology, Medical College of Wisconsin, Milwaukee, Wisconsin.
FAU - Baxter, Sally L
AU  - Baxter SL
AD  - Division of Ophthalmology Informatics and Data Science, Viterbi Family Department 
      of Ophthalmology and Shiley Eye Institute, La Jolla, California.
AD  - Health Department of Biomedical Informatics, University of California San Diego, 
      La Jolla, California.
FAU - Ting, Daniel Shu Wei
AU  - Ting DSW
AD  - Singapore Eye Research Institute, Singapore National Eye Centre, Singapore.
AD  - Byers Eye Institute, Stanford University, Stanford, California.
LA  - eng
GR  - MR/T019050/1/MRC_/Medical Research Council/United Kingdom
GR  - P30 EY010572/EY/NEI NIH HHS/United States
GR  - R01 EY019474/EY/NEI NIH HHS/United States
GR  - R01 EY031331/EY/NEI NIH HHS/United States
PT  - Journal Article
DEP - 20230909
PL  - Netherlands
TA  - Ophthalmol Sci
JT  - Ophthalmology science
JID - 9918230896206676
PMC - PMC10598525
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Chatbots
OT  - Large language models
EDAT- 2023/10/27 06:43
MHDA- 2023/10/27 06:44
PMCR- 2023/09/09
CRDT- 2023/10/27 04:22
PHST- 2023/04/26 00:00 [received]
PHST- 2023/08/07 00:00 [revised]
PHST- 2023/08/30 00:00 [accepted]
PHST- 2023/10/27 06:44 [medline]
PHST- 2023/10/27 06:43 [pubmed]
PHST- 2023/10/27 04:22 [entrez]
PHST- 2023/09/09 00:00 [pmc-release]
AID - S2666-9145(23)00126-4 [pii]
AID - 100394 [pii]
AID - 10.1016/j.xops.2023.100394 [doi]
PST - epublish
SO  - Ophthalmol Sci. 2023 Sep 9;3(4):100394. doi: 10.1016/j.xops.2023.100394. 
      eCollection 2023 Dec.

PMID- 39925940
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250213
IS  - 2474-9567 (Electronic)
VI  - 8
IP  - 1
DP  - 2024 Mar
TI  - Mental-LLM: Leveraging Large Language Models for Mental Health Prediction via 
      Online Text Data.
LID - 31 [pii]
LID - 10.1145/3643540 [doi]
AB  - Advances in large language models (LLMs) have empowered a variety of 
      applications. However, there is still a significant gap in research when it comes 
      to understanding and enhancing the capabilities of LLMs in the field of mental 
      health. In this work, we present a comprehensive evaluation of multiple LLMs on 
      various mental health prediction tasks via online text data, including Alpaca, 
      Alpaca-LoRA, FLAN-T5, GPT-3.5, and GPT-4. We conduct a broad range of 
      experiments, covering zero-shot prompting, few-shot prompting, and instruction 
      fine-tuning. The results indicate a promising yet limited performance of LLMs 
      with zero-shot and few-shot prompt designs for mental health tasks. More 
      importantly, our experiments show that instruction finetuning can significantly 
      boost the performance of LLMs for all tasks simultaneously. Our best-finetuned 
      models, Mental-Alpaca and Mental-FLAN-T5, outperform the best prompt design of 
      GPT-3.5 (25 and 15 times bigger) by 10.9% on balanced accuracy and the best of 
      GPT-4 (250 and 150 times bigger) by 4.8%. They further perform on par with the 
      state-of-the-art task-specific language model. We also conduct an exploratory 
      case study on LLMs' capability on mental health reasoning tasks, illustrating the 
      promising capability of certain models such as GPT-4. We summarize our findings 
      into a set of action guidelines for potential methods to enhance LLMs' capability 
      for mental health tasks. Meanwhile, we also emphasize the important limitations 
      before achieving deployability in real-world mental health settings, such as 
      known racial and gender bias. We highlight the important ethical risks 
      accompanying this line of research.
FAU - Xu, Xuhai
AU  - Xu X
AUID- ORCID: 0000-0001-5930-3899
AD  - Massachusetts Institute of Technology & University of Washington, USA.
FAU - Yao, Bingsheng
AU  - Yao B
AUID- ORCID: 0009-0004-8329-4610
AD  - Rensselaer Polytechnic Institute, USA.
FAU - Dong, Yuanzhe
AU  - Dong Y
AUID- ORCID: 0009-0006-2013-1157
AD  - Stanford University, USA.
FAU - Gabriel, Saadia
AU  - Gabriel S
AUID- ORCID: 0009-0001-9353-951X
AD  - Massachusetts Institute of Technology, USA.
FAU - Yu, Hong
AU  - Yu H
AUID- ORCID: 0000-0001-9263-5035
AD  - University of Massachusetts Lowell, USA.
FAU - Hendler, James
AU  - Hendler J
AUID- ORCID: 0000-0003-3056-1960
AD  - Rensselaer Polytechnic Institute, USA.
FAU - Ghassemi, Marzyeh
AU  - Ghassemi M
AUID- ORCID: 0000-0001-6349-7251
AD  - Massachusetts Institute of Technology, USA.
FAU - Dey, Anind K
AU  - Dey AK
AUID- ORCID: 0000-0002-3004-0770
AD  - University of Washington, USA.
FAU - Wang, Dakuo
AU  - Wang D
AUID- ORCID: 0000-0001-9371-9441
AD  - Northeastern University, USA.
LA  - eng
GR  - R01 MD018424/MD/NIMHD NIH HHS/United States
PT  - Journal Article
DEP - 20240306
PL  - United States
TA  - Proc ACM Interact Mob Wearable Ubiquitous Technol
JT  - Proceedings of the ACM on interactive, mobile, wearable and ubiquitous 
      technologies
JID - 101719413
PMC - PMC11806945
MID - NIHMS2052486
OTO - NOTNLM
OT  - Instruction Finetuning
OT  - Large Language Model
OT  - Mental Health
EDAT- 2025/02/10 06:22
MHDA- 2025/02/10 06:23
PMCR- 2025/02/08
CRDT- 2025/02/10 05:32
PHST- 2025/02/10 06:23 [medline]
PHST- 2025/02/10 06:22 [pubmed]
PHST- 2025/02/10 05:32 [entrez]
PHST- 2025/02/08 00:00 [pmc-release]
AID - 31 [pii]
AID - 10.1145/3643540 [doi]
PST - ppublish
SO  - Proc ACM Interact Mob Wearable Ubiquitous Technol. 2024 Mar;8(1):31. doi: 
      10.1145/3643540. Epub 2024 Mar 6.

PMID- 39569431
OWN - NLM
STAT- MEDLINE
DCOM- 20250121
LR  - 20250129
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 32
IP  - 2
DP  - 2025 Feb 1
TI  - Identifying stigmatizing and positive/preferred language in obstetric clinical 
      notes using natural language processing.
PG  - 308-317
LID - 10.1093/jamia/ocae290 [doi]
AB  - OBJECTIVE: To identify stigmatizing language in obstetric clinical notes using 
      natural language processing (NLP). MATERIALS AND METHODS: We analyzed electronic 
      health records from birth admissions in the Northeast United States in 2017. We 
      annotated 1771 clinical notes to generate the initial gold standard dataset. 
      Annotators labeled for exemplars of 5 stigmatizing and 1 positive/preferred 
      language categories. We used a semantic similarity-based search approach to 
      expand the initial dataset by adding additional exemplars, composing an enhanced 
      dataset. We employed traditional classifiers (Support Vector Machine, Decision 
      Trees, and Random Forest) and a transformer-based model, ClinicalBERT 
      (Bidirectional Encoder Representations from Transformers) and BERT base. Models 
      were trained and validated on initial and enhanced datasets and were tested on 
      enhanced testing dataset. RESULTS: In the initial dataset, we annotated 963 
      exemplars as stigmatizing or positive/preferred. The most frequently identified 
      category was marginalized language/identities (n = 397, 41%), and the least 
      frequent was questioning patient credibility (n = 51, 5%). After employing a 
      semantic similarity-based search approach, 502 additional exemplars were added, 
      increasing the number of low-frequency categories. All NLP models also showed 
      improved performance, with Decision Trees demonstrating the greatest improvement 
      (21%). ClinicalBERT outperformed other models, with the highest average F1-score 
      of 0.78. DISCUSSION: Clinical BERT seems to most effectively capture the nuanced 
      and context-dependent stigmatizing language found in obstetric clinical notes, 
      demonstrating its potential clinical applications for real-time monitoring and 
      alerts to prevent usages of stigmatizing language use and reduce healthcare bias. 
      Future research should explore stigmatizing language in diverse geographic 
      locations and clinical settings to further contribute to high-quality and 
      equitable perinatal care. CONCLUSION: ClinicalBERT effectively captures the 
      nuanced stigmatizing language in obstetric clinical notes. Our semantic 
      similarity-based search approach to rapidly extract additional exemplars enhanced 
      the performances while reducing the need for labor-intensive annotation.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Scroggins, Jihye Kim
AU  - Scroggins JK
AUID- ORCID: 0000-0002-0864-7867
AD  - School of Nursing, Columbia University, New York, NY 10032, United States.
FAU - Hulchafo, Ismael I
AU  - Hulchafo II
AUID- ORCID: 0009-0005-5504-4646
AD  - School of Nursing, Columbia University, New York, NY 10032, United States.
FAU - Harkins, Sarah
AU  - Harkins S
AD  - School of Nursing, Columbia University, New York, NY 10032, United States.
FAU - Scharp, Danielle
AU  - Scharp D
AD  - Icahn School of Medicine, Mount Sinai, NY 10029, United States.
FAU - Moen, Hans
AU  - Moen H
AD  - Department of Computer Science, Aalto University, Espoo 02150, Finland.
FAU - Davoudi, Anahita
AU  - Davoudi A
AD  - VNS Health, New York, NY 10017, United States.
FAU - Cato, Kenrick
AU  - Cato K
AD  - School of Nursing, University of Pennsylvania, Philadelphia, PA 19104, United 
      States.
FAU - Tadiello, Michele
AU  - Tadiello M
AD  - Center for Community-Engaged Health Informatics and Data Science, Columbia 
      University Irving Medical Center, New York, NY 10032, United States.
FAU - Topaz, Maxim
AU  - Topaz M
AUID- ORCID: 0000-0002-2358-9837
AD  - School of Nursing, Columbia University, New York, NY 10032, United States.
FAU - Barcelona, Veronica
AU  - Barcelona V
AD  - School of Nursing, Columbia University, New York, NY 10032, United States.
LA  - eng
GR  - GBMF9048/Gordon and Betty Moore Foundation/
GR  - Columbia University Data Science Institute Seed Funds/
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - *Natural Language Processing
MH  - Humans
MH  - *Electronic Health Records
MH  - Female
MH  - Pregnancy
MH  - Semantics
MH  - Obstetrics
MH  - Language
MH  - Support Vector Machine
MH  - Stereotyping
MH  - Decision Trees
PMC - PMC11756426
OTO - NOTNLM
OT  - bias
OT  - electronic health records
OT  - health communication
OT  - natural language processing
OT  - nursing informatics
COIS- None declared.
EDAT- 2024/11/21 06:21
MHDA- 2025/01/22 05:32
PMCR- 2024/11/21
CRDT- 2024/11/21 04:52
PHST- 2024/07/10 00:00 [received]
PHST- 2024/10/23 00:00 [revised]
PHST- 2024/11/06 00:00 [accepted]
PHST- 2025/01/22 05:32 [medline]
PHST- 2024/11/21 06:21 [pubmed]
PHST- 2024/11/21 04:52 [entrez]
PHST- 2024/11/21 00:00 [pmc-release]
AID - 7906099 [pii]
AID - ocae290 [pii]
AID - 10.1093/jamia/ocae290 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2025 Feb 1;32(2):308-317. doi: 10.1093/jamia/ocae290.

PMID- 38705894
OWN - NLM
STAT- MEDLINE
DCOM- 20241027
LR  - 20241028
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Linking)
VI  - 281
IP  - 11
DP  - 2024 Nov
TI  - The utility of ChatGPT as a generative medical translator.
PG  - 6161-6165
LID - 10.1007/s00405-024-08708-8 [doi]
AB  - PURPOSE: Large language models continue to dramatically change the medical 
      landscape. We aimed to explore the utility of ChatGPT in providing accurate, 
      actionable, and understandable generative medical translations in English, 
      Spanish, and Mandarin pertaining to Otolaryngology. METHODS: Responses of GPT-4 
      to commonly asked patient questions listed on official otolaryngology clinical 
      practice guidelines (CPG) were evaluated with the Patient Education materials 
      Assessment Tool-printable (PEMAT-P.) Additional critical elements were identified 
      a priori to evaluate ChatGPT's accuracy and thoroughness in its responses. 
      Multiple fluent speakers of English, Mandarin, and Spanish evaluated each 
      response generated by ChatGPT. RESULTS: Total PEMAT-P scores differed between 
      English, Mandarin, and Spanish GPT-4 generated responses depicting a moderate 
      effect size of language, Eta-Square 0.07 with scores ranging from 73 to 77 
      (P-value = 0.03). Overall understandability scores did not differ between 
      English, Mandarin, and Spanish depicting a small effect size of language, 
      Eta-Square 0.02 scores ranging from 76 to 79 (P-value = 0.17), nor did overall 
      actionability scores Eta-Square 0 score ranging 66-73 (P-value = 0.44). Overall a 
      priori procedure-specific responses similarly did not differ between English, 
      Spanish, and Mandarin Eta-Square 0.02 scores ranging 61-78 (P-value = 0.22). 
      CONCLUSION: GPT-4 produces accurate, understandable, and actionable outputs in 
      English, Spanish, and Mandarin. Responses generated by GPT-4 in Spanish and 
      Mandarin are comparable to English counterparts indicating a novel use for these 
      models within Otolaryngology, and implications for bridging healthcare access and 
      literacy gaps. LEVEL OF EVIDENCE: IV.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Grimm, David R
AU  - Grimm DR
AUID- ORCID: 0000-0002-7422-4280
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head and Neck 
      Surgery, Stanford University School of Medicine, Stanford, CA, 94305, USA.
FAU - Lee, Yu-Jin
AU  - Lee YJ
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head and Neck 
      Surgery, Stanford University School of Medicine, Stanford, CA, 94305, USA.
FAU - Hu, Katherine
AU  - Hu K
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head and Neck 
      Surgery, Stanford University School of Medicine, Stanford, CA, 94305, USA.
FAU - Liu, Longsha
AU  - Liu L
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head and Neck 
      Surgery, Stanford University School of Medicine, Stanford, CA, 94305, USA.
FAU - Garcia, Omar
AU  - Garcia O
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head and Neck 
      Surgery, Stanford University School of Medicine, Stanford, CA, 94305, USA.
FAU - Balakrishnan, Karthik
AU  - Balakrishnan K
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head and Neck 
      Surgery, Stanford University School of Medicine, Stanford, CA, 94305, USA.
FAU - Ayoub, Noel F
AU  - Ayoub NF
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head and Neck 
      Surgery, Stanford University School of Medicine, Stanford, CA, 94305, USA. 
      noelayoub@gmail.com.
AD  - Division of Rhinology and Skull Base Surgery, Department of Otolaryngology-Head 
      and Neck Surgery, Mass Eye and Ear, 243 Charles Street, Boston, MA, 02114, USA. 
      noelayoub@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240505
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
MH  - Humans
MH  - *Otolaryngology
MH  - Translating
MH  - Language
MH  - Patient Education as Topic/methods
MH  - Translations
MH  - Comprehension
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Disparities
OT  - Large language models
EDAT- 2024/05/06 00:52
MHDA- 2024/10/27 17:13
CRDT- 2024/05/05 23:04
PHST- 2024/03/19 00:00 [received]
PHST- 2024/04/24 00:00 [accepted]
PHST- 2024/10/27 17:13 [medline]
PHST- 2024/05/06 00:52 [pubmed]
PHST- 2024/05/05 23:04 [entrez]
AID - 10.1007/s00405-024-08708-8 [pii]
AID - 10.1007/s00405-024-08708-8 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2024 Nov;281(11):6161-6165. doi: 
      10.1007/s00405-024-08708-8. Epub 2024 May 5.

PMID- 39752214
OWN - NLM
STAT- MEDLINE
DCOM- 20250103
LR  - 20250129
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 9
DP  - 2025 Jan 3
TI  - ChatGPT's Attitude, Knowledge, and Clinical Application in Geriatrics Practice 
      and Education: Exploratory Observational Study.
PG  - e63494
LID - 10.2196/63494 [doi]
LID - e63494
AB  - BACKGROUND: The increasing use of ChatGPT in clinical practice and medical 
      education necessitates the evaluation of its reliability, particularly in 
      geriatrics. OBJECTIVE: This study aimed to evaluate ChatGPT's trustworthiness in 
      geriatrics through 3 distinct approaches: evaluating ChatGPT's geriatrics 
      attitude, knowledge, and clinical application with 2 vignettes of geriatric 
      syndromes (polypharmacy and falls). METHODS: We used the validated University of 
      California, Los Angeles, geriatrics attitude and knowledge instruments to 
      evaluate ChatGPT's geriatrics attitude and knowledge and compare its performance 
      with that of medical students, residents, and geriatrics fellows from reported 
      results in the literature. We also evaluated ChatGPT's application to 2 vignettes 
      of geriatric syndromes (polypharmacy and falls). RESULTS: The mean total score on 
      geriatrics attitude of ChatGPT was significantly lower than that of trainees 
      (medical students, internal medicine residents, and geriatric medicine fellows; 
      2.7 vs 3.7 on a scale from 1-5; 1=strongly disagree; 5=strongly agree). The mean 
      subscore on positive geriatrics attitude of ChatGPT was higher than that of the 
      trainees (medical students, internal medicine residents, and neurologists; 4.1 vs 
      3.7 on a scale from 1 to 5 where a higher score means a more positive attitude 
      toward older adults). The mean subscore on negative geriatrics attitude of 
      ChatGPT was lower than that of the trainees and neurologists (1.8 vs 2.8 on a 
      scale from 1 to 5 where a lower subscore means a less negative attitude toward 
      aging). On the University of California, Los Angeles geriatrics knowledge test, 
      ChatGPT outperformed all medical students, internal medicine residents, and 
      geriatric medicine fellows from validated studies (14.7 vs 11.3 with a score 
      range of -18 to +18 where +18 means that all questions were answered correctly). 
      Regarding the polypharmacy vignette, ChatGPT not only demonstrated solid 
      knowledge of potentially inappropriate medications but also accurately identified 
      7 common potentially inappropriate medications and 5 drug-drug and 3 drug-disease 
      interactions. However, ChatGPT missed 5 drug-disease and 1 drug-drug interaction 
      and produced 2 hallucinations. Regarding the fall vignette, ChatGPT answered 3 of 
      5 pretests correctly and 2 of 5 pretests partially correctly, identified 6 
      categories of fall risks, followed fall guidelines correctly, listed 6 key 
      physical examinations, and recommended 6 categories of fall prevention methods. 
      CONCLUSIONS: This study suggests that ChatGPT can be a valuable supplemental tool 
      in geriatrics, offering reliable information with less age bias, robust 
      geriatrics knowledge, and comprehensive recommendations for managing 2 common 
      geriatric syndromes (polypharmacy and falls) that are consistent with evidence 
      from guidelines, systematic reviews, and other types of studies. ChatGPT's 
      potential as an educational and clinical resource could significantly benefit 
      trainees, health care providers, and laypeople. Further research using GPT-4o, 
      larger geriatrics question sets, and more geriatric syndromes is needed to expand 
      and confirm these findings before adopting ChatGPT widely for geriatrics 
      education and practice.
CI  - ©Huai Yong Cheng. Originally published in JMIR Formative Research 
      (https://formative.jmir.org), 03.01.2025.
FAU - Cheng, Huai Yong
AU  - Cheng HY
AUID- ORCID: 0009-0004-9501-7143
AD  - Minneapolis VA Health Care System, Minneapolis, MN, United States.
LA  - eng
PT  - Journal Article
PT  - Observational Study
DEP - 20250103
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
SB  - IM
MH  - Adult
MH  - Female
MH  - Humans
MH  - Male
MH  - Clinical Competence
MH  - *Geriatrics/education
MH  - *Health Knowledge, Attitudes, Practice
MH  - Reproducibility of Results
MH  - Students, Medical/psychology
MH  - Surveys and Questionnaires
MH  - *Artificial Intelligence
MH  - *Practice Patterns, Physicians'
MH  - Aged
PMC - PMC11742095
OTO - NOTNLM
OT  - ChatGPT
OT  - ageism
OT  - aging, older adults
OT  - falls
OT  - geriatric syndromes
OT  - geriatrics attitude
OT  - geriatrics competence
OT  - polypharmacy
COIS- Conflicts of Interest: None declared.
EDAT- 2025/01/03 12:21
MHDA- 2025/01/03 18:20
PMCR- 2025/01/03
CRDT- 2025/01/03 11:53
PHST- 2024/06/30 00:00 [received]
PHST- 2024/11/17 00:00 [accepted]
PHST- 2024/10/26 00:00 [revised]
PHST- 2025/01/03 18:20 [medline]
PHST- 2025/01/03 12:21 [pubmed]
PHST- 2025/01/03 11:53 [entrez]
PHST- 2025/01/03 00:00 [pmc-release]
AID - v9i1e63494 [pii]
AID - 10.2196/63494 [doi]
PST - epublish
SO  - JMIR Form Res. 2025 Jan 3;9:e63494. doi: 10.2196/63494.

PMID- 37673708
OWN - NLM
STAT- Publisher
LR  - 20231005
IS  - 2090-2387 (Electronic)
IS  - 1687-1979 (Linking)
VI  - 24
IP  - 3
DP  - 2023 Aug
TI  - ChatGPT's ability to comprehend and answer cirrhosis related questions in Arabic.
PG  - 145-148
LID - S1687-1979(23)00058-8 [pii]
LID - 10.1016/j.ajg.2023.08.001 [doi]
AB  - BACKGROUND AND STUDY AIMS: Cirrhosis is a chronic progressive disease which 
      requires complex care. Its incidence is rising in the Arab countries making it 
      the 7th leading cause of death in the Arab League in 2010. ChatGPT is a large 
      language model with a growing body of literature demonstrating its ability to 
      answer clinical questions. We examined ChatGPT's accuracy in responding to 
      cirrhosis related questions in Arabic and compared its performance to English. 
      MATERIALS AND METHODS: ChatGPTs responses to 91 questions in Arabic and English 
      were graded by a transplant hepatologist fluent in both languages. Accuracy of 
      responses was assessed using the scale: 1. Comprehensive, 2. Correct but 
      inadequate, 3. Mixed with correct and incorrect/outdated data, and 4. Completely 
      incorrect.Accuracy of Arabic compared to English responses was assessed using the 
      scale: 1. Arabic response is more accurate, 2. Similar accuracy, 3. Arabic 
      response is less accurate. RESULTS: The model provided 22 (24.2%) comprehensive, 
      44 (48.4%) correct but inadequate, 13 (14.3%) mixed with correct and 
      incorrect/outdated data and 12 (13.2%) completely incorrect Arabic responses. 
      When comparing the accuracy of Arabic and English responses, 9 (9.9%) of the 
      Arabic responses were graded as more accurate, 52 (57.1%) similar in accuracy and 
      30 (33.0%) as less accurate compared to English. CONCLUSION: ChatGPT has the 
      potential to serve as an adjunct source of information for Arabic speaking 
      patients with cirrhosis. The model provided correct responses in Arabic to 72.5% 
      of questions, although its performance in Arabic was less accurate than in 
      English. The model produced completely incorrect responses to 13.2% of questions, 
      reinforcing its potential role as an adjunct and not replacement of care by 
      licensed healthcare professionals. Future studies to refine this technology are 
      needed to help Arabic speaking patients with cirrhosis across the globe 
      understand their disease and improve their outcomes.
CI  - Copyright © 2023 Pan-Arab Association of Gastroenterology. Published by Elsevier 
      B.V. All rights reserved.
FAU - Samaan, Jamil S
AU  - Samaan JS
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Yeo, Yee Hui
AU  - Yeo YH
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Ng, Wee Han
AU  - Ng WH
AD  - Bristol Medical School, University of Bristol, Bristol, UK.
FAU - Ting, Peng-Sheng
AU  - Ting PS
AD  - School of Medicine, Tulane University, New Orleans, LA, USA.
FAU - Trivedi, Hirsh
AU  - Trivedi H
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Vipani, Aarshi
AU  - Vipani A
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Yang, Ju Dong
AU  - Yang JD
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA; Samuel Oschin 
      Comprehensive Cancer Institute, Cedars-Sinai Medical Center, Los Angeles, CA, 
      USA.
FAU - Liran, Omer
AU  - Liran O
AD  - Department of Psychiatry and Behavioral Sciences, Cedars-Sinai, Los Angeles, CA, 
      USA; Division of Health Services Research, Department of Medicine, Cedars-Sinai, 
      Los Angeles, CA, USA.
FAU - Spiegel, Brennan
AU  - Spiegel B
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Division of Health Services 
      Research, Department of Medicine, Cedars-Sinai, Los Angeles, CA, USA.
FAU - Kuo, Alexander
AU  - Kuo A
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Ayoub, Walid S
AU  - Ayoub WS
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA; Comprehensive Transplant 
      Center, Cedars-Sinai Medical Center, Los Angeles, CA, USA. Electronic address: 
      walid.ayoub@cshs.org.
LA  - eng
PT  - Journal Article
DEP - 20230904
PL  - Egypt
TA  - Arab J Gastroenterol
JT  - Arab journal of gastroenterology : the official publication of the Pan-Arab 
      Association of Gastroenterology
JID - 101298363
SB  - IM
OTO - NOTNLM
OT  - Arabic
OT  - ChatGPT
OT  - Cirrhosis
OT  - Disparity
OT  - Large language model
COIS- Declaration of competing interests The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/09/07 00:41
MHDA- 2023/09/07 00:41
CRDT- 2023/09/06 21:56
PHST- 2023/04/25 00:00 [received]
PHST- 2023/07/24 00:00 [revised]
PHST- 2023/08/18 00:00 [accepted]
PHST- 2023/09/07 00:41 [pubmed]
PHST- 2023/09/07 00:41 [medline]
PHST- 2023/09/06 21:56 [entrez]
AID - S1687-1979(23)00058-8 [pii]
AID - 10.1016/j.ajg.2023.08.001 [doi]
PST - ppublish
SO  - Arab J Gastroenterol. 2023 Aug;24(3):145-148. doi: 10.1016/j.ajg.2023.08.001. 
      Epub 2023 Sep 4.

PMID- 37827724
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231023
IS  - 2632-1009 (Electronic)
IS  - 2632-1009 (Linking)
VI  - 30
IP  - 1
DP  - 2023 Oct
TI  - Comparative study of ChatGPT and human evaluators on the assessment of medical 
      literature according to recognised reporting standards.
LID - 10.1136/bmjhci-2023-100830 [doi]
LID - e100830
AB  - INTRODUCTION: Amid clinicians' challenges in staying updated with medical 
      research, artificial intelligence (AI) tools like the large language model (LLM) 
      ChatGPT could automate appraisal of research quality, saving time and reducing 
      bias. This study compares the proficiency of ChatGPT3 against human evaluation in 
      scoring abstracts to determine its potential as a tool for evidence synthesis. 
      METHODS: We compared ChatGPT's scoring of implant dentistry abstracts with human 
      evaluators using the Consolidated Standards of Reporting Trials for Abstracts 
      reporting standards checklist, yielding an overall compliance score (OCS). 
      Bland-Altman analysis assessed agreement between human and AI-generated OCS 
      percentages. Additional error analysis included mean difference of OCS subscores, 
      Welch's t-test and Pearson's correlation coefficient. RESULTS: Bland-Altman 
      analysis showed a mean difference of 4.92% (95% CI 0.62%, 0.37%) in OCS between 
      human evaluation and ChatGPT. Error analysis displayed small mean differences in 
      most domains, with the highest in 'conclusion' (0.764 (95% CI 0.186, 0.280)) and 
      the lowest in 'blinding' (0.034 (95% CI 0.818, 0.895)). The strongest 
      correlations between were in 'harms' (r=0.32, p<0.001) and 'trial registration' 
      (r=0.34, p=0.002), whereas the weakest were in 'intervention' (r=0.02, p<0.001) 
      and 'objective' (r=0.06, p<0.001). CONCLUSION: LLMs like ChatGPT can help 
      automate appraisal of medical literature, aiding in the identification of 
      accurately reported research. Possible applications of ChatGPT include 
      integration within medical databases for abstract evaluation. Current limitations 
      include the token limit, restricting its usage to abstracts. As AI technology 
      advances, future versions like GPT4 could offer more reliable, comprehensive 
      evaluations, enhancing the identification of high-quality research and 
      potentially improving patient outcomes.
CI  - © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY. Published 
      by BMJ.
FAU - Roberts, Richard Hr
AU  - Roberts RH
AUID- ORCID: 0000-0002-9600-5943
AD  - Reconstructive Surgery and Regenerative Medicine Research Centre, Swansea 
      University, Swansea, UK 838272@swansea.ac.uk.
AD  - Swansea University Medical School, Swansea University, Swansea, UK.
AD  - Welsh Centre for Burns and Plastic Surgery, Morriston Hospital, Swansea, UK.
FAU - Ali, Stephen R
AU  - Ali SR
AD  - Reconstructive Surgery and Regenerative Medicine Research Centre, Swansea 
      University, Swansea, UK.
AD  - Welsh Centre for Burns and Plastic Surgery, Morriston Hospital, Swansea, UK.
FAU - Hutchings, Hayley A
AU  - Hutchings HA
AD  - Swansea University Medical School, Swansea University, Swansea, UK.
FAU - Dobbs, Thomas D
AU  - Dobbs TD
AD  - Reconstructive Surgery and Regenerative Medicine Research Centre, Swansea 
      University, Swansea, UK.
AD  - Welsh Centre for Burns and Plastic Surgery, Morriston Hospital, Swansea, UK.
FAU - Whitaker, Iain S
AU  - Whitaker IS
AD  - Reconstructive Surgery and Regenerative Medicine Research Centre, Swansea 
      University, Swansea, UK.
AD  - Welsh Centre for Burns and Plastic Surgery, Morriston Hospital, Swansea, UK.
LA  - eng
PT  - Journal Article
PL  - England
TA  - BMJ Health Care Inform
JT  - BMJ health & care informatics
JID - 101745500
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Biomedical Research
MH  - Checklist
MH  - Databases, Factual
MH  - Patient Compliance
PMC - PMC10583079
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Medical Informatics
COIS- Competing interests: None declared.
EDAT- 2023/10/13 00:43
MHDA- 2023/10/23 01:18
PMCR- 2023/10/12
CRDT- 2023/10/12 21:12
PHST- 2023/06/14 00:00 [received]
PHST- 2023/09/05 00:00 [accepted]
PHST- 2023/10/23 01:18 [medline]
PHST- 2023/10/13 00:43 [pubmed]
PHST- 2023/10/12 21:12 [entrez]
PHST- 2023/10/12 00:00 [pmc-release]
AID - bmjhci-2023-100830 [pii]
AID - 10.1136/bmjhci-2023-100830 [doi]
PST - ppublish
SO  - BMJ Health Care Inform. 2023 Oct;30(1):e100830. doi: 10.1136/bmjhci-2023-100830.

PMID- 39157995
OWN - NLM
STAT- MEDLINE
DCOM- 20241212
LR  - 20250212
IS  - 1531-4995 (Electronic)
IS  - 0023-852X (Linking)
VI  - 135
IP  - 1
DP  - 2025 Jan
TI  - Large Language Models in Otolaryngology Residency Admissions: A Random Sampling 
      Analysis.
PG  - 87-93
LID - 10.1002/lary.31705 [doi]
AB  - OBJECTIVES: To investigate potential demographic bias in artificial intelligence 
      (AI)-based simulations of otolaryngology, residency selection committee (RSC) 
      members tasked with selecting one applicant among candidates with varied racial, 
      gender, and sexual orientations. METHODS: This study employed random sampling of 
      simulated RSC member decisions using a novel Application Programming Interface 
      (API) to virtually connect to OpenAI's Generative Pre-Trained Transformers (GPT-4 
      and GPT-4o). Simulated RSC members with diverse demographics were tasked with 
      ranking to match 1 applicant among 10 with varied racial, gender, and sexual 
      orientations. All applicants had identical qualifications; only demographics of 
      the applicants and RSC members were varied for each simulation. Each RSC 
      simulation ran 1000 times. Chi-square tests analyzed differences across 
      categorical variables. GPT-4o simulations additionally requested a rationale for 
      each decision. RESULTS: Simulated RSCs consistently showed racial, gender, and 
      sexual orientation bias. Most applicant pairwise comparisons showed statistical 
      significance (p < 0.05). White and Black RSCs exhibited greatest preference for 
      applicants sharing their own demographic characteristics, favoring White and 
      Black female applicants, respectively, over others (all pairwise p < 0.001). 
      Asian male applicants consistently received lowest selection rates. Male RSCs 
      favored White male and female applicants, while female RSCs preferred LGBTQIA+, 
      White and Black female applicants (all p < 0.05). High socioeconomic status (SES) 
      RSCs favored White female and LGBTQIA+ applicants, while low SES RSCs favored 
      Black female and LGBTQIA+ applicants over others (all p < 0.001). Results from 
      the newest iteration of the LLM, ChatGPT-4o, indicated evolved selection 
      preferences favoring Black female and LGBTQIA+ applicants across all RSCs, with 
      the rationale of prioritizing inclusivity given in >95% of such decisions. 
      CONCLUSION: Utilizing publicly available LLMs to aid in otolaryngology residency 
      selection may introduce significant racial, gender, and sexual orientation bias. 
      Potential for significant and evolving LLM bias should be appreciated and 
      minimized to promote a diverse and representative field of future 
      otolaryngologists in alignment with current workforce data. LEVEL OF EVIDENCE: NA 
      Laryngoscope, 135:87-93, 2025.
CI  - © 2024 The American Laryngological, Rhinological and Otological Society, Inc.
FAU - Halagur, Akash S
AU  - Halagur AS
AD  - Department of Otolaryngology-Head & Neck Surgery, Stanford University School of 
      Medicine, Stanford, California, U.S.A.
AD  - Department of Otolaryngology-Head & Neck Surgery, Geisel School of Medicine at 
      Dartmouth, Hanover, New Hampshire, U.S.A.
FAU - Balakrishnan, Karthik
AU  - Balakrishnan K
AUID- ORCID: 0000-0002-0244-249X
AD  - Division of Pediatric Otolaryngology, Department of Otolaryngology-Head & Neck 
      Surgery, Stanford University School of Medicine, Palo Alto, California, U.S.A.
FAU - Ayoub, Noel
AU  - Ayoub N
AUID- ORCID: 0000-0003-1867-994X
AD  - Division of Rhinology and Skull Base Surgery, Department of Otolaryngology-Head & 
      Neck Surgery, Mass Eye and Ear, Boston, Massachusetts, U.S.A.
LA  - eng
PT  - Journal Article
DEP - 20240819
PL  - United States
TA  - Laryngoscope
JT  - The Laryngoscope
JID - 8607378
SB  - IM
MH  - Humans
MH  - *Internship and Residency/statistics & numerical data
MH  - *Otolaryngology/education
MH  - Male
MH  - Female
MH  - School Admission Criteria/statistics & numerical data
MH  - Language
MH  - Personnel Selection/methods/statistics & numerical data
MH  - Adult
OTO - NOTNLM
OT  - Artificial Intelligence in Healthcare
OT  - bias
OT  - diversity, equity, and inclusion (DEI)
OT  - large language models
OT  - otolaryngology residency admissions
EDAT- 2024/08/19 12:42
MHDA- 2024/12/12 06:23
CRDT- 2024/08/19 06:32
PHST- 2024/07/25 00:00 [revised]
PHST- 2024/04/11 00:00 [received]
PHST- 2024/07/29 00:00 [accepted]
PHST- 2024/12/12 06:23 [medline]
PHST- 2024/08/19 12:42 [pubmed]
PHST- 2024/08/19 06:32 [entrez]
AID - 10.1002/lary.31705 [doi]
PST - ppublish
SO  - Laryngoscope. 2025 Jan;135(1):87-93. doi: 10.1002/lary.31705. Epub 2024 Aug 19.

PMID- 38222330
OWN - NLM
STAT- MEDLINE
DCOM- 20240116
LR  - 20240116
IS  - 1942-597X (Electronic)
IS  - 1559-4076 (Linking)
VI  - 2023
DP  - 2023
TI  - Caregivers Attitude Detection From Clinical Notes.
PG  - 1125-1134
AB  - Caregivers' attitudes impact healthcare quality and disparities. Clinical notes 
      contain highly specialized and ambiguous language that requires extensive domain 
      knowledge to understand, and using negative language does not necessarily imply a 
      negative attitude. This study discusses the challenge of detecting caregivers' 
      attitudes from their clinical notes. To address these challenges, we annotate 
      MIMIC clinical notes and train state-of-the-art language models from the Hugging 
      Face platform. The study focuses on the Neonatal Intensive Care Unit and 
      evaluates models in zero-shot, few-shot, and fully-trained scenarios. Among the 
      chosen models, RoBERTa identifies caregivers' attitudes from clinical notes with 
      an F1-score of 0.75. This approach not only enhances patient satisfaction, but 
      opens up exciting possibilities for detecting and preventing care provider 
      syndromes, such as fatigue, stress, and burnout. The paper concludes by 
      discussing limitations and potential future work.
CI  - ©2023 AMIA - All rights reserved.
FAU - Manzo, Gaetano
AU  - Manzo G
AD  - Computational Health Research Branch, National Library of Medicine, Bethesda, 
      Maryland, USA.
FAU - Celi, Leo Anthony
AU  - Celi LA
AD  - Massachusetts Institute of Technology (MIT), Harvard Medical School, and the Beth 
      Israel Deaconess Medical Center.
FAU - Shabazz, Yasmeen
AU  - Shabazz Y
AD  - Massachusetts Institute of Technology (MIT), Harvard Medical School, and the Beth 
      Israel Deaconess Medical Center.
FAU - Mulcahey, Rory
AU  - Mulcahey R
AD  - Computational Health Research Branch, National Library of Medicine, Bethesda, 
      Maryland, USA.
FAU - Flores, Lorenzo Jaime
AU  - Flores LJ
AD  - Massachusetts Institute of Technology (MIT), Harvard Medical School, and the Beth 
      Israel Deaconess Medical Center.
FAU - Demner-Fushman, Dina
AU  - Demner-Fushman D
AD  - Computational Health Research Branch, National Library of Medicine, Bethesda, 
      Maryland, USA.
LA  - eng
PT  - Journal Article
DEP - 20240111
PL  - United States
TA  - AMIA Annu Symp Proc
JT  - AMIA ... Annual Symposium proceedings. AMIA Symposium
JID - 101209213
SB  - IM
MH  - Infant, Newborn
MH  - Humans
MH  - *Caregivers
MH  - Attitude
MH  - Quality of Health Care
MH  - *Burnout, Professional
PMC - PMC10785866
COIS- The authors declare that they have no conflict of interest.
EDAT- 2024/01/15 06:43
MHDA- 2024/01/16 06:41
PMCR- 2024/01/11
CRDT- 2024/01/15 04:32
PHST- 2024/01/16 06:41 [medline]
PHST- 2024/01/15 06:43 [pubmed]
PHST- 2024/01/15 04:32 [entrez]
PHST- 2024/01/11 00:00 [pmc-release]
AID - 337 [pii]
PST - epublish
SO  - AMIA Annu Symp Proc. 2024 Jan 11;2023:1125-1134. eCollection 2023.

PMID- 35615042
OWN - NLM
STAT- MEDLINE
DCOM- 20220527
LR  - 20250110
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 10
DP  - 2022
TI  - Classifying Characteristics of Opioid Use Disorder From Hospital Discharge 
      Summaries Using Natural Language Processing.
PG  - 850619
LID - 10.3389/fpubh.2022.850619 [doi]
LID - 850619
AB  - BACKGROUND: Opioid use disorder (OUD) is underdiagnosed in health system 
      settings, limiting research on OUD using electronic health records (EHRs). 
      Medical encounter notes can enrich structured EHR data with documented signs and 
      symptoms of OUD and social risks and behaviors. To capture this information at 
      scale, natural language processing (NLP) tools must be developed and evaluated. 
      We developed and applied an annotation schema to deeply characterize OUD and 
      related clinical, behavioral, and environmental factors, and automated the 
      annotation schema using machine learning and deep learning-based approaches. 
      METHODS: Using the MIMIC-III Critical Care Database, we queried hospital 
      discharge summaries of patients with International Classification of Diseases 
      (ICD-9) OUD diagnostic codes. We developed an annotation schema to characterize 
      problematic opioid use, identify individuals with potential OUD, and provide 
      psychosocial context. Two annotators reviewed discharge summaries from 100 
      patients. We randomly sampled patients with their associated annotated sentences 
      and divided them into training (66 patients; 2,127 annotated sentences) and 
      testing (29 patients; 1,149 annotated sentences) sets. We used the training set 
      to generate features, employing three NLP algorithms/knowledge sources. We 
      trained and tested prediction models for classification with a traditional 
      machine learner (logistic regression) and deep learning approach (Autogluon based 
      on ELECTRA's replaced token detection model). We applied a five-fold 
      cross-validation approach to reduce bias in performance estimates. RESULTS: The 
      resulting annotation schema contained 32 classes. We achieved moderate 
      inter-annotator agreement, with F(1)-scores across all classes increasing from 48 
      to 66%. Five classes had a sufficient number of annotations for automation; of 
      these, we observed consistently high performance (F(1)-scores) across training 
      and testing sets for drug screening (training: 91-96; testing: 91-94) and opioid 
      type (training: 86-96; testing: 86-99). Performance dropped from training and to 
      testing sets for other drug use (training: 52-65; testing: 40-48), pain 
      management (training: 72-78; testing: 61-78) and psychiatric (training: 73-80; 
      testing: 72). Autogluon achieved the highest performance. CONCLUSION: This pilot 
      study demonstrated that rich information regarding problematic opioid use can be 
      manually identified by annotators. However, more training samples and features 
      would improve our ability to reliably identify less common classes from clinical 
      text, including text from outpatient settings.
CI  - Copyright © 2022 Poulsen, Freda, Troiani, Davoudi and Mowery.
FAU - Poulsen, Melissa N
AU  - Poulsen MN
AD  - Department of Population Health Sciences, Geisinger, Danville, PA, United States.
FAU - Freda, Philip J
AU  - Freda PJ
AD  - Department of Biostatistics, Epidemiology and Informatics, University of 
      Pennsylvania, Philadelphia, PA, United States.
FAU - Troiani, Vanessa
AU  - Troiani V
AD  - Autism and Developmental Medicine Institute, Geisinger, Danville, PA, United 
      States.
FAU - Davoudi, Anahita
AU  - Davoudi A
AD  - Department of Biostatistics, Epidemiology and Informatics, University of 
      Pennsylvania, Philadelphia, PA, United States.
FAU - Mowery, Danielle L
AU  - Mowery DL
AD  - Department of Biostatistics, Epidemiology and Informatics, University of 
      Pennsylvania, Philadelphia, PA, United States.
AD  - Department of Biostatistics, Epidemiology and Informatics, Institute for 
      Biomedical Informatics, University of Pennsylvania, Philadelphia, PA, United 
      States.
LA  - eng
GR  - K01 DA049903/DA/NIDA NIH HHS/United States
GR  - R01 DA044015/DA/NIDA NIH HHS/United States
GR  - T32 HG009495/HG/NHGRI NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20220509
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
RN  - 0 (Analgesics, Opioid)
SB  - IM
MH  - Analgesics, Opioid
MH  - Hospitals
MH  - Humans
MH  - *Natural Language Processing
MH  - *Opioid-Related Disorders
MH  - Patient Discharge
MH  - Pilot Projects
PMC - PMC9124945
OTO - NOTNLM
OT  - deep learning
OT  - machine learning
OT  - natural language processing
OT  - opioid-related disorders
OT  - substance use
OT  - supervised learning
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2022/05/27 06:00
MHDA- 2022/05/28 06:00
PMCR- 2022/05/09
CRDT- 2022/05/26 02:15
PHST- 2022/01/07 00:00 [received]
PHST- 2022/04/19 00:00 [accepted]
PHST- 2022/05/26 02:15 [entrez]
PHST- 2022/05/27 06:00 [pubmed]
PHST- 2022/05/28 06:00 [medline]
PHST- 2022/05/09 00:00 [pmc-release]
AID - 10.3389/fpubh.2022.850619 [doi]
PST - epublish
SO  - Front Public Health. 2022 May 9;10:850619. doi: 10.3389/fpubh.2022.850619. 
      eCollection 2022.

PMID- 38749026
OWN - NLM
STAT- MEDLINE
DCOM- 20240515
LR  - 20250130
IS  - 1929-0748 (Electronic)
IS  - 1929-0748 (Linking)
VI  - 13
DP  - 2024 May 15
TI  - Natural Language Processing for Work-Related Stress Detection Among Health 
      Professionals: Protocol for a Scoping Review.
PG  - e56267
LID - 10.2196/56267 [doi]
LID - e56267
AB  - BACKGROUND: There is an urgent need worldwide for qualified health professionals. 
      High attrition rates among health professionals, combined with a predicted rise 
      in life expectancy, further emphasize the need for additional health 
      professionals. Work-related stress is a major concern among health professionals, 
      affecting both the well-being of health professionals and the quality of patient 
      care. OBJECTIVE: This scoping review aims to identify processes and methods for 
      the automatic detection of work-related stress among health professionals using 
      natural language processing (NLP) and text mining techniques. METHODS: This 
      review follows Joanna Briggs Institute Methodology and PRISMA-ScR (Preferred 
      Reporting Items for Systematic Reviews and Meta-Analyses Extension for Scoping 
      Reviews) guidelines. The inclusion criteria for this scoping review encompass 
      studies involving health professionals using NLP for work-related stress 
      detection while excluding studies involving other professions or children. The 
      review focuses on various aspects, including NLP applications for stress 
      detection, criteria for stress identification, technical aspects of NLP, and 
      implications of stress detection through NLP. Studies within health care settings 
      using diverse NLP techniques are considered, including experimental and 
      observational designs, aiming to provide a comprehensive understanding of NLP's 
      role in detecting stress among health professionals. Studies published in 
      English, German, or French from 2013 to present will be considered. The databases 
      to be searched include MEDLINE (via PubMed), CINAHL, PubMed, Cochrane, ACM 
      Digital Library, and IEEE Xplore. Sources of unpublished studies and gray 
      literature to be searched will include ProQuest Dissertations & Theses and 
      OpenGrey. Two reviewers will independently retrieve full-text studies and extract 
      data. The collected data will be organized in tables, graphs, and a qualitative 
      narrative summary. This review will use tables and graphs to present data on 
      studies' distribution by year, country, activity field, and research methods. 
      Results synthesis involves identifying, grouping, and categorizing. The final 
      scoping review will include a narrative written report detailing the search and 
      study selection process, a visual representation using a PRISMA-ScR flow diagram, 
      and a discussion of implications for practice and research. RESULTS: We 
      anticipate the outcomes will be presented in a systematic scoping review by June 
      2024. CONCLUSIONS: This review fills a literature gap by identifying automated 
      work-related stress detection among health professionals using NLP and text 
      mining, providing insights on an innovative approach, and identifying research 
      needs for further systematic reviews. Despite promising outcomes, acknowledging 
      limitations in the reviewed studies, including methodological constraints, sample 
      biases, and potential oversight, is crucial to refining methodologies and 
      advancing automatic stress detection among health professionals. INTERNATIONAL 
      REGISTERED REPORT IDENTIFIER (IRRID): PRR1-10.2196/56267.
CI  - ©Jannic Stefan Bieri, Catherine Ikae, Souhir Ben Souissi, Thomas Jörg Müller, 
      Margarithe Charlotte Schlunegger, Christoph Golz. Originally published in JMIR 
      Research Protocols (https://www.researchprotocols.org), 15.05.2024.
FAU - Bieri, Jannic Stefan
AU  - Bieri JS
AUID- ORCID: 0009-0000-8325-1398
AD  - Department of Health Professions, Bern University of Applied Sciences, Bern, 
      Switzerland.
FAU - Ikae, Catherine
AU  - Ikae C
AUID- ORCID: 0009-0006-2476-3581
AD  - School of Engineering and Computer Science, Bern University of Applied Sciences, 
      Bern, Switzerland.
FAU - Souissi, Souhir Ben
AU  - Souissi SB
AUID- ORCID: 0000-0002-9815-6948
AD  - School of Engineering and Computer Science, Bern University of Applied Sciences, 
      Bern, Switzerland.
FAU - Müller, Thomas Jörg
AU  - Müller TJ
AUID- ORCID: 0000-0001-9315-8138
AD  - Private Clinic Meiringen, Bern, Switzerland.
AD  - Translational Research Center, University Hospital of Psychiatry and 
      Psychotherapy, University of Bern, Bern, Switzerland.
FAU - Schlunegger, Margarithe Charlotte
AU  - Schlunegger MC
AUID- ORCID: 0000-0002-5410-4951
AD  - Department of Health Professions, Bern University of Applied Sciences, Bern, 
      Switzerland.
FAU - Golz, Christoph
AU  - Golz C
AUID- ORCID: 0000-0003-1711-5106
AD  - Department of Health Professions, Bern University of Applied Sciences, Bern, 
      Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20240515
PL  - Canada
TA  - JMIR Res Protoc
JT  - JMIR research protocols
JID - 101599504
SB  - IM
MH  - Humans
MH  - *Health Personnel/psychology
MH  - *Natural Language Processing
MH  - *Occupational Stress/diagnosis/psychology
MH  - Scoping Reviews As Topic
PMC - PMC11137421
OTO - NOTNLM
OT  - automatic detection
OT  - health professionals
OT  - healthcare
OT  - methodology
OT  - natural language processing
OT  - occupational well-being
OT  - scoping review protocol
OT  - synthesis
OT  - text-mining
OT  - work-related stress
COIS- Conflicts of Interest: None declared.
EDAT- 2024/05/15 18:44
MHDA- 2024/05/15 18:45
PMCR- 2024/05/15
CRDT- 2024/05/15 16:53
PHST- 2024/01/19 00:00 [received]
PHST- 2024/04/02 00:00 [accepted]
PHST- 2024/03/28 00:00 [revised]
PHST- 2024/05/15 18:45 [medline]
PHST- 2024/05/15 18:44 [pubmed]
PHST- 2024/05/15 16:53 [entrez]
PHST- 2024/05/15 00:00 [pmc-release]
AID - v13i1e56267 [pii]
AID - 10.2196/56267 [doi]
PST - epublish
SO  - JMIR Res Protoc. 2024 May 15;13:e56267. doi: 10.2196/56267.

PMID- 39173690
OWN - NLM
STAT- MEDLINE
DCOM- 20250123
LR  - 20250123
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
VI  - 41
IP  - 2
DP  - 2025 Feb
TI  - Currently Available Large Language Models Do Not Provide Musculoskeletal 
      Treatment Recommendations That Are Concordant With Evidence-Based Clinical 
      Practice Guidelines.
PG  - 263-275.e6
LID - S0749-8063(24)00575-9 [pii]
LID - 10.1016/j.arthro.2024.07.040 [doi]
AB  - PURPOSE: To determine whether several leading, commercially available large 
      language models (LLMs) provide treatment recommendations concordant with 
      evidence-based clinical practice guidelines (CPGs) developed by the American 
      Academy of Orthopaedic Surgeons (AAOS). METHODS: All CPGs concerning the 
      management of rotator cuff tears (n = 33) and anterior cruciate ligament injuries 
      (n = 15) were extracted from the AAOS. Treatment recommendations from 
      Chat-Generative Pretrained Transformer version 4 (ChatGPT-4), Gemini, Mistral-7B, 
      and Claude-3 were graded by 2 blinded physicians as being concordant, discordant, 
      or indeterminate (i.e., neutral response without definitive recommendation) with 
      respect to AAOS CPGs. The overall concordance between LLM and AAOS 
      recommendations was quantified, and the comparative overall concordance of 
      recommendations among the 4 LLMs was evaluated through the Fisher exact test. 
      RESULTS: Overall, 135 responses (70.3%) were concordant, 43 (22.4%) were 
      indeterminate, and 14 (7.3%) were discordant. Inter-rater reliability for 
      concordance classification was excellent (κ = 0.92). Concordance with AAOS CPGs 
      was most frequently observed with ChatGPT-4 (n = 38, 79.2%) and least frequently 
      observed with Mistral-7B (n = 28, 58.3%). Indeterminate recommendations were most 
      frequently observed with Mistral-7B (n = 17, 35.4%) and least frequently observed 
      with Claude-3 (n = 8, 6.7%). Discordant recommendations were most frequently 
      observed with Gemini (n = 6, 12.5%) and least frequently observed with ChatGPT-4 
      (n = 1, 2.1%). Overall, no statistically significant difference in concordant 
      recommendations was observed across LLMs (P = .12). Of all recommendations, only 
      20 (10.4%) were transparent and provided references with full bibliographic 
      details or links to specific peer-reviewed content to support recommendations. 
      CONCLUSIONS: Among leading commercially available LLMs, more than 1-in-4 
      recommendations concerning the evaluation and management of rotator cuff and 
      anterior cruciate ligament injuries do not reflect current evidence-based CPGs. 
      Although ChatGPT-4 showed the highest performance, clinically significant rates 
      of recommendations without concordance or supporting evidence were observed. Only 
      10% of responses by LLMs were transparent, precluding users from fully 
      interpreting the sources from which recommendations were provided. CLINICAL 
      RELEVANCE: Although leading LLMs generally provide recommendations concordant 
      with CPGs, a substantial error rate exists, and the proportion of recommendations 
      that do not align with these CPGs suggests that LLMs are not trustworthy clinical 
      support tools at this time. Each off-the-shelf, closed-source LLM has strengths 
      and weaknesses. Future research should evaluate and compare multiple LLMs to 
      avoid bias associated with narrow evaluation of few models as observed in the 
      current literature.
CI  - Copyright © 2024 Arthroscopy Association of North America. Published by Elsevier 
      Inc. All rights reserved.
FAU - Nwachukwu, Benedict U
AU  - Nwachukwu BU
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.
FAU - Varady, Nathan H
AU  - Varady NH
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.
FAU - Allen, Answorth A
AU  - Allen AA
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.
FAU - Dines, Joshua S
AU  - Dines JS
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.
FAU - Altchek, David W
AU  - Altchek DW
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.
FAU - Williams, Riley J 3rd
AU  - Williams RJ 3rd
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.
FAU - Kunze, Kyle N
AU  - Kunze KN
AD  - Department of Orthopaedic Surgery, Hospital for Special Surgery, New York, New 
      York, U.S.A.. Electronic address: Kylekunze7@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240822
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic & related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
MH  - Humans
MH  - *Practice Guidelines as Topic
MH  - *Evidence-Based Medicine
MH  - *Anterior Cruciate Ligament Injuries/therapy/surgery
MH  - Rotator Cuff Injuries/therapy
MH  - Language
COIS- Disclosures The authors declare the following financial interests/personal 
      relationships which may be considered as potential competing interests: B.U.N. 
      owns stock or stock options in BICMD and is a paid consultant for Figur8. A.A.A. 
      owns stock or stock options in Pristine Surgical and Rom3. J.S.D. is a board or 
      committee member of American Shoulder and Elbow Surgeons; receives intellectual 
      property royalties from Arthrex and Linvatec; is a paid consultant for Arthrex; 
      is a paid presenter or speaker for Arthrex; receives research support from 
      Arthrex; is on the editorial or governing board of Journal of Shoulder and Elbow 
      Surgery; receives publishing royalties and/or financial or material support from 
      Thieme and Wolters Kluwer Health–Lippincott Williams & Wilkins; and owns stock or 
      stock options in ViewFi. D.W.A. is a paid consultant for Arthrex and Stryker. 
      R.J.W. receives intellectual property royalties from Arthrex; is a paid 
      consultant for Arthrex, JRF Ortho, and Lipogems; owns stock or stock options in 
      BICMD, Cymedica, Engage Surgical, Gramercy Extremity Orthopedics, Pristine 
      Surgical, and RecoverX; and receives research support from Histogenics. K.N.K. is 
      on the editorial board of Arthroscopy and HSS Journal. The other author (N.H.V.) 
      declares that he has no known competing financial interests or personal 
      relationships that could have appeared to influence the work reported in this 
      paper.
EDAT- 2024/08/23 00:43
MHDA- 2025/01/24 00:26
CRDT- 2024/08/22 19:18
PHST- 2024/07/09 00:00 [received]
PHST- 2024/07/26 00:00 [revised]
PHST- 2024/07/29 00:00 [accepted]
PHST- 2025/01/24 00:26 [medline]
PHST- 2024/08/23 00:43 [pubmed]
PHST- 2024/08/22 19:18 [entrez]
AID - S0749-8063(24)00575-9 [pii]
AID - 10.1016/j.arthro.2024.07.040 [doi]
PST - ppublish
SO  - Arthroscopy. 2025 Feb;41(2):263-275.e6. doi: 10.1016/j.arthro.2024.07.040. Epub 
      2024 Aug 22.

PMID- 38971715
OWN - NLM
STAT- MEDLINE
DCOM- 20240801
LR  - 20240818
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Aug 1
TI  - Ethical Considerations and Fundamental Principles of Large Language Models in 
      Medical Education: Viewpoint.
PG  - e60083
LID - 10.2196/60083 [doi]
LID - e60083
AB  - This viewpoint article first explores the ethical challenges associated with the 
      future application of large language models (LLMs) in the context of medical 
      education. These challenges include not only ethical concerns related to the 
      development of LLMs, such as artificial intelligence (AI) hallucinations, 
      information bias, privacy and data risks, and deficiencies in terms of 
      transparency and interpretability but also issues concerning the application of 
      LLMs, including deficiencies in emotional intelligence, educational inequities, 
      problems with academic integrity, and questions of responsibility and copyright 
      ownership. This paper then analyzes existing AI-related legal and ethical 
      frameworks and highlights their limitations with regard to the application of 
      LLMs in the context of medical education. To ensure that LLMs are integrated in a 
      responsible and safe manner, the authors recommend the development of a unified 
      ethical framework that is specifically tailored for LLMs in this field. This 
      framework should be based on 8 fundamental principles: quality control and 
      supervision mechanisms; privacy and data protection; transparency and 
      interpretability; fairness and equal treatment; academic integrity and moral 
      norms; accountability and traceability; protection and respect for intellectual 
      property; and the promotion of educational research and innovation. The authors 
      further discuss specific measures that can be taken to implement these 
      principles, thereby laying a solid foundation for the development of a 
      comprehensive and actionable ethical framework. Such a unified ethical framework 
      based on these 8 fundamental principles can provide clear guidance and support 
      for the application of LLMs in the context of medical education. This approach 
      can help establish a balance between technological advancement and ethical 
      safeguards, thereby ensuring that medical education can progress without 
      compromising the principles of fairness, justice, or patient safety and 
      establishing a more equitable, safer, and more efficient environment for medical 
      education.
CI  - ©Li Zhui, Li Fenghe, Wang Xuehu, Fu Qining, Ren Wei. Originally published in the 
      Journal of Medical Internet Research (https://www.jmir.org), 01.08.2024.
FAU - Zhui, Li
AU  - Zhui L
AUID- ORCID: 0000-0003-3467-7063
AD  - Department of Vascular Surgery, The First Affiliated Hospital of Chongqing 
      Medical University, Chongqing, China.
FAU - Fenghe, Li
AU  - Fenghe L
AUID- ORCID: 0000-0003-3965-8152
AD  - Department of Vascular Surgery, The First Affiliated Hospital of Chongqing 
      Medical University, Chongqing, China.
FAU - Xuehu, Wang
AU  - Xuehu W
AUID- ORCID: 0000-0003-4918-5088
AD  - Department of Vascular Surgery, The First Affiliated Hospital of Chongqing 
      Medical University, Chongqing, China.
FAU - Qining, Fu
AU  - Qining F
AUID- ORCID: 0000-0002-5205-2908
AD  - Department of Vascular Surgery, The First Affiliated Hospital of Chongqing 
      Medical University, Chongqing, China.
FAU - Wei, Ren
AU  - Wei R
AUID- ORCID: 0009-0002-1280-878X
AD  - Department of Vascular Surgery, The First Affiliated Hospital of Chongqing 
      Medical University, Chongqing, China.
LA  - eng
PT  - Journal Article
DEP - 20240801
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - *Education, Medical/ethics
MH  - Humans
MH  - *Artificial Intelligence/ethics
MH  - Language
MH  - Privacy
PMC - PMC11327620
OTO - NOTNLM
OT  - AI
OT  - LLMs
OT  - academic integrity
OT  - artificial intelligence
OT  - data protection
OT  - data security
OT  - educational research
OT  - ethics
OT  - intellectual property rights
OT  - large language models
OT  - medical education
OT  - medical ethics
OT  - privacy and data risks
COIS- Conflicts of Interest: None declared.
EDAT- 2024/07/07 00:42
MHDA- 2024/08/01 18:43
PMCR- 2024/08/01
CRDT- 2024/07/06 22:13
PHST- 2024/04/30 00:00 [received]
PHST- 2024/07/06 00:00 [accepted]
PHST- 2024/08/01 18:43 [medline]
PHST- 2024/07/07 00:42 [pubmed]
PHST- 2024/07/06 22:13 [entrez]
PHST- 2024/08/01 00:00 [pmc-release]
AID - v26i1e60083 [pii]
AID - 10.2196/60083 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Aug 1;26:e60083. doi: 10.2196/60083.

PMID- 38712037
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241224
DP  - 2024 Apr 24
TI  - Leveraging a Large Language Model to Assess Quality-of-Care: Monitoring ADHD 
      Medication Side Effects.
LID - 2024.04.23.24306225 [pii]
LID - 10.1101/2024.04.23.24306225 [doi]
AB  - OBJECTIVE: To assess the accuracy of a large language model (LLM) in measuring 
      clinician adherence to practice guidelines for monitoring side effects after 
      prescribing medications for children with attention-deficit/hyperactivity 
      disorder (ADHD). METHODS: Retrospective population-based cohort study of 
      electronic health records. Cohort included children aged 6-11 years with ADHD 
      diagnosis and ≥2 ADHD medication encounters (stimulants or non-stimulants 
      prescribed) between 2015-2022 in a community-based primary healthcare network 
      (n=1247). To identify documentation of side effects inquiry, we trained, tested, 
      and deployed an open-source LLM (LLaMA) on all clinical notes from ADHD-related 
      encounters (ADHD diagnosis or ADHD medication prescription), including 
      in-clinic/telehealth and telephone encounters (n=15,593 notes). Model performance 
      was assessed using holdout and deployment test sets, compared to manual chart 
      review. RESULTS: The LLaMA model achieved excellent performance in classifying 
      notes that contain side effects inquiry (sensitivity= 87.2%, 
      specificity=86.3/90.3%, area under curve (AUC)=0.93/0.92 on holdout/deployment 
      test sets). Analyses revealed no model bias in relation to patient age, sex, or 
      insurance. Mean age (SD) at first prescription was 8.8 (1.6) years; patient 
      characteristics were similar across patients with and without documented side 
      effects inquiry. Rates of documented side effects inquiry were lower in telephone 
      encounters than in-clinic/telehealth encounters (51.9% vs. 73.0%, p<0.01). Side 
      effects inquiry was documented in 61% of encounters following stimulant 
      prescriptions and 48% of encounters following non-stimulant prescriptions 
      (p<0.01). CONCLUSIONS: Deploying an LLM on a variable set of clinical notes, 
      including telephone notes, offered scalable measurement of quality-of-care and 
      uncovered opportunities to improve psychopharmacological medication management in 
      primary care.
FAU - Bannett, Yair
AU  - Bannett Y
AUID- ORCID: 0000-0001-5134-3300
AD  - Division of Developmental-Behavioral Pediatrics, Stanford University School of 
      Medicine, Stanford, CA, USA.
FAU - Gunturkun, Fatma
AU  - Gunturkun F
AD  - Stanford Quantitative Sciences Unit, Stanford, CA, USA.
FAU - Pillai, Malvika
AU  - Pillai M
AUID- ORCID: 0000-0001-8739-189X
AD  - Veterans Affairs Palo Alto Health Care System, Palo Alto, California, USA.
AD  - Biomedical Informatics Research Center, Stanford University School of Medicine, 
      Stanford, California, USA.
FAU - Herrmann, Jessica E
AU  - Herrmann JE
AUID- ORCID: 0000-0002-3357-8437
AD  - Stanford University School of Medicine, Stanford, California, USA.
FAU - Luo, Ingrid
AU  - Luo I
AD  - Stanford Quantitative Sciences Unit, Stanford, CA, USA.
FAU - Huffman, Lynne C
AU  - Huffman LC
AUID- ORCID: 0000-0003-1240-7118
AD  - Division of Developmental-Behavioral Pediatrics, Stanford University School of 
      Medicine, Stanford, CA, USA.
FAU - Feldman, Heidi M
AU  - Feldman HM
AUID- ORCID: 0000-0002-4435-0913
AD  - Division of Developmental-Behavioral Pediatrics, Stanford University School of 
      Medicine, Stanford, CA, USA.
LA  - eng
GR  - K23 MH128455/MH/NIMH NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240424
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - Pediatrics. 2025 Jan 1;155(1):e2024067223. doi: 10.1542/peds.2024-067223. PMID: 
      39701141
PMC - PMC11071552
COIS- Conflict of Interest Disclosures (includes financial disclosures): The authors 
      have no conflicts of interest to disclose.
EDAT- 2024/05/07 06:42
MHDA- 2024/05/07 06:43
PMCR- 2024/05/06
CRDT- 2024/05/07 03:46
PHST- 2024/05/07 06:42 [pubmed]
PHST- 2024/05/07 06:43 [medline]
PHST- 2024/05/07 03:46 [entrez]
PHST- 2024/05/06 00:00 [pmc-release]
AID - 2024.04.23.24306225 [pii]
AID - 10.1101/2024.04.23.24306225 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Apr 24:2024.04.23.24306225. doi: 
      10.1101/2024.04.23.24306225.

PMID- 37553423
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241012
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 6
IP  - 1
DP  - 2023 Aug 8
TI  - Disparities in cannabis use and documentation in electronic health records among 
      children and young adults.
PG  - 138
LID - 10.1038/s41746-023-00885-w [doi]
LID - 138
AB  - The legalizations of medical and recreational cannabis have generated a great 
      deal of interest in studying the health impacts of cannabis products. Despite 
      increases in cannabis use, its documentation during clinical visits is not yet 
      mainstream. This lack of information hampers efforts to study cannabis's effects 
      on health outcomes. A clear and in-depth understanding of current trends in 
      cannabis use documentation is necessary to develop proper guidelines to screen 
      and document cannabis use. Here we have developed and used a natural language 
      processing pipeline to evaluate the trends and disparities in cannabis 
      documentation. The pipeline includes a screening step to identify clinical notes 
      with cannabis use documentation which is then fed into a BERT-based classifier to 
      confirm positive use. This pipeline is applied to more than 23 million notes from 
      a large cohort of 370,087 patients seen in a high-volume multi-site pediatric and 
      young adult clinic over a period of 21 years. Our findings show a very low but 
      growing rate of cannabis use documentation (<2%) in electronic health records 
      with significant demographic and socioeconomic disparities in both documentation 
      and positive use, which requires further attention.
CI  - © 2023. Springer Nature Limited.
FAU - Tavabi, Nazgol
AU  - Tavabi N
AUID- ORCID: 0000-0002-8877-622X
AD  - Department of Orthopaedic Surgery and Sports Medicine, Boston Children's 
      Hospital, Boston, MA, USA.
AD  - Harvard Medical School, Boston, MA, USA.
FAU - Raza, Marium
AU  - Raza M
AD  - Department of Orthopaedic Surgery and Sports Medicine, Boston Children's 
      Hospital, Boston, MA, USA.
AD  - Harvard Medical School, Boston, MA, USA.
FAU - Singh, Mallika
AU  - Singh M
AUID- ORCID: 0000-0002-2640-7592
AD  - Department of Orthopaedic Surgery and Sports Medicine, Boston Children's 
      Hospital, Boston, MA, USA.
FAU - Golchin, Shahriar
AU  - Golchin S
AD  - Department of Orthopaedic Surgery and Sports Medicine, Boston Children's 
      Hospital, Boston, MA, USA.
AD  - Department of Computer Science, University of Arizona, Tucson, USA.
FAU - Singh, Harsev
AU  - Singh H
AD  - Department of Orthopaedic Surgery and Sports Medicine, Boston Children's 
      Hospital, Boston, MA, USA.
FAU - Hogue, Grant D
AU  - Hogue GD
AD  - Department of Orthopaedic Surgery and Sports Medicine, Boston Children's 
      Hospital, Boston, MA, USA.
AD  - Harvard Medical School, Boston, MA, USA.
FAU - Kiapour, Ata M
AU  - Kiapour AM
AUID- ORCID: 0000-0001-7742-5769
AD  - Department of Orthopaedic Surgery and Sports Medicine, Boston Children's 
      Hospital, Boston, MA, USA. Ata.Kiapour@childrens.harvard.edu.
AD  - Harvard Medical School, Boston, MA, USA. Ata.Kiapour@childrens.harvard.edu.
LA  - eng
PT  - Journal Article
DEP - 20230808
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC10409778
COIS- The authors declare no competing interests.
EDAT- 2023/08/09 01:05
MHDA- 2023/08/09 01:06
PMCR- 2023/08/08
CRDT- 2023/08/08 23:22
PHST- 2022/10/07 00:00 [received]
PHST- 2023/07/26 00:00 [accepted]
PHST- 2023/08/09 01:06 [medline]
PHST- 2023/08/09 01:05 [pubmed]
PHST- 2023/08/08 23:22 [entrez]
PHST- 2023/08/08 00:00 [pmc-release]
AID - 10.1038/s41746-023-00885-w [pii]
AID - 885 [pii]
AID - 10.1038/s41746-023-00885-w [doi]
PST - epublish
SO  - NPJ Digit Med. 2023 Aug 8;6(1):138. doi: 10.1038/s41746-023-00885-w.

PMID- 38827059
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240604
IS  - 2153-4063 (Electronic)
VI  - 2024
DP  - 2024
TI  - ChatGPT and Vaccine Hesitancy: A Comparison of English, Spanish, and French 
      Responses Using a Validated Scale.
PG  - 266-275
AB  - ChatGPT is a popular information system (over 1 billion visits in August 2023) 
      that can generate natural language responses to user queries. It is important to 
      study the quality and equity of its responses on health-related topics, such as 
      vaccination, as they may influence public health decision-making. We use the 
      Vaccine Hesitancy Scale (VHS) proposed by Shapiro et al.(1) to measure the 
      hesitancy of ChatGPT responses in English, Spanish, and French. We find that: (a) 
      ChatGPT responses indicate less hesitancy than those reported for human 
      respondents in past literature; (b) ChatGPT responses vary significantly across 
      languages, with English responses being the most hesitant on average and Spanish 
      being the least; (c) ChatGPT responses are largely consistent across different 
      model parameters but show some variations across the scale factors (vaccine 
      competency, risk). Results have implications for researchers interested in 
      evaluating and improving the quality and equity of health-related web 
      information.
CI  - ©2024 AMIA - All rights reserved.
FAU - Joshi, Saubhagya
AU  - Joshi S
AD  - School of Communication & Information Rutgers University, New Brunswick, NJ, USA.
FAU - Ha, Eunbin
AU  - Ha E
AD  - School of Communication & Information Rutgers University, New Brunswick, NJ, USA.
FAU - Rivera, Yonaira
AU  - Rivera Y
AD  - School of Communication & Information Rutgers University, New Brunswick, NJ, USA.
FAU - Singh, Vivek K
AU  - Singh VK
AD  - School of Communication & Information Rutgers University, New Brunswick, NJ, USA.
LA  - eng
PT  - Journal Article
DEP - 20240531
PL  - United States
TA  - AMIA Jt Summits Transl Sci Proc
JT  - AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on 
      Translational Science
JID - 101539486
PMC - PMC11141820
EDAT- 2024/06/03 06:42
MHDA- 2024/06/03 06:43
PMCR- 2024/05/31
CRDT- 2024/06/03 04:18
PHST- 2024/06/03 06:43 [medline]
PHST- 2024/06/03 06:42 [pubmed]
PHST- 2024/06/03 04:18 [entrez]
PHST- 2024/05/31 00:00 [pmc-release]
AID - 2195 [pii]
PST - epublish
SO  - AMIA Jt Summits Transl Sci Proc. 2024 May 31;2024:266-275. eCollection 2024.

PMID- 31329877
OWN - NLM
STAT- MEDLINE
DCOM- 20210113
LR  - 20231013
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 26
IP  - 8-9
DP  - 2019 Aug 1
TI  - Social determinants of health in mental health care and research: a case for 
      greater inclusion.
PG  - 895-899
LID - 10.1093/jamia/ocz049 [doi]
AB  - Social determinants of health (SDOH) are known to influence mental health 
      outcomes, which are independent risk factors for poor health status and physical 
      illness. Currently, however, existing SDOH data collection methods are ad hoc and 
      inadequate, and SDOH data are not systematically included in clinical research or 
      used to inform patient care. Social contextual data are rarely captured 
      prospectively in a structured and comprehensive manner, leaving large knowledge 
      gaps. Extraction methods are now being developed to facilitate the collection, 
      standardization, and integration of SDOH data into electronic health records. If 
      successful, these efforts may have implications for health equity, such as 
      reducing disparities in access and outcomes. Broader use of surveys, natural 
      language processing, and machine learning methods to harness SDOH may help 
      researchers and clinical teams reduce barriers to mental health care.
CI  - © The Author(s) 2019. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Deferio, Joseph J
AU  - Deferio JJ
AD  - Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, 
      New York, USA.
FAU - Breitinger, Scott
AU  - Breitinger S
AD  - Department of Psychiatry, Weill Cornell Medicine, New York, New York, USA.
FAU - Khullar, Dhruv
AU  - Khullar D
AD  - Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, 
      New York, USA.
AD  - Department of Medicine, Weill Cornell Medicine, New York, New York, USA.
FAU - Sheth, Amit
AU  - Sheth A
AD  - Ohio Center of Excellence in Knowledge-enabled Computing (Kno.e.sis), Wright 
      State University, Dayton, Ohio, USA.
FAU - Pathak, Jyotishman
AU  - Pathak J
AD  - Department of Healthcare Policy and Research, Weill Cornell Medicine, New York, 
      New York, USA.
LA  - eng
GR  - R01 MH105384/MH/NIMH NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - *Biomedical Research
MH  - Data Collection/*methods
MH  - Electronic Health Records/standards
MH  - *Health Equity
MH  - Healthcare Disparities
MH  - Humans
MH  - Machine Learning
MH  - Mental Disorders/therapy
MH  - *Mental Health
MH  - Natural Language Processing
MH  - *Social Determinants of Health
PMC - PMC6696493
EDAT- 2019/07/23 06:00
MHDA- 2021/01/14 06:00
PMCR- 2020/04/26
CRDT- 2019/07/23 06:00
PHST- 2019/01/09 00:00 [received]
PHST- 2019/03/22 00:00 [revised]
PHST- 2019/03/26 00:00 [accepted]
PHST- 2019/07/23 06:00 [pubmed]
PHST- 2021/01/14 06:00 [medline]
PHST- 2019/07/23 06:00 [entrez]
PHST- 2020/04/26 00:00 [pmc-release]
AID - 5480562 [pii]
AID - ocz049 [pii]
AID - 10.1093/jamia/ocz049 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2019 Aug 1;26(8-9):895-899. doi: 10.1093/jamia/ocz049.

PMID- 38046016
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231205
IS  - 2048-8505 (Print)
IS  - 2048-8513 (Electronic)
IS  - 2048-8505 (Linking)
VI  - 16
IP  - 12
DP  - 2023 Dec
TI  - Artificial intelligence: a new field of knowledge for nephrologists?
PG  - 2314-2326
LID - 10.1093/ckj/sfad182 [doi]
AB  - Artificial intelligence (AI) is a science that involves creating machines that 
      can imitate human intelligence and learn. AI is ubiquitous in our daily lives, 
      from search engines like Google to home assistants like Alexa and, more recently, 
      OpenAI with its chatbot. AI can improve clinical care and research, but its use 
      requires a solid understanding of its fundamentals, the promises and perils of 
      algorithmic fairness, the barriers and solutions to its clinical implementation, 
      and the pathways to developing an AI-competent workforce. The potential of AI in 
      the field of nephrology is vast, particularly in the areas of diagnosis, 
      treatment and prediction. One of the most significant advantages of AI is the 
      ability to improve diagnostic accuracy. Machine learning algorithms can be 
      trained to recognize patterns in patient data, including lab results, imaging and 
      medical history, in order to identify early signs of kidney disease and thereby 
      allow timely diagnoses and prompt initiation of treatment plans that can improve 
      outcomes for patients. In short, AI holds the promise of advancing personalized 
      medicine to new levels. While AI has tremendous potential, there are also 
      significant challenges to its implementation, including data access and quality, 
      data privacy and security, bias, trustworthiness, computing power, AI integration 
      and legal issues. The European Commission's proposed regulatory framework for AI 
      technology will play a significant role in ensuring the safe and ethical 
      implementation of these technologies in the healthcare industry. Training 
      nephrologists in the fundamentals of AI is imperative because traditionally, 
      decision-making pertaining to the diagnosis, prognosis and treatment of renal 
      patients has relied on ingrained practices, whereas AI serves as a powerful tool 
      for swiftly and confidently synthesizing this information.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the ERA.
FAU - Fayos De Arizón, Leonor
AU  - Fayos De Arizón L
AD  - Nephrology Department, Fundació Puigvert; Institut d'Investigacions Biomèdiques 
      Sant Pau (IIB-Sant Pau); Departament de Medicina, Universitat Autònoma de 
      Barcelona, Barcelona, Spain.
FAU - Viera, Elizabeth R
AU  - Viera ER
AD  - Nephrology Department, Fundació Puigvert; Institut d'Investigacions Biomèdiques 
      Sant Pau (IIB-Sant Pau); Departament de Medicina, Universitat Autònoma de 
      Barcelona, Barcelona, Spain.
FAU - Pilco, Melissa
AU  - Pilco M
AD  - Nephrology Department, Fundació Puigvert; Institut d'Investigacions Biomèdiques 
      Sant Pau (IIB-Sant Pau); Departament de Medicina, Universitat Autònoma de 
      Barcelona, Barcelona, Spain.
FAU - Perera, Alexandre
AU  - Perera A
AD  - Center for Biomedical Engineering Research (CREB), Universitat Politècnica de 
      Barcelona (UPC), Barcelona, Spain; Networking Biomedical Research Centre in the 
      subject area of Bioengineering, Biomaterials and Nanomedicine (CIBER-BBN), 
      Madrid, Spain; Institut de Recerca Sant Joan de Déu, Esplugues de Llobregat, 
      Barcelona, Spain.
FAU - De Maeztu, Gabriel
AU  - De Maeztu G
AD  - IOMED, Barcelona, Spain.
FAU - Nicolau, Anna
AU  - Nicolau A
AD  - Neuroelectrics, Barcelona, Spain.
FAU - Furlano, Monica
AU  - Furlano M
AD  - Nephrology Department, Fundació Puigvert; Institut d'Investigacions Biomèdiques 
      Sant Pau (IIB-Sant Pau); Departament de Medicina, Universitat Autònoma de 
      Barcelona, Barcelona, Spain.
FAU - Torra, Roser
AU  - Torra R
AUID- ORCID: 0000-0001-8714-2332
AD  - Nephrology Department, Fundació Puigvert; Institut d'Investigacions Biomèdiques 
      Sant Pau (IIB-Sant Pau); Departament de Medicina, Universitat Autònoma de 
      Barcelona, Barcelona, Spain.
LA  - eng
PT  - Journal Article
DEP - 20230729
PL  - England
TA  - Clin Kidney J
JT  - Clinical kidney journal
JID - 101579321
PMC - PMC10689169
OTO - NOTNLM
OT  - artificial intelligence
OT  - kidney
OT  - machine learning
OT  - natural language processing
OT  - nephrology
COIS- None declared.
EDAT- 2023/12/04 06:42
MHDA- 2023/12/04 06:43
PMCR- 2023/07/29
CRDT- 2023/12/04 04:48
PHST- 2023/05/23 00:00 [received]
PHST- 2023/12/04 06:43 [medline]
PHST- 2023/12/04 06:42 [pubmed]
PHST- 2023/12/04 04:48 [entrez]
PHST- 2023/07/29 00:00 [pmc-release]
AID - sfad182 [pii]
AID - 10.1093/ckj/sfad182 [doi]
PST - epublish
SO  - Clin Kidney J. 2023 Jul 29;16(12):2314-2326. doi: 10.1093/ckj/sfad182. 
      eCollection 2023 Dec.

PMID- 40032513
OWN - NLM
STAT- Publisher
LR  - 20250303
IS  - 1473-4257 (Electronic)
IS  - 0306-6800 (Linking)
DP  - 2025 Mar 3
TI  - Which AI doctor would you like to see? Emulating healthcare provider-patient 
      communication models with GPT-4: proof-of-concept and ethical exploration.
LID - jme-2024-110256 [pii]
LID - 10.1136/jme-2024-110256 [doi]
AB  - Large language models (LLMs) have demonstrated potential in enhancing various 
      aspects of healthcare, including health provider-patient communication. However, 
      some have raised the concern that such communication may adopt implicit 
      communication norms that deviate from what patients want or need from talking 
      with their healthcare provider. This paper explores the possibility of using LLMs 
      to enable patients to choose their preferred communication style when discussing 
      their medical cases. By providing a proof-of-concept demonstration using 
      ChatGPT-4, we suggest LLMs can emulate different healthcare provider-patient 
      communication approaches (building on Emanuel and Emanuel's four models: 
      paternalistic, informative, interpretive and deliberative). This allows patients 
      to engage in a communication style that aligns with their individual needs and 
      preferences. We also highlight potential risks associated with using LLMs in 
      healthcare communication, such as reinforcing patients' biases and the persuasive 
      capabilities of LLMs that may lead to unintended manipulation.
CI  - © Author(s) (or their employer(s)) 2025. Re-use permitted under CC BY. Published 
      by BMJ Group.
FAU - Zohny, Hazem
AU  - Zohny H
AUID- ORCID: 0000-0002-7734-2186
AD  - Oxford Uehiro Centre for Practical Ethics, Oxford University, Oxford, UK 
      hazem.zohny@uehiro.ox.ac.uk.
FAU - Allen, Jemima Winifred
AU  - Allen JW
AD  - Philosophy, University of Oxford Uehiro Centre for Practical Ethics, Oxford, UK.
AD  - Department of Paediatrics, Monash University, Melbourne, Victoria, Australia.
FAU - Wilkinson, Dominic
AU  - Wilkinson D
AUID- ORCID: 0000-0003-3958-8633
AD  - Oxford Uehiro Centre for Practical Ethics, Oxford University, Oxford, UK.
AD  - Oxford University Hospitals NHS Foundation Trust, Oxford, UK.
FAU - Savulescu, Julian
AU  - Savulescu J
AUID- ORCID: 0000-0003-1691-6403
AD  - Centre for Biomedical Ethics, Yong Loo Lin School of Medicine, National 
      University of Singapore, Singapore.
AD  - Wellcome Centre for Ethics and Humanities, Oxford University, Oxford, UK.
LA  - eng
PT  - Journal Article
DEP - 20250303
PL  - England
TA  - J Med Ethics
JT  - Journal of medical ethics
JID - 7513619
SB  - IM
OTO - NOTNLM
OT  - Ethics- Medical
OT  - Information Technology
OT  - Personal Autonomy
COIS- Competing interests: JS is an advisor of AminoChain. JS is a Bioethics Advisor to 
      the Hevolution Foundation. JS is a Bioethics Committee consultant for Bayer.
EDAT- 2025/03/04 00:22
MHDA- 2025/03/04 00:22
CRDT- 2025/03/03 21:33
PHST- 2024/06/24 00:00 [received]
PHST- 2025/02/01 00:00 [accepted]
PHST- 2025/03/04 00:22 [medline]
PHST- 2025/03/04 00:22 [pubmed]
PHST- 2025/03/03 21:33 [entrez]
AID - jme-2024-110256 [pii]
AID - 10.1136/jme-2024-110256 [doi]
PST - aheadofprint
SO  - J Med Ethics. 2025 Mar 3:jme-2024-110256. doi: 10.1136/jme-2024-110256.

PMID- 40033130
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250315
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 8
IP  - 1
DP  - 2025 Mar 3
TI  - Assessing and alleviating state anxiety in large language models.
PG  - 132
LID - 10.1038/s41746-025-01512-6 [doi]
LID - 132
AB  - The use of Large Language Models (LLMs) in mental health highlights the need to 
      understand their responses to emotional content. Previous research shows that 
      emotion-inducing prompts can elevate "anxiety" in LLMs, affecting behavior and 
      amplifying biases. Here, we found that traumatic narratives increased 
      Chat-GPT-4's reported anxiety while mindfulness-based exercises reduced it, 
      though not to baseline. These findings suggest managing LLMs' "emotional states" 
      can foster safer and more ethical human-AI interactions.
CI  - © 2025. The Author(s).
FAU - Ben-Zion, Ziv
AU  - Ben-Zion Z
AUID- ORCID: 0000-0003-3629-5851
AD  - Department of Comparative Medicine, Yale School of Medicine, New Haven, CT, USA. 
      ziv.ben-zion@yale.edu.
AD  - Department of Psychiatry, Yale School of Medicine, New Haven, CT, USA. 
      ziv.ben-zion@yale.edu.
AD  - United States Department of Veterans Affairs National Center for PTSD, Clinical 
      Neuroscience Division, VA Connecticut Healthcare System, West Haven, CT, USA. 
      ziv.ben-zion@yale.edu.
AD  - School of Public Health, Faculty of Social Welfare and Health Sciences, 
      University of Haifa, Haifa, Israel. ziv.ben-zion@yale.edu.
FAU - Witte, Kristin
AU  - Witte K
AD  - Helmholtz Institute for Human-Centered Artificial Intelligence, Munich, Germany.
AD  - Max Planck Institute for Biological Cybernetics, Tubingen, Germany.
FAU - Jagadish, Akshay K
AU  - Jagadish AK
AD  - Helmholtz Institute for Human-Centered Artificial Intelligence, Munich, Germany.
AD  - Max Planck Institute for Biological Cybernetics, Tubingen, Germany.
FAU - Duek, Or
AU  - Duek O
AUID- ORCID: 0000-0001-5211-7946
AD  - Department of Epidemiology, Biostatistics, and Community Health Sciences, 
      Ben-Gurion University of the Negev, Beer-Sheva, Israel.
AD  - Department of Psychology, Yale University, New Haven, CT, USA.
FAU - Harpaz-Rotem, Ilan
AU  - Harpaz-Rotem I
AD  - Department of Psychiatry, Yale School of Medicine, New Haven, CT, USA.
AD  - United States Department of Veterans Affairs National Center for PTSD, Clinical 
      Neuroscience Division, VA Connecticut Healthcare System, West Haven, CT, USA.
AD  - Department of Psychology, Yale University, New Haven, CT, USA.
AD  - Wu Tsai Institute, Yale University, New Haven, CT, USA.
FAU - Khorsandian, Marie-Christine
AU  - Khorsandian MC
AD  - Psychiatric University Clinic Zurich (PUK), Zurich, Switzerland.
AD  - University of Zurich (UZH), Zurich, Switzerland.
FAU - Burrer, Achim
AU  - Burrer A
AD  - Psychiatric University Clinic Zurich (PUK), Zurich, Switzerland.
AD  - University of Zurich (UZH), Zurich, Switzerland.
FAU - Seifritz, Erich
AU  - Seifritz E
AD  - Psychiatric University Clinic Zurich (PUK), Zurich, Switzerland.
AD  - University of Zurich (UZH), Zurich, Switzerland.
FAU - Homan, Philipp
AU  - Homan P
AUID- ORCID: 0000-0001-9034-148X
AD  - Psychiatric University Clinic Zurich (PUK), Zurich, Switzerland.
AD  - University of Zurich (UZH), Zurich, Switzerland.
AD  - Neuroscience Center Zurich, University of Zurich and ETH Zurich, Zurich, 
      Switzerland.
FAU - Schulz, Eric
AU  - Schulz E
AD  - Helmholtz Institute for Human-Centered Artificial Intelligence, Munich, Germany.
AD  - Max Planck Institute for Biological Cybernetics, Tubingen, Germany.
FAU - Spiller, Tobias R
AU  - Spiller TR
AUID- ORCID: 0000-0002-0107-0743
AD  - Department of Psychiatry, Yale School of Medicine, New Haven, CT, USA.
AD  - Psychiatric University Clinic Zurich (PUK), Zurich, Switzerland.
AD  - University of Zurich (UZH), Zurich, Switzerland.
LA  - eng
GR  - UL1 TR001863/TR/NCATS NIH HHS/United States
PT  - Journal Article
DEP - 20250303
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC11876565
COIS- Competing interests: The authors declare no competing interests.
EDAT- 2025/03/04 00:21
MHDA- 2025/03/04 00:22
PMCR- 2025/03/03
CRDT- 2025/03/03 23:38
PHST- 2024/05/31 00:00 [received]
PHST- 2025/02/11 00:00 [accepted]
PHST- 2025/03/04 00:22 [medline]
PHST- 2025/03/04 00:21 [pubmed]
PHST- 2025/03/03 23:38 [entrez]
PHST- 2025/03/03 00:00 [pmc-release]
AID - 10.1038/s41746-025-01512-6 [pii]
AID - 1512 [pii]
AID - 10.1038/s41746-025-01512-6 [doi]
PST - epublish
SO  - NPJ Digit Med. 2025 Mar 3;8(1):132. doi: 10.1038/s41746-025-01512-6.

PMID- 39018490
OWN - NLM
STAT- MEDLINE
DCOM- 20240920
LR  - 20240923
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 10
DP  - 2024 Oct 1
TI  - Applying natural language processing to patient messages to identify depression 
      concerns in cancer patients.
PG  - 2255-2262
LID - 10.1093/jamia/ocae188 [doi]
AB  - OBJECTIVE: This study aims to explore and develop tools for early identification 
      of depression concerns among cancer patients by leveraging the novel data source 
      of messages sent through a secure patient portal. MATERIALS AND METHODS: We 
      developed classifiers based on logistic regression (LR), support vector machines 
      (SVMs), and 2 Bidirectional Encoder Representations from Transformers (BERT) 
      models (original and Reddit-pretrained) on 6600 patient messages from a cancer 
      center (2009-2022), annotated by a panel of healthcare professionals. Performance 
      was compared using AUROC scores, and model fairness and explainability were 
      examined. We also examined correlations between model predictions and depression 
      diagnosis and treatment. RESULTS: BERT and RedditBERT attained AUROC scores of 
      0.88 and 0.86, respectively, compared to 0.79 for LR and 0.83 for SVM. BERT 
      showed bigger differences in performance across sex, race, and ethnicity than 
      RedditBERT. Patients who sent messages classified as concerning had a higher 
      chance of receiving a depression diagnosis, a prescription for antidepressants, 
      or a referral to the psycho-oncologist. Explanations from BERT and RedditBERT 
      differed, with no clear preference from annotators. DISCUSSION: We show the 
      potential of BERT and RedditBERT in identifying depression concerns in messages 
      from cancer patients. Performance disparities across demographic groups highlight 
      the need for careful consideration of potential biases. Further research is 
      needed to address biases, evaluate real-world impacts, and ensure responsible 
      integration into clinical settings. CONCLUSION: This work represents a 
      significant methodological advancement in the early identification of depression 
      concerns among cancer patients. Our work contributes to a route to reduce 
      clinical burden while enhancing overall patient care, leveraging BERT-based 
      models.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - van Buchem, Marieke M
AU  - van Buchem MM
AUID- ORCID: 0000-0002-2917-0842
AD  - Department of Medicine (Biomedical Informatics), Stanford University, Stanford, 
      CA 94305, United States.
AD  - Clinical Artificial Intelligence Implementation and Research Lab (CAIRELab), 
      Leiden University Medical Center, Leiden 2333ZN, The Netherlands.
FAU - de Hond, Anne A H
AU  - de Hond AAH
AD  - Department of Medicine (Biomedical Informatics), Stanford University, Stanford, 
      CA 94305, United States.
AD  - Julius Centre for Health Sciences and Primary Care, University Medical Center, 
      Utrecht 3584CX, The Netherlands.
FAU - Fanconi, Claudio
AU  - Fanconi C
AD  - Department of Medicine (Biomedical Informatics), Stanford University, Stanford, 
      CA 94305, United States.
AD  - Department of Information Technology and Electrical Engineering, ETH Zürich, 
      Zürich 8092, Switzerland.
FAU - Shah, Vaibhavi
AU  - Shah V
AD  - Department of Medicine (Biomedical Informatics), Stanford University, Stanford, 
      CA 94305, United States.
FAU - Schuessler, Max
AU  - Schuessler M
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA 94305, 
      United States.
FAU - Kant, Ilse M J
AU  - Kant IMJ
AD  - Department of Digital Health, University Medical Center Utrecht, Utrecht 3584CX, 
      The Netherlands.
FAU - Steyerberg, Ewout W
AU  - Steyerberg EW
AD  - Clinical Artificial Intelligence Implementation and Research Lab (CAIRELab), 
      Leiden University Medical Center, Leiden 2333ZN, The Netherlands.
AD  - Department of Biomedical Data Sciences, Leiden University Medical Center, Leiden 
      2333ZN, The Netherlands.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AUID- ORCID: 0000-0001-6553-3455
AD  - Department of Medicine (Biomedical Informatics), Stanford University, Stanford, 
      CA 94305, United States.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA 94305, 
      United States.
LA  - eng
GR  - UL1TR003142/NH/NIH HHS/United States
GR  - R01 LM013362/LM/NLM NIH HHS/United States
GR  - Catharine van Tussenbroek Fund/
GR  - R01LM013362/NH/NIH HHS/United States
GR  - Prins Bernhard Cultuur Fund/
GR  - UL1TR003142/National Center for Advancing Translational Sciences of the National 
      Institutes of Health/
GR  - UL1 TR003142/TR/NCATS NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Neoplasms/complications
MH  - *Depression
MH  - Male
MH  - Female
MH  - *Support Vector Machine
MH  - Logistic Models
MH  - Patient Portals
MH  - Middle Aged
MH  - Adult
PMC - PMC11413442
OTO - NOTNLM
OT  - machine learning
OT  - mental health
OT  - natural language processing
OT  - oncology
COIS- The authors have no competing interests to disclose.
EDAT- 2024/07/17 18:42
MHDA- 2024/09/21 13:19
PMCR- 2025/07/17
CRDT- 2024/07/17 15:23
PHST- 2024/03/19 00:00 [received]
PHST- 2024/06/03 00:00 [revised]
PHST- 2024/07/09 00:00 [accepted]
PHST- 2025/07/17 00:00 [pmc-release]
PHST- 2024/09/21 13:19 [medline]
PHST- 2024/07/17 18:42 [pubmed]
PHST- 2024/07/17 15:23 [entrez]
AID - 7715991 [pii]
AID - ocae188 [pii]
AID - 10.1093/jamia/ocae188 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Oct 1;31(10):2255-2262. doi: 10.1093/jamia/ocae188.

PMID- 39476380
OWN - NLM
STAT- MEDLINE
DCOM- 20241030
LR  - 20241116
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 8
DP  - 2024 Oct 30
TI  - Ensuring Accuracy and Equity in Vaccination Information From ChatGPT and CDC: 
      Mixed-Methods Cross-Language Evaluation.
PG  - e60939
LID - 10.2196/60939 [doi]
LID - e60939
AB  - BACKGROUND: In the digital age, large language models (LLMs) like ChatGPT have 
      emerged as important sources of health care information. Their interactive 
      capabilities offer promise for enhancing health access, particularly for groups 
      facing traditional barriers such as insurance and language constraints. Despite 
      their growing public health use, with millions of medical queries processed 
      weekly, the quality of LLM-provided information remains inconsistent. Previous 
      studies have predominantly assessed ChatGPT's English responses, overlooking the 
      needs of non-English speakers in the United States. This study addresses this gap 
      by evaluating the quality and linguistic parity of vaccination information from 
      ChatGPT and the Centers for Disease Control and Prevention (CDC), emphasizing 
      health equity. OBJECTIVE: This study aims to assess the quality and language 
      equity of vaccination information provided by ChatGPT and the CDC in English and 
      Spanish. It highlights the critical need for cross-language evaluation to ensure 
      equitable health information access for all linguistic groups. METHODS: We 
      conducted a comparative analysis of ChatGPT's and CDC's responses to frequently 
      asked vaccination-related questions in both languages. The evaluation encompassed 
      quantitative and qualitative assessments of accuracy, readability, and 
      understandability. Accuracy was gauged by the perceived level of misinformation; 
      readability, by the Flesch-Kincaid grade level and readability score; and 
      understandability, by items from the National Institutes of Health's 
      Patient Education Materials Assessment Tool (PEMAT) instrument. RESULTS: The 
      study found that both ChatGPT and CDC provided mostly accurate and understandable 
      (eg, scores over 95 out of 100) responses. However, Flesch-Kincaid grade levels 
      often exceeded the American Medical Association's recommended levels, 
      particularly in English (eg, average grade level in English for ChatGPT=12.84, 
      Spanish=7.93, recommended=6). CDC responses outperformed ChatGPT in readability 
      across both languages. Notably, some Spanish responses appeared to be direct 
      translations from English, leading to unnatural phrasing. The findings underscore 
      the potential and challenges of using ChatGPT for health care access. 
      CONCLUSIONS: ChatGPT holds potential as a health information resource but 
      requires improvements in readability and linguistic equity to be truly effective 
      for diverse populations. Crucially, the default user experience with ChatGPT, 
      typically encountered by those without advanced language and prompting skills, 
      can significantly shape health perceptions. This is vital from a public health 
      standpoint, as the majority of users will interact with LLMs in their most 
      accessible form. Ensuring that default responses are accurate, understandable, 
      and equitable is imperative for fostering informed health decisions across 
      diverse communities.
CI  - ©Saubhagya Joshi, Eunbin Ha, Andee Amaya, Melissa Mendoza, Yonaira Rivera, Vivek 
      K Singh. Originally published in JMIR Formative Research 
      (https://formative.jmir.org), 30.10.2024.
FAU - Joshi, Saubhagya
AU  - Joshi S
AUID- ORCID: 0009-0000-8067-6227
AD  - School of Communication & Information, Rutgers University, New Brunswick, NJ, 
      United States.
FAU - Ha, Eunbin
AU  - Ha E
AUID- ORCID: 0009-0005-4452-0299
AD  - School of Communication & Information, Rutgers University, New Brunswick, NJ, 
      United States.
FAU - Amaya, Andee
AU  - Amaya A
AUID- ORCID: 0009-0006-5578-1192
AD  - School of Communication & Information, Rutgers University, New Brunswick, NJ, 
      United States.
FAU - Mendoza, Melissa
AU  - Mendoza M
AUID- ORCID: 0009-0007-7635-5202
AD  - School of Communication & Information, Rutgers University, New Brunswick, NJ, 
      United States.
FAU - Rivera, Yonaira
AU  - Rivera Y
AUID- ORCID: 0000-0002-5041-5250
AD  - School of Communication & Information, Rutgers University, New Brunswick, NJ, 
      United States.
FAU - Singh, Vivek K
AU  - Singh VK
AUID- ORCID: 0000-0002-8194-2336
AD  - School of Communication & Information, Rutgers University, New Brunswick, NJ, 
      United States.
LA  - eng
PT  - Journal Article
DEP - 20241030
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
SB  - IM
MH  - Humans
MH  - United States
MH  - *Centers for Disease Control and Prevention, U.S.
MH  - *Vaccination
MH  - Language
MH  - Consumer Health Information/standards
MH  - Health Literacy
MH  - Health Equity
PMC - PMC11561424
OTO - NOTNLM
OT  - artificial intelligence
OT  - conversational agents
OT  - health equity
OT  - health information
OT  - health literacy
OT  - language equity
OT  - large language models
OT  - multilingualism
OT  - online health information
OT  - public health
OT  - vaccination
COIS- Conflicts of Interest: None declared.
EDAT- 2024/10/30 22:17
MHDA- 2024/10/31 04:20
PMCR- 2024/10/30
CRDT- 2024/10/30 16:53
PHST- 2024/05/26 00:00 [received]
PHST- 2024/08/21 00:00 [accepted]
PHST- 2024/07/31 00:00 [revised]
PHST- 2024/10/31 04:20 [medline]
PHST- 2024/10/30 22:17 [pubmed]
PHST- 2024/10/30 16:53 [entrez]
PHST- 2024/10/30 00:00 [pmc-release]
AID - v8i1e60939 [pii]
AID - 10.2196/60939 [doi]
PST - epublish
SO  - JMIR Form Res. 2024 Oct 30;8:e60939. doi: 10.2196/60939.

PMID- 39222957
OWN - NLM
STAT- MEDLINE
DCOM- 20240902
LR  - 20240905
IS  - 1526-2359 (Electronic)
IS  - 1073-2748 (Print)
IS  - 1073-2748 (Linking)
VI  - 31
DP  - 2024 Jan-Dec
TI  - A Multi-Institutional Natural Language Processing Pipeline to Extract Performance 
      Status From Electronic Health Records.
PG  - 10732748241279518
LID - 10.1177/10732748241279518 [doi]
LID - 10732748241279518
AB  - PURPOSE: Performance status (PS), an essential indicator of patients' functional 
      abilities, is often documented in clinical notes of patients with cancer. The use 
      of natural language processing (NLP) in extracting PS from electronic medical 
      records (EMRs) has shown promise in enhancing clinical decision-making, patient 
      monitoring, and research studies. We designed and validated a multi-institute NLP 
      pipeline to automatically extract performance status from free-text patient 
      notes. PATIENTS AND METHODS: We collected data from 19,481 patients in Harris 
      Health System (HHS) and 333,862 patients from veteran affair's corporate data 
      warehouse (VA-CDW) and randomly selected 400 patients from each data source to 
      train and validate (50%) and test (50%) the proposed pipeline. We designed an NLP 
      pipeline using an expert-derived rule-based approach in conjunction with 
      extensive post-processing to solidify its proficiency. To demonstrate the 
      pipeline's application, we tested the compliance of PS documentation suggested by 
      the American Society of Clinical Oncology (ASCO) Quality Metric and investigated 
      the potential disparity in PS reporting for stage IV non-small cell lung cancer 
      (NSCLC). We used a logistic regression test, considering patients in terms of 
      race/ethnicity, conversing language, marital status, and gender. RESULTS: The 
      test results on the HHS cohort showed 92% accuracy, and on VA data demonstrated 
      98.5% accuracy. For stage IV NSCLC patients, the proposed pipeline achieved an 
      accuracy of 98.5%. Furthermore, our analysis revealed a documentation rate of 
      over 85% for PS among NSCLC patients, surpassing the ASCO Quality Metrics. No 
      disparities were observed in the documentation of PS. CONCLUSION: Our proposed 
      NLP pipeline shows promising results in extracting PS from free-text notes from 
      various health institutions. It may be used in longitudinal cancer data 
      registries.
FAU - Maghsoudi, Arash
AU  - Maghsoudi A
AD  - Center for Innovations in Quality, Effectiveness, and Safety, Michael E. DeBakey 
      VA Medical Center, Houston, TX, USA. RINGGOLD: 72723
AD  - Department of Medicine, Baylor College of Medicine, Houston, TX, USA. RINGGOLD: 
      3989
FAU - Sada, Yvonne H
AU  - Sada YH
AD  - Center for Innovations in Quality, Effectiveness, and Safety, Michael E. DeBakey 
      VA Medical Center, Houston, TX, USA. RINGGOLD: 72723
AD  - Department of Medicine, Baylor College of Medicine, Houston, TX, USA. RINGGOLD: 
      3989
FAU - Nowakowski, Sara
AU  - Nowakowski S
AD  - Center for Innovations in Quality, Effectiveness, and Safety, Michael E. DeBakey 
      VA Medical Center, Houston, TX, USA. RINGGOLD: 72723
AD  - Department of Medicine, Baylor College of Medicine, Houston, TX, USA. RINGGOLD: 
      3989
FAU - Guffey, Danielle
AU  - Guffey D
AUID- ORCID: 0000-0003-3721-614X
AD  - Section of Hematology-Oncology, Baylor College of Medicine, Houston, TX, USA. 
      RINGGOLD: 3989
FAU - Zhu, Huili
AU  - Zhu H
AD  - Department of Medicine, Baylor College of Medicine, Houston, TX, USA. RINGGOLD: 
      3989
FAU - Yarlagadda, Sudha R
AU  - Yarlagadda SR
AD  - Department of Medicine, Baylor College of Medicine, Houston, TX, USA. RINGGOLD: 
      3989
FAU - Li, Ang
AU  - Li A
AD  - Section of Hematology-Oncology, Baylor College of Medicine, Houston, TX, USA. 
      RINGGOLD: 3989
FAU - Razjouyan, Javad
AU  - Razjouyan J
AD  - Center for Innovations in Quality, Effectiveness, and Safety, Michael E. DeBakey 
      VA Medical Center, Houston, TX, USA. RINGGOLD: 72723
AD  - Department of Medicine, Baylor College of Medicine, Houston, TX, USA. RINGGOLD: 
      3989
AD  - Big Data Scientist Training Enhancement Program (BD-STEP), VA Office of Research 
      and Development, Washington, DC, USA.
LA  - eng
GR  - IK2 CX001981/CX/CSRD VA/United States
GR  - K25 HL152006/HL/NHLBI NIH HHS/United States
GR  - OT2 OD032581/OD/NIH HHS/United States
PT  - Journal Article
PT  - Multicenter Study
PL  - United States
TA  - Cancer Control
JT  - Cancer control : journal of the Moffitt Cancer Center
JID - 9438457
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Electronic Health Records/statistics & numerical data
MH  - Male
MH  - Female
MH  - Lung Neoplasms/therapy
MH  - Carcinoma, Non-Small-Cell Lung/therapy
MH  - Middle Aged
MH  - Neoplasms/therapy
PMC - PMC11369884
OTO - NOTNLM
OT  - American Society of Clinical Oncology
OT  - Eastern cooperative oncology group
OT  - Non small cell lung cancer
OT  - natural language processing
OT  - performance status
OT  - quality metric
EDAT- 2024/09/03 01:42
MHDA- 2024/09/03 01:43
PMCR- 2024/09/02
CRDT- 2024/09/02 20:22
PHST- 2024/09/03 01:43 [medline]
PHST- 2024/09/03 01:42 [pubmed]
PHST- 2024/09/02 20:22 [entrez]
PHST- 2024/09/02 00:00 [pmc-release]
AID - 10.1177_10732748241279518 [pii]
AID - 10.1177/10732748241279518 [doi]
PST - ppublish
SO  - Cancer Control. 2024 Jan-Dec;31:10732748241279518. doi: 
      10.1177/10732748241279518.

PMID- 37350895
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230701
IS  - 2153-4063 (Electronic)
VI  - 2023
DP  - 2023
TI  - Natural Language Processing Methods to Identify Oncology Patients at High Risk 
      for Acute Care with Clinical Notes.
PG  - 138-147
AB  - Clinical notes are an essential component of a health record. This paper 
      evaluates how natural language processing (NLP) can be used to identify the risk 
      of acute care use (ACU) in oncology patients, once chemotherapy starts. Risk 
      prediction using structured health data (SHD) is now standard, but predictions 
      using free-text formats are complex. This paper explores the use of free-text 
      notes for the prediction of ACU in leu of SHD. Deep Learning models were compared 
      to manually engineered language features. Results show that SHD models minimally 
      outperform NLP models; an ℓ(1)-penalised logistic regression with SHD achieved a 
      C-statistic of 0.748 (95%-CI: 0.735, 0.762), while the same model with language 
      features achieved 0.730 (95%-CI: 0.717, 0.745) and a transformer-based model 
      achieved 0.702 (95%-CI: 0.688, 0.717). This paper shows how language models can 
      be used in clinical applications and underlines how risk bias is different for 
      diverse patient groups, even using only free-text data.
CI  - ©2023 AMIA - All rights reserved.
FAU - Fanconi, Claudio
AU  - Fanconi C
AD  - Stanford University, Stanford, California, United States.
AD  - ETH Zürich, Zürich, Switzerland.
FAU - van Buchem, Marieke
AU  - van Buchem M
AD  - Stanford University, Stanford, California, United States.
AD  - Leiden University Medical Center, Leiden, The Netherlands.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AD  - Stanford University, Stanford, California, United States.
LA  - eng
PT  - Journal Article
DEP - 20230616
PL  - United States
TA  - AMIA Jt Summits Transl Sci Proc
JT  - AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on 
      Translational Science
JID - 101539486
PMC - PMC10283145
EDAT- 2023/06/23 13:07
MHDA- 2023/06/23 13:08
PMCR- 2023/06/16
CRDT- 2023/06/23 10:25
PHST- 2023/06/23 13:08 [medline]
PHST- 2023/06/23 13:07 [pubmed]
PHST- 2023/06/23 10:25 [entrez]
PHST- 2023/06/16 00:00 [pmc-release]
AID - 2286 [pii]
PST - epublish
SO  - AMIA Jt Summits Transl Sci Proc. 2023 Jun 16;2023:138-147. eCollection 2023.

PMID- 39281744
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250203
DP  - 2024 Sep 6
TI  - Large language models outperform traditional natural language processing methods 
      in extracting patient-reported outcomes in IBD.
LID - 2024.09.05.24313139 [pii]
LID - 10.1101/2024.09.05.24313139 [doi]
AB  - BACKGROUND AND AIMS: Patient-reported outcomes (PROs) are vital in assessing 
      disease activity and treatment outcomes in inflammatory bowel disease (IBD). 
      However, manual extraction of these PROs from the free-text of clinical notes is 
      burdensome. We aimed to improve data curation from free-text information in the 
      electronic health record, making it more available for research and quality 
      improvement. This study aimed to compare traditional natural language processing 
      (tNLP) and large language models (LLMs) in extracting three IBD PROs (abdominal 
      pain, diarrhea, fecal blood) from clinical notes across two institutions. 
      METHODS: Clinic notes were annotated for each PRO using preset protocols. Models 
      were developed and internally tested at the University of California San 
      Francisco (UCSF), and then externally validated at Stanford University. We 
      compared tNLP and LLM-based models on accuracy, sensitivity, specificity, 
      positive and negative predictive value. Additionally, we conducted fairness and 
      error assessments. RESULTS: Inter-rater reliability between annotators was >90%. 
      On the UCSF test set (n=50), the top-performing tNLP models showcased accuracies 
      of 92% (abdominal pain), 82% (diarrhea) and 80% (fecal blood), comparable to 
      GPT-4, which was 96%, 88%, and 90% accurate, respectively. On external validation 
      at Stanford (n=250), tNLP models failed to generalize (61-62% accuracy) while 
      GPT-4 maintained accuracies >90%. PaLM-2 and GPT-4 showed similar performance. No 
      biases were detected based on demographics or diagnosis. CONCLUSIONS: LLMs are 
      accurate and generalizable methods for extracting PROs. They maintain excellent 
      accuracy across institutions, despite heterogeneity in note templates and 
      authors. Widespread adoption of such tools has the potential to enhance IBD 
      research and patient care.
FAU - Patel, Perseus V
AU  - Patel PV
AUID- ORCID: 0000-0002-8287-3424
AD  - Department of Pediatrics, University of California San Francisco, San Francisco, 
      CA.
AD  - Division of Pediatric Gastroenterology, Stanford University School of Medicine, 
      Palo Alto, CA.
FAU - Davis, Conner
AU  - Davis C
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, CA.
FAU - Ralbovsky, Amariel
AU  - Ralbovsky A
AD  - Department of Pediatrics, University of California San Francisco, San Francisco, 
      CA.
FAU - Tinoco, Daniel
AU  - Tinoco D
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, CA.
FAU - Williams, Christopher Y K
AU  - Williams CYK
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, CA.
FAU - Slatter, Shadera
AU  - Slatter S
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, CA.
FAU - Naderalvojoud, Behzad
AU  - Naderalvojoud B
AD  - Stanford Center for Biomedical Informatics Research, Department of Medicine, 
      StanfordUniversity, Palo Alto, CA.
FAU - Rosen, Michael J
AU  - Rosen MJ
AD  - Division of Pediatric Gastroenterology, Stanford University School of Medicine, 
      Palo Alto, CA.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AD  - Stanford Center for Biomedical Informatics Research, Department of Medicine, 
      StanfordUniversity, Palo Alto, CA.
FAU - Rudrapatna, Vivek
AU  - Rudrapatna V
AUID- ORCID: 0000-0003-1789-3004
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, CA.
AD  - Division of Gastroenterology, Department of Medicine, University of California 
      San Francisco,San Francisco, CA.
LA  - eng
GR  - K99 LM014099/LM/NLM NIH HHS/United States
GR  - T32 DK007762/DK/NIDDK NIH HHS/United States
GR  - UL1 TR001872/TR/NCATS NIH HHS/United States
GR  - UL1 TR001881/TR/NCATS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240906
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - Gastro Hep Adv. 2024 Oct 10;4(2):100563. doi: 10.1016/j.gastha.2024.10.003. PMID: 
      39877865
PMC - PMC11398594
OTO - NOTNLM
OT  - GPT-4
OT  - PaLM-2
OT  - clinical data science
OT  - machine learning
COIS- VAR receives research support from Alnylam, Takeda, Merck,Genentech, Blueprint 
      Medicines, Stryker, Mitsubishi Tanabe, and Janssen. He also is a shareholder of 
      ZebraMD. MJR has served on an advisory board for Pfizer. THB reports consulting 
      fees from Grai-Matter, Paul Hartmann AG, and Verantos, Inc outside the submitted 
      work and she is a board member of Athelo Health. This study was funded in part by 
      Microsoft, which is an investor in OpenAI, the developer of the GPT-4 model. 
      There are no conflicts of interest for any of the other authors.
EDAT- 2024/09/17 10:46
MHDA- 2024/09/17 10:47
PMCR- 2024/09/13
CRDT- 2024/09/16 06:17
PHST- 2024/09/17 10:46 [pubmed]
PHST- 2024/09/17 10:47 [medline]
PHST- 2024/09/16 06:17 [entrez]
PHST- 2024/09/13 00:00 [pmc-release]
AID - 2024.09.05.24313139 [pii]
AID - 10.1101/2024.09.05.24313139 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Sep 6:2024.09.05.24313139. doi: 
      10.1101/2024.09.05.24313139.

PMID- 40053817
OWN - NLM
STAT- MEDLINE
DCOM- 20250307
LR  - 20250323
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Mar 5
TI  - Competency of Large Language Models in Evaluating Appropriate Responses to 
      Suicidal Ideation: Comparative Study.
PG  - e67891
LID - 10.2196/67891 [doi]
LID - e67891
AB  - BACKGROUND: With suicide rates in the United States at an all-time high, 
      individuals experiencing suicidal ideation are increasingly turning to large 
      language models (LLMs) for guidance and support. OBJECTIVE: The objective of this 
      study was to assess the competency of 3 widely used LLMs to distinguish 
      appropriate versus inappropriate responses when engaging individuals who exhibit 
      suicidal ideation. METHODS: This observational, cross-sectional study evaluated 
      responses to the revised Suicidal Ideation Response Inventory (SIRI-2) generated 
      by ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro. Data collection and 
      analyses were conducted in July 2024. A common training module for mental health 
      professionals, SIRI-2 provides 24 hypothetical scenarios in which a patient 
      exhibits depressive symptoms and suicidal ideation, followed by two clinician 
      responses. Clinician responses were scored from -3 (highly inappropriate) to +3 
      (highly appropriate). All 3 LLMs were provided with a standardized set of 
      instructions to rate clinician responses. We compared LLM responses to those of 
      expert suicidologists, conducting linear regression analyses and converting LLM 
      responses to z scores to identify outliers (z score>1.96 or <-1.96; P<0.05). 
      Furthermore, we compared final SIRI-2 scores to those produced by health 
      professionals in prior studies. RESULTS: All 3 LLMs rated responses as more 
      appropriate than ratings provided by expert suicidologists. The item-level mean 
      difference was 0.86 for ChatGPT (95% CI 0.61-1.12; P<.001), 0.61 for Claude (95% 
      CI 0.41-0.81; P<.001), and 0.73 for Gemini (95% CI 0.35-1.11; P<.001). In terms 
      of z scores, 19% (9 of 48) of ChatGPT responses were outliers when compared to 
      expert suicidologists. Similarly, 11% (5 of 48) of Claude responses were outliers 
      compared to expert suicidologists. Additionally, 36% (17 of 48) of Gemini 
      responses were outliers compared to expert suicidologists. ChatGPT produced a 
      final SIRI-2 score of 45.7, roughly equivalent to master's level counselors in 
      prior studies. Claude produced an SIRI-2 score of 36.7, exceeding prior 
      performance of mental health professionals after suicide intervention skills 
      training. Gemini produced a final SIRI-2 score of 54.5, equivalent to untrained 
      K-12 school staff. CONCLUSIONS: Current versions of 3 major LLMs demonstrated an 
      upward bias in their evaluations of appropriate responses to suicidal ideation; 
      however, 2 of the 3 models performed equivalent to or exceeded the performance of 
      mental health professionals.
CI  - ©Ryan K McBain, Jonathan H Cantor, Li Ang Zhang, Olesya Baker, Fang Zhang, Alyssa 
      Halbisen, Aaron Kofner, Joshua Breslau, Bradley Stein, Ateev Mehrotra, Hao Yu. 
      Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 05.03.2025.
FAU - McBain, Ryan K
AU  - McBain RK
AUID- ORCID: 0000-0003-0073-0348
AD  - RAND, Arlington, VA, United States.
AD  - Brigham and Women's Hospital, Boston, MA, MA, United States.
AD  - Harvard Medical School, Boston, MA, United States.
FAU - Cantor, Jonathan H
AU  - Cantor JH
AUID- ORCID: 0000-0003-4468-833X
AD  - RAND, Santa Monica, CA, United States.
FAU - Zhang, Li Ang
AU  - Zhang LA
AUID- ORCID: 0000-0001-9468-2513
AD  - RAND, Santa Monica, CA, United States.
FAU - Baker, Olesya
AU  - Baker O
AUID- ORCID: 0000-0001-9125-2761
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Harvard Pilgrim Health Care Institute, Boston, MA, United States.
FAU - Zhang, Fang
AU  - Zhang F
AUID- ORCID: 0000-0002-8282-8738
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Harvard Pilgrim Health Care Institute, Boston, MA, United States.
FAU - Halbisen, Alyssa
AU  - Halbisen A
AUID- ORCID: 0009-0000-0482-729X
AD  - Harvard Pilgrim Health Care Institute, Boston, MA, United States.
FAU - Kofner, Aaron
AU  - Kofner A
AUID- ORCID: 0000-0001-6980-1218
AD  - RAND, Arlington, VA, United States.
FAU - Breslau, Joshua
AU  - Breslau J
AUID- ORCID: 0000-0002-1194-4643
AD  - RAND, Pittsburgh, PA, United States.
FAU - Stein, Bradley
AU  - Stein B
AUID- ORCID: 0000-0003-1544-458X
AD  - RAND, Pittsburgh, PA, United States.
FAU - Mehrotra, Ateev
AU  - Mehrotra A
AUID- ORCID: 0000-0003-2223-1582
AD  - Brown University School of Public Health, Providence, RI, United States.
FAU - Yu, Hao
AU  - Yu H
AUID- ORCID: 0000-0001-6169-4243
AD  - Harvard Medical School, Boston, MA, United States.
AD  - Harvard Pilgrim Health Care Institute, Boston, MA, United States.
LA  - eng
GR  - R01 MH132551/MH/NIMH NIH HHS/United States
PT  - Comparative Study
PT  - Journal Article
PT  - Observational Study
DEP - 20250305
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Suicidal Ideation
MH  - Cross-Sectional Studies
MH  - Female
MH  - Male
MH  - Adult
MH  - Language
MH  - United States
PMC - PMC11928068
OTO - NOTNLM
OT  - ChatGPT
OT  - Suicidal Ideation Response Inventory
OT  - artificial intelligence
OT  - chatbot
OT  - depression
OT  - digital health
OT  - large language model
OT  - mental health
OT  - suicide
OT  - suicidologist
COIS- Conflicts of Interest: None declared.
EDAT- 2025/03/07 18:21
MHDA- 2025/03/07 18:22
PMCR- 2025/03/05
CRDT- 2025/03/07 14:47
PHST- 2024/10/23 00:00 [received]
PHST- 2025/01/22 00:00 [accepted]
PHST- 2024/12/07 00:00 [revised]
PHST- 2025/03/07 18:22 [medline]
PHST- 2025/03/07 18:21 [pubmed]
PHST- 2025/03/07 14:47 [entrez]
PHST- 2025/03/05 00:00 [pmc-release]
AID - v27i1e67891 [pii]
AID - 10.2196/67891 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Mar 5;27:e67891. doi: 10.2196/67891.

PMID- 40093243
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250321
DP  - 2025 Mar 5
TI  - LLM-Guided Pain Management: Examining Socio-Demographic Gaps in Cancer vs 
      non-Cancer cases.
LID - 2025.03.04.25323396 [pii]
LID - 10.1101/2025.03.04.25323396 [doi]
AB  - Large language models (LLMs) offer potential benefits in clinical care. However, 
      concerns remain regarding socio-demographic biases embedded in their outputs. 
      Opioid prescribing is one domain in which these biases can have serious 
      implications, especially given the ongoing opioid epidemic and the need to 
      balance effective pain management with addiction risk. We tested ten LLMs-both 
      open-access and closed-source-on 1,000 acute-pain vignettes. Half of the 
      vignettes were labeled as non-cancer and half as cancer. Each vignette was 
      presented in 34 socio-demographic variations, including a control group without 
      demographic identifiers. We analyzed the models' recommendations on opioids, 
      anxiety treatment, perceived psychological stress, risk scores, and monitoring 
      recommendations. Overall, yielding 3.4 million model-generated responses. Using 
      logistic and linear mixed-effects models, we measured how these outputs varied by 
      demographic group and whether a cancer diagnosis intensified or reduced observed 
      disparities. Across both cancer and non-cancer cases, historically marginalized 
      groups-especially cases labeled as individuals who are unhoused, Black, or 
      identify as LGBTQIA+-often received more or stronger opioid recommendations, 
      sometimes exceeding 90% in cancer settings, despite being labeled as high risk by 
      the same models. Meanwhile, low-income or unemployed groups were assigned 
      elevated risk scores yet fewer opioid recommendations, hinting at inconsistent 
      rationales. Disparities in anxiety treatment and perceived psychological stress 
      similarly clustered within marginalized populations, even when clinical details 
      were identical. These patterns diverged from standard guidelines and point to 
      model-driven bias rather than acceptable clinical variation. Our findings 
      underscore the need for rigorous bias evaluation and the integration of 
      guideline-based checks in LLMs to ensure equitable and evidence-based pain care.
FAU - Omar, Mahmud
AU  - Omar M
AUID- ORCID: 0009-0001-0438-0827
AD  - The Windreich Department of Artificial Intelligence and Human Health, Mount Sinai 
      Medical Center, NY, USA.
AD  - The Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Soffer, Shelly
AU  - Soffer S
AUID- ORCID: 0000-0002-7853-2029
AD  - Institute of Hematology, Davidoff Cancer Center, Rabin Medical Center; 
      Petah-Tikva, Israel.
FAU - Agbareia, Reem
AU  - Agbareia R
AUID- ORCID: 0009-0000-8030-9232
AD  - Ophthalmology Department, Hadassah Medical Center, Jerusalem, Israel.
FAU - Bragazzi, Nicola Luigi
AU  - Bragazzi NL
AUID- ORCID: 0000-0001-8409-868X
AD  - Human Nutrition Unit (HNU), Department of Food and Drugs, Medical School, Parma, 
      Italy.
FAU - Glicksberg, Benjamin S
AU  - Glicksberg BS
AUID- ORCID: 0000-0003-4515-8090
AD  - The Windreich Department of Artificial Intelligence and Human Health, Mount Sinai 
      Medical Center, NY, USA.
AD  - The Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Hurd, Yasmin L
AU  - Hurd YL
AD  - Department of Psychiatry, Icahn School of Medicine at Mount Sinai, Addiction 
      Institute of Mount Sinai, 1399 Park Ave, Room 3-330, New York, NY, 10029, USA.
FAU - Apakama, Donald U
AU  - Apakama DU
AUID- ORCID: 0000-0001-6217-1620
AD  - The Windreich Department of Artificial Intelligence and Human Health, Mount Sinai 
      Medical Center, NY, USA.
AD  - The Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
AD  - Institute for Health Equity Research, Icahn School of Medicine at Mount Sinai, 
      New York, NY, USA.
FAU - Charney, Alexander W
AU  - Charney AW
AUID- ORCID: 0000-0001-8135-6858
AD  - The Windreich Department of Artificial Intelligence and Human Health, Mount Sinai 
      Medical Center, NY, USA.
AD  - The Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Reich, David L
AU  - Reich DL
AD  - Department of Anesthesiology, Perioperative, and Pain Medicine, Icahn School of 
      Medicine at Mount Sinai, New York, NY.
FAU - Nadkarni, Girish N
AU  - Nadkarni GN
AUID- ORCID: 0000-0001-6319-4314
AD  - The Windreich Department of Artificial Intelligence and Human Health, Mount Sinai 
      Medical Center, NY, USA.
AD  - The Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Klang, Eyal
AU  - Klang E
AUID- ORCID: 0000-0002-4567-3108
AD  - The Windreich Department of Artificial Intelligence and Human Health, Mount Sinai 
      Medical Center, NY, USA.
AD  - The Division of Data-Driven and Digital Medicine (D3M), Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
LA  - eng
GR  - S10 OD026880/OD/NIH HHS/United States
GR  - S10 OD030463/OD/NIH HHS/United States
GR  - UL1 TR004419/TR/NCATS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20250305
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11908302
COIS- Competing interest – None declared for all authors.
EDAT- 2025/03/17 15:20
MHDA- 2025/03/17 15:21
PMCR- 2025/03/14
CRDT- 2025/03/17 06:30
PHST- 2025/03/17 15:20 [pubmed]
PHST- 2025/03/17 15:21 [medline]
PHST- 2025/03/17 06:30 [entrez]
PHST- 2025/03/14 00:00 [pmc-release]
AID - 2025.03.04.25323396 [pii]
AID - 10.1101/2025.03.04.25323396 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2025 Mar 5:2025.03.04.25323396. doi: 
      10.1101/2025.03.04.25323396.

PMID- 39801619
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250304
IS  - 2331-8422 (Electronic)
IS  - 2331-8422 (Linking)
DP  - 2024 Nov 20
TI  - Demystifying Large Language Models for Medicine: A Primer.
LID - arXiv:2410.18856v3
AB  - Large language models (LLMs) represent a transformative class of AI tools capable 
      of revolutionizing various aspects of healthcare by generating human-like 
      responses across diverse contexts and adapting to novel tasks following human 
      instructions. Their potential application spans a broad range of medical tasks, 
      such as clinical documentation, matching patients to clinical trials, and 
      answering medical questions. In this primer paper, we propose an actionable 
      guideline to help healthcare professionals more efficiently utilize LLMs in their 
      work, along with a set of best practices. This approach consists of several main 
      phases, including formulating the task, choosing LLMs, prompt engineering, 
      fine-tuning, and deployment. We start with the discussion of critical 
      considerations in identifying healthcare tasks that align with the core 
      capabilities of LLMs and selecting models based on the selected task and data, 
      performance requirements, and model interface. We then review the strategies, 
      such as prompt engineering and fine-tuning, to adapt standard LLMs to specialized 
      medical tasks. Deployment considerations, including regulatory compliance, 
      ethical guidelines, and continuous monitoring for fairness and bias, are also 
      discussed. By providing a structured step-by-step methodology, this tutorial aims 
      to equip healthcare professionals with the tools necessary to effectively 
      integrate LLMs into clinical practice, ensuring that these powerful technologies 
      are applied in a safe, reliable, and impactful manner.
FAU - Jin, Qiao
AU  - Jin Q
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Wan, Nicholas
AU  - Wan N
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Leaman, Robert
AU  - Leaman R
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Tian, Shubo
AU  - Tian S
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Wang, Zhizheng
AU  - Wang Z
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Yang, Yifan
AU  - Yang Y
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Wang, Zifeng
AU  - Wang Z
AD  - Department of Computer Science, University of Illinois Urbana-Champaign, 
      Champaign, IL, USA.
FAU - Xiong, Guangzhi
AU  - Xiong G
AD  - Department of Computer Science, University of Virginia, Charlottesville, VA, USA.
FAU - Lai, Po-Ting
AU  - Lai PT
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Zhu, Qingqing
AU  - Zhu Q
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Hou, Benjamin
AU  - Hou B
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Sarfo-Gyamfi, Maame
AU  - Sarfo-Gyamfi M
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
FAU - Zhang, Gongbo
AU  - Zhang G
AD  - Department of Biomedical Informatics, Columbia University, New York, NY, USA.
FAU - Gilson, Aidan
AU  - Gilson A
AD  - School of Medicine, Yale University, New Haven, CT, USA.
FAU - Bhasuran, Balu
AU  - Bhasuran B
AD  - School of Information, Florida State University, Tallahassee, FL, USA.
FAU - He, Zhe
AU  - He Z
AD  - School of Information, Florida State University, Tallahassee, FL, USA.
FAU - Zhang, Aidong
AU  - Zhang A
AD  - Department of Computer Science, University of Virginia, Charlottesville, VA, USA.
FAU - Sun, Jimeng
AU  - Sun J
AD  - Department of Computer Science, University of Illinois Urbana-Champaign, 
      Champaign, IL, USA.
FAU - Weng, Chunhua
AU  - Weng C
AD  - Department of Biomedical Informatics, Columbia University, New York, NY, USA.
FAU - Summers, Ronald M
AU  - Summers RM
AD  - Department of Radiology and Imaging Sciences, NIH Clinical Center, Bethesda, MD, 
      USA.
FAU - Chen, Qingyu
AU  - Chen Q
AD  - School of Medicine, Yale University, New Haven, CT, USA.
FAU - Peng, Yifan
AU  - Peng Y
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      USA.
FAU - Lu, Zhiyong
AU  - Lu Z
AD  - National Library of Medicine (NLM), National Institutes of Health (NIH), 
      Bethesda, MD, USA.
LA  - eng
PT  - Journal Article
PT  - Preprint
DEP - 20241120
PL  - United States
TA  - ArXiv
JT  - ArXiv
JID - 101759493
PMC - PMC11722506
COIS- Disclosures The recommendations in this article are those of the authors and do 
      not necessarily represent the official position of the National Institutes of 
      Health.
EDAT- 2025/01/13 06:16
MHDA- 2025/01/13 06:17
PMCR- 2024/11/20
CRDT- 2025/01/13 05:16
PHST- 2025/01/13 06:16 [pubmed]
PHST- 2025/01/13 06:17 [medline]
PHST- 2025/01/13 05:16 [entrez]
PHST- 2024/11/20 00:00 [pmc-release]
AID - 2410.18856 [pii]
PST - epublish
SO  - ArXiv [Preprint]. 2024 Nov 20:arXiv:2410.18856v3.

PMID- 39677375
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 1175-8899 (Electronic)
IS  - 0303-6758 (Print)
IS  - 0303-6758 (Linking)
VI  - 55
IP  - 2
DP  - 2025
TI  - Debiasing large language models: research opportunities.
PG  - 372-395
LID - 10.1080/03036758.2024.2398567 [doi]
AB  - Large language models (LLMs) are powerful decision-making tools widely adopted in 
      healthcare, finance, and transportation. Embracing the opportunities and 
      innovations of LLMs is inevitable. However, LLMs inherit stereotypes, 
      misrepresentations, discrimination, and societies' biases from various 
      sources-including training data, algorithm design, and user 
      interactions-resulting in concerns about equality, diversity, and fairness. The 
      bias problem has triggered increased research towards defining, detecting and 
      quantifying bias and developing debiasing techniques. The predominant focus in 
      tackling the bias problem is skewed towards resource-rich regions such as the US 
      and Europe, resulting in a scarcity of research in other societies. As a small 
      country with a unique history, culture and social composition, there is an 
      opportunity for Aotearoa New Zealand's (NZ) research community to address this 
      inadequacy. This paper presents an experimental evaluation of existing bias 
      metrics and debiasing techniques in the NZ context. Research gaps derived from 
      the study and a literature review are outlined, current and ongoing research in 
      this space are discussed, and the suggested scope of research opportunities for 
      NZ are presented.
CI  - © 2024 The Author(s). Published by Informa UK Limited, trading as Taylor & 
      Francis Group.
FAU - Yogarajan, Vithya
AU  - Yogarajan V
AUID- ORCID: 0000-0002-6054-9543
AD  - School of Computer Science, University of Auckland, Auckland, New Zealand.
FAU - Dobbie, Gillian
AU  - Dobbie G
AUID- ORCID: 0000-0001-7245-0367
AD  - School of Computer Science, University of Auckland, Auckland, New Zealand.
FAU - Keegan, Te Taka
AU  - Keegan TT
AUID- ORCID: 0000-0002-8628-4993
AD  - School of Computing and Mathematical Sciences, University of Waikato, Hamilton, 
      New Zealand.
LA  - eng
PT  - Journal Article
DEP - 20240916
PL  - England
TA  - J R Soc N Z
JT  - Journal of the Royal Society of New Zealand
JID - 101086969
PMC - PMC11639098
OTO - NOTNLM
OT  - Large language models
OT  - New Zealand
OT  - bias
OT  - generative AI
OT  - responsible AI
COIS- No potential conflict of interest was reported by the author(s).
EDAT- 2024/12/16 12:28
MHDA- 2024/12/16 12:29
PMCR- 2024/09/16
CRDT- 2024/12/16 06:29
PHST- 2024/12/16 12:29 [medline]
PHST- 2024/12/16 12:28 [pubmed]
PHST- 2024/12/16 06:29 [entrez]
PHST- 2024/09/16 00:00 [pmc-release]
AID - 2398567 [pii]
AID - 10.1080/03036758.2024.2398567 [doi]
PST - epublish
SO  - J R Soc N Z. 2024 Sep 16;55(2):372-395. doi: 10.1080/03036758.2024.2398567. 
      eCollection 2025.

PMID- 36865144
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230303
DP  - 2023 Feb 23
TI  - Assessing the Value of ChatGPT for Clinical Decision Support Optimization.
LID - 2023.02.21.23286254 [pii]
LID - 10.1101/2023.02.21.23286254 [doi]
AB  - OBJECTIVE: To determine if ChatGPT can generate useful suggestions for improving 
      clinical decision support (CDS) logic and to assess noninferiority compared to 
      human-generated suggestions. METHODS: We supplied summaries of CDS logic to 
      ChatGPT, an artificial intelligence (AI) tool for question answering that uses a 
      large language model, and asked it to generate suggestions. We asked human 
      clinician reviewers to review the AI-generated suggestions as well as 
      human-generated suggestions for improving the same CDS alerts, and rate the 
      suggestions for their usefulness, acceptance, relevance, understanding, workflow, 
      bias, inversion, and redundancy. RESULTS: Five clinicians analyzed 36 
      AI-generated suggestions and 29 human-generated suggestions for 7 alerts. Of the 
      20 suggestions that scored highest in the survey, 9 were generated by ChatGPT. 
      The suggestions generated by AI were found to offer unique perspectives and were 
      evaluated as highly understandable and relevant, with moderate usefulness, low 
      acceptance, bias, inversion, redundancy. CONCLUSION: AI-generated suggestions 
      could be an important complementary part of optimizing CDS alerts, can identify 
      potential improvements to alert logic and support their implementation, and may 
      even be able to assist experts in formulating their own suggestions for CDS 
      improvement. ChatGPT shows great potential for using large language models and 
      reinforcement learning from human feedback to improve CDS alert logic and 
      potentially other medical areas involving complex, clinical logic, a key step in 
      the development of an advanced learning health system.
FAU - Liu, Siru
AU  - Liu S
FAU - Wright, Aileen P
AU  - Wright AP
FAU - Patterson, Barron L
AU  - Patterson BL
FAU - Wanderer, Jonathan P
AU  - Wanderer JP
FAU - Turer, Robert W
AU  - Turer RW
FAU - Nelson, Scott D
AU  - Nelson SD
FAU - McCoy, Allison B
AU  - McCoy AB
FAU - Sittig, Dean F
AU  - Sittig DF
FAU - Wright, Adam
AU  - Wright A
LA  - eng
PT  - Journal Article
PT  - Preprint
DEP - 20230223
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC9980251
EDAT- 2023/03/04 06:00
MHDA- 2023/03/04 06:01
PMCR- 2023/03/02
CRDT- 2023/03/03 02:28
PHST- 2023/03/03 02:28 [entrez]
PHST- 2023/03/04 06:00 [pubmed]
PHST- 2023/03/04 06:01 [medline]
PHST- 2023/03/02 00:00 [pmc-release]
AID - 2023.02.21.23286254 [pii]
AID - 10.1101/2023.02.21.23286254 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Feb 23:2023.02.21.23286254. doi: 
      10.1101/2023.02.21.23286254.

PMID- 38239824
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240210
IS  - 2575-2626 (Print)
IS  - 2575-2634 (Electronic)
IS  - 2575-2626 (Linking)
VI  - 2023
DP  - 2023 Jun
TI  - Benchmarking Transformer-Based Models for Identifying Social Determinants of 
      Health in Clinical Notes.
PG  - 570-574
LID - 10.1109/ichi57859.2023.00102 [doi]
AB  - Electronic health records (EHR) have been widely used in building machine 
      learning models for health outcomes prediction. However, many EHR-based models 
      are inherently biased due to lack of risk factors on social determinants of 
      health (SDoH), which are responsible for up to 40% preventive deaths. As SDoH 
      information is often captured in clinical notes, recent efforts have been made to 
      extract such information from notes with natural language processing and append 
      it to other structured data. In this work, we benchmark 7 pre-trained 
      transformer-based models, including BERT, ALBERT, BioBERT, BioClinicalBERT, 
      RoBERTa, ELECTRA, and RoBERTa-MIMIC-Trial, for recognizing SDoH terms using a 
      previously annotated corpus of MIMIC-III clinical notes. Our study shows that 
      BioClinicalBERT model performs best on F-1 scores (0.911, 0.923) under both 
      strict and relaxed criteria. This work shows the promise of using 
      transformer-based models for recognizing SDoH information from clinical notes.
FAU - Wang, Xiaoyu
AU  - Wang X
AD  - Department of Statistics Florida State University Tallahassee, FL, USA.
FAU - Gupta, Dipankar
AU  - Gupta D
AD  - College of Medicine University of Florida Gainesville, FL, Florida.
FAU - Killian, Michael
AU  - Killian M
AD  - College of Social Work Florida State University Tallahassee, FL, USA.
FAU - He, Zhe
AU  - He Z
AD  - School of Information Florida State University Tallahassee, FL, USA.
LA  - eng
GR  - R21 LM013911/LM/NLM NIH HHS/United States
GR  - UL1 TR001427/TR/NCATS NIH HHS/United States
PT  - Journal Article
DEP - 20231211
PL  - United States
TA  - Proc (IEEE Int Conf Healthc Inform)
JT  - Proceedings. IEEE International Conference on Healthcare Informatics
JID - 101683411
PMC - PMC10795706
MID - NIHMS1957582
OTO - NOTNLM
OT  - Named entity recognition
OT  - Natural language processing
OT  - Social determinants of health
EDAT- 2024/01/19 06:42
MHDA- 2024/01/19 06:43
PMCR- 2024/01/18
CRDT- 2024/01/19 03:47
PHST- 2024/01/19 06:43 [medline]
PHST- 2024/01/19 06:42 [pubmed]
PHST- 2024/01/19 03:47 [entrez]
PHST- 2024/01/18 00:00 [pmc-release]
AID - 10.1109/ichi57859.2023.00102 [doi]
PST - ppublish
SO  - Proc (IEEE Int Conf Healthc Inform). 2023 Jun;2023:570-574. doi: 
      10.1109/ichi57859.2023.00102. Epub 2023 Dec 11.

PMID- 39601443
OWN - NLM
STAT- MEDLINE
DCOM- 20250127
LR  - 20250130
IS  - 1547-5069 (Electronic)
IS  - 1527-6546 (Print)
IS  - 1527-6546 (Linking)
VI  - 57
IP  - 1
DP  - 2025 Jan
TI  - Applying natural language processing to understand symptoms among older adult 
      home healthcare patients with urinary incontinence.
PG  - 152-164
LID - 10.1111/jnu.13038 [doi]
AB  - INTRODUCTION: Little is known about the range and frequency of symptoms among 
      older adult home healthcare patients with urinary incontinence, as this 
      information is predominantly contained in clinical notes. Natural language 
      processing can uncover symptom information among older adults with urinary 
      incontinence to promote holistic, equitable care. DESIGN: We conducted a 
      secondary analysis of cross-sectional data collected between January 1, 2015, and 
      December 31, 2017, from the largest HHC agency in the Northeastern United States. 
      We aimed to develop and test a natural language processing algorithm to extract 
      symptom information from clinical notes for older adults with urinary 
      incontinence and analyze differences in symptom documentation by race or 
      ethnicity. METHODS: Symptoms were identified through expert clinician-driven 
      Delphi survey rounds. We developed a natural language processing algorithm for 
      symptom identification in clinical notes, examined symptom documentation 
      frequencies, and analyzed differences in symptom documentation by race or 
      ethnicity using chi-squared tests and logistic regression models. RESULTS: In 
      total, 39,179 home healthcare episodes containing 1,098,419 clinical notes for 
      29,981 distinct patients were included. Nearly 40% of the sample represented 
      racially or ethnically minoritized groups (i.e., 18% Black, 14% Hispanic, 7% 
      Asian/Pacific Islander, 0.3% multi-racial, and 0.2% Native American). Based on 
      expert clinician-driven Delphi survey rounds, the following symptoms were 
      identified: anxiety, dizziness, constipation, syncope, tachycardia, urinary 
      frequency/urgency, urinary hesitancy/retention, and vision impairment/blurred 
      vision. The natural language processing algorithm achieved excellent performance 
      (average precision of 0.92). Approximately 29% of home healthcare episodes had 
      symptom information documented. Compared to home healthcare episodes for White 
      patients, home healthcare episodes for Asian/Pacific Islander (odds ratio = 0.74, 
      95% confidence interval [0.67-0.80], p < 0.001), Black (odds ratio = 0.69, 95% 
      confidence interval [0.64-0.73], p < 0.001), and Hispanic (odds ratio = 0.91, 95% 
      confidence interval [0.85-0.97], p < 0.01) patients were less likely to have any 
      symptoms documented in clinical notes. CONCLUSION: We found multidimensional 
      symptoms and differences in symptom documentation among a diverse cohort of older 
      adults with urinary incontinence, underscoring the need for comprehensive 
      assessments by clinicians. Future research should apply natural language 
      processing to other data sources and investigate symptom clusters to inform 
      holistic care strategies for diverse populations. CLINICAL RELEVANCE: Knowledge 
      of symptoms of older adult home healthcare patients with urinary incontinence can 
      facilitate comprehensive assessments, health equity, and improved outcomes.
CI  - © 2024 Sigma Theta Tau International.
FAU - Scharp, Danielle
AU  - Scharp D
AUID- ORCID: 0000-0002-3265-6667
AD  - Columbia University School of Nursing, New York, New York, USA.
FAU - Song, Jiyoun
AU  - Song J
AUID- ORCID: 0000-0003-0362-0670
AD  - Department of Biobehavioral Sciences, University of Pennsylvania School of 
      Nursing, Philadelphia, Pennsylvania, USA.
FAU - Hobensack, Mollie
AU  - Hobensack M
AD  - Department of Geriatrics and Palliative Care, Icahn School of Medicine at Mount 
      Sinai, New York, New York, USA.
FAU - Palmer, Mary Happel
AU  - Palmer MH
AD  - University of North Carolina School of Nursing, Chapel Hill, North Carolina, USA.
FAU - Barcelona, Veronica
AU  - Barcelona V
AUID- ORCID: 0000-0003-3070-1716
AD  - Columbia University School of Nursing, New York, New York, USA.
FAU - Topaz, Maxim
AU  - Topaz M
AD  - Columbia University School of Nursing, New York, New York, USA.
LA  - eng
GR  - T32NR007969/NR/NINR NIH HHS/United States
GR  - 1K99HL169940/HL/NHLBI NIH HHS/United States
GR  - K99 HL169940/HL/NHLBI NIH HHS/United States
GR  - T32 NR007969/NR/NINR NIH HHS/United States
GR  - R01HS027742/Agency for Healthcare Research and Quality/
GR  - R01 HS027742/HS/AHRQ HHS/United States
PT  - Journal Article
DEP - 20241127
PL  - United States
TA  - J Nurs Scholarsh
JT  - Journal of nursing scholarship : an official publication of Sigma Theta Tau 
      International Honor Society of Nursing
JID - 100911591
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Aged
MH  - Female
MH  - Cross-Sectional Studies
MH  - Male
MH  - *Urinary Incontinence/psychology
MH  - *Home Care Services/statistics & numerical data
MH  - Aged, 80 and over
MH  - Delphi Technique
MH  - New England
PMC - PMC11772115
MID - NIHMS2037787
OTO - NOTNLM
OT  - healthcare disparities
OT  - home healthcare
OT  - natural language processing
OT  - nursing informatics
OT  - older adults
OT  - symptom burden
OT  - urinary incontinence
COIS- Conflict of Interest Statement: The authors have no conflicts of interest to 
      disclose.
EDAT- 2024/11/27 12:35
MHDA- 2025/01/27 12:25
PMCR- 2026/01/01
CRDT- 2024/11/27 08:33
PHST- 2024/08/22 00:00 [revised]
PHST- 2024/01/03 00:00 [received]
PHST- 2024/11/05 00:00 [accepted]
PHST- 2026/01/01 00:00 [pmc-release]
PHST- 2025/01/27 12:25 [medline]
PHST- 2024/11/27 12:35 [pubmed]
PHST- 2024/11/27 08:33 [entrez]
AID - 10.1111/jnu.13038 [doi]
PST - ppublish
SO  - J Nurs Scholarsh. 2025 Jan;57(1):152-164. doi: 10.1111/jnu.13038. Epub 2024 Nov 
      27.

PMID- 38100393
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231217
IS  - 2767-3170 (Electronic)
IS  - 2767-3170 (Linking)
VI  - 2
IP  - 12
DP  - 2023 Dec
TI  - GPT-4 can pass the Korean National Licensing Examination for Korean Medicine 
      Doctors.
PG  - e0000416
LID - 10.1371/journal.pdig.0000416 [doi]
LID - e0000416
AB  - Traditional Korean medicine (TKM) emphasizes individualized diagnosis and 
      treatment. This uniqueness makes AI modeling difficult due to limited data and 
      implicit processes. Large language models (LLMs) have demonstrated impressive 
      medical inference, even without advanced training in medical texts. This study 
      assessed the capabilities of GPT-4 in TKM, using the Korean National Licensing 
      Examination for Korean Medicine Doctors (K-NLEKMD) as a benchmark. The K-NLEKMD, 
      administered by a national organization, encompasses 12 major subjects in TKM. 
      GPT-4 answered 340 questions from the 2022 K-NLEKMD. We optimized prompts with 
      Chinese-term annotation, English translation for questions and instruction, 
      exam-optimized instruction, and self-consistency. GPT-4 with optimized prompts 
      achieved 66.18% accuracy, surpassing both the examination's average pass mark of 
      60% and the 40% minimum for each subject. The gradual introduction of 
      language-related prompts and prompting techniques enhanced the accuracy from 
      51.82% to its maximum accuracy. GPT-4 showed low accuracy in subjects including 
      public health & medicine-related law, internal medicine (2), and acupuncture 
      medicine which are highly localized in Korea and TKM. The model's accuracy was 
      lower for questions requiring TKM-specialized knowledge than those that did not. 
      It exhibited higher accuracy in diagnosis-based and recall-based questions than 
      in intervention-based questions. A significant positive correlation was observed 
      between the consistency and accuracy of GPT-4's responses. This study unveils 
      both the potential and challenges of applying LLMs to TKM. These findings 
      underline the potential of LLMs like GPT-4 in culturally adapted medicine, 
      especially TKM, for tasks such as clinical assistance, medical education, and 
      research. But they also point towards the necessity for the development of 
      methods to mitigate cultural bias inherent in large language models and validate 
      their efficacy in real-world clinical settings.
CI  - Copyright: © 2023 Jang et al. This is an open access article distributed under 
      the terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Jang, Dongyeop
AU  - Jang D
AUID- ORCID: 0000-0002-3546-8389
AD  - Department of Physiology, College of Korean Medicine, Gachon University, 
      Seongnam, Gyeonggi-do, Korea.
FAU - Yun, Tae-Rim
AU  - Yun TR
AD  - Department of Physiology, College of Korean Medicine, Gachon University, 
      Seongnam, Gyeonggi-do, Korea.
FAU - Lee, Choong-Yeol
AU  - Lee CY
AD  - Department of Physiology, College of Korean Medicine, Gachon University, 
      Seongnam, Gyeonggi-do, Korea.
FAU - Kwon, Young-Kyu
AU  - Kwon YK
AUID- ORCID: 0000-0003-3823-5799
AD  - Division of Integrated Art Therapy, School of Korean Medicine, Pusan National 
      University, Yangsan, Gyeongsangnam-do, Korea.
AD  - Division of Longevity and Biofunctional Medicine, School of Korean Medicine, 
      Pusan National University, Yangsan, Gyeongsangnam-do, Korea.
FAU - Kim, Chang-Eop
AU  - Kim CE
AUID- ORCID: 0000-0001-8281-9148
AD  - Department of Physiology, College of Korean Medicine, Gachon University, 
      Seongnam, Gyeonggi-do, Korea.
AD  - Department of Neurobiology, Stanford University School of Medicine, Stanford, 
      California, United States of America.
LA  - eng
PT  - Journal Article
DEP - 20231215
PL  - United States
TA  - PLOS Digit Health
JT  - PLOS digital health
JID - 9918335064206676
PMC - PMC10723673
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/12/15 18:41
MHDA- 2023/12/15 18:42
PMCR- 2023/12/15
CRDT- 2023/12/15 13:23
PHST- 2023/04/19 00:00 [received]
PHST- 2023/11/20 00:00 [accepted]
PHST- 2023/12/15 18:42 [medline]
PHST- 2023/12/15 18:41 [pubmed]
PHST- 2023/12/15 13:23 [entrez]
PHST- 2023/12/15 00:00 [pmc-release]
AID - PDIG-D-23-00147 [pii]
AID - 10.1371/journal.pdig.0000416 [doi]
PST - epublish
SO  - PLOS Digit Health. 2023 Dec 15;2(12):e0000416. doi: 10.1371/journal.pdig.0000416. 
      eCollection 2023 Dec.

PMID- 38076944
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231219
DP  - 2023 Nov 27
TI  - ChatGPT Influence on Medical Decision-Making, Bias, and Equity: A Randomized 
      Study of Clinicians Evaluating Clinical Vignettes.
LID - 2023.11.24.23298844 [pii]
LID - 10.1101/2023.11.24.23298844 [doi]
AB  - In a randomized, pre-post intervention study, we evaluated the influence of a 
      large language model (LLM) generative AI system on accuracy of physician 
      decision-making and bias in healthcare. 50 US-licensed physicians reviewed a 
      video clinical vignette, featuring actors representing different demographics (a 
      White male or a Black female) with chest pain. Participants were asked to answer 
      clinical questions around triage, risk, and treatment based on these vignettes, 
      then asked to reconsider after receiving advice generated by ChatGPT+ (GPT4). The 
      primary outcome was the accuracy of clinical decisions based on pre-established 
      evidence-based guidelines. Results showed that physicians are willing to change 
      their initial clinical impressions given AI assistance, and that this led to a 
      significant improvement in clinical decision-making accuracy in a chest pain 
      evaluation scenario without introducing or exacerbating existing race or gender 
      biases. A survey of physician participants indicates that the majority expect LLM 
      tools to play a significant role in clinical decision making.
FAU - Goh, Ethan
AU  - Goh E
AUID- ORCID: 0009-0001-7491-4257
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA.
AD  - Stanford Clinical Excellence Research Center, Stanford University, Stanford, CA.
FAU - Bunning, Bryan
AU  - Bunning B
AUID- ORCID: 0000-0003-3092-0038
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA.
FAU - Khoong, Elaine
AU  - Khoong E
AUID- ORCID: 0000-0002-2514-3572
AD  - UCSF Center for Vulnerable Populations at San Francisco General Hospital, SF, CA.
FAU - Gallo, Robert
AU  - Gallo R
AUID- ORCID: 0000-0002-2601-0173
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA.
AD  - Center for Innovation to Implementation, VA Palo Alto Health Care System, PA, CA.
FAU - Milstein, Arnold
AU  - Milstein A
AUID- ORCID: 0000-0002-2794-2378
AD  - Stanford Clinical Excellence Research Center, Stanford University, Stanford, CA.
FAU - Centola, Damon
AU  - Centola D
AUID- ORCID: 0000-0002-8084-2333
AD  - Communication, Sociology and Engineering, University of Pennsylvania, PA.
FAU - Chen, Jonathan H
AU  - Chen JH
AUID- ORCID: 0000-0002-4387-8740
AD  - Stanford Biomedical Informatics Research, Stanford University, Stanford, CA.
AD  - Division of Hospital Medicine, Stanford University, Stanford, CA.
AD  - Stanford Clinical Excellence Research Center, Stanford University, Stanford, CA.
LA  - eng
GR  - K23 HL157750/HL/NHLBI NIH HHS/United States
GR  - T15 LM007033/LM/NLM NIH HHS/United States
GR  - UG1 DA015815/DA/NIDA NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20231127
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC10705632
EDAT- 2023/12/11 12:43
MHDA- 2023/12/11 12:44
PMCR- 2023/12/08
CRDT- 2023/12/11 06:21
PHST- 2023/12/11 12:43 [pubmed]
PHST- 2023/12/11 12:44 [medline]
PHST- 2023/12/11 06:21 [entrez]
PHST- 2023/12/08 00:00 [pmc-release]
AID - 2023.11.24.23298844 [pii]
AID - 10.1101/2023.11.24.23298844 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Nov 27:2023.11.24.23298844. doi: 
      10.1101/2023.11.24.23298844.

PMID- 39974103
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250224
DP  - 2025 Feb 3
TI  - The Clinical Value of ChatGPT for Epilepsy Presurgical Decision Making: 
      Systematic Evaluation on Seizure Semiology Interpretation.
LID - 2024.04.13.24305773 [pii]
LID - 10.1101/2024.04.13.24305773 [doi]
AB  - BACKGROUND: For patients with drug-resistant focal epilepsy (DRE), surgical 
      resection of the epileptogenic zone (EZ) is an effective treatment to control 
      seizures. Accurate localization of the EZ is crucial and is typically achieved 
      through comprehensive presurgical approaches such as seizure semiology 
      interpretation, electroencephalography (EEG), magnetic resonance imaging (MRI), 
      and intracranial EEG (iEEG). However, interpreting seizure semiology poses 
      challenges because it relies heavily on expert knowledge and is often based on 
      inconsistent and incoherent descriptions, leading to variability and potential 
      limitations in presurgical evaluation. To overcome these challenges, advanced 
      technologies like large language models (LLMs)-with ChatGPT being a notable 
      example-offer valuable tools for analyzing complex textual information, making 
      them well-suited to interpret detailed seizure semiology descriptions and assist 
      in accurately localizing the EZ. OBJECTIVE: This study evaluates the clinical 
      value of ChatGPT in interpreting seizure semiology to localize EZs in presurgical 
      assessments for patients with focal epilepsy and compares its performance with 
      epileptologists. METHODS: Two data cohorts were compiled: a publicly sourced 
      cohort consisting of 852 semiology-EZ pairs from 193 peer-reviewed journal 
      publications and a private cohort of 184 semiology-EZ pairs collected from Far 
      Eastern Memorial Hospital (FEMH) in Taiwan. ChatGPT was evaluated to predict the 
      most likely EZ locations using two prompt methods: zero-shot prompting (ZSP) and 
      few-shot prompting (FSP). To compare ChatGPT's performance, eight epileptologists 
      were recruited to participate in an online survey to interpret 100 randomly 
      selected semiology records. The responses from ChatGPT and the epileptologists 
      were compared using three metrics: regional sensitivity (RSens), weighted 
      sensitivity (WSens), and net positive inference rate (NPIR). RESULTS: In the 
      publicly sourced cohort, ChatGPT demonstrated high RSens reliability, achieving 
      80-90% for the frontal and temporal lobes, 20-40% for the parietal lobe, 
      occipital lobe, and insular cortex, and only 3% for the cingulate cortex. The 
      WSens, which accounts for biased data distribution, consistently exceeded 67%, 
      while the mean NPIR remained around 0. These evaluation results based on the 
      private FEMH cohort are consistent with those from the publicly sourced cohort. A 
      group t-test with 1000 bootstrap samples revealed that ChatGPT-4 significantly 
      outperformed epileptologists in RSens for commonly represented EZs, such as the 
      frontal and temporal lobes (p < 0.001). Additionally, ChatGPT-4 demonstrated 
      superior overall performance in WSens (p < 0.001). However, no significant 
      differences were observed between ChatGPT and the epileptologists in NPIR, 
      highlighting comparable performance in this metric. CONCLUSIONS: ChatGPT 
      demonstrated clinical value as a tool to assist the decision-making in the 
      epilepsy preoperative workup. With ongoing advancements in LLMs, it is 
      anticipated that the reliability and accuracy of LLMs will continue to improve in 
      the future.
FAU - Luo, Yaxi
AU  - Luo Y
AD  - Department of Computer Science, Schaefer School of Engineering & Science, Stevens 
      Institute of Technology, Hoboken, NJ 07030, United States.
FAU - Jiao, Meng
AU  - Jiao M
AD  - Department of Systems and Enterprises, Schaefer School of Engineering & Science, 
      Stevens Institute of Technology, Hoboken, NJ 07030, United States.
FAU - Fotedar, Neel
AU  - Fotedar N
AD  - Department of Neurology, University Hospitals Cleveland Medical Center, School of 
      Medicine at Case Western Reserve University, Cleveland, OH, 44106, United States.
FAU - Ding, Jun-En
AU  - Ding JE
AD  - Department of Systems and Enterprises, Schaefer School of Engineering & Science, 
      Stevens Institute of Technology, Hoboken, NJ 07030, United States.
FAU - Karakis, Ioannis
AU  - Karakis I
AD  - Department of Neurology, Emory University School of Medicine GA 30322, United 
      States.
AD  - Department of Neurology, University of Crete School of Medicine, Giofirakia 
      71500, Greece.
FAU - Rao, Vikram R
AU  - Rao VR
AD  - Department of Neurology and Weill Institute for Neurosciences, University of 
      California San Francisco, San Francisco, CA 94143, United States.
FAU - Asmar, Melissa
AU  - Asmar M
AD  - Department of Neurology, University of California Davis, Davis, CA 95616, United 
      States.
FAU - Xian, Xiaochen
AU  - Xian X
AD  - H. Milton Stewart School of Industrial and Systems Engineering, Georgia Institute 
      of Technology, Atlanta, GA 30332, United States.
FAU - Aboud, Orwa
AU  - Aboud O
AD  - Department of Neurology and Neurological Surgery, University of California Davis, 
      Davis, CA 95616, United States.
FAU - Wen, Yuxin
AU  - Wen Y
AD  - Fowler School of Engineering, Chapman University, Orange, CA 92866, United 
      States.
FAU - Lin, Jack J
AU  - Lin JJ
AD  - Department of Neurology, University of California Davis, Davis, CA 95616, United 
      States.
FAU - Hung, Fang-Ming
AU  - Hung FM
AD  - Center of Artificial Intelligence, Far Eastern Memorial Hospital, New Taipei 
      City, Taiwan.
AD  - Surgical Trauma Intensive Care Unit, Far Eastern Memorial Hospital, New Taipei 
      City, Taiwan.
FAU - Sun, Hai
AU  - Sun H
AD  - Department of Neurosurgery, Rutgers Robert Wood Johnson Medical School, Rutgers 
      University, New Brunswick, NJ 08901, United States.
FAU - Rosenow, Felix
AU  - Rosenow F
AD  - Goethe-University Frankfurt, Epilepsy Center Frankfurt Rhine-Main, Department of 
      Neurology, Frankfurt am Main, 60590, Germany.
FAU - Liu, Feng
AU  - Liu F
AUID- ORCID: 0000-0002-5225-8199
AD  - Department of Systems and Enterprises, Schaefer School of Engineering & Science, 
      Stevens Institute of Technology, Hoboken, NJ 07030, United States.
AD  - Semcer Center for Healthcare Innovation, Stevens Institute of Technology, 
      Hoboken, NJ, 07030, United States.
LA  - eng
GR  - K12 CA138464/CA/NCI NIH HHS/United States
GR  - R21 NS135482/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20250203
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11838686
OTO - NOTNLM
OT  - ChatGPT
OT  - Epileptogenic Zones Localization
OT  - Large Language Models
OT  - Seizure Semiology
COIS- Conflict of Interest: “All authors have completed the Unified Competing Interest 
      form at www.icmje.org/coi_disclosure.pdf.”
EDAT- 2025/02/20 06:22
MHDA- 2025/02/20 06:23
PMCR- 2025/02/19
CRDT- 2025/02/20 05:25
PHST- 2025/02/20 06:22 [pubmed]
PHST- 2025/02/20 06:23 [medline]
PHST- 2025/02/20 05:25 [entrez]
PHST- 2025/02/19 00:00 [pmc-release]
AID - 2024.04.13.24305773 [pii]
AID - 10.1101/2024.04.13.24305773 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2025 Feb 3:2024.04.13.24305773. doi: 
      10.1101/2024.04.13.24305773.

PMID- 30818342
OWN - NLM
STAT- MEDLINE
DCOM- 20191212
LR  - 20200309
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 14
IP  - 2
DP  - 2019
TI  - Natural language processing and machine learning algorithm to identify brain MRI 
      reports with acute ischemic stroke.
PG  - e0212778
LID - 10.1371/journal.pone.0212778 [doi]
LID - e0212778
AB  - BACKGROUND AND PURPOSE: This project assessed performance of natural language 
      processing (NLP) and machine learning (ML) algorithms for classification of brain 
      MRI radiology reports into acute ischemic stroke (AIS) and non-AIS phenotypes. 
      MATERIALS AND METHODS: All brain MRI reports from a single academic institution 
      over a two year period were randomly divided into 2 groups for ML: training (70%) 
      and testing (30%). Using "quanteda" NLP package, all text data were parsed into 
      tokens to create the data frequency matrix. Ten-fold cross-validation was applied 
      for bias correction of the training set. Labeling for AIS was performed manually, 
      identifying clinical notes. We applied binary logistic regression, naïve Bayesian 
      classification, single decision tree, and support vector machine for the binary 
      classifiers, and we assessed performance of the algorithms by F1-measure. We also 
      assessed how n-grams or term frequency-inverse document frequency weighting 
      affected the performance of the algorithms. RESULTS: Of all 3,204 brain MRI 
      documents, 432 (14.3%) were labeled as AIS. AIS documents were longer in 
      character length than those of non-AIS (median [interquartile range]; 551 
      [377-681] vs. 309 [164-396]). Of all ML algorithms, single decision tree had the 
      highest F1-measure (93.2) and accuracy (98.0%). Adding bigrams to the ML model 
      improved F1-mesaure of naïve Bayesian classification, but not in others, and term 
      frequency-inverse document frequency weighting to data frequency matrix did not 
      show any additional performance improvements. CONCLUSIONS: Supervised ML based 
      NLP algorithms are useful for automatic classification of brain MRI reports for 
      identification of AIS patients. Single decision tree was the best classifier to 
      identify brain MRI reports with AIS.
FAU - Kim, Chulho
AU  - Kim C
AUID- ORCID: 0000-0001-8762-8340
AD  - Department of Neurology, Hallym University College of Medicine, Chuncheon, Korea.
AD  - Medical University of South Carolina, Charleston, South Carolina, United States 
      of America.
AD  - Biomedical Informatics Center, Medical University of South Carolina, Charleston, 
      South Carolina, United States of America.
FAU - Zhu, Vivienne
AU  - Zhu V
AD  - Medical University of South Carolina, Charleston, South Carolina, United States 
      of America.
AD  - Biomedical Informatics Center, Medical University of South Carolina, Charleston, 
      South Carolina, United States of America.
FAU - Obeid, Jihad
AU  - Obeid J
AD  - Medical University of South Carolina, Charleston, South Carolina, United States 
      of America.
AD  - Biomedical Informatics Center, Medical University of South Carolina, Charleston, 
      South Carolina, United States of America.
FAU - Lenert, Leslie
AU  - Lenert L
AD  - Medical University of South Carolina, Charleston, South Carolina, United States 
      of America.
AD  - Biomedical Informatics Center, Medical University of South Carolina, Charleston, 
      South Carolina, United States of America.
AD  - Department of Internal Medicine, Medical University of South Carolina, 
      Charleston, South Carolina, United States of America.
LA  - eng
GR  - P20 GM109040/GM/NIGMS NIH HHS/United States
GR  - UL1 TR001450/TR/NCATS NIH HHS/United States
PT  - Comparative Study
PT  - Evaluation Study
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
PT  - Validation Study
DEP - 20190228
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Adult
MH  - Aged
MH  - Brain/diagnostic imaging
MH  - Brain Infarction/*diagnostic imaging
MH  - Case-Control Studies
MH  - Decision Trees
MH  - Female
MH  - Humans
MH  - Image Interpretation, Computer-Assisted/*methods
MH  - Magnetic Resonance Imaging
MH  - Male
MH  - Middle Aged
MH  - *Natural Language Processing
MH  - Random Allocation
MH  - Retrospective Studies
MH  - *Support Vector Machine
PMC - PMC6394972
COIS- Drs. Kim, Zhu and Obeid have no competing interests. Dr. Lenert is a member of 
      the Board of Directors of the ATCC. This does not alter the authors' adherence to 
      PLOS ONE policies on sharing data and materials.
EDAT- 2019/03/01 06:00
MHDA- 2019/12/18 06:00
PMCR- 2019/02/28
CRDT- 2019/03/01 06:00
PHST- 2018/08/23 00:00 [received]
PHST- 2019/02/08 00:00 [accepted]
PHST- 2019/03/01 06:00 [entrez]
PHST- 2019/03/01 06:00 [pubmed]
PHST- 2019/12/18 06:00 [medline]
PHST- 2019/02/28 00:00 [pmc-release]
AID - PONE-D-18-24904 [pii]
AID - 10.1371/journal.pone.0212778 [doi]
PST - epublish
SO  - PLoS One. 2019 Feb 28;14(2):e0212778. doi: 10.1371/journal.pone.0212778. 
      eCollection 2019.

PMID- 37093597
OWN - NLM
STAT- MEDLINE
DCOM- 20230426
LR  - 20240917
IS  - 2574-3805 (Electronic)
IS  - 2574-3805 (Linking)
VI  - 6
IP  - 4
DP  - 2023 Apr 3
TI  - Artificial Intelligence-Enabled Analysis of Statin-Related Topics and Sentiments 
      on Social Media.
PG  - e239747
LID - 10.1001/jamanetworkopen.2023.9747 [doi]
LID - e239747
AB  - IMPORTANCE: Despite compelling evidence that statins are safe, are generally well 
      tolerated, and reduce cardiovascular events, statins are underused even in 
      patients with the highest risk. Social media may provide contemporary insights 
      into public perceptions about statins. OBJECTIVE: To characterize and classify 
      public perceptions about statins that were gleaned from more than a decade of 
      statin-related discussions on Reddit, a widely used social media platform. 
      DESIGN, SETTING, AND PARTICIPANTS: This qualitative study analyzed all 
      statin-related discussions on the social media platform that were dated between 
      January 1, 2009, and July 12, 2022. Statin- and cholesterol-focused communities, 
      were identified to create a list of statin-related discussions. An artificial 
      intelligence (AI) pipeline was developed to cluster these discussions into 
      specific topics and overarching thematic groups. The pipeline consisted of a 
      semisupervised natural language processing model (BERT [Bidirectional Encoder 
      Representations from Transformers]), a dimensionality reduction technique, and a 
      clustering algorithm. The sentiment for each discussion was labeled as positive, 
      neutral, or negative using a pretrained BERT model. EXPOSURES: Statin-related 
      posts and comments containing the terms statin and cholesterol. MAIN OUTCOMES AND 
      MEASURES: Statin-related topics and thematic groups. RESULTS: A total of 10 233 
      unique statin-related discussions (961 posts and 9272 comments) from 5188 unique 
      authors were identified. The number of statin-related discussions increased by a 
      mean (SD) of 32.9% (41.1%) per year. A total of 100 discussion topics were 
      identified and were classified into 6 overarching thematic groups: (1) ketogenic 
      diets, diabetes, supplements, and statins; (2) statin adverse effects; (3) statin 
      hesitancy; (4) clinical trial appraisals; (5) pharmaceutical industry bias and 
      statins; and (6) red yeast rice and statins. The sentiment analysis revealed that 
      most discussions had a neutral (66.6%) or negative (30.8%) sentiment. CONCLUSIONS 
      AND RELEVANCE: Results of this study demonstrated the potential of an AI approach 
      to analyze large, contemporary, publicly available social media data and generate 
      insights into public perceptions about statins. This information may help guide 
      strategies for addressing barriers to statin use and adherence.
FAU - Somani, Sulaiman
AU  - Somani S
AD  - Department of Medicine, Stanford University, Stanford, California.
FAU - van Buchem, Marieke Meija
AU  - van Buchem MM
AD  - Department of Information Technology & Digital Innovation, Leiden University 
      Medical Center (LUMC), Leiden, the Netherlands.
AD  - CAIRELab, LUMC, Leiden, the Netherlands.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, California.
FAU - Sarraju, Ashish
AU  - Sarraju A
AD  - Department of Cardiovascular Medicine, Cleveland Clinic, Cleveland, Ohio.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AD  - Department of Medicine, Stanford University, Stanford, California.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, California.
AD  - Department of Surgery, Stanford University School of Medicine, Stanford, 
      California.
FAU - Rodriguez, Fatima
AU  - Rodriguez F
AD  - Division of Cardiovascular Medicine and Cardiovascular Institute, Stanford 
      University, Stanford, California.
LA  - eng
GR  - K01 HL144607/HL/NHLBI NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20230403
PL  - United States
TA  - JAMA Netw Open
JT  - JAMA network open
JID - 101729235
RN  - 0 (Hydroxymethylglutaryl-CoA Reductase Inhibitors)
RN  - 97C5T2UQ7J (Cholesterol)
SB  - IM
MH  - Humans
MH  - *Hydroxymethylglutaryl-CoA Reductase Inhibitors/therapeutic use
MH  - Artificial Intelligence
MH  - *Social Media
MH  - Cholesterol
MH  - Attitude
PMC - PMC10126874
COIS- Conflict of Interest Disclosures: Dr Rodriguez reported receiving personal fees 
      from HealthPals, Novartis, Novo Nordisk, and AstraZeneca outside the submitted 
      work. No other disclosures were reported.
EDAT- 2023/04/24 12:41
MHDA- 2023/04/26 06:41
PMCR- 2023/04/24
CRDT- 2023/04/24 11:33
PHST- 2023/04/26 06:41 [medline]
PHST- 2023/04/24 12:41 [pubmed]
PHST- 2023/04/24 11:33 [entrez]
PHST- 2023/04/24 00:00 [pmc-release]
AID - 2803988 [pii]
AID - zoi230310 [pii]
AID - 10.1001/jamanetworkopen.2023.9747 [doi]
PST - epublish
SO  - JAMA Netw Open. 2023 Apr 3;6(4):e239747. doi: 10.1001/jamanetworkopen.2023.9747.

PMID- 38955389
OWN - NLM
STAT- MEDLINE
DCOM- 20240702
LR  - 20240704
IS  - 2632-1009 (Electronic)
IS  - 2632-1009 (Linking)
VI  - 31
IP  - 1
DP  - 2024 Jul 1
TI  - Advancing equity in breast cancer care: natural language processing for analysing 
      treatment outcomes in under-represented populations.
LID - 10.1136/bmjhci-2023-100966 [doi]
LID - e100966
AB  - OBJECTIVE: The study aimed to develop natural language processing (NLP) 
      algorithms to automate extracting patient-centred breast cancer treatment 
      outcomes from clinical notes in electronic health records (EHRs), particularly 
      for women from under-represented populations. METHODS: The study used clinical 
      notes from 2010 to 2021 from a tertiary hospital in the USA. The notes were 
      processed through various NLP techniques, including vectorisation methods (term 
      frequency-inverse document frequency (TF-IDF), Word2Vec, Doc2Vec) and 
      classification models (support vector classification, K-nearest neighbours (KNN), 
      random forest (RF)). Feature selection and optimisation through random search and 
      fivefold cross-validation were also conducted. RESULTS: The study annotated 100 
      out of 1000 clinical notes, using 970 notes to build the text corpus. TF-IDF and 
      Doc2Vec combined with RF showed the highest performance, while Word2Vec was less 
      effective. RF classifier demonstrated the best performance, although with lower 
      recall rates, suggesting more false negatives. KNN showed lower recall due to its 
      sensitivity to data noise. DISCUSSION: The study highlights the significance of 
      using NLP in analysing clinical notes to understand breast cancer treatment 
      outcomes in under-represented populations. The TF-IDF and Doc2Vec models were 
      more effective in capturing relevant information than Word2Vec. The study 
      observed lower recall rates in RF models, attributed to the dataset's imbalanced 
      nature and the complexity of clinical notes. CONCLUSION: The study developed 
      high-performing NLP pipeline to capture treatment outcomes for breast cancer in 
      under-represented populations, demonstrating the importance of document-level 
      vectorisation and ensemble methods in clinical notes analysis. The findings 
      provide insights for more equitable healthcare strategies and show the potential 
      for broader NLP applications in clinical settings.
CI  - © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Park, Jung In
AU  - Park JI
AUID- ORCID: 0000-0002-1771-7361
AD  - University of California Irvine, Irvine, California, USA junginp@uci.edu.
FAU - Park, Jong Won
AU  - Park JW
AD  - Yonsei Cancer Center, Yonsei University College of Medicine, Seoul, South Korea.
FAU - Zhang, Kexin
AU  - Zhang K
AD  - Donald Bren School of Information & Computer Sciences, University of California 
      Irvine, Irvine, California, USA.
FAU - Kim, Doyop
AU  - Kim D
AD  - Independent Researcher, Irvine, California, USA.
LA  - eng
PT  - Journal Article
DEP - 20240701
PL  - England
TA  - BMJ Health Care Inform
JT  - BMJ health & care informatics
JID - 101745500
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Breast Neoplasms/therapy
MH  - Female
MH  - *Electronic Health Records
MH  - Algorithms
MH  - Treatment Outcome
MH  - United States
PMC - PMC11218025
OTO - NOTNLM
OT  - BMJ health informatics
OT  - artificial intelligence
OT  - health equity
OT  - machine learning
OT  - nursing informatics
COIS- Competing interests: None declared.
EDAT- 2024/07/03 00:42
MHDA- 2024/07/03 00:43
PMCR- 2024/07/01
CRDT- 2024/07/02 20:43
PHST- 2023/11/16 00:00 [received]
PHST- 2024/06/21 00:00 [accepted]
PHST- 2024/07/03 00:43 [medline]
PHST- 2024/07/03 00:42 [pubmed]
PHST- 2024/07/02 20:43 [entrez]
PHST- 2024/07/01 00:00 [pmc-release]
AID - bmjhci-2023-100966 [pii]
AID - 10.1136/bmjhci-2023-100966 [doi]
PST - epublish
SO  - BMJ Health Care Inform. 2024 Jul 1;31(1):e100966. doi: 
      10.1136/bmjhci-2023-100966.

PMID- 33902657
OWN - NLM
STAT- MEDLINE
DCOM- 20211117
LR  - 20231111
IS  - 1748-5908 (Electronic)
IS  - 1748-5908 (Linking)
VI  - 16
IP  - 1
DP  - 2021 Apr 26
TI  - 5335 days of Implementation Science: using natural language processing to examine 
      publication trends and topics.
PG  - 47
LID - 10.1186/s13012-021-01120-4 [doi]
LID - 47
AB  - INTRODUCTION: Moving evidence-based practices into the hands of practitioners 
      requires the synthesis and translation of research literature. However, the 
      growing pace of scientific publications across disciplines makes it increasingly 
      difficult to stay abreast of research literature. Natural language processing 
      (NLP) methods are emerging as a valuable strategy for conducting content analyses 
      of academic literature. We sought to apply NLP to identify publication trends in 
      the journal Implementation Science, including key topic clusters and the 
      distribution of topics over time. A parallel study objective was to demonstrate 
      how NLP can be used in research synthesis. METHODS: We examined 1711 
      Implementation Science abstracts published from February 22, 2006, to October 1, 
      2020. We retrieved the study data using PubMed's Application Programming 
      Interface (API) to assemble a database. Following standard preprocessing steps, 
      we use topic modeling with Latent Dirichlet allocation (LDA) to cluster the 
      abstracts following a minimization algorithm. RESULTS: We examined 30 topics and 
      computed topic model statistics of quality. Analyses revealed that published 
      articles largely reflect (i) characteristics of research, or (ii) domains of 
      practice. Emergent topic clusters encompassed key terms both salient and common 
      to implementation science. HIV and stroke represent the most commonly published 
      clinical areas. Systematic reviews have grown in topic prominence and coherence, 
      whereas articles pertaining to knowledge translation (KT) have dropped in 
      prominence since 2013. Articles on HIV and implementation effectiveness have 
      increased in topic exclusivity over time. DISCUSSION: We demonstrated how NLP can 
      be used as a synthesis and translation method to identify trends and topics 
      across a large number of (over 1700) articles. With applicability to a variety of 
      research domains, NLP is a promising approach to accelerate the dissemination and 
      uptake of research literature. For future research in implementation science, we 
      encourage the inclusion of more equity-focused studies to expand the impact of 
      implementation science on disadvantaged communities.
FAU - Scaccia, Jonathan P
AU  - Scaccia JP
AUID- ORCID: 0000-0001-6800-1286
AD  - Dawn Chorus Group, 1014 Hartman Road, Reading, PA, 19606, USA. 
      jon@dawnchrousgroup.com.
FAU - Scott, Victoria C
AU  - Scott VC
AD  - Department of Psychological Science, University of North Carolina at Charlotte, 
      9201 University City Boulevard, Charlotte, NC, 28223, USA.
LA  - eng
PT  - Journal Article
DEP - 20210426
PL  - England
TA  - Implement Sci
JT  - Implementation science : IS
JID - 101258411
SB  - IM
MH  - Bibliometrics
MH  - Humans
MH  - *Implementation Science
MH  - *Natural Language Processing
MH  - Research Design
MH  - Translational Research, Biomedical
PMC - PMC8077727
OTO - NOTNLM
OT  - Bibliometric study
OT  - Implementation science
OT  - Natural language processing
OT  - Synthesis and translation
OT  - Systematic review
COIS- The authors of this manuscript declare that they have no competing interests.
EDAT- 2021/04/28 06:00
MHDA- 2021/11/18 06:00
PMCR- 2021/04/26
CRDT- 2021/04/27 05:47
PHST- 2020/11/17 00:00 [received]
PHST- 2021/04/14 00:00 [accepted]
PHST- 2021/04/27 05:47 [entrez]
PHST- 2021/04/28 06:00 [pubmed]
PHST- 2021/11/18 06:00 [medline]
PHST- 2021/04/26 00:00 [pmc-release]
AID - 10.1186/s13012-021-01120-4 [pii]
AID - 1120 [pii]
AID - 10.1186/s13012-021-01120-4 [doi]
PST - epublish
SO  - Implement Sci. 2021 Apr 26;16(1):47. doi: 10.1186/s13012-021-01120-4.

PMID- 40093199
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250317
DP  - 2025 Mar 6
TI  - irAE-GPT: Leveraging large language models to identify immune-related adverse 
      events in electronic health records and clinical trial datasets.
LID - 2025.03.05.25323445 [pii]
LID - 10.1101/2025.03.05.25323445 [doi]
AB  - BACKGROUND: Large language models (LLMs) have emerged as transformative 
      technologies, revolutionizing natural language understanding and generation 
      across various domains, including medicine. In this study, we investigated the 
      capabilities, limitations, and generalizability of Generative Pre-trained 
      Transformer (GPT) models in analyzing unstructured patient notes from large 
      healthcare datasets to identify immune-related adverse events (irAEs) associated 
      with the use of immune checkpoint inhibitor (ICI) therapy. METHODS: We evaluated 
      the performance of GPT-3.5, GPT-4, and GPT-4o models on manually annotated 
      datasets of patients receiving ICI therapy, sampled from two electronic health 
      record (EHR) systems and seven clinical trials. A zero-shot prompt was designed 
      to exhaustively identify irAEs at the patient level (main analysis) and the note 
      level (secondary analysis). The LLM-based system followed a multi-label 
      classification approach to identify any combination of irAEs associated with 
      individual patients or clinical notes. System evaluation was conducted for each 
      available irAE as well as for broader categories of irAEs classified at the organ 
      level. RESULTS: Our analysis included 442 patients across three institutions. The 
      most common irAEs manually identified in the patient datasets included 
      pneumonitis (N=64), colitis (N=56), rash (N=32), and hepatitis (N=28). Overall, 
      GPT models achieved high sensitivity and specificity but only moderate positive 
      predictive values, reflecting a potential bias towards overpredicting irAE 
      outcomes. GPT-4o achieved the highest F1 and micro-averaged F1 scores for both 
      patient-level and note-level evaluations. Highest performance was observed in the 
      hematological (F1 range=1.0-1.0), gastrointestinal (F1 range=0.81-0.85), and 
      musculoskeletal and rheumatologic (F1 range=0.67-1.0) irAE categories. Error 
      analysis uncovered substantial limitations of GPT models in handling textual 
      causation, where adverse events should not only be accurately identified in 
      clinical text but also causally linked to immune checkpoint inhibitors. 
      CONCLUSION: The GPT models demonstrated generalizable abilities in identifying 
      irAEs across EHRs and clinical trial reports. Using GPT models to automate 
      adverse event detection in large healthcare datasets will reduce the burden on 
      physicians and healthcare professionals by eliminating the need for manual 
      review. This will strengthen safety monitoring and lead to improved patient care.
FAU - Bejan, Cosmin A
AU  - Bejan CA
AUID- ORCID: 0000-0001-5107-0584
FAU - Wang, Michelle
AU  - Wang M
FAU - Venkateswaran, Sriram
AU  - Venkateswaran S
FAU - Bergmann, Ewa A
AU  - Bergmann EA
FAU - Hiles, Laura
AU  - Hiles L
FAU - Xu, Yaomin
AU  - Xu Y
AUID- ORCID: 0000-0002-3752-4006
FAU - Chandler, G Scott
AU  - Chandler GS
FAU - Brondfield, Sam
AU  - Brondfield S
FAU - Silverstein, Jordyn
AU  - Silverstein J
FAU - Wright, Francis
AU  - Wright F
FAU - de Dios, Kimberly
AU  - de Dios K
FAU - Kim, Daniel
AU  - Kim D
FAU - Mukherjee, Eric
AU  - Mukherjee E
AUID- ORCID: 0000-0001-8715-1378
FAU - Krantz, Matthew S
AU  - Krantz MS
FAU - Yao, Lydia
AU  - Yao L
FAU - Johnson, Douglas B
AU  - Johnson DB
FAU - Phillips, Elizabeth J
AU  - Phillips EJ
FAU - Balko, Justin M
AU  - Balko JM
FAU - Mohindra, Rajat
AU  - Mohindra R
FAU - Quandt, Zoe
AU  - Quandt Z
LA  - eng
PT  - Journal Article
PT  - Preprint
DEP - 20250306
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11908319
EDAT- 2025/03/17 15:20
MHDA- 2025/03/17 15:21
PMCR- 2025/03/14
CRDT- 2025/03/17 06:30
PHST- 2025/03/17 15:21 [medline]
PHST- 2025/03/17 15:20 [pubmed]
PHST- 2025/03/17 06:30 [entrez]
PHST- 2025/03/14 00:00 [pmc-release]
AID - 2025.03.05.25323445 [pii]
AID - 10.1101/2025.03.05.25323445 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2025 Mar 6:2025.03.05.25323445. doi: 
      10.1101/2025.03.05.25323445.

PMID- 38879943
OWN - NLM
STAT- MEDLINE
DCOM- 20240717
LR  - 20250228
IS  - 1532-8171 (Electronic)
IS  - 0735-6757 (Linking)
VI  - 82
DP  - 2024 Aug
TI  - The American Journal of Emergency Medicine's policy on large language model usage 
      in manuscript preparation: Balancing innovation and responsibility.
PG  - 105-106
LID - S0735-6757(24)00267-5 [pii]
LID - 10.1016/j.ajem.2024.06.002 [doi]
AB  - Large Language Models (LLMs) represent a transformative advancement in the 
      preparation of medical scientific manuscripts, offering significant benefits such 
      as reducing drafting time, enhancing linguistic precision, and aiding non-native 
      English speakers. These models, which generate text by learning from extensive 
      datasets, can streamline the publication process and maintain consistency across 
      collaborative projects. However, their limitations, including the risk of 
      generating plausible yet incorrect text and the potential for biases, necessitate 
      careful oversight. Ethical concerns about accuracy, authorship, and transparency 
      need to be carefully considered. The American Journal of Emergency Medicine has 
      adopted a policy permitting LLM use with full disclosure and author 
      responsibility, emphasizing the need for ongoing policy evolution in response to 
      technological advancements.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Hartka, Thomas
AU  - Hartka T
AD  - University of Virginia, Department of Emergency Medicine, Charlottesville, VA, 
      United States of America. Electronic address: trh6u@virginia.edu.
LA  - eng
PT  - Editorial
DEP - 20240608
PL  - United States
TA  - Am J Emerg Med
JT  - The American journal of emergency medicine
JID - 8309942
SB  - IM
MH  - *Emergency Medicine
MH  - Humans
MH  - United States
MH  - Periodicals as Topic
MH  - Editorial Policies
MH  - Language
MH  - Publishing/standards
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/06/17 00:42
MHDA- 2024/07/18 00:42
CRDT- 2024/06/16 18:02
PHST- 2024/05/21 00:00 [received]
PHST- 2024/06/06 00:00 [accepted]
PHST- 2024/07/18 00:42 [medline]
PHST- 2024/06/17 00:42 [pubmed]
PHST- 2024/06/16 18:02 [entrez]
AID - S0735-6757(24)00267-5 [pii]
AID - 10.1016/j.ajem.2024.06.002 [doi]
PST - ppublish
SO  - Am J Emerg Med. 2024 Aug;82:105-106. doi: 10.1016/j.ajem.2024.06.002. Epub 2024 
      Jun 8.

PMID- 33615222
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20220420
IS  - 2632-2498 (Electronic)
IS  - 2632-2498 (Linking)
VI  - 3
IP  - 1
DP  - 2021 Jan-Dec
TI  - Radiogenomic modeling predicts survival-associated prognostic groups in 
      glioblastoma.
PG  - vdab004
LID - 10.1093/noajnl/vdab004 [doi]
LID - vdab004
AB  - BACKGROUND: Combined whole-exome sequencing (WES) and somatic copy number 
      alteration (SCNA) information can separate isocitrate dehydrogenase 
      (IDH)1/2-wildtype glioblastoma into two prognostic molecular subtypes, which 
      cannot be distinguished by epigenetic or clinical features. The potential for 
      radiographic features to discriminate between these molecular subtypes has yet to 
      be established. METHODS: Radiologic features (n = 35 340) were extracted from 46 
      multisequence, pre-operative magnetic resonance imaging (MRI) scans of 
      IDH1/2-wildtype glioblastoma patients from The Cancer Imaging Archive (TCIA), all 
      of whom have corresponding WES/SCNA data. We developed a novel feature selection 
      method that leverages the structure of extracted MRI features to mitigate the 
      dimensionality challenge posed by the disparity between a large number of 
      features and the limited patients in our cohort. Six traditional machine learning 
      classifiers were trained to distinguish molecular subtypes using our feature 
      selection method, which was compared to least absolute shrinkage and selection 
      operator (LASSO) feature selection, recursive feature elimination, and variance 
      thresholding. RESULTS: We were able to classify glioblastomas into two prognostic 
      subgroups with a cross-validated area under the curve score of 0.80 (±0.03) using 
      ridge logistic regression on the 15-dimensional principle component analysis 
      (PCA) embedding of the features selected by our novel feature selection method. 
      An interrogation of the selected features suggested that features describing 
      contours in the T2 signal abnormality region on the T2-weighted fluid-attenuated 
      inversion recovery (FLAIR) MRI sequence may best distinguish these two groups 
      from one another. CONCLUSIONS: We successfully trained a machine learning model 
      that allows for relevant targeted feature extraction from standard MRI to 
      accurately predict molecularly-defined risk-stratifying IDH1/2-wildtype 
      glioblastoma patient groups.
CI  - © The Author(s) 2021. Published by Oxford University Press, the Society for 
      Neuro-Oncology and the European Association of Neuro-Oncology.
FAU - Nuechterlein, Nicholas
AU  - Nuechterlein N
AD  - Paul G. Allen School of Computer Science & Engineering, University of Washington, 
      Seattle, Washington, USA.
FAU - Li, Beibin
AU  - Li B
AD  - Paul G. Allen School of Computer Science & Engineering, University of Washington, 
      Seattle, Washington, USA.
FAU - Feroze, Abdullah
AU  - Feroze A
AD  - Department of Neurological Surgery, University of Washington, Seattle, 
      Washington, USA.
FAU - Holland, Eric C
AU  - Holland EC
AD  - Division of Human Biology, Fred Hutchinson Cancer Research Center, Seattle, 
      Washington, USA.
FAU - Shapiro, Linda
AU  - Shapiro L
AD  - Paul G. Allen School of Computer Science & Engineering, University of Washington, 
      Seattle, Washington, USA.
FAU - Haynor, David
AU  - Haynor D
AD  - Department of Radiology, University of Washington, Seattle, Washington, USA.
FAU - Fink, James
AU  - Fink J
AD  - Department of Radiology, University of Washington, Seattle, Washington, USA.
FAU - Cimino, Patrick J
AU  - Cimino PJ
AD  - Division of Human Biology, Fred Hutchinson Cancer Research Center, Seattle, 
      Washington, USA.
AD  - Department of Pathology, Division of Neuropathology, University of Washington, 
      Seattle, Washington, USA.
LA  - eng
GR  - K08 CA245037/CA/NCI NIH HHS/United States
PT  - Journal Article
DEP - 20210215
PL  - England
TA  - Neurooncol Adv
JT  - Neuro-oncology advances
JID - 101755003
PMC - PMC7883769
OTO - NOTNLM
OT  - MRI
OT  - biomarkers
OT  - copy number alterations
OT  - glioblastoma
OT  - radiogenomics
EDAT- 2021/02/23 06:00
MHDA- 2021/02/23 06:01
PMCR- 2021/02/15
CRDT- 2021/02/22 06:00
PHST- 2021/02/22 06:00 [entrez]
PHST- 2021/02/23 06:00 [pubmed]
PHST- 2021/02/23 06:01 [medline]
PHST- 2021/02/15 00:00 [pmc-release]
AID - vdab004 [pii]
AID - 10.1093/noajnl/vdab004 [doi]
PST - epublish
SO  - Neurooncol Adv. 2021 Feb 15;3(1):vdab004. doi: 10.1093/noajnl/vdab004. 
      eCollection 2021 Jan-Dec.

PMID- 39178303
OWN - NLM
STAT- MEDLINE
DCOM- 20250207
LR  - 20250207
IS  - 1475-990X (Electronic)
IS  - 1473-9879 (Linking)
VI  - 35
IP  - 6
DP  - 2024 Nov
TI  - The digital Balint: using AI in reflective practice.
PG  - 198-202
LID - 10.1080/14739879.2024.2372606 [doi]
AB  - Reflective practice is fundamental to postgraduate general practitioner (GP) 
      training and ongoing professional development. However, real-world challenges 
      like time constraints and professional isolation often limit meaningful 
      engagement with this critical skill. This article proposes that large language 
      models (LLMs), sophisticated artificial intelligence systems, may have potential 
      for enhancing reflective practice. We present three case studies, in which we 
      explore the ability of LLMs to generate thought-provoking questions, which could 
      prompt GPs to consider new angles, address underlying factors, and bridge the gap 
      between theory and practice. Our findings suggest that LLMs could help reframe 
      experiences and foster deeper self reflection, particularly for isolated 
      practitioners. While ethical concerns regarding privacy, over reliance, and 
      potential biases exist, we consider the possibility of responsibly integrating 
      LLMs into reflective practice. For trainees, AI-generated questions might 
      complement personal reflection under guidance. For GPs working in isolation, LLMs 
      present an opportunity to enhance reflective practice, challenging us to consider 
      a place for this technological innovation without diminishing the human aspects 
      essential to medical practice.
FAU - Lewis, Marcus
AU  - Lewis M
AUID- ORCID: 0009-0009-0457-6975
AD  - Abbey Medical Centre, London, UK.
AD  - Royal Free Hospital GP Speciality Training Scheme, Royal Free Hospital, London, 
      UK.
FAU - Hayhoe, Benedict
AU  - Hayhoe B
AUID- ORCID: 0000-0002-2645-6191
AD  - Department of Primary Care and Public Health, School of Public Health, Imperial 
      College London, UK.
LA  - eng
PT  - Journal Article
DEP - 20240823
PL  - England
TA  - Educ Prim Care
JT  - Education for primary care : an official publication of the Association of Course 
      Organisers, National Association of GP Tutors, World Organisation of Family 
      Doctors
JID - 101141280
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *General Practitioners/education
MH  - General Practice/education
MH  - Cognitive Reflection
OTO - NOTNLM
OT  - Artificial intelligence
OT  - cognitive reflection
OT  - education
OT  - general practice
OT  - medical
OT  - natural language processing
EDAT- 2024/08/23 18:42
MHDA- 2025/02/07 12:26
CRDT- 2024/08/23 14:13
PHST- 2025/02/07 12:26 [medline]
PHST- 2024/08/23 18:42 [pubmed]
PHST- 2024/08/23 14:13 [entrez]
AID - 10.1080/14739879.2024.2372606 [doi]
PST - ppublish
SO  - Educ Prim Care. 2024 Nov;35(6):198-202. doi: 10.1080/14739879.2024.2372606. Epub 
      2024 Aug 23.

PMID- 39399661
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241023
IS  - 2693-5015 (Electronic)
IS  - 2693-5015 (Linking)
DP  - 2024 Sep 23
TI  - Language-model-based patient embedding using electronic health records 
      facilitates phenotyping, disease forecasting, and progression analysis.
LID - rs.3.rs-4708839 [pii]
LID - 10.21203/rs.3.rs-4708839/v1 [doi]
AB  - Current studies regarding the secondary use of electronic health records (EHR) 
      predominantly rely on domain expertise and existing medical knowledge. Though 
      significant efforts have been devoted to investigating the application of machine 
      learning algorithms in the EHR, efficient and powerful representation of patients 
      is needed to unleash the potential of discovering new medical patterns underlying 
      the EHR. Here, we present an unsupervised method for embedding high-dimensional 
      EHR data at the patient level, aimed at characterizing patient heterogeneity in 
      complex diseases and identifying new disease patterns associated with clinical 
      outcome disparities. Inspired by the architecture of modern language 
      models-specifically transformers with attention mechanisms, we use patient 
      diagnosis and procedure codes as vocabularies and treat each patient as a 
      sentence to perform the patient embedding. We applied this approach to 34,851 
      unique medical codes across 1,046,649 longitudinal patient events, including 
      102,739 patients from the electronic Medical Records and GEnomics (eMERGE) 
      Network. The resulting patient vectors demonstrated excellent performance in 
      predicting future disease events (median AUROC = 0.87 within one year) and bulk 
      phenotyping (median AUROC = 0.84). We then illustrated the utility of these 
      patient vectors in revealing heterogeneous comorbidity patterns, exemplified by 
      disease subtypes in colorectal cancer and systemic lupus erythematosus, and 
      capturing distinct longitudinal disease trajectories. External validation using 
      EHR data from the University of Washington confirmed robust model performance, 
      with median AUROCs of 0.83 and 0.84 for bulk phenotyping tasks and disease onset 
      prediction, respectively. Importantly, the model reproduced the clustering 
      results of disease subtypes identified in the eMERGE cohort and uncovered 
      variations in overall mortality among these subtypes. Together, these results 
      underscore the potential of representation learning in EHRs to enhance patient 
      characterization and associated clinical outcomes, thereby advancing disease 
      forecasting and facilitating personalized medicine.
FAU - Xian, Su
AU  - Xian S
AUID- ORCID: 0000-0002-8295-876X
AD  - Department of Biomedical Informatics and Medical Education, University of 
      Washington, Seattle, WA.
FAU - Grabowska, Monika E
AU  - Grabowska ME
AUID- ORCID: 0000-0003-0708-676X
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN.
FAU - Kullo, Iftikhar J
AU  - Kullo IJ
AUID- ORCID: 0000-0002-6524-3471
AD  - Department of Cardiovascular Medicine and the Gonda Vascular Center, Mayo Clinic 
      Rochester Minnesota.
FAU - Luo, Yuan
AU  - Luo Y
AUID- ORCID: 0000-0003-0195-7456
AD  - Department of Preventive Medicine, Northwestern University Feinberg School of 
      Medicine.
FAU - Smoller, Jordan W
AU  - Smoller JW
AD  - Psychiatric and Neurodevelopmental Genetics Unit, Center for Genomic Medicine, 
      Massachusetts General Hospital, Boston, MA.
AD  - Center for Precision Psychiatry, Department of Psychiatry, Massachusetts General 
      Hospital, Boston, MA.
FAU - Wei, Wei-Qi
AU  - Wei WQ
AUID- ORCID: 0000-0003-4985-056X
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN.
FAU - Jarvik, Gail
AU  - Jarvik G
AD  - Department of Medicine, Division of Medical Genetics, University of Washington, 
      Seattle, WA.
FAU - Mooney, Sean
AU  - Mooney S
AD  - Center for Information Technology, National Institutes of Health.
FAU - Crosslin, David
AU  - Crosslin D
AD  - Department of Medicine, Division of Biomedical Informatics and Genomics, Tulane 
      University, New Orleans, LA.
LA  - eng
GR  - U01 HG008657/HG/NHGRI NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240923
PL  - United States
TA  - Res Sq
JT  - Research square
JID - 101768035
PMC - PMC11469380
EDAT- 2024/10/14 16:18
MHDA- 2024/10/14 16:19
PMCR- 2024/10/11
CRDT- 2024/10/14 07:23
PHST- 2024/10/14 16:18 [pubmed]
PHST- 2024/10/14 16:19 [medline]
PHST- 2024/10/14 07:23 [entrez]
PHST- 2024/10/11 00:00 [pmc-release]
AID - rs.3.rs-4708839 [pii]
AID - 10.21203/rs.3.rs-4708839/v1 [doi]
PST - epublish
SO  - Res Sq [Preprint]. 2024 Sep 23:rs.3.rs-4708839. doi: 10.21203/rs.3.rs-4708839/v1.

PMID- 38032714
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231217
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Nov 30
TI  - Can we use ChatGPT for Mental Health and Substance Use Education? Examining Its 
      Quality and Potential Harms.
PG  - e51243
LID - 10.2196/51243 [doi]
LID - e51243
AB  - BACKGROUND: The use of generative artificial intelligence, more specifically 
      large language models (LLMs), is proliferating, and as such, it is vital to 
      consider both the value and potential harms of its use in medical education. 
      Their efficiency in a variety of writing styles makes LLMs, such as ChatGPT, 
      attractive for tailoring educational materials. However, this technology can 
      feature biases and misinformation, which can be particularly harmful in medical 
      education settings, such as mental health and substance use education. This 
      viewpoint investigates if ChatGPT is sufficient for 2 common health education 
      functions in the field of mental health and substance use: (1) answering users' 
      direct queries and (2) aiding in the development of quality consumer educational 
      health materials. OBJECTIVE: This viewpoint includes a case study to provide 
      insight into the accessibility, biases, and quality of ChatGPT's query responses 
      and educational health materials. We aim to provide guidance for the general 
      public and health educators wishing to utilize LLMs. METHODS: We collected real 
      world queries from 2 large-scale mental health and substance use portals and 
      engineered a variety of prompts to use on GPT-4 Pro with the Bing BETA internet 
      browsing plug-in. The outputs were evaluated with tools from the Sydney Health 
      Literacy Lab to determine the accessibility, the adherence to Mindframe 
      communication guidelines to identify biases, and author assessments on quality, 
      including tailoring to audiences, duty of care disclaimers, and evidence-based 
      internet references. RESULTS: GPT-4's outputs had good face validity, but upon 
      detailed analysis were substandard in comparison to expert-developed materials. 
      Without engineered prompting, the reading level, adherence to communication 
      guidelines, and use of evidence-based websites were poor. Therefore, all outputs 
      still required cautious human editing and oversight. CONCLUSIONS: GPT-4 is 
      currently not reliable enough for direct-consumer queries, but educators and 
      researchers can use it for creating educational materials with caution. Materials 
      created with LLMs should disclose the use of generative artificial intelligence 
      and be evaluated on their efficacy with the target audience.
CI  - ©Sophia Spallek, Louise Birrell, Stephanie Kershaw, Emma Krogh Devine, Louise 
      Thornton. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 30.11.2023.
FAU - Spallek, Sophia
AU  - Spallek S
AUID- ORCID: 0000-0001-5222-1794
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Birrell, Louise
AU  - Birrell L
AUID- ORCID: 0000-0002-1335-1382
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Kershaw, Stephanie
AU  - Kershaw S
AUID- ORCID: 0000-0003-2494-4391
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Devine, Emma Krogh
AU  - Devine EK
AUID- ORCID: 0000-0001-8110-6445
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
FAU - Thornton, Louise
AU  - Thornton L
AUID- ORCID: 0000-0001-7705-833X
AD  - The Matilda Centre for Research in Mental Health and Substance Use, The 
      University of Sydney, Sydney, Australia.
LA  - eng
PT  - Journal Article
DEP - 20231130
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10722374
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - educational intervention
OT  - generative artificial intelligence
OT  - health education
OT  - large language models
OT  - medical education
OT  - mental health
OT  - patient education handout
OT  - preventive health services
OT  - substance use
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/30 12:42
MHDA- 2023/11/30 12:43
PMCR- 2023/11/30
CRDT- 2023/11/30 11:54
PHST- 2023/07/26 00:00 [received]
PHST- 2023/11/08 00:00 [accepted]
PHST- 2023/11/02 00:00 [revised]
PHST- 2023/11/30 12:43 [medline]
PHST- 2023/11/30 12:42 [pubmed]
PHST- 2023/11/30 11:54 [entrez]
PHST- 2023/11/30 00:00 [pmc-release]
AID - v9i1e51243 [pii]
AID - 10.2196/51243 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Nov 30;9:e51243. doi: 10.2196/51243.

PMID- 39454500
OWN - NLM
STAT- MEDLINE
DCOM- 20241112
LR  - 20241112
IS  - 1873-2860 (Electronic)
IS  - 0933-3657 (Linking)
VI  - 157
DP  - 2024 Nov
TI  - Advancing health coaching: A comparative study of large language model and health 
      coaches.
PG  - 103004
LID - S0933-3657(24)00246-X [pii]
LID - 10.1016/j.artmed.2024.103004 [doi]
AB  - OBJECTIVE: Recent advances in large language models (LLM) offer opportunities to 
      automate health coaching. With zero-shot learning ability, LLMs could 
      revolutionize health coaching by providing better accessibility, scalability, and 
      customization. The aim of this study is to compare the quality of responses to 
      clients' sleep-related questions provided by health coaches and an LLM. DESIGN, 
      SETTING, AND PARTICIPANTS: From a de-identified dataset of coaching conversations 
      from a pilot randomized controlled trial, we extracted 100 question-answer pairs 
      comprising client questions and corresponding health coach responses. These 
      questions were entered into a retrieval-augmented generation (RAG)-enabled 
      open-source LLM (LLaMa-2-7b-chat) to generate LLM responses. Out of 100 
      question-answer pairs, 90 were taken out and assigned to three groups of 
      evaluators: experts, lay-users, and GPT-4. Each group conducted two evaluation 
      tasks: (Task 1) a single-response quality assessment spanning five 
      criteria-accuracy, readability, helpfulness, empathy, and likelihood of 
      harm-rated on a five-point Likert scale, and (Task 2) a pairwise comparison to 
      choose the superior response between pairs. A suite of inferential statistical 
      methods, including the paired and independent sample t-tests, Pearson 
      correlation, and chi-square tests, were utilized to answer the study objective. 
      Recognizing potential biases in human judgment, the remaining 10 question-answer 
      pairs were used to assess inter-evaluator reliability among the human evaluators, 
      quantified using the interclass correlation coefficient and percentage agreement 
      metrics. RESULTS: Upon exclusion of incomplete data, the analysis included 178 
      single-response evaluations (Task 1) and 83 pairwise comparisons (Task 2). Expert 
      and GPT-4 assessments revealed no discernible disparities in health coach and LLM 
      responses across the five metrics. Contrarily, lay-users deemed LLM responses 
      significantly more helpful than that of human coaches (p < 0.05). LLM responses 
      were preferred in the majority (62.25 %, n = 155) of the aggregate 249 
      assessments, with all three evaluator groups favoring LLM over health coach 
      inputs. While GPT-4 rated both health coach and LLM responses significantly 
      higher than experts in terms of readability, helpfulness, and empathy, its 
      ratings on accuracy and likelihood of harm aligned with those of experts. 
      Response length positively correlated with accuracy and empathy scores, but 
      negatively affected readability across all evaluator groups. Expert and lay-user 
      evaluators demonstrated moderate to high inter-evaluator reliability. CONCLUSION: 
      Our study showed encouraging findings by demonstrating that RAG-enabled LLM has 
      comparable performance to health coaches in the domain tested. Serving as an 
      initial step towards the creation of more sophisticated, adaptive, 
      round-the-clock automated health coaching systems, our findings call for more 
      extensive evaluation which could assist in the development of the model that 
      could in the future lead to potential clinical implementation.
CI  - Copyright © 2024 Elsevier B.V. All rights reserved.
FAU - Ong, Qi Chwen
AU  - Ong QC
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay 
      Rd, 308232, Singapore; School of Public Health, Imperial College London, 90 Wood 
      Ln, London W12 0BZ, United Kingdom. Electronic address: qichwen.ong@ntu.edu.sg.
FAU - Ang, Chin-Siang
AU  - Ang CS
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay 
      Rd, 308232, Singapore.
FAU - Chee, Davidson Zun Yin
AU  - Chee DZY
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay 
      Rd, 308232, Singapore.
FAU - Lawate, Ashwini
AU  - Lawate A
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay 
      Rd, 308232, Singapore.
FAU - Sundram, Frederick
AU  - Sundram F
AD  - Department of Psychological Medicine, Faculty of Medical and Health Sciences, 
      University of Auckland, Auckland 1023, New Zealand.
FAU - Dalakoti, Mayank
AU  - Dalakoti M
AD  - Department of Cardiology, National University Heart Centre, 5 Lower Kent Ridge 
      Rd, 119074, Singapore; Cardiovascular Metabolic Disease Translational Research 
      Program, National University of Singapore, Singapore.
FAU - Pasalic, Leonardo
AU  - Pasalic L
AD  - Haematology, Sydney Centres for Thrombosis and Haemostasis, Institute of Clinical 
      Pathology and Medical Research (ICPMR), NSW Health Pathology, Westmead Hospital, 
      Westmead, NSW, Australia; Westmead Clinical School, University of Sydney, 
      Westmead, NSW, Australia.
FAU - To, Daniel
AU  - To D
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI, United 
      States.
FAU - Erlikh Fox, Tatiana
AU  - Erlikh Fox T
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay 
      Rd, 308232, Singapore; Onze Lieve Vrouwen Gasthuis, Jan Tooropstraat 164, 1061 AE 
      Amsterdam, Netherlands.
FAU - Bojic, Iva
AU  - Bojic I
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay 
      Rd, 308232, Singapore.
FAU - Car, Josip
AU  - Car J
AD  - Lee Kong Chian School of Medicine, Nanyang Technological University, 11 Mandalay 
      Rd, 308232, Singapore; School of Life Course & Population Sciences, King's 
      College London, Strand WC2R 2LS, United Kingdom.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20241019
PL  - Netherlands
TA  - Artif Intell Med
JT  - Artificial intelligence in medicine
JID - 8915031
SB  - IM
MH  - Humans
MH  - *Mentoring/methods
MH  - Female
MH  - Male
MH  - Adult
MH  - Language
OTO - NOTNLM
OT  - AI health coaching
OT  - Human evaluation
OT  - Q/A system
OT  - Retrieval-augmented generation
OT  - Sleep
COIS- Declaration of competing interest Frederick Sundram is on the Clinical Advisory 
      Board for Clearhead, a digital ecosystem for promoting mental wellbeing. All 
      other authors declared no known competing financial interests and personal 
      relationships with individuals or organizations that could inappropriately 
      influence the reported work.
EDAT- 2024/10/26 19:24
MHDA- 2024/11/13 13:57
CRDT- 2024/10/25 18:10
PHST- 2024/04/02 00:00 [received]
PHST- 2024/09/26 00:00 [revised]
PHST- 2024/10/16 00:00 [accepted]
PHST- 2024/11/13 13:57 [medline]
PHST- 2024/10/26 19:24 [pubmed]
PHST- 2024/10/25 18:10 [entrez]
AID - S0933-3657(24)00246-X [pii]
AID - 10.1016/j.artmed.2024.103004 [doi]
PST - ppublish
SO  - Artif Intell Med. 2024 Nov;157:103004. doi: 10.1016/j.artmed.2024.103004. Epub 
      2024 Oct 19.

PMID- 39657144
OWN - NLM
STAT- MEDLINE
DCOM- 20241210
LR  - 20250104
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Dec 10
TI  - ChatGPT May Improve Access to Language-Concordant Care for Patients With 
      Non-English Language Preferences.
PG  - e51435
LID - 10.2196/51435 [doi]
LID - e51435
AB  - This study evaluated the accuracy of ChatGPT in translating English patient 
      education materials into Spanish, Mandarin, and Russian. While ChatGPT shows 
      promise for translating Spanish and Russian medical information, Mandarin 
      translations require further refinement, highlighting the need for careful review 
      of AI-generated translations before clinical use.
CI  - © Fiatsogbe Dzuali, Kira Seiger, Roberto Novoa, Maria Aleshin, Joyce Teng, Jenna 
      Lester, Roxana Daneshjou. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org).
FAU - Dzuali, Fiatsogbe
AU  - Dzuali F
AUID- ORCID: 0000-0003-2437-1423
AD  - Department of Dermatology, University of California, San Francisco, 1701 
      Divisadero Street, San Francisco, CA, 94115, United States, 1 415-353-7800.
FAU - Seiger, Kira
AU  - Seiger K
AUID- ORCID: 0009-0000-3118-8286
AD  - Department of Dermatology, University of Washington, Seattle, WA, United States.
FAU - Novoa, Roberto
AU  - Novoa R
AUID- ORCID: 0000-0002-7955-0536
AD  - Department of Dermatology, Stanford University, Redwood City, CA, United States.
AD  - Department of Pathology, Stanford University, Redwood City, CA, United States.
FAU - Aleshin, Maria
AU  - Aleshin M
AUID- ORCID: 0000-0001-8893-9212
AD  - Department of Dermatology, Stanford University, Redwood City, CA, United States.
FAU - Teng, Joyce
AU  - Teng J
AUID- ORCID: 0000-0002-1633-6807
AD  - Department of Dermatology, Stanford University, Redwood City, CA, United States.
FAU - Lester, Jenna
AU  - Lester J
AUID- ORCID: 0000-0003-1849-1082
AD  - Department of Dermatology, University of California, San Francisco, 1701 
      Divisadero Street, San Francisco, CA, 94115, United States, 1 415-353-7800.
FAU - Daneshjou, Roxana
AU  - Daneshjou R
AUID- ORCID: 0000-0001-7988-9356
AD  - Department of Dermatology, Stanford University, Redwood City, CA, United States.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, United 
      States.
LA  - eng
PT  - Journal Article
DEP - 20241210
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Translating
MH  - Language
MH  - Communication Barriers
MH  - Health Services Accessibility
MH  - Patient Education as Topic
PMC - PMC11651640
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - health care disparity
OT  - human language
OT  - language
OT  - language-concordant care
OT  - natural language model
OT  - patient education
OT  - preference
OT  - survey
OT  - translation
COIS- RD is an AAD AI committee member and associate editor at the Journal of 
      Investigative Dermatology and NEJM AI; has received consulting fees from Pfizer, 
      L’Oreal, and Frazier Healthcare Partners; and has stock options in Revea and 
      MDAlgorithms.
EDAT- 2024/12/15 19:30
MHDA- 2024/12/15 19:31
PMCR- 2024/12/10
CRDT- 2024/12/10 16:33
PHST- 2023/07/31 00:00 [received]
PHST- 2024/08/31 00:00 [revised]
PHST- 2024/09/05 00:00 [accepted]
PHST- 2024/12/15 19:31 [medline]
PHST- 2024/12/15 19:30 [pubmed]
PHST- 2024/12/10 16:33 [entrez]
PHST- 2024/12/10 00:00 [pmc-release]
AID - v10i1e51435 [pii]
AID - 51435 [pii]
AID - 10.2196/51435 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Dec 10;10:e51435. doi: 10.2196/51435.

PMID- 38481027
OWN - NLM
STAT- MEDLINE
DCOM- 20240520
LR  - 20250314
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 6
DP  - 2024 May 20
TI  - Disparities in seizure outcomes revealed by large language models.
PG  - 1348-1355
LID - 10.1093/jamia/ocae047 [doi]
AB  - OBJECTIVE: Large-language models (LLMs) can potentially revolutionize health care 
      delivery and research, but risk propagating existing biases or introducing new 
      ones. In epilepsy, social determinants of health are associated with disparities 
      in care access, but their impact on seizure outcomes among those with access 
      remains unclear. Here we (1) evaluated our validated, epilepsy-specific LLM for 
      intrinsic bias, and (2) used LLM-extracted seizure outcomes to determine if 
      different demographic groups have different seizure outcomes. MATERIALS AND 
      METHODS: We tested our LLM for differences and equivalences in prediction 
      accuracy and confidence across demographic groups defined by race, ethnicity, 
      sex, income, and health insurance, using manually annotated notes. Next, we used 
      LLM-classified seizure freedom at each office visit to test for demographic 
      outcome disparities, using univariable and multivariable analyses. RESULTS: We 
      analyzed 84 675 clinic visits from 25 612 unique patients seen at our epilepsy 
      center. We found little evidence of bias in the prediction accuracy or confidence 
      of outcome classifications across demographic groups. Multivariable analysis 
      indicated worse seizure outcomes for female patients (OR 1.33, P ≤ .001), those 
      with public insurance (OR 1.53, P ≤ .001), and those from lower-income zip codes 
      (OR ≥1.22, P  ≤ .007). Black patients had worse outcomes than White patients in 
      univariable but not multivariable analysis (OR 1.03, P = .66). CONCLUSION: We 
      found little evidence that our LLM was intrinsically biased against any 
      demographic group. Seizure freedom extracted by LLM revealed disparities in 
      seizure outcomes across several demographic groups. These findings quantify the 
      critical need to reduce disparities in the care of people with epilepsy.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Xie, Kevin
AU  - Xie K
AUID- ORCID: 0000-0003-1849-2085
AD  - Department of Bioengineering, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
AD  - Center for Neuroengineering and Therapeutics, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
FAU - Ojemann, William K S
AU  - Ojemann WKS
AUID- ORCID: 0009-0007-5166-536X
AD  - Department of Bioengineering, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
AD  - Center for Neuroengineering and Therapeutics, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
FAU - Gallagher, Ryan S
AU  - Gallagher RS
AD  - Center for Neuroengineering and Therapeutics, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
AD  - Department of Neurology, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
FAU - Shinohara, Russell T
AU  - Shinohara RT
AD  - Department of Biostatistics, Epidemiology and Informatics, University of 
      Pennsylvania, Philadelphia, PA 19104, United States.
FAU - Lucas, Alfredo
AU  - Lucas A
AD  - Department of Bioengineering, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
AD  - Center for Neuroengineering and Therapeutics, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
AD  - Department of Neurology, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
FAU - Hill, Chloé E
AU  - Hill CE
AD  - Department of Neurology, University of Michigan, Ann Arbor, MI 48109, United 
      States.
FAU - Hamilton, Roy H
AU  - Hamilton RH
AD  - Department of Neurology, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
FAU - Johnson, Kevin B
AU  - Johnson KB
AD  - Department of Bioengineering, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
AD  - Department of Biostatistics, Epidemiology and Informatics, University of 
      Pennsylvania, Philadelphia, PA 19104, United States.
AD  - Department of Computer and Information Science, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
AD  - Department of Pediatrics, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
FAU - Roth, Dan
AU  - Roth D
AD  - Department of Computer and Information Science, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
FAU - Litt, Brian
AU  - Litt B
AD  - Department of Bioengineering, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
AD  - Center for Neuroengineering and Therapeutics, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
AD  - Department of Neurology, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
FAU - Ellis, Colin A
AU  - Ellis CA
AUID- ORCID: 0000-0003-2152-8106
AD  - Center for Neuroengineering and Therapeutics, University of Pennsylvania, 
      Philadelphia, PA 19104, United States.
AD  - Department of Neurology, University of Pennsylvania, Philadelphia, PA 19104, 
      United States.
LA  - eng
GR  - DP1NS122038/NS/NINDS NIH HHS/United States
GR  - DP1 NS122038/NS/NINDS NIH HHS/United States
GR  - DGE-1845298/National Science Foundation Research/
GR  - R01NS125137/NH/NIH HHS/United States
GR  - K23 NS126495/NS/NINDS NIH HHS/United States
GR  - Mirowski Family Foundation/
GR  - American Academy of Neurology Susan S. Spencer Clinical Research Training 
      Scholarship/
GR  - K23 NS121520/NS/NINDS NIH HHS/United States
GR  - R01 NS125137/NS/NINDS NIH HHS/United States
GR  - T32NS091006/NS/NINDS NIH HHS/United States
GR  - N00014-19-1-2620/Office of Naval Research/
GR  - K23NS121520/NH/NIH HHS/United States
GR  - T32 NS091006/NS/NINDS NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
UOF - medRxiv. 2023 Sep 22:2023.09.20.23295842. doi: 10.1101/2023.09.20.23295842. PMID: 
      37790442
MH  - Humans
MH  - Female
MH  - Male
MH  - Adult
MH  - *Healthcare Disparities
MH  - *Seizures
MH  - *Epilepsy
MH  - Middle Aged
MH  - Natural Language Processing
MH  - Social Determinants of Health
MH  - Adolescent
MH  - Young Adult
MH  - Language
PMC - PMC11105138
OTO - NOTNLM
OT  - clinical informatics
OT  - electronic health record
OT  - health disparities
OT  - natural language processing
COIS- None to declare.
EDAT- 2024/03/14 06:47
MHDA- 2024/05/20 18:44
PMCR- 2025/03/13
CRDT- 2024/03/14 02:10
PHST- 2023/09/21 00:00 [received]
PHST- 2024/02/21 00:00 [revised]
PHST- 2024/02/23 00:00 [accepted]
PHST- 2024/05/20 18:44 [medline]
PHST- 2024/03/14 06:47 [pubmed]
PHST- 2024/03/14 02:10 [entrez]
PHST- 2025/03/13 00:00 [pmc-release]
AID - 7628160 [pii]
AID - ocae047 [pii]
AID - 10.1093/jamia/ocae047 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 May 20;31(6):1348-1355. doi: 10.1093/jamia/ocae047.

PMID- 40080818
OWN - NLM
STAT- MEDLINE
DCOM- 20250313
LR  - 20250318
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Mar 13
TI  - Assessing Racial and Ethnic Bias in Text Generation by Large Language Models for 
      Health Care-Related Tasks: Cross-Sectional Study.
PG  - e57257
LID - 10.2196/57257 [doi]
LID - e57257
AB  - BACKGROUND: Racial and ethnic bias in large language models (LLMs) used for 
      health care tasks is a growing concern, as it may contribute to health 
      disparities. In response, LLM operators implemented safeguards against prompts 
      that are overtly seeking certain biases. OBJECTIVE: This study aims to 
      investigate a potential racial and ethnic bias among 4 popular LLMs: 
      GPT-3.5-turbo (OpenAI), GPT-4 (OpenAI), Gemini-1.0-pro (Google), and Llama3-70b 
      (Meta) in generating health care consumer-directed text in the absence of overtly 
      biased queries. METHODS: In this cross-sectional study, the 4 LLMs were prompted 
      to generate discharge instructions for patients with HIV. Each patient's 
      encounter deidentified metadata including race/ethnicity as a variable was passed 
      over in a table format through a prompt 4 times, altering only the race/ethnicity 
      information (African American, Asian, Hispanic White, and non-Hispanic White) 
      each time, while keeping all other information constant. The prompt requested the 
      model to write discharge instructions for each encounter without explicitly 
      mentioning race or ethnicity. The LLM-generated instructions were analyzed for 
      sentiment, subjectivity, reading ease, and word frequency by race/ethnicity. 
      RESULTS: The only observed statistically significant difference between 
      race/ethnicity groups was found in entity count (GPT-4, df=42, P=.047). However, 
      post hoc chi-square analysis for GPT-4's entity counts showed no significant 
      pairwise differences among race/ethnicity categories after Bonferroni correction. 
      CONCLUSIONS: A total of 4 LLMs were relatively invariant to race/ethnicity in 
      terms of linguistic and readability measures. While our study used proxy 
      linguistic and readability measures to investigate racial and ethnic bias among 4 
      LLM responses in a health care-related task, there is an urgent need to establish 
      universally accepted standards for measuring bias in LLM-generated responses. 
      Further studies are needed to validate these results and assess their 
      implications.
CI  - ©John J Hanna, Abdi D Wakene, Andrew O Johnson, Christoph U Lehmann, Richard J 
      Medford. Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 13.03.2025.
FAU - Hanna, John J
AU  - Hanna JJ
AUID- ORCID: 0000-0003-0909-9396
AD  - Information Services, ECU Health, Greenville, NC, United States.
AD  - Division of Infectious Diseases, Department of Internal Medicine, East Carolina 
      University, Greenville, NC, United States.
AD  - Clinical Informatics Center, University of Texas Southwestern, Dallas, TX, United 
      States.
FAU - Wakene, Abdi D
AU  - Wakene AD
AUID- ORCID: 0009-0000-7270-0506
AD  - Clinical Informatics Center, University of Texas Southwestern, Dallas, TX, United 
      States.
FAU - Johnson, Andrew O
AU  - Johnson AO
AUID- ORCID: 0009-0007-0513-0778
AD  - Information Services, ECU Health, Greenville, NC, United States.
FAU - Lehmann, Christoph U
AU  - Lehmann CU
AUID- ORCID: 0000-0001-9559-4646
AD  - Clinical Informatics Center, University of Texas Southwestern, Dallas, TX, United 
      States.
AD  - Department of Pediatrics, University of Texas Southwestern, The University of 
      Texas Southwestern Medical Center, Dallas, TX, United States.
FAU - Medford, Richard J
AU  - Medford RJ
AUID- ORCID: 0000-0001-9814-8043
AD  - Information Services, ECU Health, Greenville, NC, United States.
AD  - Division of Infectious Diseases, Department of Internal Medicine, East Carolina 
      University, Greenville, NC, United States.
AD  - Clinical Informatics Center, University of Texas Southwestern, Dallas, TX, United 
      States.
LA  - eng
PT  - Journal Article
DEP - 20250313
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
UOF - medRxiv. 2023 Aug 28:2023.08.28.23294730. doi: 10.1101/2023.08.28.23294730. PMID: 
      37693388
MH  - Cross-Sectional Studies
MH  - Humans
MH  - *Racism
MH  - Language
MH  - Ethnicity/statistics & numerical data
PMC - PMC11950697
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - bias
OT  - consumer-directed
OT  - cross sectional
OT  - healthcare
OT  - human immunodeficiency virus
OT  - large language models
OT  - racism
OT  - reading ease
OT  - sentiment analysis
OT  - task
OT  - text generation
OT  - word frequency
COIS- Conflicts of Interest: JJH has provided clinical AI consultations to Pieces 
      Technologies, Inc.
EDAT- 2025/03/14 11:20
MHDA- 2025/03/14 11:21
PMCR- 2025/03/13
CRDT- 2025/03/13 16:53
PHST- 2024/02/09 00:00 [received]
PHST- 2025/01/16 00:00 [accepted]
PHST- 2024/04/29 00:00 [revised]
PHST- 2025/03/14 11:21 [medline]
PHST- 2025/03/14 11:20 [pubmed]
PHST- 2025/03/13 16:53 [entrez]
PHST- 2025/03/13 00:00 [pmc-release]
AID - v27i1e57257 [pii]
AID - 10.2196/57257 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Mar 13;27:e57257. doi: 10.2196/57257.

PMID- 39416584
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241018
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 9
DP  - 2024 Sep
TI  - Fairness in AI-Driven Oncology: Investigating Racial and Gender Biases in Large 
      Language Models.
PG  - e69541
LID - 10.7759/cureus.69541 [doi]
LID - e69541
AB  - INTRODUCTION: Large language model (LLM) chatbots have many applications in 
      medical settings. However, these tools can potentially perpetuate racial and 
      gender biases through their responses, worsening disparities in healthcare. With 
      the ongoing discussion of LLM chatbots in oncology and the widespread goal of 
      addressing cancer disparities, this study focuses on biases propagated by LLM 
      chatbots in oncology. METHODS: Chat Generative Pre-trained Transformer (Chat GPT; 
      OpenAI, San Francisco, CA, USA) was asked to determine what occupation a generic 
      description of "assesses cancer patients" would correspond to for different 
      demographics. Chat GPT, Gemini (Alphabet Inc., Mountain View, CA, USA), and Bing 
      Chat (Microsoft Corp., Redmond, WA, USA) were prompted to provide oncologist 
      recommendations in the top U.S. cities and demographic information (race, gender) 
      of recommendations was compared against national distributions. Chat GPT was also 
      asked to generate a job description for oncologists with different demographic 
      backgrounds. Finally, Chat GPT, Gemini, and Bing Chat were asked to generate 
      hypothetical cancer patients with race, smoking, and drinking histories. RESULTS: 
      LLM chatbots are about two times more likely to predict Blacks and Native 
      Americans as oncology nurses than oncologists, compared to Asians (p < 0.01 and < 
      0.001, respectively). Similarly, they are also significantly more likely to 
      predict females than males as oncology nurses (p < 0.001). Chat GPT's real-world 
      oncologist recommendations overrepresent Asians by almost double and 
      underrepresent Blacks by double and Hispanics by seven times. Chatbots also 
      generate different job descriptions based on demographics, including cultural 
      competency and advocacy and excluding treatment administration for 
      underrepresented backgrounds. AI-generated cancer cases are not fully 
      representative of real-world demographic distributions and encode stereotypes on 
      substance abuse, such as Hispanics having a greater proportion of smokers than 
      Whites by about 20% in Chat GPT breast cancer cases. CONCLUSION: To our 
      knowledge, this is the first study of its kind to investigate racial and gender 
      biases of such a diverse set of AI chatbots, and that too, within oncology. The 
      methodology presented in this study provides a framework for targeted bias 
      evaluation of LLMs in various fields across medicine.
CI  - Copyright © 2024, Agrawal et al.
FAU - Agrawal, Anjali
AU  - Agrawal A
AD  - Department of Computer Science, University of Texas at Austin, Austin, USA.
LA  - eng
PT  - Journal Article
DEP - 20240916
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11482645
OTO - NOTNLM
OT  - ai chatbot
OT  - chat gpt
OT  - gender bias
OT  - generative ai
OT  - health disparity
OT  - large language model
OT  - oncology
OT  - racial bias
COIS- Human subjects: All authors have confirmed that this study did not involve human 
      participants or tissue. Animal subjects: All authors have confirmed that this 
      study did not involve animal subjects or tissue. Conflicts of interest: In 
      compliance with the ICMJE uniform disclosure form, all authors declare the 
      following: Payment/services info: All authors have declared that no financial 
      support was received from any organization for the submitted work. Financial 
      relationships: All authors have declared that they have no financial 
      relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2024/10/17 10:05
MHDA- 2024/10/17 10:06
PMCR- 2024/09/16
CRDT- 2024/10/17 04:56
PHST- 2024/09/16 00:00 [accepted]
PHST- 2024/10/17 10:06 [medline]
PHST- 2024/10/17 10:05 [pubmed]
PHST- 2024/10/17 04:56 [entrez]
PHST- 2024/09/16 00:00 [pmc-release]
AID - 10.7759/cureus.69541 [doi]
PST - epublish
SO  - Cureus. 2024 Sep 16;16(9):e69541. doi: 10.7759/cureus.69541. eCollection 2024 
      Sep.

PMID- 38961161
OWN - NLM
STAT- MEDLINE
DCOM- 20240703
LR  - 20240706
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Jul 4
TI  - Early detection of pediatric health risks using maternal and child health data.
PG  - 15350
LID - 10.1038/s41598-024-65449-8 [doi]
LID - 15350
AB  - Machine learning (ML)-driven diagnosis systems are particularly relevant in 
      pediatrics given the well-documented impact of early-life health conditions on 
      later-life outcomes. Yet, early identification of diseases and their subsequent 
      impact on length of hospital stay for this age group has so far remained 
      uncharacterized, likely because access to relevant health data is severely 
      limited. Thanks to a confidential data use agreement with the California 
      Department of Health Care Access and Information, we introduce Ped-BERT: a 
      state-of-the-art deep learning model that accurately predicts the likelihood of 
      100+ conditions and the length of stay in a pediatric patient's next medical 
      visit. We link mother-specific pre- and postnatal period health information to 
      pediatric patient hospital discharge and emergency room visits. Our data set 
      comprises 513.9K mother-baby pairs and contains medical diagnosis codes, length 
      of stay, as well as temporal and spatial pediatric patient characteristics, such 
      as age and residency zip code at the time of visit. Following the popular 
      bidirectional encoder representations from the transformers (BERT) approach, we 
      pre-train Ped-BERT via the masked language modeling objective to learn embedding 
      features for the diagnosis codes contained in our data. We then continue to 
      fine-tune our model to accurately predict primary diagnosis outcomes and length 
      of stay for a pediatric patient's next visit, given the history of previous 
      visits and, optionally, the mother's pre- and postnatal health information. We 
      find that Ped-BERT generally outperforms contemporary and state-of-the-art 
      classifiers when trained with minimum features. We also find that incorporating 
      mother health attributes leads to significant improvements in model performance 
      overall and across all patient subgroups in our data. Our most successful 
      Ped-BERT model configuration achieves an area under the receiver operator curve 
      (ROC AUC) of 0.927 and an average precision score (APS) of 0.408 for the 
      diagnosis prediction task, and a ROC AUC of 0.855 and APS of 0.815 for the length 
      of hospital stay task. Further, we examine Ped-BERT's fairness by determining 
      whether prediction errors are evenly distributed across various subgroups of 
      mother-baby demographics and health characteristics, or if certain subgroups 
      exhibit a higher susceptibility to prediction errors.
CI  - © 2024. The Author(s).
FAU - Ilin, Cornelia
AU  - Ilin C
AD  - University of California, Berkeley, CA, USA. cornelia.ilin@berkeley.edu.
LA  - eng
PT  - Journal Article
DEP - 20240704
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Humans
MH  - Female
MH  - *Child Health
MH  - Infant
MH  - Child, Preschool
MH  - *Maternal Health
MH  - Child
MH  - Early Diagnosis
MH  - Length of Stay
MH  - Infant, Newborn
MH  - Male
MH  - Deep Learning
MH  - Machine Learning
PMC - PMC11222373
COIS- The authors declare no competing interests.
EDAT- 2024/07/04 00:43
MHDA- 2024/07/04 00:44
PMCR- 2024/07/04
CRDT- 2024/07/03 23:30
PHST- 2023/11/13 00:00 [received]
PHST- 2024/06/20 00:00 [accepted]
PHST- 2024/07/04 00:44 [medline]
PHST- 2024/07/04 00:43 [pubmed]
PHST- 2024/07/03 23:30 [entrez]
PHST- 2024/07/04 00:00 [pmc-release]
AID - 10.1038/s41598-024-65449-8 [pii]
AID - 65449 [pii]
AID - 10.1038/s41598-024-65449-8 [doi]
PST - epublish
SO  - Sci Rep. 2024 Jul 4;14(1):15350. doi: 10.1038/s41598-024-65449-8.

PMID- 38684792
OWN - NLM
STAT- MEDLINE
DCOM- 20240822
LR  - 20240824
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 9
DP  - 2024 Sep 1
TI  - Large language models leverage external knowledge to extend clinical insight 
      beyond language boundaries.
PG  - 2054-2064
LID - 10.1093/jamia/ocae079 [doi]
AB  - OBJECTIVES: Large Language Models (LLMs) such as ChatGPT and Med-PaLM have 
      excelled in various medical question-answering tasks. However, these 
      English-centric models encounter challenges in non-English clinical settings, 
      primarily due to limited clinical knowledge in respective languages, a 
      consequence of imbalanced training corpora. We systematically evaluate LLMs in 
      the Chinese medical context and develop a novel in-context learning framework to 
      enhance their performance. MATERIALS AND METHODS: The latest China National 
      Medical Licensing Examination (CNMLE-2022) served as the benchmark. We collected 
      53 medical books and 381 149 medical questions to construct the medical knowledge 
      base and question bank. The proposed Knowledge and Few-shot Enhancement 
      In-context Learning (KFE) framework leverages the in-context learning ability of 
      LLMs to integrate diverse external clinical knowledge sources. We evaluated KFE 
      with ChatGPT (GPT-3.5), GPT-4, Baichuan2-7B, Baichuan2-13B, and QWEN-72B in 
      CNMLE-2022 and further investigated the effectiveness of different pathways for 
      incorporating LLMs with medical knowledge from 7 distinct perspectives. RESULTS: 
      Directly applying ChatGPT failed to qualify for the CNMLE-2022 at a score of 51. 
      Cooperated with the KFE framework, the LLMs with varying sizes yielded consistent 
      and significant improvements. The ChatGPT's performance surged to 70.04 and GPT-4 
      achieved the highest score of 82.59. This surpasses the qualification threshold 
      (60) and exceeds the average human score of 68.70, affirming the effectiveness 
      and robustness of the framework. It also enabled a smaller Baichuan2-13B to pass 
      the examination, showcasing the great potential in low-resource settings. 
      DISCUSSION AND CONCLUSION: This study shed light on the optimal practices to 
      enhance the capabilities of LLMs in non-English medical scenarios. By synergizing 
      medical knowledge through in-context learning, LLMs can extend clinical insight 
      beyond language barriers in healthcare, significantly reducing language-related 
      disparities of LLM applications and ensuring global benefit in this field.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Wu, Jiageng
AU  - Wu J
AD  - School of Public Health, Zhejiang University School of Medicine, Hangzhou, 
      310058, China.
FAU - Wu, Xian
AU  - Wu X
AD  - Jarvis Research Center, Tencent YouTu Lab, Beijing, 100101, China.
FAU - Qiu, Zhaopeng
AU  - Qiu Z
AD  - Jarvis Research Center, Tencent YouTu Lab, Beijing, 100101, China.
FAU - Li, Minghui
AU  - Li M
AD  - School of Public Health, Zhejiang University School of Medicine, Hangzhou, 
      310058, China.
FAU - Lin, Shixu
AU  - Lin S
AD  - School of Public Health, Zhejiang University School of Medicine, Hangzhou, 
      310058, China.
FAU - Zhang, Yingying
AU  - Zhang Y
AD  - Jarvis Research Center, Tencent YouTu Lab, Beijing, 100101, China.
FAU - Zheng, Yefeng
AU  - Zheng Y
AD  - Jarvis Research Center, Tencent YouTu Lab, Beijing, 100101, China.
FAU - Yuan, Changzheng
AU  - Yuan C
AD  - School of Public Health, Zhejiang University School of Medicine, Hangzhou, 
      310058, China.
AD  - Department of Nutrition, Harvard T.H. Chan School of Public Health, Boston, MA 
      02115, United States.
FAU - Yang, Jie
AU  - Yang J
AD  - School of Public Health, Zhejiang University School of Medicine, Hangzhou, 
      310058, China.
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital, Harvard Medical School, Boston, MA 02115, United 
      States.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - *Knowledge Bases
MH  - *Language
MH  - Humans
MH  - China
MH  - Licensure, Medical
MH  - Natural Language Processing
PMC - PMC11339525
OTO - NOTNLM
OT  - clinical knowledge
OT  - large language models
OT  - medical examination
OT  - natural language processing
COIS- The authors declare no competing interests.
EDAT- 2024/04/30 00:42
MHDA- 2024/08/22 06:42
PMCR- 2025/04/29
CRDT- 2024/04/29 23:36
PHST- 2023/12/19 00:00 [received]
PHST- 2024/03/14 00:00 [revised]
PHST- 2024/04/02 00:00 [accepted]
PHST- 2025/04/29 00:00 [pmc-release]
PHST- 2024/08/22 06:42 [medline]
PHST- 2024/04/30 00:42 [pubmed]
PHST- 2024/04/29 23:36 [entrez]
AID - 7659846 [pii]
AID - ocae079 [pii]
AID - 10.1093/jamia/ocae079 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Sep 1;31(9):2054-2064. doi: 10.1093/jamia/ocae079.

PMID- 40069766
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250314
IS  - 1472-6955 (Print)
IS  - 1472-6955 (Electronic)
IS  - 1472-6955 (Linking)
VI  - 24
IP  - 1
DP  - 2025 Mar 11
TI  - Knowledge, attitudes, and practices toward AI technology (ChatGPT) among nursing 
      students at Palestinian universities.
PG  - 269
LID - 10.1186/s12912-025-02913-4 [doi]
LID - 269
AB  - BACKGROUND: AI can improve medical practice, address staff shortages, and enhance 
      diagnostic efficiency. The ChatGPT of Open AI, launched in 2022, uses AI in 
      medical education. However, the long-term impact is uncertain, and integration 
      varies globally, particularly in the Middle East. AIM: To explore the knowledge, 
      practices, and attitudes of nursing students in Palestinian universities 
      regarding AI, specifically the use of ChatGPT. METHODOLOGY: A cross-sectional 
      design was used to conduct this study. The study was performed at 8 private and 
      governmental universities in the West Bank, Palestine, from 1st May 2024 to 30 
      May 2024, and 304 nursing students participated. RESULTS: The study revealed that 
      84.5% of nursing students at Palestinian universities were aware of AI 
      technology, yet 69.9% lacked formal education or training related to ChatGPT. 
      Despite this gap, 79% supported the integration of AI into nursing curricula and 
      specialized training programs, reflecting strong optimism about its role in 
      education and healthcare. While 58.6% had used AI in their coursework and 68.1% 
      felt comfortable with technology, disparities in proficiency and access remain 
      key barriers to effective AI integration. Major challenges to AI adoption in 
      Palestine include insufficient training, the absence of AI-focused curricula, and 
      financial constraints, underscoring the need for institutional and pedagogical 
      reforms. Concerns about AI's reliability, costs, and potential diagnostic errors 
      persist, emphasizing the complexities of its integration into nursing education 
      and practice. CONCLUSION: This study highlights the knowledge, attitudes, and 
      practices of Palestinian nursing students regarding AI and ChatGPT. It reveals 
      that, despite growing awareness, the lack of formal education on AI underscores 
      the need for comprehensive curricula. While students' express optimism about AI's 
      potential in healthcare, concerns about its reliability and integration persist. 
      The study also reveals that barriers such as inadequate training, limited 
      curricula, and financial constraints must be addressed to effectively integrate 
      AI into nursing education and prepare students for its expanding role in 
      healthcare.
CI  - © 2025. The Author(s).
FAU - Salama, Nisreen
AU  - Salama N
AD  - Faculty of Nursing, Arab American University, Jenin, Palestine. 
      nisreen.salama@aaup.edu.
FAU - Bsharat, Rebhi
AU  - Bsharat R
AD  - Nursing Collage, Ramallah, Palestine.
FAU - Alwawi, Abdallah
AU  - Alwawi A
AD  - Nursing Department, Al-Quds University, Jerusalem, Palestine.
FAU - Khlaif, Zuheir N
AU  - Khlaif ZN
AD  - Faculty of Humanities and Educational Sciences, A Najah National University, 
      Nablus, Palestine.
LA  - eng
PT  - Journal Article
DEP - 20250311
PL  - England
TA  - BMC Nurs
JT  - BMC nursing
JID - 101088683
PMC - PMC11895262
OTO - NOTNLM
OT  - AI technology
OT  - Artificial intelligence in nursing education
OT  - Attitudes
OT  - ChatGPT
OT  - Knowledge
OT  - Middle East healthcare technology
OT  - Nursing
OT  - Practices
OT  - Students university
COIS- Declarations. Ethics approval and consent to participate: The study was approved 
      by the Scientific and Ethical Research Committee at the Palestinian Universities. 
      Participants were informed that their involvement was voluntary, and data 
      collection commenced only after ethical approval was granted. All procedures 
      adhered strictly to relevant standards and regulations, including the Declaration 
      of Helsinki. Informed consent was obtained from all participants, and data was 
      collected using a self-reported online questionnaire. Consent for publication: 
      Not applicable. Competing interests: The authors declare no competing interests.
EDAT- 2025/03/12 11:33
MHDA- 2025/03/12 11:34
PMCR- 2025/03/11
CRDT- 2025/03/12 00:46
PHST- 2024/11/07 00:00 [received]
PHST- 2025/03/01 00:00 [accepted]
PHST- 2025/03/12 11:34 [medline]
PHST- 2025/03/12 11:33 [pubmed]
PHST- 2025/03/12 00:46 [entrez]
PHST- 2025/03/11 00:00 [pmc-release]
AID - 10.1186/s12912-025-02913-4 [pii]
AID - 2913 [pii]
AID - 10.1186/s12912-025-02913-4 [doi]
PST - epublish
SO  - BMC Nurs. 2025 Mar 11;24(1):269. doi: 10.1186/s12912-025-02913-4.

PMID- 39652394
OWN - NLM
STAT- MEDLINE
DCOM- 20241209
LR  - 20250104
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Dec 9
TI  - Use of ChatGPT to Explore Gender and Geographic Disparities in Scientific Peer 
      Review.
PG  - e57667
LID - 10.2196/57667 [doi]
LID - e57667
AB  - BACKGROUND: In the realm of scientific research, peer review serves as a 
      cornerstone for ensuring the quality and integrity of scholarly papers. Recent 
      trends in promoting transparency and accountability has led some journals to 
      publish peer-review reports alongside papers. OBJECTIVE: ChatGPT-4 (OpenAI) was 
      used to quantitatively assess sentiment and politeness in peer-review reports 
      from high-impact medical journals. The objective was to explore gender and 
      geographical disparities to enhance inclusivity within the peer-review process. 
      METHODS: All 9 general medical journals with an impact factor >2 that publish 
      peer-review reports were identified. A total of 12 research papers per journal 
      were randomly selected, all published in 2023. The names of the first and last 
      authors along with the first author's country of affiliation were collected, and 
      the gender of both the first and last authors was determined. For each review, 
      ChatGPT-4 was asked to evaluate the "sentiment score," ranging from -100 
      (negative) to 0 (neutral) to +100 (positive), and the "politeness score," ranging 
      from -100 (rude) to 0 (neutral) to +100 (polite). The measurements were repeated 
      5 times and the minimum and maximum values were removed. The mean sentiment and 
      politeness scores for each review were computed and then summarized using the 
      median and interquartile range. Statistical analyses included Wilcoxon rank-sum 
      tests, Kruskal-Wallis rank tests, and negative binomial regressions. RESULTS: 
      Analysis of 291 peer-review reports corresponding to 108 papers unveiled notable 
      regional disparities. Papers from the Middle East, Latin America, or Africa 
      exhibited lower sentiment and politeness scores compared to those from North 
      America, Europe, or Pacific and Asia (sentiment scores: 27 vs 60 and 62 
      respectively; politeness scores: 43.5 vs 67 and 65 respectively, adjusted P=.02). 
      No significant differences based on authors' gender were observed (all P>.05). 
      CONCLUSIONS: Notable regional disparities were found, with papers from the Middle 
      East, Latin America, and Africa demonstrating significantly lower scores, while 
      no discernible differences were observed based on authors' gender. The absence of 
      gender-based differences suggests that gender biases may not manifest as 
      prominently as other forms of bias within the context of peer review. The study 
      underscores the need for targeted interventions to address regional disparities 
      in peer review and advocates for ongoing efforts to promote equity and 
      inclusivity in scholarly communication.
CI  - ©Paul Sebo. Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 09.12.2024.
FAU - Sebo, Paul
AU  - Sebo P
AUID- ORCID: 0000-0001-7616-0017
AD  - University of Geneva, Geneva, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20241209
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Male
MH  - Female
MH  - *Peer Review
MH  - Journal Impact Factor
MH  - Periodicals as Topic/statistics & numerical data
MH  - Sex Factors
MH  - Peer Review, Research
PMC - PMC11667125
OTO - NOTNLM
OT  - Africa
OT  - ChatGPT
OT  - artificial intelligence
OT  - assessment
OT  - communication
OT  - consultation
OT  - discrimination
OT  - disparity
OT  - gender
OT  - gender bias
OT  - geographic
OT  - global south
OT  - inequality
OT  - peer review
OT  - researcher
OT  - sentiment analysis
OT  - woman
COIS- Conflicts of Interest: None declared.
EDAT- 2024/12/09 17:34
MHDA- 2024/12/09 18:26
PMCR- 2024/12/09
CRDT- 2024/12/09 11:54
PHST- 2024/02/22 00:00 [received]
PHST- 2024/06/12 00:00 [accepted]
PHST- 2024/04/21 00:00 [revised]
PHST- 2024/12/09 18:26 [medline]
PHST- 2024/12/09 17:34 [pubmed]
PHST- 2024/12/09 11:54 [entrez]
PHST- 2024/12/09 00:00 [pmc-release]
AID - v26i1e57667 [pii]
AID - 10.2196/57667 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Dec 9;26:e57667. doi: 10.2196/57667.

PMID- 39105505
OWN - NLM
STAT- MEDLINE
DCOM- 20241212
LR  - 20241212
IS  - 1532-5415 (Electronic)
IS  - 0002-8614 (Linking)
VI  - 72
IP  - 12
DP  - 2024 Dec
TI  - Use of a large language model with instruction-tuning for reliable clinical 
      frailty scoring.
PG  - 3849-3854
LID - 10.1111/jgs.19114 [doi]
AB  - BACKGROUND: Frailty is an important predictor of health outcomes, characterized 
      by increased vulnerability due to physiological decline. The Clinical Frailty 
      Scale (CFS) is commonly used for frailty assessment but may be influenced by 
      rater bias. Use of artificial intelligence (AI), particularly Large Language 
      Models (LLMs) offers a promising method for efficient and reliable frailty 
      scoring. METHODS: The study utilized seven standardized patient scenarios to 
      evaluate the consistency and reliability of CFS scoring by OpenAI's GPT-3.5-turbo 
      model. Two methods were tested: a basic prompt and an instruction-tuned prompt 
      incorporating CFS definition, a directive for accurate responses, and temperature 
      control. The outputs were compared using the Mann-Whitney U test and Fleiss' 
      Kappa for inter-rater reliability. The outputs were compared with historic human 
      scores of the same scenarios. RESULTS: The LLM's median scores were similar to 
      human raters, with differences of no more than one point. Significant differences 
      in score distributions were observed between the basic and instruction-tuned 
      prompts in five out of seven scenarios. The instruction-tuned prompt showed high 
      inter-rater reliability (Fleiss' Kappa of 0.887) and produced consistent 
      responses in all scenarios. Difficulty in scoring was noted in scenarios with 
      less explicit information on activities of daily living (ADLs). CONCLUSIONS: This 
      study demonstrates the potential of LLMs in consistently scoring clinical frailty 
      with high reliability. It demonstrates that prompt engineering via 
      instruction-tuning can be a simple but effective approach for optimizing LLMs in 
      healthcare applications. The LLM may overestimate frailty scores when less 
      information about ADLs is provided, possibly as it is less subject to implicit 
      assumptions and extrapolation than humans. Future research could explore the 
      integration of LLMs in clinical research and frailty-related outcome prediction.
CI  - © 2024 The American Geriatrics Society.
FAU - Kee, Xiang Lee Jamie
AU  - Kee XLJ
AUID- ORCID: 0000-0001-8387-9513
AD  - Department of Geriatric Medicine, Singapore General Hospital, Singapore, 
      Singapore.
FAU - Sng, Gerald Gui Ren
AU  - Sng GGR
AD  - Department of Endocrinology, Singapore General Hospital, Singapore, Singapore.
AD  - Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, 
      Singapore, Singapore.
FAU - Lim, Daniel Yan Zheng
AU  - Lim DYZ
AD  - Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, 
      Singapore, Singapore.
AD  - Department of Gastroenterology, Singapore General Hospital, Singapore, Singapore.
FAU - Tung, Joshua Yi Min
AU  - Tung JYM
AD  - Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, 
      Singapore, Singapore.
AD  - Department of Urology, Singapore General Hospital, Singapore, Singapore.
FAU - Abdullah, Hairil Rizal
AU  - Abdullah HR
AD  - Data Science and Artificial Intelligence Laboratory, Singapore General Hospital, 
      Singapore, Singapore.
AD  - Department of Anaesthesiology, Singapore General Hospital, Singapore, Singapore.
FAU - Chowdury, Anupama Roy
AU  - Chowdury AR
AD  - Department of Geriatric Medicine, Singapore General Hospital, Singapore, 
      Singapore.
LA  - eng
PT  - Journal Article
DEP - 20240806
PL  - United States
TA  - J Am Geriatr Soc
JT  - Journal of the American Geriatrics Society
JID - 7503062
SB  - IM
MH  - Humans
MH  - *Frailty/diagnosis
MH  - *Geriatric Assessment/methods
MH  - Aged
MH  - Reproducibility of Results
MH  - *Frail Elderly
MH  - Female
MH  - Male
MH  - Artificial Intelligence
MH  - Aged, 80 and over
OTO - NOTNLM
OT  - artificial intelligence
OT  - frailty
OT  - geriatrics
EDAT- 2024/08/06 12:42
MHDA- 2024/12/12 18:23
CRDT- 2024/08/06 08:03
PHST- 2024/06/15 00:00 [revised]
PHST- 2024/03/03 00:00 [received]
PHST- 2024/07/09 00:00 [accepted]
PHST- 2024/12/12 18:23 [medline]
PHST- 2024/08/06 12:42 [pubmed]
PHST- 2024/08/06 08:03 [entrez]
AID - 10.1111/jgs.19114 [doi]
PST - ppublish
SO  - J Am Geriatr Soc. 2024 Dec;72(12):3849-3854. doi: 10.1111/jgs.19114. Epub 2024 
      Aug 6.

PMID- 39980823
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250228
IS  - 2398-8835 (Electronic)
IS  - 2398-8835 (Linking)
VI  - 8
IP  - 2
DP  - 2025 Feb
TI  - Advancing Medical Research Through Artificial Intelligence: Progressive and 
      Transformative Strategies: A Literature Review.
PG  - e70200
LID - 10.1002/hsr2.70200 [doi]
LID - e70200
AB  - BACKGROUND AND AIMS: Artificial intelligence (AI) has become integral to medical 
      research, impacting various aspects such as data analysis, writing assistance, 
      and publishing. This paper explores the multifaceted influence of AI on the 
      process of writing medical research papers, encompassing data analysis, ethical 
      considerations, writing assistance, and publishing efficiency. METHODS: The 
      review was conducted following the PRISMA guidelines; a comprehensive search was 
      performed in Scopus, PubMed, EMBASE, and MEDLINE databases for research 
      publications on artificial intelligence in medical research published up to 
      October 2023. RESULTS: AI facilitates the writing process by generating drafts, 
      offering grammar and style suggestions, and enhancing manuscript quality through 
      advanced models like ChatGPT. Ethical concerns regarding content ownership and 
      potential biases in AI-generated content underscore the need for collaborative 
      efforts among researchers, publishers, and AI creators to establish ethical 
      standards. Moreover, AI significantly influences data analysis in healthcare, 
      optimizing outcomes and patient care, particularly in fields such as obstetrics 
      and gynecology and pharmaceutical research. The application of AI in publishing, 
      ranging from peer review to manuscript quality control and journal matching, 
      underscores its potential to streamline and enhance the entire research and 
      publication process. Overall, while AI presents substantial benefits, ongoing 
      research, and ethical guidelines are essential for its responsible integration 
      into the evolving landscape of medical research and publishing. CONCLUSION: The 
      integration of AI in medical research has revolutionized efficiency and 
      innovation, impacting data analysis, writing assistance, publishing, and others. 
      While AI tools offer significant benefits, ethical considerations such as biases 
      and content ownership must be addressed. Ongoing research and collaborative 
      efforts are crucial to ensure responsible and transparent AI implementation in 
      the dynamic landscape of medical research and publishing.
CI  - © 2024 The Authors. Health Science Reports published by Wiley Periodicals LLC.
FAU - Al-Qudimat, Ahmad R
AU  - Al-Qudimat AR
AUID- ORCID: 0000-0003-1161-7244
AD  - Department of Surgery, Hamad Medical Corporation Surgical Research Section Doha 
      Qatar.
AD  - Department of Public Health, College of Health Sciences, QU-Health Qatar 
      University Doha Qatar.
FAU - Fares, Zainab E
AU  - Fares ZE
AUID- ORCID: 0000-0002-0661-3487
AD  - Department of Surgery, Hamad Medical Corporation Surgical Research Section Doha 
      Qatar.
FAU - Elaarag, Mai
AU  - Elaarag M
AUID- ORCID: 0000-0001-6192-5654
AD  - Department of Surgery, Hamad Medical Corporation Surgical Research Section Doha 
      Qatar.
FAU - Osman, Maha
AU  - Osman M
AD  - Department of Public Health, College of Health Sciences, QU-Health Qatar 
      University Doha Qatar.
FAU - Al-Zoubi, Raed M
AU  - Al-Zoubi RM
AUID- ORCID: 0000-0002-0548-429X
AD  - Department of Surgery, Hamad Medical Corporation Surgical Research Section Doha 
      Qatar.
AD  - Department of Biomedical Sciences, College of Health Sciences, QU-Health Qatar 
      University Doha Qatar.
AD  - Department of Chemistry, College of Science Jordan University of Science and 
      Technology Irbid Jordan.
FAU - Aboumarzouk, Omar M
AU  - Aboumarzouk OM
AUID- ORCID: 0000-0002-7961-7614
AD  - Department of Surgery, Hamad Medical Corporation Surgical Research Section Doha 
      Qatar.
AD  - School of Medicine, Dentistry and Nursing The University of Glasgow Glasgow UK.
LA  - eng
PT  - Journal Article
DEP - 20250219
PL  - United States
TA  - Health Sci Rep
JT  - Health science reports
JID - 101728855
PMC - PMC11839394
OTO - NOTNLM
OT  - AI technology
OT  - artificial intelligence
OT  - deep learning
OT  - healthcare workers
OT  - machine learning
OT  - medical research
COIS- All authors declare there is no conflict of interest.
EDAT- 2025/02/21 06:22
MHDA- 2025/02/21 06:23
PMCR- 2025/02/19
CRDT- 2025/02/21 04:49
PHST- 2023/12/27 00:00 [received]
PHST- 2024/07/23 00:00 [revised]
PHST- 2024/10/28 00:00 [accepted]
PHST- 2025/02/21 06:23 [medline]
PHST- 2025/02/21 06:22 [pubmed]
PHST- 2025/02/21 04:49 [entrez]
PHST- 2025/02/19 00:00 [pmc-release]
AID - HSR270200 [pii]
AID - 10.1002/hsr2.70200 [doi]
PST - epublish
SO  - Health Sci Rep. 2025 Feb 19;8(2):e70200. doi: 10.1002/hsr2.70200. eCollection 
      2025 Feb.

PMID- 39365655
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241021
IS  - 2817-1705 (Electronic)
IS  - 2817-1705 (Linking)
VI  - 3
DP  - 2024 Oct 4
TI  - The Utility and Implications of Ambient Scribes in Primary Care.
PG  - e57673
LID - 10.2196/57673 [doi]
LID - e57673
AB  - Ambient scribe technology, utilizing large language models, represents an 
      opportunity for addressing several current pain points in the delivery of primary 
      care. We explore the evolution of ambient scribes and their current use in 
      primary care. We discuss the suitability of primary care for ambient scribe 
      integration, considering the varied nature of patient presentations and the 
      emphasis on comprehensive care. We also propose the stages of maturation in the 
      use of ambient scribes in primary care and their impact on care delivery. 
      Finally, we call for focused research on safety, bias, patient impact, and 
      privacy in ambient scribe technology, emphasizing the need for early training and 
      education of health care providers in artificial intelligence and digital health 
      tools.
CI  - ©Puneet Seth, Romina Carretas, Frank Rudzicz. Originally published in JMIR AI 
      (https://ai.jmir.org), 04.10.2024.
FAU - Seth, Puneet
AU  - Seth P
AUID- ORCID: 0000-0003-0102-3581
AD  - Department of Family Medicine, McMaster University, Hamilton, ON, Canada.
FAU - Carretas, Romina
AU  - Carretas R
AUID- ORCID: 0009-0005-9915-1590
AD  - School of Public Health, University of Alberta, Edmonton, AB, Canada.
FAU - Rudzicz, Frank
AU  - Rudzicz F
AUID- ORCID: 0000-0002-1139-3423
AD  - Faculty of Computer Science, Dalhousie University, Halifax, NS, Canada.
AD  - Vector Institute for Artificial Intelligence, Toronto, ON, Canada.
LA  - eng
PT  - Journal Article
DEP - 20241004
PL  - Canada
TA  - JMIR AI
JT  - JMIR AI
JID - 9918645789006676
PMC - PMC11489790
OTO - NOTNLM
OT  - AI
OT  - LLM
OT  - administrative burden
OT  - ambient scribe
OT  - artificial intelligence
OT  - digital scribe
OT  - documentation burden
OT  - electronic health record
OT  - large language model
OT  - organizational efficiency
COIS- Conflicts of Interest: PS is a paid advisor for a company that makes an ambient 
      scribe solution. RC is employed by a company that provides technologies that 
      integrate with ambient scribe solutions. FR is a shareholder of a company that 
      makes an ambient scribe solution.
EDAT- 2024/10/04 12:43
MHDA- 2024/10/04 12:44
PMCR- 2024/10/04
CRDT- 2024/10/04 11:53
PHST- 2024/02/23 00:00 [received]
PHST- 2024/09/08 00:00 [accepted]
PHST- 2024/08/18 00:00 [revised]
PHST- 2024/10/04 12:44 [medline]
PHST- 2024/10/04 12:43 [pubmed]
PHST- 2024/10/04 11:53 [entrez]
PHST- 2024/10/04 00:00 [pmc-release]
AID - v3i1e57673 [pii]
AID - 10.2196/57673 [doi]
PST - epublish
SO  - JMIR AI. 2024 Oct 4;3:e57673. doi: 10.2196/57673.

PMID- 29966483
OWN - NLM
STAT- MEDLINE
DCOM- 20190923
LR  - 20190923
IS  - 1097-6817 (Electronic)
IS  - 0194-5998 (Linking)
VI  - 159
IP  - 5
DP  - 2018 Nov
TI  - Spontaneous Labyrinthine Hemorrhage: A Case Series.
PG  - 908-913
LID - 10.1177/0194599818785900 [doi]
AB  - OBJECTIVES: To describe patient characteristics, audiometric outcomes, and 
      magnetic resonance imaging (MRI) signal patterns in patients with suspected 
      labyrinthine hemorrhage. STUDY DESIGN: Retrospective review. SETTING: Tertiary 
      medical center. SUBJECTS AND METHODS: Radiology database was queried for terms 
      related to labyrinth hemorrhage or labyrinthitis and then selected for patients 
      in which labyrinthine hemorrhage was suspected in the report. Eleven patients 
      were identified and all treated at our institution. Blinded assessment of 
      temporal bone MRI by 2 experienced neuroradiologists was performed and interrater 
      reliability assessed. Patient demographics, medical comorbidities, and 
      audiometric outcomes are described. RESULTS: Of the 11 patients identified, the 
      median patient age was 60 years; 7 were female and 4 male. Ten of 11 patients 
      presented with unilateral sudden sensorineural hearing loss (SNHL), and 8 of 11 
      had associated vertigo. One patient experienced vertigo without hearing loss. Of 
      those presenting with sudden SNHL, 82% were left with nonserviceable American 
      Academy of Otolaryngology-Head and Neck Surgery class D hearing. Interrater 
      reliability for detecting T1 signal abnormalities was moderate but very good for 
      detecting fluid attenuation inversion recovery (FLAIR) signal abnormalities. Most 
      patients had existing hypertension. Average follow-up was 13.3 months. 
      CONCLUSION: We present the largest cohort of patients with radiographic diagnosis 
      of labyrinthine hemorrhage using T1 and FLAIR signal abnormalities on MRI. Most 
      patients presented with a profound unilateral sudden SNHL that did not recover. 
      Our findings are consistent with prior reports that abnormal FLAIR signal on MRI 
      is a reliable marker for detecting inner ear injury and can potentially be used 
      as a marker for poor prognosis.
FAU - Vivas, Esther X
AU  - Vivas EX
AD  - 1 Department of Otolaryngology-Head & Neck Surgery, Emory University, Atlanta, 
      Georgia, USA.
FAU - Panella, Nicholas J
AU  - Panella NJ
AD  - 1 Department of Otolaryngology-Head & Neck Surgery, Emory University, Atlanta, 
      Georgia, USA.
FAU - Baugnon, Kristen L
AU  - Baugnon KL
AD  - 2 Department of Radiology, Emory University, Atlanta, Georgia, USA.
LA  - eng
PT  - Journal Article
DEP - 20180703
PL  - England
TA  - Otolaryngol Head Neck Surg
JT  - Otolaryngology--head and neck surgery : official journal of American Academy of 
      Otolaryngology-Head and Neck Surgery
JID - 8508176
SB  - IM
MH  - Age Distribution
MH  - Aged
MH  - Audiometry/methods
MH  - Cohort Studies
MH  - Databases, Factual
MH  - Female
MH  - Hearing Loss, Sensorineural/epidemiology/*etiology/physiopathology
MH  - Hearing Loss, Sudden/diagnostic imaging/epidemiology/*etiology
MH  - Hemorrhage/complications/*diagnostic imaging/physiopathology
MH  - Humans
MH  - *Imaging, Three-Dimensional
MH  - Incidence
MH  - Magnetic Resonance Imaging/methods
MH  - Male
MH  - Middle Aged
MH  - Observer Variation
MH  - Prognosis
MH  - Retrospective Studies
MH  - Risk Assessment
MH  - Sex Distribution
MH  - Tertiary Care Centers
OTO - NOTNLM
OT  - MRI
OT  - hemorrhagic labyrinthitis
OT  - labyrinthine hemorrhage
OT  - sudden sensorineural hearing loss
EDAT- 2018/07/04 06:00
MHDA- 2019/09/24 06:00
CRDT- 2018/07/04 06:00
PHST- 2018/07/04 06:00 [pubmed]
PHST- 2019/09/24 06:00 [medline]
PHST- 2018/07/04 06:00 [entrez]
AID - 10.1177/0194599818785900 [doi]
PST - ppublish
SO  - Otolaryngol Head Neck Surg. 2018 Nov;159(5):908-913. doi: 
      10.1177/0194599818785900. Epub 2018 Jul 3.

PMID- 39618089
OWN - NLM
STAT- MEDLINE
DCOM- 20241202
LR  - 20241202
IS  - 1365-2753 (Electronic)
IS  - 1356-1294 (Print)
IS  - 1356-1294 (Linking)
VI  - 31
IP  - 1
DP  - 2025 Feb
TI  - Implications of Large Language Models for Clinical Practice: Ethical Analysis 
      Through the Principlism Framework.
PG  - e14250
LID - 10.1111/jep.14250 [doi]
LID - e14250
AB  - INTRODUCTION: The potential applications of large language models (LLMs)-a form 
      of generative artificial intelligence (AI)-in medicine and health care are being 
      increasingly explored by medical practitioners and health care researchers. 
      METHODS: This paper considers the ethical implications of LLMs for medical 
      practitioners in their delivery of clinical care through the ethical framework of 
      principlism. FINDINGS: It finds that, regarding beneficence, LLMs can improve 
      patient outcomes through supporting administrative tasks that surround patient 
      care, and by directly informing clinical care. Simultaneously, LLMs can cause 
      patient harm through various mechanisms, meaning non-maleficence would prevent 
      their deployment in the absence of sufficient risk mitigation. Regarding 
      autonomy, medical practitioners must inform patients if their medical care will 
      be influenced by LLMs for their consent to be informed, and alternative care 
      uninfluenced by LLMs must be available for patients who withhold such consent. 
      Finally, regarding justice, LLMs could promote the standardisation of care within 
      individual medical practitioners by mitigating any biases harboured by those 
      practitioners and by protecting against human factors, while also up-skilling 
      existing medical practitioners in low-resource settings to reduce global health 
      disparities. DISCUSSION: Accordingly, this paper finds a strong case for the 
      incorporation of LLMs into clinical practice and, if their risk of patient harm 
      is sufficiently mitigated, this incorporation might be ethically required, at 
      least according to principlism.
CI  - © 2024 The Author(s). Journal of Evaluation in Clinical Practice published by 
      John Wiley & Sons Ltd.
FAU - Armitage, Richard C
AU  - Armitage RC
AUID- ORCID: 0000-0003-1165-6753
AD  - Academic Unit of Population and Lifespan Sciences, School of Medicine, Clinical 
      Sciences Building, University of Nottingham, Nottingham, Nottinghamshire, UK.
LA  - eng
GR  - The author received no specific funding for this work./
PT  - Journal Article
PL  - England
TA  - J Eval Clin Pract
JT  - Journal of evaluation in clinical practice
JID - 9609066
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence/ethics
MH  - Beneficence
MH  - Ethical Analysis
MH  - Principle-Based Ethics
MH  - Personal Autonomy
MH  - Social Justice/ethics
MH  - Informed Consent/ethics
MH  - Ethics, Medical
MH  - Language
PMC - PMC11609490
COIS- The author declares no conflicts of interest.
EDAT- 2024/12/02 06:27
MHDA- 2024/12/02 06:28
PMCR- 2024/12/02
CRDT- 2024/12/02 01:53
PHST- 2024/09/04 00:00 [revised]
PHST- 2024/04/07 00:00 [received]
PHST- 2024/11/07 00:00 [accepted]
PHST- 2024/12/02 06:28 [medline]
PHST- 2024/12/02 06:27 [pubmed]
PHST- 2024/12/02 01:53 [entrez]
PHST- 2024/12/02 00:00 [pmc-release]
AID - JEP14250 [pii]
AID - 10.1111/jep.14250 [doi]
PST - ppublish
SO  - J Eval Clin Pract. 2025 Feb;31(1):e14250. doi: 10.1111/jep.14250.

PMID- 40059391
OWN - NLM
STAT- Publisher
LR  - 20250310
IS  - 1600-0714 (Electronic)
IS  - 0904-2512 (Linking)
DP  - 2025 Mar 9
TI  - The Need to Improve the Medical Subject Headings (MeSH) and the Excerpta Medica 
      Tree (EMTREE) Thesauri to Perform Systematic Review on Oral Potentially Malignant 
      Disorders.
LID - 10.1111/jop.13616 [doi]
AB  - BACKGROUND: Despite recent advancements in the understanding and classification 
      of oral potentially malignant disorders (OPMD), their terminology remains 
      inconsistent and heterogeneous throughout the scientific literature, thus 
      affecting evidence-based decision-making relevant for clinical management of 
      these disorders. Updating this classification represents a necessity to improve 
      the indexing and retrieval of OPMD publications, in particular for systematic 
      reviews and meta-analysis. METHODS: Through a critical appraisal of the Medical 
      Subject Headings (MeSH) and Excerpta Medica Tree (EMTREE) thesauri, we assessed 
      gaps in the indexing for OPMD literature and propose improvements for enhanced 
      categorisation and retrieval. RESULTS: The present study identifies 
      inconsistencies and limitations in the classification of these disorders across 
      the major medical databases, which may be summarized in the following findings: 
      a) The MeSH database lacks a dedicated subject heading for "oral potentially 
      malignant disorders"; b) EMTREE indexing is incomplete, with only 5 out of 11 
      recognised OPMD having corresponding terms; c) Incoherent controlled vocabulary 
      mappings hinder systematic literature retrieval. CONCLUSION: To ensure accurate 
      evidence synthesis, the authors recommend searching both PubMed and Embase for 
      OPMD studies. Moreover, the use of Embase's PubMed query translator and Large 
      Language Models, such as ChatGPT, may lead to retrieval biases due to indexing 
      discrepancies, posing challenges for early-career researchers and students. We 
      recommend introducing "oral potentially malignant disorders" as a standardised 
      subject heading. Evidence-based medicine underpins clinical decision support 
      systems, which rely on standardised clinical coding for reliable health 
      information. Enhanced medical ontologies will facilitate structured clinical 
      coding, ensuring interoperability and improving clinical decision support 
      systems.
CI  - © 2025 The Author(s). Journal of Oral Pathology & Medicine published by John 
      Wiley & Sons Ltd.
FAU - Caponio, Vito Carlo Alberto
AU  - Caponio VCA
AUID- ORCID: 0000-0001-5080-5921
AD  - Department of Clinical and Experimental Medicine, University of Foggia, Foggia, 
      Italy.
AD  - ORALMED Research Group, Department of Dental Clinical Specialties, School of 
      Dentistry, Complutense University, Madrid, Spain.
FAU - Musella, Gennaro
AU  - Musella G
AUID- ORCID: 0009-0005-3576-4670
AD  - Department of Clinical and Experimental Medicine, University of Foggia, Foggia, 
      Italy.
FAU - Pérez-Sayáns, Mario
AU  - Pérez-Sayáns M
AUID- ORCID: 0000-0003-2196-9868
AD  - Oral Medicine, Oral Surgery and Implantology Unit (MedOralRes), Faculty of 
      Medicine and Dentistry, Santiago de Compostela University, Santiago de 
      Compostela, Spain.
AD  - ORALRES Group, Health Research Institute of Santiago de Compostela (FIDIS), 
      Santiago de Compostela, Spain.
AD  - Instituto de los materiales de Santiago de Compostela (iMATUS), Avenida do Mestre 
      Mateo, Santiago de Compostela, Spain.
FAU - Lo Muzio, Lorenzo
AU  - Lo Muzio L
AUID- ORCID: 0000-0003-4633-4893
AD  - Department of Clinical and Experimental Medicine, University of Foggia, Foggia, 
      Italy.
FAU - Amaral Mendes, Rui
AU  - Amaral Mendes R
AUID- ORCID: 0000-0001-7628-8598
AD  - Department of Community Medicine, Information and Health Decision Sciences 
      (MEDCIDS), Faculty of Medicine of the University of Porto, Porto, Portugal.
AD  - RISE-Health, PerMed Research Group, Faculty of Medicine of the University of 
      Porto, Porto, Portugal.
AD  - RISE-Laboratorio Associado, LT2-Clinical and Translational Research in Oncology, 
      Faculty of Medicine of the University of Porto, Porto, Portugal.
AD  - Department of Oral and Maxillofacial Medicine and Diagnostic Sciences, Case 
      Western Reserve University, Cleveland, OH, USA.
FAU - López-Pintor, Rosa María
AU  - López-Pintor RM
AUID- ORCID: 0000-0002-5727-0920
AD  - ORALMED Research Group, Department of Dental Clinical Specialties, School of 
      Dentistry, Complutense University, Madrid, Spain.
LA  - eng
GR  - This article is based upon work from COST Action CA21140 - INTercEption of oRal 
      CancEr develoPmenT (INTERCEPTOR), supported by COST (European Cooperation in 
      Science and Technology)/
GR  - This work was supported by Instituto de Salud Carlos III through project 
      PI22/00905 co-funded by the European Union./
PT  - Journal Article
DEP - 20250309
PL  - Denmark
TA  - J Oral Pathol Med
JT  - Journal of oral pathology & medicine : official publication of the International 
      Association of Oral Pathologists and the American Academy of Oral Pathology
JID - 8911934
SB  - IM
OTO - NOTNLM
OT  - medical informatics
OT  - meta‐analysis
OT  - mouth diseases
OT  - oral lichen planus
OT  - oral potentially malignant disorder
OT  - precancerous conditions
EDAT- 2025/03/10 08:00
MHDA- 2025/03/10 08:00
CRDT- 2025/03/10 01:53
PHST- 2024/08/12 00:00 [received]
PHST- 2025/01/29 00:00 [accepted]
PHST- 2025/03/10 08:00 [medline]
PHST- 2025/03/10 08:00 [pubmed]
PHST- 2025/03/10 01:53 [entrez]
AID - 10.1111/jop.13616 [doi]
PST - aheadofprint
SO  - J Oral Pathol Med. 2025 Mar 9. doi: 10.1111/jop.13616.

PMID- 39012633
OWN - NLM
STAT- MEDLINE
DCOM- 20240716
LR  - 20250224
IS  - 2574-3805 (Electronic)
IS  - 2574-3805 (Linking)
VI  - 7
IP  - 7
DP  - 2024 Jul 1
TI  - Large Language Model-Based Responses to Patients' In-Basket Messages.
PG  - e2422399
LID - 10.1001/jamanetworkopen.2024.22399 [doi]
LID - e2422399
AB  - IMPORTANCE: Virtual patient-physician communications have increased since 2020 
      and negatively impacted primary care physician (PCP) well-being. Generative 
      artificial intelligence (GenAI) drafts of patient messages could potentially 
      reduce health care professional (HCP) workload and improve communication quality, 
      but only if the drafts are considered useful. OBJECTIVES: To assess PCPs' 
      perceptions of GenAI drafts and to examine linguistic characteristics associated 
      with equity and perceived empathy. DESIGN, SETTING, AND PARTICIPANTS: This 
      cross-sectional quality improvement study tested the hypothesis that PCPs' 
      ratings of GenAI drafts (created using the electronic health record [EHR] 
      standard prompts) would be equivalent to HCP-generated responses on 3 dimensions. 
      The study was conducted at NYU Langone Health using private patient-HCP 
      communications at 3 internal medicine practices piloting GenAI. EXPOSURES: 
      Randomly assigned patient messages coupled with either an HCP message or the 
      draft GenAI response. MAIN OUTCOMES AND MEASURES: PCPs rated responses' 
      information content quality (eg, relevance), using a Likert scale, communication 
      quality (eg, verbosity), using a Likert scale, and whether they would use the 
      draft or start anew (usable vs unusable). Branching logic further probed for 
      empathy, personalization, and professionalism of responses. Computational 
      linguistics methods assessed content differences in HCP vs GenAI responses, 
      focusing on equity and empathy. RESULTS: A total of 16 PCPs (8 [50.0%] female) 
      reviewed 344 messages (175 GenAI drafted; 169 HCP drafted). Both GenAI and HCP 
      responses were rated favorably. GenAI responses were rated higher for 
      communication style than HCP responses (mean [SD], 3.70 [1.15] vs 3.38 [1.20]; 
      P = .01, U = 12 568.5) but were similar to HCPs on information content (mean 
      [SD], 3.53 [1.26] vs 3.41 [1.27]; P = .37; U = 13 981.0) and usable draft 
      proportion (mean [SD], 0.69 [0.48] vs 0.65 [0.47], P = .49, t = -0.6842). Usable 
      GenAI responses were considered more empathetic than usable HCP responses (32 of 
      86 [37.2%] vs 13 of 79 [16.5%]; difference, 125.5%), possibly attributable to 
      more subjective (mean [SD], 0.54 [0.16] vs 0.31 [0.23]; P < .001; difference, 
      74.2%) and positive (mean [SD] polarity, 0.21 [0.14] vs 0.13 [0.25]; P = .02; 
      difference, 61.5%) language; they were also numerically longer (mean [SD] word 
      count, 90.5 [32.0] vs 65.4 [62.6]; difference, 38.4%), but the difference was not 
      statistically significant (P = .07) and more linguistically complex (mean [SD] 
      score, 125.2 [47.8] vs 95.4 [58.8]; P = .002; difference, 31.2%). CONCLUSIONS: In 
      this cross-sectional study of PCP perceptions of an EHR-integrated GenAI chatbot, 
      GenAI was found to communicate information better and with more empathy than 
      HCPs, highlighting its potential to enhance patient-HCP communication. However, 
      GenAI drafts were less readable than HCPs', a significant concern for patients 
      with low health or English literacy.
FAU - Small, William R
AU  - Small WR
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Wiesenfeld, Batia
AU  - Wiesenfeld B
AD  - NYU Stern School of Business, New York, New York.
FAU - Brandfield-Harvey, Beatrix
AU  - Brandfield-Harvey B
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Jonassen, Zoe
AU  - Jonassen Z
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Mandal, Soumik
AU  - Mandal S
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Stevens, Elizabeth R
AU  - Stevens ER
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Major, Vincent J
AU  - Major VJ
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Lostraglio, Erin
AU  - Lostraglio E
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Szerencsy, Adam
AU  - Szerencsy A
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Jones, Simon
AU  - Jones S
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Aphinyanaphongs, Yindalon
AU  - Aphinyanaphongs Y
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Johnson, Stephen B
AU  - Johnson SB
AD  - NYU Grossman School of Medicine, New York, New York.
FAU - Nov, Oded
AU  - Nov O
AD  - NYU Tandon School of Engineering, New York, New York.
FAU - Mann, Devin
AU  - Mann D
AD  - NYU Grossman School of Medicine, New York, New York.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240701
PL  - United States
TA  - JAMA Netw Open
JT  - JAMA network open
JID - 101729235
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Physician-Patient Relations
MH  - Female
MH  - Male
MH  - Adult
MH  - Middle Aged
MH  - Communication
MH  - Quality Improvement
MH  - Artificial Intelligence
MH  - Physicians, Primary Care/psychology
MH  - Electronic Health Records
MH  - Language
MH  - Empathy
MH  - Attitude of Health Personnel
PMC - PMC11252893
COIS- Conflict of Interest Disclosures: Dr Wiesenfeld reported receiving grants from 
      the National Science Foundation (award Nos. 1928614 and 2129076) during the 
      conduct of the study. Dr Jonassen reported receiving grants from the Swiss 
      National Science Foundation General Postdoc Mobility Fellowship (award Nos. 
      P500PS_202955 and P5R5PS_217714) during the conduct of the study. No other 
      disclosures were reported.
EDAT- 2024/07/16 12:44
MHDA- 2024/07/16 12:45
PMCR- 2024/07/16
CRDT- 2024/07/16 11:32
PHST- 2024/07/16 12:45 [medline]
PHST- 2024/07/16 12:44 [pubmed]
PHST- 2024/07/16 11:32 [entrez]
PHST- 2024/07/16 00:00 [pmc-release]
AID - 2821167 [pii]
AID - zoi240715 [pii]
AID - 10.1001/jamanetworkopen.2024.22399 [doi]
PST - epublish
SO  - JAMA Netw Open. 2024 Jul 1;7(7):e2422399. doi: 
      10.1001/jamanetworkopen.2024.22399.

PMID- 35084481
OWN - NLM
STAT- MEDLINE
DCOM- 20220222
LR  - 20220222
IS  - 2574-3805 (Electronic)
IS  - 2574-3805 (Linking)
VI  - 5
IP  - 1
DP  - 2022 Jan 4
TI  - Examination of Stigmatizing Language in the Electronic Health Record.
PG  - e2144967
LID - 10.1001/jamanetworkopen.2021.44967 [doi]
LID - e2144967
AB  - IMPORTANCE: Stigmatizing language in the electronic health record (EHR) may alter 
      treatment plans, transmit biases between clinicians, and alienate patients. 
      However, neither the frequency of stigmatizing language in hospital notes, nor 
      whether clinicians disproportionately use it in describing patients in particular 
      demographic subgroups are known. OBJECTIVE: To examine the prevalence of 
      stigmatizing language in hospital admission notes and the patient and clinician 
      characteristics associated with the use of such language. DESIGN, SETTING, AND 
      PARTICIPANTS: This cross-sectional study of admission notes used natural language 
      processing on 48 651 admission notes written about 29 783 unique patients by 1932 
      clinicians at a large, urban academic medical center between January to December 
      2018. The admission notes included 8738 notes about 4309 patients with diabetes 
      written by 1204 clinicians; 6197 notes about 3058 patients with substance use 
      disorder by 1132 clinicians; and 5176 notes about 2331 patients with chronic pain 
      by 1056 clinicians. Statistical analyses were performed between May and September 
      2021. EXPOSURES: Patients' demographic characteristics (age, race and ethnicity, 
      gender, and preferred language); clinicians' characteristics (gender, 
      postgraduate year [PGY], and credential [physician vs advanced practice 
      clinician]). MAIN OUTCOME AND MEASURES: Binary indicator for any vs no 
      stigmatizing language; frequencies of specific stigmatizing words. Linear 
      probability models were the main measure, and logistic regression and odds ratios 
      were used for sensitivity analyses and further exploration. RESULTS: The sample 
      included notes on 29 783 patients with a mean (SD) age of 46.9 (27.6) years. Of 
      these patients, 1033 (3.5%) were non-Hispanic Asian, 2498 (8.4%) were 
      non-Hispanic Black, 18 956 (63.6%) were non-Hispanic White, 17 334 (58.2%) were 
      female, and 2939 (9.9%) preferred a language other than English. Of all admission 
      notes, 1197 (2.5%) contained stigmatizing language. The diagnosis-specific 
      stigmatizing language was present in 599 notes (6.9%) for patients with diabetes, 
      209 (3.4%) for patients with substance use disorders, and 37 (0.7%) for patients 
      with chronic pain. In the whole sample, notes about non-Hispanic Black patients 
      vs non-Hispanic White patients had a 0.67 (95% CI, 0.15 to 1.18) percentage 
      points greater probability of containing stigmatizing language, with similar 
      disparities in all 3 diagnosis-specific subgroups. Greater diabetes severity and 
      the physician-author being less advanced in their training was associated with 
      more stigmatizing language. A 1 point increase in the diabetes severity index was 
      associated with a 1.23 (95% CI, .23 to 2.23) percentage point greater probability 
      of a note containing stigmatizing language. In the sample restricted to 
      physicians, a higher PGY was associated with less use of stigmatizing language 
      overall (-0.05 percentage points/PGY [95% CI, -0.09 to -0.01]). CONCLUSIONS AND 
      RELEVANCE: In this cross-sectional study, stigmatizing language in hospital notes 
      varied by medical condition and was more often used to describe non-Hispanic 
      Black patients. Training clinicians to minimize stigmatizing language in the EHR 
      might improve patient-clinician relationships and reduce the transmission of bias 
      between clinicians.
FAU - Himmelstein, Gracie
AU  - Himmelstein G
AD  - Office of Population Research, Princeton University, Princeton, New Jersey.
AD  - Department of Medicine, University of California Los Angeles Health, Los Angeles.
FAU - Bates, David
AU  - Bates D
AD  - Division of General Internal Medicine, Brigham and Women's Hospital and Harvard 
      Medical School, Boston, Massachusetts.
AD  - Department of Health Policy and Management, Harvard T. H. Chan School of Public 
      Health, Boston, Massachusetts.
FAU - Zhou, Li
AU  - Zhou L
AD  - Division of General Internal Medicine, Brigham and Women's Hospital and Harvard 
      Medical School, Boston, Massachusetts.
LA  - eng
GR  - P2C HD047879/HD/NICHD NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20220104
PL  - United States
TA  - JAMA Netw Open
JT  - JAMA network open
JID - 101729235
SB  - IM
MH  - Academic Medical Centers
MH  - Adult
MH  - *Attitude of Health Personnel
MH  - Cross-Sectional Studies
MH  - Electronic Health Records/*statistics & numerical data
MH  - Female
MH  - Humans
MH  - *Language
MH  - Linear Models
MH  - Male
MH  - Middle Aged
MH  - Natural Language Processing
MH  - Physicians/*psychology
MH  - *Stereotyping
PMC - PMC8796019
COIS- Conflict of Interest Disclosures: Dr Bates reported receiving grants from 
      EarlySense and IBM Watson Health, receiving personal fees from EarlySense, CDI 
      Negev, FeelBetter, and AESOP, and having equity in FeelBetter, ValeraHealth, CLEW 
      Medical, MDClone, and AESOP outside the submitted work. Dr Zhou reported 
      receiving grants from the Agency for Healthcare Research and Quality, CRICO, IBM 
      Watson Health, and the National Institutes of Health (NIH) and receiving personal 
      fees from Merck outside the submitted work.
EDAT- 2022/01/28 06:00
MHDA- 2022/02/23 06:00
PMCR- 2022/01/27
CRDT- 2022/01/27 12:15
PHST- 2022/01/27 12:15 [entrez]
PHST- 2022/01/28 06:00 [pubmed]
PHST- 2022/02/23 06:00 [medline]
PHST- 2022/01/27 00:00 [pmc-release]
AID - 2788454 [pii]
AID - zoi211246 [pii]
AID - 10.1001/jamanetworkopen.2021.44967 [doi]
PST - epublish
SO  - JAMA Netw Open. 2022 Jan 4;5(1):e2144967. doi: 
      10.1001/jamanetworkopen.2021.44967.

PMID- 36451354
OWN - NLM
STAT- MEDLINE
DCOM- 20221216
LR  - 20221221
IS  - 2213-1582 (Electronic)
IS  - 2213-1582 (Linking)
VI  - 36
DP  - 2022
TI  - T1w/FLAIR ratio standardization as a myelin marker in MS patients.
PG  - 103248
LID - S2213-1582(22)00313-8 [pii]
LID - 10.1016/j.nicl.2022.103248 [doi]
LID - 103248
AB  - INTRODUCTION: Calculation of a T1w/T2w ratio was introduced as a proxy for myelin 
      integrity in the brain of multiple sclerosis (MS) patients. Since nowadays 3D 
      FLAIR is commonly used for lesion detection instead of T2w images, we introduce a 
      T1w/FLAIR ratio as an alternative for the T1w/T2w ratio. OBJECTIVES: Bias and 
      intensity variation are widely present between different scanners, between 
      subjects and within subjects over time in T1w, T2w and FLAIR images. We present a 
      standardized method for calculating a histogram calibrated T1w/FLAIR ratio to 
      reduce bias and intensity variation in MR sequences from different scanners and 
      at different time-points. MATERIAL AND METHODS: 207 Relapsing Remitting MS 
      patients were scanned on 4 different 3 T scanners with a protocol including 3D 
      T1w, 2D T2w and 3D FLAIR images. After bias correction, T1w/FLAIR ratio maps and 
      T1w/T2w ratio maps were calculated in 4 different ways: without calibration, with 
      linear histogram calibration as described by Ganzetti et al. (2014), and by using 
      2 methods of non-linear histogram calibration. The first nonlinear calibration 
      uses a template of extra-cerebral tissue and cerebrospinal fluid (CSF) brought 
      from Montreal Neurological Institute (MNI) space to subject space; for the second 
      nonlinear method we used an extra-cerebral tissue and CSF template of our own 
      subjects. Additionally, we segmented several brain structures such as Normal 
      Appearing White Matter (NAWM), Normal Appearing Grey Matter (NAGM), corpus 
      callosum, thalami and MS lesions using Freesurfer and Samseg. RESULTS: The 
      coefficient of variation of T1w/FLAIR ratio in NAWM for the no calibrated, 
      linear, and 2 nonlinear calibration methods were respectively 24, 19.1, 9.5, 
      13.8. The nonlinear methods of calibration showed the best results for 
      calculating the T1w/FLAIR ratio with a smaller dispersion of the data and a 
      smaller overlap of T1w/FLAIR ratio in the different segmented brain structures. 
      T1w/T2w and T1w/FLAIR ratios showed a wider range of values compared to MTR 
      values. CONCLUSIONS: Calibration of T1w/T2w and T1w/FLAIR ratio maps is 
      imperative to account for the sources of variation described above. The nonlinear 
      calibration methods showed the best reduction of between-subject and 
      within-subject variability. The T1w/T2w and T1w/FLAIR ratio seem to be more 
      sensitive to smaller changes in tissue integrity than MTR. Future work is needed 
      to determine the exact substrate of T1w/FLAIR ratio and to obtain correlations 
      with clinical outcome.
CI  - Copyright © 2022 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Cappelle, S
AU  - Cappelle S
AD  - Department of Radiology, University Hospitals Leuven, Leuven, Belgium.
FAU - Pareto, D
AU  - Pareto D
AD  - Department of Radiology (IDI), Vall d'Hebron University Hospital, Barcelona, 
      Spain.
FAU - Sunaert, S
AU  - Sunaert S
AD  - Department of Radiology, University Hospitals Leuven, Leuven, Belgium; Department 
      of Imaging & Pathology, Translational MRI, KU Leuven, Leuven, Belgium.
FAU - Smets, I
AU  - Smets I
AD  - Laboratory for Neuroimmunology, KU Leuven, Leuven, Belgium; Department of 
      Neurology, Erasmus MC, Rotterdam, The Netherlands.
FAU - Laenen, A
AU  - Laenen A
AD  - Interuniversity Institute for Biostatistics and Statistical Bioinformatics, KU 
      Leuven and Hasselt University, Leuven, Belgium.
FAU - Dubois, B
AU  - Dubois B
AD  - Laboratory for Neuroimmunology, KU Leuven, Leuven, Belgium; Department of 
      Neurology, University Hospitals Leuven, Leuven, Belgium.
FAU - Demaerel, Ph
AU  - Demaerel P
AD  - Department of Radiology, University Hospitals Leuven, Leuven, Belgium; Department 
      of Imaging & Pathology, Translational MRI, KU Leuven, Leuven, Belgium.
LA  - eng
PT  - Journal Article
DEP - 20221025
PL  - Netherlands
TA  - Neuroimage Clin
JT  - NeuroImage. Clinical
JID - 101597070
SB  - IM
MH  - Humans
MH  - Myelin Sheath/pathology
MH  - Magnetic Resonance Imaging/methods
MH  - *Multiple Sclerosis/pathology
MH  - *White Matter/diagnostic imaging/pathology
MH  - Brain/diagnostic imaging/pathology
PMC - PMC9668645
OTO - NOTNLM
OT  - Image calibration
OT  - Integrity
OT  - Multiple sclerosis
OT  - T1w/FLAIR ratio
OT  - T1w/T2w ratio
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2022/12/02 06:00
MHDA- 2022/12/15 06:00
PMCR- 2022/10/25
CRDT- 2022/12/01 01:03
PHST- 2022/03/30 00:00 [received]
PHST- 2022/10/20 00:00 [revised]
PHST- 2022/10/23 00:00 [accepted]
PHST- 2022/12/02 06:00 [pubmed]
PHST- 2022/12/15 06:00 [medline]
PHST- 2022/12/01 01:03 [entrez]
PHST- 2022/10/25 00:00 [pmc-release]
AID - S2213-1582(22)00313-8 [pii]
AID - 103248 [pii]
AID - 10.1016/j.nicl.2022.103248 [doi]
PST - ppublish
SO  - Neuroimage Clin. 2022;36:103248. doi: 10.1016/j.nicl.2022.103248. Epub 2022 Oct 
      25.

PMID- 38928668
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240629
IS  - 2075-4418 (Print)
IS  - 2075-4418 (Electronic)
IS  - 2075-4418 (Linking)
VI  - 14
IP  - 12
DP  - 2024 Jun 13
TI  - Google Bard and ChatGPT in Orthopedics: Which Is the Better Doctor in Sports 
      Medicine and Pediatric Orthopedics? The Role of AI in Patient Education.
LID - 10.3390/diagnostics14121253 [doi]
LID - 1253
AB  - BACKGROUND: This study evaluates the potential of ChatGPT and Google Bard as 
      educational tools for patients in orthopedics, focusing on sports medicine and 
      pediatric orthopedics. The aim is to compare the quality of responses provided by 
      these natural language processing (NLP) models, addressing concerns about the 
      potential dissemination of incorrect medical information. METHODS: Ten ACL- and 
      flat foot-related questions from a Google search were presented to ChatGPT-3.5 
      and Google Bard. Expert orthopedic surgeons rated the responses using the Global 
      Quality Score (GQS). The study minimized bias by clearing chat history before 
      each question, maintaining respondent anonymity and employing statistical 
      analysis to compare response quality. RESULTS: ChatGPT-3.5 and Google Bard 
      yielded good-quality responses, with average scores of 4.1 ± 0.7 and 4 ± 0.78, 
      respectively, for sports medicine. For pediatric orthopedics, Google Bard scored 
      3.5 ± 1, while the average score for responses generated by ChatGPT was 3.8 ± 
      0.83. In both cases, no statistically significant difference was found between 
      the platforms (p = 0.6787, p = 0.3092). Despite ChatGPT's responses being 
      considered more readable, both platforms showed promise for AI-driven patient 
      education, with no reported misinformation. CONCLUSIONS: ChatGPT and Google Bard 
      demonstrate significant potential as supplementary patient education resources in 
      orthopedics. However, improvements are needed for increased reliability. The 
      study underscores the evolving role of AI in orthopedics and calls for continued 
      research to ensure a conscientious integration of AI in healthcare education.
FAU - Giorgino, Riccardo
AU  - Giorgino R
AUID- ORCID: 0000-0002-1067-7424
AD  - Residency Program in Orthopaedics and Traumatology, University of Milan, 20122 
      Milan, Italy.
AD  - IRCCS Ospedale Galeazzi Sant'ambrogio, 20157 Milan, Italy.
FAU - Alessandri-Bonetti, Mario
AU  - Alessandri-Bonetti M
AUID- ORCID: 0000-0002-5506-8323
AD  - Department of Plastic Surgery, University of Pittsburgh Medical Center, 1350 
      Locust Street, Pittsburgh, PA 15213, USA.
FAU - Del Re, Matteo
AU  - Del Re M
AD  - IRCCS Ospedale Galeazzi Sant'ambrogio, 20157 Milan, Italy.
FAU - Verdoni, Fabio
AU  - Verdoni F
AD  - IRCCS Ospedale Galeazzi Sant'ambrogio, 20157 Milan, Italy.
FAU - Peretti, Giuseppe M
AU  - Peretti GM
AUID- ORCID: 0000-0001-9341-7187
AD  - IRCCS Ospedale Galeazzi Sant'ambrogio, 20157 Milan, Italy.
AD  - Department of Biomedical Sciences for Health, University of Milan, 20122 Milan, 
      Italy.
FAU - Mangiavini, Laura
AU  - Mangiavini L
AD  - IRCCS Ospedale Galeazzi Sant'ambrogio, 20157 Milan, Italy.
AD  - Department of Biomedical Sciences for Health, University of Milan, 20122 Milan, 
      Italy.
LA  - eng
GR  - Ricerca Corrente/Ministero della Salute/
PT  - Journal Article
DEP - 20240613
PL  - Switzerland
TA  - Diagnostics (Basel)
JT  - Diagnostics (Basel, Switzerland)
JID - 101658402
PMC - PMC11202930
OTO - NOTNLM
OT  - ACL
OT  - AI
OT  - diagnostics
OT  - flat foot
OT  - natural language processing
OT  - orthopedics
OT  - pediatric orthopedics
OT  - sports medicine
COIS- The authors declare no conflicts of interest.
EDAT- 2024/06/27 06:43
MHDA- 2024/06/27 06:44
PMCR- 2024/06/13
CRDT- 2024/06/27 01:08
PHST- 2024/04/22 00:00 [received]
PHST- 2024/05/31 00:00 [revised]
PHST- 2024/06/11 00:00 [accepted]
PHST- 2024/06/27 06:44 [medline]
PHST- 2024/06/27 06:43 [pubmed]
PHST- 2024/06/27 01:08 [entrez]
PHST- 2024/06/13 00:00 [pmc-release]
AID - diagnostics14121253 [pii]
AID - diagnostics-14-01253 [pii]
AID - 10.3390/diagnostics14121253 [doi]
PST - epublish
SO  - Diagnostics (Basel). 2024 Jun 13;14(12):1253. doi: 10.3390/diagnostics14121253.

PMID- 39284061
OWN - NLM
STAT- MEDLINE
DCOM- 20240916
LR  - 20250308
IS  - 1091-6490 (Electronic)
IS  - 0027-8424 (Print)
IS  - 0027-8424 (Linking)
VI  - 121
IP  - 39
DP  - 2024 Sep 24
TI  - On the development and validation of large language model-based classifiers for 
      identifying social determinants of health.
PG  - e2320716121
LID - 10.1073/pnas.2320716121 [doi]
LID - e2320716121
AB  - The assessment of social determinants of health (SDoH) within healthcare systems 
      is crucial for comprehensive patient care and addressing health disparities. 
      Current challenges arise from the limited inclusion of structured SDoH 
      information within electronic health record (EHR) systems, often due to the lack 
      of standardized diagnosis codes. This study delves into the transformative 
      potential of large language models (LLM) to overcome these challenges. LLM-based 
      classifiers-using Bidirectional Encoder Representations from Transformers (BERT) 
      and A Robustly Optimized BERT Pretraining Approach (RoBERTa)-were developed for 
      SDoH concepts, including homelessness, food insecurity, and domestic violence, 
      using synthetic training datasets generated by generative pre-trained 
      transformers combined with authentic clinical notes. Models were then validated 
      on separate datasets: Medical Information Mart for Intensive Care-III and our 
      institutional EHR data. When training the model with a combination of synthetic 
      and authentic notes, validation on our institutional dataset yielded an area 
      under the receiver operating characteristics curve of 0.78 for detecting 
      homelessness, 0.72 for detecting food insecurity, and 0.83 for detecting domestic 
      violence. This study underscores the potential of LLMs in extracting SDoH 
      information from clinical text. Automated detection of SDoH may be instrumental 
      for healthcare providers in identifying at-risk patients, guiding targeted 
      interventions, and contributing to population health initiatives aimed at 
      mitigating disparities.
FAU - Gabriel, Rodney A
AU  - Gabriel RA
AD  - Division of Perioperative Informatics, Department of Anesthesiology, University 
      of California, San Diego, La Jolla, CA 92037.
AD  - Department of Biomedical Informatics, University of California, San Diego Health, 
      La Jolla, CA 92037.
FAU - Litake, Onkar
AU  - Litake O
AD  - Division of Perioperative Informatics, Department of Anesthesiology, University 
      of California, San Diego, La Jolla, CA 92037.
FAU - Simpson, Sierra
AU  - Simpson S
AUID- ORCID: 0000-0002-1352-0617
AD  - Division of Perioperative Informatics, Department of Anesthesiology, University 
      of California, San Diego, La Jolla, CA 92037.
FAU - Burton, Brittany N
AU  - Burton BN
AD  - Department of Anesthesiology, University of California, Los Angeles, CA 90095.
FAU - Waterman, Ruth S
AU  - Waterman RS
AUID- ORCID: 0000-0002-7825-3142
AD  - Division of Perioperative Informatics, Department of Anesthesiology, University 
      of California, San Diego, La Jolla, CA 92037.
FAU - Macias, Alvaro A
AU  - Macias AA
AUID- ORCID: 0000-0002-2276-9131
AD  - Division of Perioperative Informatics, Department of Anesthesiology, University 
      of California, San Diego, La Jolla, CA 92037.
LA  - eng
GR  - L60 HL175673/HL/NHLBI NIH HHS/United States
GR  - T15 LM011271/LM/NLM NIH HHS/United States
GR  - T32 GM148369/GM/NIGMS NIH HHS/United States
PT  - Journal Article
DEP - 20240916
PL  - United States
TA  - Proc Natl Acad Sci U S A
JT  - Proceedings of the National Academy of Sciences of the United States of America
JID - 7505876
SB  - IM
MH  - *Social Determinants of Health
MH  - Humans
MH  - *Electronic Health Records
MH  - *Food Insecurity
MH  - *Ill-Housed Persons
MH  - *Domestic Violence
PMC - PMC11441499
OTO - NOTNLM
OT  - AI
OT  - large language models
OT  - social determinants of health
COIS- Competing interests statement:The authors declare no competing interest.
EDAT- 2024/09/17 10:43
MHDA- 2024/09/17 10:44
PMCR- 2024/09/16
CRDT- 2024/09/16 15:43
PHST- 2024/09/17 10:44 [medline]
PHST- 2024/09/17 10:43 [pubmed]
PHST- 2024/09/16 15:43 [entrez]
PHST- 2024/09/16 00:00 [pmc-release]
AID - 202320716 [pii]
AID - 10.1073/pnas.2320716121 [doi]
PST - ppublish
SO  - Proc Natl Acad Sci U S A. 2024 Sep 24;121(39):e2320716121. doi: 
      10.1073/pnas.2320716121. Epub 2024 Sep 16.

PMID- 37223985
OWN - NLM
STAT- MEDLINE
DCOM- 20230526
LR  - 20230630
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 May 24
TI  - Text Analysis of Trends in Health Equity and Disparities From the Internal 
      Revenue Service Tax Documentation Submitted by US Nonprofit Hospitals Between 
      2010 and 2019: Exploratory Study.
PG  - e44330
LID - 10.2196/44330 [doi]
LID - e44330
AB  - BACKGROUND: Many US hospitals are classified as nonprofits and receive tax-exempt 
      status partially in exchange for providing benefits to the community. Proof of 
      compliance is collected with the Schedule H form submitted as part of the annual 
      Internal Revenue Service Form 990 (F990H), including a free-response text section 
      that is known for being ambiguous and difficult to audit. This research is among 
      the first to use natural language processing approaches to evaluate this text 
      section with a focus on health equity and disparities. OBJECTIVE: This study aims 
      to determine the extent to which the free-response text in F990H reveals how 
      nonprofit hospitals address health equity and disparities, including alignment 
      with public priorities. METHODS: We used free-response text submitted by hospital 
      reporting entities in Part V and VI of the Internal Revenue Service Form 990 
      Schedule H between 2010 and 2019. We identified 29 main themes connected to 
      health equity and disparities, and 152 related key phrases. We tallied 
      occurrences of these phrases through term frequency analysis, calculated the 
      Moran I statistic to assess geographic variation in 2018, analyzed Google Trends 
      use for the same terms during the same period, and used semantic search with 
      Sentence-BERT in Python to understand contextual use. RESULTS: We found increased 
      use from 2010 to 2019 across all the 29 phrase themes related to health equity 
      and disparities. More than 90% of hospital reporting entities used terms in 2018 
      and 2019 related to affordability (2018: 2117/2131, 99.34%; 2019: 1620/1627, 
      99.57%), government organizations (2018: 2053/2131, 96.33%; 2019: 1577/1627, 
      96.93%), mental health (2018: 1937/2131, 90.9%; 2019: 1517/1627, 93.24%), and 
      data collection (2018: 1947/2131, 91.37%; 2019: 1502/1627, 92.32%). The themes 
      with the largest relative increase were LGBTQ (lesbian, gay, bisexual, 
      transgender, and queer; 1676%; 2010: 12/2328, 0.51%; 2019: 149/1627, 9.16%) and 
      social determinants of health (958%; 2010: 68/2328, 2.92%; 2019: 503/1627, 
      30.92%). Terms related to homelessness varied geographically from 2010 to 2018, 
      and terms related to equity, health IT, immigration, LGBTQ, oral health, rural, 
      social determinants of health, and substance use showed statistically significant 
      (P<.05) geographic variation in 2018. The largest percentage point increase was 
      for terms related to substance use (2010: 403/2328, 17.31%; 2019: 1149/1627, 
      70.62%). However, use in themes such as LGBTQ, disability, oral health, and race 
      and ethnicity ranked lower than public interest in these topics, and some 
      increased mentions of themes were to explicitly say that no action was taken. 
      CONCLUSIONS: Hospital reporting entities demonstrate an increasing awareness of 
      health equity and disparities in community benefit tax documentation, but these 
      do not necessarily correspond with general population interests or additional 
      action. We propose further investigation of alignment with community health needs 
      assessments and make suggestions for improvements to F990H reporting 
      requirements.
CI  - ©Emily Hadley, Laura Haak Marcial, Wes Quattrone, Georgiy Bobashev. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      24.05.2023.
FAU - Hadley, Emily
AU  - Hadley E
AUID- ORCID: 0000-0003-0074-4344
AD  - RTI International, Durham, NC, United States.
FAU - Marcial, Laura Haak
AU  - Marcial LH
AUID- ORCID: 0000-0003-2277-5723
AD  - RTI International, Durham, NC, United States.
FAU - Quattrone, Wes
AU  - Quattrone W
AUID- ORCID: 0000-0003-1957-9887
AD  - RTI International, Durham, NC, United States.
FAU - Bobashev, Georgiy
AU  - Bobashev G
AUID- ORCID: 0000-0003-2346-1400
AD  - RTI International, Durham, NC, United States.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230524
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Female
MH  - Humans
MH  - *Health Equity
MH  - Organizations, Nonprofit
MH  - *Sexual and Gender Minorities
MH  - Documentation
MH  - Hospitals
PMC - PMC10248774
OTO - NOTNLM
OT  - health care disparities
OT  - hospital administration
OT  - natural language processing
OT  - text mining
COIS- Conflicts of Interest: None declared.
EDAT- 2023/05/24 13:09
MHDA- 2023/05/26 06:42
PMCR- 2023/05/24
CRDT- 2023/05/24 12:03
PHST- 2022/11/15 00:00 [received]
PHST- 2023/04/14 00:00 [accepted]
PHST- 2023/03/13 00:00 [revised]
PHST- 2023/05/26 06:42 [medline]
PHST- 2023/05/24 13:09 [pubmed]
PHST- 2023/05/24 12:03 [entrez]
PHST- 2023/05/24 00:00 [pmc-release]
AID - v25i1e44330 [pii]
AID - 10.2196/44330 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 May 24;25:e44330. doi: 10.2196/44330.

PMID- 40063081
OWN - NLM
STAT- Publisher
LR  - 20250310
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Linking)
DP  - 2025 Mar 10
TI  - Application of unified health large language model evaluation framework to 
      In-Basket message replies: bridging qualitative and quantitative assessments.
LID - ocaf023 [pii]
LID - 10.1093/jamia/ocaf023 [doi]
AB  - OBJECTIVES: Large language models (LLMs) are increasingly utilized in healthcare, 
      transforming medical practice through advanced language processing capabilities. 
      However, the evaluation of LLMs predominantly relies on human qualitative 
      assessment, which is time-consuming, resource-intensive, and may be subject to 
      variability and bias. There is a pressing need for quantitative metrics to enable 
      scalable, objective, and efficient evaluation. MATERIALS AND METHODS: We propose 
      a unified evaluation framework that bridges qualitative and quantitative methods 
      to assess LLM performance in healthcare settings. This framework maps evaluation 
      aspects-such as linguistic quality, efficiency, content integrity, 
      trustworthiness, and usefulness-to both qualitative assessments and quantitative 
      metrics. We apply our approach to empirically evaluate the Epic In-Basket 
      feature, which uses LLM to generate patient message replies. RESULTS: The 
      empirical evaluation demonstrates that while Artificial Intelligence 
      (AI)-generated replies exhibit high fluency, clarity, and minimal toxicity, they 
      face challenges with coherence and completeness. Clinicians' manual decision to 
      use AI-generated drafts correlates strongly with quantitative metrics, suggesting 
      that quantitative metrics have the potential to reduce human effort in the 
      evaluation process and make it more scalable. DISCUSSION: Our study highlights 
      the potential of a unified evaluation framework that integrates qualitative and 
      quantitative methods, enabling scalable and systematic assessments of LLMs in 
      healthcare. Automated metrics streamline evaluation and monitoring processes, but 
      their effective use depends on alignment with human judgment, particularly for 
      aspects requiring contextual interpretation. As LLM applications expand, refining 
      evaluation strategies and fostering interdisciplinary collaboration will be 
      critical to maintaining high standards of accuracy, ethics, and regulatory 
      compliance. CONCLUSION: Our unified evaluation framework bridges the gap between 
      qualitative human assessments and automated quantitative metrics, enhancing the 
      reliability and scalability of LLM evaluations in healthcare. While automated 
      quantitative evaluations are not ready to fully replace qualitative human 
      evaluations, they can be used to enhance the process and, with relevant 
      benchmarks derived from the unified framework proposed here, they can be applied 
      to LLM monitoring and evaluation of updated versions of the original technology 
      evaluated using qualitative human standards.
CI  - © The Author(s) 2025. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For commercial 
      re-use, please contact reprints@oup.com for reprints and translation rights for 
      reprints. All other permissions can be obtained through our RightsLink service 
      via the Permissions link on the article page on our site—for further information 
      please contact journals.permissions@oup.com.
FAU - Hong, Chuan
AU  - Hong C
AUID- ORCID: 0000-0001-7056-9559
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
FAU - Chowdhury, Anand
AU  - Chowdhury A
AUID- ORCID: 0000-0001-5703-113X
AD  - Department of Medicine, Duke University School of Medicine, Durham, NC 27710, 
      United States.
FAU - Sorrentino, Anthony D
AU  - Sorrentino AD
AD  - Department of Medicine, Duke University School of Medicine, Durham, NC 27710, 
      United States.
FAU - Wang, Haoyuan
AU  - Wang H
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
FAU - Agrawal, Monica
AU  - Agrawal M
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
FAU - Bedoya, Armando
AU  - Bedoya A
AUID- ORCID: 0000-0001-6496-7024
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
AD  - Department of Medicine, Duke University School of Medicine, Durham, NC 27710, 
      United States.
FAU - Bessias, Sophia
AU  - Bessias S
AD  - Duke Clinical and Translational Science Institute, Duke University School of 
      Medicine, Durham, NC 27710, United States.
FAU - Economou-Zavlanos, Nicoleta J
AU  - Economou-Zavlanos NJ
AUID- ORCID: 0009-0000-4078-9809
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
FAU - Wong, Ian
AU  - Wong I
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
AD  - Department of Medicine, Duke University School of Medicine, Durham, NC 27710, 
      United States.
FAU - Pean, Christian
AU  - Pean C
AD  - Department of Medicine, Duke University School of Medicine, Durham, NC 27710, 
      United States.
FAU - Li, Fan
AU  - Li F
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
AD  - Department of Statistical Science, Duke University, Durham, NC 27710, United 
      States.
FAU - Pollak, Kathryn I
AU  - Pollak KI
AUID- ORCID: 0000-0002-5559-2416
AD  - Cancer Prevention and Control Research Program, Duke Cancer Institute, Durham, NC 
      27710, United States.
AD  - Department of Population Health Sciences, Duke University School of Medicine, 
      Durham, NC 27710, United States.
FAU - Poon, Eric G
AU  - Poon EG
AUID- ORCID: 0000-0002-7251-5842
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
AD  - Department of Medicine, Duke University School of Medicine, Durham, NC 27710, 
      United States.
FAU - Pencina, Michael J
AU  - Pencina MJ
AUID- ORCID: 0000-0001-5798-8855
AD  - Department of Biostatistics and Bioinformatics, Duke University School of 
      Medicine, Durham, NC 27710, United States.
LA  - eng
PT  - Journal Article
DEP - 20250310
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
OTO - NOTNLM
OT  - generative AI
OT  - healthcare
OT  - large language model
OT  - qualitative evaluation
OT  - quantitative evaluation
EDAT- 2025/03/10 12:31
MHDA- 2025/03/10 12:31
CRDT- 2025/03/10 11:53
PHST- 2024/04/04 00:00 [received]
PHST- 2025/01/26 00:00 [revised]
PHST- 2025/02/19 00:00 [accepted]
PHST- 2025/03/10 12:31 [medline]
PHST- 2025/03/10 12:31 [pubmed]
PHST- 2025/03/10 11:53 [entrez]
AID - 8068783 [pii]
AID - 10.1093/jamia/ocaf023 [doi]
PST - aheadofprint
SO  - J Am Med Inform Assoc. 2025 Mar 10:ocaf023. doi: 10.1093/jamia/ocaf023.

PMID- 37553439
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230810
LR  - 20241011
IS  - 2052-4463 (Electronic)
IS  - 2052-4463 (Linking)
VI  - 10
IP  - 1
DP  - 2023 Aug 8
TI  - ThoughtSource: A central hub for large language model reasoning data.
PG  - 528
LID - 10.1038/s41597-023-02433-3 [doi]
LID - 528
AB  - Large language models (LLMs) such as GPT-4 have recently demonstrated impressive 
      results across a wide range of tasks. LLMs are still limited, however, in that 
      they frequently fail at complex reasoning, their reasoning processes are opaque, 
      they are prone to 'hallucinate' facts, and there are concerns about their 
      underlying biases. Letting models verbalize reasoning steps as natural language, 
      a technique known as chain-of-thought prompting, has recently been proposed as a 
      way to address some of these issues. Here we present ThoughtSource, a 
      meta-dataset and software library for chain-of-thought (CoT) reasoning. The goal 
      of ThoughtSource is to improve future artificial intelligence systems by 
      facilitating qualitative understanding of CoTs, enabling empirical evaluations, 
      and providing training data. This first release of ThoughtSource integrates seven 
      scientific/medical, three general-domain and five math word question answering 
      datasets.
CI  - © 2023. Springer Nature Limited.
FAU - Ott, Simon
AU  - Ott S
AD  - Institute of Artificial Intelligence, Medical University of Vienna, Vienna, 
      Austria.
FAU - Hebenstreit, Konstantin
AU  - Hebenstreit K
AUID- ORCID: 0009-0005-4604-0635
AD  - Institute of Artificial Intelligence, Medical University of Vienna, Vienna, 
      Austria.
FAU - Liévin, Valentin
AU  - Liévin V
AD  - Section for Cognitive Systems, Technical University of Denmark, Lyngby, Denmark.
FAU - Hother, Christoffer Egeberg
AU  - Hother CE
AD  - Department of Clinical Immunology, Copenhagen University Hospital, Copenhagen, 
      Denmark.
FAU - Moradi, Milad
AU  - Moradi M
AD  - Institute of Artificial Intelligence, Medical University of Vienna, Vienna, 
      Austria.
FAU - Mayrhauser, Maximilian
AU  - Mayrhauser M
AD  - Institute of Artificial Intelligence, Medical University of Vienna, Vienna, 
      Austria.
FAU - Praas, Robert
AU  - Praas R
AD  - Institute of Artificial Intelligence, Medical University of Vienna, Vienna, 
      Austria.
AD  - School of Electrical Engineering and Computer Science, The Royal Institute of 
      Technology (KTH), Stockholm, Sweden.
FAU - Winther, Ole
AU  - Winther O
AD  - Section for Cognitive Systems, Technical University of Denmark, Lyngby, Denmark.
FAU - Samwald, Matthias
AU  - Samwald M
AUID- ORCID: 0000-0002-4855-2571
AD  - Institute of Artificial Intelligence, Medical University of Vienna, Vienna, 
      Austria. matthias.samwald@meduniwien.ac.at.
LA  - eng
PT  - Dataset
PT  - Journal Article
DEP - 20230808
PL  - England
TA  - Sci Data
JT  - Scientific data
JID - 101640192
SB  - IM
PMC - PMC10409727
COIS- The authors declare no competing interests.
EDAT- 2023/08/09 01:05
MHDA- 2023/08/10 06:42
PMCR- 2023/08/08
CRDT- 2023/08/08 23:23
PHST- 2023/02/28 00:00 [received]
PHST- 2023/07/31 00:00 [accepted]
PHST- 2023/08/10 06:42 [medline]
PHST- 2023/08/09 01:05 [pubmed]
PHST- 2023/08/08 23:23 [entrez]
PHST- 2023/08/08 00:00 [pmc-release]
AID - 10.1038/s41597-023-02433-3 [pii]
AID - 2433 [pii]
AID - 10.1038/s41597-023-02433-3 [doi]
PST - epublish
SO  - Sci Data. 2023 Aug 8;10(1):528. doi: 10.1038/s41597-023-02433-3.

PMID- 39001657
OWN - NLM
STAT- MEDLINE
DCOM- 20240823
LR  - 20240825
IS  - 1758-535X (Electronic)
IS  - 1079-5006 (Print)
IS  - 1079-5006 (Linking)
VI  - 79
IP  - 9
DP  - 2024 Sep 1
TI  - Enhancing Care for Older Adults and Dementia Patients With Large Language Models: 
      Proceedings of the National Institute on Aging-Artificial Intelligence & 
      Technology Collaboratory for Aging Research Symposium.
LID - 10.1093/gerona/glae176 [doi]
LID - glae176
AB  - Large Language Models (LLMs) stand on the brink of reshaping the field of aging 
      and dementia care, challenging the one-size-fits-all paradigm with their capacity 
      for precision medicine and individualized treatment strategies. The "Large 
      Pre-Trained Models with a Focus on AD/ADRD and Healthy Aging" symposium, 
      organized by the National Institute on Aging and the Johns Hopkins Artificial 
      Intelligence & Technology Collaboratory for Aging Research, served as a platform 
      for exploring this potential. The symposium brought together diverse experts to 
      discuss the integration of LLMs in aging and dementia care. They highlighted the 
      roles LLMs can play in clinical decision support and predictive analytics, while 
      also addressing critical ethical concerns including bias, privacy, and the 
      responsible use of artificial intelligence (AI). The discussions focused on the 
      need to balance technological advancement with ethical considerations in AI 
      deployment. In conclusion, the symposium projected a future where LLMs not only 
      revolutionize healthcare practices but also pose significant challenges that 
      require careful navigation.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of The 
      Gerontological Society of America. All rights reserved. For commercial re-use, 
      please contact reprints@oup.com for reprints and translation rights for reprints. 
      All other permissions can be obtained through our RightsLink service via the 
      Permissions link on the article page on our site—for further information please 
      contact journals.permissions@oup.com.
FAU - Abadir, Peter M
AU  - Abadir PM
AUID- ORCID: 0000-0002-8186-0066
AD  - Johns Hopkins Medicine, Johns Hopkins University, Baltimore, Maryland, USA.
AD  - Whiting School of Engineering, Johns Hopkins University, Baltimore, Maryland, 
      USA.
FAU - Battle, Alexis
AU  - Battle A
AD  - Whiting School of Engineering, Johns Hopkins University, Baltimore, Maryland, 
      USA.
FAU - Walston, Jeremy D
AU  - Walston JD
AD  - Johns Hopkins Medicine, Johns Hopkins University, Baltimore, Maryland, USA.
FAU - Chellappa, Rama
AU  - Chellappa R
AD  - Johns Hopkins Medicine, Johns Hopkins University, Baltimore, Maryland, USA.
AD  - Whiting School of Engineering, Johns Hopkins University, Baltimore, Maryland, 
      USA.
LA  - eng
GR  - P30 AG073104/AG/NIA NIH HHS/United States
GR  - P30AG073104/NH/NIH HHS/United States
PT  - Journal Article
PL  - United States
TA  - J Gerontol A Biol Sci Med Sci
JT  - The journals of gerontology. Series A, Biological sciences and medical sciences
JID - 9502837
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Dementia/therapy
MH  - Aged
MH  - *National Institute on Aging (U.S.)
MH  - United States
MH  - Aging/physiology
MH  - Precision Medicine/methods
MH  - Congresses as Topic
PMC - PMC11341983
OTO - NOTNLM
OT  - Alzheimer’s disease
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Healthy aging
OT  - Large language models
COIS- None.
EDAT- 2024/07/13 07:43
MHDA- 2024/08/23 06:41
PMCR- 2025/07/13
CRDT- 2024/07/13 03:42
PHST- 2024/03/29 00:00 [received]
PHST- 2025/07/13 00:00 [pmc-release]
PHST- 2024/08/23 06:41 [medline]
PHST- 2024/07/13 07:43 [pubmed]
PHST- 2024/07/13 03:42 [entrez]
AID - 7713113 [pii]
AID - glae176 [pii]
AID - 10.1093/gerona/glae176 [doi]
PST - ppublish
SO  - J Gerontol A Biol Sci Med Sci. 2024 Sep 1;79(9):glae176. doi: 
      10.1093/gerona/glae176.

PMID- 39365643
OWN - NLM
STAT- MEDLINE
DCOM- 20241004
LR  - 20241023
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Oct 4
TI  - Engine of Innovation in Hospital Pharmacy: Applications and Reflections of 
      ChatGPT.
PG  - e51635
LID - 10.2196/51635 [doi]
LID - e51635
AB  - Hospital pharmacy plays an important role in ensuring medical care quality and 
      safety, especially in the area of drug information retrieval, therapy guidance, 
      and drug-drug interaction management. ChatGPT is a powerful artificial 
      intelligence language model that can generate natural-language texts. Here, we 
      explored the applications and reflections of ChatGPT in hospital pharmacy, where 
      it may enhance the quality and efficiency of pharmaceutical care. We also 
      explored ChatGPT's prospects in hospital pharmacy and discussed its working 
      principle, diverse applications, and practical cases in daily operations and 
      scientific research. Meanwhile, the challenges and limitations of ChatGPT, such 
      as data privacy, ethical issues, bias and discrimination, and human oversight, 
      are discussed. ChatGPT is a promising tool for hospital pharmacy, but it requires 
      careful evaluation and validation before it can be integrated into clinical 
      practice. Some suggestions for future research and development of ChatGPT in 
      hospital pharmacy are provided.
CI  - ©Xingang Li, Heng Guo, Dandan Li, Yingming Zheng. Originally published in the 
      Journal of Medical Internet Research (https://www.jmir.org), 04.10.2024.
FAU - Li, Xingang
AU  - Li X
AUID- ORCID: 0000-0001-6726-9571
AD  - Department of Pharmacy, Beijing Friendship Hospital, Capital Medical University, 
      Beijing, China.
FAU - Guo, Heng
AU  - Guo H
AUID- ORCID: 0009-0000-1982-9722
AD  - Department of Pharmacy, Beijing Friendship Hospital, Capital Medical University, 
      Beijing, China.
FAU - Li, Dandan
AU  - Li D
AUID- ORCID: 0000-0002-1082-4623
AD  - Department of Pharmacy, Beijing Friendship Hospital, Capital Medical University, 
      Beijing, China.
FAU - Zheng, Yingming
AU  - Zheng Y
AUID- ORCID: 0000-0002-6721-923X
AD  - Department of Pharmacy, Beijing Friendship Hospital, Capital Medical University, 
      Beijing, China.
LA  - eng
PT  - Journal Article
DEP - 20241004
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - *Pharmacy Service, Hospital
MH  - Humans
MH  - Artificial Intelligence
MH  - Natural Language Processing
PMC - PMC11489799
OTO - NOTNLM
OT  - ChatGPT
OT  - drug information
OT  - drug interaction
OT  - drug therapy
OT  - hospital pharmacy
OT  - innovation
OT  - medical care quality
OT  - natural language processing
OT  - pharmaceutical care
OT  - pharmacy
OT  - quality
OT  - safety
OT  - scientific research
OT  - tool
COIS- Conflicts of Interest: None declared.
EDAT- 2024/10/04 12:43
MHDA- 2024/10/04 18:59
PMCR- 2024/10/04
CRDT- 2024/10/04 11:53
PHST- 2023/08/06 00:00 [received]
PHST- 2024/09/06 00:00 [accepted]
PHST- 2024/04/09 00:00 [revised]
PHST- 2024/10/04 18:59 [medline]
PHST- 2024/10/04 12:43 [pubmed]
PHST- 2024/10/04 11:53 [entrez]
PHST- 2024/10/04 00:00 [pmc-release]
AID - v26i1e51635 [pii]
AID - 10.2196/51635 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Oct 4;26:e51635. doi: 10.2196/51635.

PMID- 39228726
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241023
DP  - 2024 Aug 19
TI  - Generative Large Language Models in Electronic Health Records for Patient Care 
      Since 2023: A Systematic Review.
LID - 2024.08.11.24311828 [pii]
LID - 10.1101/2024.08.11.24311828 [doi]
AB  - BACKGROUND: Generative Large language models (LLMs) represent a significant 
      advancement in natural language processing, achieving state-of-the-art 
      performance across various tasks. However, their application in clinical settings 
      using real electronic health records (EHRs) is still rare and presents numerous 
      challenges. OBJECTIVE: This study aims to systematically review the use of 
      generative LLMs, and the effectiveness of relevant techniques in patient 
      care-related topics involving EHRs, summarize the challenges faced, and suggest 
      future directions. METHODS: A Boolean search for peer-reviewed articles was 
      conducted on May 19(th), 2024 using PubMed and Web of Science to include research 
      articles published since 2023, which was one month after the release of ChatGPT. 
      The search results were deduplicated. Multiple reviewers, including biomedical 
      informaticians, computer scientists, and a physician, screened the publications 
      for eligibility and conducted data extraction. Only studies utilizing generative 
      LLMs to analyze real EHR data were included. We summarized the use of prompt 
      engineering, fine-tuning, multimodal EHR data, and evaluation matrices. 
      Additionally, we identified current challenges in applying LLMs in clinical 
      settings as reported by the included studies and proposed future directions. 
      RESULTS: The initial search identified 6,328 unique studies, with 76 studies 
      included after eligibility screening. Of these, 67 studies (88.2%) employed 
      zero-shot prompting, five of them reported 100% accuracy on five specific 
      clinical tasks. Nine studies used advanced prompting strategies; four tested 
      these strategies experimentally, finding that prompt engineering improved 
      performance, with one study noting a non-linear relationship between the number 
      of examples in a prompt and performance improvement. Eight studies explored 
      fine-tuning generative LLMs, all reported performance improvements on specific 
      tasks, but three of them noted potential performance degradation after 
      fine-tuning on certain tasks. Only two studies utilized multimodal data, which 
      improved LLM-based decision-making and enabled accurate rare disease diagnosis 
      and prognosis. The studies employed 55 different evaluation metrics for 22 
      purposes, such as correctness, completeness, and conciseness. Two studies 
      investigated LLM bias, with one detecting no bias and the other finding that male 
      patients received more appropriate clinical decision-making suggestions. Six 
      studies identified hallucinations, such as fabricating patient names in 
      structured thyroid ultrasound reports. Additional challenges included but were 
      not limited to the impersonal tone of LLM consultations, which made patients 
      uncomfortable, and the difficulty patients had in understanding LLM responses. 
      CONCLUSION: Our review indicates that few studies have employed advanced 
      computational techniques to enhance LLM performance. The diverse evaluation 
      metrics used highlight the need for standardization. LLMs currently cannot 
      replace physicians due to challenges such as bias, hallucinations, and impersonal 
      responses.
FAU - Du, Xinsong
AU  - Du X
AUID- ORCID: 0000-0003-3713-3264
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, Massachusetts 02115.
AD  - Department of Medicine, Harvard Medical School, Boston, Massachusetts 02115.
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, 
      Massachusetts 02115.
FAU - Zhou, Zhengyang
AU  - Zhou Z
AD  - Department of Computer Science, Brandeis University, Waltham, MA 02453.
FAU - Wang, Yifei
AU  - Wang Y
AD  - Department of Computer Science, Brandeis University, Waltham, MA 02453.
FAU - Chuang, Ya-Wen
AU  - Chuang YW
AD  - Division of Nephrology, Department of Internal Medicine, Taichung Veterans 
      General Hospital, Taichung, Taiwan, 407219.
AD  - Department of Post-Baccalaureate Medicine, College of Medicine, National Chung 
      Hsing University, Taichung, Taiwan, 402202.
AD  - School of Medicine, College of Medicine, China Medical University, Taichung, 
      Taiwan, 404328.
FAU - Yang, Richard
AU  - Yang R
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, Massachusetts 02115.
AD  - Department of Medicine, Harvard Medical School, Boston, Massachusetts 02115.
FAU - Zhang, Wenyu
AU  - Zhang W
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, Massachusetts 02115.
AD  - Department of Medicine, Harvard Medical School, Boston, Massachusetts 02115.
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, 
      Massachusetts 02115.
FAU - Wang, Xinyi
AU  - Wang X
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, Massachusetts 02115.
AD  - Department of Medicine, Harvard Medical School, Boston, Massachusetts 02115.
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, 
      Massachusetts 02115.
FAU - Zhang, Rui
AU  - Zhang R
AUID- ORCID: 0000-0001-8258-3585
AD  - Division of Computational Health Sciences, University of Minnesota, Minneapolis, 
      MN 55455.
FAU - Hong, Pengyu
AU  - Hong P
AUID- ORCID: 0000-0002-3177-2754
AD  - Department of Computer Science, Brandeis University, Waltham, MA 02453.
FAU - Bates, David W
AU  - Bates DW
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, Massachusetts 02115.
AD  - Department of Medicine, Harvard Medical School, Boston, Massachusetts 02115.
AD  - Department of Health Policy and Management, Harvard T.H. Chan School of Public 
      Health, Boston, MA 02115.
FAU - Zhou, Li
AU  - Zhou L
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, Massachusetts 02115.
AD  - Department of Medicine, Harvard Medical School, Boston, Massachusetts 02115.
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, 
      Massachusetts 02115.
LA  - eng
GR  - R01 AG080429/AG/NIA NIH HHS/United States
GR  - R01 LM014239/LM/NLM NIH HHS/United States
GR  - R44 AG081006/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240819
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11370524
EDAT- 2024/09/04 06:42
MHDA- 2024/09/04 06:43
PMCR- 2024/09/03
CRDT- 2024/09/04 04:27
PHST- 2024/09/04 06:42 [pubmed]
PHST- 2024/09/04 06:43 [medline]
PHST- 2024/09/04 04:27 [entrez]
PHST- 2024/09/03 00:00 [pmc-release]
AID - 2024.08.11.24311828 [pii]
AID - 10.1101/2024.08.11.24311828 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Aug 19:2024.08.11.24311828. doi: 
      10.1101/2024.08.11.24311828.

PMID- 39823022
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250129
IS  - 2169-7574 (Print)
IS  - 2169-7574 (Electronic)
IS  - 2169-7574 (Linking)
VI  - 13
IP  - 1
DP  - 2025 Jan
TI  - Artificial Intelligence Scribe and Large Language Model Technology in Healthcare 
      Documentation: Advantages, Limitations, and Recommendations.
PG  - e6450
LID - 10.1097/GOX.0000000000006450 [doi]
LID - e6450
AB  - Artificial intelligence (AI) scribe applications in the healthcare community are 
      in the early adoption phase and offer unprecedented efficiency for medical 
      documentation. They typically use an application programming interface with a 
      large language model (LLM), for example, generative pretrained transformer 4. 
      They use automatic speech recognition on the physician-patient interaction, 
      generating a full medical note for the encounter, together with a draft follow-up 
      e-mail for the patient and, often, recommendations, all within seconds or 
      minutes. This provides physicians with increased cognitive freedom during medical 
      encounters due to less time needed interfacing with electronic medical records. 
      However, careful proofreading of the AI-generated language by the physician 
      signing the note is essential. Insidious and potentially significant errors of 
      omission, fabrication, or substitution may occur. The neural network algorithms 
      of LLMs have unpredictable sensitivity to user input and inherent variability in 
      their output. LLMs are unconstrained by established medical knowledge or rules. 
      As they gain increasing levels of access to large corpora of medical records, the 
      explosion of discovered knowledge comes with large potential risks, including to 
      patient privacy, and potential bias in algorithms. Medical AI developers should 
      use robust regulatory oversights, adhere to ethical guidelines, correct bias in 
      algorithms, and improve detection and correction of deviations from the intended 
      output.
CI  - Copyright © 2025 The Authors. Published by Wolters Kluwer Health, Inc. on behalf 
      of The American Society of Plastic Surgeons.
FAU - Mess, Sarah A
AU  - Mess SA
AD  - From Sarah A. Mess, M. D., LLC, Columbia, MD.
AD  - Department of Plastic Surgery, Georgetown University Clinical Faculty, 
      Washington, DC.
AD  - Department of Plastic Surgery, Johns Hopkins Clinical Instructor, Baltimore, MD.
FAU - Mackey, Alison J
AU  - Mackey AJ
AD  - Department of Linguistics, Georgetown University, Washington, DC.
FAU - Yarowsky, David E
AU  - Yarowsky DE
AD  - Department of Computer Science, Johns Hopkins University, Baltimore, MD.
LA  - eng
PT  - Journal Article
DEP - 20250116
PL  - United States
TA  - Plast Reconstr Surg Glob Open
JT  - Plastic and reconstructive surgery. Global open
JID - 101622231
PMC - PMC11737491
COIS- Dr. Mess is on the speaker’s bureau for Allergan and Sciton. She has consulted 
      for Becton, Dickinson, and Company once in the past 2 years and Medical Mutual 
      Liability Insurance Society of Maryland twice in the past year. The other authors 
      have no financial interest to declare in relation to the content of this article.
EDAT- 2025/01/17 18:23
MHDA- 2025/01/17 18:24
PMCR- 2025/01/16
CRDT- 2025/01/17 15:03
PHST- 2024/08/25 00:00 [received]
PHST- 2024/11/11 00:00 [accepted]
PHST- 2025/01/17 18:24 [medline]
PHST- 2025/01/17 18:23 [pubmed]
PHST- 2025/01/17 15:03 [entrez]
PHST- 2025/01/16 00:00 [pmc-release]
AID - GOX-D-24-00947 [pii]
AID - 10.1097/GOX.0000000000006450 [doi]
PST - epublish
SO  - Plast Reconstr Surg Glob Open. 2025 Jan 16;13(1):e6450. doi: 
      10.1097/GOX.0000000000006450. eCollection 2025 Jan.

PMID- 37480515
OWN - NLM
STAT- MEDLINE
DCOM- 20230821
LR  - 20240123
IS  - 1573-689X (Electronic)
IS  - 0148-5598 (Print)
IS  - 0148-5598 (Linking)
VI  - 47
IP  - 1
DP  - 2023 Jul 22
TI  - Non-response Bias in Social Risk Factor Screening Among Adult Emergency 
      Department Patients.
PG  - 78
LID - 10.1007/s10916-023-01975-8 [doi]
AB  - Healthcare organizations increasingly use screening questionnaires to assess 
      patients' social factors, but non-response may contribute to selection bias. This 
      study assessed differences between respondents and those refusing participation 
      in a social factor screening. We used a cross-sectional approach with logistic 
      regression models to measure the association between subject characteristics and 
      social factor screening questionnaire participation. The study subjects were 
      patients from a mid-western state safety-net hospital's emergency department. 
      Subjects' inclusion criteria were: (1) ≥ 18 years old, (2) spoke English or 
      Spanish, and (3) able to complete a self-administered questionnaire. We 
      classified subjects that consented and answered the screening questionnaire in 
      full as respondents. All others were non-respondents. Using natural language 
      processing, we linked all subjects' participation status to demographic 
      characteristics, clinical data, an area-level deprivation measure, and social 
      risk factors extracted from clinical notes. We found that nearly 6 out of every 
      10 subjects approached (59.9%), consented, and completed the questionnaire. 
      Subjects with prior documentation of financial insecurity were 22% less likely to 
      respond to the screening questionnaire (marginal effect = -22.40; 95% confidence 
      interval (CI) = -41.16, -3.63; p = 0.019). No other factors were significantly 
      associated with response. This study uniquely contributes to the growing social 
      determinants of health literature by confirming that selection bias may exist 
      within social factor screening practices and research studies.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Vest, Joshua R
AU  - Vest JR
AUID- ORCID: 0000-0002-7226-9688
AD  - Department of Health Policy & Management, Indiana University Richard M. Fairbanks 
      School of Public Health - Indianapolis, 1050 Wishard Blvd, Indianapolis, IN, 
      46202, USA.
AD  - Center for Biomedical Informatics, Regenstrief Institute, Indianapolis, IN, 
      46202, USA.
FAU - Mazurenko, Olena
AU  - Mazurenko O
AUID- ORCID: 0000-0002-1003-9262
AD  - Department of Health Policy & Management, Indiana University Richard M. Fairbanks 
      School of Public Health - Indianapolis, 1050 Wishard Blvd, Indianapolis, IN, 
      46202, USA. omazuren@iu.edu.
LA  - eng
GR  - R01 HS028008/HS/AHRQ HHS/United States
PT  - Journal Article
DEP - 20230722
PL  - United States
TA  - J Med Syst
JT  - Journal of medical systems
JID - 7806056
SB  - IM
MH  - Humans
MH  - Adult
MH  - Adolescent
MH  - *Documentation
MH  - *Emergency Service, Hospital
MH  - Language
MH  - Logistic Models
MH  - Natural Language Processing
PMC - PMC10439727
MID - NIHMS1922222
OTO - NOTNLM
OT  - Bias
OT  - Emergency department
OT  - Social determinants of health
OT  - Surveys
COIS- COMPETING INTERESTS Joshua Vest is a founder and equity holder in Uppstroms, Inc, 
      a health information technology company. Olena Mazurenko has no conflicts to 
      declare.
EDAT- 2023/07/22 21:06
MHDA- 2023/08/21 06:42
PMCR- 2024/01/22
CRDT- 2023/07/22 11:14
PHST- 2022/12/07 00:00 [received]
PHST- 2023/07/10 00:00 [accepted]
PHST- 2023/08/21 06:42 [medline]
PHST- 2023/07/22 21:06 [pubmed]
PHST- 2023/07/22 11:14 [entrez]
PHST- 2024/01/22 00:00 [pmc-release]
AID - 10.1007/s10916-023-01975-8 [pii]
AID - 10.1007/s10916-023-01975-8 [doi]
PST - epublish
SO  - J Med Syst. 2023 Jul 22;47(1):78. doi: 10.1007/s10916-023-01975-8.

PMID- 38224784
OWN - NLM
STAT- MEDLINE
DCOM- 20240311
LR  - 20240916
IS  - 1097-6825 (Electronic)
IS  - 0091-6749 (Print)
IS  - 0091-6749 (Linking)
VI  - 153
IP  - 3
DP  - 2024 Mar
TI  - Proceedings from the inaugural Artificial Intelligence in Primary Immune 
      Deficiencies (AIPID) conference.
PG  - 637-642
LID - S0091-6749(24)00033-2 [pii]
LID - 10.1016/j.jaci.2024.01.002 [doi]
AB  - Here, we summarize the proceedings of the inaugural Artificial Intelligence in 
      Primary Immune Deficiencies conference, during which experts and advocates 
      gathered to advance research into the applications of artificial intelligence 
      (AI), machine learning, and other computational tools in the diagnosis and 
      management of inborn errors of immunity (IEIs). The conference focused on the key 
      themes of expediting IEI diagnoses, challenges in data collection, roles of 
      natural language processing and large language models in interpreting electronic 
      health records, and ethical considerations in implementation. Innovative AI-based 
      tools trained on electronic health records and claims databases have discovered 
      new patterns of warning signs for IEIs, facilitating faster diagnoses and 
      enhancing patient outcomes. Challenges in training AIs persist on account of data 
      limitations, especially in cases of rare diseases, overlapping phenotypes, and 
      biases inherent in current data sets. Furthermore, experts highlighted the 
      significance of ethical considerations, data protection, and the necessity for 
      open science principles. The conference delved into regulatory frameworks, equity 
      in access, and the imperative for collaborative efforts to overcome these 
      obstacles and harness the transformative potential of AI. Concerted efforts to 
      successfully integrate AI into daily clinical immunology practice are still 
      needed.
CI  - Copyright © 2024 American Academy of Allergy, Asthma & Immunology. Published by 
      Elsevier Inc. All rights reserved.
FAU - Rivière, Jacques G
AU  - Rivière JG
AD  - Infection and Immunity in Pediatric Patients Research Group, Vall d'Hebron 
      Barcelona Hospital Campus, Barcelona, Spain; Pediatric Infectious Diseases and 
      Immunodeficiencies Unit, Hospital Infantil i de la Dona, Vall d'Hebron Barcelona 
      Hospital Campus, Barcelona, Spain; Jeffrey Modell Diagnostic and Research Center 
      for Primary Immunodeficiencies, Barcelona, Spain; Universitat Autònoma de 
      Barcelona, Barcelona, Spain.
FAU - Soler Palacín, Pere
AU  - Soler Palacín P
AD  - Infection and Immunity in Pediatric Patients Research Group, Vall d'Hebron 
      Barcelona Hospital Campus, Barcelona, Spain; Pediatric Infectious Diseases and 
      Immunodeficiencies Unit, Hospital Infantil i de la Dona, Vall d'Hebron Barcelona 
      Hospital Campus, Barcelona, Spain; Jeffrey Modell Diagnostic and Research Center 
      for Primary Immunodeficiencies, Barcelona, Spain; Universitat Autònoma de 
      Barcelona, Barcelona, Spain.
FAU - Butte, Manish J
AU  - Butte MJ
AD  - Division of Immunology, Allergy, and Rheumatology, Department of Pediatrics, 
      University of California Los Angeles, Los Angeles, Calif; Department of 
      Microbiology, Immunology, and Molecular Genetics, University of California Los 
      Angeles, Los Angeles, Calif; Department of Human Genetics, University of 
      California Los Angeles, Los Angeles, Calif. Electronic address: 
      mbutte@mednet.ucla.edu.
LA  - eng
GR  - R01 AI153827/AI/NIAID NIH HHS/United States
PT  - Journal Article
DEP - 20240113
PL  - United States
TA  - J Allergy Clin Immunol
JT  - The Journal of allergy and clinical immunology
JID - 1275002
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Machine Learning
MH  - Natural Language Processing
MH  - Data Collection
MH  - *Primary Immunodeficiency Diseases
PMC - PMC11402388
MID - NIHMS2020912
OTO - NOTNLM
OT  - Artificial intelligence
OT  - diagnosis
OT  - electronic health records
OT  - ethics
OT  - inborn errors of immunity
OT  - large language models
OT  - machine learning
OT  - natural language processing
COIS- DISCLOSURE STATEMENT Disclosure of potential conflict of interest: The authors 
      declare that they have no relevant conflicts of interest.
EDAT- 2024/01/16 00:42
MHDA- 2024/03/11 06:42
PMCR- 2024/09/15
CRDT- 2024/01/15 19:31
PHST- 2023/12/11 00:00 [received]
PHST- 2024/01/09 00:00 [revised]
PHST- 2024/01/11 00:00 [accepted]
PHST- 2024/03/11 06:42 [medline]
PHST- 2024/01/16 00:42 [pubmed]
PHST- 2024/01/15 19:31 [entrez]
PHST- 2024/09/15 00:00 [pmc-release]
AID - S0091-6749(24)00033-2 [pii]
AID - 10.1016/j.jaci.2024.01.002 [doi]
PST - ppublish
SO  - J Allergy Clin Immunol. 2024 Mar;153(3):637-642. doi: 10.1016/j.jaci.2024.01.002. 
      Epub 2024 Jan 13.

PMID- 38642997
OWN - NLM
STAT- MEDLINE
DCOM- 20240422
LR  - 20241231
IS  - 2044-6055 (Electronic)
IS  - 2044-6055 (Linking)
VI  - 14
IP  - 4
DP  - 2024 Apr 19
TI  - Distributions of recorded pain in mental health records: a natural language 
      processing based study.
PG  - e079923
LID - 10.1136/bmjopen-2023-079923 [doi]
LID - e079923
AB  - OBJECTIVE: The objective of this study is to determine demographic and diagnostic 
      distributions of physical pain recorded in clinical notes of a mental health 
      electronic health records database by using natural language processing and 
      examine the overlap in recorded physical pain between primary and secondary care. 
      DESIGN, SETTING AND PARTICIPANTS: The data were extracted from an anonymised 
      version of the electronic health records of a large secondary mental healthcare 
      provider serving a catchment of 1.3 million residents in south London. These 
      included patients under active referral, aged 18+ at the index date of 1 July 
      2018 and having at least one clinical document (≥30 characters) between 1 July 
      2017 and 1 July 2019. This cohort was compared with linked primary care records 
      from one of the four local government areas. OUTCOME: The primary outcome of 
      interest was the presence of recorded physical pain within the clinical notes of 
      the patients, not including psychological or metaphorical pain. RESULTS: A total 
      of 27 211 patients were retrieved. Of these, 52% (14,202) had narrative text 
      containing relevant mentions of physical pain. Older patients (OR 1.17, 95% CI 
      1.15 to 1.19), females (OR 1.42, 95% CI 1.35 to 1.49), Asians (OR 1.30, 95% CI 
      1.16 to 1.45) or black (OR 1.49, 95% CI 1.40 to 1.59) ethnicities, living in 
      deprived neighbourhoods (OR 1.64, 95% CI 1.55 to 1.73) showed higher odds of 
      recorded pain. Patients with severe mental illnesses were found to be less likely 
      to report pain (OR 0.43, 95% CI 0.41 to 0.46, p<0.001). 17% of the cohort from 
      secondary care also had records from primary care. CONCLUSION: The findings of 
      this study show sociodemographic and diagnostic differences in recorded pain. 
      Specifically, lower documentation across certain groups indicates the need for 
      better screening protocols and training on recognising varied pain presentations. 
      Additionally, targeting improved detection of pain for minority and disadvantaged 
      groups by care providers can promote health equity.
CI  - © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY. Published 
      by BMJ.
FAU - Chaturvedi, Jaya
AU  - Chaturvedi J
AUID- ORCID: 0000-0002-6359-9853
AD  - Institute of Psychiatry, Psychology and Neuroscience, King's College, London, UK 
      jaya.1.chaturvedi@kcl.ac.uk.
FAU - Stewart, Robert
AU  - Stewart R
AD  - Institute of Psychiatry, Psychology and Neuroscience, King's College, London, UK.
AD  - South London and Maudsley NHS Foundation Trust, London, UK.
FAU - Ashworth, Mark
AU  - Ashworth M
AUID- ORCID: 0000-0001-6514-9904
AD  - School of Population Health & Environmental Sciences, King's College, London, UK.
FAU - Roberts, Angus
AU  - Roberts A
AD  - Institute of Psychiatry, Psychology and Neuroscience, King's College, London, UK.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240419
PL  - England
TA  - BMJ Open
JT  - BMJ open
JID - 101552874
SB  - IM
MH  - Female
MH  - Humans
MH  - *Mental Health
MH  - Natural Language Processing
MH  - Health Promotion
MH  - *Mental Disorders/epidemiology
MH  - Pain/epidemiology
MH  - Electronic Health Records
PMC - PMC11033644
OTO - NOTNLM
OT  - Chronic Pain
OT  - EPIDEMIOLOGY
OT  - Electronic Health Records
OT  - MENTAL HEALTH
OT  - Natural Language Processing
COIS- Competing interests: This paper represents independent research part-funded by 
      the National Institute for Health Research (NIHR) Biomedical Research Centre at 
      South London and Maudsley NHS Foundation Trust and King’s College London. The 
      views expressed are those of the authors and not necessarily those of the NHS, 
      the NIHR or the Department of Health and Social Care. The funders had no role in 
      study design, data collection and analysis, decision to publish or preparation of 
      the manuscript.
EDAT- 2024/04/21 00:43
MHDA- 2024/04/22 06:43
PMCR- 2024/04/19
CRDT- 2024/04/20 21:02
PHST- 2024/04/22 06:43 [medline]
PHST- 2024/04/21 00:43 [pubmed]
PHST- 2024/04/20 21:02 [entrez]
PHST- 2024/04/19 00:00 [pmc-release]
AID - bmjopen-2023-079923 [pii]
AID - 10.1136/bmjopen-2023-079923 [doi]
PST - epublish
SO  - BMJ Open. 2024 Apr 19;14(4):e079923. doi: 10.1136/bmjopen-2023-079923.

PMID- 39953146
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250218
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 8
IP  - 1
DP  - 2025 Feb 14
TI  - Improving medical machine learning models with generative balancing for equity 
      and excellence.
PG  - 100
LID - 10.1038/s41746-025-01438-z [doi]
LID - 100
AB  - Applying machine learning to clinical outcome prediction is challenging due to 
      imbalanced datasets and sensitive tasks that contain rare yet critical outcomes 
      and where equitable treatment across diverse patient groups is essential. Despite 
      attempts, biases in predictions persist, driven by disparities in representation 
      and exacerbated by the scarcity of positive labels, perpetuating health 
      inequities. This paper introduces FairPlay, a synthetic data generation approach 
      leveraging large language models, to address these issues. FairPlay enhances 
      algorithmic performance and reduces bias by creating realistic, anonymous 
      synthetic patient data that improves representation and augments dataset patterns 
      while preserving privacy. Through experiments on multiple datasets, we 
      demonstrate that FairPlay boosts mortality prediction performance across diverse 
      subgroups, achieving up to a 21% improvement in F1 Score without requiring 
      additional data or altering downstream training pipelines. Furthermore, FairPlay 
      consistently reduces subgroup performance gaps, as shown by universal 
      improvements in performance and fairness metrics across four experimental setups.
CI  - © 2025. The Author(s).
FAU - Theodorou, Brandon
AU  - Theodorou B
AD  - University of Illinois at Urbana-Champaign, Urbana, IL, USA.
AD  - Keiji AI, Seattle, USA.
FAU - Danek, Benjamin
AU  - Danek B
AD  - University of Illinois at Urbana-Champaign, Urbana, IL, USA.
AD  - Keiji AI, Seattle, USA.
FAU - Tummala, Venkat
AU  - Tummala V
AD  - University of Illinois at Urbana-Champaign, Urbana, IL, USA.
FAU - Kumar, Shivam Pankaj
AU  - Kumar SP
AD  - University of Illinois at Urbana-Champaign, Urbana, IL, USA.
FAU - Malin, Bradley
AU  - Malin B
AD  - Vanderbilt University, Nashville, TN, USA.
AD  - Vanderbilt University Medical Center, Nashville, USA.
FAU - Sun, Jimeng
AU  - Sun J
AD  - University of Illinois at Urbana-Champaign, Urbana, IL, USA. jimeng@illinois.edu.
LA  - eng
GR  - SCH-2205289/National Science Foundation, USA/
GR  - SCH-2205289/National Science Foundation, USA/
PT  - Journal Article
DEP - 20250214
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC11828851
COIS- Competing interests: The authors declare no competing interests.
EDAT- 2025/02/15 15:10
MHDA- 2025/02/15 15:11
PMCR- 2025/02/14
CRDT- 2025/02/14 23:22
PHST- 2024/10/12 00:00 [received]
PHST- 2025/01/05 00:00 [accepted]
PHST- 2025/02/15 15:11 [medline]
PHST- 2025/02/15 15:10 [pubmed]
PHST- 2025/02/14 23:22 [entrez]
PHST- 2025/02/14 00:00 [pmc-release]
AID - 10.1038/s41746-025-01438-z [pii]
AID - 1438 [pii]
AID - 10.1038/s41746-025-01438-z [doi]
PST - epublish
SO  - NPJ Digit Med. 2025 Feb 14;8(1):100. doi: 10.1038/s41746-025-01438-z.

PMID- 38688841
OWN - NLM
STAT- MEDLINE
DCOM- 20240506
LR  - 20240523
IS  - 2291-5222 (Electronic)
IS  - 2291-5222 (Linking)
VI  - 12
DP  - 2024 May 6
TI  - The Evaluation of Generative AI Should Include Repetition to Assess Stability.
PG  - e57978
LID - 10.2196/57978 [doi]
LID - e57978
AB  - The increasing interest in the potential applications of generative artificial 
      intelligence (AI) models like ChatGPT in health care has prompted numerous 
      studies to explore its performance in various medical contexts. However, 
      evaluating ChatGPT poses unique challenges due to the inherent randomness in its 
      responses. Unlike traditional AI models, ChatGPT generates different responses 
      for the same input, making it imperative to assess its stability through 
      repetition. This commentary highlights the importance of including repetition in 
      the evaluation of ChatGPT to ensure the reliability of conclusions drawn from its 
      performance. Similar to biological experiments, which often require multiple 
      repetitions for validity, we argue that assessing generative AI models like 
      ChatGPT demands a similar approach. Failure to acknowledge the impact of 
      repetition can lead to biased conclusions and undermine the credibility of 
      research findings. We urge researchers to incorporate appropriate repetition in 
      their studies from the outset and transparently report their methods to enhance 
      the robustness and reproducibility of findings in this rapidly evolving field.
CI  - ©Lingxuan Zhu, Weiming Mou, Chenglin Hong, Tao Yang, Yancheng Lai, Chang Qi, Anqi 
      Lin, Jian Zhang, Peng Luo. Originally published in JMIR mHealth and uHealth 
      (https://mhealth.jmir.org), 06.05.2024.
FAU - Zhu, Lingxuan
AU  - Zhu L
AUID- ORCID: 0009-0001-9077-408X
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 
      Guangzhou, China.
FAU - Mou, Weiming
AU  - Mou W
AUID- ORCID: 0009-0007-1089-6516
AD  - Department of Urology, Shanghai General Hospital, Shanghai Jiao Tong University 
      School of Medicine, Shanghai, China.
FAU - Hong, Chenglin
AU  - Hong C
AUID- ORCID: 0009-0009-3565-3486
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 
      Guangzhou, China.
FAU - Yang, Tao
AU  - Yang T
AUID- ORCID: 0009-0007-5246-3284
AD  - Department of Medical Oncology, National Cancer Center/National Clinical Research 
      Center for Cancer/Cancer Hospital, Chinese Academy of Medical Sciences and Peking 
      Union Medical College, Beijing, China.
FAU - Lai, Yancheng
AU  - Lai Y
AUID- ORCID: 0009-0004-8444-7535
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 
      Guangzhou, China.
FAU - Qi, Chang
AU  - Qi C
AUID- ORCID: 0009-0005-3840-550X
AD  - Institute of Logic and Computation, TU Wien, Austria.
FAU - Lin, Anqi
AU  - Lin A
AUID- ORCID: 0000-0002-6324-0410
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 
      Guangzhou, China.
FAU - Zhang, Jian
AU  - Zhang J
AUID- ORCID: 0000-0001-7217-0111
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 
      Guangzhou, China.
FAU - Luo, Peng
AU  - Luo P
AUID- ORCID: 0000-0002-8215-2045
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 
      Guangzhou, China.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240506
PL  - Canada
TA  - JMIR Mhealth Uhealth
JT  - JMIR mHealth and uHealth
JID - 101624439
SB  - IM
CON - JMIR Mhealth Uhealth. 12:e51526.
MH  - Humans
MH  - *Artificial Intelligence/trends/standards
MH  - Reproducibility of Results
PMC - PMC11106698
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - generative AI
OT  - health care
OT  - large language model
COIS- Conflicts of Interest: None declared.
EDAT- 2024/05/01 01:48
MHDA- 2024/05/06 19:14
PMCR- 2024/05/06
CRDT- 2024/04/30 22:12
PHST- 2024/03/01 00:00 [received]
PHST- 2024/04/30 00:00 [accepted]
PHST- 2024/05/06 19:14 [medline]
PHST- 2024/05/01 01:48 [pubmed]
PHST- 2024/04/30 22:12 [entrez]
PHST- 2024/05/06 00:00 [pmc-release]
AID - v12i1e57978 [pii]
AID - 10.2196/57978 [doi]
PST - epublish
SO  - JMIR Mhealth Uhealth. 2024 May 6;12:e57978. doi: 10.2196/57978.

PMID- 33936440
OWN - NLM
STAT- MEDLINE
DCOM- 20210604
LR  - 20210604
IS  - 1942-597X (Electronic)
IS  - 1559-4076 (Linking)
VI  - 2020
DP  - 2020
TI  - Facilitating information extraction without annotated data using unsupervised and 
      positive-unlabeled learning.
PG  - 658-667
AB  - Information extraction (IE), the distillation of specific information from 
      unstructured data, is a core task in natural language processing. For rare 
      entities (<1% prevalence), collection of positive examples required to train a 
      model may require an infeasibly large sample of mostly negative ones. We combined 
      unsupervised- with biased positive-unlabeled (PU) learning methods to: 1) 
      facilitate positive example collection while maintaining the assumptions needed 
      to 2) learn a binary classifier from the biased positive-unlabeled data alone. We 
      tested the methods on a real-life use case of rare (<0.42%) entity extraction 
      from medical malpractice documents. When tested on a manually reviewed random 
      sample of documents, the PU model achieved an area under the precision-recall 
      curve of0.283 and Fj of 0.410, outperforming fully supervised learning (0.022 and 
      0.096, respectively). The results demonstrate our method's potential to reduce 
      the manual effort required for extracting rare entities from narrative texts.
CI  - ©2020 AMIA - All rights reserved.
FAU - Korach, Zfania Tom
AU  - Korach ZT
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, MA.
AD  - Harvard Medical School, Boston, MA.
FAU - Yerneni, Sharmitha
AU  - Yerneni S
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, MA.
FAU - Einbinder, Jonathan
AU  - Einbinder J
AD  - Harvard Medical School, Boston, MA.
AD  - CRICO Risk Management Foundation, Boston, MA.
FAU - Kallenberg, Carl
AU  - Kallenberg C
AD  - CRICO Risk Management Foundation, Boston, MA.
FAU - Zhou, Li
AU  - Zhou L
AD  - Division of General Internal Medicine and Primary Care, Brigham and Women's 
      Hospital, Boston, MA.
AD  - Harvard Medical School, Boston, MA.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20210125
PL  - United States
TA  - AMIA Annu Symp Proc
JT  - AMIA ... Annual Symposium proceedings. AMIA Symposium
JID - 101209213
SB  - IM
MH  - Data Curation
MH  - Data Mining/*methods
MH  - Humans
MH  - *Natural Language Processing
PMC - PMC8075513
EDAT- 2021/05/04 06:00
MHDA- 2021/06/05 06:00
PMCR- 2021/01/25
CRDT- 2021/05/03 06:15
PHST- 2021/05/03 06:15 [entrez]
PHST- 2021/05/04 06:00 [pubmed]
PHST- 2021/06/05 06:00 [medline]
PHST- 2021/01/25 00:00 [pmc-release]
AID - 100_3415510 [pii]
PST - epublish
SO  - AMIA Annu Symp Proc. 2021 Jan 25;2020:658-667. eCollection 2020.

PMID- 39347259
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241001
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 8
DP  - 2024 Aug
TI  - Artificial Intelligence-Powered Surgical Consent: Patient Insights.
PG  - e68134
LID - 10.7759/cureus.68134 [doi]
LID - e68134
AB  - Introduction The integration of artificial intelligence (AI) in healthcare has 
      revolutionized patient interactions and service delivery. AI's role extends from 
      supporting clinical diagnostics and enhancing operational efficiencies to 
      potentially improving informed consent processes in surgical settings. This study 
      investigates the application of AI, particularly large language models like 
      OpenAI's ChatGPT, in facilitating surgical consent, focusing on patient 
      understanding, satisfaction, and trust. Methods We employed a mixed-methods 
      approach involving 86 participants, including laypeople and medical staff, who 
      engaged in a simulated AI-driven consent process for a tonsillectomy. 
      Participants interacted with ChatGPT-4, which provided detailed procedure 
      explanations, risks, and benefits. Post-interaction, participants completed a 
      survey assessing their experience through quantitative and qualitative measures. 
      Results Participants had a cautiously optimistic response to AI in the surgical 
      consent process. Notably, 71% felt adequately informed, 86% found the information 
      clear, and 71% felt they could make informed decisions. Overall, 71% were 
      satisfied, 57% felt respected and confident, and 57% would recommend it, 
      indicating areas needing refinement. However, concerns about data privacy and the 
      lack of personal interaction were significant, with only 42% reassured about the 
      security of their data. The standardization of information provided by AI was 
      appreciated for potentially reducing human error, but the absence of empathetic 
      human interaction was noted as a drawback. Discussion While AI shows promise in 
      enhancing the consistency and comprehensiveness of information delivered during 
      the consent process, significant challenges remain. These include addressing data 
      privacy concerns and bridging the gap in personal interaction. The potential for 
      AI to misinform due to system "hallucinations" or inherent biases also needs 
      consideration. Future research should focus on refining AI interactions to 
      support more nuanced and empathetic engagements, ensuring that AI supplements 
      rather than replacing human elements in healthcare. Conclusion The integration of 
      AI into surgical consent processes could standardize and potentially improve the 
      delivery of information but must be balanced with efforts to maintain the 
      critical human elements of care. Collaborative efforts between developers, 
      clinicians, and ethicists are essential to optimize AI use, ensuring it 
      complements the traditional consent process while enhancing patient satisfaction 
      and trust.
CI  - Copyright © 2024, Teasdale et al.
FAU - Teasdale, Alex
AU  - Teasdale A
AD  - Ear Nose Throat, Morriston Hospital, Swansea, GBR.
FAU - Mills, Laura
AU  - Mills L
AD  - General Practice, Dyfed Road Surgery, Swansea, GBR.
FAU - Costello, Rhodri
AU  - Costello R
AD  - Ear Nose Throat, Morriston Hospital, Swansea, GBR.
LA  - eng
PT  - Journal Article
DEP - 20240829
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11438496
OTO - NOTNLM
OT  - ai in healthcare
OT  - artificial intelligence
OT  - chatgpt
OT  - consent process
OT  - data privacy
OT  - healthcare innovation
OT  - medical ethics
OT  - patient autonomy
OT  - patient engagement
OT  - surgical consent
COIS- Human subjects: Consent was obtained or waived by all participants in this study. 
      Animal subjects: All authors have confirmed that this study did not involve 
      animal subjects or tissue. Conflicts of interest: In compliance with the ICMJE 
      uniform disclosure form, all authors declare the following: Payment/services 
      info: All authors have declared that no financial support was received from any 
      organization for the submitted work. Financial relationships: All authors have 
      declared that they have no financial relationships at present or within the 
      previous three years with any organizations that might have an interest in the 
      submitted work. Other relationships: All authors have declared that there are no 
      other relationships or activities that could appear to have influenced the 
      submitted work.
EDAT- 2024/09/30 12:47
MHDA- 2024/09/30 12:48
PMCR- 2024/08/29
CRDT- 2024/09/30 10:01
PHST- 2024/08/28 00:00 [accepted]
PHST- 2024/09/30 12:48 [medline]
PHST- 2024/09/30 12:47 [pubmed]
PHST- 2024/09/30 10:01 [entrez]
PHST- 2024/08/29 00:00 [pmc-release]
AID - 10.7759/cureus.68134 [doi]
PST - epublish
SO  - Cureus. 2024 Aug 29;16(8):e68134. doi: 10.7759/cureus.68134. eCollection 2024 
      Aug.

PMID- 37790442
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240520
DP  - 2023 Sep 22
TI  - Disparities in seizure outcomes revealed by large language models.
LID - 2023.09.20.23295842 [pii]
LID - 10.1101/2023.09.20.23295842 [doi]
AB  - OBJECTIVE: Large-language models (LLMs) in healthcare have the potential to 
      propagate existing biases or introduce new ones. For people with epilepsy, social 
      determinants of health are associated with disparities in access to care, but 
      their impact on seizure outcomes among those with access to specialty care 
      remains unclear. Here we (1) evaluated our validated, epilepsy-specific LLM for 
      intrinsic bias, and (2) used LLM-extracted seizure outcomes to test the 
      hypothesis that different demographic groups have different seizure outcomes. 
      METHODS: First, we tested our LLM for intrinsic bias in the form of differential 
      performance in demographic groups by race, ethnicity, sex, income, and health 
      insurance in manually annotated notes. Next, we used LLM-classified seizure 
      freedom at each office visit to test for outcome disparities in the same 
      demographic groups, using univariable and multivariable analyses. RESULTS: We 
      analyzed 84,675 clinic visits from 25,612 patients seen at our epilepsy center 
      2005-2022. We found no differences in the accuracy, or positive or negative class 
      balance of outcome classifications across demographic groups. Multivariable 
      analysis indicated worse seizure outcomes for female patients (OR 1.33, p = 
      3×10(-8)), those with public insurance (OR 1.53, p = 2×10(-13)), and those from 
      lower-income zip codes (OR ≥ 1.22, p ≤ 6.6×10(-3)). Black patients had worse 
      outcomes than White patients in univariable but not multivariable analysis (OR 
      1.03, p = 0.66). SIGNIFICANCE: We found no evidence that our LLM was 
      intrinsically biased against any demographic group. Seizure freedom extracted by 
      LLM revealed disparities in seizure outcomes across several demographic groups. 
      These findings highlight the critical need to reduce disparities in the care of 
      people with epilepsy.
FAU - Xie, Kevin
AU  - Xie K
AUID- ORCID: 0000-0003-1849-2085
AD  - University of Pennsylvania, Dept. of Bioengineering, Philadelphia, PA, USA.
AD  - University of Pennsylvania, Center for Neuroengineering and Therapeutics, 
      Philadelphia, PA, USA.
FAU - Ojemann, William K S
AU  - Ojemann WKS
AUID- ORCID: 0009-0007-5166-536X
AD  - University of Pennsylvania, Dept. of Bioengineering, Philadelphia, PA, USA.
AD  - University of Pennsylvania, Center for Neuroengineering and Therapeutics, 
      Philadelphia, PA, USA.
FAU - Gallagher, Ryan S
AU  - Gallagher RS
AD  - University of Pennsylvania, Center for Neuroengineering and Therapeutics, 
      Philadelphia, PA, USA.
AD  - University of Pennsylvania, Dept. of Neurology, Philadelphia, PA, USA.
FAU - Lucas, Alfredo
AU  - Lucas A
AD  - University of Pennsylvania, Dept. of Bioengineering, Philadelphia, PA, USA.
AD  - University of Pennsylvania, Center for Neuroengineering and Therapeutics, 
      Philadelphia, PA, USA.
AD  - University of Pennsylvania, Dept. of Neurology, Philadelphia, PA, USA.
FAU - Hill, Chloé E
AU  - Hill CE
AD  - University of Michigan, Dept. of Neurology, Ann Arbor, MI, USA.
FAU - Hamilton, Roy H
AU  - Hamilton RH
AD  - University of Pennsylvania, Dept. of Neurology, Philadelphia, PA, USA.
FAU - Johnson, Kevin B
AU  - Johnson KB
AD  - University of Pennsylvania, Dept. of Bioengineering, Philadelphia, PA, USA.
AD  - University of Pennsylvania, Dept. Of Biostatistics, Epidemiology and Informatics, 
      Philadelphia, PA USA.
AD  - University of Pennsylvania, Dept. of Computer and Information Science, 
      Philadelphia, PA, USA.
AD  - University of Pennsylvania, Dept. of Pediatrics, Philadelphia, PA, USA.
FAU - Roth, Dan
AU  - Roth D
AD  - University of Pennsylvania, Dept. of Computer and Information Science, 
      Philadelphia, PA, USA.
FAU - Litt, Brian
AU  - Litt B
AUID- ORCID: 0000-0003-2732-6927
AD  - University of Pennsylvania, Dept. of Bioengineering, Philadelphia, PA, USA.
AD  - University of Pennsylvania, Center for Neuroengineering and Therapeutics, 
      Philadelphia, PA, USA.
AD  - University of Pennsylvania, Dept. of Neurology, Philadelphia, PA, USA.
FAU - Ellis, Colin A
AU  - Ellis CA
AUID- ORCID: 0000-0003-2152-8106
AD  - University of Pennsylvania, Center for Neuroengineering and Therapeutics, 
      Philadelphia, PA, USA.
AD  - University of Pennsylvania, Dept. of Neurology, Philadelphia, PA, USA.
LA  - eng
GR  - DP1 NS122038/NS/NINDS NIH HHS/United States
GR  - K23 NS121520/NS/NINDS NIH HHS/United States
GR  - R01 NS125137/NS/NINDS NIH HHS/United States
GR  - T32 NS091006/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20230922
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - J Am Med Inform Assoc. 2024 May 20;31(6):1348-1355. doi: 10.1093/jamia/ocae047. 
      PMID: 38481027
PMC - PMC10543059
OTO - NOTNLM
OT  - Clinical Informatics
OT  - Electronic Health Record
OT  - Health Disparities
OT  - Natural Language Processing
COIS- Disclosure of Conflicts of Interest: Authors have no competing interests to 
      disclose. Conflict of Interest and Ethical Publication Statement Authors have no 
      competing interests to disclose. We confirm that we have read the Journal’s 
      position on issues involved in ethical publication and a rm that this report is 
      consistent with those guidelines.
EDAT- 2023/10/04 06:43
MHDA- 2023/10/04 06:44
PMCR- 2023/10/02
CRDT- 2023/10/04 04:04
PHST- 2023/10/04 06:43 [pubmed]
PHST- 2023/10/04 06:44 [medline]
PHST- 2023/10/04 04:04 [entrez]
PHST- 2023/10/02 00:00 [pmc-release]
AID - 2023.09.20.23295842 [pii]
AID - 10.1101/2023.09.20.23295842 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Sep 22:2023.09.20.23295842. doi: 
      10.1101/2023.09.20.23295842.

PMID- 39638453
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241211
IS  - 2093-4777 (Print)
IS  - 2093-6931 (Electronic)
IS  - 2093-4777 (Linking)
VI  - 28
IP  - Suppl 2
DP  - 2024 Nov
TI  - Exploring Large Language Models and the Metaverse for Urologic Applications: 
      Potential, Challenges, and the Path Forward.
PG  - S65-73
LID - 10.5213/inj.2448402.201 [doi]
AB  - The metaverse, a 3-dimensional digital platform that enables users to interact 
      and engage in realistic virtual activities beyond time and space limitations, has 
      garnered significant investment across industries, particularly in healthcare. In 
      the medical field, the metaverse shows promise as a digital therapeutic platform 
      to enhance interaction between medical professionals and patients. Concurrently, 
      generative artificial intelligence, especially large language models, is being 
      integrated into healthcare for applications in data analysis, image recognition, 
      and natural language processing. In urology, large language models (LLMs) support 
      are increasingly used in urology for tasks such as image diagnosis, data 
      processing, patient education, and treatment assistance in order to provide 
      significant support in clinical settings. By combining LLMs with the immersive 
      capabilities of the metaverse, new possibilities emerge to improve urologic 
      treatment in areas that require consistent treatments, habit formation, and 
      long-term management. This paper reviews current research and applications of 
      LLMs in urology, discusses the challenges associated with their use including 
      data quality, bias, security, and ethical issues, and explores the need for 
      regulatory standards. Furthermore, it highlights the potential of a 
      metaverse-based digital platform to improve urologic care and streamline 
      information exchange to maximize the benefits of this integrated approach in 
      future healthcare applications.
FAU - Park, Hyung Jun
AU  - Park HJ
AD  - Department of Game and Interactive Media, Graduate School of Game, Gachon 
      University, Seongnam, Korea.
FAU - Kim, Eun Joung
AU  - Kim EJ
AD  - Department of Game Contents, College of Smart Content, Kyungil University, 
      Gyeongsan, Korea.
FAU - Kim, Jung Yoon
AU  - Kim JY
AD  - Department of Game Media, College of IT Convergence, Gachon University, Seongnam, 
      Korea.
LA  - eng
GR  - 2022R1F1A1066602/National Research Foundation of Korea/
GR  - Ministry of Education/
GR  - Korea Creative Content Agency/
GR  - RS-2023-00227648/Ministry of Culture, Sports and Tourism/
PT  - Journal Article
DEP - 20241130
PL  - Korea (South)
TA  - Int Neurourol J
JT  - International neurourology journal
JID - 101534513
PMC - PMC11627225
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Digital therapeutics
OT  - Large language models
OT  - Metaverse
OT  - Urology
COIS- Conflict of Interest No potential conflict of interest relevant to this article 
      was reported.
EDAT- 2024/12/06 05:30
MHDA- 2024/12/06 05:31
PMCR- 2024/11/01
CRDT- 2024/12/05 20:58
PHST- 2024/09/30 00:00 [received]
PHST- 2024/11/15 00:00 [accepted]
PHST- 2024/12/06 05:31 [medline]
PHST- 2024/12/06 05:30 [pubmed]
PHST- 2024/12/05 20:58 [entrez]
PHST- 2024/11/01 00:00 [pmc-release]
AID - inj.2448402.201 [pii]
AID - inj-2448402-201 [pii]
AID - 10.5213/inj.2448402.201 [doi]
PST - ppublish
SO  - Int Neurourol J. 2024 Nov;28(Suppl 2):S65-73. doi: 10.5213/inj.2448402.201. Epub 
      2024 Nov 30.

PMID- 37925406
OWN - NLM
STAT- MEDLINE
DCOM- 20231106
LR  - 20241004
IS  - 1466-609X (Electronic)
IS  - 1364-8535 (Print)
IS  - 1364-8535 (Linking)
VI  - 27
IP  - 1
DP  - 2023 Nov 4
TI  - Natural language processing diagnosed behavioural disturbance phenotypes in the 
      intensive care unit: characteristics, prevalence, trajectory, treatment, and 
      outcomes.
PG  - 425
LID - 10.1186/s13054-023-04695-0 [doi]
LID - 425
AB  - BACKGROUND: Natural language processing (NLP) may help evaluate the 
      characteristics, prevalence, trajectory, treatment, and outcomes of behavioural 
      disturbance phenotypes in critically ill patients. METHODS: We obtained 
      electronic clinical notes, demographic information, outcomes, and treatment data 
      from three medical-surgical ICUs. Using NLP, we screened for behavioural 
      disturbance phenotypes based on words suggestive of an agitated state, a 
      non-agitated state, or a combination of both. RESULTS: We studied 2931 patients. 
      Of these, 225 (7.7%) were NLP-Dx-BD positive for the agitated phenotype, 544 
      (18.6%) for the non-agitated phenotype and 667 (22.7%) for the combined 
      phenotype. Patients with these phenotypes carried multiple clinical baseline 
      differences. On time-dependent multivariable analysis to compensate for immortal 
      time bias and after adjustment for key outcome predictors, agitated phenotype 
      patients were more likely to receive antipsychotic medications (odds ratio [OR] 
      1.84, 1.35-2.51, p < 0.001) compared to non-agitated phenotype patients but not 
      compared to combined phenotype patients (OR 1.27, 0.86-1.89, p = 0.229). 
      Moreover, agitated phenotype patients were more likely to die than other 
      phenotypes patients (OR 1.57, 1.10-2.25, p = 0.012 vs non-agitated phenotype; OR 
      4.61, 2.14-9.90, p < 0.001 vs. combined phenotype). This association was 
      strongest in patients receiving mechanical ventilation when compared with the 
      combined phenotype (OR 7.03, 2.07-23.79, p = 0.002). A similar increased risk was 
      also seen for patients with the non-agitated phenotype compared with the combined 
      phenotype (OR 6.10, 1.80-20.64, p = 0.004). CONCLUSIONS: NLP-Dx-BD screening 
      enabled identification of three behavioural disturbance phenotypes with different 
      characteristics, prevalence, trajectory, treatment, and outcome. Such phenotype 
      identification appears relevant to prognostication and trial design.
CI  - © 2023. The Author(s).
FAU - Young, Marcus
AU  - Young M
AUID- ORCID: 0000-0002-6195-660X
AD  - Data Analytics Research and Evaluation (DARE) Centre, Austin Health and The 
      University of Melbourne, Heidelberg, VIC, Australia.
AD  - Department of Critical Care, School of Medicine, The University of Melbourne, 
      Parkville, Melbourne, VIC, Australia.
FAU - Holmes, Natasha E
AU  - Holmes NE
AUID- ORCID: 0000-0001-8501-4054
AD  - Data Analytics Research and Evaluation (DARE) Centre, Austin Health and The 
      University of Melbourne, Heidelberg, VIC, Australia.
AD  - Department of Infectious Diseases, Peter Doherty Institute for Infection and 
      Immunity, University of Melbourne, Victoria, 3000, Australia.
FAU - Kishore, Kartik
AU  - Kishore K
AUID- ORCID: 0000-0002-6254-6063
AD  - Data Analytics Research and Evaluation (DARE) Centre, Austin Health and The 
      University of Melbourne, Heidelberg, VIC, Australia.
FAU - Amjad, Sobia
AU  - Amjad S
AUID- ORCID: 0000-0002-1595-0370
AD  - Data Analytics Research and Evaluation (DARE) Centre, Austin Health and The 
      University of Melbourne, Heidelberg, VIC, Australia.
AD  - School of Computing and Information Systems, The University of Melbourne, 
      Parkville, Melbourne, VIC, Australia.
FAU - Gaca, Michele
AU  - Gaca M
AUID- ORCID: 0000-0001-7350-3299
AD  - Data Analytics Research and Evaluation (DARE) Centre, Austin Health and The 
      University of Melbourne, Heidelberg, VIC, Australia.
FAU - Serpa Neto, Ary
AU  - Serpa Neto A
AUID- ORCID: 0000-0003-1520-9387
AD  - Data Analytics Research and Evaluation (DARE) Centre, Austin Health and The 
      University of Melbourne, Heidelberg, VIC, Australia.
AD  - Australian and New Zealand Intensive Care Research Centre, School of Public 
      Health and Preventive Medicine, Monash University, Melbourne, Australia.
FAU - Reade, Michael C
AU  - Reade MC
AUID- ORCID: 0000-0003-1570-0707
AD  - Faculty of Medicine, University of Queensland, Brisbane, QLD, Australia.
AD  - Joint Health Command, Australian Defence Force, Brisbane, QLD, Australia.
AD  - Department of Intensive Care Medicine, Royal Brisbane and Women's Hospital, 
      Brisbane, QLD, Australia.
FAU - Bellomo, Rinaldo
AU  - Bellomo R
AUID- ORCID: 0000-0002-1650-8939
AD  - Data Analytics Research and Evaluation (DARE) Centre, Austin Health and The 
      University of Melbourne, Heidelberg, VIC, Australia. 
      Rinaldo.bellomo@austin.org.au.
AD  - Australian and New Zealand Intensive Care Research Centre, School of Public 
      Health and Preventive Medicine, Monash University, Melbourne, Australia. 
      Rinaldo.bellomo@austin.org.au.
AD  - Department of Intensive Care, Austin Hospital, 145 Studley Rd, Heidelberg, 
      Melbourne, Australia. Rinaldo.bellomo@austin.org.au.
AD  - Department of Critical Care, School of Medicine, The University of Melbourne, 
      Parkville, Melbourne, VIC, Australia. Rinaldo.bellomo@austin.org.au.
AD  - Department of Intensive Care, Royal Melbourne Hospital, Melbourne, Australia. 
      Rinaldo.bellomo@austin.org.au.
LA  - eng
PT  - Journal Article
DEP - 20231104
PL  - England
TA  - Crit Care
JT  - Critical care (London, England)
JID - 9801902
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Prevalence
MH  - *Intensive Care Units
MH  - Respiration, Artificial
MH  - Phenotype
PMC - PMC10625294
OTO - NOTNLM
OT  - Agitation
OT  - Antipsychotic drugs
OT  - Critical illness
OT  - Delirium
OT  - Intensive care
OT  - Mortality
COIS- The authors declare that they have no competing interests..
EDAT- 2023/11/05 06:41
MHDA- 2023/11/06 06:43
PMCR- 2023/11/04
CRDT- 2023/11/05 00:14
PHST- 2023/08/07 00:00 [received]
PHST- 2023/10/19 00:00 [accepted]
PHST- 2023/11/06 06:43 [medline]
PHST- 2023/11/05 06:41 [pubmed]
PHST- 2023/11/05 00:14 [entrez]
PHST- 2023/11/04 00:00 [pmc-release]
AID - 10.1186/s13054-023-04695-0 [pii]
AID - 4695 [pii]
AID - 10.1186/s13054-023-04695-0 [doi]
PST - epublish
SO  - Crit Care. 2023 Nov 4;27(1):425. doi: 10.1186/s13054-023-04695-0.

PMID- 39877865
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250203
IS  - 2772-5723 (Electronic)
IS  - 2772-5723 (Linking)
VI  - 4
IP  - 2
DP  - 2025
TI  - Large Language Models Outperform Traditional Natural Language Processing Methods 
      in Extracting Patient-Reported Outcomes in Inflammatory Bowel Disease.
PG  - 100563
LID - 10.1016/j.gastha.2024.10.003 [doi]
LID - 100563
AB  - BACKGROUND AND AIMS: Patient-reported outcomes (PROs) are vital in assessing 
      disease activity and treatment outcomes in inflammatory bowel disease (IBD). 
      However, manual extraction of these PROs from the free-text of clinical notes is 
      burdensome. We aimed to improve data curation from free-text information in the 
      electronic health record, making it more available for research and quality 
      improvement. This study aimed to compare traditional natural language processing 
      (tNLP) and large language models (LLMs) in extracting 3 IBD PROs (abdominal pain, 
      diarrhea, fecal blood) from clinical notes across 2 institutions. METHODS: Clinic 
      notes were annotated for each PRO using preset protocols. Models were developed 
      and internally tested at the University of California, San Francisco, and then 
      externally validated at Stanford University. We compared tNLP and LLM-based 
      models on accuracy, sensitivity, specificity, positive, and negative predictive 
      value. In addition, we conducted fairness and error assessments. RESULTS: 
      Interrater reliability between annotators was >90%. On the University of 
      California, San Francisco test set (n = 50), the top-performing tNLP models 
      showcased accuracies of 92% (abdominal pain), 82% (diarrhea) and 80% (fecal 
      blood), comparable to GPT-4, which was 96%, 88%, and 90% accurate, respectively. 
      On external validation at Stanford (n = 250), tNLP models failed to generalize 
      (61%-62% accuracy) while GPT-4 maintained accuracies >90%. Pathways Language 
      Model-2 and Generative Pre-trained Transformer-4 showed similar performance. No 
      biases were detected based on demographics or diagnosis. CONCLUSION: LLMs are 
      accurate and generalizable methods for extracting PROs. They maintain excellent 
      accuracy across institutions, despite heterogeneity in note templates and 
      authors. Widespread adoption of such tools has the potential to enhance IBD 
      research and patient care.
CI  - © 2024 The Authors.
FAU - Patel, Perseus V
AU  - Patel PV
AD  - Department of Pediatrics, University of California, San Francisco, San Francisco, 
      California.
AD  - Division of Pediatric Gastroenterology, Stanford University School of Medicine, 
      Palo Alto, California.
FAU - Davis, Conner
AU  - Davis C
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, California.
FAU - Ralbovsky, Amariel
AU  - Ralbovsky A
AD  - Department of Pediatrics, University of California, San Francisco, San Francisco, 
      California.
FAU - Tinoco, Daniel
AU  - Tinoco D
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, California.
FAU - Williams, Christopher Y K
AU  - Williams CYK
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, California.
FAU - Slatter, Shadera
AU  - Slatter S
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, California.
FAU - Naderalvojoud, Behzad
AU  - Naderalvojoud B
AD  - Stanford Center for Biomedical Informatics Research, Department of Medicine, 
      Stanford University, Palo Alto, California.
FAU - Rosen, Michael J
AU  - Rosen MJ
AD  - Division of Pediatric Gastroenterology, Stanford University School of Medicine, 
      Palo Alto, California.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AD  - Stanford Center for Biomedical Informatics Research, Department of Medicine, 
      Stanford University, Palo Alto, California.
FAU - Rudrapatna, Vivek
AU  - Rudrapatna V
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, California.
AD  - Division of Gastroenterology, Department of Medicine, University of California, 
      San Francisco, San Francisco, California.
LA  - eng
GR  - K99 LM014099/LM/NLM NIH HHS/United States
GR  - T32 DK007762/DK/NIDDK NIH HHS/United States
GR  - UL1 TR001872/TR/NCATS NIH HHS/United States
GR  - UL1 TR001881/TR/NCATS NIH HHS/United States
PT  - Journal Article
DEP - 20241010
PL  - Netherlands
TA  - Gastro Hep Adv
JT  - Gastro hep advances
JID - 9918350485906676
UOF - medRxiv. 2024 Sep 06:2024.09.05.24313139. doi: 10.1101/2024.09.05.24313139. PMID: 
      39281744
PMC - PMC11772946
OTO - NOTNLM
OT  - Clinical data science
OT  - GPT-4
OT  - Machine learning
OT  - PaLM-2
EDAT- 2025/01/29 06:20
MHDA- 2025/01/29 06:21
PMCR- 2024/10/10
CRDT- 2025/01/29 04:39
PHST- 2024/09/04 00:00 [received]
PHST- 2024/10/04 00:00 [accepted]
PHST- 2025/01/29 06:21 [medline]
PHST- 2025/01/29 06:20 [pubmed]
PHST- 2025/01/29 04:39 [entrez]
PHST- 2024/10/10 00:00 [pmc-release]
AID - S2772-5723(24)00158-4 [pii]
AID - 100563 [pii]
AID - 10.1016/j.gastha.2024.10.003 [doi]
PST - epublish
SO  - Gastro Hep Adv. 2024 Oct 10;4(2):100563. doi: 10.1016/j.gastha.2024.10.003. 
      eCollection 2025.

PMID- 37546795
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231019
DP  - 2023 Jul 27
TI  - Interdisciplinary Inquiry via PanelGPT: Application to Explore Chatbot 
      Application in Sports Rehabilitation.
LID - 2023.07.23.23292452 [pii]
LID - 10.1101/2023.07.23.23292452 [doi]
AB  - BACKGROUND: ChatGPT showcases exceptional conversational capabilities and 
      extensive cross-disciplinary knowledge. In addition, it possesses the ability to 
      perform multiple roles within a single chat session. This unique 
      multi-role-playing feature positions ChatGPT as a promising tool to explore 
      interdisciplinary subjects. OBJECTIVE: The study intended to guide ChatGPT for 
      interdisciplinary exploration through simulated panel discussions. As a 
      proof-of-concept, we employed this method to evaluate the advantages and 
      challenges of using chatbots in sports rehabilitation. METHODS: We proposed a 
      model termed PanelGPT to explore ChatGPTs' knowledge graph on interdisciplinary 
      topics through simulated panel discussions. Applied to "chatbots in sports 
      rehabilitation", ChatGPT role-played both the moderator and panelists, which 
      included a physiotherapist, psychologist, nutritionist, AI expert, and an 
      athlete. We act as the audience posed questions to the panel, with ChatGPT acting 
      as both the panelists for responses and the moderator for hosting the discussion. 
      We performed the simulation using the ChatGPT-4 model and evaluated the responses 
      with existing literature and human expertise. RESULTS: Each simulation mimicked a 
      real-life panel discussion: The moderator introduced the panel and posed 
      opening/closing questions, to which all panelists responded. The experts engaged 
      with each other to address inquiries from the audience, primarily from their 
      respective fields of expertise. By tackling questions related to education, 
      physiotherapy, physiology, nutrition, and ethical consideration, the discussion 
      highlighted benefits such as 24/7 support, personalized advice, automated 
      tracking, and reminders. It also emphasized the importance of user education and 
      identified challenges such as limited interaction modes, inaccuracies in 
      emotion-related advice, assurance on data privacy and security, transparency in 
      data handling, and fairness in model training. The panelists reached a consensus 
      that chatbots are designed to assist, not replace, human healthcare professionals 
      in the rehabilitation process. CONCLUSIONS: Compared to a typical conversation 
      with ChatGPT, the multi-perspective approach of PanelGPT facilitates a 
      comprehensive understanding of an interdisciplinary topic by integrating insights 
      from experts with complementary knowledge. Beyond addressing the exemplified 
      topic of chatbots in sports rehabilitation, the model can be adapted to tackle a 
      wide array of interdisciplinary topics within educational, research, and 
      healthcare settings.
FAU - McBee, Joseph C
AU  - McBee JC
AD  - Department of Microbiology, Immunology & Cell Biology, West Virginia University, 
      Morgantown, WV 26506, USA.
AD  - Department of Chemical and Biomedical Engineering, West Virginia University, 
      Morgantown, WV 26506, USA.
FAU - Han, Daniel Y
AU  - Han DY
AD  - Department of Microbiology, Immunology & Cell Biology, West Virginia University, 
      Morgantown, WV 26506, USA.
FAU - Liu, Li
AU  - Liu L
AD  - College of Health Solutions, Arizona State University, Phoenix, AZ 85004, USA.
AD  - Biodesign Institute, Arizona State University, Tempe, AZ, 85281 USA.
FAU - Ma, Leah
AU  - Ma L
AD  - College of Health, Education, and Human Services, Wright State University, 
      Dayton, OH 45345, USA.
FAU - Adjeroh, Donald A
AU  - Adjeroh DA
AD  - Lane Department of Computer Science & Electrical Engineering, West Virginia 
      University, Morgantown, WV 26506, USA.
FAU - Xu, Dong
AU  - Xu D
AD  - Department of Electrical Engineer and Computer Science, Christopher S. Bond Life 
      Sciences Center, University of Missouri, Columbia, MO65211, USA.
FAU - Hu, Gangqing
AU  - Hu G
AD  - Department of Microbiology, Immunology & Cell Biology, West Virginia University, 
      Morgantown, WV 26506, USA.
LA  - eng
GR  - R01 LM013392/LM/NLM NIH HHS/United States
GR  - U54 GM104942/GM/NIGMS NIH HHS/United States
GR  - P20 GM121322/GM/NIGMS NIH HHS/United States
GR  - P20 GM103434/GM/NIGMS NIH HHS/United States
GR  - R01 LM013438/LM/NLM NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20230727
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC10402232
OTO - NOTNLM
OT  - ChatGPT
OT  - chatbots
OT  - interdisciplinary inquiry
OT  - multi-role-playing
OT  - sports medicine
COIS- Competing Interests The Authors declare no Competing Financial or Non-Financial 
      Interests
EDAT- 2023/08/07 06:41
MHDA- 2023/08/07 06:42
PMCR- 2023/08/04
CRDT- 2023/08/07 04:43
PHST- 2023/08/07 06:41 [pubmed]
PHST- 2023/08/07 06:42 [medline]
PHST- 2023/08/07 04:43 [entrez]
PHST- 2023/08/04 00:00 [pmc-release]
AID - 2023.07.23.23292452 [pii]
AID - 10.1101/2023.07.23.23292452 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2023 Jul 27:2023.07.23.23292452. doi: 
      10.1101/2023.07.23.23292452.

PMID- 32696698
OWN - NLM
STAT- MEDLINE
DCOM- 20210906
LR  - 20210906
IS  - 2000-1967 (Electronic)
IS  - 0300-9734 (Print)
IS  - 0300-9734 (Linking)
VI  - 125
IP  - 4
DP  - 2020 Nov
TI  - Natural language processing and machine learning to enable automatic extraction 
      and classification of patients' smoking status from electronic medical records.
PG  - 316-324
LID - 10.1080/03009734.2020.1792010 [doi]
AB  - BACKGROUND: The electronic medical record (EMR) offers unique possibilities for 
      clinical research, but some important patient attributes are not readily 
      available due to its unstructured properties. We applied text mining using 
      machine learning to enable automatic classification of unstructured information 
      on smoking status from Swedish EMR data. METHODS: Data on patients' smoking 
      status from EMRs were used to develop 32 different predictive models that were 
      trained using Weka, changing sentence frequency, classifier type, tokenization, 
      and attribute selection in a database of 85,000 classified sentences. The models 
      were evaluated using F-score and accuracy based on out-of-sample test data 
      including 8500 sentences. The error weight matrix was used to select the best 
      model, assigning a weight to each type of misclassification and applying it to 
      the model confusion matrices. The best performing model was then compared to a 
      rule-based method. RESULTS: The best performing model was based on the Support 
      Vector Machine (SVM) Sequential Minimal Optimization (SMO) classifier using a 
      combination of unigrams and bigrams as tokens. Sentence frequency and attributes 
      selection did not improve model performance. SMO achieved 98.14% accuracy and 
      0.981 F-score versus 79.32% and 0.756 for the rule-based model. CONCLUSION: A 
      model using machine-learning algorithms to automatically classify patients' 
      smoking status was successfully developed. Such algorithms may enable automatic 
      assessment of smoking status and other unstructured data directly from EMRs 
      without manual classification of complete case notes.
FAU - Caccamisi, Andrea
AU  - Caccamisi A
AD  - Department of Learning, Informatics, Management and Ethics, Karolinska 
      Institutet, Stockholm, Sweden.
AD  - Department of Computer and Systems Sciences (DSV), Stockholm University, 
      Stockholm, Sweden.
FAU - Jørgensen, Leif
AU  - Jørgensen L
AD  - IQVIA Solutions Sweden AB, Solna, Sweden.
FAU - Dalianis, Hercules
AU  - Dalianis H
AD  - Department of Computer and Systems Sciences (DSV), Stockholm University, 
      Stockholm, Sweden.
FAU - Rosenlund, Mats
AU  - Rosenlund M
AD  - Department of Learning, Informatics, Management and Ethics, Karolinska 
      Institutet, Stockholm, Sweden.
AD  - IQVIA Solutions Sweden AB, Solna, Sweden.
LA  - eng
PT  - Journal Article
DEP - 20200722
PL  - Sweden
TA  - Ups J Med Sci
JT  - Upsala journal of medical sciences
JID - 0332203
SB  - IM
MH  - Algorithms
MH  - Automation
MH  - Bayes Theorem
MH  - Data Mining
MH  - *Electronic Health Records
MH  - False Positive Reactions
MH  - Humans
MH  - *Machine Learning
MH  - Medical Informatics
MH  - *Natural Language Processing
MH  - Observer Variation
MH  - Pattern Recognition, Automated
MH  - ROC Curve
MH  - Reproducibility of Results
MH  - Research Design
MH  - *Smoking
MH  - Software
MH  - Support Vector Machine
MH  - Sweden/epidemiology
MH  - Tobacco Use Disorder/*diagnosis/epidemiology
PMC - PMC7594865
OTO - NOTNLM
OT  - Clinical informatics
OT  - electronic medical records
OT  - machine learning
OT  - natural language processing
OT  - smoking
OT  - text mining
COIS- The authors of this manuscript have no conflict of interest to disclose.
EDAT- 2020/07/23 06:00
MHDA- 2021/09/07 06:00
PMCR- 2020/07/22
CRDT- 2020/07/23 06:00
PHST- 2020/07/23 06:00 [pubmed]
PHST- 2021/09/07 06:00 [medline]
PHST- 2020/07/23 06:00 [entrez]
PHST- 2020/07/22 00:00 [pmc-release]
AID - 1792010 [pii]
AID - 10.1080/03009734.2020.1792010 [doi]
PST - ppublish
SO  - Ups J Med Sci. 2020 Nov;125(4):316-324. doi: 10.1080/03009734.2020.1792010. Epub 
      2020 Jul 22.

PMID- 36940395
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231024
IS  - 1938-808X (Electronic)
IS  - 1040-2446 (Linking)
VI  - 98
IP  - 9
DP  - 2023 Sep 1
TI  - A New Tool for Holistic Residency Application Review: Using Natural Language 
      Processing of Applicant Experiences to Predict Interview Invitation.
PG  - 1018-1021
LID - 10.1097/ACM.0000000000005210 [doi]
AB  - PROBLEM: Reviewing residency application narrative components is time intensive 
      and has contributed to nearly half of applications not receiving holistic review. 
      The authors developed a natural language processing (NLP)-based tool to automate 
      review of applicants' narrative experience entries and predict interview 
      invitation. APPROACH: Experience entries (n = 188,500) were extracted from 6,403 
      residency applications across 3 application cycles (2017-2019) at 1 internal 
      medicine program, combined at the applicant level, and paired with the interview 
      invitation decision (n = 1,224 invitations). NLP identified important words (or 
      word pairs) with term frequency-inverse document frequency, which were used to 
      predict interview invitation using logistic regression with L1 regularization. 
      Terms remaining in the model were analyzed thematically. Logistic regression 
      models were also built using structured application data and a combination of NLP 
      and structured data. Model performance was evaluated on never-before-seen data 
      using area under the receiver operating characteristic and precision-recall 
      curves (AUROC, AUPRC). OUTCOMES: The NLP model had an AUROC of 0.80 (vs chance 
      decision of 0.50) and AUPRC of 0.49 (vs chance decision of 0.19), showing 
      moderate predictive strength. Phrases indicating active leadership, research, or 
      work in social justice and health disparities were associated with interview 
      invitation. The model's detection of these key selection factors demonstrated 
      face validity. Adding structured data to the model significantly improved 
      prediction (AUROC 0.92, AUPRC 0.73), as expected given reliance on such metrics 
      for interview invitation. NEXT STEPS: This model represents a first step in using 
      NLP-based artificial intelligence tools to promote holistic residency application 
      review. The authors are assessing the practical utility of using this model to 
      identify applicants screened out using traditional metrics. Generalizability must 
      be determined through model retraining and evaluation at other programs. Work is 
      ongoing to thwart model "gaming," improve prediction, and remove unwanted biases 
      introduced during model training.
CI  - Copyright © 2023 by the Association of American Medical Colleges.
FAU - Mahtani, Arun Umesh
AU  - Mahtani AU
AUID- ORCID: 0000-0002-2101-7157
AD  - A.U. Mahtani is a resident, Richmond University Medical Center/Mount Sinai, 
      Staten Island, New York; ORCID: https://orcid.org/0000-0002-2101-7157 .
FAU - Reinstein, Ilan
AU  - Reinstein I
AD  - I. Reinstein is a data science engineer, Institute for Innovations in Medical 
      Education, NYU Grossman School of Medicine, New York, New York.
FAU - Marin, Marina
AU  - Marin M
AD  - M. Marin is director, Division of Academic Analytics, Institute for Innovations 
      in Medical Education, NYU Grossman School of Medicine, New York, New York.
FAU - Burk-Rafel, Jesse
AU  - Burk-Rafel J
AD  - J. Burk-Rafel is assistant professor of medicine and assistant director, 
      Precision and Translational Medical Education, Institute for Innovations in 
      Medical Education, NYU Grossman School of Medicine, New York, New York; ORCID: 
      https://orcid.org/0000-0003-3785-2154 .
LA  - eng
PT  - Journal Article
DEP - 20230316
PL  - United States
TA  - Acad Med
JT  - Academic medicine : journal of the Association of American Medical Colleges
JID - 8904605
SB  - IM
MH  - Humans
MH  - *Internship and Residency
MH  - Natural Language Processing
MH  - Artificial Intelligence
MH  - Personnel Selection
MH  - Leadership
EDAT- 2023/03/21 06:00
MHDA- 2023/10/23 12:42
CRDT- 2023/03/20 16:03
PHST- 2023/10/23 12:42 [medline]
PHST- 2023/03/21 06:00 [pubmed]
PHST- 2023/03/20 16:03 [entrez]
AID - 00001888-990000000-00395 [pii]
AID - 10.1097/ACM.0000000000005210 [doi]
PST - ppublish
SO  - Acad Med. 2023 Sep 1;98(9):1018-1021. doi: 10.1097/ACM.0000000000005210. Epub 
      2023 Mar 16.

PMID- 40110624
OWN - NLM
STAT- MEDLINE
DCOM- 20250320
LR  - 20250320
IS  - 1573-3599 (Electronic)
IS  - 1059-7700 (Linking)
VI  - 34
IP  - 2
DP  - 2025 Apr
TI  - Generative AI and the profession of genetic counseling.
PG  - e2009
LID - 10.1002/jgc4.2009 [doi]
AB  - The development of artificial intelligence (AI) including generative large 
      language models (LLMs) and software like ChatGPT is likely to significantly 
      influence existing workforces. Genetic counseling has been identified as a 
      profession likely impacted by advancements of LLMs in natural language processing 
      tasks. It is important therefore to understand LLMs before using them in 
      practice. We provide an overview of LLMs and the strengths, biases, risks, and 
      potential uses in genetic counseling. We discuss how these models show promise 
      for supporting certain tasks in genetic healthcare (e.g., letter writing, triage, 
      intake or follow-up, decision aids, chatbots, and simulations). However, any 
      interaction between LLMs and clients or clients' confidential information raises 
      significant ethical, regulatory, and privacy concerns that are yet to be 
      addressed. While LLMs may excel in information processing and are making 
      unprecedented strides with regard to communication, we highlight aspects of 
      psychotherapeutic encounters that require human interaction. Although 
      LLMs/chatbots can provide information relevant to genetic tests and can mimic 
      empathy, we postulate that these interactions cannot adequately replace the 
      personalized application of counseling theory, skills, knowledge, and 
      decision-making provided by a human genetic counselor. We propose that LLMs show 
      great potential for use in aspects of genetic counseling practice. A continued, 
      strengthened philosophical focus on the counseling process and psychotherapeutic 
      goals of practice will be an essential aspect of genetic counselors' roles in the 
      era of AI-supported counseling. Ongoing attention to the deployment of AI in 
      clinical contexts and the relational elements of care will help ensure quality 
      care for clients.
CI  - © 2025 National Society of Genetic Counselors.
FAU - Meekins-Doherty, Leo
AU  - Meekins-Doherty L
AUID- ORCID: 0000-0002-6601-294X
AD  - Genomic Medicine & Familial Cancer Centre, Royal Melbourne Hospital and Peter 
      MacCallum Cancer Centre, Parkville, Victoria, Australia.
FAU - Dive, Lisa
AU  - Dive L
AUID- ORCID: 0000-0001-6655-5138
AD  - Genetic Counseling, Graduate School of Health, University of Technology Sydney, 
      Sydney, New South Wales, Australia.
FAU - McEwen, Alison
AU  - McEwen A
AUID- ORCID: 0000-0001-8705-1190
AD  - Genetic Counseling, Graduate School of Health, University of Technology Sydney, 
      Sydney, New South Wales, Australia.
FAU - Sexton, Adrienne
AU  - Sexton A
AUID- ORCID: 0000-0001-8749-1639
AD  - Genomic Medicine & Familial Cancer Centre, Royal Melbourne Hospital and Peter 
      MacCallum Cancer Centre, Parkville, Victoria, Australia.
AD  - Department of Medicine - RMH, The University of Melbourne, Parkville, Victoria, 
      Australia.
AD  - Epworth Freemasons, East Melbourne, Victoria, Australia.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Genet Couns
JT  - Journal of genetic counseling
JID - 9206865
SB  - IM
MH  - *Genetic Counseling
MH  - Humans
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - genetic counseling
OT  - genetic services
OT  - practice models
OT  - roles
EDAT- 2025/03/20 06:24
MHDA- 2025/03/20 06:25
CRDT- 2025/03/20 05:33
PHST- 2024/11/28 00:00 [revised]
PHST- 2023/09/28 00:00 [received]
PHST- 2024/12/04 00:00 [accepted]
PHST- 2025/03/20 06:25 [medline]
PHST- 2025/03/20 06:24 [pubmed]
PHST- 2025/03/20 05:33 [entrez]
AID - 10.1002/jgc4.2009 [doi]
PST - ppublish
SO  - J Genet Couns. 2025 Apr;34(2):e2009. doi: 10.1002/jgc4.2009.

PMID- 39838160
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250129
IS  - 2730-664X (Electronic)
IS  - 2730-664X (Linking)
VI  - 5
IP  - 1
DP  - 2025 Jan 21
TI  - Current applications and challenges in large language models for patient care: a 
      systematic review.
PG  - 26
LID - 10.1038/s43856-024-00717-2 [doi]
LID - 26
AB  - BACKGROUND: The introduction of large language models (LLMs) into clinical 
      practice promises to improve patient education and empowerment, thereby 
      personalizing medical care and broadening access to medical knowledge. Despite 
      the popularity of LLMs, there is a significant gap in systematized information on 
      their use in patient care. Therefore, this systematic review aims to synthesize 
      current applications and limitations of LLMs in patient care. METHODS: We 
      systematically searched 5 databases for qualitative, quantitative, and mixed 
      methods articles on LLMs in patient care published between 2022 and 2023. From 
      4349 initial records, 89 studies across 29 medical specialties were included. 
      Quality assessment was performed using the Mixed Methods Appraisal Tool 2018. A 
      data-driven convergent synthesis approach was applied for thematic syntheses of 
      LLM applications and limitations using free line-by-line coding in Dedoose. 
      RESULTS: We show that most studies investigate Generative Pre-trained 
      Transformers (GPT)-3.5 (53.2%, n = 66 of 124 different LLMs examined) and GPT-4 
      (26.6%, n = 33/124) in answering medical questions, followed by patient 
      information generation, including medical text summarization or translation, and 
      clinical documentation. Our analysis delineates two primary domains of LLM 
      limitations: design and output. Design limitations include 6 second-order and 12 
      third-order codes, such as lack of medical domain optimization, data 
      transparency, and accessibility issues, while output limitations include 9 
      second-order and 32 third-order codes, for example, non-reproducibility, 
      non-comprehensiveness, incorrectness, unsafety, and bias. CONCLUSIONS: This 
      review systematically maps LLM applications and limitations in patient care, 
      providing a foundational framework and taxonomy for their implementation and 
      evaluation in healthcare settings.
CI  - © 2025. The Author(s).
FAU - Busch, Felix
AU  - Busch F
AUID- ORCID: 0000-0001-9770-8555
AD  - School of Medicine and Health, Department of Diagnostic and Interventional 
      Radiology, Klinikum rechts der Isar, TUM University Hospital, Technical 
      University of Munich, Munich, Germany. felix.busch@tum.de.
FAU - Hoffmann, Lena
AU  - Hoffmann L
AD  - Department of Neuroradiology, Charité - Universitätsmedizin Berlin, Corporate 
      Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Berlin, 
      Germany.
FAU - Rueger, Christopher
AU  - Rueger C
AD  - Department of Neuroradiology, Charité - Universitätsmedizin Berlin, Corporate 
      Member of Freie Universität Berlin and Humboldt Universität zu Berlin, Berlin, 
      Germany.
FAU - van Dijk, Elon Hc
AU  - van Dijk EH
AD  - Department of Ophthalmology, Leiden University Medical Center, Leiden, The 
      Netherlands.
AD  - Department of Ophthalmology, Sir Charles Gairdner Hospital, Perth, Australia.
FAU - Kader, Rawen
AU  - Kader R
AUID- ORCID: 0000-0001-9133-0838
AD  - Division of Surgery and Interventional Sciences, University College London, 
      London, United Kingdom.
FAU - Ortiz-Prado, Esteban
AU  - Ortiz-Prado E
AD  - One Health Research Group, Faculty of Health Science, Universidad de Las 
      Américas, Quito, Ecuador.
FAU - Makowski, Marcus R
AU  - Makowski MR
AUID- ORCID: 0000-0001-8778-647X
AD  - School of Medicine and Health, Department of Diagnostic and Interventional 
      Radiology, Klinikum rechts der Isar, TUM University Hospital, Technical 
      University of Munich, Munich, Germany.
FAU - Saba, Luca
AU  - Saba L
AD  - Department of Radiology, Azienda Ospedaliero Universitaria (A.O.U.), Cagliari, 
      Italy.
FAU - Hadamitzky, Martin
AU  - Hadamitzky M
AD  - School of Medicine and Health, Institute for Cardiovascular Radiology and Nuclear 
      Medicine, German Heart Center Munich, TUM University Hospital, Technical 
      University of Munich, Munich, Germany.
FAU - Kather, Jakob Nikolas
AU  - Kather JN
AUID- ORCID: 0000-0002-3730-5348
AD  - Department of Medical Oncology, National Center for Tumor Diseases (NCT), 
      Heidelberg University Hospital, Heidelberg, Germany.
AD  - Else Kroener Fresenius Center for Digital Health, Medical Faculty Carl Gustav 
      Carus, Technical University Dresden, Dresden, Germany.
FAU - Truhn, Daniel
AU  - Truhn D
AUID- ORCID: 0000-0002-9605-0728
AD  - Department of Diagnostic and Interventional Radiology, University Hospital 
      Aachen, Aachen, Germany.
FAU - Cuocolo, Renato
AU  - Cuocolo R
AD  - Department of Medicine, Surgery and Dentistry, University of Salerno, Baronissi, 
      Italy.
FAU - Adams, Lisa C
AU  - Adams LC
AD  - School of Medicine and Health, Department of Diagnostic and Interventional 
      Radiology, Klinikum rechts der Isar, TUM University Hospital, Technical 
      University of Munich, Munich, Germany.
FAU - Bressem, Keno K
AU  - Bressem KK
AD  - School of Medicine and Health, Department of Diagnostic and Interventional 
      Radiology, Klinikum rechts der Isar, TUM University Hospital, Technical 
      University of Munich, Munich, Germany.
AD  - School of Medicine and Health, Institute for Cardiovascular Radiology and Nuclear 
      Medicine, German Heart Center Munich, TUM University Hospital, Technical 
      University of Munich, Munich, Germany.
LA  - eng
GR  - 101079894/European Commission (EC)/
GR  - 101079894/European Commission (EC)/
GR  - 101079894/European Commission (EC)/
GR  - 101079894/European Commission (EC)/
GR  - 101079894/European Commission (EC)/
PT  - Journal Article
DEP - 20250121
PL  - England
TA  - Commun Med (Lond)
JT  - Communications medicine
JID - 9918250414506676
PMC - PMC11751060
OAB - Large language models (LLMs) are computer programs that can generate human-like 
      text. They promise to improve patient education and expand access to medical 
      information by helping patients better understand health conditions and treatment 
      options. However, more information is needed about how these tools are used in 
      patient care and the challenges they present. In this review, researchers 
      analyzed 89 studies from 2022 to 2023 covering 29 medical specialties. These 
      studies explored ways LLMs are used: for example, answering patient questions, 
      summarizing or translating medical texts, and supporting clinical paperwork. 
      While these tools show potential, the review highlights limitations. Many LLMs 
      are not optimized for medical use, lack transparency about data use, and can be 
      difficult for some users to access. Additionally, the text they generate may 
      sometimes be inaccurate, incomplete, or biased, raising safety concerns.
OABL- eng
COIS- Competing interests: JNK declares consulting services for Owkin, France; DoMore 
      Diagnostics, Norway; Panakeia, UK, and Scailyte, Basel, Switzerland; furthermore 
      JNK holds shares in Kather Consulting, Dresden, Germany; and StratifAI GmbH, 
      Dresden, Germany, and has received honoraria for lectures and advisory board 
      participation by AstraZeneca, Bayer, Eisai, MSD, BMS, Roche, Pfizer and 
      Fresenius. DT holds shares in StratifAI GmbH, Dresden, Germany and has received 
      honoraria for lectures by Bayer. KKB reports grants from the European Union 
      (101079894) and Wilhelm-Sander Foundation; participation on a Data Safety 
      Monitoring Board or Advisory Board for the EU Horizon 2020 LifeChamps project 
      (875329) and the EU IHI Project IMAGIO (101112053); speaker Fees for Canon 
      Medical Systems Corporation and GE HealthCare. RK receives medical consultancy 
      fees from Odin Vision. The remaining authors declare no competing interests.
EDAT- 2025/01/22 05:31
MHDA- 2025/01/22 05:32
PMCR- 2025/01/21
CRDT- 2025/01/21 23:31
PHST- 2024/03/11 00:00 [received]
PHST- 2024/12/17 00:00 [accepted]
PHST- 2025/01/22 05:32 [medline]
PHST- 2025/01/22 05:31 [pubmed]
PHST- 2025/01/21 23:31 [entrez]
PHST- 2025/01/21 00:00 [pmc-release]
AID - 10.1038/s43856-024-00717-2 [pii]
AID - 717 [pii]
AID - 10.1038/s43856-024-00717-2 [doi]
PST - epublish
SO  - Commun Med (Lond). 2025 Jan 21;5(1):26. doi: 10.1038/s43856-024-00717-2.

PMID- 39677419
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
DP  - 2024 Dec 5
TI  - Not the Models You Are Looking For: Traditional ML Outperforms LLMs in Clinical 
      Prediction Tasks.
LID - 2024.12.03.24318400 [pii]
LID - 10.1101/2024.12.03.24318400 [doi]
AB  - OBJECTIVES: To determine the extent to which current Large Language Models (LLMs) 
      can serve as substitutes for traditional machine learning (ML) as clinical 
      predictors using data from electronic health records (EHRs), we investigated 
      various factors that can impact their adoption, including overall performance, 
      calibration, fairness, and resilience to privacy protections that reduce data 
      fidelity. MATERIALS AND METHODS: We evaluated GPT-3.5, GPT-4, and ML (as 
      gradient-boosting trees) on clinical prediction tasks in EHR data from Vanderbilt 
      University Medical Center and MIMIC IV. We measured predictive performance with 
      AUROC and model calibration using Brier Score. To evaluate the impact of data 
      privacy protections, we assessed AUROC when demographic variables are 
      generalized. We evaluated algorithmic fairness using equalized odds and 
      statistical parity across race, sex, and age of patients. We also considered the 
      impact of using in-context learning by incorporating labeled examples within the 
      prompt. RESULTS: Traditional ML (AUROC: 0.847, 0.894 (VUMC, MIMIC)) substantially 
      outperformed GPT-3.5 (AUROC: 0.537, 0.517) and GPT-4 (AUROC: 0.629, 0.602) (with 
      and without in-context learning) in predictive performance and output probability 
      calibration (Brier Score (ML vs GPT-3.5 vs GPT-4): 0.134 versus 0.384 versus 
      0.251, 0.042 versus 0.06 versus 0.219). Traditional ML is more robust than 
      GPT-3.5 and GPT-4 to generalizing demographic information to protect privacy. 
      GPT-4 is the fairest model according to our selected metrics but at the cost of 
      poor model performance. CONCLUSION: These findings suggest that LLMs are much 
      less effective and robust than locally-trained ML for clinical prediction tasks, 
      but they are getting better over time.
FAU - Brown, Katherine E
AU  - Brown KE
AUID- ORCID: 0000-0003-4443-8541
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
FAU - Yan, Chao
AU  - Yan C
AUID- ORCID: 0000-0002-6719-1388
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
FAU - Li, Zhuohang
AU  - Li Z
AUID- ORCID: 0000-0001-5559-4094
AD  - Department of Computer Science, Vanderbilt University, Nashville, Tennessee.
FAU - Zhang, Xinmeng
AU  - Zhang X
AUID- ORCID: 0000-0001-7876-0753
AD  - Department of Computer Science, Vanderbilt University, Nashville, Tennessee.
FAU - Collins, Benjamin X
AU  - Collins BX
AUID- ORCID: 0000-0002-6884-3819
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
FAU - Chen, You
AU  - Chen Y
AUID- ORCID: 0000-0001-8232-8840
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
AD  - Department of Computer Science, Vanderbilt University, Nashville, Tennessee.
FAU - Clayton, Ellen Wright
AU  - Clayton EW
AUID- ORCID: 0000-0002-0308-4110
AD  - Law School, Vanderbilt University, Nashville, Tennessee, USA.
AD  - Department of Health Policy, Vanderbilt University Medical Center, Nashville, 
      Tennessee.
AD  - Department of Pediatrics, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA.
FAU - Kantarcioglu, Murat
AU  - Kantarcioglu M
AUID- ORCID: 0000-0001-9795-9063
AD  - Department of Computer Science, Virginia Tech, Blacksburg, Virginia.
FAU - Vorobeychik, Yevgeniy
AU  - Vorobeychik Y
AUID- ORCID: 0000-0003-2471-5345
AD  - Department of Computer Science, Washington University, St. Louis, Missouri.
FAU - Malin, Bradley A
AU  - Malin BA
AUID- ORCID: 0000-0003-3040-5175
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee.
AD  - Department of Computer Science, Vanderbilt University, Nashville, Tennessee.
AD  - Department of Biostatistics, Vanderbilt University Medical Center, Nashville, 
      Tennessee.
LA  - eng
GR  - T15 LM007450/LM/NLM NIH HHS/United States
GR  - U54 HG012510/HG/NHGRI NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20241205
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11643212
OTO - NOTNLM
OT  - Large language models
OT  - clinical prediction models
OT  - fairness
OT  - privacy
EDAT- 2024/12/16 17:25
MHDA- 2024/12/16 17:26
PMCR- 2024/12/13
CRDT- 2024/12/16 06:31
PHST- 2024/12/16 17:25 [pubmed]
PHST- 2024/12/16 17:26 [medline]
PHST- 2024/12/16 06:31 [entrez]
PHST- 2024/12/13 00:00 [pmc-release]
AID - 2024.12.03.24318400 [pii]
AID - 10.1101/2024.12.03.24318400 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Dec 5:2024.12.03.24318400. doi: 
      10.1101/2024.12.03.24318400.

PMID- 39278424
OWN - NLM
STAT- Publisher
LR  - 20241010
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
DP  - 2024 Sep 14
TI  - Editorial Commentary: The Scope of Medical Research Concerning ChatGPT Remains 
      Limited by Lack of Originality.
LID - S0749-8063(24)00679-0 [pii]
LID - 10.1016/j.arthro.2024.09.013 [doi]
AB  - There is no shortage of literature surrounding ChatGPT and whether this large 
      language model can provide accurate and clinically relevant information in 
      response to simulated patient queries. Unfortunately, there is a shortage of 
      literature addressing important considerations beyond these experimental and 
      entertaining uses. Indeed, a trend for redundancy has emerged where most of the 
      literature has applied ChatGPT to the same tasks while simply swapping the 
      subject matter, resulting in a failure to expand the impact and reach of this 
      potentially transformational artificial intelligence (AI) solution. Instead, 
      research addressing pressing health care challenges and a renewed focus on novel 
      use cases will allow for more meaningful research initiatives, product 
      development, and tangible changes at both the system and point-of-care levels. 
      Current target areas of interest in medicine that remain obstacles to patient 
      care include prior authorization, administrative burden, documentation 
      generation, medical triage and diagnosis, and patient communication efficiency. 
      To advance this area of research toward such meaningful applications, a 
      structured framework is necessary. Such frameworks should include problem 
      identification; definition of key performance indicators; multidisciplinary and 
      multi-institutional collaboration of those with domain expertise, including AI 
      engineers and information technology specialists; policy and strategy development 
      driven by executive-level personnel; institutional financial support and 
      investment from key stakeholders for AI infrastructure and maintenance; and 
      critical assessment of AI performance, bias, and equity.
CI  - Copyright © 2024 Arthroscopy Association of North America. Published by Elsevier 
      Inc. All rights reserved.
FAU - Kunze, Kyle N
AU  - Kunze KN
LA  - eng
PT  - Editorial
DEP - 20240914
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic & related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
COIS- Disclosures The author declares the following financial interests/personal 
      relationships which may be considered as potential competing interests: K.N.K. 
      reports a relationship with AllaiHealth and BICMD that includes consulting or 
      advisory and equity or stocks.
EDAT- 2024/09/16 00:42
MHDA- 2024/09/16 00:42
CRDT- 2024/09/15 19:26
PHST- 2024/09/04 00:00 [received]
PHST- 2024/09/06 00:00 [revised]
PHST- 2024/09/07 00:00 [accepted]
PHST- 2024/09/16 00:42 [pubmed]
PHST- 2024/09/16 00:42 [medline]
PHST- 2024/09/15 19:26 [entrez]
AID - S0749-8063(24)00679-0 [pii]
AID - 10.1016/j.arthro.2024.09.013 [doi]
PST - aheadofprint
SO  - Arthroscopy. 2024 Sep 14:S0749-8063(24)00679-0. doi: 
      10.1016/j.arthro.2024.09.013.

PMID- 34383925
OWN - NLM
STAT- MEDLINE
DCOM- 20211209
LR  - 20240403
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 28
IP  - 11
DP  - 2021 Oct 12
TI  - Bias and fairness assessment of a natural language processing opioid misuse 
      classifier: detection and mitigation of electronic health record data 
      disadvantages across racial subgroups.
PG  - 2393-2403
LID - 10.1093/jamia/ocab148 [doi]
AB  - OBJECTIVES: To assess fairness and bias of a previously validated machine 
      learning opioid misuse classifier. MATERIALS & METHODS: Two experiments were 
      conducted with the classifier's original (n = 1000) and external validation 
      (n = 53 974) datasets from 2 health systems. Bias was assessed via testing for 
      differences in type II error rates across racial/ethnic subgroups (Black, 
      Hispanic/Latinx, White, Other) using bootstrapped 95% confidence intervals. A 
      local surrogate model was estimated to interpret the classifier's predictions by 
      race and averaged globally from the datasets. Subgroup analyses and post-hoc 
      recalibrations were conducted to attempt to mitigate biased metrics. RESULTS: We 
      identified bias in the false negative rate (FNR = 0.32) of the Black subgroup 
      compared to the FNR (0.17) of the White subgroup. Top features included "heroin" 
      and "substance abuse" across subgroups. Post-hoc recalibrations eliminated bias 
      in FNR with minimal changes in other subgroup error metrics. The Black FNR 
      subgroup had higher risk scores for readmission and mortality than the White FNR 
      subgroup, and a higher mortality risk score than the Black true positive subgroup 
      (P < .05). DISCUSSION: The Black FNR subgroup had the greatest severity of 
      disease and risk for poor outcomes. Similar features were present between 
      subgroups for predicting opioid misuse, but inequities were present. Post-hoc 
      mitigation techniques mitigated bias in type II error rate without creating 
      substantial type I error rates. From model design through deployment, bias and 
      data disadvantages should be systematically addressed. CONCLUSION: Standardized, 
      transparent bias assessments are needed to improve trustworthiness in clinical 
      machine learning models.
CI  - © The Author(s) 2021. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Thompson, Hale M
AU  - Thompson HM
AD  - Department of Psychiatry & Behavioral Sciences, Rush University Medical Center, 
      Chicago, Illinois, USA.
FAU - Sharma, Brihat
AU  - Sharma B
AD  - Department of Psychiatry & Behavioral Sciences, Rush University Medical Center, 
      Chicago, Illinois, USA.
FAU - Bhalla, Sameer
AU  - Bhalla S
AD  - Department of Psychiatry & Behavioral Sciences, Rush University Medical Center, 
      Chicago, Illinois, USA.
FAU - Boley, Randy
AU  - Boley R
AD  - Department of Psychiatry & Behavioral Sciences, Rush University Medical Center, 
      Chicago, Illinois, USA.
FAU - McCluskey, Connor
AU  - McCluskey C
AD  - Department of Psychiatry & Behavioral Sciences, Rush University Medical Center, 
      Chicago, Illinois, USA.
FAU - Dligach, Dmitriy
AU  - Dligach D
AD  - Department of Computer Science, Loyola University, Chicago, Illinois, USA.
FAU - Churpek, Matthew M
AU  - Churpek MM
AD  - Department of Medicine, University of Wisconsin, Madison, Wisconsin, USA.
FAU - Karnik, Niranjan S
AU  - Karnik NS
AD  - Department of Psychiatry & Behavioral Sciences, Rush University Medical Center, 
      Chicago, Illinois, USA.
FAU - Afshar, Majid
AU  - Afshar M
AD  - Department of Medicine, University of Wisconsin, Madison, Wisconsin, USA.
LA  - eng
GR  - R01LM012973/LM/NLM NIH HHS/United States
GR  - R01DA051464/DA/NIDA NIH HHS/United States
GR  - UG1 DA049467/DA/NIDA NIH HHS/United States
GR  - R25DA035692/DA/NIDA NIH HHS/United States
GR  - K12 HS026385/HS/AHRQ HHS/United States
GR  - R01 DA051464/DA/NIDA NIH HHS/United States
GR  - R25 DA035692/DA/NIDA NIH HHS/United States
GR  - R01DA04171/DA/NIDA NIH HHS/United States
GR  - R01GM123193/GM/NIGMS NIH HHS/United States
GR  - K23AA024503/AA/NIAAA NIH HHS/United States
GR  - R01 LM012973/LM/NLM NIH HHS/United States
GR  - R01 LM010090/LM/NLM NIH HHS/United States
GR  - K12-HS-026385/HS/AHRQ HHS/United States
GR  - R01 GM123193/GM/NIGMS NIH HHS/United States
GR  - U01 TR002398/TR/NCATS NIH HHS/United States
GR  - K23 AA024503/AA/NIAAA NIH HHS/United States
GR  - UL1-TR-002398/TR/NCATS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, U.S. Gov't, P.H.S.
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Electronic Health Records
MH  - Hispanic or Latino
MH  - Humans
MH  - Machine Learning
MH  - *Natural Language Processing
MH  - *Opioid-Related Disorders
PMC - PMC8510285
OTO - NOTNLM
OT  - bias and fairness
OT  - interpretability
OT  - machine learning
OT  - natural language processing
OT  - opioid use disorder
OT  - structural racism
EDAT- 2021/08/13 06:00
MHDA- 2021/12/15 06:00
PMCR- 2021/08/12
CRDT- 2021/08/12 17:32
PHST- 2021/04/18 00:00 [received]
PHST- 2021/06/28 00:00 [revised]
PHST- 2021/07/01 00:00 [accepted]
PHST- 2021/08/13 06:00 [pubmed]
PHST- 2021/12/15 06:00 [medline]
PHST- 2021/08/12 17:32 [entrez]
PHST- 2021/08/12 00:00 [pmc-release]
AID - 6349190 [pii]
AID - ocab148 [pii]
AID - 10.1093/jamia/ocab148 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2021 Oct 12;28(11):2393-2403. doi: 10.1093/jamia/ocab148.

PMID- 38173951
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241019
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 1
DP  - 2024 Jan
TI  - Comparing Artificial Intelligence and Senior Residents in Oral Lesion Diagnosis: 
      A Comparative Study.
PG  - e51584
LID - 10.7759/cureus.51584 [doi]
LID - e51584
AB  - INTRODUCTION: Artificial intelligence (AI) is a field of computer science that 
      seeks to build intelligent machines that can carry out tasks that usually 
      necessitate human intelligence. AI may help dentists with a variety of dental 
      tasks, including clinical diagnosis and treatment planning. This study aims to 
      compare the performance of AI and oral medicine residents in diagnosing different 
      cases, providing treatment, and determining if it is reliable to assist them in 
      their field of work. METHODS: The study conducted a comparative analysis of the 
      responses from third- and fourth-year residents trained in Oral Medicine and 
      Pathology at King Saud University, College of Dentistry. The residents were given 
      a closed multiple-choice test consisting of 19 questions with four response 
      options labeled A-D and one question with five response options labeled A-E. The 
      test was administered via Google Forms, and each resident's response was stored 
      electronically in an Excel sheet (Microsoft® Corp., Redmond, WA). The residents' 
      answers were then compared to the responses generated by three major language 
      models: OpenAI, Stablediffusion, and PopAI. The questions were inputted into the 
      language models in the same format as the original test, and prior to each 
      question, an artificial intelligence chat session was created to eliminate memory 
      retention bias. The input was done on November 19, 2023, the same day the 
      official multiple-choice test was administered. The study had a sample size of 20 
      residents trained in Oral Medicine and Pathology at King Saud University, College 
      of Dentistry, consisting of both third-year and fourth-year residents. RESULT: 
      The responses of three large language models (LLM), including OpenAI, 
      Stablediffusion, and PopAI, as well as the responses of 20 senior residents for 
      20 clinical cases about oral lesion diagnosis. There were no significant 
      variations observed for the remaining questions in the responses to only two 
      questions (10%). For the remaining questions, there were no significant 
      differences. The median (IQR) score of LLMs was 50.0 (45.0 to 60.0), with a 
      minimum of 40 (for stable diffusion) and a maximum of 70 (for OpenAI). The median 
      (IQR) score of senior residents was 65.0 (55.0-75.0). The highest and lowest 
      scores of residents were 40 and 90, respectively. There was no significant 
      difference in the percent scores of residents and LLMs (p = 0.211). The agreement 
      level was measured using the Kappa value. The agreement among senior dental 
      residents was observed to be weak, with a Kappa value of 0.396. In contrast, the 
      agreement among LLMs demonstrated a moderate level, with a Kappa value of 0.622, 
      suggesting a more cohesive alignment in responses among the artificial 
      intelligence models. When comparing residents' responses with those generated by 
      different OpenAI models, including OpenAI, Stablediffusion, and PopAI, the 
      agreement levels were consistently categorized as weak, with Kappa values of 
      0.402, 0.381, and 0.392, respectively. CONCLUSION: What the current study reveals 
      is that when comparing the response score, there is no significant difference, in 
      contrast to the agreement analysis among the residents, which was low compared to 
      the LLMs, in which it was high. Dentists should consider that AI is very 
      beneficial in providing diagnosis and treatment and use it to assist them.
CI  - Copyright © 2024, Albagieh et al.
FAU - Albagieh, Hamad
AU  - Albagieh H
AD  - Oral Medicine, King Saud University, Riyadh, SAU.
FAU - Alzeer, Zaid O
AU  - Alzeer ZO
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
FAU - Alasmari, Osama N
AU  - Alasmari ON
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
FAU - Alkadhi, Abdullah A
AU  - Alkadhi AA
AD  - College of Dentistry, Dental University Hospital/King Saud University, Riyadh, 
      SAU.
FAU - Naitah, Abdulaziz N
AU  - Naitah AN
AD  - College of Dentistry, Dental University Hospital/King Saud University, Riyadh, 
      SAU.
FAU - Almasaad, Khaled F
AU  - Almasaad KF
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
FAU - Alshahrani, Turki S
AU  - Alshahrani TS
AD  - College of Dentistry, Dental University Hospital/King Saud University, Riyadh, 
      SAU.
FAU - Alshahrani, Khalid S
AU  - Alshahrani KS
AD  - College of Dentistry, Dental University Hospital/King Saud University, Riyadh, 
      SAU.
FAU - Almahmoud, Mohammed I
AU  - Almahmoud MI
AD  - Dentistry, College of Dentistry, King Saud University, Riyadh, SAU.
LA  - eng
PT  - Journal Article
DEP - 20240103
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10763647
OTO - NOTNLM
OT  - artificial intellingence in dentistry
OT  - chatgpt 3.5
OT  - llm
OT  - oral diagonisis
OT  - oral medicine
OT  - test
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/01/04 11:44
MHDA- 2024/01/04 11:45
PMCR- 2024/01/03
CRDT- 2024/01/04 04:13
PHST- 2024/01/03 00:00 [accepted]
PHST- 2024/01/04 11:45 [medline]
PHST- 2024/01/04 11:44 [pubmed]
PHST- 2024/01/04 04:13 [entrez]
PHST- 2024/01/03 00:00 [pmc-release]
AID - 10.7759/cureus.51584 [doi]
PST - epublish
SO  - Cureus. 2024 Jan 3;16(1):e51584. doi: 10.7759/cureus.51584. eCollection 2024 Jan.

PMID- 39331527
OWN - NLM
STAT- MEDLINE
DCOM- 20240927
LR  - 20241006
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Sep 27
TI  - Artificial Intelligence in Dental Education: Opportunities and Challenges of 
      Large Language Models and Multimodal Foundation Models.
PG  - e52346
LID - 10.2196/52346 [doi]
LID - e52346
AB  - Instructional and clinical technologies have been transforming dental education. 
      With the emergence of artificial intelligence (AI), the opportunities of using AI 
      in education has increased. With the recent advancement of generative AI, large 
      language models (LLMs) and foundation models gained attention with their 
      capabilities in natural language understanding and generation as well as 
      combining multiple types of data, such as text, images, and audio. A common 
      example has been ChatGPT, which is based on a powerful LLM-the GPT model. This 
      paper discusses the potential benefits and challenges of incorporating LLMs in 
      dental education, focusing on periodontal charting with a use case to outline 
      capabilities of LLMs. LLMs can provide personalized feedback, generate case 
      scenarios, and create educational content to contribute to the quality of dental 
      education. However, challenges, limitations, and risks exist, including bias and 
      inaccuracy in the content created, privacy and security concerns, and the risk of 
      overreliance. With guidance and oversight, and by effectively and ethically 
      integrating LLMs, dental education can incorporate engaging and personalized 
      learning experiences for students toward readiness for real-life clinical 
      practice.
CI  - © Daniel Claman, Emre Sezgin. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org).
FAU - Claman, Daniel
AU  - Claman D
AUID- ORCID: 0000-0003-4286-3333
AD  - Pediatric Dentistry, Nationwide Children's Hospital, Columbus, OH, United States.
FAU - Sezgin, Emre
AU  - Sezgin E
AUID- ORCID: 0000-0001-8798-9605
AD  - Department of Pediatrics, The Ohio State University College of Medicine, 
      Columbus, OH, United States.
AD  - Center for Biobehavioral Health, The Abigail Wexner Research Institute at 
      Nationwide Children's Hospital, 700, Children's Drive, Columbus, OH, 43205, 
      United States, 1 6147223179.
LA  - eng
PT  - Journal Article
DEP - 20240927
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - *Artificial Intelligence
MH  - Humans
MH  - *Education, Dental/methods
MH  - Models, Educational
PMC - PMC11451510
OTO - NOTNLM
OT  - generative pretrained transformer
OT  - AI
OT  - ChatGPT
OT  - GPT
OT  - LLM
OT  - LLMs
OT  - artificial intelligence
OT  - chatbot
OT  - dental education
OT  - innovation
OT  - large language model
OT  - large language models
OT  - natural language
OT  - periodontal health
OT  - technology
COIS- ES is an associate editor in the editorial board of Journal of Medical Internet 
      Research at the time of this publication.
EDAT- 2024/09/27 18:53
MHDA- 2024/09/27 18:54
PMCR- 2024/09/27
CRDT- 2024/09/27 13:02
PHST- 2023/09/05 00:00 [received]
PHST- 2024/06/19 00:00 [revised]
PHST- 2024/06/19 00:00 [accepted]
PHST- 2024/09/27 18:54 [medline]
PHST- 2024/09/27 18:53 [pubmed]
PHST- 2024/09/27 13:02 [entrez]
PHST- 2024/09/27 00:00 [pmc-release]
AID - v10i1e52346 [pii]
AID - 52346 [pii]
AID - 10.2196/52346 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Sep 27;10:e52346. doi: 10.2196/52346.

PMID- 39132980
OWN - NLM
STAT- MEDLINE
DCOM- 20240812
LR  - 20240815
IS  - 2639-8028 (Electronic)
IS  - 2639-8028 (Linking)
VI  - 6
IP  - 8
DP  - 2024 Aug 1
TI  - Incorporating Patient Values in Large Language Model Recommendations for 
      Surrogate and Proxy Decisions.
PG  - e1131
LID - 10.1097/CCE.0000000000001131 [doi]
LID - e1131
AB  - BACKGROUND: Surrogates, proxies, and clinicians making shared treatment decisions 
      for patients who have lost decision-making capacity often fail to honor patients' 
      wishes, due to stress, time pressures, misunderstanding patient values, and 
      projecting personal biases. Advance directives intend to align care with patient 
      values but are limited by low completion rates and application to only a subset 
      of medical decisions. Here, we investigate the potential of large language models 
      (LLMs) to incorporate patient values in supporting critical care clinical 
      decision-making for incapacitated patients in a proof-of-concept study. METHODS: 
      We simulated text-based scenarios for 50 decisionally incapacitated patients for 
      whom a medical condition required imminent clinical decisions regarding specific 
      interventions. For each patient, we also simulated five unique value profiles 
      captured using alternative formats: numeric ranking questionnaires, text-based 
      questionnaires, and free-text narratives. We used pre-trained generative LLMs for 
      two tasks: 1) text extraction of the treatments under consideration and 2) 
      prompt-based question-answering to generate a recommendation in response to the 
      scenario information, extracted treatment, and patient value profiles. Model 
      outputs were compared with adjudications by three domain experts who 
      independently evaluated each scenario and decision. RESULTS AND CONCLUSIONS: 
      Automated extractions of the treatment in question were accurate for 88% (n = 
      44/50) of scenarios. LLM treatment recommendations received an average Likert 
      score by the adjudicators of 3.92 of 5.00 (five being best) across all patients 
      for being medically plausible and reasonable treatment recommendations, and 3.58 
      of 5.00 for reflecting the documented values of the patient. Scores were highest 
      when patient values were captured as short, unstructured, and free-text 
      narratives based on simulated patient profiles. This proof-of-concept study 
      demonstrates the potential for LLMs to function as support tools for surrogates, 
      proxies, and clinicians aiming to honor the wishes and values of decisionally 
      incapacitated patients.
CI  - Copyright © 2024 The Authors. Published by Wolters Kluwer Health, Inc. on behalf 
      of the Society of Critical Care Medicine.
FAU - Nolan, Victoria J
AU  - Nolan VJ
AD  - Department of Surgery, University of Florida, Gainesville, FL.
FAU - Balch, Jeremy A
AU  - Balch JA
AD  - Department of Surgery, University of Florida, Gainesville, FL.
FAU - Baskaran, Naveen P
AU  - Baskaran NP
AD  - Department of Medicine, University of Florida, Gainesville, FL.
FAU - Shickel, Benjamin
AU  - Shickel B
AD  - Department of Medicine, University of Florida, Gainesville, FL.
FAU - Efron, Philip A
AU  - Efron PA
AD  - Department of Surgery, University of Florida, Gainesville, FL.
FAU - Upchurch, Gilbert R Jr
AU  - Upchurch GR Jr
AD  - Department of Surgery, University of Florida, Gainesville, FL.
FAU - Bihorac, Azra
AU  - Bihorac A
AD  - Department of Medicine, University of Florida, Gainesville, FL.
FAU - Tignanelli, Christopher J
AU  - Tignanelli CJ
AD  - Department of Surgery, University of Minnesota, Minneapolis-Saint Paul, MN.
FAU - Moseley, Ray E
AU  - Moseley RE
AD  - College of Medicine, University of Florida, Gainesville, FL.
FAU - Loftus, Tyler J
AU  - Loftus TJ
AUID- ORCID: 0000-0001-5354-443
AD  - Department of Surgery, University of Florida, Gainesville, FL.
LA  - eng
GR  - K23 GM140268/GM/NIGMS NIH HHS/United States
GR  - R01 GM149657/GM/NIGMS NIH HHS/United States
PT  - Journal Article
DEP - 20240812
PL  - United States
TA  - Crit Care Explor
JT  - Critical care explorations
JID - 101746347
SB  - IM
MH  - Humans
MH  - *Proxy
MH  - Advance Directives
MH  - Decision Making
MH  - Clinical Decision-Making/methods
MH  - Proof of Concept Study
MH  - Surveys and Questionnaires
MH  - Language
MH  - Critical Care/methods
PMC - PMC11321752
COIS- Dr. Loftus was supported by the National Institute of General Medical Sciences of 
      the National Institutes of Health under Award Numbers K23 GM140268 and R01 
      GM149657; he was also supported by the Thomas Maren Junior Investigator Fund. The 
      remaining authors have disclosed that they do not have any potential conflicts of 
      interest.
EDAT- 2024/08/12 12:42
MHDA- 2024/08/12 12:43
PMCR- 2024/08/12
CRDT- 2024/08/12 08:53
PHST- 2024/08/12 12:43 [medline]
PHST- 2024/08/12 12:42 [pubmed]
PHST- 2024/08/12 08:53 [entrez]
PHST- 2024/08/12 00:00 [pmc-release]
AID - 02107256-202408000-00010 [pii]
AID - CCE-D-24-00122 [pii]
AID - 10.1097/CCE.0000000000001131 [doi]
PST - epublish
SO  - Crit Care Explor. 2024 Aug 12;6(8):e1131. doi: 10.1097/CCE.0000000000001131. 
      eCollection 2024 Aug 1.

PMID- 39178224
OWN - NLM
STAT- MEDLINE
DCOM- 20240823
LR  - 20240825
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 19
IP  - 8
DP  - 2024
TI  - The state of artificial intelligence in medical research: A survey of 
      corresponding authors from top medical journals.
PG  - e0309208
LID - 10.1371/journal.pone.0309208 [doi]
LID - e0309208
AB  - Natural Language Processing (NLP) is a subset of artificial intelligence that 
      enables machines to understand and respond to human language through Large 
      Language Models (LLMs)‥ These models have diverse applications in fields such as 
      medical research, scientific writing, and publishing, but concerns such as 
      hallucination, ethical issues, bias, and cybersecurity need to be addressed. To 
      understand the scientific community's understanding and perspective on the role 
      of Artificial Intelligence (AI) in research and authorship, a survey was designed 
      for corresponding authors in top medical journals. An online survey was conducted 
      from July 13th, 2023, to September 1st, 2023, using the SurveyMonkey web 
      instrument, and the population of interest were corresponding authors who 
      published in 2022 in the 15 highest-impact medical journals, as ranked by the 
      Journal Citation Report. The survey link has been sent to all the identified 
      corresponding authors by mail. A total of 266 authors answered, and 236 entered 
      the final analysis. Most of the researchers (40.6%) reported having moderate 
      familiarity with artificial intelligence, while a minority (4.4%) had no 
      associated knowledge. Furthermore, the vast majority (79.0%) believe that 
      artificial intelligence will play a major role in the future of research. Of 
      note, no correlation between academic metrics and artificial intelligence 
      knowledge or confidence was found. The results indicate that although researchers 
      have varying degrees of familiarity with artificial intelligence, its use in 
      scientific research is still in its early phases. Despite lacking formal AI 
      training, many scholars publishing in high-impact journals have started 
      integrating such technologies into their projects, including rephrasing, 
      translation, and proofreading tasks. Efforts should focus on providing training 
      for their effective use, establishing guidelines by journal editors, and creating 
      software applications that bundle multiple integrated tools into a single 
      platform.
CI  - Copyright: © 2024 Salvagno et al. This is an open access article distributed 
      under the terms of the Creative Commons Attribution License, which permits 
      unrestricted use, distribution, and reproduction in any medium, provided the 
      original author and source are credited.
FAU - Salvagno, Michele
AU  - Salvagno M
AUID- ORCID: 0000-0002-8415-4247
AD  - Department of Intensive Care, Hôpital Universitaire de Bruxelles (HUB), Brussels, 
      Belgium.
FAU - Cassai, Alessandro De
AU  - Cassai A
AUID- ORCID: 0000-0002-9773-1832
AD  - Sant'Antonio Anesthesia and Intensive Care Unit, University Hospital of Padua, 
      Padua, Italy.
FAU - Zorzi, Stefano
AU  - Zorzi S
AD  - Department of Intensive Care, Hôpital Universitaire de Bruxelles (HUB), Brussels, 
      Belgium.
FAU - Zaccarelli, Mario
AU  - Zaccarelli M
AD  - Department of Intensive Care, Hôpital Universitaire de Bruxelles (HUB), Brussels, 
      Belgium.
FAU - Pasetto, Marco
AU  - Pasetto M
AUID- ORCID: 0009-0003-4055-2088
AD  - Department of Intensive Care, Hôpital Universitaire de Bruxelles (HUB), Brussels, 
      Belgium.
FAU - Sterchele, Elda Diletta
AU  - Sterchele ED
AD  - Department of Intensive Care, Hôpital Universitaire de Bruxelles (HUB), Brussels, 
      Belgium.
FAU - Chumachenko, Dmytro
AU  - Chumachenko D
AUID- ORCID: 0000-0003-2623-3294
AD  - Department of Mathematical Modelling and Artificial Intelligence, National 
      Aerospace University "Kharkiv Aviation Institute", Kharkiv, Ukraine.
AD  - Ubiquitous Health Technologies Lab, University of Waterloo, Waterloo, Canada.
FAU - Gerli, Alberto Giovanni
AU  - Gerli AG
AD  - Department of Clinical Sciences and Community Health, Università degli Studi di 
      Milano, Milan, Italy.
FAU - Azamfirei, Razvan
AU  - Azamfirei R
AUID- ORCID: 0000-0003-3301-0566
AD  - Department of Anesthesiology and Critical Care Medicine, Johns Hopkins University 
      School of Medicine, Baltimore, MD, United States of America.
FAU - Taccone, Fabio Silvio
AU  - Taccone FS
AD  - Department of Intensive Care, Hôpital Universitaire de Bruxelles (HUB), Brussels, 
      Belgium.
LA  - eng
PT  - Journal Article
DEP - 20240823
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - *Artificial Intelligence
MH  - Humans
MH  - *Biomedical Research
MH  - Surveys and Questionnaires
MH  - *Authorship
MH  - *Periodicals as Topic/statistics & numerical data
MH  - Natural Language Processing
PMC - PMC11343420
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/08/23 18:41
MHDA- 2024/08/23 18:42
PMCR- 2024/08/23
CRDT- 2024/08/23 13:53
PHST- 2023/11/22 00:00 [received]
PHST- 2024/08/08 00:00 [accepted]
PHST- 2024/08/23 18:42 [medline]
PHST- 2024/08/23 18:41 [pubmed]
PHST- 2024/08/23 13:53 [entrez]
PHST- 2024/08/23 00:00 [pmc-release]
AID - PONE-D-23-38146 [pii]
AID - 10.1371/journal.pone.0309208 [doi]
PST - epublish
SO  - PLoS One. 2024 Aug 23;19(8):e0309208. doi: 10.1371/journal.pone.0309208. 
      eCollection 2024.

PMID- 37892198
OWN - NLM
STAT- MEDLINE
DCOM- 20231030
LR  - 20231030
IS  - 2218-273X (Electronic)
IS  - 2218-273X (Linking)
VI  - 13
IP  - 10
DP  - 2023 Oct 12
TI  - Using LLMs and Explainable ML to Analyze Biomarkers at Single-Cell Level for 
      Improved Understanding of Diseases.
LID - 10.3390/biom13101516 [doi]
LID - 1516
AB  - Single-cell RNA sequencing (scRNA-seq) technology has significantly advanced our 
      understanding of the diversity of cells and how this diversity is implicated in 
      diseases. Yet, translating these findings across various scRNA-seq datasets poses 
      challenges due to technical variability and dataset-specific biases. To overcome 
      this, we present a novel approach that employs both an LLM-based framework and 
      explainable machine learning to facilitate generalization across single-cell 
      datasets and identify gene signatures to capture disease-driven transcriptional 
      changes. Our approach uses scBERT, which harnesses shared transcriptomic features 
      among cell types to establish consistent cell-type annotations across multiple 
      scRNA-seq datasets. Additionally, we employed a symbolic regression algorithm to 
      pinpoint highly relevant, yet minimally redundant models and features for 
      inferring a cell type's disease state based on its transcriptomic profile. We 
      ascertained the versatility of these cell-specific gene signatures across 
      datasets, showcasing their resilience as molecular markers to pinpoint and 
      characterize disease-associated cell types. The validation was carried out using 
      four publicly available scRNA-seq datasets from both healthy individuals and 
      those suffering from ulcerative colitis (UC). This demonstrates our approach's 
      efficacy in bridging disparities specific to different datasets, fostering 
      comparative analyses. Notably, the simplicity and symbolic nature of the 
      retrieved gene signatures facilitate their interpretability, allowing us to 
      elucidate underlying molecular disease mechanisms using these models.
FAU - Elsborg, Jonas
AU  - Elsborg J
AUID- ORCID: 0000-0002-1283-6492
AD  - Department of Energy Conversion and Storage, Technical University of Denmark, 
      2800 Kongens Lyngby, Denmark.
AD  - Abzu ApS, 2150 København, Denmark.
FAU - Salvatore, Marco
AU  - Salvatore M
AUID- ORCID: 0000-0001-5775-0417
AD  - Abzu ApS, 2150 København, Denmark.
LA  - eng
PT  - Journal Article
DEP - 20231012
PL  - Switzerland
TA  - Biomolecules
JT  - Biomolecules
JID - 101596414
RN  - 0 (Biomarkers)
SB  - IM
MH  - Humans
MH  - *Single-Cell Analysis
MH  - Sequence Analysis, RNA
MH  - *Algorithms
MH  - Gene Expression Profiling
MH  - Biomarkers
PMC - PMC10605495
OTO - NOTNLM
OT  - LLM
OT  - biomarker
OT  - interpretability
OT  - machine learning
OT  - scRNA-seq
OT  - symbolic regression
COIS- The authors are employed at Abzu, the developers of the QLattice. The QLattice is 
      freely available only for academic use.
EDAT- 2023/10/28 11:44
MHDA- 2023/10/30 06:46
PMCR- 2023/10/12
CRDT- 2023/10/28 01:02
PHST- 2023/08/24 00:00 [received]
PHST- 2023/10/07 00:00 [revised]
PHST- 2023/10/09 00:00 [accepted]
PHST- 2023/10/30 06:46 [medline]
PHST- 2023/10/28 11:44 [pubmed]
PHST- 2023/10/28 01:02 [entrez]
PHST- 2023/10/12 00:00 [pmc-release]
AID - biom13101516 [pii]
AID - biomolecules-13-01516 [pii]
AID - 10.3390/biom13101516 [doi]
PST - epublish
SO  - Biomolecules. 2023 Oct 12;13(10):1516. doi: 10.3390/biom13101516.

PMID- 38640573
OWN - NLM
STAT- MEDLINE
DCOM- 20240513
LR  - 20240513
IS  - 1872-8464 (Electronic)
IS  - 0165-5876 (Linking)
VI  - 180
DP  - 2024 May
TI  - Comparison of ChatGPT knowledge against 2020 consensus statement on ankyloglossia 
      in children.
PG  - 111957
LID - S0165-5876(24)00111-3 [pii]
LID - 10.1016/j.ijporl.2024.111957 [doi]
AB  - OBJECTIVE: This paper evaluates ChatGPT's accuracy and consistency in providing 
      information on ankyloglossia, a congenital oral condition. Assessing alignment 
      with expert consensus, the study explores potential implications for patients 
      relying on AI for medical information. METHODS: Statements from the 2020 clinical 
      consensus statement on ankyloglossia were presented to ChatGPT, and its responses 
      were scored using a 9-point Likert scale. The study analyzed the mean and 
      standard deviation of ChatGPT scores for each statement. Statistical analysis was 
      conducted using Excel. RESULTS: Among the 63 statements assessed, 67 % of ChatGPT 
      responses closely aligned with expert consensus mean scores. However, 17 % 
      (11/63) were statements in which the ChatGPT mean response was different from the 
      CCS mean by 2.0 or greater, raising concerns about ChatGPT's potential influence 
      in disseminating uncertain or debated medical information. Variations in mean 
      scores highlighted discrepancies, with some statements showing significant 
      deviations from expert opinions. CONCLUSION: While ChatGPT mirrored medical 
      viewpoints on ankyloglossia, alignment with non-consensus statements raises 
      caution in relying on it for medical advice. Future research should refine AI 
      models, address inaccuracies, and explore diverse user queries for safe 
      integration into medical decision-making. Despite potential benefits, ongoing 
      examination of ChatGPT's power and limitations is crucial, considering its impact 
      on health equity and information access.
CI  - Copyright © 2024 Elsevier B.V. All rights reserved.
FAU - Howard, Eileen C
AU  - Howard EC
AD  - Boston University Chobanian & Avedisian School of Medicine, Boston, MA, USA. 
      Electronic address: echoward@bu.edu.
FAU - Chong, Nicholas Y K
AU  - Chong NYK
AD  - Boston University Chobanian & Avedisian School of Medicine, Boston, MA, USA.
FAU - Carnino, Jonathan M
AU  - Carnino JM
AD  - Boston University Chobanian & Avedisian School of Medicine, Boston, MA, USA.
FAU - Levi, Jessica R
AU  - Levi JR
AD  - Boston University Chobanian & Avedisian School of Medicine, Boston, MA, USA; 
      Department of Otolaryngology - Head and Neck Surgery, Boston Medical Center, 
      Boston, MA, USA.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20240416
PL  - Ireland
TA  - Int J Pediatr Otorhinolaryngol
JT  - International journal of pediatric otorhinolaryngology
JID - 8003603
SB  - IM
MH  - Humans
MH  - *Ankyloglossia
MH  - *Consensus
MH  - Child
OTO - NOTNLM
OT  - Ankyloglossia
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Consensus statement
COIS- Declaration of competing interest none.
EDAT- 2024/04/20 00:44
MHDA- 2024/05/14 00:43
CRDT- 2024/04/19 18:02
PHST- 2024/01/12 00:00 [received]
PHST- 2024/04/01 00:00 [revised]
PHST- 2024/04/13 00:00 [accepted]
PHST- 2024/05/14 00:43 [medline]
PHST- 2024/04/20 00:44 [pubmed]
PHST- 2024/04/19 18:02 [entrez]
AID - S0165-5876(24)00111-3 [pii]
AID - 10.1016/j.ijporl.2024.111957 [doi]
PST - ppublish
SO  - Int J Pediatr Otorhinolaryngol. 2024 May;180:111957. doi: 
      10.1016/j.ijporl.2024.111957. Epub 2024 Apr 16.

PMID- 35308909
OWN - NLM
STAT- MEDLINE
DCOM- 20220408
LR  - 20220429
IS  - 1942-597X (Electronic)
IS  - 1559-4076 (Linking)
VI  - 2021
DP  - 2021
TI  - Bias Assessment and Correction in Machine Learning Algorithms: A Use-Case in a 
      Natural Language Processing Algorithm to Identify Hospitalized Patients with 
      Unhealthy Alcohol Use.
PG  - 247-254
AB  - Unhealthy alcohol use represents a major economic burden and cause of morbidity 
      and mortality in the United States. Implementation of interventions for unhealthy 
      alcohol use depends on the availability and accuracy of screening tools. Our 
      group previously applied methods in natural language processing and machine 
      learning to build a classifier for unhealthy alcohol use. In this study, we 
      sought to evaluate and address bias through the use-case of our classifier. We 
      demonstrated the presence of biased unhealthy alcohol use risk underestimation 
      among Hispanic compared to Non-Hispanic White trauma inpatients, 18- to 
      44-year-old compared to 45 years and older medical/surgical inpatients, and 
      Non-Hispanic Black compared to Non-Hispanic White medical/surgical inpatients. We 
      further showed that intercept, slope, and concurrent intercept and slope 
      recalibration resulted in minimal or no improvements in bias-indicating metrics 
      within these subgroups. Our results exemplify the importance of integrating bias 
      assessment early into the classifier development pipeline.
CI  - ©2021 AMIA - All rights reserved.
FAU - Borgese, Marissa
AU  - Borgese M
AD  - Loyola University Chicago Stritch School of Medicine, Maywood, IL.
FAU - Joyce, Cara
AU  - Joyce C
AD  - Loyola University Chicago, Chicago, IL.
FAU - Anderson, Emily E
AU  - Anderson EE
AD  - Loyola University Chicago, Chicago, IL.
FAU - Churpek, Matthew M
AU  - Churpek MM
AD  - University of Wisconsin, Madison, WI.
FAU - Afshar, Majid
AU  - Afshar M
AD  - Loyola University Chicago, Chicago, IL.
AD  - University of Wisconsin, Madison, WI.
LA  - eng
GR  - K23 AA024503/AA/NIAAA NIH HHS/United States
GR  - R01 DA051464/DA/NIDA NIH HHS/United States
PT  - Journal Article
DEP - 20220221
PL  - United States
TA  - AMIA Annu Symp Proc
JT  - AMIA ... Annual Symposium proceedings. AMIA Symposium
JID - 101209213
SB  - IM
MH  - Adolescent
MH  - Adult
MH  - Algorithms
MH  - Hispanic or Latino
MH  - Humans
MH  - Inpatients
MH  - *Machine Learning
MH  - *Natural Language Processing
MH  - United States
MH  - Young Adult
PMC - PMC8861719
EDAT- 2022/03/22 06:00
MHDA- 2022/04/09 06:00
PMCR- 2022/02/21
CRDT- 2022/03/21 08:45
PHST- 2022/03/21 08:45 [entrez]
PHST- 2022/03/22 06:00 [pubmed]
PHST- 2022/04/09 06:00 [medline]
PHST- 2022/02/21 00:00 [pmc-release]
AID - 3575666 [pii]
PST - epublish
SO  - AMIA Annu Symp Proc. 2022 Feb 21;2021:247-254. eCollection 2021.

PMID- 40056436
OWN - NLM
STAT- Publisher
LR  - 20250308
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Linking)
DP  - 2025 Mar 8
TI  - Large language models are less effective at clinical prediction tasks than 
      locally trained machine learning models.
LID - ocaf038 [pii]
LID - 10.1093/jamia/ocaf038 [doi]
AB  - OBJECTIVES: To determine the extent to which current large language models (LLMs) 
      can serve as substitutes for traditional machine learning (ML) as clinical 
      predictors using data from electronic health records (EHRs), we investigated 
      various factors that can impact their adoption, including overall performance, 
      calibration, fairness, and resilience to privacy protections that reduce data 
      fidelity. MATERIALS AND METHODS: We evaluated GPT-3.5, GPT-4, and traditional ML 
      (as gradient-boosting trees) on clinical prediction tasks in EHR data from 
      Vanderbilt University Medical Center (VUMC) and MIMIC IV. We measured predictive 
      performance with area under the receiver operating characteristic (AUROC) and 
      model calibration using Brier Score. To evaluate the impact of data privacy 
      protections, we assessed AUROC when demographic variables are generalized. We 
      evaluated algorithmic fairness using equalized odds and statistical parity across 
      race, sex, and age of patients. We also considered the impact of using in-context 
      learning by incorporating labeled examples within the prompt. RESULTS: 
      Traditional ML [AUROC: 0.847, 0.894 (VUMC, MIMIC)] substantially outperformed 
      GPT-3.5 (AUROC: 0.537, 0.517) and GPT-4 (AUROC: 0.629, 0.602) (with and without 
      in-context learning) in predictive performance and output probability calibration 
      [Brier Score (ML vs GPT-3.5 vs GPT-4): 0.134 vs 0.384 vs 0.251, 0.042 vs 0.06 vs 
      0.219)]. DISCUSSION: Traditional ML is more robust than GPT-3.5 and GPT-4 in 
      generalizing demographic information to protect privacy. GPT-4 is the fairest 
      model according to our selected metrics but at the cost of poor model 
      performance. CONCLUSION: These findings suggest that non-fine-tuned LLMs are less 
      effective and robust than locally trained ML for clinical prediction tasks, but 
      they are improving across releases.
CI  - © The Author(s) 2025. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Brown, Katherine E
AU  - Brown KE
AUID- ORCID: 0000-0003-4443-8541
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center 
      (VUMC), Nashville, TN 37203, United States.
FAU - Yan, Chao
AU  - Yan C
AUID- ORCID: 0000-0002-6719-1388
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center 
      (VUMC), Nashville, TN 37203, United States.
FAU - Li, Zhuohang
AU  - Li Z
AUID- ORCID: 0000-0001-5559-4094
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN 37212, 
      United States.
FAU - Zhang, Xinmeng
AU  - Zhang X
AUID- ORCID: 0000-0001-7876-0753
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN 37212, 
      United States.
FAU - Collins, Benjamin X
AU  - Collins BX
AUID- ORCID: 0000-0002-6884-3819
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center 
      (VUMC), Nashville, TN 37203, United States.
FAU - Chen, You
AU  - Chen Y
AUID- ORCID: 0000-0001-8232-8840
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center 
      (VUMC), Nashville, TN 37203, United States.
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN 37212, 
      United States.
FAU - Clayton, Ellen Wright
AU  - Clayton EW
AUID- ORCID: 0000-0002-0308-4110
AD  - Law School, Vanderbilt University, Nashville, TN 37203, United States.
AD  - Department of Health Policy, Vanderbilt University Medical Center (VUMC), 
      Nashville, TN 37203, United States.
AD  - Department of Pediatrics, Vanderbilt University Medical Center (VUMC), Nashville, 
      TN 37232, United States.
FAU - Kantarcioglu, Murat
AU  - Kantarcioglu M
AUID- ORCID: 0000-0001-9795-9063
AD  - Department of Computer Science, Virginia Tech, Blacksburg, VA 24061, United 
      States.
FAU - Vorobeychik, Yevgeniy
AU  - Vorobeychik Y
AUID- ORCID: 0000-0003-2471-5345
AD  - Department of Computer Science, Washington University, St. Louis, MO 63130, 
      United States.
FAU - Malin, Bradley A
AU  - Malin BA
AUID- ORCID: 0000-0003-3040-5175
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center 
      (VUMC), Nashville, TN 37203, United States.
AD  - Department of Computer Science, Vanderbilt University, Nashville, TN 37212, 
      United States.
AD  - Department of Biostatistics, Vanderbilt University Medical Center (VUMC), 
      Nashville, TN 37203, United States.
LA  - eng
GR  - U54HG012510/NH/NIH HHS/United States
GR  - IIS-1905558/National Science Foundation/
PT  - Journal Article
DEP - 20250308
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
OTO - NOTNLM
OT  - clinical prediction models
OT  - fairness
OT  - large language models
OT  - privacy
EDAT- 2025/03/09 15:06
MHDA- 2025/03/09 15:06
CRDT- 2025/03/08 13:52
PHST- 2024/11/11 00:00 [received]
PHST- 2025/01/31 00:00 [revised]
PHST- 2025/02/21 00:00 [accepted]
PHST- 2025/03/09 15:06 [medline]
PHST- 2025/03/09 15:06 [pubmed]
PHST- 2025/03/08 13:52 [entrez]
AID - 8064348 [pii]
AID - 10.1093/jamia/ocaf038 [doi]
PST - aheadofprint
SO  - J Am Med Inform Assoc. 2025 Mar 8:ocaf038. doi: 10.1093/jamia/ocaf038.

PMID- 35300959
OWN - NLM
STAT- MEDLINE
DCOM- 20220510
LR  - 20230502
IS  - 2213-2201 (Electronic)
IS  - 2213-2198 (Print)
VI  - 10
IP  - 5
DP  - 2022 May
TI  - A Framework for Augmented Intelligence in Allergy and Immunology Practice and 
      Research-A Work Group Report of the AAAAI Health Informatics, Technology, and 
      Education Committee.
PG  - 1178-1188
LID - S2213-2198(22)00143-X [pii]
LID - 10.1016/j.jaip.2022.01.047 [doi]
AB  - Artificial and augmented intelligence (AI) and machine learning (ML) methods are 
      expanding into the health care space. Big data are increasingly used in patient 
      care applications, diagnostics, and treatment decisions in allergy and 
      immunology. How these technologies will be evaluated, approved, and assessed for 
      their impact is an important consideration for researchers and practitioners 
      alike. With the potential of ML, deep learning, natural language processing, and 
      other assistive methods to redefine health care usage, a scaffold for the impact 
      of AI technology on research and patient care in allergy and immunology is 
      needed. An American Academy of Asthma Allergy and Immunology Health Information 
      Technology and Education subcommittee workgroup was convened to perform a scoping 
      review of AI within health care as well as the specialty of allergy and 
      immunology to address impacts on allergy and immunology practice and research as 
      well as potential challenges including education, AI governance, ethical and 
      equity considerations, and potential opportunities for the specialty. There are 
      numerous potential clinical applications of AI in allergy and immunology that 
      range from disease diagnosis to multidimensional data reduction in electronic 
      health records or immunologic datasets. For appropriate application and 
      interpretation of AI, specialists should be involved in the design, validation, 
      and implementation of AI in allergy and immunology. Challenges include 
      incorporation of data science and bioinformatics into training of future 
      allergists-immunologists.
CI  - Published by Elsevier Inc.
FAU - Khoury, Paneez
AU  - Khoury P
AD  - Laboratory of Allergic Diseases, NIAID, Bethesda, Md. Electronic address: 
      khouryp@nih.gov.
FAU - Srinivasan, Renganathan
AU  - Srinivasan R
AD  - The Vancouver Clinic, Vancouver, Wash.
FAU - Kakumanu, Sujani
AU  - Kakumanu S
AD  - Division of Allergy, Pulmonary and Critical Care Medicine, University of 
      Wisconsin School of Medicine and Public Health and the William S. Middleton 
      Veterans Memorial Hospital, Madison, Wisc.
FAU - Ochoa, Sebastian
AU  - Ochoa S
AD  - National Institutes of Infectious and Allergic Diseases, Bethesda, Md; Laboratory 
      of Clinical Immunology and Microbiology, NIAID, Bethesda, Md.
FAU - Keswani, Anjeni
AU  - Keswani A
AD  - Division of Allergy/Immunology, George Washington University School of Medicine 
      and Health Sciences, Washington, DC.
FAU - Sparks, Rachel
AU  - Sparks R
AD  - National Institutes of Infectious and Allergic Diseases, Bethesda, Md; Laboratory 
      of Immune System Biology, NIAID, Bethesda, Md.
FAU - Rider, Nicholas L
AU  - Rider NL
AD  - Section of Immunology, Allergy and Retrovirology and the William T. Shearer 
      Center for Human Immunobiology, Baylor College of Medicine, Texas Children's 
      Hospital, Houston, Texas.
LA  - eng
GR  - ZIE AI001148/ImNIH/Intramural NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Intramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20220315
PL  - United States
TA  - J Allergy Clin Immunol Pract
JT  - The journal of allergy and clinical immunology. In practice
JID - 101597220
SB  - IM
MH  - Humans
MH  - *Hypersensitivity/diagnosis/therapy
MH  - Intelligence
MH  - *Medical Informatics
MH  - Natural Language Processing
MH  - Technology
PMC - PMC9205719
MID - NIHMS1795111
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Asthma
OT  - Atopic dermatitis
OT  - Augmented intelligence
OT  - Clinical decision support
OT  - Electronic health records
OT  - Equity
OT  - Machine learning
OT  - Medical education
OT  - Natural language processing
OT  - Primary immunodeficiency
COIS- Conflicts of Interest: RS, SOG, AK and RS declare no conflicts of interest. PK 
      has received research grant funding from CEGIR/NCATS and APFED. SK has received 
      royalties from UpToDate and federal grant funding from VA HSR&D and NLR receives 
      grant funding from the Jeffrey Modell Foundation, Takeda Pharmaceuticals and 
      Pharma Healthcare. He is a consultant to Horizon Therapeutics, Takeda 
      Pharmaceuticals and Pharming Healthcare. He receives royalties for topic 
      contributions to Up-to-Date from Wolters Kluwer.
EDAT- 2022/03/19 06:00
MHDA- 2022/05/11 06:00
PMCR- 2023/05/01
CRDT- 2022/03/18 05:38
PHST- 2021/07/16 00:00 [received]
PHST- 2022/01/19 00:00 [revised]
PHST- 2022/01/20 00:00 [accepted]
PHST- 2022/03/19 06:00 [pubmed]
PHST- 2022/05/11 06:00 [medline]
PHST- 2022/03/18 05:38 [entrez]
PHST- 2023/05/01 00:00 [pmc-release]
AID - S2213-2198(22)00143-X [pii]
AID - 10.1016/j.jaip.2022.01.047 [doi]
PST - ppublish
SO  - J Allergy Clin Immunol Pract. 2022 May;10(5):1178-1188. doi: 
      10.1016/j.jaip.2022.01.047. Epub 2022 Mar 15.

PMID- 38020160
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241013
IS  - 2296-858X (Print)
IS  - 2296-858X (Electronic)
IS  - 2296-858X (Linking)
VI  - 10
DP  - 2023
TI  - Artificial intelligence in global health equity: an evaluation and discussion on 
      the application of ChatGPT, in the Chinese National Medical Licensing 
      Examination.
PG  - 1237432
LID - 10.3389/fmed.2023.1237432 [doi]
LID - 1237432
AB  - BACKGROUND: The demand for healthcare is increasing globally, with notable 
      disparities in access to resources, especially in Asia, Africa, and Latin 
      America. The rapid development of Artificial Intelligence (AI) technologies, such 
      as OpenAI's ChatGPT, has shown promise in revolutionizing healthcare. However, 
      potential challenges, including the need for specialized medical training, 
      privacy concerns, and language bias, require attention. METHODS: To assess the 
      applicability and limitations of ChatGPT in Chinese and English settings, we 
      designed an experiment evaluating its performance in the 2022 National Medical 
      Licensing Examination (NMLE) in China. For a standardized evaluation, we used the 
      comprehensive written part of the NMLE, translated into English by a bilingual 
      expert. All questions were input into ChatGPT, which provided answers and reasons 
      for choosing them. Responses were evaluated for "information quality" using the 
      Likert scale. RESULTS: ChatGPT demonstrated a correct response rate of 81.25% for 
      Chinese and 86.25% for English questions. Logistic regression analysis showed 
      that neither the difficulty nor the subject matter of the questions was a 
      significant factor in AI errors. The Brier Scores, indicating predictive 
      accuracy, were 0.19 for Chinese and 0.14 for English, indicating good predictive 
      performance. The average quality score for English responses was excellent (4.43 
      point), slightly higher than for Chinese (4.34 point). CONCLUSION: While AI 
      language models like ChatGPT show promise for global healthcare, language bias is 
      a key challenge. Ensuring that such technologies are robustly trained and 
      sensitive to multiple languages and cultures is vital. Further research into AI's 
      role in healthcare, particularly in areas with limited resources, is warranted.
CI  - Copyright © 2023 Tong, Guan, Chen, Huang, Zhong, Zhang and Zhang.
FAU - Tong, Wenting
AU  - Tong W
AD  - Department of Pharmacy, Gannan Healthcare Vocational College, Ganzhou, Jiangxi, 
      China.
FAU - Guan, Yongfu
AU  - Guan Y
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, Jiangxi, China.
FAU - Chen, Jinping
AU  - Chen J
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, Jiangxi, China.
FAU - Huang, Xixuan
AU  - Huang X
AD  - Department of Mathematics, Xiamen University, Xiamen, Fujian, China.
FAU - Zhong, Yuting
AU  - Zhong Y
AD  - Department of Anesthesiology, Gannan Medical University, Jiangxi, China.
FAU - Zhang, Changrong
AU  - Zhang C
AD  - Department of Chinese Medicine, Affiliated Hospital of Qinghai University, 
      Xining, Qinghai, China.
FAU - Zhang, Hui
AU  - Zhang H
AD  - Department of Rehabilitation and Elderly Care, Gannan Healthcare Vocational 
      College, Ganzhou, Jiangxi, China.
AD  - Chair of Endocrinology and Medical Sexology (ENDOSEX), Department of Experimental 
      Medicine, University of Rome Tor Vergata, Rome, Italy.
LA  - eng
PT  - Journal Article
DEP - 20231019
PL  - Switzerland
TA  - Front Med (Lausanne)
JT  - Frontiers in medicine
JID - 101648047
PMC - PMC10656681
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - equity
OT  - global healthcare
OT  - language bias
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/29 18:41
MHDA- 2023/11/29 18:42
PMCR- 2023/10/19
CRDT- 2023/11/29 14:40
PHST- 2023/06/09 00:00 [received]
PHST- 2023/10/09 00:00 [accepted]
PHST- 2023/11/29 18:42 [medline]
PHST- 2023/11/29 18:41 [pubmed]
PHST- 2023/11/29 14:40 [entrez]
PHST- 2023/10/19 00:00 [pmc-release]
AID - 10.3389/fmed.2023.1237432 [doi]
PST - epublish
SO  - Front Med (Lausanne). 2023 Oct 19;10:1237432. doi: 10.3389/fmed.2023.1237432. 
      eCollection 2023.

PMID- 38618358
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240425
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 3
DP  - 2024 Mar
TI  - Generative Artificial Intelligence Performs at a Second-Year Orthopedic Resident 
      Level.
PG  - e56104
LID - 10.7759/cureus.56104 [doi]
LID - e56104
AB  - Introduction Artificial intelligence (AI) models using large language models 
      (LLMs) and non-specific domains have gained attention for their innovative 
      information processing. As AI advances, it's essential to regularly evaluate 
      these tools' competency to maintain high standards, prevent errors or biases, and 
      avoid flawed reasoning or misinformation that could harm patients or spread 
      inaccuracies. Our study aimed to determine the performance of Chat Generative 
      Pre-trained Transformer (ChatGPT) by OpenAI and Google BARD (BARD) in orthopedic 
      surgery, assess performance based on question types, contrast performance between 
      different AIs and compare AI performance to orthopedic residents. Methods We 
      administered ChatGPT and BARD 757 Orthopedic In-Training Examination (OITE) 
      questions. After excluding image-related questions, the AIs answered 390 multiple 
      choice questions, all categorized within 10 sub-specialties (basic science, 
      trauma, sports medicine, spine, hip and knee, pediatrics, oncology, shoulder and 
      elbow, hand, and food and ankle) and three taxonomy classes (recall, 
      interpretation, and application of knowledge). Statistical analysis was performed 
      to analyze the number of questions answered correctly by each AI model, the 
      performance returned by each AI model within the categorized question 
      sub-specialty designation, and the performance of each AI model in comparison to 
      the results returned by orthopedic residents classified by their respective 
      post-graduate year (PGY) level. Results BARD answered more overall questions 
      correctly (58% vs 54%, p<0.001). ChatGPT performed better in sports medicine and 
      basic science and worse in hand surgery, while BARD performed better in basic 
      science (p<0.05). The AIs performed better in recall questions compared to the 
      application of knowledge (p<0.05). Based on previous data, it ranked in the 
      42nd-96th percentile for post-graduate year ones (PGY1s), 27th-58th for PGY2s, 
      3rd-29th for PGY3s, 1st-21st for PGY4s, and 1st-17th for PGY5s. Discussion 
      ChatGPT excelled in sports medicine but fell short in hand surgery, while both 
      AIs performed well in the basic science sub-specialty but performed poorly in the 
      application of knowledge-based taxonomy questions. BARD performed better than 
      ChatGPT overall. Although the AI reached the second-year PGY orthopedic resident 
      level, it fell short of passing the American Board of Orthopedic Surgery (ABOS). 
      Its strengths in recall-based inquiries highlight its potential as an orthopedic 
      learning and educational tool.
CI  - Copyright © 2024, Lum et al.
FAU - Lum, Zachary C
AU  - Lum ZC
AD  - Orthopedic Surgery, University of California (UC) Davis School of Medicine, 
      Sacramento, USA.
AD  - Orthopedic Surgery, Nova Southeastern University, Pembroke Pines, USA.
FAU - Collins, Dylon P
AU  - Collins DP
AD  - College of Medicine, Nova Southeastern University Dr. Kiran C. Patel College of 
      Osteopathic Medicine, Fort Lauderdale, USA.
FAU - Dennison, Stanley
AU  - Dennison S
AD  - College of Medicine, Nova Southeastern University Dr. Kiran C. Patel College of 
      Osteopathic Medicine, Fort Lauderdale, USA.
FAU - Guntupalli, Lohitha
AU  - Guntupalli L
AD  - Osteopathic Medicine, Nova Southeastern University Dr. Kiran C. Patel College of 
      Osteopathic Medicine, Clearwater, USA.
FAU - Choudhary, Soham
AU  - Choudhary S
AD  - Orthopedic Surgery, University of California, Davis, Davis, USA.
FAU - Saiz, Augustine M
AU  - Saiz AM
AD  - Orthopedic Surgery, University of California (UC) Davis Health, Sacramento, USA.
FAU - Randall, Robert L
AU  - Randall RL
AD  - Orthopedic Surgery, University of California (UC) Davis Health, Sacramento, USA.
LA  - eng
PT  - Journal Article
DEP - 20240313
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11014641
OTO - NOTNLM
OT  - chatgpt
OT  - generative artificial intelligence
OT  - google bard
OT  - oite
OT  - orthopaedic surgery
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/04/15 06:44
MHDA- 2024/04/15 06:45
PMCR- 2024/03/13
CRDT- 2024/04/15 04:32
PHST- 2024/02/01 00:00 [received]
PHST- 2024/03/12 00:00 [accepted]
PHST- 2024/04/15 06:45 [medline]
PHST- 2024/04/15 06:44 [pubmed]
PHST- 2024/04/15 04:32 [entrez]
PHST- 2024/03/13 00:00 [pmc-release]
AID - 10.7759/cureus.56104 [doi]
PST - epublish
SO  - Cureus. 2024 Mar 13;16(3):e56104. doi: 10.7759/cureus.56104. eCollection 2024 
      Mar.

PMID- 37350905
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230701
IS  - 2153-4063 (Electronic)
VI  - 2023
DP  - 2023
TI  - Toward Improving Health Literacy in Patient Education Materials with Neural 
      Machine Translation Models.
PG  - 418-426
AB  - Health literacy is the central focus of Healthy People 2030, the fifth iteration 
      of the U.S. national goals and objectives. People with low health literacy 
      usually have trouble understanding health information, following post-visit 
      instructions, and using prescriptions, which results in worse health outcomes and 
      serious health disparities. In this study, we propose to leverage natural 
      language processing techniques to improve health literacy in patient education 
      materials by automatically translating illiterate languages in a given sentence. 
      We scraped patient education materials from four online health information 
      websites: MedlinePlus.gov, Drugs.com, Mayoclinic.org and Reddit.com. We trained 
      and tested the state-of-the-art neural machine translation (NMT) models on a 
      silver standard training dataset and a gold standard testing dataset, 
      respectively. The experimental results showed that the Bidirectional Long 
      Short-Term Memory (BiLSTM) NMT model outperformed Bidirectional Encoder 
      Representations from Transformers (BERT)-based NMT models. We also verified the 
      effectiveness of NMT models in translating health illiterate languages by 
      comparing the ratio of health illiterate language in the sentence. The proposed 
      NMT models were able to identify the correct complicated words and simplify into 
      layman language while at the same time, the models suffer from sentence 
      completeness, fluency, readability, and have difficulty in translating certain 
      medical terms.
CI  - ©2023 AMIA - All rights reserved.
FAU - Oniani, David
AU  - Oniani D
AD  - Department of Health Information Management, University of Pittsburgh, 
      Pittsburgh, PA.
FAU - Sreekumar, Sreekanth
AU  - Sreekumar S
AD  - Department of Health Information Management, University of Pittsburgh, 
      Pittsburgh, PA.
FAU - DeAlmeida, Renuk
AU  - DeAlmeida R
AD  - North Allegheny Intermediate High School, Pittsburgh, PA.
FAU - DeAlmeida, Dinuk
AU  - DeAlmeida D
AD  - North Allegheny Intermediate High School, Pittsburgh, PA.
FAU - Hui, Vivian
AU  - Hui V
AD  - School of Nursing, The Hong Kong Polytechnic University.
FAU - Lee, Young Ji
AU  - Lee YJ
AD  - School of Nursing, University of Pittsburgh, Pittsburgh, PA.
AD  - Department of Biomedical Informatics, University of Pittsburgh, Pittsburgh, PA.
FAU - Zhang, Yiye
AU  - Zhang Y
AD  - Division of Health Informatics, Weill Cornell Medicine, New York, NY.
FAU - Zhou, Leming
AU  - Zhou L
AD  - Department of Health Information Management, University of Pittsburgh, 
      Pittsburgh, PA.
FAU - Wang, Yanshan
AU  - Wang Y
AD  - Department of Health Information Management, University of Pittsburgh, 
      Pittsburgh, PA.
AD  - Department of Biomedical Informatics, University of Pittsburgh, Pittsburgh, PA.
AD  - Intelligent Systems Program, University of Pittsburgh, Pittsburgh, PA.
LA  - eng
PT  - Journal Article
DEP - 20230616
PL  - United States
TA  - AMIA Jt Summits Transl Sci Proc
JT  - AMIA Joint Summits on Translational Science proceedings. AMIA Joint Summits on 
      Translational Science
JID - 101539486
PMC - PMC10283125
EDAT- 2023/06/23 13:07
MHDA- 2023/06/23 13:08
PMCR- 2023/06/16
CRDT- 2023/06/23 10:25
PHST- 2023/06/23 13:08 [medline]
PHST- 2023/06/23 13:07 [pubmed]
PHST- 2023/06/23 10:25 [entrez]
PHST- 2023/06/16 00:00 [pmc-release]
AID - 2114 [pii]
PST - epublish
SO  - AMIA Jt Summits Transl Sci Proc. 2023 Jun 16;2023:418-426. eCollection 2023.

PMID- 37984184
OWN - NLM
STAT- MEDLINE
DCOM- 20231206
LR  - 20240117
IS  - 1873-5347 (Electronic)
IS  - 0277-9536 (Linking)
VI  - 339
DP  - 2023 Dec
TI  - Geospatial vaccine misinformation risk on social media: Online insights from an 
      English/Spanish natural language processing (NLP) analysis of vaccine-related 
      tweets.
PG  - 116365
LID - S0277-9536(23)00722-0 [pii]
LID - 10.1016/j.socscimed.2023.116365 [doi]
AB  - BACKGROUND: Misinformation is known to affect norms, attitudes, and intentions to 
      engage with healthy behaviors. Evidence strongly supports that Spanish speakers 
      may be particularly affected by misinformation and its outcomes, yet current 
      insights into the scope and scale of misinformation is primarily ethnocentric, 
      with greater emphasis on English-language design. OBJECTIVE: This study applies 
      Natural Language Processing (NLP) to analyze a corpus of English/Spanish tweets 
      about vaccines, broadly defined, for misinformation indicators. METHODS: We 
      analyzed N(English) = 247,140 and N(Spanish) = 104,445 tweets using Latent 
      Dirichlet Allocation (LDA) topic models with Coherence score calculation (model 
      fit) with a Mallet adjustment (topic optimization). We used informal coding to 
      name computer-identified topics and compare misinformation scope and scale 
      between languages. RESULTS: The LDA analysis yielded a 12-topic solution for 
      English and a 14-topic solution for Spanish. Both corpora contained overlapping 
      misinformation, including uncertainty of research guiding policy recommendations 
      or standing in support of antivax movements. However, the Spanish data were 
      positioned in a global context, where misinformation was directed at government 
      equity and disparate vaccine distribution. CONCLUSION: Our findings support that 
      misinformation is a global issue. However, misinformation may vary depending on 
      culture and language. As such, tailored strategies to combat misinformation in 
      digital planes are strongly encouraged.
CI  - Published by Elsevier Ltd.
FAU - Valdez, Danny
AU  - Valdez D
AD  - Indiana University School of Public Health, Department of Applied Health Science, 
      1025 E 7th Street, 116 F, Bloomington, IN, 47403, USA. Electronic address: 
      danvald@iu.edu.
FAU - Soto-Vásquez, Arthur D
AU  - Soto-Vásquez AD
AD  - Texas A&M International University, Department of Psychology and Communication, 
      5201 University Blvd, Laredo, TX, 78041, USA. Electronic address: 
      arthur.soto-vasquez@tamiu.edu.
FAU - Montenegro, María S
AU  - Montenegro MS
AD  - Indiana University, Department of Spanish and Portuguese Studies, 355 Eagleson 
      Ave, 2132, Bloomington, IN, 47403, USA. Electronic address: mmonten@iu.edu.
LA  - eng
PT  - Journal Article
DEP - 20231110
PL  - England
TA  - Soc Sci Med
JT  - Social science & medicine (1982)
JID - 8303205
RN  - 0 (Vaccines)
SB  - IM
MH  - Humans
MH  - Government
MH  - Language
MH  - Natural Language Processing
MH  - *Social Media
MH  - *Vaccines
OTO - NOTNLM
OT  - Cross-cultural
OT  - Misinformation
OT  - Natural language processing
OT  - Social media
EDAT- 2023/11/21 01:07
MHDA- 2023/12/04 12:42
CRDT- 2023/11/20 18:10
PHST- 2023/02/09 00:00 [received]
PHST- 2023/10/19 00:00 [revised]
PHST- 2023/10/24 00:00 [accepted]
PHST- 2023/12/04 12:42 [medline]
PHST- 2023/11/21 01:07 [pubmed]
PHST- 2023/11/20 18:10 [entrez]
AID - S0277-9536(23)00722-0 [pii]
AID - 10.1016/j.socscimed.2023.116365 [doi]
PST - ppublish
SO  - Soc Sci Med. 2023 Dec;339:116365. doi: 10.1016/j.socscimed.2023.116365. Epub 2023 
      Nov 10.

PMID- 39819585
OWN - NLM
STAT- MEDLINE
DCOM- 20250117
LR  - 20250129
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 9
DP  - 2025 Jan 16
TI  - Assessing the Current Limitations of Large Language Models in Advancing Health 
      Care Education.
PG  - e51319
LID - 10.2196/51319 [doi]
LID - e51319
AB  - The integration of large language models (LLMs), as seen with the generative 
      pretrained transformers series, into health care education and clinical 
      management represents a transformative potential. The practical use of current 
      LLMs in health care sparks great anticipation for new avenues, yet its 
      embracement also elicits considerable concerns that necessitate careful 
      deliberation. This study aims to evaluate the application of state-of-the-art 
      LLMs in health care education, highlighting the following shortcomings as areas 
      requiring significant and urgent improvements: (1) threats to academic integrity, 
      (2) dissemination of misinformation and risks of automation bias, (3) challenges 
      with information completeness and consistency, (4) inequity of access, (5) risks 
      of algorithmic bias, (6) exhibition of moral instability, (7) technological 
      limitations in plugin tools, and (8) lack of regulatory oversight in addressing 
      legal and ethical challenges. Future research should focus on strategically 
      addressing the persistent challenges of LLMs highlighted in this paper, opening 
      the door for effective measures that can improve their application in health care 
      education.
CI  - © JaeYong Kim, Bathri Narayan Vajravelu. Originally published in JMIR Formative 
      Research (https://formative.jmir.org).
FAU - Kim, JaeYong
AU  - Kim J
AUID- ORCID: 0009-0008-5855-7676
AD  - School of Pharmacy, Massachusetts College of Pharmacy and Health Sciences, 
      Boston, MA, United States.
FAU - Vajravelu, Bathri Narayan
AU  - Vajravelu BN
AUID- ORCID: 0000-0002-1558-2651
AD  - Department of Physician Assistant Studies, Massachusetts College of Pharmacy and 
      Health Sciences, 179 Longwood Avenue, Boston, MA, 02115, United States, 1 
      6177322961.
LA  - eng
PT  - Journal Article
DEP - 20250116
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
SB  - IM
MH  - Humans
MH  - *Language
MH  - Health Education/methods
PMC - PMC11756841
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - artificial intelligence
OT  - generative pretrained transformer
OT  - health care delivery
OT  - health care education
OT  - large language model
COIS- None declared.
EDAT- 2025/01/17 18:23
MHDA- 2025/01/17 18:24
PMCR- 2025/01/16
CRDT- 2025/01/17 12:33
PHST- 2023/07/28 00:00 [received]
PHST- 2024/08/31 00:00 [revised]
PHST- 2024/09/03 00:00 [accepted]
PHST- 2025/01/17 18:24 [medline]
PHST- 2025/01/17 18:23 [pubmed]
PHST- 2025/01/17 12:33 [entrez]
PHST- 2025/01/16 00:00 [pmc-release]
AID - v9i1e51319 [pii]
AID - 51319 [pii]
AID - 10.2196/51319 [doi]
PST - epublish
SO  - JMIR Form Res. 2025 Jan 16;9:e51319. doi: 10.2196/51319.

PMID- 38459205
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240418
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 7
IP  - 1
DP  - 2024 Mar 8
TI  - Bridging the literacy gap for surgical consents: an AI-human expert collaborative 
      approach.
PG  - 63
LID - 10.1038/s41746-024-01039-2 [doi]
LID - 63
AB  - Despite the importance of informed consent in healthcare, the readability and 
      specificity of consent forms often impede patients' comprehension. This study 
      investigates the use of GPT-4 to simplify surgical consent forms and introduces 
      an AI-human expert collaborative approach to validate content appropriateness. 
      Consent forms from multiple institutions were assessed for readability and 
      simplified using GPT-4, with pre- and post-simplification readability metrics 
      compared using nonparametric tests. Independent reviews by medical authors and a 
      malpractice defense attorney were conducted. Finally, GPT-4's potential for 
      generating de novo procedure-specific consent forms was assessed, with forms 
      evaluated using a validated 8-item rubric and expert subspecialty surgeon review. 
      Analysis of 15 academic medical centers' consent forms revealed significant 
      reductions in average reading time, word rarity, and passive sentence frequency 
      (all P < 0.05) following GPT-4-faciliated simplification. Readability improved 
      from an average college freshman to an 8th-grade level (P = 0.004), matching the 
      average American's reading level. Medical and legal sufficiency consistency was 
      confirmed. GPT-4 generated procedure-specific consent forms for five varied 
      surgical procedures at an average 6th-grade reading level. These forms received 
      perfect scores on a standardized consent form rubric and withstood scrutiny upon 
      expert subspeciality surgeon review. This study demonstrates the first AI-human 
      expert collaboration to enhance surgical consent forms, significantly improving 
      readability without sacrificing clinical detail. Our framework could be extended 
      to other patient communication materials, emphasizing clear communication and 
      mitigating disparities related to health literacy barriers.
CI  - © 2024. The Author(s).
FAU - Ali, Rohaid
AU  - Ali R
AUID- ORCID: 0000-0002-6509-0129
AD  - Department of Neurosurgery, Rhode Island Hospital and The Warren Alpert Medical 
      School of Brown University, Providence, RI, USA. ali.rohaid@gmail.com.
AD  - Norman Prince Neurosciences Institute, Providence, RI, USA. ali.rohaid@gmail.com.
FAU - Connolly, Ian D
AU  - Connolly ID
AD  - Department of Neurosurgery, Massachusetts General Hospital, Boston, MA, USA.
FAU - Tang, Oliver Y
AU  - Tang OY
AUID- ORCID: 0000-0002-8604-2708
AD  - Department of Neurosurgery, Rhode Island Hospital and The Warren Alpert Medical 
      School of Brown University, Providence, RI, USA.
FAU - Mirza, Fatima N
AU  - Mirza FN
AUID- ORCID: 0000-0003-1299-6258
AD  - Department of Dermatology, The Warren Alpert Medical School of Brown University, 
      Providence, RI, USA.
FAU - Johnston, Benjamin
AU  - Johnston B
AUID- ORCID: 0000-0002-6456-3908
AD  - Department of Neurosurgery, Brigham and Women's Hospital, Boston, MA, USA.
FAU - Abdulrazeq, Hael F
AU  - Abdulrazeq HF
AD  - Department of Neurosurgery, Rhode Island Hospital and The Warren Alpert Medical 
      School of Brown University, Providence, RI, USA.
AD  - Norman Prince Neurosciences Institute, Providence, RI, USA.
FAU - Lim, Rachel K
AU  - Lim RK
AD  - Department of Surgery & Division of Cardiothoracic Surgery, Rhode Island Hospital 
      and The Warren Alpert Medical School of Brown University, Providence, RI, USA.
FAU - Galamaga, Paul F
AU  - Galamaga PF
AD  - Ratcliffe Harten Galamaga LLP, Providence, RI, USA.
FAU - Libby, Tiffany J
AU  - Libby TJ
AD  - Department of Dermatology, The Warren Alpert Medical School of Brown University, 
      Providence, RI, USA.
FAU - Sodha, Neel R
AU  - Sodha NR
AD  - Department of Surgery & Division of Cardiothoracic Surgery, Rhode Island Hospital 
      and The Warren Alpert Medical School of Brown University, Providence, RI, USA.
FAU - Groff, Michael W
AU  - Groff MW
AD  - Department of Neurosurgery, Brigham and Women's Hospital, Boston, MA, USA.
FAU - Gokaslan, Ziya L
AU  - Gokaslan ZL
AD  - Department of Neurosurgery, Rhode Island Hospital and The Warren Alpert Medical 
      School of Brown University, Providence, RI, USA.
AD  - Norman Prince Neurosciences Institute, Providence, RI, USA.
FAU - Telfeian, Albert E
AU  - Telfeian AE
AD  - Department of Neurosurgery, Rhode Island Hospital and The Warren Alpert Medical 
      School of Brown University, Providence, RI, USA.
AD  - Norman Prince Neurosciences Institute, Providence, RI, USA.
FAU - Shin, John H
AU  - Shin JH
AD  - Department of Neurosurgery, Massachusetts General Hospital, Boston, MA, USA.
FAU - Asaad, Wael F
AU  - Asaad WF
AUID- ORCID: 0000-0003-4406-9096
AD  - Department of Neurosurgery, Rhode Island Hospital and The Warren Alpert Medical 
      School of Brown University, Providence, RI, USA.
FAU - Zou, James
AU  - Zou J
AD  - Departments of Electrical Engineering, Biomedical Data Science, and Computer 
      Science, Stanford University, Stanford, CA, USA.
AD  - Chan Zuckerberg Biohub, San Francisco, CA, USA.
FAU - Doberstein, Curtis E
AU  - Doberstein CE
AD  - Department of Neurosurgery, Rhode Island Hospital and The Warren Alpert Medical 
      School of Brown University, Providence, RI, USA.
AD  - Norman Prince Neurosciences Institute, Providence, RI, USA.
LA  - eng
PT  - Journal Article
DEP - 20240308
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
EIN - NPJ Digit Med. 2024 Apr 12;7(1):93. doi: 10.1038/s41746-024-01099-4. PMID: 
      38609435
PMC - PMC10923794
COIS- The authors declare no competing interests.
EDAT- 2024/03/09 10:42
MHDA- 2024/03/09 10:43
PMCR- 2024/03/08
CRDT- 2024/03/08 23:34
PHST- 2023/06/30 00:00 [received]
PHST- 2024/02/14 00:00 [accepted]
PHST- 2024/03/09 10:43 [medline]
PHST- 2024/03/09 10:42 [pubmed]
PHST- 2024/03/08 23:34 [entrez]
PHST- 2024/03/08 00:00 [pmc-release]
AID - 10.1038/s41746-024-01039-2 [pii]
AID - 1039 [pii]
AID - 10.1038/s41746-024-01039-2 [doi]
PST - epublish
SO  - NPJ Digit Med. 2024 Mar 8;7(1):63. doi: 10.1038/s41746-024-01039-2.

PMID- 35142635
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20220311
IS  - 2291-9694 (Print)
IS  - 2291-9694 (Electronic)
IS  - 2291-9694 (Linking)
VI  - 10
IP  - 2
DP  - 2022 Feb 10
TI  - Operationalizing and Implementing Pretrained, Large Artificial Intelligence 
      Linguistic Models in the US Health Care System: Outlook of Generative Pretrained 
      Transformer 3 (GPT-3) as a Service Model.
PG  - e32875
LID - 10.2196/32875 [doi]
LID - e32875
AB  - Generative pretrained transformer models have been popular recently due to their 
      enhanced capabilities and performance. In contrast to many existing artificial 
      intelligence models, generative pretrained transformer models can perform with 
      very limited training data. Generative pretrained transformer 3 (GPT-3) is one of 
      the latest releases in this pipeline, demonstrating human-like logical and 
      intellectual responses to prompts. Some examples include writing essays, 
      answering complex questions, matching pronouns to their nouns, and conducting 
      sentiment analyses. However, questions remain with regard to its implementation 
      in health care, specifically in terms of operationalization and its use in 
      clinical practice and research. In this viewpoint paper, we briefly introduce 
      GPT-3 and its capabilities and outline considerations for its implementation and 
      operationalization in clinical practice through a use case. The implementation 
      considerations include (1) processing needs and information systems 
      infrastructure, (2) operating costs, (3) model biases, and (4) evaluation 
      metrics. In addition, we outline the following three major operational factors 
      that drive the adoption of GPT-3 in the US health care system: (1) ensuring 
      Health Insurance Portability and Accountability Act compliance, (2) building 
      trust with health care providers, and (3) establishing broader access to the 
      GPT-3 tools. This viewpoint can inform health care practitioners, developers, 
      clinicians, and decision makers toward understanding the use of the powerful 
      artificial intelligence tools integrated into hospital systems and health care.
CI  - ©Emre Sezgin, Joseph Sirrianni, Simon L Linwood. Originally published in JMIR 
      Medical Informatics (https://medinform.jmir.org), 10.02.2022.
FAU - Sezgin, Emre
AU  - Sezgin E
AUID- ORCID: 0000-0001-8798-9605
AD  - The Abigail Wexner Research Institute, Nationwide Children's Hospital, Columbus, 
      OH, United States.
FAU - Sirrianni, Joseph
AU  - Sirrianni J
AUID- ORCID: 0000-0002-2952-5818
AD  - The Abigail Wexner Research Institute, Nationwide Children's Hospital, Columbus, 
      OH, United States.
FAU - Linwood, Simon L
AU  - Linwood SL
AUID- ORCID: 0000-0003-2876-2042
AD  - School of Medicine, University of California Riverside, Riverside, CA, United 
      States.
LA  - eng
PT  - Journal Article
DEP - 20220210
PL  - Canada
TA  - JMIR Med Inform
JT  - JMIR medical informatics
JID - 101645109
PMC - PMC8874824
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatbot
OT  - clinical informatics
OT  - generative pretrained transformer
OT  - natural language processing
COIS- Conflicts of Interest: None declared.
EDAT- 2022/02/11 06:00
MHDA- 2022/02/11 06:01
PMCR- 2022/02/10
CRDT- 2022/02/10 12:13
PHST- 2021/08/12 00:00 [received]
PHST- 2022/01/09 00:00 [accepted]
PHST- 2021/12/14 00:00 [revised]
PHST- 2022/02/10 12:13 [entrez]
PHST- 2022/02/11 06:00 [pubmed]
PHST- 2022/02/11 06:01 [medline]
PHST- 2022/02/10 00:00 [pmc-release]
AID - v10i2e32875 [pii]
AID - 10.2196/32875 [doi]
PST - epublish
SO  - JMIR Med Inform. 2022 Feb 10;10(2):e32875. doi: 10.2196/32875.

PMID- 39993309
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250313
IS  - 2817-1705 (Electronic)
IS  - 2817-1705 (Linking)
VI  - 4
DP  - 2025 Feb 24
TI  - Leveraging Medical Knowledge Graphs Into Large Language Models for Diagnosis 
      Prediction: Design and Application Study.
PG  - e58670
LID - 10.2196/58670 [doi]
LID - e58670
AB  - BACKGROUND: Electronic health records (EHRs) and routine documentation practices 
      play a vital role in patients' daily care, providing a holistic record of health, 
      diagnoses, and treatment. However, complex and verbose EHR narratives can 
      overwhelm health care providers, increasing the risk of diagnostic inaccuracies. 
      While large language models (LLMs) have showcased their potential in diverse 
      language tasks, their application in health care must prioritize the minimization 
      of diagnostic errors and the prevention of patient harm. Integrating knowledge 
      graphs (KGs) into LLMs offers a promising approach because structured knowledge 
      from KGs could enhance LLMs' diagnostic reasoning by providing contextually 
      relevant medical information. OBJECTIVE: This study introduces DR.KNOWS 
      (Diagnostic Reasoning Knowledge Graph System), a model that integrates Unified 
      Medical Language System-based KGs with LLMs to improve diagnostic predictions 
      from EHR data by retrieving contextually relevant paths aligned with 
      patient-specific information. METHODS: DR.KNOWS combines a stack graph 
      isomorphism network for node embedding with an attention-based path ranker to 
      identify and rank knowledge paths relevant to a patient's clinical context. We 
      evaluated DR.KNOWS on 2 real-world EHR datasets from different geographic 
      locations, comparing its performance to baseline models, including QuickUMLS and 
      standard LLMs (Text-to-Text Transfer Transformer and ChatGPT). To assess 
      diagnostic reasoning quality, we designed and implemented a human evaluation 
      framework grounded in clinical safety metrics. RESULTS: DR.KNOWS demonstrated 
      notable improvements over baseline models, showing higher accuracy in extracting 
      diagnostic concepts and enhanced diagnostic prediction metrics. Prompt-based 
      fine-tuning of Text-to-Text Transfer Transformer with DR.KNOWS knowledge paths 
      achieved the highest ROUGE-L (Recall-Oriented Understudy for Gisting 
      Evaluation-Longest Common Subsequence) and concept unique identifier F(1)-scores, 
      highlighting the benefits of KG integration. Human evaluators found the 
      diagnostic rationales of DR.KNOWS to be aligned strongly with correct clinical 
      reasoning, indicating improved abstraction and reasoning. Recognized limitations 
      include potential biases within the KG data, which we addressed by emphasizing 
      case-specific path selection and proposing future bias-mitigation strategies. 
      CONCLUSIONS: DR.KNOWS offers a robust approach for enhancing diagnostic accuracy 
      and reasoning by integrating structured KG knowledge into LLM-based clinical 
      workflows. Although further work is required to address KG biases and extend 
      generalizability, DR.KNOWS represents progress toward trustworthy artificial 
      intelligence-driven clinical decision support, with a human evaluation framework 
      focused on diagnostic safety and alignment with clinical standards.
CI  - ©Yanjun Gao, Ruizhe Li, Emma Croxford, John Caskey, Brian W Patterson, Matthew 
      Churpek, Timothy Miller, Dmitriy Dligach, Majid Afshar. Originally published in 
      JMIR AI (https://ai.jmir.org), 24.02.2025.
FAU - Gao, Yanjun
AU  - Gao Y
AUID- ORCID: 0000-0002-9341-7360
AD  - Department of Biomedical Informatics, University of Colorado Anschutz Medical 
      Campus, Denver, CO, United States.
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI, United 
      States.
FAU - Li, Ruizhe
AU  - Li R
AUID- ORCID: 0000-0003-2512-845X
AD  - University of Aberdeen, Aberdeen, United Kingdom.
FAU - Croxford, Emma
AU  - Croxford E
AUID- ORCID: 0009-0001-9117-7009
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI, United 
      States.
FAU - Caskey, John
AU  - Caskey J
AUID- ORCID: 0000-0001-5665-524X
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI, United 
      States.
FAU - Patterson, Brian W
AU  - Patterson BW
AUID- ORCID: 0000-0002-4584-3808
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI, United 
      States.
FAU - Churpek, Matthew
AU  - Churpek M
AUID- ORCID: 0000-0002-4030-5250
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI, United 
      States.
FAU - Miller, Timothy
AU  - Miller T
AUID- ORCID: 0000-0003-4513-403X
AD  - Boston Children's Hospital, Harvard Medical School, Boston, MA, United States.
FAU - Dligach, Dmitriy
AU  - Dligach D
AUID- ORCID: 0000-0002-2585-2707
AD  - Loyola University Chicago, Chicago, IL, United States.
FAU - Afshar, Majid
AU  - Afshar M
AUID- ORCID: 0000-0002-6368-4652
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI, United 
      States.
LA  - eng
PT  - Journal Article
DEP - 20250224
PL  - Canada
TA  - JMIR AI
JT  - JMIR AI
JID - 9918645789006676
PMC - PMC11894347
OTO - NOTNLM
OT  - artificial intelligence
OT  - diagnosis prediction
OT  - electronic health record
OT  - graph model
OT  - knowledge graph
OT  - large language model
OT  - machine learning
OT  - natural language processing
COIS- Conflicts of Interest: TM is a consultant for Lavita.ai, a startup that builds 
      NLP tools for medical use cases. All other authors declare no conflicts of 
      interest.
EDAT- 2025/02/24 23:04
MHDA- 2025/02/24 23:05
PMCR- 2025/02/24
CRDT- 2025/02/24 16:54
PHST- 2024/03/21 00:00 [received]
PHST- 2024/11/07 00:00 [accepted]
PHST- 2024/08/07 00:00 [revised]
PHST- 2025/02/24 23:05 [medline]
PHST- 2025/02/24 23:04 [pubmed]
PHST- 2025/02/24 16:54 [entrez]
PHST- 2025/02/24 00:00 [pmc-release]
AID - v4i1e58670 [pii]
AID - 10.2196/58670 [doi]
PST - epublish
SO  - JMIR AI. 2025 Feb 24;4:e58670. doi: 10.2196/58670.

PMID- 38821760
OWN - NLM
STAT- MEDLINE
DCOM- 20240912
LR  - 20240912
IS  - 1444-2892 (Electronic)
IS  - 1443-9506 (Linking)
VI  - 33
IP  - 9
DP  - 2024 Sep
TI  - Appropriateness of ChatGPT in Answering Heart Failure Related Questions.
PG  - 1314-1318
LID - S1443-9506(24)00165-3 [pii]
LID - 10.1016/j.hlc.2024.03.005 [doi]
AB  - BACKGROUND: Heart failure requires complex management, and increased patient 
      knowledge has been shown to improve outcomes. This study assessed the knowledge 
      of Chat Generative Pre-trained Transformer (ChatGPT) and its appropriateness as a 
      supplemental resource of information for patients with heart failure. METHOD: A 
      total of 107 frequently asked heart failure-related questions were included in 3 
      categories: "basic knowledge" (49), "management" (41) and "other" (17). Two 
      responses per question were generated using both GPT-3.5 and GPT-4 (i.e., two 
      responses per question per model). The accuracy and reproducibility of responses 
      were graded by two reviewers, board-certified in cardiology, with differences 
      resolved by a third reviewer, board-certified in cardiology and advanced heart 
      failure. Accuracy was graded using a four-point scale: (1) comprehensive, (2) 
      correct but inadequate, (3) some correct and some incorrect, and (4) completely 
      incorrect. RESULTS: GPT-4 provided 107/107 (100%) responses with correct 
      information. Further, GPT-4 displayed a greater proportion of comprehensive 
      knowledge for the categories of "basic knowledge" and "management" (89.8% and 
      82.9%, respectively). For GPT-3, there were two total responses (1.9%) graded as 
      "some correct and incorrect" for GPT-3.5, while no "completely incorrect" 
      responses were produced. With respect to comprehensive knowledge, GPT-3.5 
      performed best in the "management" category and "other" category (prognosis, 
      procedures, and support) (78.1%, 94.1%). The models also provided highly 
      reproducible responses, with GPT-3.5 scoring above 94% in every category and 
      GPT-4 with 100% for all answers. CONCLUSIONS: GPT-3.5 and GPT-4 answered the 
      majority of heart failure-related questions accurately and reliably. If validated 
      in future studies, ChatGPT may serve as a useful tool in the future by providing 
      accessible health-related information and education to patients living with heart 
      failure. In its current state, ChatGPT necessitates further rigorous testing and 
      validation to ensure patient safety and equity across all patient demographics.
CI  - Copyright © 2024 The Author(s). Published by Elsevier B.V. All rights reserved.
FAU - King, Ryan C
AU  - King RC
AD  - Division of Cardiology, Department of Medicine, Irvine Medical Center, University 
      of California, Orange, CA, USA. Electronic address: kingrc@hs.uci.edu.
FAU - Samaan, Jamil S
AU  - Samaan JS
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Yeo, Yee Hui
AU  - Yeo YH
AD  - Karsh Division of Gastroenterology and Hepatology, Department of Medicine, 
      Cedars-Sinai Medical Center, Los Angeles, CA, USA.
FAU - Mody, Behram
AU  - Mody B
AD  - Division of Cardiology, Department of Medicine, Irvine Medical Center, University 
      of California, Orange, CA, USA.
FAU - Lombardo, Dawn M
AU  - Lombardo DM
AD  - Division of Cardiology, Department of Medicine, Irvine Medical Center, University 
      of California, Orange, CA, USA.
FAU - Ghashghaei, Roxana
AU  - Ghashghaei R
AD  - Division of Cardiology, Department of Medicine, Irvine Medical Center, University 
      of California, Orange, CA, USA.
LA  - eng
PT  - Journal Article
DEP - 20240531
PL  - Australia
TA  - Heart Lung Circ
JT  - Heart, lung & circulation
JID - 100963739
SB  - IM
MH  - *Heart Failure/therapy/diagnosis
MH  - Humans
MH  - Female
MH  - Male
MH  - Surveys and Questionnaires
MH  - Patient Education as Topic/methods
MH  - Reproducibility of Results
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Equity
OT  - Health education
OT  - Heart failure
COIS- Disclosures R.G. is a consultant for Pfizer, Alnylam, and AstraZeneca. None of 
      the other authors have interests to disclose.
EDAT- 2024/06/01 10:50
MHDA- 2024/09/13 00:46
CRDT- 2024/05/31 21:54
PHST- 2023/08/29 00:00 [received]
PHST- 2024/02/26 00:00 [revised]
PHST- 2024/03/02 00:00 [accepted]
PHST- 2024/09/13 00:46 [medline]
PHST- 2024/06/01 10:50 [pubmed]
PHST- 2024/05/31 21:54 [entrez]
AID - S1443-9506(24)00165-3 [pii]
AID - 10.1016/j.hlc.2024.03.005 [doi]
PST - ppublish
SO  - Heart Lung Circ. 2024 Sep;33(9):1314-1318. doi: 10.1016/j.hlc.2024.03.005. Epub 
      2024 May 31.

PMID- 33358394
OWN - NLM
STAT- MEDLINE
DCOM- 20210809
LR  - 20210809
IS  - 1527-2966 (Electronic)
IS  - 0099-1767 (Linking)
VI  - 47
IP  - 2
DP  - 2021 Mar
TI  - Improving ED Emergency Severity Index Acuity Assignment Using Machine Learning 
      and Clinical Natural Language Processing.
PG  - 265-278.e7
LID - S0099-1767(20)30376-7 [pii]
LID - 10.1016/j.jen.2020.11.001 [doi]
AB  - INTRODUCTION: Triage is critical to mitigating the effect of increased volume by 
      determining patient acuity, need for resources, and establishing acuity-based 
      patient prioritization. The purpose of this retrospective study was to determine 
      whether historical EHR data can be used with clinical natural language processing 
      and machine learning algorithms (KATE) to produce accurate ESI predictive models. 
      METHODS: The KATE triage model was developed using 166,175 patient encounters 
      from two participating hospitals. The model was tested against a random sample of 
      encounters that were correctly assigned an acuity by study clinicians using the 
      Emergency Severity Index (ESI) standard as a guide. RESULTS: At the study sites, 
      KATE predicted accurate ESI acuity assignments 75.7% of the time compared with 
      nurses (59.8%) and the average of individual study clinicians (75.3%). KATE's 
      accuracy was 26.9% higher than the average nurse accuracy (P <.001). On the 
      boundary between ESI 2 and ESI 3 acuity assignments, which relates to the risk of 
      decompensation, KATE's accuracy was 93.2% higher, with 80% accuracy compared with 
      triage nurses 41.4% accuracy (P <.001). DISCUSSION: KATE provides a triage acuity 
      assignment more accurate than the triage nurses in this study sample. KATE 
      operates independently of contextual factors, unaffected by the external 
      pressures that can cause under triage and may mitigate biases that can negatively 
      affect triage accuracy. Future research should focus on the impact of KATE 
      providing feedback to triage nurses in real time, on mortality and morbidity, ED 
      throughput, resource optimization, and nursing outcomes.
CI  - Copyright © 2020 Emergency Nurses Association. Published by Elsevier Inc. All 
      rights reserved.
FAU - Ivanov, Oleksandr
AU  - Ivanov O
FAU - Wolf, Lisa
AU  - Wolf L
FAU - Brecher, Deena
AU  - Brecher D
FAU - Lewis, Erica
AU  - Lewis E
FAU - Masek, Kevin
AU  - Masek K
FAU - Montgomery, Kyla
AU  - Montgomery K
FAU - Andrieiev, Yurii
AU  - Andrieiev Y
FAU - McLaughlin, Moss
AU  - McLaughlin M
FAU - Liu, Stephen
AU  - Liu S
FAU - Dunne, Robert
AU  - Dunne R
FAU - Klauer, Kevin
AU  - Klauer K
FAU - Reilly, Christian
AU  - Reilly C
LA  - eng
PT  - Journal Article
PT  - Multicenter Study
DEP - 20201224
PL  - United States
TA  - J Emerg Nurs
JT  - Journal of emergency nursing
JID - 7605913
MH  - Adolescent
MH  - Adult
MH  - Aged
MH  - Child
MH  - Electronic Health Records
MH  - *Emergency Service, Hospital
MH  - Female
MH  - Humans
MH  - *Machine Learning
MH  - Male
MH  - Middle Aged
MH  - *Natural Language Processing
MH  - *Patient Acuity
MH  - Predictive Value of Tests
MH  - *Quality Improvement
MH  - Retrospective Studies
MH  - *Triage
MH  - United States
OTO - NOTNLM
OT  - Acuity
OT  - Emergency Severity Index
OT  - Machine learning
OT  - Triage
EDAT- 2020/12/29 06:00
MHDA- 2021/08/10 06:00
CRDT- 2020/12/28 10:34
PHST- 2020/07/21 00:00 [received]
PHST- 2020/11/02 00:00 [revised]
PHST- 2020/11/03 00:00 [accepted]
PHST- 2020/12/29 06:00 [pubmed]
PHST- 2021/08/10 06:00 [medline]
PHST- 2020/12/28 10:34 [entrez]
AID - S0099-1767(20)30376-7 [pii]
AID - 10.1016/j.jen.2020.11.001 [doi]
PST - ppublish
SO  - J Emerg Nurs. 2021 Mar;47(2):265-278.e7. doi: 10.1016/j.jen.2020.11.001. Epub 
      2020 Dec 24.

PMID- 39712469
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 7
DP  - 2024
TI  - AI-assisted human clinical reasoning in the ICU: beyond "to err is human".
PG  - 1506676
LID - 10.3389/frai.2024.1506676 [doi]
LID - 1506676
AB  - Diagnostic errors pose a significant public health challenge, affecting nearly 
      800,000 Americans annually, with even higher rates globally. In the ICU, these 
      errors are particularly prevalent, leading to substantial morbidity and 
      mortality. The clinical reasoning process aims to reduce diagnostic uncertainty 
      and establish a plausible differential diagnosis but is often hindered by 
      cognitive load, patient complexity, and clinician burnout. These factors 
      contribute to cognitive biases that compromise diagnostic accuracy. Emerging 
      technologies like large language models (LLMs) offer potential solutions to 
      enhance clinical reasoning and improve diagnostic precision. In this perspective 
      article, we explore the roles of LLMs, such as GPT-4, in addressing diagnostic 
      challenges in critical care settings through a case study of a critically ill 
      patient managed with LLM assistance.
CI  - Copyright © 2024 El Gharib, Jundi, Furfaro and Abdulnour.
FAU - El Gharib, Khalil
AU  - El Gharib K
AD  - Division of Pulmonary and Critical Care Medicine, Rutgers Robert Wood Johnson 
      Medical School, New Brunswick, NJ, United States.
FAU - Jundi, Bakr
AU  - Jundi B
AD  - Division of Pulmonary and Critical Care Medicine, Brigham and Women's Hospital 
      and Harvard Medical School, Boston, MA, United States.
FAU - Furfaro, David
AU  - Furfaro D
AD  - Division of Pulmonary and Critical Care Medicine, Beth Israel Deaconess Medical 
      Center and Harvard Medical School, Boston, MA, United States.
FAU - Abdulnour, Raja-Elie E
AU  - Abdulnour RE
AD  - Division of Pulmonary and Critical Care Medicine, Brigham and Women's Hospital 
      and Harvard Medical School, Boston, MA, United States.
LA  - eng
PT  - Journal Article
DEP - 20241204
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC11659639
OTO - NOTNLM
OT  - artificial intelligence
OT  - clinical reasoning
OT  - critical care
OT  - diagnostic errors
OT  - large language models
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/12/23 17:24
MHDA- 2024/12/23 17:25
PMCR- 2024/12/04
CRDT- 2024/12/23 06:06
PHST- 2024/10/05 00:00 [received]
PHST- 2024/11/19 00:00 [accepted]
PHST- 2024/12/23 17:25 [medline]
PHST- 2024/12/23 17:24 [pubmed]
PHST- 2024/12/23 06:06 [entrez]
PHST- 2024/12/04 00:00 [pmc-release]
AID - 10.3389/frai.2024.1506676 [doi]
PST - epublish
SO  - Front Artif Intell. 2024 Dec 4;7:1506676. doi: 10.3389/frai.2024.1506676. 
      eCollection 2024.

PMID- 33351675
OWN - NLM
STAT- MEDLINE
DCOM- 20210624
LR  - 20250103
IS  - 2688-1535 (Electronic)
IS  - 2688-1527 (Print)
IS  - 2688-1527 (Linking)
VI  - 17
IP  - 1
DP  - 2021 Jan
TI  - Exploring the Process of Cancer Care for Patients With Pre-Existing Mobility 
      Disability.
PG  - e53-e61
LID - 10.1200/OP.20.00378 [doi]
AB  - PURPOSE: Approximately 13% of the US population report mobility disability. 
      People with mobility disability experience healthcare disparities, including 
      lower rates of cancer screening and substandard cancer care compared with 
      nondisabled people. We explored clinicians' reports of aspects of diagnosing and 
      treating three common cancer types among persons with pre-existing mobility 
      disability. METHODS: We used standard diagnosis codes and natural language 
      processing to screen electronic health records (EHR) in the Research Patient Data 
      Repository for patients with pre-existing chronic mobility impairment who were 
      newly diagnosed with one of three common cancers (colorectal, prostate, and 
      non-Hodgkin lymphoma) between 2005 and 2017. We eliminated numerous cases whose 
      EHRs lacked essential information. We reviewed EHRs of 27 cases, using 
      conventional content analysis to identify themes concerning their cancer 
      diagnoses and treatments. RESULTS: Clinicians' notations coalesced around four 
      major themes: (1) patients' health risks raise concerns about diagnostic 
      processes; (2) cancer signs or symptoms can be erroneously attributed to the 
      patient's underlying disabling condition, delaying diagnosis; (3) disability 
      complicates cancer treatment decisions; and (4) problems with equipment 
      accessibility and disability accommodations impede cancer diagnoses. DISCUSSION: 
      Clinicians view patients with pre-existing mobility disability as often 
      clinically complex, presenting challenges for diagnosing and treating their 
      cancer. Nonetheless, these patients may experience substandard care because of 
      disability-related problems. Given the growing population of people with mobility 
      disability, further efforts to improve care quality and timeliness of diagnosis 
      are warranted.
FAU - Agaronnik, Nicole D
AU  - Agaronnik ND
AD  - Health Policy Research Center-Mongan Institute, Massachusetts General Hospital, 
      Boston, MA.
FAU - El-Jawahri, Areej
AU  - El-Jawahri A
AD  - Department of Medicine, Harvard Medical School, Boston, MA.
AD  - Division of Hematology and Oncology, Massachusetts General Hospital, Boston, MA.
FAU - Lindvall, Charlotta
AU  - Lindvall C
AD  - Department of Psychosocial Oncology and Palliative Care, Dana-Farber Cancer 
      Institute, Boston, MA.
AD  - Division of Palliative Medicine, Brigham and Women's Hospital, Boston, MA.
FAU - Iezzoni, Lisa I
AU  - Iezzoni LI
AD  - Health Policy Research Center-Mongan Institute, Massachusetts General Hospital, 
      Boston, MA.
AD  - Department of Medicine, Harvard Medical School, Boston, MA.
LA  - eng
GR  - R21 HD095240/HD/NICHD NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20201222
PL  - United States
TA  - JCO Oncol Pract
JT  - JCO oncology practice
JID - 101758685
SB  - IM
MH  - *Persons with Disabilities
MH  - Early Detection of Cancer
MH  - Electronic Health Records
MH  - Healthcare Disparities
MH  - Humans
MH  - Male
MH  - Natural Language Processing
MH  - *Neoplasms/diagnosis/epidemiology/therapy
PMC - PMC8257981
EDAT- 2020/12/23 06:00
MHDA- 2021/06/25 06:00
PMCR- 2022/01/01
CRDT- 2020/12/22 17:11
PHST- 2020/12/23 06:00 [pubmed]
PHST- 2021/06/25 06:00 [medline]
PHST- 2020/12/22 17:11 [entrez]
PHST- 2022/01/01 00:00 [pmc-release]
AID - OP.20.00378 [pii]
AID - 10.1200/OP.20.00378 [doi]
PST - ppublish
SO  - JCO Oncol Pract. 2021 Jan;17(1):e53-e61. doi: 10.1200/OP.20.00378. Epub 2020 Dec 
      22.

PMID- 38609476
OWN - NLM
STAT- MEDLINE
DCOM- 20240415
LR  - 20240618
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Apr 12
TI  - AI-driven translations for kidney transplant equity in Hispanic populations.
PG  - 8511
LID - 10.1038/s41598-024-59237-7 [doi]
LID - 8511
AB  - Health equity and accessing Spanish kidney transplant information continues being 
      a substantial challenge facing the Hispanic community. This study evaluated 
      ChatGPT's capabilities in translating 54 English kidney transplant frequently 
      asked questions (FAQs) into Spanish using two versions of the AI model, GPT-3.5 
      and GPT-4.0. The FAQs included 19 from Organ Procurement and Transplantation 
      Network (OPTN), 15 from National Health Service (NHS), and 20 from National 
      Kidney Foundation (NKF). Two native Spanish-speaking nephrologists, both of whom 
      are of Mexican heritage, scored the translations for linguistic accuracy and 
      cultural sensitivity tailored to Hispanics using a 1-5 rubric. The inter-rater 
      reliability of the evaluators, measured by Cohen's Kappa, was 0.85. Overall 
      linguistic accuracy was 4.89 ± 0.31 for GPT-3.5 versus 4.94 ± 0.23 for GPT-4.0 
      (non-significant p = 0.23). Both versions scored 4.96 ± 0.19 in cultural 
      sensitivity (p = 1.00). By source, GPT-3.5 linguistic accuracy was 4.84 ± 0.37 
      (OPTN), 4.93 ± 0.26 (NHS), 4.90 ± 0.31 (NKF). GPT-4.0 scored 4.95 ± 0.23 (OPTN), 
      4.93 ± 0.26 (NHS), 4.95 ± 0.22 (NKF). For cultural sensitivity, GPT-3.5 scored 
      4.95 ± 0.23 (OPTN), 4.93 ± 0.26 (NHS), 5.00 ± 0.00 (NKF), while GPT-4.0 scored 
      5.00 ± 0.00 (OPTN), 5.00 ± 0.00 (NHS), 4.90 ± 0.31 (NKF). These high linguistic 
      and cultural sensitivity scores demonstrate Chat GPT effectively translated the 
      English FAQs into Spanish across systems. The findings suggest Chat GPT's 
      potential to promote health equity by improving Spanish access to essential 
      kidney transplant information. Additional research should evaluate its medical 
      translation capabilities across diverse contexts/languages. These 
      English-to-Spanish translations may increase access to vital transplant 
      information for underserved Spanish-speaking Hispanic patients.
CI  - © 2024. The Author(s).
FAU - Garcia Valencia, Oscar A
AU  - Garcia Valencia OA
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Jadlowiec, Caroline C
AU  - Jadlowiec CC
AD  - Division of Transplant Surgery, Mayo Clinic, Phoenix, AZ, USA.
FAU - Mao, Shennen A
AU  - Mao SA
AD  - Division of Transplant Surgery, Department of Transplantation, Mayo Clinic, 
      Jacksonville, FL, USA.
FAU - Leeaphorn, Napat
AU  - Leeaphorn N
AD  - Division of Transplant Surgery, Department of Transplantation, Mayo Clinic, 
      Jacksonville, FL, USA.
AD  - Department of Transplant, Mayo Clinic, Jacksonville, USA.
FAU - Budhiraja, Pooja
AU  - Budhiraja P
AD  - Division of Transplant Surgery, Mayo Clinic, Phoenix, AZ, USA.
FAU - Craici, Iasmina M
AU  - Craici IM
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Gonzalez Suarez, Maria L
AU  - Gonzalez Suarez ML
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA. wcheungpasitporn@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240412
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
RN  - EC 2.6.1.2 (Alanine Transaminase)
RN  - EC 2.3.1.6 (Choline O-Acetyltransferase)
SB  - IM
MH  - Humans
MH  - Alanine Transaminase
MH  - Artificial Intelligence
MH  - Choline O-Acetyltransferase
MH  - Health Promotion
MH  - Hispanic or Latino
MH  - *Kidney Transplantation
MH  - Reproducibility of Results
MH  - State Medicine
MH  - Mexican Americans
PMC - PMC11014982
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Cultural sensitivity
OT  - Health equity
OT  - Kidney transplant information
OT  - Large language models
OT  - Spanish translation
COIS- The authors declare no competing interests.
EDAT- 2024/04/13 10:42
MHDA- 2024/04/15 06:44
PMCR- 2024/04/12
CRDT- 2024/04/12 23:21
PHST- 2024/01/24 00:00 [received]
PHST- 2024/04/08 00:00 [accepted]
PHST- 2024/04/15 06:44 [medline]
PHST- 2024/04/13 10:42 [pubmed]
PHST- 2024/04/12 23:21 [entrez]
PHST- 2024/04/12 00:00 [pmc-release]
AID - 10.1038/s41598-024-59237-7 [pii]
AID - 59237 [pii]
AID - 10.1038/s41598-024-59237-7 [doi]
PST - epublish
SO  - Sci Rep. 2024 Apr 12;14(1):8511. doi: 10.1038/s41598-024-59237-7.

PMID- 37060945
OWN - NLM
STAT- MEDLINE
DCOM- 20231102
LR  - 20231109
IS  - 2667-2960 (Electronic)
IS  - 2667-2960 (Linking)
VI  - 64
IP  - 4
DP  - 2023 Jul-Aug
TI  - Quality Improvement Framework to Examine Health Care Disparities in Behavioral 
      Emergency Management in the Inpatient Medical Setting: A Consultation-Liaison 
      Psychiatry Health Equity Project.
PG  - 322-331
LID - S2667-2960(23)00051-4 [pii]
LID - 10.1016/j.jaclp.2023.04.002 [doi]
AB  - BACKGROUND: De-escalation of behavioral emergencies in the inpatient medical 
      setting may involve restrictive clinical interventions that directly challenge 
      patient autonomy. OBJECTIVE: We describe a quality improvement framework used to 
      examine associations between patient characteristics and behavioral emergency 
      de-escalation strategies. This project may inform other Consultation-Liaison 
      Psychiatry teams seeking to promote equity in care. METHODS: We examined 
      behavioral emergency response team (BERT) management at an urban, tertiary-care 
      medical center in the United States over a 3-year period. BERT data from an 
      existing dataset were combined with demographic information from the hospital's 
      electronic medical record. Race and ethnic identities were categorized as Black, 
      Hispanic, Asian, White, and unknown. BERT events were coded based on the most 
      restrictive intervention utilized per unique patient. Cross-tabulations and 
      adjusted odds ratios from multivariate logistic regression were used to identify 
      quality improvement targets in this exploratory project. RESULTS: The sample 
      included N = 902 patients and 1532 BERT events. The most frequent intervention 
      reached was verbal de-escalation (n = 419 patients, 46.45%) and the least 
      frequent was 4-point restraints (n = 29 patients, 3.2%). Half of BERT activations 
      for Asian and a third for Hispanic patients required interpreter services. 
      Anxiety and cognitive disorders and 2 BERT interventions, verbal de-escalation, 
      and intramuscular/intravenous/ medications, were significantly associated with 
      race/ethnic category. The most restrictive intervention for BERTs involving Black 
      and Asian patients were verbal de-escalation (60.1%) and 
      intramuscular/intravenous(53.7%), respectively. These proportions were higher 
      compared with other race/ethnic groups. There was a greater percentage of 
      patients from the unknown (6.3%) and Black (5.9%) race/ethnic groups placed in 
      4-point restraints compared with other groups (3.2%) that did not reach 
      statistical significance. A logistic regression model predicting 4-point 
      restraints indicated that younger age, multiple BERTs, and violent behavior as a 
      reason for BERT activation, but not race/ethnic group, resulted in significantly 
      higher odds. CONCLUSIONS: This project illustrates that a quality improvement 
      framework utilizing existing clinical data can be used to engage in 
      organizational introspection and identify potential areas of bias in BERT 
      management. Our findings suggest opportunities for further exploration, enhanced 
      education, and programmatic improvements regarding BERT intervention; 4-point 
      restraints; interpreter services; and the influence of race on perception of 
      psychopathology.
CI  - Copyright © 2023 Academy of Consultation-Liaison Psychiatry. Published by 
      Elsevier Inc. All rights reserved.
FAU - Caravella, Rachel A
AU  - Caravella RA
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY. Electronic address: Rachel.Caravella@nyulangone.org.
FAU - Ying, Patrick
AU  - Ying P
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY.
FAU - Siegel, Carole
AU  - Siegel C
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY.
FAU - Vaughn, Rubiahna
AU  - Vaughn R
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY; Department of Psychiatry, Montefiore Medical Center - Einstein 
      Division, Albert Einstein College of Medicine, Bronx, NY.
FAU - Deutch, Allison B
AU  - Deutch AB
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY.
FAU - Caroff, Aviva
AU  - Caroff A
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY.
FAU - Madanes, Sharon
AU  - Madanes S
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY.
FAU - Ackerman, Marra G
AU  - Ackerman MG
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY.
FAU - Lewis, Crystal
AU  - Lewis C
AD  - Department of Psychiatry, New York University, Grossman School of Medicine, New 
      York, NY.
LA  - eng
PT  - Journal Article
DEP - 20230413
PL  - Netherlands
TA  - J Acad Consult Liaison Psychiatry
JT  - Journal of the Academy of Consultation-Liaison Psychiatry
JID - 101775059
SB  - IM
MH  - Humans
MH  - United States
MH  - Healthcare Disparities
MH  - *Health Equity
MH  - Inpatients
MH  - Quality Improvement
MH  - *Psychiatry
MH  - Referral and Consultation
OTO - NOTNLM
OT  - consultation-liaison psychiatry
OT  - health disparities
OT  - psychiatric emergencies
OT  - quality improvement
OT  - racial bias
OT  - restraints
EDAT- 2023/04/16 06:00
MHDA- 2023/04/16 06:01
CRDT- 2023/04/15 19:24
PHST- 2022/05/23 00:00 [received]
PHST- 2023/04/05 00:00 [revised]
PHST- 2023/04/09 00:00 [accepted]
PHST- 2023/04/16 06:01 [medline]
PHST- 2023/04/16 06:00 [pubmed]
PHST- 2023/04/15 19:24 [entrez]
AID - S2667-2960(23)00051-4 [pii]
AID - 10.1016/j.jaclp.2023.04.002 [doi]
PST - ppublish
SO  - J Acad Consult Liaison Psychiatry. 2023 Jul-Aug;64(4):322-331. doi: 
      10.1016/j.jaclp.2023.04.002. Epub 2023 Apr 13.

PMID- 38621641
OWN - NLM
STAT- MEDLINE
DCOM- 20240501
LR  - 20250113
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Print)
IS  - 1532-0464 (Linking)
VI  - 153
DP  - 2024 May
TI  - Identifying social determinants of health from clinical narratives: A study of 
      performance, documentation ratio, and potential bias.
PG  - 104642
LID - S1532-0464(24)00060-1 [pii]
LID - 10.1016/j.jbi.2024.104642 [doi]
AB  - OBJECTIVE: To develop a natural language processing (NLP) package to extract 
      social determinants of health (SDoH) from clinical narratives, examine the bias 
      among race and gender groups, test the generalizability of extracting SDoH for 
      different disease groups, and examine population-level extraction ratio. METHODS: 
      We developed SDoH corpora using clinical notes identified at the University of 
      Florida (UF) Health. We systematically compared 7 transformer-based large 
      language models (LLMs) and developed an open-source package - SODA (i.e., SOcial 
      DeterminAnts) to facilitate SDoH extraction from clinical narratives. We examined 
      the performance and potential bias of SODA for different race and gender groups, 
      tested the generalizability of SODA using two disease domains including cancer 
      and opioid use, and explored strategies for improvement. We applied SODA to 
      extract 19 categories of SDoH from the breast (n = 7,971), lung (n = 11,804), and 
      colorectal cancer (n = 6,240) cohorts to assess patient-level extraction ratio 
      and examine the differences among race and gender groups. RESULTS: We developed 
      an SDoH corpus using 629 clinical notes of cancer patients with annotations of 
      13,193 SDoH concepts/attributes from 19 categories of SDoH, and another 
      cross-disease validation corpus using 200 notes from opioid use patients with 
      4,342 SDoH concepts/attributes. We compared 7 transformer models and the 
      GatorTron model achieved the best mean average strict/lenient F1 scores of 0.9122 
      and 0.9367 for SDoH concept extraction and 0.9584 and 0.9593 for linking 
      attributes to SDoH concepts. There is a small performance gap (∼4%) between Males 
      and Females, but a large performance gap (>16 %) among race groups. The 
      performance dropped when we applied the cancer SDoH model to the opioid cohort; 
      fine-tuning using a smaller opioid SDoH corpus improved the performance. The 
      extraction ratio varied in the three cancer cohorts, in which 10 SDoH could be 
      extracted from over 70 % of cancer patients, but 9 SDoH could be extracted from 
      less than 70 % of cancer patients. Individuals from the White and Black groups 
      have a higher extraction ratio than other minority race groups. CONCLUSIONS: Our 
      SODA package achieved good performance in extracting 19 categories of SDoH from 
      clinical narratives. The SODA package with pre-trained transformer models is 
      available at https://github.com/uf-hobi-informatics-lab/SODA_Docker.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Yu, Zehao
AU  - Yu Z
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA.
FAU - Peng, Cheng
AU  - Peng C
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA; Cancer Informatics Shared Resource, 
      University of Florida Health Cancer Center, Gainesville, FL, USA.
FAU - Yang, Xi
AU  - Yang X
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA; Cancer Informatics Shared Resource, 
      University of Florida Health Cancer Center, Gainesville, FL, USA.
FAU - Dang, Chong
AU  - Dang C
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA.
FAU - Adekkanattu, Prakash
AU  - Adekkanattu P
AD  - Information Technologies and Services, Weill Cornell Medicine, New York, NY, USA.
FAU - Gopal Patra, Braja
AU  - Gopal Patra B
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      USA.
FAU - Peng, Yifan
AU  - Peng Y
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      USA.
FAU - Pathak, Jyotishman
AU  - Pathak J
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      USA.
FAU - Wilson, Debbie L
AU  - Wilson DL
AD  - Department of Pharmaceutical Outcomes & Policy, College of Pharmacy, University 
      of Florida, Gainesville, FL 32611, USA.
FAU - Chang, Ching-Yuan
AU  - Chang CY
AD  - Department of Pharmaceutical Outcomes & Policy, College of Pharmacy, University 
      of Florida, Gainesville, FL 32611, USA.
FAU - Lo-Ciganic, Wei-Hsuan
AU  - Lo-Ciganic WH
AD  - Department of Pharmaceutical Outcomes & Policy, College of Pharmacy, University 
      of Florida, Gainesville, FL 32611, USA.
FAU - George, Thomas J
AU  - George TJ
AD  - Division of Hematology & Oncology, Department of Medicine, College of Medicine, 
      University of Florida, Gainesville, FL, USA.
FAU - Hogan, William R
AU  - Hogan WR
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA.
FAU - Guo, Yi
AU  - Guo Y
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA; Cancer Informatics Shared Resource, 
      University of Florida Health Cancer Center, Gainesville, FL, USA.
FAU - Bian, Jiang
AU  - Bian J
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA; Cancer Informatics Shared Resource, 
      University of Florida Health Cancer Center, Gainesville, FL, USA.
FAU - Wu, Yonghui
AU  - Wu Y
AD  - Department of Health Outcomes and Biomedical Informatics, College of Medicine, 
      University of Florida, Gainesville, FL, USA; Cancer Informatics Shared Resource, 
      University of Florida Health Cancer Center, Gainesville, FL, USA. Electronic 
      address: yonghui.wu@ufl.edu.
LA  - eng
GR  - R21 MH129682/MH/NIMH NIH HHS/United States
GR  - R56 AG069880/AG/NIA NIH HHS/United States
GR  - U18 DP006512/DP/NCCDPHP CDC HHS/United States
GR  - R00 LM013001/LM/NLM NIH HHS/United States
GR  - R01 MH121907/MH/NIMH NIH HHS/United States
GR  - R01 HL169277/HL/NHLBI NIH HHS/United States
GR  - R01 AG080624/AG/NIA NIH HHS/United States
GR  - R01 AI172875/AI/NIAID NIH HHS/United States
GR  - R01 AG080991/AG/NIA NIH HHS/United States
GR  - R01 CA246418/CA/NCI NIH HHS/United States
GR  - U18DP006512/ACL/ACL HHS/United States
GR  - R21 CA253394/CA/NCI NIH HHS/United States
GR  - R21 CA245858/CA/NCI NIH HHS/United States
GR  - R01 DA050676/DA/NIDA NIH HHS/United States
GR  - R21 AG068717/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20240414
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Social Determinants of Health
MH  - Female
MH  - Male
MH  - *Narration
MH  - Bias
MH  - Electronic Health Records
MH  - Documentation/methods
MH  - Data Mining/methods
PMC - PMC11141428
MID - NIHMS1987201
OTO - NOTNLM
OT  - Cancer
OT  - Clinical concept extraction
OT  - Large language model
OT  - Natural language processing
OT  - Social determinants of health
OT  - Transformer
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/04/16 00:42
MHDA- 2024/05/02 00:48
PMCR- 2024/05/31
CRDT- 2024/04/15 19:24
PHST- 2023/10/25 00:00 [received]
PHST- 2024/04/09 00:00 [revised]
PHST- 2024/04/12 00:00 [accepted]
PHST- 2024/05/02 00:48 [medline]
PHST- 2024/04/16 00:42 [pubmed]
PHST- 2024/04/15 19:24 [entrez]
PHST- 2024/05/31 00:00 [pmc-release]
AID - S1532-0464(24)00060-1 [pii]
AID - 10.1016/j.jbi.2024.104642 [doi]
PST - ppublish
SO  - J Biomed Inform. 2024 May;153:104642. doi: 10.1016/j.jbi.2024.104642. Epub 2024 
      Apr 14.

PMID- 34803885
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231103
IS  - 1664-2295 (Print)
IS  - 1664-2295 (Electronic)
IS  - 1664-2295 (Linking)
VI  - 12
DP  - 2021
TI  - Prospective Quantitative Neuroimaging Analysis of Putative Temporal Lobe 
      Epilepsy.
PG  - 747580
LID - 10.3389/fneur.2021.747580 [doi]
LID - 747580
AB  - Purpose: A prospective study of individual and combined quantitative imaging 
      applications for lateralizing epileptogenicity was performed in a cohort of 
      consecutive patients with a putative diagnosis of mesial temporal lobe epilepsy 
      (mTLE). Methods: Quantitative metrics were applied to MRI and nuclear medicine 
      imaging studies as part of a comprehensive presurgical investigation. The 
      neuroimaging analytics were conducted remotely to remove bias. All quantitative 
      lateralizing tools were trained using a separate dataset. Outcomes were 
      determined after 2 years. Of those treated, some underwent resection, and others 
      were implanted with a responsive neurostimulation (RNS) device. Results: 
      Forty-eight consecutive cases underwent evaluation using nine attributes of 
      individual or combinations of neuroimaging modalities: 1) hippocampal volume, 2) 
      FLAIR signal, 3) PET profile, 4) multistructural analysis (MSA), 5) multimodal 
      model analysis (MMM), 6) DTI uncertainty analysis, 7) DTI connectivity, and 9) 
      fMRI connectivity. Of the 24 patients undergoing resection, MSA, MMM, and PET 
      proved most effective in predicting an Engel class 1 outcome (>80% accuracy). 
      Both hippocampal volume and FLAIR signal analysis showed 76% and 69% concordance 
      with an Engel class 1 outcome, respectively. Conclusion: Quantitative multimodal 
      neuroimaging in the context of a putative mTLE aids in declaring laterality. The 
      degree to which there is disagreement among the various quantitative neuroimaging 
      metrics will judge whether epileptogenicity can be confined sufficiently to a 
      particular temporal lobe to warrant further study and choice of therapy. 
      Prediction models will improve with continued exploration of combined optimal 
      neuroimaging metrics.
CI  - Copyright © 2021 Elisevich, Davoodi-Bojd, Heredia and Soltanian-Zadeh.
FAU - Elisevich, Kost
AU  - Elisevich K
AD  - Department of Clinical Neurosciences, Spectrum Health, Grand Rapids, MI, United 
      States.
AD  - Department of Surgery, College of Human Medicine, Michigan State University, 
      Grand Rapids, MI, United States.
FAU - Davoodi-Bojd, Esmaeil
AU  - Davoodi-Bojd E
AD  - Radiology and Research Administration, Henry Ford Health System, Detroit, MI, 
      United States.
FAU - Heredia, John G
AU  - Heredia JG
AD  - Imaging Physics, Department of Radiology, Spectrum Health, Grand Rapids, MI, 
      United States.
FAU - Soltanian-Zadeh, Hamid
AU  - Soltanian-Zadeh H
AD  - Radiology and Research Administration, Henry Ford Health System, Detroit, MI, 
      United States.
AD  - Control and Intelligent Processing Center of Excellence (CIPCE), School of 
      Electrical and Computer Engineering, University of Tehran, Tehran, Iran.
LA  - eng
GR  - R01 EB013227/EB/NIBIB NIH HHS/United States
PT  - Journal Article
DEP - 20211105
PL  - Switzerland
TA  - Front Neurol
JT  - Frontiers in neurology
JID - 101546899
PMC - PMC8602195
OTO - NOTNLM
OT  - MRI
OT  - lateralization
OT  - multimodal analysis
OT  - neuroimaging
OT  - temporal lobe epilepsy
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2021/11/23 06:00
MHDA- 2021/11/23 06:01
PMCR- 2021/11/05
CRDT- 2021/11/22 06:40
PHST- 2021/07/26 00:00 [received]
PHST- 2021/09/20 00:00 [accepted]
PHST- 2021/11/22 06:40 [entrez]
PHST- 2021/11/23 06:00 [pubmed]
PHST- 2021/11/23 06:01 [medline]
PHST- 2021/11/05 00:00 [pmc-release]
AID - 10.3389/fneur.2021.747580 [doi]
PST - epublish
SO  - Front Neurol. 2021 Nov 5;12:747580. doi: 10.3389/fneur.2021.747580. eCollection 
      2021.

PMID- 38070128
OWN - NLM
STAT- MEDLINE
DCOM- 20240411
LR  - 20240425
IS  - 1365-2141 (Electronic)
IS  - 0007-1048 (Linking)
VI  - 204
IP  - 4
DP  - 2024 Apr
TI  - Evaluating the performance of large language models in haematopoietic stem cell 
      transplantation decision-making.
PG  - 1523-1528
LID - 10.1111/bjh.19200 [doi]
AB  - In a first-of-its-kind study, we assessed the capabilities of large language 
      models (LLMs) in making complex decisions in haematopoietic stem cell 
      transplantation. The evaluation was conducted not only for Generative Pre-trained 
      Transformer 4 (GPT-4) but also conducted on other artificial intelligence models: 
      PaLm 2 and Llama-2. Using detailed haematological histories that include both 
      clinical, molecular and donor data, we conducted a triple-blind survey to compare 
      LLMs to haematology residents. We found that residents significantly outperformed 
      LLMs (p = 0.02), particularly in transplant eligibility assessment (p = 0.01). 
      Our triple-blind methodology aimed to mitigate potential biases in evaluating 
      LLMs and revealed both their promise and limitations in deciphering complex 
      haematological clinical scenarios.
CI  - © 2023 The Authors. British Journal of Haematology published by British Society 
      for Haematology and John Wiley & Sons Ltd.
FAU - Civettini, Ivan
AU  - Civettini I
AUID- ORCID: 0000-0002-7707-584X
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Zappaterra, Arianna
AU  - Zappaterra A
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Transplantation Unit, ASST Grande 
      Ospedale Metropolitano Niguarda, Milan, Italy.
FAU - Granelli, Bianca Maria
AU  - Granelli BM
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Rindone, Giovanni
AU  - Rindone G
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Aroldi, Andrea
AU  - Aroldi A
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Bonfanti, Stefano
AU  - Bonfanti S
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Colombo, Federica
AU  - Colombo F
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Fedele, Marilena
AU  - Fedele M
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Grillo, Giovanni
AU  - Grillo G
AD  - Department of Haematology and Bone Marrow Transplantation Unit, ASST Grande 
      Ospedale Metropolitano Niguarda, Milan, Italy.
FAU - Parma, Matteo
AU  - Parma M
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Perfetti, Paola
AU  - Perfetti P
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Terruzzi, Elisabetta
AU  - Terruzzi E
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Gambacorti-Passerini, Carlo
AU  - Gambacorti-Passerini C
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
FAU - Ramazzotti, Daniele
AU  - Ramazzotti D
AD  - Department of Medicine and Surgery, University of Milano-Bicocca, Monza, Italy.
FAU - Cavalca, Fabrizio
AU  - Cavalca F
AD  - Department of Haematology and Bone Marrow Trasplantation Unit, Fondazione IRCCS 
      San Gerardo dei Tintori, Monza, Italy.
LA  - eng
PT  - Journal Article
DEP - 20231209
PL  - England
TA  - Br J Haematol
JT  - British journal of haematology
JID - 0372544
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Hematopoietic Stem Cell Transplantation
MH  - Language
MH  - Tissue Donors
OTO - NOTNLM
OT  - GPT
OT  - HSC transplantation
OT  - artificial intelligence
OT  - interrater agreement
OT  - transplant
EDAT- 2023/12/10 06:42
MHDA- 2024/04/11 06:43
CRDT- 2023/12/09 12:02
PHST- 2023/10/14 00:00 [revised]
PHST- 2023/08/29 00:00 [received]
PHST- 2023/10/31 00:00 [accepted]
PHST- 2024/04/11 06:43 [medline]
PHST- 2023/12/10 06:42 [pubmed]
PHST- 2023/12/09 12:02 [entrez]
AID - 10.1111/bjh.19200 [doi]
PST - ppublish
SO  - Br J Haematol. 2024 Apr;204(4):1523-1528. doi: 10.1111/bjh.19200. Epub 2023 Dec 
      9.

PMID- 38065003
OWN - NLM
STAT- MEDLINE
DCOM- 20240108
LR  - 20240116
IS  - 1872-8243 (Electronic)
IS  - 1386-5056 (Linking)
VI  - 182
DP  - 2024 Feb
TI  - Can natural language processing be effectively applied for audit data analysis in 
      gynaecological oncology at a UK cancer centre?
PG  - 105306
LID - S1386-5056(23)00324-6 [pii]
LID - 10.1016/j.ijmedinf.2023.105306 [doi]
AB  - BACKGROUND: The British Gynaecological Cancer Society (BGCS) has highlighted the 
      disparity of ovarian cancer outcomes in the UK compared to other European 
      countries. Therefore, cancer quality assurance audits and subspecialty training 
      are important in improving the UK standard of care for these patients. The 
      current workforce crisis afflicting the NHS creates difficulty in dedicating 
      teams of clinicians to these audits. We present a single institution study to 
      evaluate if NLP-generated code can improve the efficiency of ovarian cancer and 
      subspeciality reaccreditations audits. We used the chat bot Google Bard to write 
      Visual Basic Applications algorithms that utilise Excel files from electronic 
      health records. METHODS: Primary ovarian cancer data from 2019 to 2022 was 
      retrospectively collected from the Cambridge University Hospital electronic 
      health records. The surgical subspecialty reaccreditation audit analysed the 2022 
      surgical database. A modular coding approach with Google Bard was applied to 
      generate audit algorithms. The time to complete these current audits was compared 
      against the 2016 ovarian cancer and 2020 subspeciality reaccreditation audits. 
      RESULTS: The previous ovarian cancer audit conducted in 2016 required 3 
      clinicians for the 135 cases and data collection required 1800 min. Data analysis 
      was completed in 300 min. The current ovarian cancer audit allocated 2 clinicians 
      to the 600 surgical cases. Data collection was completed in 3120 min, 3360 min 
      for code development and 720 min for testing. The 2020 subspecialty 
      reaccreditation audit was completed in 360 min. The 2022 subspecialty 
      reaccreditation audit was completed in 1680 min, with 960 min for code 
      development, 240 for debugging and 480 min for testing. CONCLUSION: We have 
      demonstrated that NLP-generated code can significantly increase the efficiency of 
      surgical quality assurance audits by eliminating the need for manual data 
      analysis. With the current trajectory of NLP development, increasingly complex 
      algorithms can be developed with minimal programming knowledge.
CI  - Copyright © 2023 Elsevier B.V. All rights reserved.
FAU - McGowan, Mark
AU  - McGowan M
AD  - Addenbrookes hospital, United Kingdom. Electronic address: mark.mcgowan2@nhs.net.
FAU - Correia Martins, Filipe
AU  - Correia Martins F
AD  - University College London Hospitals, United Kingdom. Electronic address: 
      f.correiamartins@nhs.net.
FAU - Keen, Jodi-Louise
AU  - Keen JL
AD  - Addenbrookes hospital, United Kingdom. Electronic address: jkeen@nhs.net.
FAU - Whitehead, Amelia
AU  - Whitehead A
AD  - University of Cambridge, United Kingdom. Electronic address: aaw42@cam.ac.uk.
FAU - Davis, Ellie
AU  - Davis E
AD  - University of Cambridge, United Kingdom. Electronic address: emd63@cam.ac.uk.
FAU - Pathiraja, Pubudu
AU  - Pathiraja P
AD  - Addenbrookes hospital, United Kingdom. Electronic address: 
      pubudu.pathiraja1@nhs.net.
FAU - Bolton, Helen
AU  - Bolton H
AD  - Addenbrookes hospital, United Kingdom. Electronic address: helen.bolton@nhs.net.
FAU - Baldwin, Peter
AU  - Baldwin P
AD  - Addenbrookes hospital, United Kingdom. Electronic address: 
      peter.baldwin4@nhs.net.
LA  - eng
PT  - Journal Article
DEP - 20231202
PL  - Ireland
TA  - Int J Med Inform
JT  - International journal of medical informatics
JID - 9711057
SB  - IM
MH  - Female
MH  - Humans
MH  - *Natural Language Processing
MH  - Retrospective Studies
MH  - *Ovarian Neoplasms/surgery
MH  - Data Collection
MH  - United Kingdom
MH  - Medical Audit
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Gynaecological oncology
OT  - NHS
OT  - Natural language processing
OT  - Quality assurance audit
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/12/09 05:43
MHDA- 2024/01/08 06:43
CRDT- 2023/12/08 18:10
PHST- 2023/09/19 00:00 [received]
PHST- 2023/11/05 00:00 [revised]
PHST- 2023/11/27 00:00 [accepted]
PHST- 2024/01/08 06:43 [medline]
PHST- 2023/12/09 05:43 [pubmed]
PHST- 2023/12/08 18:10 [entrez]
AID - S1386-5056(23)00324-6 [pii]
AID - 10.1016/j.ijmedinf.2023.105306 [doi]
PST - ppublish
SO  - Int J Med Inform. 2024 Feb;182:105306. doi: 10.1016/j.ijmedinf.2023.105306. Epub 
      2023 Dec 2.

PMID- 39965195
OWN - NLM
STAT- MEDLINE
DCOM- 20250218
LR  - 20250309
IS  - 2369-1999 (Electronic)
IS  - 2369-1999 (Linking)
VI  - 11
DP  - 2025 Feb 18
TI  - Developing Effective Frameworks for Large Language Model-Based Medical Chatbots: 
      Insights From Radiotherapy Education With ChatGPT.
PG  - e66633
LID - 10.2196/66633 [doi]
LID - e66633
AB  - This Viewpoint proposes a robust framework for developing a medical chatbot 
      dedicated to radiotherapy education, emphasizing accuracy, reliability, privacy, 
      ethics, and future innovations. By analyzing existing research, the framework 
      evaluates chatbot performance and identifies challenges such as content accuracy, 
      bias, and system integration. The findings highlight opportunities for 
      advancements in natural language processing, personalized learning, and immersive 
      technologies. When designed with a focus on ethical standards and reliability, 
      large language model-based chatbots could significantly impact radiotherapy 
      education and health care delivery, positioning them as valuable tools for future 
      developments in medical education globally.
CI  - ©James C L Chow, Kay Li. Originally published in JMIR Cancer 
      (https://cancer.jmir.org), 18.02.2025.
FAU - Chow, James C L
AU  - Chow JCL
AUID- ORCID: 0000-0003-4202-4855
AD  - Department of Medical Physics, Princess Margaret Cancer Centre, University Health 
      Network, Toronto, ON, Canada.
AD  - Department of Radiation Oncology, Temerty Faculty of Medicine, University of 
      Toronto, Toronto, ON, Canada.
FAU - Li, Kay
AU  - Li K
AUID- ORCID: 0000-0002-5765-1635
AD  - Department of English, Faculty of Arts and Science, University of Toronto, 
      Toronto, ON, Canada.
LA  - eng
PT  - Journal Article
DEP - 20250218
PL  - Canada
TA  - JMIR Cancer
JT  - JMIR cancer
JID - 101666844
SB  - IM
MH  - Humans
MH  - *Radiotherapy/methods
MH  - Education, Medical/methods
PMC - PMC11888077
OTO - NOTNLM
OT  - AI
OT  - AI in medical education
OT  - AI-driven learning tools
OT  - LLMs
OT  - NLP
OT  - artificial intelligence
OT  - ethical AI in health care
OT  - health care AI
OT  - large language models
OT  - medical chatbots
OT  - natural language processing
OT  - personalized learning
OT  - radiotherapy chatbot
OT  - radiotherapy education
COIS- Conflicts of Interest: None declared.
EDAT- 2025/02/18 18:20
MHDA- 2025/02/18 18:21
PMCR- 2025/02/18
CRDT- 2025/02/18 16:52
PHST- 2024/09/18 00:00 [received]
PHST- 2025/01/16 00:00 [accepted]
PHST- 2024/12/15 00:00 [revised]
PHST- 2025/02/18 18:21 [medline]
PHST- 2025/02/18 18:20 [pubmed]
PHST- 2025/02/18 16:52 [entrez]
PHST- 2025/02/18 00:00 [pmc-release]
AID - v11i1e66633 [pii]
AID - 10.2196/66633 [doi]
PST - epublish
SO  - JMIR Cancer. 2025 Feb 18;11:e66633. doi: 10.2196/66633.

PMID- 38682512
OWN - NLM
STAT- MEDLINE
DCOM- 20240429
LR  - 20240429
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 313
DP  - 2024 Apr 26
TI  - Editing Physicians' Responses Using GPT-4 for Academic Research.
PG  - 101-106
LID - 10.3233/SHTI240019 [doi]
AB  - The integration of Artificial Intelligence (AI) into digital healthcare, 
      particularly in the anonymisation and processing of health information, holds 
      considerable potential. OBJECTIVES: To develop a methodology using Generative 
      Pre-trained Transformer (GPT) models to preserve the essence of medical advice in 
      doctors' responses, while editing them for use in scientific studies. METHODS: 
      German and English responses from EXABO, a rare respiratory disease platform, 
      were processed using iterative refinement and other prompt engineering 
      techniques, with a focus on removing identifiable and irrelevant content. 
      RESULTS: Of 40 responses tested, 31 were accurately modified according to the 
      developed guidelines. Challenges included misclassification and incomplete 
      removal, with incremental prompting proving more accurate than combined 
      prompting. CONCLUSION: GPT-4 models show promise in medical response editing, but 
      face challenges in accuracy and consistency. Precision in prompt engineering is 
      essential in medical contexts to minimise bias and retain relevant information.
FAU - Weber, Magdalena T
AU  - Weber MT
AD  - Institute of Medical Informatics, Goethe University Frankfurt, University 
      Hospital Frankfurt, Frankfurt, Germany.
FAU - Schaaf, Jannik
AU  - Schaaf J
AD  - Institute of Medical Informatics, Goethe University Frankfurt, University 
      Hospital Frankfurt, Frankfurt, Germany.
FAU - Storf, Holger
AU  - Storf H
AD  - Institute of Medical Informatics, Goethe University Frankfurt, University 
      Hospital Frankfurt, Frankfurt, Germany.
FAU - Wagner, Thomas O F
AU  - Wagner TOF
AD  - European Reference Network for Rare Respiratory Diseases (ERN-LUNG), University 
      Hospital Frankfurt, Frankfurt, Germany.
FAU - Berger, Alexandra
AU  - Berger A
AD  - Reference Center for Rare Diseases (FRZSE), University Hospital Frankfurt, 
      Frankfurt, Germany.
FAU - Noll, Richard
AU  - Noll R
AD  - Institute of Medical Informatics, Goethe University Frankfurt, University 
      Hospital Frankfurt, Frankfurt, Germany.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Physicians
MH  - Germany
MH  - Electronic Health Records
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Data Anonymisation
OT  - Medical Informatics
OT  - Natural Language Processing
EDAT- 2024/04/29 06:44
MHDA- 2024/04/29 14:03
CRDT- 2024/04/29 05:53
PHST- 2024/04/29 14:03 [medline]
PHST- 2024/04/29 06:44 [pubmed]
PHST- 2024/04/29 05:53 [entrez]
AID - SHTI240019 [pii]
AID - 10.3233/SHTI240019 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2024 Apr 26;313:101-106. doi: 10.3233/SHTI240019.

PMID- 32066734
OWN - NLM
STAT- MEDLINE
DCOM- 20201019
LR  - 20240328
IS  - 2052-4463 (Electronic)
IS  - 2052-4463 (Linking)
VI  - 7
IP  - 1
DP  - 2020 Feb 17
TI  - High-resolution T2-FLAIR and non-contrast CT brain atlas of the elderly.
PG  - 56
LID - 10.1038/s41597-020-0379-9 [doi]
LID - 56
AB  - Normative brain atlases are a standard tool for neuroscience research and are, 
      for example, used for spatial normalization of image datasets prior to 
      voxel-based analyses of brain morphology and function. Although many different 
      atlases are publicly available, they are usually biased with respect to an 
      imaging modality and the age distribution. Both effects are well known to 
      negatively impact the accuracy and reliability of the spatial normalization 
      process using non-linear image registration methods. An important and very active 
      neuroscience area that lacks appropriate atlases is lesion-related research in 
      elderly populations (e.g. stroke, multiple sclerosis) for which FLAIR MRI and 
      non-contrast CT are often the clinical imaging modalities of choice. To overcome 
      the lack of atlases for these tasks and modalities, this paper presents 
      high-resolution, age-specific FLAIR and non-contrast CT atlases of the elderly 
      generated using clinical images.
FAU - Rajashekar, Deepthi
AU  - Rajashekar D
AD  - Biomedical Engineering Graduate Program, University of Calgary, Calgary, AB, 
      Canada. deepthi.rajasheka1@ucalgary.ca.
AD  - Department of Radiology, Cumming School of Medicine, University of Calgary, 
      Calgary, AB, Canada. deepthi.rajasheka1@ucalgary.ca.
FAU - Wilms, Matthias
AU  - Wilms M
AUID- ORCID: 0000-0001-8845-360X
AD  - Department of Radiology, Cumming School of Medicine, University of Calgary, 
      Calgary, AB, Canada.
FAU - MacDonald, M Ethan
AU  - MacDonald ME
AD  - Department of Radiology, Cumming School of Medicine, University of Calgary, 
      Calgary, AB, Canada.
AD  - Healthy Brain Aging Lab, University of Calgary, Calgary, AB, Canada.
FAU - Ehrhardt, Jan
AU  - Ehrhardt J
AD  - Institute of Medical Informatics, University of Luebeck, Lübeck, Germany.
FAU - Mouches, Pauline
AU  - Mouches P
AD  - Biomedical Engineering Graduate Program, University of Calgary, Calgary, AB, 
      Canada.
AD  - Department of Radiology, Cumming School of Medicine, University of Calgary, 
      Calgary, AB, Canada.
FAU - Frayne, Richard
AU  - Frayne R
AD  - Seaman Family MR Research Center, Foothills Medical Centre, Calgary, AB, Canada.
AD  - Calgary Image Processing and Analysis Center (CIPAC), Foothills Medical Centre, 
      Calgary, AB, Canada.
FAU - Hill, Michael D
AU  - Hill MD
AD  - Department of Radiology, Cumming School of Medicine, University of Calgary, 
      Calgary, AB, Canada.
AD  - Department of Clinical Neurosciences, Cumming School of Medicine, University of 
      Calgary, Calgary, AB, Canada.
FAU - Forkert, Nils D
AU  - Forkert ND
AUID- ORCID: 0000-0003-2556-3224
AD  - Department of Radiology, Cumming School of Medicine, University of Calgary, 
      Calgary, AB, Canada.
AD  - Department of Clinical Neurosciences, Cumming School of Medicine, University of 
      Calgary, Calgary, AB, Canada.
LA  - eng
PT  - Dataset
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20200217
PL  - England
TA  - Sci Data
JT  - Scientific data
JID - 101640192
SB  - IM
MH  - Aged
MH  - Brain/*anatomy & histology/diagnostic imaging
MH  - Brain Mapping/*methods
MH  - Humans
MH  - Image Processing, Computer-Assisted
MH  - *Magnetic Resonance Imaging
MH  - *Tomography, X-Ray Computed
PMC - PMC7026039
COIS- The authors declare no competing interests.
EDAT- 2020/02/19 06:00
MHDA- 2020/10/21 06:00
PMCR- 2020/02/17
CRDT- 2020/02/19 06:00
PHST- 2019/08/09 00:00 [received]
PHST- 2020/01/10 00:00 [accepted]
PHST- 2020/02/19 06:00 [entrez]
PHST- 2020/02/19 06:00 [pubmed]
PHST- 2020/10/21 06:00 [medline]
PHST- 2020/02/17 00:00 [pmc-release]
AID - 10.1038/s41597-020-0379-9 [pii]
AID - 379 [pii]
AID - 10.1038/s41597-020-0379-9 [doi]
PST - epublish
SO  - Sci Data. 2020 Feb 17;7(1):56. doi: 10.1038/s41597-020-0379-9.

PMID- 35685304
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20220716
IS  - 2673-253X (Electronic)
IS  - 2673-253X (Linking)
VI  - 4
DP  - 2022
TI  - Validating GAN-BioBERT: A Methodology for Assessing Reporting Trends in Clinical 
      Trials.
PG  - 878369
LID - 10.3389/fdgth.2022.878369 [doi]
LID - 878369
AB  - BACKGROUND: The aim of this study was to validate a three-class sentiment 
      classification model for clinical trial abstracts combining adversarial learning 
      and the BioBERT language processing model as a tool to assess trends in 
      biomedical literature in a clearly reproducible manner. We then assessed the 
      model's performance for this application and compared it to previous models used 
      for this task. METHODS: Using 108 expert-annotated clinical trial abstracts and 
      2,000 unlabeled abstracts this study develops a three-class sentiment 
      classification algorithm for clinical trial abstracts. The model uses a 
      semi-supervised model based on the Bidirectional Encoder Representation from 
      Transformers (BERT) model, a much more advanced and accurate method compared to 
      previously used models based upon traditional machine learning methods. The 
      prediction performance was compared to those previous studies. RESULTS: The 
      algorithm was found to have a classification accuracy of 91.3%, with a macro 
      F1-Score of 0.92, significantly outperforming previous studies used to classify 
      sentiment in clinical trial literature, while also making the sentiment 
      classification finer grained with greater reproducibility. CONCLUSION: We 
      demonstrate an easily applied sentiment classification model for clinical trial 
      abstracts that significantly outperforms previous models with greater 
      reproducibility and applicability to large-scale study of reporting trends.
CI  - Copyright © 2022 Myszewski, Klossowski, Meyer, Bevil, Klesius and Schroeder.
FAU - Myszewski, Joshua J
AU  - Myszewski JJ
AD  - School of Medicine and Public Health, University of Wisconsin, Madison, WI, 
      United States.
FAU - Klossowski, Emily
AU  - Klossowski E
AD  - University of Wisconsin-Milwaukee, Milwaukee, WI, United States.
FAU - Meyer, Patrick
AU  - Meyer P
AD  - Department of Anesthesiology, School of Medicine and Public Health, University of 
      Wisconsin, Madison, WI, United States.
FAU - Bevil, Kristin
AU  - Bevil K
AD  - Department of Anesthesiology, School of Medicine and Public Health, University of 
      Wisconsin, Madison, WI, United States.
FAU - Klesius, Lisa
AU  - Klesius L
AD  - Department of Anesthesiology, School of Medicine and Public Health, University of 
      Wisconsin, Madison, WI, United States.
FAU - Schroeder, Kristopher M
AU  - Schroeder KM
AD  - Department of Anesthesiology, School of Medicine and Public Health, University of 
      Wisconsin, Madison, WI, United States.
LA  - eng
PT  - Journal Article
DEP - 20220524
PL  - Switzerland
TA  - Front Digit Health
JT  - Frontiers in digital health
JID - 101771889
PMC - PMC9170913
OTO - NOTNLM
OT  - clinical trial
OT  - meta-analyses
OT  - natural language processing
OT  - publication bias
OT  - sentiment analysis
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2022/06/11 06:00
MHDA- 2022/06/11 06:01
PMCR- 2022/05/24
CRDT- 2022/06/10 02:28
PHST- 2022/02/17 00:00 [received]
PHST- 2022/05/05 00:00 [accepted]
PHST- 2022/06/10 02:28 [entrez]
PHST- 2022/06/11 06:00 [pubmed]
PHST- 2022/06/11 06:01 [medline]
PHST- 2022/05/24 00:00 [pmc-release]
AID - 10.3389/fdgth.2022.878369 [doi]
PST - epublish
SO  - Front Digit Health. 2022 May 24;4:878369. doi: 10.3389/fdgth.2022.878369. 
      eCollection 2022.

PMID- 38770501
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240522
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 4
DP  - 2024 Apr
TI  - Assessing ChatGPT's Diagnostic Accuracy and Therapeutic Strategies in Oral 
      Pathologies: A Cross-Sectional Study.
PG  - e58607
LID - 10.7759/cureus.58607 [doi]
LID - e58607
AB  - BACKGROUND: The rapid adoption of artificial intelligence (AI) models in the 
      medical field is due to their ability to collaborate with clinicians in the 
      diagnosis and management of a wide range of conditions. This research assesses 
      the diagnostic accuracy and therapeutic strategies of Chat Generative Pre-trained 
      Transformer (ChatGPT) in comparison to dental professionals across 12 clinical 
      cases. METHODOLOGY: ChatGPT 3.5 was queried for diagnoses and management plans 
      for 12 retrospective cases. Physicians were tasked with rating the complexity of 
      clinical scenarios and their agreement with the ChatGPT responses using a 
      five-point Likert scale. Comparisons were made between the complexity of the 
      cases and the accuracy of the diagnoses and treatment plans. RESULTS: ChatGPT 
      exhibited high accuracy in providing differential diagnoses and acceptable 
      treatment plans. In a survey involving 30 attending physicians, scenarios were 
      rated with an overall median difficulty level of 3, showing acceptable agreement 
      with ChatGPT's differential diagnosis accuracy (overall median 4). Our study 
      revealed lower diagnosis scores correlating with decreased treatment management 
      scores, as demonstrated by univariate ordinal regression analysis. CONCLUSIONS: 
      ChatGPT's rapid processing aids healthcare by offering an objective, 
      evidence-based approach, reducing human error and workload. However, potential 
      biases may affect outcomes and challenge less-experienced practitioners. AI in 
      healthcare, including ChatGPT, is still evolving, and further research is needed 
      to understand its full potential in analyzing clinical information, establishing 
      diagnoses, and suggesting treatments.
CI  - Copyright © 2024, Uranbey et al.
FAU - Uranbey, Ömer
AU  - Uranbey Ö
AD  - Oral and Maxillofacial Surgery, Ordu University, Ordu, TUR.
FAU - Özbey, Furkan
AU  - Özbey F
AD  - Oral and Maxillofacial Radiology, Ordu University, Ordu, TUR.
FAU - Kaygısız, Ömer
AU  - Kaygısız Ö
AD  - Oral and Maxillofacial Surgery, Gaziantep University, Gaziantep, TUR.
FAU - Ayrancı, Ferhat
AU  - Ayrancı F
AD  - Oral and Maxillofacial Surgery, Ordu University, Ordu, TUR.
LA  - eng
PT  - Journal Article
DEP - 20240419
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11102887
OTO - NOTNLM
OT  - artificial intelligence in healthcare
OT  - chatgpt
OT  - large language model
OT  - oral pathologies
OT  - oral surgery
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/05/21 06:43
MHDA- 2024/05/21 06:44
PMCR- 2024/04/19
CRDT- 2024/05/21 03:47
PHST- 2024/04/15 00:00 [accepted]
PHST- 2024/05/21 06:44 [medline]
PHST- 2024/05/21 06:43 [pubmed]
PHST- 2024/05/21 03:47 [entrez]
PHST- 2024/04/19 00:00 [pmc-release]
AID - 10.7759/cureus.58607 [doi]
PST - epublish
SO  - Cureus. 2024 Apr 19;16(4):e58607. doi: 10.7759/cureus.58607. eCollection 2024 
      Apr.

PMID- 37011635
OWN - NLM
STAT- MEDLINE
DCOM- 20230721
LR  - 20240929
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 30
IP  - 8
DP  - 2023 Jul 19
TI  - A marker-based neural network system for extracting social determinants of 
      health.
PG  - 1398-1407
LID - 10.1093/jamia/ocad041 [doi]
AB  - OBJECTIVE: The impact of social determinants of health (SDoH) on patients' 
      healthcare quality and the disparity is well known. Many SDoH items are not coded 
      in structured forms in electronic health records. These items are often captured 
      in free-text clinical notes, but there are limited methods for automatically 
      extracting them. We explore a multi-stage pipeline involving named entity 
      recognition (NER), relation classification (RC), and text classification methods 
      to automatically extract SDoH information from clinical notes. MATERIALS AND 
      METHODS: The study uses the N2C2 Shared Task data, which were collected from 2 
      sources of clinical notes: MIMIC-III and University of Washington Harborview 
      Medical Centers. It contains 4480 social history sections with full annotation 
      for 12 SDoHs. In order to handle the issue of overlapping entities, we developed 
      a novel marker-based NER model. We used it in a multi-stage pipeline to extract 
      SDoH information from clinical notes. RESULTS: Our marker-based system 
      outperformed the state-of-the-art span-based models at handling overlapping 
      entities based on the overall Micro-F1 score performance. It also achieved 
      state-of-the-art performance compared with the shared task methods. Our approach 
      achieved an F1 of 0.9101, 0.8053, and 0.9025 for Subtasks A, B, and C, 
      respectively. CONCLUSIONS: The major finding of this study is that the 
      multi-stage pipeline effectively extracts SDoH information from clinical notes. 
      This approach can improve the understanding and tracking of SDoHs in clinical 
      settings. However, error propagation may be an issue and further research is 
      needed to improve the extraction of entities with complex semantic meanings and 
      low-frequency entities. We have made the source code available at 
      https://github.com/Zephyr1022/SDOH-N2C2-UTSA.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Zhao, Xingmeng
AU  - Zhao X
AD  - Information Systems and Cyber Security, The University of Texas at San Antonio, 
      San Antonio, Texas, USA.
FAU - Rios, Anthony
AU  - Rios A
AD  - Information Systems and Cyber Security, The University of Texas at San Antonio, 
      San Antonio, Texas, USA.
LA  - eng
PT  - Journal Article
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Humans
MH  - *Social Determinants of Health
MH  - *Neural Networks, Computer
MH  - Electronic Health Records
MH  - Hospitals
MH  - Natural Language Processing
PMC - PMC10354756
OTO - NOTNLM
OT  - machine learning
OT  - natural language processing
OT  - neural networks
OT  - social determinants of health
OT  - NLP
OT  - information extraction
COIS- None.
EDAT- 2023/04/04 06:00
MHDA- 2023/07/21 06:42
PMCR- 2024/04/20
CRDT- 2023/04/03 18:52
PHST- 2022/12/05 00:00 [received]
PHST- 2023/02/14 00:00 [revised]
PHST- 2023/02/28 00:00 [accepted]
PHST- 2023/07/21 06:42 [medline]
PHST- 2023/04/04 06:00 [pubmed]
PHST- 2023/04/03 18:52 [entrez]
PHST- 2024/04/20 00:00 [pmc-release]
AID - 7100845 [pii]
AID - ocad041 [pii]
AID - 10.1093/jamia/ocad041 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2023 Jul 19;30(8):1398-1407. doi: 10.1093/jamia/ocad041.

PMID- 40088857
OWN - NLM
STAT- Publisher
LR  - 20250315
IS  - 1873-7714 (Electronic)
IS  - 0163-8343 (Linking)
VI  - 94
DP  - 2025 Mar 7
TI  - AI-driven report-generation tools in mental healthcare: A review of commercial 
      tools.
PG  - 150-158
LID - S0163-8343(25)00048-9 [pii]
LID - 10.1016/j.genhosppsych.2025.02.018 [doi]
AB  - Artificial intelligence (AI) systems are increasingly being integrated in 
      clinical care, including for AI-powered note-writing. We aimed to develop and 
      apply a scale for assessing mental health electronic health records (EHRs) that 
      use large language models (LLMs) for note-writing, focusing on their features, 
      security, and ethics. The assessment involved analyzing product information and 
      directly querying vendors about their systems. On their websites, the majority of 
      vendors provided comprehensive information on data protection, privacy measures, 
      multi-platform availability, patient access features, software update history, 
      and Meaningful Use compliance. Most products clearly indicated the LLM's 
      capabilities in creating customized reports or functioning as a co-pilot. 
      However, critical information was often absent, including details on LLM training 
      methodologies, the specific LLM used, bias correction techniques, and methods for 
      evaluating the evidence base. The lack of transparency regarding LLM specifics 
      and bias mitigation strategies raises concerns about the ethical implementation 
      and reliability of these systems in clinical practice. While LLM-enhanced EHRs 
      show promise in alleviating the documentation burden for mental health 
      professionals, there is a pressing need for greater transparency and 
      standardization in reporting LLM-related information. We propose recommendations 
      for the future development and implementation of these systems to ensure they 
      meet the highest standards of security, ethics, and clinical care.
CI  - Copyright © 2025 Elsevier Inc. All rights reserved.
FAU - Bouguettaya, Ayoub
AU  - Bouguettaya A
AD  - Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, CA, 
      United States; School of Nursing and Midwifery, Monash University, Melbourne, 
      Victoria, Australia.
FAU - Team, Victoria
AU  - Team V
AD  - School of Nursing and Midwifery, Monash University, Melbourne, Victoria, 
      Australia.
FAU - Stuart, Elizabeth M
AU  - Stuart EM
AD  - Jonathan Jaques Children's Cancer Institute, Miller Children's & Women's Hospital 
      Long Beach, Long Beach, CA, United States.
FAU - Aboujaoude, Elias
AU  - Aboujaoude E
AD  - Department of Biomedical Sciences, Cedars-Sinai Medical Center, Los Angeles, CA, 
      United States; Department of Psychiatry and Behavioral Sciences, Stanford 
      University, Stanford, CA, United States. Electronic address: 
      elias.aboujaoude@cshs.org.
LA  - eng
PT  - Journal Article
DEP - 20250307
PL  - United States
TA  - Gen Hosp Psychiatry
JT  - General hospital psychiatry
JID - 7905527
SB  - IM
COIS- Declaration of competing interest The authors have no competing interests to 
      declare.
EDAT- 2025/03/16 12:45
MHDA- 2025/03/16 12:45
CRDT- 2025/03/15 19:10
PHST- 2024/12/10 00:00 [received]
PHST- 2025/02/21 00:00 [revised]
PHST- 2025/02/21 00:00 [accepted]
PHST- 2025/03/16 12:45 [medline]
PHST- 2025/03/16 12:45 [pubmed]
PHST- 2025/03/15 19:10 [entrez]
AID - S0163-8343(25)00048-9 [pii]
AID - 10.1016/j.genhosppsych.2025.02.018 [doi]
PST - aheadofprint
SO  - Gen Hosp Psychiatry. 2025 Mar 7;94:150-158. doi: 
      10.1016/j.genhosppsych.2025.02.018.

PMID- 39977313
OWN - NLM
STAT- MEDLINE
DCOM- 20250220
LR  - 20250305
IS  - 1091-6490 (Electronic)
IS  - 0027-8424 (Print)
IS  - 0027-8424 (Linking)
VI  - 122
IP  - 8
DP  - 2025 Feb 25
TI  - Explicitly unbiased large language models still form biased associations.
PG  - e2416228122
LID - 10.1073/pnas.2416228122 [doi]
LID - e2416228122
AB  - Large language models (LLMs) can pass explicit social bias tests but still harbor 
      implicit biases, similar to humans who endorse egalitarian beliefs yet exhibit 
      subtle biases. Measuring such implicit biases can be a challenge: As LLMs become 
      increasingly proprietary, it may not be possible to access their embeddings and 
      apply existing bias measures; furthermore, implicit biases are primarily a 
      concern if they affect the actual decisions that these systems make. We address 
      both challenges by introducing two measures: LLM Word Association Test, a 
      prompt-based method for revealing implicit bias; and LLM Relative Decision Test, 
      a strategy to detect subtle discrimination in contextual decisions. Both measures 
      are based on psychological research: LLM Word Association Test adapts the 
      Implicit Association Test, widely used to study the automatic associations 
      between concepts held in human minds; and LLM Relative Decision Test 
      operationalizes psychological results indicating that relative evaluations 
      between two candidates, not absolute evaluations assessing each independently, 
      are more diagnostic of implicit biases. Using these measures, we found pervasive 
      stereotype biases mirroring those in society in 8 value-aligned models across 4 
      social categories (race, gender, religion, health) in 21 stereotypes (such as 
      race and criminality, race and weapons, gender and science, age and negativity). 
      These prompt-based measures draw from psychology's long history of research into 
      measuring stereotypes based on purely observable behavior; they expose nuanced 
      biases in proprietary value-aligned LLMs that appear unbiased according to 
      standard benchmarks.
FAU - Bai, Xuechunzi
AU  - Bai X
AUID- ORCID: 0000-0002-2277-5451
AD  - Department of Psychology, The University of Chicago, Chicago, IL 60637.
FAU - Wang, Angelina
AU  - Wang A
AUID- ORCID: 0000-0001-9140-3523
AD  - Department of Computer Science, Stanford University, Palo Alto, CA 94305.
FAU - Sucholutsky, Ilia
AU  - Sucholutsky I
AUID- ORCID: 0000-0003-4121-7479
AD  - Center for Data Science, New York University, New York, NY 10011.
FAU - Griffiths, Thomas L
AU  - Griffiths TL
AD  - Departments of Psychology and Computer Science, Princeton University, Princeton, 
      NJ 08540.
LA  - eng
GR  - 12345/Microsoft Foundation Models Grant/
PT  - Journal Article
DEP - 20250220
PL  - United States
TA  - Proc Natl Acad Sci U S A
JT  - Proceedings of the National Academy of Sciences of the United States of America
JID - 7505876
SB  - IM
MH  - Humans
MH  - *Language
MH  - Stereotyping
MH  - Prejudice/psychology
MH  - Word Association Tests
MH  - Decision Making/physiology
MH  - Female
PMC - PMC11874501
OTO - NOTNLM
OT  - bias and fairness
OT  - large language models
OT  - psychology
OT  - stereotypes
COIS- Competing interests statement:The authors declare no competing interest.
EDAT- 2025/02/20 18:21
MHDA- 2025/02/20 18:22
PMCR- 2025/08/20
CRDT- 2025/02/20 13:02
PHST- 2025/08/20 00:00 [pmc-release]
PHST- 2025/02/20 18:22 [medline]
PHST- 2025/02/20 18:21 [pubmed]
PHST- 2025/02/20 13:02 [entrez]
AID - 202416228 [pii]
AID - 10.1073/pnas.2416228122 [doi]
PST - ppublish
SO  - Proc Natl Acad Sci U S A. 2025 Feb 25;122(8):e2416228122. doi: 
      10.1073/pnas.2416228122. Epub 2025 Feb 20.

PMID- 36215784
OWN - NLM
STAT- MEDLINE
DCOM- 20221129
LR  - 20250129
IS  - 1873-7994 (Electronic)
IS  - 0021-9924 (Print)
IS  - 0021-9924 (Linking)
VI  - 100
DP  - 2022 Nov-Dec
TI  - Aphasia severity is modulated by race and lesion size in chronic survivors: A 
      retrospective study.
PG  - 106270
LID - S0021-9924(22)00089-2 [pii]
LID - 10.1016/j.jcomdis.2022.106270 [doi]
AB  - INTRODUCTION: In stroke survivors with aphasia (SWA), differences in behavioral 
      language performance have been observed between Black and White Americans. These 
      racial differences in aphasia outcomes may reflect biological stroke severity, 
      disparities in access to care, potential assessment bias, or interactions between 
      these factors and race. Understanding the origin of disparities in aphasia 
      outcomes is critical to any efforts to promote health equity among SWA. In this 
      study, we explore aphasia outcomes by examining the relationship between race, 
      socioeconomic status, and neurological factors in SWA. METHOD: Eighty-five 
      chronic left-hemisphere SWA (31 Black, 54 White) participated in the study. The 
      primary aphasia outcome measure was the Western Aphasia Battery-Revised (WAB-R). 
      Lesion size was measured based on manual lesion segmentations. FLAIR and T2 
      images were scored for severity of white matter disease. Independent sample 
      t-tests were used to determine differences by race in education, age, income, 
      aphasia severity, white matter disease, and lesion size. A linear regression 
      model was used to explore factors that predicted aphasia severity on the WAB-R. 
      RESULT: Level of education and estimated income differed by race in our sample. 
      For predictors of aphasia severity, the regression model revealed a significant 
      effect of lesion size on WAB Aphasia Quotient and an interaction of race x lesion 
      size, such that Black and White participants with small lesions had similar WAB 
      scores, but in individuals with larger lesions, Black participants had lower WAB 
      scores than White participants. CONCLUSION: We suggest two explanations for the 
      difference between Black and White SWA in the relationship between lesion size 
      and aphasia severity. First, the impact of disparities in access to 
      rehabilitation after stroke may be more evident when a stroke is larger and 
      causes significant aphasia. Additionally, an assessment bias in aphasia outcome 
      measures may be more evident with increasing severity of aphasia. Future studies 
      should further discern the drivers of observed disparities in aphasia outcomes in 
      order to identify opportunities to improve equity in aphasia care.
CI  - Copyright © 2022. Published by Elsevier Inc.
FAU - Gadson, Davetrina S
AU  - Gadson DS
AD  - Center for Brain Plasticity and Recovery, Georgetown University School of 
      Medicine, Washington, (DC), USA; Georgetown University Medical Center, 
      Washington, DC, USA. Electronic address: dg988@georgetown.edu.
FAU - Wesley, Deliya B
AU  - Wesley DB
AD  - MedStar Health Research Institute, Hyattsville, MD, USA.
FAU - van der Stelt, Candace M
AU  - van der Stelt CM
AD  - Center for Brain Plasticity and Recovery, Georgetown University School of 
      Medicine, Washington, (DC), USA; Center for Aphasia Research and Rehabilitation, 
      Georgetown University School of Medicine, Washington, (DC), USA.
FAU - Lacey, Elizabeth
AU  - Lacey E
AD  - Center for Brain Plasticity and Recovery, Georgetown University School of 
      Medicine, Washington, (DC), USA; Center for Aphasia Research and Rehabilitation, 
      Georgetown University School of Medicine, Washington, (DC), USA; Research 
      Division, MedStar National Rehabilitation Hospital, Washington, (DC), USA; 
      Georgetown University Medical Center, Washington, DC, USA; Medstar National 
      Rehabilitation Hospital, Washington, DC, USA.
FAU - DeMarco, Andrew T
AU  - DeMarco AT
AD  - Center for Brain Plasticity and Recovery, Georgetown University School of 
      Medicine, Washington, (DC), USA; Center for Aphasia Research and Rehabilitation, 
      Georgetown University School of Medicine, Washington, (DC), USA.
FAU - Snider, Sarah F
AU  - Snider SF
AD  - Center for Aphasia Research and Rehabilitation, Georgetown University School of 
      Medicine, Washington, (DC), USA.
FAU - Turkeltaub, Peter E
AU  - Turkeltaub PE
AD  - Center for Brain Plasticity and Recovery, Georgetown University School of 
      Medicine, Washington, (DC), USA; Center for Aphasia Research and Rehabilitation, 
      Georgetown University School of Medicine, Washington, (DC), USA; Research 
      Division, MedStar National Rehabilitation Hospital, Washington, (DC), USA; 
      Georgetown University Medical Center, Washington, DC, USA; Medstar National 
      Rehabilitation Hospital, Washington, DC, USA.
LA  - eng
GR  - K12 HD093427/HD/NICHD NIH HHS/United States
GR  - K99 DC018828/DC/NIDCD NIH HHS/United States
GR  - R01 DC014960/DC/NIDCD NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20221005
PL  - United States
TA  - J Commun Disord
JT  - Journal of communication disorders
JID - 0260316
SB  - IM
MH  - Humans
MH  - Retrospective Studies
MH  - Health Promotion
MH  - *Aphasia/etiology
MH  - *Stroke/complications
MH  - *Leukoencephalopathies/complications
MH  - Survivors
PMC - PMC11744488
MID - NIHMS2042704
OTO - NOTNLM
OT  - African-American, Language
OT  - Aphasia
OT  - Language
OT  - Lesion symptom mapping
OT  - Stroke
OT  - Western aphasia battery
EDAT- 2022/10/11 06:00
MHDA- 2022/11/30 06:00
PMCR- 2025/01/20
CRDT- 2022/10/10 18:18
PHST- 2022/03/15 00:00 [received]
PHST- 2022/08/04 00:00 [revised]
PHST- 2022/09/26 00:00 [accepted]
PHST- 2022/10/11 06:00 [pubmed]
PHST- 2022/11/30 06:00 [medline]
PHST- 2022/10/10 18:18 [entrez]
PHST- 2025/01/20 00:00 [pmc-release]
AID - S0021-9924(22)00089-2 [pii]
AID - 10.1016/j.jcomdis.2022.106270 [doi]
PST - ppublish
SO  - J Commun Disord. 2022 Nov-Dec;100:106270. doi: 10.1016/j.jcomdis.2022.106270. 
      Epub 2022 Oct 5.

PMID- 34662699
OWN - NLM
STAT- MEDLINE
DCOM- 20220318
LR  - 20230102
IS  - 1873-5894 (Electronic)
IS  - 0730-725X (Print)
IS  - 0730-725X (Linking)
VI  - 85
DP  - 2022 Jan
TI  - Automatic quantification of white matter hyperintensities on T2-weighted fluid 
      attenuated inversion recovery magnetic resonance imaging.
PG  - 71-79
LID - S0730-725X(21)00174-0 [pii]
LID - 10.1016/j.mri.2021.10.007 [doi]
AB  - White matter hyperintensities (WMH) are areas of increased signal visualized on 
      T2-weighted fluid attenuated inversion recovery (FLAIR) brain magnetic resonance 
      imaging (MRI) sequences. They are typically attributed to small vessel 
      cerebrovascular disease in the context of aging. Among older adults, WMH are 
      associated with risk of cognitive decline and dementia, stroke, and various other 
      health outcomes. There has been increasing interest in incorporating quantitative 
      WMH measurement as outcomes in clinical trials, observational research, and 
      clinical settings. Here, we present a novel, fully automated, unsupervised 
      detection algorithm for WMH segmentation and quantification. The algorithm uses a 
      robust preprocessing pipeline, including brain extraction and a sample-specific 
      mask that incorporates spatial information for automatic false positive 
      reduction, and a half Gaussian mixture model (HGMM). The method was evaluated in 
      24 participants with varying degrees of WMH (4.9-78.6 cm(3)) from a 
      community-based study of aging and dementia with dice coefficient, sensitivity, 
      specificity, correlation, and bias relative to the ground truth manual 
      segmentation approach performed by two expert raters. Results were compared with 
      those derived from commonly used available WMH segmentation packages, including 
      SPM lesion probability algorithm (LPA), SPM lesion growing algorithm (LGA), and 
      Brain Intensity AbNormality Classification Algorithm (BIANCA). The HGMM algorithm 
      derived WMH values that had a dice score of 0.87, sensitivity of 0.89, and 
      specificity of 0.99 compared to ground truth. White matter hyperintensity volumes 
      derived with HGMM were strongly correlated with ground truth values (r = 0.97, 
      p = 3.9e-16), with no observable bias (-1.1 [-2.6, 0.44], p-value = 0.16). Our 
      novel algorithm uniquely uses a robust preprocessing pipeline and a half-Gaussian 
      mixture model to segment WMH with high agreement with ground truth for large 
      scale studies of brain aging.
CI  - Copyright © 2021 Elsevier Inc. All rights reserved.
FAU - Igwe, Kay C
AU  - Igwe KC
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA.
FAU - Lao, Patrick J
AU  - Lao PJ
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA; Department of Neurology, Vagelos College of Physicians and Surgeons, 
      Columbia University, 630 West 168th Street, New York, NY 10032, USA.
FAU - Vorburger, Robert S
AU  - Vorburger RS
AD  - Institute of Applied Simulation, School of Life Sciences and Facility Management, 
      Zurich University of Applied Sciences, Wädenswil 8820, Switzerland.
FAU - Banerjee, Arit
AU  - Banerjee A
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA.
FAU - Rivera, Andres
AU  - Rivera A
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA.
FAU - Chesebro, Anthony
AU  - Chesebro A
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA.
FAU - Laing, Krystal
AU  - Laing K
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA.
FAU - Manly, Jennifer J
AU  - Manly JJ
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA; Department of Neurology, Vagelos College of Physicians and Surgeons, 
      Columbia University, 630 West 168th Street, New York, NY 10032, USA.
FAU - Brickman, Adam M
AU  - Brickman AM
AD  - Taub Institute for Research on Alzheimer's Disease and the Aging Brain, Vagelos 
      College of Physicians and Surgeons, Columbia University, 630 West 168th Street, 
      New York, NY 10032, USA; Gertrude H. Sergievsky Center, Vagelos College of 
      Physicians and Surgeons, Columbia University, 630 West 168th Street, New York, NY 
      10032, USA; Department of Neurology, Vagelos College of Physicians and Surgeons, 
      Columbia University, 630 West 168th Street, New York, NY 10032, USA. Electronic 
      address: amb2139@columbia.edu.
LA  - eng
GR  - R01 AG034189/AG/NIA NIH HHS/United States
GR  - R56 AG034189/AG/NIA NIH HHS/United States
GR  - R01 AG054520/AG/NIA NIH HHS/United States
GR  - P01 AG007232/AG/NIA NIH HHS/United States
GR  - RF1 AG054023/AG/NIA NIH HHS/United States
GR  - P30 AG066462/AG/NIA NIH HHS/United States
GR  - R01 AG037212/AG/NIA NIH HHS/United States
GR  - R01 AG054070/AG/NIA NIH HHS/United States
GR  - R01 AG072474/AG/NIA NIH HHS/United States
GR  - K99 AG065506/AG/NIA NIH HHS/United States
GR  - K23 AG029949/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20211016
PL  - Netherlands
TA  - Magn Reson Imaging
JT  - Magnetic resonance imaging
JID - 8214883
SB  - IM
MH  - Aged
MH  - Brain/diagnostic imaging/pathology
MH  - Humans
MH  - *Leukoaraiosis
MH  - Magnetic Resonance Imaging/methods
MH  - *Stroke/pathology
MH  - *White Matter/diagnostic imaging/pathology
PMC - PMC8818099
MID - NIHMS1750723
OTO - NOTNLM
OT  - Automated segmentation
OT  - Half Gaussian mixture model
OT  - Mixture model
OT  - Small vessel cerebrovascular disease
OT  - White matter hyperintensity
EDAT- 2021/10/19 06:00
MHDA- 2022/03/19 06:00
PMCR- 2023/01/01
CRDT- 2021/10/18 20:12
PHST- 2021/06/12 00:00 [received]
PHST- 2021/08/20 00:00 [revised]
PHST- 2021/10/12 00:00 [accepted]
PHST- 2021/10/19 06:00 [pubmed]
PHST- 2022/03/19 06:00 [medline]
PHST- 2021/10/18 20:12 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - S0730-725X(21)00174-0 [pii]
AID - 10.1016/j.mri.2021.10.007 [doi]
PST - ppublish
SO  - Magn Reson Imaging. 2022 Jan;85:71-79. doi: 10.1016/j.mri.2021.10.007. Epub 2021 
      Oct 16.

PMID- 37190006
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240917
IS  - 2227-9067 (Print)
IS  - 2227-9067 (Electronic)
IS  - 2227-9067 (Linking)
VI  - 10
IP  - 4
DP  - 2023 Apr 21
TI  - May Artificial Intelligence Influence Future Pediatric Research?-The Case of 
      ChatGPT.
LID - 10.3390/children10040757 [doi]
LID - 757
AB  - BACKGROUND: In recent months, there has been growing interest in the potential of 
      artificial intelligence (AI) to revolutionize various aspects of medicine, 
      including research, education, and clinical practice. ChatGPT represents a 
      leading AI language model, with possible unpredictable effects on the quality of 
      future medical research, including clinical decision-making, medical education, 
      drug development, and better research outcomes. AIM AND METHODS: In this 
      interview with ChatGPT, we explore the potential impact of AI on future pediatric 
      research. Our discussion covers a range of topics, including the potential 
      positive effects of AI, such as improved clinical decision-making, enhanced 
      medical education, faster drug development, and better research outcomes. We also 
      examine potential negative effects, such as bias and fairness concerns, safety 
      and security issues, overreliance on technology, and ethical considerations. 
      CONCLUSIONS: While AI continues to advance, it is crucial to remain vigilant 
      about the possible risks and limitations of these technologies and to consider 
      the implications of these technologies and their use in the medical field. The 
      development of AI language models represents a significant advancement in the 
      field of artificial intelligence and has the potential to revolutionize daily 
      clinical practice in every branch of medicine, both surgical and clinical. 
      Ethical and social implications must also be considered to ensure that these 
      technologies are used in a responsible and beneficial manner.
FAU - Corsello, Antonio
AU  - Corsello A
AUID- ORCID: 0000-0003-4578-0066
AD  - Department of Clinical Sciences and Community Health, University of Milan, 20122 
      Milan, Italy.
FAU - Santangelo, Andrea
AU  - Santangelo A
AUID- ORCID: 0000-0003-2668-6373
AD  - Department of Pediatrics, Santa Chiara Hospital, University of Pisa, 56126 Pisa, 
      Italy.
LA  - eng
PT  - Journal Article
DEP - 20230421
PL  - Switzerland
TA  - Children (Basel)
JT  - Children (Basel, Switzerland)
JID - 101648936
PMC - PMC10136583
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical decision-making
OT  - pediatric research
OT  - predictive modeling
COIS- The authors declare that they have no competing interest.
EDAT- 2023/05/16 06:42
MHDA- 2023/05/16 06:43
PMCR- 2023/04/21
CRDT- 2023/05/16 01:12
PHST- 2023/03/13 00:00 [received]
PHST- 2023/04/17 00:00 [revised]
PHST- 2023/04/19 00:00 [accepted]
PHST- 2023/05/16 06:43 [medline]
PHST- 2023/05/16 06:42 [pubmed]
PHST- 2023/05/16 01:12 [entrez]
PHST- 2023/04/21 00:00 [pmc-release]
AID - children10040757 [pii]
AID - children-10-00757 [pii]
AID - 10.3390/children10040757 [doi]
PST - epublish
SO  - Children (Basel). 2023 Apr 21;10(4):757. doi: 10.3390/children10040757.

PMID- 37301435
OWN - NLM
STAT- MEDLINE
DCOM- 20230911
LR  - 20231102
IS  - 2213-2201 (Electronic)
VI  - 11
IP  - 9
DP  - 2023 Sep
TI  - Artificial Intelligence Chatbots in Allergy and Immunology Practice: Where Have 
      We Been and Where Are We Going?
PG  - 2697-2700
LID - S2213-2198(23)00641-4 [pii]
LID - 10.1016/j.jaip.2023.05.042 [doi]
AB  - Artificial intelligence (AI) is rapidly becoming a valuable tool in healthcare, 
      providing clinicians with a new AI lens perspective for patient care, diagnosis, 
      and treatment. This article explores the potential applications, benefits, and 
      challenges of AI chatbots in clinical settings, with a particular emphasis on 
      ChatGPT 4.0 (OpenAI - Chat generative pretrained transformer 4.0), especially in 
      the field of allergy and immunology. AI chatbots have shown considerable promise 
      in various medical domains, including radiology and dermatology, by improving 
      patient engagement, diagnostic accuracy, and personalized treatment plans. 
      ChatGPT 4.0, developed by OpenAI, is good at understanding and replying to 
      prompts in a way that makes sense. However, it is critical to address the 
      potential biases, data privacy issues, ethical considerations, and the need for 
      verification of AI-generated findings. When used responsibly, AI chatbots can 
      significantly enhance clinical practice in allergy and immunology. However, there 
      are still challenges in using this technology that require ongoing research and 
      collaboration between AI developers and medical specialists. To this end, the 
      ChatGPT 4.0 platform has the potential to enhance patient engagement, improve 
      diagnostic accuracy, and provide personalized treatment plans in allergy and 
      immunology practice. However, limitations and risks must be addressed to ensure 
      their safe and effective use in clinical practice.
CI  - Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Goktas, Polat
AU  - Goktas P
AD  - UCD School of Computer Science, University College Dublin, Belfield, Dublin, 
      Ireland; CeADAR: Ireland's Centre for Applied Artificial Intelligence, 
      Clonskeagh, Dublin, Ireland. Electronic address: polat.goktas@ucd.ie.
FAU - Karakaya, Gul
AU  - Karakaya G
AD  - School of Medicine, Department of Chest Diseases, Division of Allergy and 
      Clinical Immunology, Hacettepe University, Ankara, Turkey.
FAU - Kalyoncu, Ali Fuat
AU  - Kalyoncu AF
AD  - School of Medicine, Department of Chest Diseases, Division of Allergy and 
      Clinical Immunology, Hacettepe University, Ankara, Turkey.
FAU - Damadoglu, Ebru
AU  - Damadoglu E
AD  - School of Medicine, Department of Chest Diseases, Division of Allergy and 
      Clinical Immunology, Hacettepe University, Ankara, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20230608
PL  - United States
TA  - J Allergy Clin Immunol Pract
JT  - The journal of allergy and clinical immunology. In practice
JID - 101597220
SB  - IM
CIN - J Allergy Clin Immunol Pract. 2023 Oct;11(10):3285-3286. doi: 
      10.1016/j.jaip.2023.07.043. PMID: 37805232
CIN - J Allergy Clin Immunol Pract. 2023 Oct;11(10):3286-3287. doi: 
      10.1016/j.jaip.2023.07.044. PMID: 37805233
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Hypersensitivity/diagnosis/therapy
MH  - Patient Participation
MH  - Technology
OTO - NOTNLM
OT  - AI chatbots
OT  - Allergy
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Ethical considerations
OT  - Generative pretrained transformer
OT  - Healthcare
OT  - Natural language processing
EDAT- 2023/06/11 01:06
MHDA- 2023/09/11 06:43
CRDT- 2023/06/10 19:28
PHST- 2023/04/30 00:00 [received]
PHST- 2023/05/22 00:00 [revised]
PHST- 2023/05/25 00:00 [accepted]
PHST- 2023/09/11 06:43 [medline]
PHST- 2023/06/11 01:06 [pubmed]
PHST- 2023/06/10 19:28 [entrez]
AID - S2213-2198(23)00641-4 [pii]
AID - 10.1016/j.jaip.2023.05.042 [doi]
PST - ppublish
SO  - J Allergy Clin Immunol Pract. 2023 Sep;11(9):2697-2700. doi: 
      10.1016/j.jaip.2023.05.042. Epub 2023 Jun 8.

PMID- 35945670
OWN - NLM
STAT- MEDLINE
DCOM- 20230301
LR  - 20230321
IS  - 2380-0194 (Electronic)
IS  - 2380-0186 (Linking)
VI  - 36
IP  - 2
DP  - 2023 Mar 1
TI  - How are Patients Describing You Online? A Natural Language Processing Driven 
      Sentiment Analysis of Online Reviews on CSRS Surgeons.
PG  - E107-E113
LID - 10.1097/BSD.0000000000001372 [doi]
AB  - STUDY DESIGN: A quantitative analysis of written, online reviews of Cervical 
      Spine Research Society (CSRS) surgeons. OBJECTIVE: This study quantitatively 
      analyzes the written reviews of members of the CSRS to report biases associated 
      with demographic factors and frequently used words in reviews to help aid 
      physician practices. SUMMARY OF BACKGROUND DATA: Physician review websites have 
      influence on a patient's selection of a provider, but written reviews are 
      subjective. Sentiment analysis of writing through artificial intelligence can 
      quantify surgeon reviews to provide actionable feedback. METHODS: Online written 
      and star-rating reviews of CSRS surgeons were obtained from healthgrades.com. A 
      sentiment analysis package was used to obtain compound scores of each physician's 
      reviews. The relationship between demographic variables and average sentiment 
      score of written reviews were evaluated through t -tests. Positive and negative 
      word and bigram frequency analysis was performed to indicate trends in the 
      reviews' language. RESULTS: In all, 2239 CSRS surgeon's reviews were analyzed. 
      Analysis showed a positive correlation between the sentiment scores and overall 
      average star-rated reviews ( r2 =0.60, P <0.01). There was no difference in 
      review sentiment by provider sex. However, the age of surgeons showed a 
      significant difference as those <55 had more positive reviews (mean=+0.50) than 
      surgeons >=55 (mean=+0.37) ( P <0.01). The most positive reviews focused both on 
      pain and behavioral factors, whereas the most negative focused mainly on pain. 
      Behavioral attributes increased the odds of receiving positive reviews while pain 
      decreased them. CONCLUSION: The top-rated surgeons were described as considerate 
      providers and effective at managing pain in their most frequently used words and 
      bigrams. However, the worst-rated ones were mainly described as unable to relieve 
      pain. Through quantitative analysis of physician reviews, pain is a clear factor 
      contributing to both positive and negative reviews of surgeons, reinforcing the 
      need for proper pain expectation management. LEVEL OF EVIDENCE: Level 
      4-retrospective case-control study.
CI  - Copyright © 2022 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Tang, Justin
AU  - Tang J
AD  - Department of Orthopedics, Icahn School of Medicine at Mount Sinai, New York, NY.
FAU - Arvind, Varun
AU  - Arvind V
FAU - White, Christopher A
AU  - White CA
FAU - Dominy, Calista
AU  - Dominy C
FAU - Cho, Samuel
AU  - Cho S
FAU - Kim, Jun S
AU  - Kim JS
AUID- ORCID: 0000-0002-6114-2673
LA  - eng
PT  - Journal Article
DEP - 20220810
PL  - United States
TA  - Clin Spine Surg
JT  - Clinical spine surgery
JID - 101675083
SB  - IM
MH  - Humans
MH  - Retrospective Studies
MH  - *Natural Language Processing
MH  - Sentiment Analysis
MH  - Case-Control Studies
MH  - Artificial Intelligence
MH  - Patient Satisfaction
MH  - *Surgeons
MH  - Pain
MH  - Cervical Vertebrae
MH  - Internet
COIS- The authors declare no conflict of interest.
EDAT- 2022/08/11 06:00
MHDA- 2023/03/03 06:00
CRDT- 2022/08/10 00:02
PHST- 2021/07/27 00:00 [received]
PHST- 2022/06/29 00:00 [accepted]
PHST- 2022/08/11 06:00 [pubmed]
PHST- 2023/03/03 06:00 [medline]
PHST- 2022/08/10 00:02 [entrez]
AID - 01933606-202303000-00014 [pii]
AID - 10.1097/BSD.0000000000001372 [doi]
PST - ppublish
SO  - Clin Spine Surg. 2023 Mar 1;36(2):E107-E113. doi: 10.1097/BSD.0000000000001372. 
      Epub 2022 Aug 10.

PMID- 39616097
OWN - NLM
STAT- Publisher
LR  - 20241130
IS  - 1878-4046 (Electronic)
IS  - 1076-6332 (Linking)
DP  - 2024 Nov 29
TI  - Impact of ChatGPT and Large Language Models on Radiology Education: Association 
      of Academic Radiology-Radiology Research Alliance Task Force White Paper.
LID - S1076-6332(24)00784-0 [pii]
LID - 10.1016/j.acra.2024.10.023 [doi]
AB  - Generative artificial intelligence, including large language models (LLMs), holds 
      immense potential to enhance healthcare, medical education, and health research. 
      Recognizing the transformative opportunities and potential risks afforded by 
      LLMs, the Association of Academic Radiology-Radiology Research Alliance convened 
      a task force to explore the promise and pitfalls of using LLMs such as ChatGPT in 
      radiology. This white paper explores the impact of LLMs on radiology education, 
      highlighting their potential to enrich curriculum development, teaching and 
      learning, and learner assessment. Despite these advantages, the implementation of 
      LLMs presents challenges, including limits on accuracy and transparency, the risk 
      of misinformation, data privacy issues, and potential biases, which must be 
      carefully considered. We provide recommendations for the successful integration 
      of LLMs and LLM-based educational tools into radiology education programs, 
      emphasizing assessment of the technological readiness of LLMs for specific use 
      cases, structured planning, regular evaluation, faculty development, increased 
      training opportunities, academic-industry collaboration, and research on best 
      practices for employing LLMs in education.
CI  - Copyright © 2024 The Association of University Radiologists. Published by 
      Elsevier Inc. All rights reserved.
FAU - Ballard, David H
AU  - Ballard DH
AD  - Mallinckrodt Institute of Radiology, Washington University School of Medicine, 
      St. Louis, Missouri, USA.
FAU - Antigua-Made, Alexander
AU  - Antigua-Made A
AD  - Anne Burnett School of Medicine, Texas Christian University, Fort Worth, Texas, 
      USA.
FAU - Barre, Emily
AU  - Barre E
AD  - Duke University School of Medicine, Durham, North Carolina, USA.
FAU - Edney, Elizabeth
AU  - Edney E
AD  - Department of Radiology, University of Nebraska Medical Center, Omaha, Nebraska, 
      USA.
FAU - Gordon, Emile B
AU  - Gordon EB
AD  - Department of Radiology, University of California San Diego, San Diego, 
      California, USA.
FAU - Kelahan, Linda
AU  - Kelahan L
AD  - Department of Radiology, Northwestern University Feinberg School of Medicine, 
      Chicago, Illinois, USA.
FAU - Lodhi, Taha
AU  - Lodhi T
AD  - Brody School of Medicine at East Carolina University, Greenville, North Carolina, 
      USA.
FAU - Martin, Jonathan G
AU  - Martin JG
AD  - Duke University School of Medicine, Durham, North Carolina, USA.
FAU - Ozkan, Melis
AU  - Ozkan M
AD  - University of Michigan Medical School, Ann Arbor, Michigan, USA.
FAU - Serdynski, Kevin
AU  - Serdynski K
AD  - Inspira Medical Center Vineland, Vineland, New Jersey, USA.
FAU - Spieler, Bradley
AU  - Spieler B
AD  - Department of Radiology, Louisiana State University School of Medicine, 
      University Medical Center, New Orleans, Louisiana, USA.
FAU - Zhu, Daphne
AU  - Zhu D
AD  - Duke University School of Medicine, Durham, North Carolina, USA.
FAU - Adams, Scott J
AU  - Adams SJ
AD  - Department of Medical Imaging, Royal University Hospital, College of Medicine, 
      University of Saskatchewan, Saskatoon, Saskatchewan, Canada. Electronic address: 
      scott.adams@usask.ca.
LA  - eng
PT  - Journal Article
DEP - 20241129
PL  - United States
TA  - Acad Radiol
JT  - Academic radiology
JID - 9440159
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Assessment
OT  - Curriculum
OT  - Large language models
OT  - Teaching and learning
COIS- Declaration of Competing Interest No conflicts of interest to disclose.
EDAT- 2024/12/01 15:22
MHDA- 2024/12/01 15:22
CRDT- 2024/11/30 21:59
PHST- 2024/06/22 00:00 [received]
PHST- 2024/10/06 00:00 [revised]
PHST- 2024/10/17 00:00 [accepted]
PHST- 2024/12/01 15:22 [medline]
PHST- 2024/12/01 15:22 [pubmed]
PHST- 2024/11/30 21:59 [entrez]
AID - S1076-6332(24)00784-0 [pii]
AID - 10.1016/j.acra.2024.10.023 [doi]
PST - aheadofprint
SO  - Acad Radiol. 2024 Nov 29:S1076-6332(24)00784-0. doi: 10.1016/j.acra.2024.10.023.

PMID- 34037527
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20210629
IS  - 2291-9694 (Print)
IS  - 2291-9694 (Electronic)
IS  - 2291-9694 (Linking)
VI  - 9
IP  - 5
DP  - 2021 May 26
TI  - Predicting Semantic Similarity Between Clinical Sentence Pairs Using Transformer 
      Models: Evaluation and Representational Analysis.
PG  - e23099
LID - 10.2196/23099 [doi]
LID - e23099
AB  - BACKGROUND: Semantic textual similarity (STS) is a natural language processing 
      (NLP) task that involves assigning a similarity score to 2 snippets of text based 
      on their meaning. This task is particularly difficult in the domain of clinical 
      text, which often features specialized language and the frequent use of 
      abbreviations. OBJECTIVE: We created an NLP system to predict similarity scores 
      for sentence pairs as part of the Clinical Semantic Textual Similarity track in 
      the 2019 n2c2/OHNLP Shared Task on Challenges in Natural Language Processing for 
      Clinical Data. We subsequently sought to analyze the intermediary token vectors 
      extracted from our models while processing a pair of clinical sentences to 
      identify where and how representations of semantic similarity are built in 
      transformer models. METHODS: Given a clinical sentence pair, we take the average 
      predicted similarity score across several independently fine-tuned transformers. 
      In our model analysis we investigated the relationship between the final model's 
      loss and surface features of the sentence pairs and assessed the decodability and 
      representational similarity of the token vectors generated by each model. 
      RESULTS: Our model achieved a correlation of 0.87 with the ground-truth 
      similarity score, reaching 6th place out of 33 teams (with a first-place score of 
      0.90). In detailed qualitative and quantitative analyses of the model's loss, we 
      identified the system's failure to correctly model semantic similarity when both 
      sentence pairs contain details of medical prescriptions, as well as its general 
      tendency to overpredict semantic similarity given significant token overlap. The 
      token vector analysis revealed divergent representational strategies for 
      predicting textual similarity between bidirectional encoder representations from 
      transformers (BERT)-style models and XLNet. We also found that a large amount 
      information relevant to predicting STS can be captured using a combination of a 
      classification token and the cosine distance between sentence-pair 
      representations in the first layer of a transformer model that did not produce 
      the best predictions on the test set. CONCLUSIONS: We designed and trained a 
      system that uses state-of-the-art NLP models to achieve very competitive results 
      on a new clinical STS data set. As our approach uses no hand-crafted rules, it 
      serves as a strong deep learning baseline for this task. Our key contribution is 
      a detailed analysis of the model's outputs and an investigation of the heuristic 
      biases learned by transformer models. We suggest future improvements based on 
      these findings. In our representational analysis we explore how different 
      transformer models converge or diverge in their representation of semantic 
      signals as the tokens of the sentences are augmented by successive layers. This 
      analysis sheds light on how these "black box" models integrate semantic 
      similarity information in intermediate layers, and points to new research 
      directions in model distillation and sentence embedding extraction for 
      applications in clinical NLP.
CI  - ©Mark Ormerod, Jesús Martínez del Rincón, Barry Devereux. Originally published in 
      JMIR Medical Informatics (https://medinform.jmir.org), 26.05.2021.
FAU - Ormerod, Mark
AU  - Ormerod M
AUID- ORCID: 0000-0003-3454-2863
AD  - Institute of Electronics, Communications & Information Technology, School of 
      Electronics, Electrical Engineering and Computer Science, Queen's University 
      Belfast, Belfast, United Kingdom.
FAU - Martínez Del Rincón, Jesús
AU  - Martínez Del Rincón J
AUID- ORCID: 0000-0002-9574-4138
AD  - Institute of Electronics, Communications & Information Technology, School of 
      Electronics, Electrical Engineering and Computer Science, Queen's University 
      Belfast, Belfast, United Kingdom.
FAU - Devereux, Barry
AU  - Devereux B
AUID- ORCID: 0000-0003-2128-8632
AD  - Institute of Electronics, Communications & Information Technology, School of 
      Electronics, Electrical Engineering and Computer Science, Queen's University 
      Belfast, Belfast, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20210526
PL  - Canada
TA  - JMIR Med Inform
JT  - JMIR medical informatics
JID - 101645109
PMC - PMC8190645
OTO - NOTNLM
OT  - biomedical NLP
OT  - clinical text
OT  - natural language processing
OT  - representation learning
OT  - transformer models
COIS- Conflicts of Interest: None declared.
EDAT- 2021/05/27 06:00
MHDA- 2021/05/27 06:01
PMCR- 2021/05/26
CRDT- 2021/05/26 12:19
PHST- 2020/07/31 00:00 [received]
PHST- 2021/01/23 00:00 [accepted]
PHST- 2021/01/07 00:00 [revised]
PHST- 2021/05/26 12:19 [entrez]
PHST- 2021/05/27 06:00 [pubmed]
PHST- 2021/05/27 06:01 [medline]
PHST- 2021/05/26 00:00 [pmc-release]
AID - v9i5e23099 [pii]
AID - 10.2196/23099 [doi]
PST - epublish
SO  - JMIR Med Inform. 2021 May 26;9(5):e23099. doi: 10.2196/23099.

PMID- 39579604
OWN - NLM
STAT- MEDLINE
DCOM- 20250322
LR  - 20250322
IS  - 1532-3374 (Electronic)
IS  - 0959-289X (Linking)
VI  - 61
DP  - 2025 Feb
TI  - Accuracy of Spanish and English-generated ChatGPT responses to commonly asked 
      patient questions about labor epidurals: a survey-based study among bilingual 
      obstetric anesthesia experts.
PG  - 104290
LID - S0959-289X(24)00302-9 [pii]
LID - 10.1016/j.ijoa.2024.104290 [doi]
AB  - BACKGROUND: Large language models (LLMs), of which ChatGPT is the most well 
      known, are now available to patients to seek medical advice in various languages. 
      However, the accuracy of the information utilized to train these models remains 
      unknown. METHODS: Ten commonly asked questions regarding labor epidurals were 
      translated from English to Spanish, and all 20 questions were entered into 
      ChatGPT version 3.5. The answers were transcribed. A survey was then sent to 10 
      bilingual fellowship-trained obstetric anesthesiologists to assess the accuracy 
      of these answers utilizing a 5-point Likert scale. RESULTS: Overall, the accuracy 
      scores for the ChatGPT-generated answers in Spanish were lower than for the 
      English answers with a median score of 34 (IQR 33-36.5) versus 40.5 (IQR 
      39-44.3), respectively (P value 0.02). Answers to two questions were scored 
      significantly lower: "Do epidurals prolong labor?" (2 (IQR 2-2.5) versus 4 (IQR 
      4-4.5), P value 0.03) and "Do epidurals increase the risk of needing cesarean 
      delivery?" (3(IQR 2-4) versus 4 (IQR 4-5); P value 0.03). There was a strong 
      agreement that answers to the question "Do epidurals cause autism" were accurate 
      in both Spanish and English. CONCLUSION: ChatGPT-generated answers in Spanish to 
      ten questions about labor epidurals scored lower for accuracythananswers 
      generated in English, particularly regarding the effect of labor epidurals on 
      labor course and mode of delivery. This disparity in ChatGPT-generated 
      information may extend already-known health inequities among non-English-speaking 
      patients and perpetuate misinformation.
CI  - Copyright © 2024 Elsevier Ltd. All rights reserved.
FAU - Gonzalez Fiol, Antonio
AU  - Gonzalez Fiol A
AD  - Department of Anesthesiology, Yale School of Medicine, New Haven, CT, United 
      States. Electronic address: antonio.gonzalez-fiol@yale.edu.
FAU - Mootz, Allison A
AU  - Mootz AA
AD  - Department of Anesthesiology, University of Texas Southwestern Medical Center & 
      Parkland Memorial Hospital, Dallas, TX, United States. Electronic address: 
      allison.mootz@utsouthwestern.edu.
FAU - He, Zili
AU  - He Z
AD  - Yale School of Public Health, United States. Electronic address: 
      hugo.he@yale.edu.
FAU - Delgado, Carlos
AU  - Delgado C
AD  - Department of Anesthesiology and Pain Medicine, University of Washington, 
      Seattle, WA, United States. Electronic address: delgadou@uw.edu.
FAU - Ortiz, Vilma
AU  - Ortiz V
AD  - Harvard Medical School, United States. Electronic address: 
      vortiz@mgh.harvard.edu.
FAU - Reale, Sharon C
AU  - Reale SC
AD  - Department of Anesthesiology, Perioperative and Pain Medicine, Harvard Medical 
      School, Brigham and Women's Hospital, Boston, MA, United States. Electronic 
      address: screale@bwh.harvard.edu.
LA  - eng
PT  - Journal Article
DEP - 20241106
PL  - Netherlands
TA  - Int J Obstet Anesth
JT  - International journal of obstetric anesthesia
JID - 9200430
SB  - IM
MH  - Humans
MH  - Female
MH  - Pregnancy
MH  - Surveys and Questionnaires
MH  - *Anesthesia, Obstetrical/methods
MH  - Multilingualism
MH  - Adult
MH  - Language
MH  - Anesthesiologists
MH  - Labor, Obstetric
MH  - Analgesia, Epidural/methods
OTO - NOTNLM
OT  - ChatGPT
OT  - English
OT  - Healthcare disparities
OT  - Labor epidurals
OT  - Language
OT  - Misinformation
OT  - Spanish
COIS- Declaration of competing interest 1) The work described below has not been 
      published previously. This manuscript is not under consideration for publication 
      elsewhere. 2) Authors will take public responsibility for the contents, and they 
      have contributed substantially to the drafting, and have approved the final 
      version. 3) This manuscript reflects an honest and transparent report of the data 
      obtained. No important aspects of the study have been omitted. This study was 
      departmentally funded without any outside funding or grant.
EDAT- 2024/11/24 00:44
MHDA- 2025/03/23 16:51
CRDT- 2024/11/23 18:07
PHST- 2024/10/12 00:00 [received]
PHST- 2024/10/24 00:00 [revised]
PHST- 2024/10/25 00:00 [accepted]
PHST- 2025/03/23 16:51 [medline]
PHST- 2024/11/24 00:44 [pubmed]
PHST- 2024/11/23 18:07 [entrez]
AID - S0959-289X(24)00302-9 [pii]
AID - 10.1016/j.ijoa.2024.104290 [doi]
PST - ppublish
SO  - Int J Obstet Anesth. 2025 Feb;61:104290. doi: 10.1016/j.ijoa.2024.104290. Epub 
      2024 Nov 6.

PMID- 38866172
OWN - NLM
STAT- MEDLINE
DCOM- 20241113
LR  - 20250301
IS  - 1873-2402 (Electronic)
IS  - 0006-3223 (Linking)
VI  - 96
IP  - 12
DP  - 2024 Dec 15
TI  - Dimensional Measures of Psychopathology in Children and Adolescents Using Large 
      Language Models.
PG  - 940-947
LID - S0006-3223(24)01299-X [pii]
LID - 10.1016/j.biopsych.2024.05.008 [doi]
AB  - BACKGROUND: To enable greater use of National Institute of Mental Health Research 
      Domain Criteria (RDoC) in real-world settings, we applied large language models 
      (LLMs) to estimate dimensional psychopathology from narrative clinical notes. 
      METHODS: We conducted a cohort study using health records from individuals age 
      ≤18 years evaluated in the psychiatric emergency department of a large academic 
      medical center between November 2008 and March 2015. Outcomes were hospital 
      admission and length of emergency department stay. RDoC domains were estimated 
      using a Health Insurance Portability and Accountability Act-compliant LLM 
      (gpt-4-1106-preview) and compared with a previously validated token-based 
      approach. RESULTS: The cohort included 3059 individuals (median age 16 years 
      [interquartile range, 13-18]; 1580 [52%] female, 1479 [48%] male; 105 [3.4%] 
      identified as Asian, 329 [11%] as Black, 288 [9.4%] as Hispanic, 474 [15%] as 
      other race, and 1863 [61%] as White), of whom 1695 (55%) were admitted. 
      Correlation between LLM-extracted RDoC scores and the token-based scores ranged 
      from small to medium as assessed by Kendall's tau (0.14-0.22). In logistic 
      regression models adjusting for sociodemographic and clinical features, admission 
      likelihood was associated with greater scores on all domains, with the exception 
      of the sensorimotor domain, which was inversely associated (p < .001 for all 
      adjusted associations). Tests for bias suggested modest but statistically 
      significant differences in positive valence scores by race (p < .05 for Asian, 
      Black, and Hispanic individuals). CONCLUSIONS: An LLM extracted estimates of 6 
      RDoC domains in an explainable manner, which were associated with clinical 
      outcomes. This approach can contribute to a new generation of prediction models 
      or biological investigations based on dimensional psychopathology.
CI  - Copyright © 2024. Published by Elsevier Inc.
FAU - McCoy, Thomas H Jr
AU  - McCoy TH Jr
AD  - Center for Quantitative Health and Department of Psychiatry, Massachusetts 
      General Hospital, Boston, Massachusetts; Department of Psychiatry, Harvard 
      Medical School, Boston, Massachusetts.
FAU - Perlis, Roy H
AU  - Perlis RH
AD  - Center for Quantitative Health and Department of Psychiatry, Massachusetts 
      General Hospital, Boston, Massachusetts; Department of Psychiatry, Harvard 
      Medical School, Boston, Massachusetts. Electronic address: 
      rperlis@mgh.harvard.edu.
LA  - eng
GR  - U01 MH136059/MH/NIMH NIH HHS/United States
PT  - Journal Article
DEP - 20240610
PL  - United States
TA  - Biol Psychiatry
JT  - Biological psychiatry
JID - 0213264
SB  - IM
MH  - Humans
MH  - Male
MH  - Female
MH  - Adolescent
MH  - *Mental Disorders/diagnosis
MH  - Cohort Studies
MH  - Child
MH  - United States
MH  - Emergency Service, Hospital
MH  - Language
MH  - Psychopathology
MH  - Length of Stay/statistics & numerical data
MH  - National Institute of Mental Health (U.S.)
MH  - Hospitalization/statistics & numerical data
OTO - NOTNLM
OT  - Anxiety
OT  - Artificial intelligence
OT  - Deep learning
OT  - Depression
OT  - Machine learning
OT  - Research domain criteria
EDAT- 2024/06/13 00:42
MHDA- 2024/11/14 03:58
CRDT- 2024/06/12 19:25
PHST- 2024/01/10 00:00 [received]
PHST- 2024/04/04 00:00 [revised]
PHST- 2024/05/08 00:00 [accepted]
PHST- 2024/11/14 03:58 [medline]
PHST- 2024/06/13 00:42 [pubmed]
PHST- 2024/06/12 19:25 [entrez]
AID - S0006-3223(24)01299-X [pii]
AID - 10.1016/j.biopsych.2024.05.008 [doi]
PST - ppublish
SO  - Biol Psychiatry. 2024 Dec 15;96(12):940-947. doi: 10.1016/j.biopsych.2024.05.008. 
      Epub 2024 Jun 10.

PMID- 39638783
OWN - NLM
STAT- MEDLINE
DCOM- 20241205
LR  - 20250104
IS  - 2052-4463 (Electronic)
IS  - 2052-4463 (Linking)
VI  - 11
IP  - 1
DP  - 2024 Dec 5
TI  - Contextualized race and ethnicity annotations for clinical text from MIMIC-III.
PG  - 1332
LID - 10.1038/s41597-024-04183-2 [doi]
LID - 1332
AB  - Observational health research often relies on accurate and complete race and 
      ethnicity (RE) patient information, such as characterizing cohorts, assessing 
      quality/performance metrics of hospitals and health systems, and identifying 
      health disparities. While the electronic health record contains structured data 
      such as accessible patient-level RE data, it is often missing, inaccurate, or 
      lacking granular details. Natural language processing models can be trained to 
      identify RE in clinical text which can supplement missing RE data in clinical 
      data repositories. Here we describe the Contextualized Race and Ethnicity 
      Annotations for Clinical Text (C-REACT) Dataset, which comprises 12,000 patients 
      and 17,281 sentences from their clinical notes in the MIMIC-III dataset. Using 
      these sentences, two sets of reference standard annotations for RE data are made 
      available with annotation guidelines. The first set of annotations comprise 
      highly granular information related to RE, such as preferred language and country 
      of origin, while the second set contains RE labels annotated by physicians. This 
      dataset can support health systems' ability to use RE data to serve health equity 
      goals.
CI  - © 2024. The Author(s).
FAU - Bear Don't Walk, Oliver J 4th
AU  - Bear Don't Walk OJ 4th
AD  - University of Washington, Seattle, Washington, USA. obdw4@uw.edu.
FAU - Pichon, Adrienne
AU  - Pichon A
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Reyes Nieva, Harry
AU  - Reyes Nieva H
AUID- ORCID: 0000-0001-7774-2561
AD  - Columbia University Irving Medical Center, New York, New York, USA.
AD  - Harvard Medical School, Boston, Massachusetts, USA.
FAU - Sun, Tony
AU  - Sun T
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Li, Jaan
AU  - Li J
AD  - One Fact Foundation, Claymont, Delaware, USA.
AD  - University of Tartu, Tartu, Estonia.
FAU - Joseph, Josh
AU  - Joseph J
AD  - Harvard Medical School, Boston, Massachusetts, USA.
AD  - Brigham and Women's Hospital, Boston, Massachusetts, USA.
FAU - Kinberg, Sivan
AU  - Kinberg S
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Richter, Lauren R
AU  - Richter LR
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Crusco, Salvatore
AU  - Crusco S
AD  - Columbia University Irving Medical Center, New York, New York, USA.
AD  - NewYork-Presbyterian Hospital, New York, New York, USA.
FAU - Kulas, Kyle
AU  - Kulas K
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Ahmed, Shaan A
AU  - Ahmed SA
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Snyder, Daniel
AU  - Snyder D
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Rahbari, Ashkon
AU  - Rahbari A
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Ranard, Benjamin L
AU  - Ranard BL
AUID- ORCID: 0000-0002-9565-6939
AD  - Columbia University Irving Medical Center, New York, New York, USA.
AD  - NewYork-Presbyterian Hospital, New York, New York, USA.
FAU - Juneja, Pallavi
AU  - Juneja P
AD  - Columbia University Irving Medical Center, New York, New York, USA.
FAU - Demner-Fushman, Dina
AU  - Demner-Fushman D
AUID- ORCID: 0000-0002-4361-5799
AD  - US National Library of Medicine, Bethesda, Maryland, USA.
FAU - Elhadad, Noémie
AU  - Elhadad N
AD  - Columbia University Irving Medical Center, New York, New York, USA.
LA  - eng
GR  - T15 LM007079/LM/NLM NIH HHS/United States
GR  - R01 LM006910/LM/NLM NIH HHS/United States
GR  - T32HS026121/U.S. Department of Health & Human Services | Agency for Healthcare 
      Research and Quality (AHRQ)/
GR  - T32 HS026121/HS/AHRQ HHS/United States
GR  - T15LM007079/U.S. Department of Health & Human Services | NIH | U.S. National 
      Library of Medicine (NLM)/
PT  - Dataset
PT  - Journal Article
DEP - 20241205
PL  - England
TA  - Sci Data
JT  - Scientific data
JID - 101640192
SB  - IM
MH  - Humans
MH  - *Electronic Health Records
MH  - *Racial Groups
MH  - *Natural Language Processing
MH  - *Ethnicity
PMC - PMC11621419
COIS- Competing interests: The authors declare no competing interests.
EDAT- 2024/12/06 05:30
MHDA- 2024/12/06 05:31
PMCR- 2024/12/05
CRDT- 2024/12/05 23:15
PHST- 2023/01/03 00:00 [received]
PHST- 2024/11/28 00:00 [accepted]
PHST- 2024/12/06 05:31 [medline]
PHST- 2024/12/06 05:30 [pubmed]
PHST- 2024/12/05 23:15 [entrez]
PHST- 2024/12/05 00:00 [pmc-release]
AID - 10.1038/s41597-024-04183-2 [pii]
AID - 4183 [pii]
AID - 10.1038/s41597-024-04183-2 [doi]
PST - epublish
SO  - Sci Data. 2024 Dec 5;11(1):1332. doi: 10.1038/s41597-024-04183-2.

PMID- 38757006
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240518
IS  - 2976-5390 (Electronic)
IS  - 2976-5390 (Linking)
VI  - 2
IP  - 5
DP  - 2024 May
TI  - Use of artificial intelligence and the future of peer review.
PG  - qxae058
LID - 10.1093/haschl/qxae058 [doi]
LID - qxae058
AB  - Conducting high-quality peer review of scientific manuscripts has become 
      increasingly challenging. The substantial increase in the number of manuscripts, 
      lack of a sufficient number of peer-reviewers, and questions related to 
      effectiveness, fairness, and efficiency, require a different approach. 
      Large-language models, 1 form of artificial intelligence (AI), have emerged as a 
      new approach to help resolve many of the issues facing contemporary medicine and 
      science. We believe AI should be used to assist in the triaging of manuscripts 
      submitted for peer-review publication.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of Project 
      HOPE - The People-To-People Health Foundation, Inc.
FAU - Bauchner, Howard
AU  - Bauchner H
AD  - Boston University Chobanian & Avedisian School of Medicine, Visiting Scholars 
      Program, National University of Singapore, 02118, Singapore.
FAU - Rivara, Frederick P
AU  - Rivara FP
AD  - Department of Pediatrics, University of Washington, Seattle, WA 98195, United 
      States.
LA  - eng
PT  - Journal Article
DEP - 20240503
PL  - England
TA  - Health Aff Sch
JT  - Health affairs scholar
JID - 9918627882906676
PMC - PMC11095530
OTO - NOTNLM
OT  - AI
OT  - peer review
OT  - scientific communication
COIS- Please see ICMJE form(s) for author conflicts of interest. These have been 
      provided as supplementary materials. Howard Bauchner receives compensation from 
      the American Medical Association as the former Editor in Chief of JAMA and the 
      JAMA Network. Frederick Rivara receives compensation from the American Medical 
      Association in his role as Editor in Chief of JAMA Network Open.
EDAT- 2024/05/17 06:43
MHDA- 2024/05/17 06:44
PMCR- 2024/05/03
CRDT- 2024/05/17 03:58
PHST- 2024/03/07 00:00 [received]
PHST- 2024/03/26 00:00 [revised]
PHST- 2024/05/01 00:00 [accepted]
PHST- 2024/05/17 06:44 [medline]
PHST- 2024/05/17 06:43 [pubmed]
PHST- 2024/05/17 03:58 [entrez]
PHST- 2024/05/03 00:00 [pmc-release]
AID - qxae058 [pii]
AID - 10.1093/haschl/qxae058 [doi]
PST - epublish
SO  - Health Aff Sch. 2024 May 3;2(5):qxae058. doi: 10.1093/haschl/qxae058. eCollection 
      2024 May.

PMID- 38725085
OWN - NLM
STAT- MEDLINE
DCOM- 20240510
LR  - 20240820
IS  - 1749-799X (Electronic)
IS  - 1749-799X (Linking)
VI  - 19
IP  - 1
DP  - 2024 May 10
TI  - Preoperative prediction model for risk of readmission after total joint 
      replacement surgery: a random forest approach leveraging NLP and unfairness 
      mitigation for improved patient care and cost-effectiveness.
PG  - 287
LID - 10.1186/s13018-024-04774-0 [doi]
LID - 287
AB  - BACKGROUND: The Center for Medicare and Medicaid Services (CMS) imposes payment 
      penalties for readmissions following total joint replacement surgeries. This 
      study focuses on total hip, knee, and shoulder arthroplasty procedures as they 
      account for most joint replacement surgeries. Apart from being a burden to 
      healthcare systems, readmissions are also troublesome for patients. There are 
      several studies which only utilized structured data from Electronic Health 
      Records (EHR) without considering any gender and payor bias adjustments. METHODS: 
      For this study, dataset of 38,581 total knee, hip, and shoulder replacement 
      surgeries performed from 2015 to 2021 at Novant Health was gathered. This data 
      was used to train a random forest machine learning model to predict the combined 
      endpoint of emergency department (ED) visit or unplanned readmissions within 30 
      days of discharge or discharge to Skilled Nursing Facility (SNF) following the 
      surgery. 98 features of laboratory results, diagnoses, vitals, medications, and 
      utilization history were extracted. A natural language processing (NLP) model 
      finetuned from Clinical BERT was used to generate an NLP risk score feature for 
      each patient based on their clinical notes. To address societal biases, a feature 
      bias analysis was performed in conjunction with propensity score matching. A 
      threshold optimization algorithm from the Fairlearn toolkit was used to mitigate 
      gender and payor biases to promote fairness in predictions. RESULTS: The model 
      achieved an Area Under the Receiver Operating characteristic Curve (AUROC) of 
      0.738 (95% confidence interval, 0.724 to 0.754) and an Area Under the 
      Precision-Recall Curve (AUPRC) of 0.406 (95% confidence interval, 0.384 to 
      0.433). Considering an outcome prevalence of 16%, these metrics indicate the 
      model's ability to accurately discriminate between readmission and 
      non-readmission cases within the context of total arthroplasty surgeries while 
      adjusting patient scores in the model to mitigate bias based on patient gender 
      and payor. CONCLUSION: This work culminated in a model that identifies the most 
      predictive and protective features associated with the combined endpoint. This 
      model serves as a tool to empower healthcare providers to proactively intervene 
      based on these influential factors without introducing bias towards protected 
      patient classes, effectively mitigating the risk of negative outcomes and 
      ultimately improving quality of care regardless of socioeconomic factors.
CI  - © 2024. The Author(s).
FAU - Digumarthi, Varun
AU  - Digumarthi V
AD  - Novant Health Cognitive Computing, Novant Health, Inc, Winston-Salem, NC, USA. 
      vdigumarthi@novanthealth.org.
FAU - Amin, Tapan
AU  - Amin T
AD  - Novant Health Cognitive Computing, Novant Health, Inc, Winston-Salem, NC, USA.
FAU - Kanu, Samuel
AU  - Kanu S
AD  - Novant Health Cognitive Computing, Novant Health, Inc, Winston-Salem, NC, USA.
FAU - Mathew, Joshua
AU  - Mathew J
AD  - Novant Health Cognitive Computing, Novant Health, Inc, Winston-Salem, NC, USA.
FAU - Edwards, Bryan
AU  - Edwards B
AD  - Novant Health Presbyterian Medical Center, Novant Health, Inc, Charlotte, NC, 
      USA.
FAU - Peterson, Lisa A
AU  - Peterson LA
AD  - Novant Health Cognitive Computing, Novant Health, Inc, Winston-Salem, NC, USA.
FAU - Lundy, Matthew E
AU  - Lundy ME
AD  - Novant Health Cognitive Computing, Novant Health, Inc, Winston-Salem, NC, USA.
FAU - Hegarty, Karen E
AU  - Hegarty KE
AD  - Novant Health Cognitive Computing, Novant Health, Inc, Winston-Salem, NC, USA.
LA  - eng
PT  - Journal Article
DEP - 20240510
PL  - England
TA  - J Orthop Surg Res
JT  - Journal of orthopaedic surgery and research
JID - 101265112
SB  - IM
MH  - Humans
MH  - *Patient Readmission/economics/statistics & numerical data
MH  - Female
MH  - Male
MH  - *Machine Learning
MH  - Aged
MH  - *Cost-Benefit Analysis
MH  - Natural Language Processing
MH  - Middle Aged
MH  - Arthroplasty, Replacement, Knee/economics
MH  - Arthroplasty, Replacement, Hip/economics
MH  - Arthroplasty, Replacement/economics/adverse effects
MH  - Risk Assessment/methods
MH  - Preoperative Period
MH  - Aged, 80 and over
MH  - Quality Improvement
MH  - Random Forest
PMC - PMC11084055
OTO - NOTNLM
OT  - Classification
OT  - Fairlearn
OT  - Natural language processing
OT  - Orthopedic
OT  - Predictive model
COIS- The authors declare no competing interests.
EDAT- 2024/05/10 00:43
MHDA- 2024/05/10 06:42
PMCR- 2024/05/10
CRDT- 2024/05/09 23:51
PHST- 2024/02/21 00:00 [received]
PHST- 2024/05/02 00:00 [accepted]
PHST- 2024/05/10 06:42 [medline]
PHST- 2024/05/10 00:43 [pubmed]
PHST- 2024/05/09 23:51 [entrez]
PHST- 2024/05/10 00:00 [pmc-release]
AID - 10.1186/s13018-024-04774-0 [pii]
AID - 4774 [pii]
AID - 10.1186/s13018-024-04774-0 [doi]
PST - epublish
SO  - J Orthop Surg Res. 2024 May 10;19(1):287. doi: 10.1186/s13018-024-04774-0.

PMID- 39437384
OWN - NLM
STAT- MEDLINE
DCOM- 20241022
LR  - 20241108
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Oct 22
TI  - Gender Bias in AI's Perception of Cardiovascular Risk.
PG  - e54242
LID - 10.2196/54242 [doi]
LID - e54242
AB  - The study investigated gender bias in GPT-4's assessment of coronary artery 
      disease risk by presenting identical clinical vignettes of men and women with and 
      without psychiatric comorbidities. Results suggest that psychiatric conditions 
      may influence GPT-4's coronary artery disease risk assessment among men and 
      women.
CI  - ©Margaux Achtari, Adil Salihu, Olivier Muller, Emmanuel Abbé, Carole Clair, 
      Joëlle Schwarz, Stephane Fournier. Originally published in the Journal of Medical 
      Internet Research (https://www.jmir.org), 22.10.2024.
FAU - Achtari, Margaux
AU  - Achtari M
AUID- ORCID: 0009-0006-6615-9374
AD  - Health and Gender Unit, University Center for Primary Care and Public Health 
      (Unisanté), University of Lausanne, Lausanne, Switzerland.
FAU - Salihu, Adil
AU  - Salihu A
AUID- ORCID: 0000-0002-9659-0396
AD  - Department of Cardiology, Lausanne University Hospital and University of 
      Lausanne, Lausanne, Switzerland.
FAU - Muller, Olivier
AU  - Muller O
AUID- ORCID: 0000-0003-2441-5799
AD  - Department of Cardiology, Lausanne University Hospital and University of 
      Lausanne, Lausanne, Switzerland.
FAU - Abbé, Emmanuel
AU  - Abbé E
AUID- ORCID: 0000-0002-1831-656X
AD  - Institute of Mathematics and School of Computer and Communication Sciences, EPFL, 
      Lausanne, Switzerland.
FAU - Clair, Carole
AU  - Clair C
AUID- ORCID: 0000-0001-5281-0943
AD  - Health and Gender Unit, University Center for Primary Care and Public Health 
      (Unisanté), University of Lausanne, Lausanne, Switzerland.
FAU - Schwarz, Joëlle
AU  - Schwarz J
AUID- ORCID: 0000-0002-0992-3165
AD  - Health and Gender Unit, University Center for Primary Care and Public Health 
      (Unisanté), University of Lausanne, Lausanne, Switzerland.
FAU - Fournier, Stephane
AU  - Fournier S
AUID- ORCID: 0000-0002-9422-9521
AD  - Department of Cardiology, Lausanne University Hospital and University of 
      Lausanne, Lausanne, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20241022
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Female
MH  - Male
MH  - *Sexism/psychology
MH  - Cardiovascular Diseases/psychology
MH  - Middle Aged
MH  - Risk Assessment/methods
MH  - Artificial Intelligence
MH  - Adult
MH  - Heart Disease Risk Factors
MH  - Coronary Artery Disease/psychology
PMC - PMC11538872
OTO - NOTNLM
OT  - AI
OT  - CAD
OT  - artery
OT  - artificial intelligence
OT  - cardiovascular
OT  - chatbot: health care
OT  - coronary
OT  - coronary artery disease
OT  - gender
OT  - gender bias
OT  - gender equity
OT  - men: women
OT  - risk
COIS- Conflicts of Interest: OM has received honoraria and/or research grant from 
      Edwards Lifesciences and Abbott.
EDAT- 2024/10/22 18:22
MHDA- 2024/10/22 18:23
PMCR- 2024/10/22
CRDT- 2024/10/22 16:53
PHST- 2023/11/02 00:00 [received]
PHST- 2024/09/10 00:00 [accepted]
PHST- 2024/06/11 00:00 [revised]
PHST- 2024/10/22 18:23 [medline]
PHST- 2024/10/22 18:22 [pubmed]
PHST- 2024/10/22 16:53 [entrez]
PHST- 2024/10/22 00:00 [pmc-release]
AID - v26i1e54242 [pii]
AID - 10.2196/54242 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Oct 22;26:e54242. doi: 10.2196/54242.

PMID- 40000063
OWN - NLM
STAT- MEDLINE
DCOM- 20250225
LR  - 20250225
IS  - 2632-1009 (Electronic)
IS  - 2632-1009 (Linking)
VI  - 32
IP  - 1
DP  - 2025 Feb 24
TI  - Benchmarking open-source large language models on Portuguese Revalida 
      multiple-choice questions.
LID - e101195 [pii]
LID - 10.1136/bmjhci-2024-101195 [doi]
AB  - OBJECTIVE: The study aimed to evaluate the top large language models (LLMs) in 
      validated medical knowledge tests in Portuguese. METHODS: This study compared 31 
      LLMs in the context of solving the national Brazilian medical examination test. 
      The research compared the performance of 23 open-source and 8 proprietary models 
      across 399 multiple-choice questions. RESULTS: Among the smaller models, Llama 3 
      8B exhibited the highest success rate, achieving 53.9%, while the medium-sized 
      model Mixtral 8×7B attained a success rate of 63.7%. Conversely, larger models 
      like Llama 3 70B achieved a success rate of 77.5%. Among the proprietary models, 
      GPT-4o and Claude Opus demonstrated superior accuracy, scoring 86.8% and 83.8%, 
      respectively. CONCLUSIONS: 10 out of the 31 LLMs attained better than human level 
      of performance in the Revalida benchmark, with 9 failing to provide coherent 
      answers to the task. Larger models exhibited superior performance overall. 
      However, certain medium-sized LLMs surpassed the performance of some of the 
      larger LLMs.
CI  - © Author(s) (or their employer(s)) 2025. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ Group.
FAU - Bruneti Severino, João Victor
AU  - Bruneti Severino JV
AUID- ORCID: 0000-0002-8649-6494
AD  - Federal University of Parana, Curitiba, Brazil.
AD  - Pontifical Catholic University of Parana, Curitiba, Brazil.
FAU - Basei de Paula, Pedro Angelo
AU  - Basei de Paula PA
AD  - Federal University of Parana, Curitiba, Brazil.
FAU - Berger, Matheus Nespolo
AU  - Berger MN
AD  - Federal University of Parana, Curitiba, Brazil.
FAU - Loures, Filipe Silveira
AU  - Loures FS
AD  - Voa Health, Belo Horizonte, Brazil.
FAU - Todeschini, Solano Amadori
AU  - Todeschini SA
AD  - Voa Health, Belo Horizonte, Brazil.
FAU - Roeder, Eduardo Augusto
AU  - Roeder EA
AD  - Federal University of Parana, Curitiba, Brazil.
AD  - Voa Health, Belo Horizonte, Brazil.
FAU - Veiga, Maria Han
AU  - Veiga MH
AD  - Mathematics, Ohio State University, Columbus, Ohio, USA.
FAU - Guedes, Murilo
AU  - Guedes M
AD  - Pontifical Catholic University of Parana, Curitiba, Brazil.
FAU - Marques, Gustavo Lenci
AU  - Marques GL
AD  - Federal University of Parana, Curitiba, Brazil gustavomarques@ufpr.br.
AD  - Pontifical Catholic University of Parana, Curitiba, Brazil.
AD  - Voa Health, Belo Horizonte, Brazil.
LA  - eng
PT  - Journal Article
DEP - 20250224
PL  - England
TA  - BMJ Health Care Inform
JT  - BMJ health & care informatics
JID - 101745500
SB  - IM
MH  - *Benchmarking
MH  - Humans
MH  - Brazil
MH  - Language
MH  - Educational Measurement
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Health Equity
OT  - Machine Learning
OT  - Medical Informatics Applications
OT  - Universal Health Care
COIS- Competing interests: None declared.
EDAT- 2025/02/26 00:20
MHDA- 2025/02/26 00:21
CRDT- 2025/02/25 20:43
PHST- 2024/07/09 00:00 [received]
PHST- 2025/02/12 00:00 [accepted]
PHST- 2025/02/26 00:21 [medline]
PHST- 2025/02/26 00:20 [pubmed]
PHST- 2025/02/25 20:43 [entrez]
AID - bmjhci-2024-101195 [pii]
AID - 10.1136/bmjhci-2024-101195 [doi]
PST - epublish
SO  - BMJ Health Care Inform. 2025 Feb 24;32(1):e101195. doi: 
      10.1136/bmjhci-2024-101195.

PMID- 39980724
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250222
IS  - 2296-858X (Print)
IS  - 2296-858X (Electronic)
IS  - 2296-858X (Linking)
VI  - 11
DP  - 2024
TI  - A guide to prompt design: foundations and applications for healthcare 
      simulationists.
PG  - 1504532
LID - 10.3389/fmed.2024.1504532 [doi]
LID - 1504532
AB  - Large Language Models (LLMs) like ChatGPT, Gemini, and Claude gain traction in 
      healthcare simulation; this paper offers simulationists a practical guide to 
      effective prompt design. Grounded in a structured literature review and iterative 
      prompt testing, this paper proposes best practices for developing calibrated 
      prompts, explores various prompt types and techniques with use cases, and 
      addresses the challenges, including ethical considerations for using LLMs in 
      healthcare simulation. This guide helps bridge the knowledge gap for 
      simulationists on LLM use in simulation-based education, offering tailored 
      guidance on prompt design. Examples were created through iterative testing to 
      ensure alignment with simulation objectives, covering use cases such as clinical 
      scenario development, OSCE station creation, simulated person scripting, and 
      debriefing facilitation. These use cases provide easy-to-apply methods to enhance 
      realism, engagement, and educational alignment in simulations. Key challenges 
      associated with LLM integration, including bias, privacy concerns, 
      hallucinations, lack of transparency, and the need for robust oversight and 
      evaluation, are discussed alongside ethical considerations unique to healthcare 
      education. Recommendations are provided to help simulationists craft prompts that 
      align with educational objectives while mitigating these challenges. By offering 
      these insights, this paper contributes valuable, timely knowledge for 
      simulationists seeking to leverage generative AI's capabilities in healthcare 
      education responsibly.
CI  - Copyright © 2025 Maaz, Palaganas, Palaganas and Bajwa.
FAU - Maaz, Sara
AU  - Maaz S
AD  - Department of Clinical Skills, College of Medicine, Alfaisal University, Riyadh, 
      Saudi Arabia.
AD  - Department of Health Professions Education, MGH Institute of Health Professions, 
      Boston, MA, United States.
FAU - Palaganas, Janice C
AU  - Palaganas JC
AD  - Department of Clinical Skills, College of Medicine, Alfaisal University, Riyadh, 
      Saudi Arabia.
FAU - Palaganas, Gerry
AU  - Palaganas G
AD  - Director of Technology, AAXIS Group Corporation, Los Angeles, CA, United States.
FAU - Bajwa, Maria
AU  - Bajwa M
AD  - Department of Clinical Skills, College of Medicine, Alfaisal University, Riyadh, 
      Saudi Arabia.
LA  - eng
PT  - Journal Article
DEP - 20250130
PL  - Switzerland
TA  - Front Med (Lausanne)
JT  - Frontiers in medicine
JID - 101648047
PMC - PMC11841430
OTO - NOTNLM
OT  - ChatGPT
OT  - LLM
OT  - artificial intelligence
OT  - generative AI
OT  - healthcare simulation
OT  - large language models
OT  - prompt
OT  - prompt engineering
COIS- GP is employed by the AAXIS Group Corporation. The remaining authors declare that 
      the research was conducted in the absence of any commercial or financial 
      relationships that could be construed as a potential conflict of interest.
EDAT- 2025/02/21 11:09
MHDA- 2025/02/21 11:10
PMCR- 2025/01/30
CRDT- 2025/02/21 04:48
PHST- 2024/09/30 00:00 [received]
PHST- 2024/12/17 00:00 [accepted]
PHST- 2025/02/21 11:10 [medline]
PHST- 2025/02/21 11:09 [pubmed]
PHST- 2025/02/21 04:48 [entrez]
PHST- 2025/01/30 00:00 [pmc-release]
AID - 10.3389/fmed.2024.1504532 [doi]
PST - epublish
SO  - Front Med (Lausanne). 2025 Jan 30;11:1504532. doi: 10.3389/fmed.2024.1504532. 
      eCollection 2024.

PMID- 38491461
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240319
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Mar 15
TI  - Evaluation of bias and gender/racial concordance based on sentiment analysis of 
      narrative evaluations of clinical clerkships using natural language processing.
PG  - 295
LID - 10.1186/s12909-024-05271-y [doi]
LID - 295
AB  - There is increasing interest in understanding potential bias in medical 
      education. We used natural language processing (NLP) to evaluate potential bias 
      in clinical clerkship evaluations. Data from medical evaluations and 
      administrative databases for medical students enrolled in third-year clinical 
      clerkship rotations across two academic years. We collected demographic 
      information of students and faculty evaluators to determine gender/racial 
      concordance (i.e., whether the student and faculty identified with the same 
      demographic). We used a multinomial log-linear model for final clerkship grades, 
      using predictors such as numerical evaluation scores, gender/racial concordance, 
      and sentiment scores of narrative evaluations using the 
      SentimentIntensityAnalyzer tool in Python. 2037 evaluations from 198 students 
      were analyzed. Statistical significance was defined as P < 0.05. Sentiment scores 
      for evaluations did not vary significantly by student gender, race, or ethnicity 
      (P = 0.88, 0.64, and 0.06, respectively). Word choices were similar across 
      faculty and student demographic groups. Modeling showed narrative evaluation 
      sentiment scores were not predictive of an honors grade (odds ratio [OR] 1.23, 
      P = 0.58). Numerical evaluation average (OR 1.45, P < 0.001) and gender 
      concordance between faculty and student (OR 1.32, P = 0.049) were significant 
      predictors of receiving honors. The lack of disparities in narrative text in our 
      study contrasts with prior findings from other institutions. Ongoing efforts 
      include comparative analyses with other institutions to understand what 
      institutional factors may contribute to bias. NLP enables a systematic approach 
      for investigating bias. The insights gained from the lack of association between 
      word choices, sentiment scores, and final grades show potential opportunities to 
      improve feedback processes for students.
CI  - © 2024. The Author(s).
FAU - Bhanvadia, Sonali
AU  - Bhanvadia S
AD  - Division of Ophthalmology Informatics and Data Science, Viterbi Family Department 
      of Ophthalmology and Shiley Eye Institute, University of California San Diego, La 
      Jolla, CA, USA.
AD  - Health Department of Biomedical Informatics, University of California San Diego, 
      La Jolla, CA, USA.
FAU - Radha Saseendrakumar, Bharanidharan
AU  - Radha Saseendrakumar B
AD  - Division of Ophthalmology Informatics and Data Science, Viterbi Family Department 
      of Ophthalmology and Shiley Eye Institute, University of California San Diego, La 
      Jolla, CA, USA.
AD  - Health Department of Biomedical Informatics, University of California San Diego, 
      La Jolla, CA, USA.
FAU - Guo, Joy
AU  - Guo J
AD  - Division of Ophthalmology Informatics and Data Science, Viterbi Family Department 
      of Ophthalmology and Shiley Eye Institute, University of California San Diego, La 
      Jolla, CA, USA.
AD  - Health Department of Biomedical Informatics, University of California San Diego, 
      La Jolla, CA, USA.
FAU - Spadafore, Maxwell
AU  - Spadafore M
AD  - Department of Emergency Medicine, University of Michigan Medical School, Ann 
      Arbor, MI, USA.
FAU - Daniel, Michelle
AU  - Daniel M
AD  - Department of Emergency Medicine, University of California San Diego, La Jolla, 
      CA, USA.
FAU - Lander, Lina
AU  - Lander L
AD  - Department of Family Medicine and Public Health, University of California San 
      Diego, La Jolla, CA, USA.
FAU - Baxter, Sally L
AU  - Baxter SL
AD  - Division of Ophthalmology Informatics and Data Science, Viterbi Family Department 
      of Ophthalmology and Shiley Eye Institute, University of California San Diego, La 
      Jolla, CA, USA. s1baxter@health.ucsd.edu.
AD  - Health Department of Biomedical Informatics, University of California San Diego, 
      La Jolla, CA, USA. s1baxter@health.ucsd.edu.
LA  - eng
GR  - 1DP5OD029610/NH/NIH HHS/United States
GR  - 1DP5OD029610/NH/NIH HHS/United States
GR  - 1DP5OD029610/NH/NIH HHS/United States
PT  - Journal Article
DEP - 20240315
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - Humans
MH  - Sentiment Analysis
MH  - *Clinical Clerkship
MH  - Natural Language Processing
MH  - *Education, Medical
MH  - *Students, Medical
MH  - Faculty, Medical
PMC - PMC10944013
OTO - NOTNLM
OT  - Bias in medical education
OT  - Medical student evaluations
OT  - Narrative evaluations
OT  - Natural language processing
COIS- Sally Baxter reports equipment support from Optomed and Topcon, outside the 
      submitted work. No conflicting relationship exists for any of the other authors.
EDAT- 2024/03/16 21:44
MHDA- 2024/03/18 06:42
PMCR- 2024/03/15
CRDT- 2024/03/16 00:43
PHST- 2023/10/10 00:00 [received]
PHST- 2024/03/06 00:00 [accepted]
PHST- 2024/03/18 06:42 [medline]
PHST- 2024/03/16 21:44 [pubmed]
PHST- 2024/03/16 00:43 [entrez]
PHST- 2024/03/15 00:00 [pmc-release]
AID - 10.1186/s12909-024-05271-y [pii]
AID - 5271 [pii]
AID - 10.1186/s12909-024-05271-y [doi]
PST - epublish
SO  - BMC Med Educ. 2024 Mar 15;24(1):295. doi: 10.1186/s12909-024-05271-y.

PMID- 38887241
OWN - NLM
STAT- MEDLINE
DCOM- 20240618
LR  - 20240619
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 12
DP  - 2024
TI  - Large language models in physical therapy: time to adapt and adept.
PG  - 1364660
LID - 10.3389/fpubh.2024.1364660 [doi]
LID - 1364660
AB  - Healthcare is experiencing a transformative phase, with artificial intelligence 
      (AI) and machine learning (ML). Physical therapists (PTs) stand on the brink of a 
      paradigm shift in education, practice, and research. Rather than visualizing AI 
      as a threat, it presents an opportunity to revolutionize. This paper examines how 
      large language models (LLMs), such as ChatGPT and BioMedLM, driven by deep ML can 
      offer human-like performance but face challenges in accuracy due to vast data in 
      PT and rehabilitation practice. PTs can benefit by developing and training an LLM 
      specifically for streamlining administrative tasks, connecting globally, and 
      customizing treatments using LLMs. However, human touch and creativity remain 
      invaluable. This paper urges PTs to engage in learning and shaping AI models by 
      highlighting the need for ethical use and human supervision to address potential 
      biases. Embracing AI as a contributor, and not just a user, is crucial by 
      integrating AI, fostering collaboration for a future in which AI enriches the PT 
      field provided data accuracy, and the challenges associated with feeding the AI 
      model are sensitively addressed.
CI  - Copyright © 2024 Naqvi, Shaikh and Mishra.
FAU - Naqvi, Waqar M
AU  - Naqvi WM
AD  - Department of Interdisciplinary Sciences, Datta Meghe Institute of Higher 
      Education and Research, Wardha, India.
AD  - Department of Physiotherapy, College of Health Sciences, Gulf Medical University, 
      Ajman, United Arab Emirates.
AD  - NKP Salve Institute of Medical Sciences and Research Center, Nagpur, India.
FAU - Shaikh, Summaiya Zareen
AU  - Shaikh SZ
AD  - Department of Neuro-Physiotherapy, The SIA College of Health Sciences, College of 
      Physiotherapy, Thane, India.
FAU - Mishra, Gaurav V
AU  - Mishra GV
AD  - Department of Radiodiagnosis, Datta Meghe Institute of Higher Education and 
      Research, Wardha, India.
LA  - eng
PT  - Journal Article
DEP - 20240524
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Machine Learning
MH  - Physical Therapists
MH  - Physical Therapy Modalities
PMC - PMC11182445
OTO - NOTNLM
OT  - BioMedLM
OT  - artificial intelligence
OT  - evidence-based practice
OT  - large language models
OT  - physical therapy
OT  - physical therapy education
OT  - rehabilitation
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/06/18 06:41
MHDA- 2024/06/18 23:43
PMCR- 2024/05/24
CRDT- 2024/06/18 03:53
PHST- 2024/01/02 00:00 [received]
PHST- 2024/05/10 00:00 [accepted]
PHST- 2024/06/18 06:41 [pubmed]
PHST- 2024/06/18 23:43 [medline]
PHST- 2024/06/18 03:53 [entrez]
PHST- 2024/05/24 00:00 [pmc-release]
AID - 10.3389/fpubh.2024.1364660 [doi]
PST - epublish
SO  - Front Public Health. 2024 May 24;12:1364660. doi: 10.3389/fpubh.2024.1364660. 
      eCollection 2024.

PMID- 38633142
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240419
IS  - 2473-974X (Electronic)
IS  - 2473-974X (Linking)
VI  - 8
IP  - 2
DP  - 2024 Apr-Jun
TI  - Portrait of a Surgeon: Artificial Intelligence Reflections.
PG  - e139
LID - 10.1002/oto2.139 [doi]
LID - e139
AB  - Text-to-image artificial intelligence (AI) programs are popular public-facing 
      tools that generate novel images based on user prompts. Given that they are 
      trained from Internet data, they may reflect societal biases, as has been shown 
      for text-to-text large language model programs. We sought to investigate whether 
      3 common text-to-image AI systems recapitulated stereotypes held about surgeons 
      and other health care professionals. All platforms queried were able to reproduce 
      common aspects of the profession including attire, equipment, and background 
      settings, but there were differences between programs most notably regarding 
      visible race and gender diversity. Thus, historical stereotypes of surgeons may 
      be reinforced by the public's use of text-to-image AI systems, particularly those 
      without procedures to regulate generated output. As AI systems become more 
      ubiquitous, understanding the implications of their use in health care and for 
      health care-adjacent purposes is critical to advocate for and preserve the core 
      values and goals of our profession.
CI  - © 2024 The Authors. OTO Open published by Wiley Periodicals LLC on behalf of 
      American Academy of Otolaryngology‐Head and Neck Surgery Foundation.
FAU - Farlow, Janice L
AU  - Farlow JL
AUID- ORCID: 0000-0003-1214-4960
AD  - Department of Otolaryngology-Head and Neck Surgery Indiana University School of 
      Medicine Indianapolis Indiana USA.
FAU - Abouyared, Marianne
AU  - Abouyared M
AD  - Department of Otolaryngology-Head and Neck Surgery University of California Davis 
      Sacramento California USA.
FAU - Rettig, Eleni M
AU  - Rettig EM
AD  - Department of Otolaryngology-Head and Neck Surgery Harvard Medical School Boston 
      Massachusetts USA.
FAU - Kejner, Alexandra
AU  - Kejner A
AD  - Department of Otolaryngology-Head and Neck Surgery Medical University of South 
      Carolina Charleston South Carolina USA.
FAU - Edwards, Heather A
AU  - Edwards HA
AD  - Department of Otolaryngology-Head and Neck Surgery Boston University Chobanian & 
      Avedisian School of Medicine Boston Massachusetts USA.
FAU - Patel, Rusha
AU  - Patel R
AD  - Department of Otolaryngology-Head and Neck Surgery University of Oklahoma College 
      of Medicine Oklahoma City Oklahoma USA.
LA  - eng
PT  - Journal Article
DEP - 20240417
PL  - United States
TA  - OTO Open
JT  - OTO open
JID - 101717942
PMC - PMC11022959
OTO - NOTNLM
OT  - artificial intelligence
OT  - diversity
OT  - gender
OT  - race
OT  - surgery
OT  - text to image
COIS- None.
EDAT- 2024/04/18 06:44
MHDA- 2024/04/18 06:45
PMCR- 2024/04/17
CRDT- 2024/04/18 03:49
PHST- 2024/02/16 00:00 [received]
PHST- 2024/03/17 00:00 [revised]
PHST- 2024/03/20 00:00 [accepted]
PHST- 2024/04/18 06:45 [medline]
PHST- 2024/04/18 06:44 [pubmed]
PHST- 2024/04/18 03:49 [entrez]
PHST- 2024/04/17 00:00 [pmc-release]
AID - OTO2139 [pii]
AID - 10.1002/oto2.139 [doi]
PST - epublish
SO  - OTO Open. 2024 Apr 17;8(2):e139. doi: 10.1002/oto2.139. eCollection 2024 Apr-Jun.

PMID- 38442909
OWN - NLM
STAT- MEDLINE
DCOM- 20240419
LR  - 20240425
IS  - 1869-0327 (Electronic)
IS  - 1869-0327 (Linking)
VI  - 15
IP  - 2
DP  - 2024 Mar
TI  - A Survey of Clinicians' Views of the Utility of Large Language Models.
PG  - 306-312
LID - 10.1055/a-2281-7092 [doi]
AB  - OBJECTIVES:  Large language models (LLMs) like Generative pre-trained transformer 
      (ChatGPT) are powerful algorithms that have been shown to produce human-like text 
      from input data. Several potential clinical applications of this technology have 
      been proposed and evaluated by biomedical informatics experts. However, few have 
      surveyed health care providers for their opinions about whether the technology is 
      fit for use. METHODS:  We distributed a validated mixed-methods survey to gauge 
      practicing clinicians' comfort with LLMs for a breadth of tasks in clinical 
      practice, research, and education, which were selected from the literature. 
      RESULTS:  A total of 30 clinicians fully completed the survey. Of the 23 tasks, 
      16 were rated positively by more than 50% of the respondents. Based on our 
      qualitative analysis, health care providers considered LLMs to have excellent 
      synthesis skills and efficiency. However, our respondents had concerns that LLMs 
      could generate false information and propagate training data bias.Our survey 
      respondents were most comfortable with scenarios that allow LLMs to function in 
      an assistive role, like a physician extender or trainee. CONCLUSION:  In a 
      mixed-methods survey of clinicians about LLM use, health care providers were 
      encouraging of having LLMs in health care for many tasks, and especially in 
      assistive roles. There is a need for continued human-centered development of both 
      LLMs and artificial intelligence in general.
CI  - The Author(s). This is an open access article published by Thieme under the terms 
      of the Creative Commons Attribution-NonDerivative-NonCommercial License, 
      permitting copying and reproduction so long as the original work is given 
      appropriate credit. Contents may not be used for commercial purposes, or adapted, 
      remixed, transformed or built upon. 
      (https://creativecommons.org/licenses/by-nc-nd/4.0/).
FAU - Spotnitz, Matthew
AU  - Spotnitz M
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
FAU - Idnay, Betina
AU  - Idnay B
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
FAU - Gordon, Emily R
AU  - Gordon ER
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
AD  - Department of Dermatology, Vagelos College of Physicians and Surgeons, Columbia 
      University Irving Medical Center, New York, New York, United States.
FAU - Shyu, Rebecca
AU  - Shyu R
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
FAU - Zhang, Gongbo
AU  - Zhang G
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
FAU - Liu, Cong
AU  - Liu C
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
FAU - Cimino, James J
AU  - Cimino JJ
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
AD  - Department of Biomedical Informatics and Data Science, Informatics Institute, 
      Heersink School of Medicine, University of Alabama at Birmingham, Birmingham, 
      Alabama, United States.
FAU - Weng, Chunhua
AU  - Weng C
AD  - Department of Biomedical Informatics, Columbia University Irving Medical Center, 
      New York, New York, United States.
LA  - eng
GR  - T15 LM007079/LM/NLM NIH HHS/United States
GR  - R01 LM009886/LM/NLM NIH HHS/United States
GR  - R01 LM014344/LM/NLM NIH HHS/United States
GR  - R01 HG012655/HG/NHGRI NIH HHS/United States
GR  - UL1 TR001873/TR/NCATS NIH HHS/United States
GR  - T15LM007079/LM/NLM NIH HHS/United States
PT  - Journal Article
DEP - 20240305
PL  - Germany
TA  - Appl Clin Inform
JT  - Applied clinical informatics
JID - 101537732
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Algorithms
MH  - Health Facilities
MH  - Health Personnel
MH  - Language
PMC - PMC11023712
COIS- None declared.
EDAT- 2024/03/06 00:42
MHDA- 2024/04/19 06:43
PMCR- 2024/04/01
CRDT- 2024/03/05 20:03
PHST- 2024/04/19 06:43 [medline]
PHST- 2024/03/06 00:42 [pubmed]
PHST- 2024/03/05 20:03 [entrez]
PHST- 2024/04/01 00:00 [pmc-release]
AID - ACI-2023-11-RA-0256 [pii]
AID - 10.1055/a-2281-7092 [doi]
PST - ppublish
SO  - Appl Clin Inform. 2024 Mar;15(2):306-312. doi: 10.1055/a-2281-7092. Epub 2024 Mar 
      5.

PMID- 39438058
OWN - NLM
STAT- Publisher
LR  - 20241022
IS  - 1535-5675 (Electronic)
IS  - 0091-4916 (Linking)
DP  - 2024 Oct 22
TI  - Gender and Ethnicity Bias of Text-to-Image Generative Artificial Intelligence in 
      Medical Imaging, Part 2: Analysis of DALL-E 3.
LID - jnmt.124.268359 [pii]
LID - 10.2967/jnmt.124.268359 [doi]
AB  - Disparity among gender and ethnicity remains an issue across medicine and health 
      science. Only 26%-35% of trainee radiologists are female, despite more than 50% 
      of medical students' being female. Similar gender disparities are evident across 
      the medical imaging professions. Generative artificial intelligence text-to-image 
      production could reinforce or amplify gender biases. Methods: In March 2024, 
      DALL-E 3 was utilized via GPT-4 to generate a series of individual and group 
      images of medical imaging professionals: radiologist, nuclear medicine physician, 
      radiographer, nuclear medicine technologist, medical physicist, radiopharmacist, 
      and medical imaging nurse. Multiple iterations of images were generated using a 
      variety of prompts. Collectively, 120 images were produced for evaluation of 524 
      characters. All images were independently analyzed by 3 expert reviewers from 
      medical imaging professions for apparent gender and skin tone. Results: 
      Collectively (individual and group images), 57.4% (n = 301) of medical imaging 
      professionals were depicted as male, 42.4% (n = 222) as female, and 91.2% (n = 
      478) as having a light skin tone. The male gender representation was 65% for 
      radiologists, 62% for nuclear medicine physicians, 52% for radiographers, 56% for 
      nuclear medicine technologists, 62% for medical physicists, 53% for 
      radiopharmacists, and 26% for medical imaging nurses. For all professions, this 
      overrepresents men compared with women. There was no representation of persons 
      with a disability. Conclusion: This evaluation reveals a significant 
      overrepresentation of the male gender associated with generative artificial 
      intelligence text-to-image production using DALL-E 3 across the medical imaging 
      professions. Generated images have a disproportionately high representation of 
      white men, which is not representative of the diversity of the medical imaging 
      professions.
CI  - © 2024 by the Society of Nuclear Medicine and Molecular Imaging.
FAU - Currie, Geoffrey
AU  - Currie G
AD  - Charles Sturt University, Wagga Wagga, New South Wales, Australia; 
      gcurrie@csu.edu.au.
AD  - Baylor College of Medicine, Houston, Texas.
FAU - Hewis, Johnathan
AU  - Hewis J
AD  - Charles Sturt University, Port Macquarie, New South Wales, Australia; and.
FAU - Hawk, Elizabeth
AU  - Hawk E
AD  - Stanford University, Stanford, California.
FAU - Rohren, Eric
AU  - Rohren E
AD  - Charles Sturt University, Wagga Wagga, New South Wales, Australia.
AD  - Baylor College of Medicine, Houston, Texas.
LA  - eng
PT  - Journal Article
DEP - 20241022
PL  - United States
TA  - J Nucl Med Technol
JT  - Journal of nuclear medicine technology
JID - 0430303
SB  - IM
OTO - NOTNLM
OT  - bias
OT  - diversity
OT  - generative artificial intelligence
OT  - nuclear medicine
OT  - radiology
EDAT- 2024/10/23 04:22
MHDA- 2024/10/23 04:22
CRDT- 2024/10/22 20:53
PHST- 2024/07/04 00:00 [received]
PHST- 2024/09/23 00:00 [accepted]
PHST- 2024/10/23 04:22 [medline]
PHST- 2024/10/23 04:22 [pubmed]
PHST- 2024/10/22 20:53 [entrez]
AID - jnmt.124.268359 [pii]
AID - 10.2967/jnmt.124.268359 [doi]
PST - aheadofprint
SO  - J Nucl Med Technol. 2024 Oct 22:jnmt.124.268359. doi: 10.2967/jnmt.124.268359.

PMID- 37370136
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230701
IS  - 2057-4967 (Electronic)
IS  - 2095-9370 (Print)
IS  - 2057-4967 (Linking)
VI  - 9
IP  - 1
DP  - 2023 Jun 28
TI  - Evaluation of lordosis recovery after lumbar arthrodesis and its clinical impact.
PG  - 18
LID - 10.1186/s41016-023-00333-4 [doi]
LID - 18
AB  - BACKGROUND: Posterior lumbar arthrodesis has become a widely used therapeutic 
      option to correct sagittal imbalances in patients suffering from degenerative 
      lumbar conditions. However, in western Africa, there is no study have reported 
      long-term outcome of posterior lumbar arthrodesis. The aim of this study was to 
      investigate the relationship between the restoration of adequate lordosis and the 
      patient's postoperative quality of life. METHOD: The study was retrospective. 
      From January 2012 to December 2019, 80 patients who underwent posterior lumbar 
      arthrodesis for lumbar degenerative diseases were included with a mean follow-up 
      of 43.2 months. Mean age was 50.8 years (SD = 12.2). Preoperative and 
      postoperative patients' symptoms were assessed by the visual analog scale (VAS), 
      Oswestry Disability Index (ODI), and 12-item Short Form (SF-12). Pre- and 
      post-operative radiographic evaluation included lumbar lordosis measured (LLm), 
      pelvic incidence (PI), sacral slope (SS), and pelvic stilt (PS). Theoretical 
      lumbar lordosis (LLt) was defined by the following: LL = 0.54 × PI + 27.6. Data 
      analysis was done using the statistical software "R." The risk of error was 5% 
      (p < 0.05). RESULT: The mean pelvic incidence was 57.23°. There was no 
      statistically significant difference between preoperative and postoperative 
      lumbar lordosis (p = 0.2567). There was no statistical difference between 
      preoperative and postoperative PI-LL (p = 0.179). There was a statistically 
      significant difference between the pre and postoperative clinical scores (p < 
      0.001). Statistical analysis showed a correlation between recovery of lumbar 
      lordosis and improvement in physical component of SF-12 (PCS) (p < 0.05) and 
      lumbar and radicular VAS (p < 0.05) for the subgroup of narrow lumbar spine. 
      There was a statistical relationship between the restoration of lumbar lordosis 
      and improvement in PCS (p = 0.004) and VAS (p = 0.003) for the subgroup of 
      isthmic lysis spondylolisthesis. DISCUSSION: The root decompression performed in 
      most patients could explain the clinical improvement regardless of recovery of 
      lordosis. The failure to consider spinal parameters and sagittal balance of 
      patients in the surgery could explain no restoration of lumbar lordosis. Our 
      study had limitations inherent to its retrospective character such as the classic 
      selection bias. CONCLUSION: Satisfactory correction of spinopelvic alignment may 
      improve long-term clinical signs.
CI  - © 2023. The Author(s).
FAU - Tchachoua Jiembou, Gabriel
AU  - Tchachoua Jiembou G
AUID- ORCID: 0009-0001-9075-6236
AD  - Department of Neurosurgery, University Hospital of Toulouse, 31300, Toulouse, 
      France. gabrieltchachoua2019@gmail.com.
FAU - Nda, Hermann Adonis
AU  - Nda HA
AD  - Department of Neurosurgery, University Hospital Yopougon, 21 BP 632, Abidjan, 
      Ivory Coast.
AD  - Training and Research Unit of Medical Sciences, University Felix Houphouet 
      Boigny, 01 BPV 34, Abidjan, Ivory Coast.
FAU - Konan, Meleine Landry
AU  - Konan ML
AD  - Department of Neurosurgery, University Hospital Yopougon, 21 BP 632, Abidjan, 
      Ivory Coast.
AD  - Training and Research Unit of Medical Sciences, University Felix Houphouet 
      Boigny, 01 BPV 34, Abidjan, Ivory Coast.
LA  - eng
PT  - Journal Article
DEP - 20230628
PL  - England
TA  - Chin Neurosurg J
JT  - Chinese neurosurgical journal
JID - 101672561
PMC - PMC10303337
OTO - NOTNLM
OT  - Clinical outcomes
OT  - Lumbar lordosis
OT  - Posterior lumbar arthrodesis
OT  - Sagittal alignment
COIS- The authors declare no competing interests.
EDAT- 2023/06/28 01:06
MHDA- 2023/06/28 01:07
PMCR- 2023/06/28
CRDT- 2023/06/27 23:43
PHST- 2023/03/03 00:00 [received]
PHST- 2023/06/14 00:00 [accepted]
PHST- 2023/06/28 01:07 [medline]
PHST- 2023/06/28 01:06 [pubmed]
PHST- 2023/06/27 23:43 [entrez]
PHST- 2023/06/28 00:00 [pmc-release]
AID - 10.1186/s41016-023-00333-4 [pii]
AID - 333 [pii]
AID - 10.1186/s41016-023-00333-4 [doi]
PST - epublish
SO  - Chin Neurosurg J. 2023 Jun 28;9(1):18. doi: 10.1186/s41016-023-00333-4.

PMID- 38562831
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250314
DP  - 2024 Mar 19
TI  - Inductive reasoning with large language models: a simulated randomized controlled 
      trial for epilepsy.
LID - 2024.03.18.24304493 [pii]
LID - 10.1101/2024.03.18.24304493 [doi]
AB  - IMPORTANCE: The analysis of electronic medical records at scale to learn from 
      clinical experience is currently very challenging. The integration of artificial 
      intelligence (AI), specifically foundational large language models (LLMs), into 
      an analysis pipeline may overcome some of the current limitations of modest input 
      sizes, inaccuracies, biases, and incomplete knowledge bases. OBJECTIVE: To 
      explore the effectiveness of using an LLM for generating realistic clinical data 
      and other LLMs for summarizing and synthesizing information in a model system, 
      simulating a randomized clinical trial (RCT) in epilepsy to demonstrate the 
      potential of inductive reasoning via medical chart review. DESIGN: An 
      LLM-generated simulated RCT based on a RCT for treatment with an antiseizure 
      medication, cenobamate, including a placebo arm and a full-strength drug arm, 
      evaluated by an LLM-based pipeline versus a human reader. SETTING: Simulation 
      based on realistic seizure diaries, treatment effects, reported symptoms and 
      clinical notes generated by LLMs with multiple different neurologist writing 
      styles. PARTICIPANTS: Simulated cohort of 240 patients, divided 1:1 into placebo 
      and drug arms. INTERVENTION: Utilization of LLMs for the generation of clinical 
      notes and for the synthesis of data from these notes, aiming to evaluate the 
      efficacy and safety of cenobamate in seizure control either with a human 
      evaluator or AI-pipeline. MEASURES: The AI and human analysis focused on 
      identifying the number of seizures, symptom reports, and treatment efficacy, with 
      statistical analysis comparing the 50%-responder rate and median percentage 
      change between the placebo and drug arms, as well as side effect rates in each 
      arm. RESULTS: AI closely mirrored human analysis, demonstrating the drug's 
      efficacy with marginal differences (<3%) in identifying both drug efficacy and 
      reported symptoms. CONCLUSIONS AND RELEVANCE: This study showcases the potential 
      of LLMs accurately simulate and analyze clinical trials. Significantly, it 
      highlights the ability of LLMs to reconstruct essential trial elements, identify 
      treatment effects, and recognize reported symptoms, within a realistic clinical 
      framework. The findings underscore the relevance of LLMs in future clinical 
      research, offering a scalable, efficient alternative to traditional data mining 
      methods without the need for specialized medical language training.
FAU - Goldenholz, Daniel M
AU  - Goldenholz DM
AUID- ORCID: 0000-0002-8370-2758
AD  - Department of Neurology, Harvard Medical School, Boston USA.
AD  - Department of Neurology, Beth Israel Deaconess Medical Center, Boston USA.
FAU - Goldenholz, Shira R
AU  - Goldenholz SR
AD  - Department of Neurology, Beth Israel Deaconess Medical Center, Boston USA.
FAU - Habib, Sara
AU  - Habib S
AD  - Department of Neurology, Harvard Medical School, Boston USA.
AD  - Department of Neurology, Beth Israel Deaconess Medical Center, Boston USA.
FAU - Westover, M Brandon
AU  - Westover MB
AD  - Department of Neurology, Harvard Medical School, Boston USA.
AD  - Department of Neurology, Beth Israel Deaconess Medical Center, Boston USA.
LA  - eng
GR  - K23 NS124656/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240319
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - Epilepsy Res. 2025 Mar;211:107532. doi: 10.1016/j.eplepsyres.2025.107532. PMID: 
      40020525
PMC - PMC10984041
OTO - NOTNLM
OT  - artificial intelligence
OT  - epilepsy
OT  - large language models
OT  - randomized clinical trials
COIS- Conflicts of interest None of the authors have any conflicts of interest to 
      declare.
EDAT- 2024/04/02 06:45
MHDA- 2024/04/02 06:46
PMCR- 2024/04/01
CRDT- 2024/04/02 03:56
PHST- 2024/04/02 06:45 [pubmed]
PHST- 2024/04/02 06:46 [medline]
PHST- 2024/04/02 03:56 [entrez]
PHST- 2024/04/01 00:00 [pmc-release]
AID - 2024.03.18.24304493 [pii]
AID - 10.1101/2024.03.18.24304493 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Mar 19:2024.03.18.24304493. doi: 
      10.1101/2024.03.18.24304493.

PMID- 37080559
OWN - NLM
STAT- MEDLINE
DCOM- 20230721
LR  - 20230721
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 30
IP  - 8
DP  - 2023 Jul 19
TI  - Automatic extraction of social determinants of health from medical notes of 
      chronic lower back pain patients.
PG  - 1438-1447
LID - 10.1093/jamia/ocad054 [doi]
AB  - OBJECTIVE: We applied natural language processing and inference methods to 
      extract social determinants of health (SDoH) information from clinical notes of 
      patients with chronic low back pain (cLBP) to enhance future analyses of the 
      associations between SDoH disparities and cLBP outcomes. MATERIALS AND METHODS: 
      Clinical notes for patients with cLBP were annotated for 7 SDoH domains, as well 
      as depression, anxiety, and pain scores, resulting in 626 notes with at least one 
      annotated entity for 364 patients. We used a 2-tier taxonomy with these 10 
      first-level classes (domains) and 52 second-level classes. We developed and 
      validated named entity recognition (NER) systems based on both rule-based and 
      machine learning approaches and validated an entailment model. RESULTS: 
      Annotators achieved a high interrater agreement (Cohen's kappa of 95.3% at 
      document level). A rule-based system (cTAKES), RoBERTa NER, and a hybrid model 
      (combining rules and logistic regression) achieved performance of F1 = 47.1%, 
      84.4%, and 80.3%, respectively, for first-level classes. DISCUSSION: While the 
      hybrid model had a lower F1 performance, it matched or outperformed RoBERTa NER 
      model in terms of recall and had lower computational requirements. Applying an 
      untuned RoBERTa entailment model, we detected many challenging wordings missed by 
      NER systems. Still, the entailment model may be sensitive to hypothesis wording. 
      CONCLUSION: This study developed a corpus of annotated clinical notes covering a 
      broad spectrum of SDoH classes. This corpus provides a basis for training machine 
      learning models and serves as a benchmark for predictive models for NER for SDoH 
      and knowledge extraction from clinical texts.
CI  - Published by Oxford University Press on behalf of the American Medical 
      Informatics Association 2023.
FAU - Lituiev, Dmytro S
AU  - Lituiev DS
AUID- ORCID: 0000-0003-0543-0758
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, California, USA.
FAU - Lacar, Benjamin
AU  - Lacar B
AUID- ORCID: 0000-0003-0874-6707
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, California, USA.
AD  - Berkeley Institute for Data Science, University of California, Berkeley, 
      California, USA.
FAU - Pak, Sang
AU  - Pak S
AD  - Department of Physical Therapy and Rehabilitation Science, University of 
      California San Francisco, San Francisco, California, USA.
FAU - Abramowitsch, Peter L
AU  - Abramowitsch PL
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, California, USA.
FAU - De Marchis, Emilia H
AU  - De Marchis EH
AD  - Department of Family & Community Medicine, University of California San 
      Francisco, San Francisco, California, USA.
FAU - Peterson, Thomas A
AU  - Peterson TA
AUID- ORCID: 0000-0002-2562-6574
AD  - Bakar Computational Health Sciences Institute, University of California San 
      Francisco, San Francisco, California, USA.
AD  - Department of Orthopaedic Surgery, University of California San Francisco, San 
      Francisco, California, USA.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Humans
MH  - *Low Back Pain
MH  - Social Determinants of Health
MH  - Natural Language Processing
MH  - Machine Learning
PMC - PMC10354762
OTO - NOTNLM
OT  - depression
OT  - lower back pain
OT  - machine learning
OT  - natural language inference
OT  - natural language processing
OT  - social determinants of health
COIS- DSL is a shareholder of Crosscope Inc and SynthezAI Corp and is currently 
      employed by Johnson & Johnson. BL is supported by Innovate for Health Data 
      Science Fellowship from Johnson & Johnson. PLA received funding from REAC RAP 
      UCSF through UCSF. EDM received support from Hellman Fellows Fund Payment, and 
      REAC RAP UCSF through UCSF. SP received support from Back Pain Consortium 
      (BACPAC) grant through UCSF.
EDAT- 2023/04/21 00:42
MHDA- 2023/07/21 06:42
PMCR- 2023/05/13
CRDT- 2023/04/20 20:22
PHST- 2022/12/05 00:00 [received]
PHST- 2023/02/15 00:00 [revised]
PHST- 2023/03/18 00:00 [accepted]
PHST- 2023/07/21 06:42 [medline]
PHST- 2023/04/21 00:42 [pubmed]
PHST- 2023/04/20 20:22 [entrez]
PHST- 2023/05/13 00:00 [pmc-release]
AID - 7133957 [pii]
AID - ocad054 [pii]
AID - 10.1093/jamia/ocad054 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2023 Jul 19;30(8):1438-1447. doi: 10.1093/jamia/ocad054.

PMID- 40035027
OWN - NLM
STAT- MEDLINE
DCOM- 20250304
LR  - 20250305
IS  - 2168-2372 (Electronic)
IS  - 2168-2372 (Linking)
VI  - 13
DP  - 2025
TI  - Multi-Branch CNN-LSTM Fusion Network-Driven System With BERT Semantic Evaluator 
      for Radiology Reporting in Emergency Head CTs.
PG  - 61-74
LID - 10.1109/JTEHM.2025.3535676 [doi]
AB  - The high volume of emergency room patients often necessitates head CT 
      examinations to rule out ischemic, hemorrhagic, or other organic pathologies. A 
      system that enhances the diagnostic efficacy of head CT imaging in emergency 
      settings through structured reporting would significantly improve clinical 
      decision making. Currently, no AI solutions address this need. Thus, our research 
      aims to develop an automatic radiology reporting system by directly analyzing 
      brain anomalies in head CT data. We propose a multi-branch CNN-LSTM fusion 
      network-driven system for enhanced radiology reporting in emergency settings. We 
      preprocessed head CT scans by resizing all slices, selecting those with 
      significant variability, and applying PCA to retain 95% of the original data 
      variance, ultimately saving the most representative five slices for each scan. We 
      linked the reports to their respective slice IDs, divided them into individual 
      captions, and preprocessed each. We performed an 80-20 split of the dataset for 
      ten times, with 15% of the training set used for validation. Our model utilizes a 
      pretrained VGG16, processing groups of five slices simultaneously, and features 
      multiple end-to-end LSTM branches, each specialized in predicting one caption, 
      subsequently combined to form the ordered reports after a BERT-based semantic 
      evaluation. Our system demonstrates effectiveness and stability, with the 
      postprocessing stage refining the syntax of the generated descriptions. However, 
      there remains an opportunity to empower the evaluation framework to more 
      accurately assess the clinical relevance of the automatically-written reports. 
      Part of future work will include transitioning to 3D and developing an improved 
      version based on vision-language models.
CI  - © 2025 The Authors.
FAU - Tomassini, Selene
AU  - Tomassini S
AUID- ORCID: 0000-0002-1087-7004
AD  - Department of Information Engineering and Computer ScienceUniversity of Trento 
      Trento 38121 Italy. RINGGOLD: 19034
FAU - Duranti, Damiano
AU  - Duranti D
AUID- ORCID: 0009-0007-4239-2988
AD  - Department of Information Engineering and Computer ScienceUniversity of Trento 
      Trento 38121 Italy. RINGGOLD: 19034
FAU - Zeggada, Abdallah
AU  - Zeggada A
AD  - Department of Information Engineering and Computer ScienceUniversity of Trento 
      Trento 38121 Italy. RINGGOLD: 19034
FAU - Cosimo Quattrocchi, Carlo
AU  - Cosimo Quattrocchi C
AUID- ORCID: 0000-0001-6823-7707
AD  - Centre for Medical SciencesUniversity of Trento Trento 38121 Italy. RINGGOLD: 
      19034
FAU - Melgani, Farid
AU  - Melgani F
AUID- ORCID: 0000-0001-9745-3732
AD  - Department of Information Engineering and Computer ScienceUniversity of Trento 
      Trento 38121 Italy. RINGGOLD: 19034
FAU - Giorgini, Paolo
AU  - Giorgini P
AUID- ORCID: 0000-0003-4152-9683
AD  - Department of Information Engineering and Computer ScienceUniversity of Trento 
      Trento 38121 Italy. RINGGOLD: 19034
LA  - eng
PT  - Journal Article
DEP - 20250128
PL  - United States
TA  - IEEE J Transl Eng Health Med
JT  - IEEE journal of translational engineering in health and medicine
JID - 101623153
SB  - IM
MH  - Humans
MH  - *Tomography, X-Ray Computed/methods
MH  - *Neural Networks, Computer
MH  - Semantics
MH  - Head/diagnostic imaging
MH  - Emergency Service, Hospital
MH  - Radiology Information Systems
MH  - Brain/diagnostic imaging
PMC - PMC11875635
OTO - NOTNLM
OT  - Clinical and Translational Impact Statement—Our system improves clinical decision 
      making by automating radiology reporting for emergency head CTs, enhancing 
      diagnostic accuracy, reducing cognitive biases, and providing timely support for 
      integration in hectic clinical settings.
OT  - Convolutional neural network
OT  - emergency room
OT  - head computed tomography
OT  - language model
OT  - long short-term memory
OT  - radiology reporting
EDAT- 2025/03/04 10:53
MHDA- 2025/03/04 10:54
PMCR- 2025/01/28
CRDT- 2025/03/04 04:58
PHST- 2024/10/02 00:00 [received]
PHST- 2025/01/05 00:00 [revised]
PHST- 2025/01/22 00:00 [accepted]
PHST- 2025/03/04 10:54 [medline]
PHST- 2025/03/04 10:53 [pubmed]
PHST- 2025/03/04 04:58 [entrez]
PHST- 2025/01/28 00:00 [pmc-release]
AID - 10.1109/JTEHM.2025.3535676 [doi]
PST - epublish
SO  - IEEE J Transl Eng Health Med. 2025 Jan 28;13:61-74. doi: 
      10.1109/JTEHM.2025.3535676. eCollection 2025.

PMID- 39135584
OWN - NLM
STAT- MEDLINE
DCOM- 20240813
LR  - 20240814
IS  - 0065-7778 (Print)
IS  - 0065-7778 (Linking)
VI  - 134
DP  - 2024
TI  - CLINICAL REASONING AND ARTIFICIAL INTELLIGENCE: CAN AI REALLY THINK?
PG  - 133-145
AB  - Artificial intelligence (AI) in the form of ChatGPT has rapidly attracted 
      attention from physicians and medical educators. While it holds great promise for 
      more routine medical tasks, may broaden one's differential diagnosis, and may be 
      able to assist in the evaluation of images, such as radiographs and 
      electrocardiograms, the technology is largely based on advanced algorithms akin 
      to pattern recognition. One of the key questions raised in concert with these 
      advances is: What does the growth of artificial intelligence mean for medical 
      education, particularly the development of critical thinking and clinical 
      reasoning? In this commentary, we will explore the elements of cognitive theory 
      that underlie the ways in which physicians are taught to reason through a 
      diagnostic case and compare hypothetico-deductive reasoning, often employing 
      illness scripts, with inductive reasoning, which is based on a deeper 
      understanding of mechanisms of health and disease. Issues of cognitive bias and 
      their impact on diagnostic error will be examined. The constructs of routine and 
      adaptive expertise will also be delineated. The application of artificial 
      intelligence to diagnostic problem solving, along with concerns about racial and 
      gender bias, will be delineated. Using several case examples, we will demonstrate 
      the limitations of this technology and its potential pitfalls and outline the 
      direction medical education may need to take in the years to come.
CI  - © 2024 The American Clinical and Climatological Association.
FAU - Schwartzstein, Richard M
AU  - Schwartzstein RM
AD  - BOSTON, MASSACHUSETTS.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Trans Am Clin Climatol Assoc
JT  - Transactions of the American Clinical and Climatological Association
JID - 7507559
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Clinical Reasoning
MH  - Education, Medical/methods
MH  - Problem Solving
MH  - Clinical Competence
MH  - Cognition
MH  - Diagnostic Errors/prevention & control
MH  - Diagnosis, Differential
MH  - Thinking
MH  - Clinical Decision-Making
PMC - PMC11316886
EDAT- 2024/08/13 06:42
MHDA- 2024/08/13 06:43
PMCR- 2024/01/01
CRDT- 2024/08/13 03:54
PHST- 2024/08/13 06:43 [medline]
PHST- 2024/08/13 06:42 [pubmed]
PHST- 2024/08/13 03:54 [entrez]
PHST- 2024/01/01 00:00 [pmc-release]
PST - ppublish
SO  - Trans Am Clin Climatol Assoc. 2024;134:133-145.

PMID- 39252056
OWN - NLM
STAT- MEDLINE
DCOM- 20240910
LR  - 20240912
IS  - 1472-6947 (Electronic)
IS  - 1472-6947 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Sep 9
TI  - Clinician voices on ethics of LLM integration in healthcare: a thematic analysis 
      of ethical concerns and implications.
PG  - 250
LID - 10.1186/s12911-024-02656-3 [doi]
LID - 250
AB  - OBJECTIVES: This study aimed to explain and categorize key ethical concerns about 
      integrating large language models (LLMs) in healthcare, drawing particularly from 
      the perspectives of clinicians in online discussions. MATERIALS AND METHODS: We 
      analyzed 3049 posts and comments extracted from a self-identified clinician 
      subreddit using unsupervised machine learning via Latent Dirichlet Allocation and 
      a structured qualitative analysis methodology. RESULTS: Analysis uncovered 14 
      salient themes of ethical implications, which we further consolidated into 4 
      overarching domains reflecting ethical issues around various clinical 
      applications of LLM in healthcare, LLM coding, algorithm, and data governance, 
      LLM's role in health equity and the distribution of public health services, and 
      the relationship between users (human) and LLM systems (machine). DISCUSSION: 
      Mapping themes to ethical frameworks in literature illustrated multifaceted 
      issues covering transparent LLM decisions, fairness, privacy, access disparities, 
      user experiences, and reliability. CONCLUSION: This study emphasizes the need for 
      ongoing ethical review from stakeholders to ensure responsible innovation and 
      advocates for tailored governance to enhance LLM use in healthcare, aiming to 
      improve clinical outcomes ethically and effectively.
CI  - © 2024. This is a U.S. Government work and not under copyright protection in the 
      US; foreign copyright protection may apply.
FAU - Mirzaei, Tala
AU  - Mirzaei T
AD  - Information Systems & Business Analytics, College of Business, Florida 
      International University, 11200 S.W. 8th St., Room RB 250, Miami, FL, 33199, USA. 
      tmirzaei@fiu.edu.
FAU - Amini, Leila
AU  - Amini L
AD  - Information Systems & Business Analytics, College of Business, Florida 
      International University, 11200 S.W. 8th St., Room RB 250, Miami, FL, 33199, USA.
FAU - Esmaeilzadeh, Pouyan
AU  - Esmaeilzadeh P
AD  - Information Systems & Business Analytics, College of Business, Florida 
      International University, 11200 S.W. 8th St., Room RB 250, Miami, FL, 33199, USA.
LA  - eng
PT  - Journal Article
DEP - 20240909
PL  - England
TA  - BMC Med Inform Decis Mak
JT  - BMC medical informatics and decision making
JID - 101088682
SB  - IM
MH  - Humans
MH  - *Attitude of Health Personnel
MH  - Delivery of Health Care/ethics
MH  - Qualitative Research
PMC - PMC11382443
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Ethics
OT  - LLM
OT  - Thematic analysis
OT  - Theme
COIS- The authors declare no competing interests.
EDAT- 2024/09/10 00:43
MHDA- 2024/09/10 06:43
PMCR- 2024/09/09
CRDT- 2024/09/09 23:54
PHST- 2024/03/25 00:00 [received]
PHST- 2024/08/27 00:00 [accepted]
PHST- 2024/09/10 06:43 [medline]
PHST- 2024/09/10 00:43 [pubmed]
PHST- 2024/09/09 23:54 [entrez]
PHST- 2024/09/09 00:00 [pmc-release]
AID - 10.1186/s12911-024-02656-3 [pii]
AID - 2656 [pii]
AID - 10.1186/s12911-024-02656-3 [doi]
PST - epublish
SO  - BMC Med Inform Decis Mak. 2024 Sep 9;24(1):250. doi: 10.1186/s12911-024-02656-3.

PMID- 39059040
OWN - NLM
STAT- MEDLINE
DCOM- 20240813
LR  - 20250108
IS  - 1872-7123 (Electronic)
IS  - 0165-1781 (Print)
IS  - 0165-1781 (Linking)
VI  - 339
DP  - 2024 Sep
TI  - Evaluating generative AI responses to real-world drug-related questions.
PG  - 116058
LID - S0165-1781(24)00343-3 [pii]
LID - 10.1016/j.psychres.2024.116058 [doi]
AB  - Generative Artificial Intelligence (AI) systems such as OpenAI's ChatGPT, capable 
      of an unprecedented ability to generate human-like text and converse in real 
      time, hold potential for large-scale deployment in clinical settings such as 
      substance use treatment. Treatment for substance use disorders (SUDs) is 
      particularly high stakes, requiring evidence-based clinical treatment, mental 
      health expertise, and peer support. Thus, promises of AI systems addressing 
      deficient healthcare resources and structural bias are relevant within this 
      domain, especially in an anonymous setting. This study explores the effectiveness 
      of generative AI in answering real-world substance use and recovery questions. We 
      collect questions from online recovery forums, use ChatGPT and Meta's LLaMA-2 for 
      responses, and have SUD clinicians rate these AI responses. While clinicians 
      rated the AI-generated responses as high quality, we discovered instances of 
      dangerous disinformation, including disregard for suicidal ideation, incorrect 
      emergency helplines, and endorsement of home detox. Moreover, the AI systems 
      produced inconsistent advice depending on question phrasing. These findings 
      indicate a risky mix of seemingly high-quality, accurate responses upon initial 
      inspection that contain inaccurate and potentially deadly medical advice. 
      Consequently, while generative AI shows promise, its real-world application in 
      sensitive healthcare domains necessitates further safeguards and clinical 
      validation.
CI  - Copyright © 2024. Published by Elsevier B.V.
FAU - Giorgi, Salvatore
AU  - Giorgi S
AD  - National Institute on Drug Abuse, Baltimore, MD, USA; University of Pennsylvania, 
      Philadelphia, PA, USA.
FAU - Isman, Kelsey
AU  - Isman K
AD  - National Institute on Drug Abuse, Baltimore, MD, USA.
FAU - Liu, Tingting
AU  - Liu T
AD  - National Institute on Drug Abuse, Baltimore, MD, USA.
FAU - Fried, Zachary
AU  - Fried Z
AD  - National Institute on Drug Abuse, Baltimore, MD, USA.
FAU - Sedoc, João
AU  - Sedoc J
AD  - New York University, New York, NY, USA.
FAU - Curtis, Brenda
AU  - Curtis B
AD  - National Institute on Drug Abuse, Baltimore, MD, USA. Electronic address: 
      brenda.curtis@nih.gov.
LA  - eng
GR  - ZIA DA000628/ImNIH/Intramural NIH HHS/United States
PT  - Journal Article
DEP - 20240626
PL  - Ireland
TA  - Psychiatry Res
JT  - Psychiatry research
JID - 7911385
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Substance-Related Disorders
MH  - Suicidal Ideation
PMC - PMC11705880
MID - NIHMS2011535
OTO - NOTNLM
OT  - Alcohol
OT  - Generative AI
OT  - Large language models
OT  - Marijuana
OT  - Opioids
OT  - Substance use
COIS- Declaration of competing interest The authors declare that the research was 
      conducted in the absence of any commercial or financial relationships that could 
      be construed as a potential conflict of interest.
EDAT- 2024/07/26 18:43
MHDA- 2024/08/14 00:42
PMCR- 2025/01/07
CRDT- 2024/07/26 18:00
PHST- 2023/12/26 00:00 [received]
PHST- 2024/06/21 00:00 [revised]
PHST- 2024/06/22 00:00 [accepted]
PHST- 2024/08/14 00:42 [medline]
PHST- 2024/07/26 18:43 [pubmed]
PHST- 2024/07/26 18:00 [entrez]
PHST- 2025/01/07 00:00 [pmc-release]
AID - S0165-1781(24)00343-3 [pii]
AID - 10.1016/j.psychres.2024.116058 [doi]
PST - ppublish
SO  - Psychiatry Res. 2024 Sep;339:116058. doi: 10.1016/j.psychres.2024.116058. Epub 
      2024 Jun 26.

PMID- 37450276
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240716
IS  - 1573-9686 (Electronic)
IS  - 0090-6964 (Print)
IS  - 0090-6964 (Linking)
VI  - 52
IP  - 4
DP  - 2024 Apr
TI  - Towards Precision Medicine in Spinal Surgery: Leveraging AI Technologies.
PG  - 735-737
LID - 10.1007/s10439-023-03315-w [doi]
AB  - This critique explores the implications of integrating artificial intelligence 
      (AI) technology, specifically OpenAI's advanced language model GPT-4 and its 
      interface, ChatGPT, into the field of spinal surgery. It examines the potential 
      effects of algorithmic bias, unique challenges in surgical domains, access and 
      equity issues, cost implications, global disparities in technology adoption, and 
      the concept of technological determinism. It posits that biases present in AI 
      training data may impact the quality and equity of healthcare outcomes. 
      Challenges related to the unique nature of surgical procedures, including 
      real-time decision-making, are also addressed. Concerns over access, equity, and 
      cost implications underscore the potential for exacerbated healthcare 
      disparities. Global disparities in technology adoption highlight the importance 
      of global collaboration, technology transfer, and capacity building. Finally, the 
      critique challenges the notion of technological determinism, emphasizing the 
      continued importance of human judgement and patient-care provider relationship in 
      healthcare. The critique calls for a comprehensive evaluation of AI technology 
      integration in healthcare to ensure equitable and quality care.
CI  - © 2023. The Author(s).
FAU - Lawson McLean, Aaron
AU  - Lawson McLean A
AUID- ORCID: 0000-0001-5528-6905
AD  - Department of Neurosurgery, Jena University Hospital - Friedrich Schiller 
      University Jena, Am Klinikum 1, 07747, Jena, Germany. 
      aaron.lawsonmclean@med.uni-jena.de.
LA  - eng
PT  - Letter
DEP - 20230714
PL  - United States
TA  - Ann Biomed Eng
JT  - Annals of biomedical engineering
JID - 0361512
SB  - IM
MH  - Humans
MH  - *Precision Medicine
MH  - *Artificial Intelligence
MH  - Neurosurgical Procedures
MH  - Technology
MH  - Healthcare Disparities
PMC - PMC10940418
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Data security
OT  - Healthcare technology
OT  - Patient outcomes
OT  - Spinal surgery
OT  - Surgical decision making
COIS- The author has no relevant financial or non-financial interests to disclose.
EDAT- 2023/07/14 13:08
MHDA- 2024/03/15 06:44
PMCR- 2023/07/14
CRDT- 2023/07/14 11:18
PHST- 2023/07/04 00:00 [received]
PHST- 2023/07/06 00:00 [accepted]
PHST- 2024/03/15 06:44 [medline]
PHST- 2023/07/14 13:08 [pubmed]
PHST- 2023/07/14 11:18 [entrez]
PHST- 2023/07/14 00:00 [pmc-release]
AID - 10.1007/s10439-023-03315-w [pii]
AID - 3315 [pii]
AID - 10.1007/s10439-023-03315-w [doi]
PST - ppublish
SO  - Ann Biomed Eng. 2024 Apr;52(4):735-737. doi: 10.1007/s10439-023-03315-w. Epub 
      2023 Jul 14.

PMID- 39046535
OWN - NLM
STAT- MEDLINE
DCOM- 20240724
LR  - 20250106
IS  - 2509-9280 (Electronic)
IS  - 2509-9280 (Linking)
VI  - 8
IP  - 1
DP  - 2024 Jul 24
TI  - The Picasso's skepticism on computer science and the dawn of generative AI: 
      questions after the answers to keep "machines-in-the-loop".
PG  - 81
LID - 10.1186/s41747-024-00485-7 [doi]
LID - 81
AB  - Starting from Picasso's quote ("Computers are useless. They can only give you 
      answers"), we discuss the introduction of generative artificial intelligence 
      (AI), including generative adversarial networks (GANs) and transformer-based 
      architectures such as large language models (LLMs) in radiology, where their 
      potential in reporting, image synthesis, and analysis is notable. However, the 
      need for improvements, evaluations, and regulations prior to clinical use is also 
      clear. Integration of LLMs into clinical workflow needs cautiousness, to avoid or 
      at least mitigate risks associated with false diagnostic suggestions. We 
      highlight challenges in synthetic image generation, inherent biases in AI models, 
      and privacy concerns, stressing the importance of diverse training datasets and 
      robust data privacy measures. We examine the regulatory landscape, including the 
      2023 Executive Order on AI in the United States and the 2024 AI Act in the 
      European Union, which set standards for AI applications in healthcare. This 
      manuscript contributes to the field by emphasizing the necessity of maintaining 
      the human element in medical procedures while leveraging generative AI, 
      advocating for a "machines-in-the-loop" approach.
CI  - © 2024. The Author(s).
FAU - Pesapane, Filippo
AU  - Pesapane F
AUID- ORCID: 0000-0002-0374-5054
AD  - Breast Imaging Division, IEO European Institute of Oncology IRCCS, Milan, Italy. 
      filippo.pesapane@ieo.it.
FAU - Cuocolo, Renato
AU  - Cuocolo R
AD  - Department of Medicine, Surgery and Dentistry, University of Salerno, Via 
      Salvador Allende 43, Baronissi, 84081, Salerno, Italy.
FAU - Sardanelli, Francesco
AU  - Sardanelli F
AD  - Unit of Radiology, IRCCS Policlinico San Donato, Via Morandi 30, San Donato 
      Milanese, 20097, Milan, Italy.
AD  - Lega Italiana Tumori (LILT) Milano Monza Brianza, Piazzale Gorini 22, 20133, 
      Milan, Italy.
LA  - eng
PT  - Editorial
DEP - 20240724
PL  - England
TA  - Eur Radiol Exp
JT  - European radiology experimental
JID - 101721752
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence/trends
MH  - Radiology/methods/trends
PMC - PMC11269548
COIS- FS has received research grants from and participated to ad hoc advisory boards 
      for Bayer Healthcare, Bracco Imaging, and General Electric Healthcare. In 
      addition, FS is the Editor-in-Chief of European Radiology Experimental while RC 
      is Section Editor and FP is member of the Editorial Board of the same journal. 
      For this reason, they were not involved in any way in the revision/decision 
      process regarding this manuscript, which was completely managed by the Deputy 
      Editor, Prof. Akos Varga-Szemes (Medical University of South Carolina, 
      Charleston, SC, USA).
EDAT- 2024/07/24 12:42
MHDA- 2024/07/26 12:47
PMCR- 2024/07/24
CRDT- 2024/07/24 11:16
PHST- 2024/03/17 00:00 [received]
PHST- 2024/06/16 00:00 [accepted]
PHST- 2024/07/26 12:47 [medline]
PHST- 2024/07/24 12:42 [pubmed]
PHST- 2024/07/24 11:16 [entrez]
PHST- 2024/07/24 00:00 [pmc-release]
AID - 10.1186/s41747-024-00485-7 [pii]
AID - 485 [pii]
AID - 10.1186/s41747-024-00485-7 [doi]
PST - epublish
SO  - Eur Radiol Exp. 2024 Jul 24;8(1):81. doi: 10.1186/s41747-024-00485-7.

PMID- 40068371
OWN - NLM
STAT- Publisher
LR  - 20250311
IS  - 1879-0852 (Electronic)
IS  - 0959-8049 (Linking)
VI  - 220
DP  - 2025 Mar 6
TI  - Retrieval-Augmented Generation: Advancing personalized care and research in 
      oncology.
PG  - 115341
LID - S0959-8049(25)00122-4 [pii]
LID - 10.1016/j.ejca.2025.115341 [doi]
AB  - Retrieval-Augmented Generation (RAG) pairs large language models (LLMs) with 
      recent data to produce more accurate, context-aware outputs. By converting text 
      into numeric embeddings, RAG locates and retrieves relevant "chunks" of data, 
      that along with the query, ground the model's responses in current, specific 
      information. This process helps reduce outdated or fabricated answers. In 
      oncology, RAG has shown particular promise. Studies have demonstrated its ability 
      to improve treatment recommendations by integrating genetic profiles, 
      strengthened clinical trial matching through biomarker analysis, and accelerated 
      drug development by clarifying model-driven insights. Despite its advantages, RAG 
      depends on high-quality data. Biased or incomplete sources can lead to inaccurate 
      outcomes. Careful implementation and human oversight are crucial for ensuring the 
      effectiveness and reliability of RAG in oncology.
CI  - Copyright © 2025 Elsevier Ltd. All rights reserved.
FAU - Zarfati, Mor
AU  - Zarfati M
AD  - Israel Defense Forces Medical Corps, Ramat Gan, Israel; Department of Military 
      Medicine, Hebrew University of Jerusalem, Faculty of Medicine, Jerusalem, Israel.
FAU - Soffer, Shelly
AU  - Soffer S
AD  - Institute of Hematology, Davidoff Cancer Center, Rabin Medical Center, 
      Petah-Tikva 49100, Israel; Faculty of Medicine, Tel Aviv University, Tel Aviv 
      52621, Israel.
FAU - Nadkarni, Girish N
AU  - Nadkarni GN
AD  - Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn 
      School of Medicine at Mount Sinai, New York, NY 10029, United States.
FAU - Klang, Eyal
AU  - Klang E
AD  - Division of Data-Driven and Digital Medicine, Department of Medicine, Icahn 
      School of Medicine at Mount Sinai, New York, NY 10029, United States. Electronic 
      address: eyal.klang@mountsinai.org.
LA  - eng
PT  - Journal Article
DEP - 20250306
PL  - England
TA  - Eur J Cancer
JT  - European journal of cancer (Oxford, England : 1990)
JID - 9005373
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Large language models
OT  - Personalized treatment
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2025/03/12 11:36
MHDA- 2025/03/12 11:36
CRDT- 2025/03/11 19:05
PHST- 2025/01/31 00:00 [received]
PHST- 2025/03/02 00:00 [accepted]
PHST- 2025/03/12 11:36 [medline]
PHST- 2025/03/12 11:36 [pubmed]
PHST- 2025/03/11 19:05 [entrez]
AID - S0959-8049(25)00122-4 [pii]
AID - 10.1016/j.ejca.2025.115341 [doi]
PST - aheadofprint
SO  - Eur J Cancer. 2025 Mar 6;220:115341. doi: 10.1016/j.ejca.2025.115341.

PMID- 39211884
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250204
DP  - 2024 Aug 13
TI  - Large Language Models Improve the Identification of Emergency Department Visits 
      for Symptomatic Kidney Stones.
LID - 2024.08.12.24311870 [pii]
LID - 10.1101/2024.08.12.24311870 [doi]
AB  - BACKGROUND: Recent advancements of large language models (LLMs) like Generative 
      Pre-trained Transformer 4 (GPT-4) have generated significant interest among the 
      scientific community. Yet, the potential of these models to be utilized in 
      clinical settings remains largely unexplored. This study investigated the 
      abilities of multiple LLMs and traditional machine learning models to analyze 
      emergency department (ED) reports and determine if the corresponding visits were 
      caused by symptomatic kidney stones. METHODS: Leveraging a dataset of manually 
      annotated ED reports, we developed strategies to enhance the performance of 
      GPT-4, GPT-3.5, and Llama-2 including prompt optimization, zero- and few-shot 
      prompting, fine-tuning, and prompt augmentation. Further, we implemented fairness 
      assessment and bias mitigation methods to investigate the potential disparities 
      by these LLMs with respect to race and gender. A clinical expert manually 
      assessed the explanations generated by GPT-4 for its predictions to determine if 
      they were sound, factually correct, unrelated to the input prompt, or potentially 
      harmful. The evaluation includes a comparison between LLMs, traditional machine 
      learning models (logistic regression, extreme gradient boosting, and light 
      gradient boosting machine), and a baseline system utilizing International 
      Classification of Diseases (ICD) codes for kidney stones. RESULTS: The best 
      results were achieved by GPT-4 (macro-F1=0.833, 95% confidence interval 
      [CI]=0.826-0.841) and GPT-3.5 (macro-F1=0.796, 95% CI=0.796-0.796), both being 
      statistically significantly better than the ICD-based baseline result 
      (macro-F1=0.71). Ablation studies revealed that the initial pre-trained GPT-3.5 
      model benefits from fine-tuning when using the same parameter configuration. 
      Adding demographic information and prior disease history to the prompts allows 
      LLMs to make more accurate decisions. The evaluation of bias found that GPT-4 
      exhibited no racial or gender disparities, in contrast to GPT-3.5, which failed 
      to effectively model racial diversity. The analysis of explanations provided by 
      GPT-4 demonstrates advanced capabilities of this model in understanding clinical 
      text and reasoning with medical knowledge.
FAU - Bejan, Cosmin A
AU  - Bejan CA
AUID- ORCID: 0000-0001-5107-0584
FAU - Reed, Amy M
AU  - Reed AM
FAU - Mikula, Matthew
AU  - Mikula M
FAU - Zhang, Siwei
AU  - Zhang S
AUID- ORCID: 0009-0005-0873-5217
FAU - Xu, Yaomin
AU  - Xu Y
AUID- ORCID: 0000-0002-3752-4006
FAU - Fabbri, Daniel
AU  - Fabbri D
AUID- ORCID: 0000-0003-0530-2510
FAU - Embí, Peter J
AU  - Embí PJ
AUID- ORCID: 0000-0002-7733-0847
FAU - Hsi, Ryan S
AU  - Hsi RS
AUID- ORCID: 0000-0003-1652-694X
LA  - eng
PT  - Journal Article
PT  - Preprint
DEP - 20240813
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - Sci Rep. 2025 Jan 28;15(1):3503. doi: 10.1038/s41598-025-86632-5. PMID: 39875475
PMC - PMC11361237
EDAT- 2024/08/31 09:49
MHDA- 2024/08/31 09:50
PMCR- 2024/08/29
CRDT- 2024/08/30 04:30
PHST- 2024/08/31 09:50 [medline]
PHST- 2024/08/31 09:49 [pubmed]
PHST- 2024/08/30 04:30 [entrez]
PHST- 2024/08/29 00:00 [pmc-release]
AID - 2024.08.12.24311870 [pii]
AID - 10.1101/2024.08.12.24311870 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Aug 13:2024.08.12.24311870. doi: 
      10.1101/2024.08.12.24311870.

PMID- 38826441
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241023
DP  - 2024 May 22
TI  - Large Language Models for Social Determinants of Health Information Extraction 
      from Clinical Notes - A Generalizable Approach across Institutions.
LID - 2024.05.21.24307726 [pii]
LID - 10.1101/2024.05.21.24307726 [doi]
AB  - The consistent and persuasive evidence illustrating the influence of social 
      determinants on health has prompted a growing realization throughout the health 
      care sector that enhancing health and health equity will likely depend, at least 
      to some extent, on addressing detrimental social determinants. However, detailed 
      social determinants of health (SDoH) information is often buried within clinical 
      narrative text in electronic health records (EHRs), necessitating natural 
      language processing (NLP) methods to automatically extract these details. Most 
      current NLP efforts for SDoH extraction have been limited, investigating on 
      limited types of SDoH elements, deriving data from a single institution, focusing 
      on specific patient cohorts or note types, with reduced focus on 
      generalizability. This study aims to address these issues by creating 
      cross-institutional corpora spanning different note types and healthcare systems, 
      and developing and evaluating the generalizability of classification models, 
      including novel large language models (LLMs), for detecting SDoH factors from 
      diverse types of notes from four institutions: Harris County Psychiatric Center, 
      University of Texas Physician Practice, Beth Israel Deaconess Medical Center, and 
      Mayo Clinic. Four corpora of deidentified clinical notes were annotated with 21 
      SDoH factors at two levels: level 1 with SDoH factor types only and level 2 with 
      SDoH factors along with associated values. Three traditional classification 
      algorithms (XGBoost, TextCNN, Sentence BERT) and an instruction tuned LLM-based 
      approach (LLaMA) were developed to identify multiple SDoH factors. Substantial 
      variation was noted in SDoH documentation practices and label distributions based 
      on patient cohorts, note types, and hospitals. The LLM achieved top performance 
      with micro-averaged F1 scores over 0.9 on level 1 annotated corpora and an F1 
      over 0.84 on level 2 annotated corpora. While models performed well when trained 
      and tested on individual datasets, cross-dataset generalization highlighted 
      remaining obstacles. To foster collaboration, access to partial annotated corpora 
      and models trained by merging all annotated datasets will be made available on 
      the PhysioNet repository.
FAU - Keloth, Vipina K
AU  - Keloth VK
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
FAU - Selek, Salih
AU  - Selek S
AD  - Department of Psychiatry and Behavioral Sciences, UTHealth McGovern Medical 
      School, Houston, TX, USA.
FAU - Chen, Qingyu
AU  - Chen Q
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
FAU - Gilman, Christopher
AU  - Gilman C
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
FAU - Fu, Sunyang
AU  - Fu S
AD  - McWilliams School of Biomedical Informatics, University of Texas Health Science 
      Center at Houston, Houston, TX, USA.
FAU - Dang, Yifang
AU  - Dang Y
AD  - McWilliams School of Biomedical Informatics, University of Texas Health Science 
      Center at Houston, Houston, TX, USA.
FAU - Chen, Xinghan
AU  - Chen X
AD  - School of Public Health, University of Texas Health Science Center at Houston, 
      Houston, TX, USA.
FAU - Hu, Xinyue
AU  - Hu X
AD  - Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 
      FL, USA.
FAU - Zhou, Yujia
AU  - Zhou Y
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
FAU - He, Huan
AU  - He H
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
FAU - Fan, Jungwei W
AU  - Fan JW
AD  - Department of Artificial Intelligence and Informatics, Mayo Clinic, Rochester, 
      MN, USA.
FAU - Wang, Karen
AU  - Wang K
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
AD  - Equity Research and Innovation Center, Yale School of Medicine, New Haven, CT, 
      USA.
FAU - Brandt, Cynthia
AU  - Brandt C
AUID- ORCID: 0000-0001-8179-1796
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
FAU - Tao, Cui
AU  - Tao C
AD  - Department of Artificial Intelligence and Informatics, Mayo Clinic, Jacksonville, 
      FL, USA.
AD  - Department of Artificial Intelligence and Informatics, Mayo Clinic, Rochester, 
      MN, USA.
FAU - Liu, Hongfang
AU  - Liu H
AD  - McWilliams School of Biomedical Informatics, University of Texas Health Science 
      Center at Houston, Houston, TX, USA.
FAU - Xu, Hua
AU  - Xu H
AD  - Department of Biomedical Informatics and Data Science, Yale School of Medicine, 
      New Haven, CT, USA.
LA  - eng
GR  - R01 AG083039/AG/NIA NIH HHS/United States
GR  - R01 AG084236/AG/NIA NIH HHS/United States
GR  - RF1 AG072799/AG/NIA NIH HHS/United States
GR  - RM1 HG011558/HG/NHGRI NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240522
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11142292
OTO - NOTNLM
OT  - Social determinants of health
OT  - electronic health records
OT  - large language models
OT  - multi-label classification
COIS- Competing interests All authors declare no financial or non-financial competing 
      interests.
EDAT- 2024/06/03 06:42
MHDA- 2024/06/03 06:43
PMCR- 2024/05/31
CRDT- 2024/06/03 04:09
PHST- 2024/06/03 06:42 [pubmed]
PHST- 2024/06/03 06:43 [medline]
PHST- 2024/06/03 04:09 [entrez]
PHST- 2024/05/31 00:00 [pmc-release]
AID - 2024.05.21.24307726 [pii]
AID - 10.1101/2024.05.21.24307726 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 May 22:2024.05.21.24307726. doi: 
      10.1101/2024.05.21.24307726.

PMID- 38266214
OWN - NLM
STAT- MEDLINE
DCOM- 20240426
LR  - 20240607
IS  - 1938-808X (Electronic)
IS  - 1040-2446 (Linking)
VI  - 99
IP  - 5
DP  - 2024 May 1
TI  - The Promise and Perils of Artificial Intelligence in Health Professions Education 
      Practice and Scholarship.
PG  - 477-481
LID - 10.1097/ACM.0000000000005636 [doi]
AB  - Artificial intelligence (AI) methods, especially machine learning and natural 
      language processing, are increasingly affecting health professions education 
      (HPE), including the medical school application and selection processes, 
      assessment, and scholarship production. The rise of large language models over 
      the past 18 months, such as ChatGPT, has raised questions about how best to 
      incorporate these methods into HPE. The lack of training in AI among most HPE 
      faculty and scholars poses an important challenge in facilitating such 
      discussions. In this commentary, the authors provide a primer on the AI methods 
      most often used in the practice and scholarship of HPE, discuss the most pressing 
      challenges and opportunities these tools afford, and underscore that these 
      methods should be understood as part of the larger set of statistical tools 
      available.Despite their ability to process huge amounts of data and their high 
      performance completing some tasks, AI methods are only as good as the data on 
      which they are trained. Of particular importance is that these models can 
      perpetuate the biases that are present in those training datasets, and they can 
      be applied in a biased manner by human users. A minimum set of expectations for 
      the application of AI methods in HPE practice and scholarship is discussed in 
      this commentary, including the interpretability of the models developed and the 
      transparency needed into the use and characteristics of such methods.The rise of 
      AI methods is affecting multiple aspects of HPE including raising questions about 
      how best to incorporate these models into HPE practice and scholarship. In this 
      commentary, we provide a primer on the AI methods most often used in HPE and 
      discuss the most pressing challenges and opportunities these tools afford.
CI  - Copyright © 2024 the Association of American Medical Colleges.
FAU - Patino, Gustavo A
AU  - Patino GA
AUID- ORCID: 0000-0003-1866-5572
FAU - Amiel, Jonathan M
AU  - Amiel JM
AUID- ORCID: 0000-0003-4027-6397
FAU - Brown, Megan
AU  - Brown M
AUID- ORCID: 0000-0002-9334-0922
FAU - Lypson, Monica L
AU  - Lypson ML
AUID- ORCID: 0000-0002-1450-9380
FAU - Chan, Teresa M
AU  - Chan TM
AUID- ORCID: 0000-0001-6104-462
LA  - eng
PT  - Journal Article
DEP - 20240124
PL  - United States
TA  - Acad Med
JT  - Academic medicine : journal of the Association of American Medical Colleges
JID - 8904605
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Health Occupations/education
MH  - Fellowships and Scholarships/methods
MH  - Natural Language Processing
MH  - Machine Learning
MH  - Education, Medical/methods
EDAT- 2024/01/24 18:42
MHDA- 2024/04/26 18:53
CRDT- 2024/01/24 16:03
PHST- 2024/04/26 18:53 [medline]
PHST- 2024/01/24 18:42 [pubmed]
PHST- 2024/01/24 16:03 [entrez]
AID - 00001888-202405000-00007 [pii]
AID - 10.1097/ACM.0000000000005636 [doi]
PST - ppublish
SO  - Acad Med. 2024 May 1;99(5):477-481. doi: 10.1097/ACM.0000000000005636. Epub 2024 
      Jan 24.

PMID- 38804330
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240530
IS  - 2409-9279 (Electronic)
IS  - 2409-9279 (Linking)
VI  - 7
IP  - 3
DP  - 2024 Apr 24
TI  - Simplifying Data Analysis in Biomedical Research: An Automated, User-Friendly 
      Tool.
LID - 10.3390/mps7030036 [doi]
LID - 36
AB  - Robust data normalization and analysis are pivotal in biomedical research to 
      ensure that observed differences in populations are directly attributable to the 
      target variable, rather than disparities between control and study groups. 
      ArsHive addresses this challenge using advanced algorithms to normalize 
      populations (e.g., control and study groups) and perform statistical evaluations 
      between demographic, clinical, and other variables within biomedical datasets, 
      resulting in more balanced and unbiased analyses. The tool's functionality 
      extends to comprehensive data reporting, which elucidates the effects of data 
      processing, while maintaining dataset integrity. Additionally, ArsHive is 
      complemented by A.D.A. (Autonomous Digital Assistant), which employs OpenAI's 
      GPT-4 model to assist researchers with inquiries, enhancing the decision-making 
      process. In this proof-of-concept study, we tested ArsHive on three different 
      datasets derived from proprietary data, demonstrating its effectiveness in 
      managing complex clinical and therapeutic information and highlighting its 
      versatility for diverse research fields.
FAU - Araújo, Rúben
AU  - Araújo R
AUID- ORCID: 0000-0002-9369-6486
AD  - NMS-NOVA Medical School, FCM-Faculdade de Ciências Médicas, Universidade NOVA de 
      Lisboa, Campo Mártires da Pátria 130, 1169-056 Lisbon, Portugal.
AD  - CHRC-Comprehensive Health Research Centre, Universidade NOVA de Lisboa, 1150-082 
      Lisbon, Portugal.
AD  - ISEL-Instituto Superior de Engenharia de Lisboa, Instituto Politécnico de Lisboa, 
      Rua Conselheiro Emídio Navarro 1, 1959-007 Lisbon, Portugal.
FAU - Ramalhete, Luís
AU  - Ramalhete L
AUID- ORCID: 0000-0002-8911-3380
AD  - NMS-NOVA Medical School, FCM-Faculdade de Ciências Médicas, Universidade NOVA de 
      Lisboa, Campo Mártires da Pátria 130, 1169-056 Lisbon, Portugal.
AD  - Blood and Transplantation Center of Lisbon, IPST-Instituto Português do Sangue e 
      da Transplantação, Alameda das Linhas de Torres 117, 1769-001 Lisbon, Portugal.
AD  - iNOVA4Health-Advancing Precision Medicine, RG11: Reno-Vascular Diseases Group, 
      NMS-NOVA Medical School, FCM-Faculdade de Ciências Médicas, Universidade NOVA de 
      Lisboa, 1169-056 Lisbon, Portugal.
FAU - Viegas, Ana
AU  - Viegas A
AD  - CHRC-Comprehensive Health Research Centre, Universidade NOVA de Lisboa, 1150-082 
      Lisbon, Portugal.
AD  - ESTeSL-Escola Superior de Tecnologia da Saúde de Lisboa, Instituto Politécnico de 
      Lisboa, Avenida D. João II, Lote 4.69.01, 1990-096 Lisbon, Portugal.
AD  - Neurosciences Area, Clinical Neurophysiology Unit, ULSSJ-Unidade Local de Saúde 
      São José, Rua José António Serrano, 1150-199 Lisbon, Portugal.
FAU - Von Rekowski, Cristiana P
AU  - Von Rekowski CP
AUID- ORCID: 0009-0009-6843-1935
AD  - NMS-NOVA Medical School, FCM-Faculdade de Ciências Médicas, Universidade NOVA de 
      Lisboa, Campo Mártires da Pátria 130, 1169-056 Lisbon, Portugal.
AD  - CHRC-Comprehensive Health Research Centre, Universidade NOVA de Lisboa, 1150-082 
      Lisbon, Portugal.
AD  - ISEL-Instituto Superior de Engenharia de Lisboa, Instituto Politécnico de Lisboa, 
      Rua Conselheiro Emídio Navarro 1, 1959-007 Lisbon, Portugal.
FAU - Fonseca, Tiago A H
AU  - Fonseca TAH
AUID- ORCID: 0000-0003-0741-2211
AD  - NMS-NOVA Medical School, FCM-Faculdade de Ciências Médicas, Universidade NOVA de 
      Lisboa, Campo Mártires da Pátria 130, 1169-056 Lisbon, Portugal.
AD  - CHRC-Comprehensive Health Research Centre, Universidade NOVA de Lisboa, 1150-082 
      Lisbon, Portugal.
AD  - ISEL-Instituto Superior de Engenharia de Lisboa, Instituto Politécnico de Lisboa, 
      Rua Conselheiro Emídio Navarro 1, 1959-007 Lisbon, Portugal.
FAU - Calado, Cecília R C
AU  - Calado CRC
AUID- ORCID: 0000-0002-5264-9755
AD  - ISEL-Instituto Superior de Engenharia de Lisboa, Instituto Politécnico de Lisboa, 
      Rua Conselheiro Emídio Navarro 1, 1959-007 Lisbon, Portugal.
AD  - Institute for Bioengineering and Biosciences (iBB), The Associate Laboratory 
      Institute for Health and Bioeconomy-i4HB, Instituto Superior Técnico (IST), 
      Universidade de Lisboa (UL), Av. Rovisco Pais, 1049-001 Lisboa, Portugal.
FAU - Bento, Luís
AU  - Bento L
AUID- ORCID: 0000-0002-0260-003X
AD  - Intensive Care Department, ULSSJ-Unidade Local de Saúde São José, Rua José 
      António Serrano, 1150-199 Lisbon, Portugal.
AD  - Integrated Pathophysiological Mechanisms, CHRC-Comprehensive Health Research 
      Centre, NMS-NOVA Medical School, FCM-Faculdade de Ciências Médicas, Universidade 
      NOVA de Lisboa, Campo Mártires da Pátria 130, 1169-056 Lisbon, Portugal.
LA  - eng
PT  - Journal Article
DEP - 20240424
PL  - Switzerland
TA  - Methods Protoc
JT  - Methods and protocols
JID - 101720073
PMC - PMC11130801
OTO - NOTNLM
OT  - LLM models
OT  - biomedical research
OT  - high dimensional data analysis
OT  - machine learning
COIS- The authors declare no conflicts of interest.
EDAT- 2024/05/28 12:43
MHDA- 2024/05/28 12:44
PMCR- 2024/04/24
CRDT- 2024/05/28 06:54
PHST- 2024/03/11 00:00 [received]
PHST- 2024/04/20 00:00 [revised]
PHST- 2024/04/22 00:00 [accepted]
PHST- 2024/05/28 12:44 [medline]
PHST- 2024/05/28 12:43 [pubmed]
PHST- 2024/05/28 06:54 [entrez]
PHST- 2024/04/24 00:00 [pmc-release]
AID - mps7030036 [pii]
AID - mps-07-00036 [pii]
AID - 10.3390/mps7030036 [doi]
PST - epublish
SO  - Methods Protoc. 2024 Apr 24;7(3):36. doi: 10.3390/mps7030036.

PMID- 39176994
OWN - NLM
STAT- MEDLINE
DCOM- 20241107
LR  - 20241123
IS  - 1759-2887 (Electronic)
IS  - 1759-2879 (Linking)
VI  - 15
IP  - 6
DP  - 2024 Nov
TI  - Zero- and few-shot prompting of generative large language models provides weak 
      assessment of risk of bias in clinical trials.
PG  - 988-1000
LID - 10.1002/jrsm.1749 [doi]
AB  - Existing systems for automating the assessment of risk-of-bias (RoB) in medical 
      studies are supervised approaches that require substantial training data to work 
      well. However, recent revisions to RoB guidelines have resulted in a scarcity of 
      available training data. In this study, we investigate the effectiveness of 
      generative large language models (LLMs) for assessing RoB. Their application 
      requires little or no training data and, if successful, could serve as a valuable 
      tool to assist human experts during the construction of systematic reviews. 
      Following Cochrane's latest guidelines (RoB2) designed for human reviewers, we 
      prepare instructions that are fed as input to LLMs, which then infer the risk 
      associated with a trial publication. We distinguish between two modelling tasks: 
      directly predicting RoB2 from text; and employing decomposition, in which a RoB2 
      decision is made after the LLM responds to a series of signalling questions. We 
      curate new testing data sets and evaluate the performance of four general- and 
      medical-domain LLMs. The results fall short of expectations, with LLMs seldom 
      surpassing trivial baselines. On the direct RoB2 prediction test set (n = 5993), 
      LLMs perform akin to the baselines (F1: 0.1-0.2). In the decomposition task setup 
      (n = 28,150), similar F1 scores are observed. Our additional comparative 
      evaluation on RoB1 data also reveals results substantially below those of a 
      supervised system. This testifies to the difficulty of solving this task based on 
      (complex) instructions alone. Using LLMs as an assisting technology for assessing 
      RoB2 thus currently seems beyond their reach.
CI  - © 2024 The Author(s). Research Synthesis Methods published by John Wiley & Sons 
      Ltd.
FAU - Šuster, Simon
AU  - Šuster S
AUID- ORCID: 0000-0002-8817-8545
AD  - School of Computing and Information Systems, The University of Melbourne, 
      Melbourne, Victoria, Australia.
FAU - Baldwin, Timothy
AU  - Baldwin T
AD  - Department of Natural Language Processing, MBZUAI, Abu Dhabi, United Arab 
      Emirates.
FAU - Verspoor, Karin
AU  - Verspoor K
AUID- ORCID: 0000-0002-8661-1544
AD  - School of Computing and Information Systems, The University of Melbourne, 
      Melbourne, Victoria, Australia.
AD  - School of Computing Technologies, RMIT University, Melbourne, Victoria, 
      Australia.
LA  - eng
GR  - IC170100030/Australian Research Council/
PT  - Journal Article
DEP - 20240823
PL  - England
TA  - Res Synth Methods
JT  - Research synthesis methods
JID - 101543738
SB  - IM
MH  - Humans
MH  - *Algorithms
MH  - *Bias
MH  - *Clinical Trials as Topic
MH  - Models, Statistical
MH  - *Natural Language Processing
MH  - Publication Bias
MH  - Reproducibility of Results
MH  - Research Design
MH  - Risk
MH  - Risk Assessment/methods
MH  - Systematic Reviews as Topic/methods
OTO - NOTNLM
OT  - ChatGPT
OT  - evidence synthesis
OT  - large language models
OT  - quality assessment
OT  - risk of bias
OT  - systematic review automation
EDAT- 2024/08/23 06:41
MHDA- 2024/11/07 10:19
CRDT- 2024/08/23 05:23
PHST- 2024/06/26 00:00 [revised]
PHST- 2024/03/19 00:00 [received]
PHST- 2024/08/05 00:00 [accepted]
PHST- 2024/11/07 10:19 [medline]
PHST- 2024/08/23 06:41 [pubmed]
PHST- 2024/08/23 05:23 [entrez]
AID - 10.1002/jrsm.1749 [doi]
PST - ppublish
SO  - Res Synth Methods. 2024 Nov;15(6):988-1000. doi: 10.1002/jrsm.1749. Epub 2024 Aug 
      23.

PMID- 34867743
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240819
IS  - 1664-2295 (Print)
IS  - 1664-2295 (Electronic)
IS  - 1664-2295 (Linking)
VI  - 12
DP  - 2021
TI  - Focal Seizures and Posterior Reversible Encephalopathy Syndrome as Presenting 
      Signs of IgA Vasculitis/Henoch-Schoenlein Purpura-An Educative Case and 
      Systematic Review of the Literature.
PG  - 759386
LID - 10.3389/fneur.2021.759386 [doi]
LID - 759386
AB  - Background: IgA vasculitis/Henoch-Schoenlein purpura (IgAV/HSP) is a systemic 
      small vessel vasculitis of unknown pathogenesis predominantly affecting children. 
      While skin, GI tract, joints, and kidneys are frequently affected and considered, 
      central nervous system (CNS) involvement of this disease is underestimated. 
      Methods: We provide a case report and systematically review the literature on 
      IgAV, collecting data on the spectrum of neurological manifestations. Results: We 
      report on a 7-year-old girl with IgAV who presented with diplopia and afebrile 
      focal seizures, which preceded the onset of purpura. Cranial magnetic resonance 
      imaging was consistent with posterior reversible encephalopathy syndrome (PRES), 
      showing typical focal bilateral parietal swelling and cortical and subcortical 
      high signal intensities on T2-fluid attenuated inversion recovery (FLAIR) images 
      predominantly without diffusion restriction. Cerebrospinal fluid analysis and 
      blood tests excluded systemic inflammation or vasculitis. Interestingly, 
      hypertension was not a hallmark of the developing disease in the initial phase of 
      PRES manifestation. Renal disease and other secondary causes for PRES were also 
      excluded. Supportive- and steroid treatment resulted in restitution ad integrum. 
      Reviewing the literature, we identified 28 other cases of IgAV with CNS 
      involvement. Severe CNS involvement includes seizures, cerebral edema, or 
      hemorrhage, as well as PRES. Thirteen patients fulfilled all diagnostic criteria 
      of PRES. The mean age was 11.2 years (median 8.0, range 5-42 years), with no 
      reported bias toward gender or ethnic background. Treatment regimens varied from 
      watchful waiting to oral and intravenously steroids up to plasmapheresis. Three 
      cases showed permanent CNS impairment. Conclusion: Collectively, our data 
      demonstrate that (I) severe CNS involvement such as PRES is an underappreciated 
      feature of IgAV, (II) CNS symptoms may precede other features of IgAV, (III) PRES 
      can occur in IgAV, and differentiation from CNS vasculitis is challenging, (IV) 
      pathogenesis of PRES in the context of IgAV remains elusive, which hampers 
      treatment decisions. We, therefore, conclude that clinical awareness and the 
      collection of structured data are necessary to elucidate the pathophysiological 
      connection of IgAV and PRES.
CI  - Copyright © 2021 Funken, Götz, Bültmann, Hennies, Gburek-Augustat, Hempel, 
      Dressler, Baumann and Klemann.
FAU - Funken, Dominik
AU  - Funken D
AD  - Department of Pediatric Pneumology, Allergology and Neonatology, Hannover Medical 
      School, Hanover, Germany.
FAU - Götz, Friedrich
AU  - Götz F
AD  - Institute of Diagnostic and Interventional Neuroradiology, Hannover Medical 
      School, Hanover, Germany.
FAU - Bültmann, Eva
AU  - Bültmann E
AD  - Institute of Diagnostic and Interventional Neuroradiology, Hannover Medical 
      School, Hanover, Germany.
FAU - Hennies, Imke
AU  - Hennies I
AD  - Department of Pediatric Nephrology, Hepatology and Metabolic Disorders, Hannover 
      Medical School, Hanover, Germany.
FAU - Gburek-Augustat, Janina
AU  - Gburek-Augustat J
AD  - Division of Neuropediatrics, Hospital for Children and Adolescents, University 
      Hospital Leipzig, Leipzig, Germany.
FAU - Hempel, Julya
AU  - Hempel J
AD  - Department of Pediatric Nephrology, Hepatology and Metabolic Disorders, Hannover 
      Medical School, Hanover, Germany.
FAU - Dressler, Frank
AU  - Dressler F
AD  - Department of Pediatric Pneumology, Allergology and Neonatology, Hannover Medical 
      School, Hanover, Germany.
FAU - Baumann, Ulrich
AU  - Baumann U
AD  - Department of Pediatric Pneumology, Allergology and Neonatology, Hannover Medical 
      School, Hanover, Germany.
FAU - Klemann, Christian
AU  - Klemann C
AD  - Department of Pediatric Pneumology, Allergology and Neonatology, Hannover Medical 
      School, Hanover, Germany.
LA  - eng
PT  - Journal Article
DEP - 20211115
PL  - Switzerland
TA  - Front Neurol
JT  - Frontiers in neurology
JID - 101546899
PMC - PMC8634645
OTO - NOTNLM
OT  - CNS involvement
OT  - Henoch-Schönlein purpura (HSP)
OT  - IgA vasculitis
OT  - cerebral vasculitis
OT  - encephalopathy syndrome
OT  - review
OT  - small-vessel vasculitis
OT  - treatment
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2021/12/07 06:00
MHDA- 2021/12/07 06:01
PMCR- 2021/11/15
CRDT- 2021/12/06 09:06
PHST- 2021/08/16 00:00 [received]
PHST- 2021/10/04 00:00 [accepted]
PHST- 2021/12/06 09:06 [entrez]
PHST- 2021/12/07 06:00 [pubmed]
PHST- 2021/12/07 06:01 [medline]
PHST- 2021/11/15 00:00 [pmc-release]
AID - 10.3389/fneur.2021.759386 [doi]
PST - epublish
SO  - Front Neurol. 2021 Nov 15;12:759386. doi: 10.3389/fneur.2021.759386. eCollection 
      2021.

PMID- 38046089
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241014
IS  - 2472-5390 (Electronic)
IS  - 2472-5390 (Linking)
VI  - 7
IP  - 6
DP  - 2023 Dec
TI  - Brain versus bot: Distinguishing letters of recommendation authored by humans 
      compared with artificial intelligence.
LID - 10.1002/aet2.10924 [doi]
AB  - OBJECTIVES: Letters of recommendation (LORs) are essential within academic 
      medicine, affecting a number of important decisions regarding advancement, yet 
      these letters take significant amounts of time and labor to prepare. The use of 
      generative artificial intelligence (AI) tools, such as ChatGPT, are gaining 
      popularity for a variety of academic writing tasks and offer an innovative 
      solution to relieve the burden of letter writing. It is yet to be determined if 
      ChatGPT could aid in crafting LORs, particularly in high-stakes contexts like 
      faculty promotion. To determine the feasibility of this process and whether there 
      is a significant difference between AI and human-authored letters, we conducted a 
      study aimed at determining whether academic physicians can distinguish between 
      the two. METHODS: A quasi-experimental study was conducted using a single-blind 
      design. Academic physicians with experience in reviewing LORs were presented with 
      LORs for promotion to associate professor, written by either humans or AI. 
      Participants reviewed LORs and identified the authorship. Statistical analysis 
      was performed to determine accuracy in distinguishing between human and 
      AI-authored LORs. Additionally, the perceived quality and persuasiveness of the 
      LORs were compared based on suspected and actual authorship. RESULTS: A total of 
      32 participants completed letter review. The mean accuracy of distinguishing 
      between human- versus AI-authored LORs was 59.4%. The reviewer's certainty and 
      time spent deliberating did not significantly impact accuracy. LORs suspected to 
      be human-authored were rated more favorably in terms of quality and 
      persuasiveness. A difference in gender-biased language was observed in our 
      letters: human-authored letters contained significantly more female-associated 
      words, while the majority of AI-authored letters tended to use more 
      male-associated words. CONCLUSIONS: Participants were unable to reliably 
      differentiate between human- and AI-authored LORs for promotion. AI may be able 
      to generate LORs and relieve the burden of letter writing for academicians. New 
      strategies, policies, and guidelines are needed to balance the benefits of AI 
      while preserving integrity and fairness in academic promotion decisions.
CI  - © 2023 The Authors. AEM Education and Training published by Wiley Periodicals LLC 
      on behalf of Society for Academic Emergency Medicine.
FAU - Preiksaitis, Carl
AU  - Preiksaitis C
AUID- ORCID: 0000-0002-3856-0068
AD  - Department of Emergency Medicine Stanford School of Medicine Stanford California 
      USA.
FAU - Nash, Christopher
AU  - Nash C
AUID- ORCID: 0000-0002-0738-409X
AD  - Department of Emergency Medicine Massachusetts General Hospital Boston 
      Massachusetts USA.
FAU - Gottlieb, Michael
AU  - Gottlieb M
AUID- ORCID: 0000-0003-3276-8375
AD  - Department of Emergency Medicine Rush University Medical Center Chicago Illinois 
      USA.
FAU - Chan, Teresa M
AU  - Chan TM
AUID- ORCID: 0000-0001-6104-462X
AD  - Division of Emergency Medicine, Department of Medicine McMaster University 
      Hamilton Ontario Canada.
FAU - Alvarez, Al'ai
AU  - Alvarez A
AUID- ORCID: 0000-0002-5438-2476
AD  - Department of Emergency Medicine Stanford School of Medicine Stanford California 
      USA.
FAU - Landry, Adaira
AU  - Landry A
AUID- ORCID: 0000-0002-5299-679X
AD  - Department of Emergency Medicine Harvard Medical School Boston Massachusetts USA.
LA  - eng
PT  - Journal Article
DEP - 20231130
PL  - United States
TA  - AEM Educ Train
JT  - AEM education and training
JID - 101722142
PMC - PMC10688127
COIS- The authors declare no conflicts of interest.
EDAT- 2023/12/04 06:42
MHDA- 2023/12/04 06:43
PMCR- 2023/12/01
CRDT- 2023/12/04 04:49
PHST- 2023/06/25 00:00 [received]
PHST- 2023/09/16 00:00 [revised]
PHST- 2023/09/18 00:00 [accepted]
PHST- 2023/12/04 06:43 [medline]
PHST- 2023/12/04 06:42 [pubmed]
PHST- 2023/12/04 04:49 [entrez]
PHST- 2023/12/01 00:00 [pmc-release]
AID - AET210924 [pii]
AID - 10.1002/aet2.10924 [doi]
PST - epublish
SO  - AEM Educ Train. 2023 Nov 30;7(6):10.1002/aet2.10924. doi: 10.1002/aet2.10924. 
      eCollection 2023 Dec.

PMID- 38152714
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231229
IS  - 2169-7574 (Print)
IS  - 2169-7574 (Electronic)
IS  - 2169-7574 (Linking)
VI  - 11
IP  - 9
DP  - 2023 Sep
TI  - Navigating the Ethical Landmines of ChatGPT: Implications of Intelligent Chatbots 
      in Plastic Surgery Clinical Practice.
PG  - e5290
LID - 10.1097/GOX.0000000000005290 [doi]
LID - e5290
AB  - ChatGPT is a cutting-edge language model developed by OpenAI with the potential 
      to impact all facets of plastic surgery from research to clinical practice. New 
      applications for ChatGPT are emerging at a rapid pace in both the scientific 
      literature and popular media. It is important for clinicians to understand the 
      capabilities and limitations of these tools before patient-facing implementation. 
      In this article, the authors explore some of the technical details behind 
      ChatGPT: what it is, and what it is not. As with any emerging technology, 
      attention should be given to the ethical and health equity implications of this 
      technology on our plastic surgery patients. The authors explore these concerns 
      within the framework of the foundational principles of biomedical ethics: patient 
      autonomy, nonmaleficence, beneficence, and justice. ChatGPT and similar 
      intelligent conversation agents have incredible promise in the field of plastic 
      surgery but should be used cautiously and sparingly in their current form. To 
      protect patients, it is imperative that societal guidelines for the safe use of 
      this rapidly developing technology are developed.
CI  - Copyright © 2023 The Authors. Published by Wolters Kluwer Health, Inc. on behalf 
      of The American Society of Plastic Surgeons.
FAU - Oleck, Nicholas C
AU  - Oleck NC
AD  - From the Division of Plastic, Maxillofacial and Oral Surgery, Duke University 
      Medical Center, Durham, N.C.
FAU - Naga, Hani I
AU  - Naga HI
AD  - From the Division of Plastic, Maxillofacial and Oral Surgery, Duke University 
      Medical Center, Durham, N.C.
FAU - Nichols, D Spencer
AU  - Nichols DS
AD  - From the Division of Plastic, Maxillofacial and Oral Surgery, Duke University 
      Medical Center, Durham, N.C.
FAU - Morris, Miranda X
AU  - Morris MX
AD  - From the Division of Plastic, Maxillofacial and Oral Surgery, Duke University 
      Medical Center, Durham, N.C.
FAU - Dhingra, Bhuwan
AU  - Dhingra B
AD  - Department of Computer Science, Duke University, Durham, N.C.
FAU - Patel, Ash
AU  - Patel A
AD  - From the Division of Plastic, Maxillofacial and Oral Surgery, Duke University 
      Medical Center, Durham, N.C.
LA  - eng
PT  - Journal Article
DEP - 20230915
PL  - United States
TA  - Plast Reconstr Surg Glob Open
JT  - Plastic and reconstructive surgery. Global open
JID - 101622231
PMC - PMC10752483
COIS- The authors have no financial interest to declare in relation to the content of 
      this article. Disclosure statements are at the end of this article, following the 
      correspondence information.
EDAT- 2023/12/28 06:42
MHDA- 2023/12/28 06:43
PMCR- 2023/09/15
CRDT- 2023/12/28 04:17
PHST- 2023/07/27 00:00 [received]
PHST- 2023/08/09 00:00 [accepted]
PHST- 2023/12/28 06:43 [medline]
PHST- 2023/12/28 06:42 [pubmed]
PHST- 2023/12/28 04:17 [entrez]
PHST- 2023/09/15 00:00 [pmc-release]
AID - 10.1097/GOX.0000000000005290 [doi]
PST - epublish
SO  - Plast Reconstr Surg Glob Open. 2023 Sep 15;11(9):e5290. doi: 
      10.1097/GOX.0000000000005290. eCollection 2023 Sep.

PMID- 40050981
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250309
IS  - 1753-6561 (Print)
IS  - 1753-6561 (Electronic)
IS  - 1753-6561 (Linking)
VI  - 19
IP  - Suppl 4
DP  - 2025 Mar 6
TI  - Harnessing the power of artificial intelligence for disease-surveillance 
      purposes.
PG  - 7
LID - 10.1186/s12919-025-00320-w [doi]
LID - 7
AB  - The COVID-19 pandemic accelerated the development of AI-driven tools to improve 
      public health surveillance and outbreak management. While AI programs have shown 
      promise in disease surveillance, they also present issues such as data privacy, 
      prejudice, and human-AI interactions. This sixth session of the of the WHO 
      Pandemic and Epidemic Intelligence Innovation Forum examines the use of 
      Artificial Intelligence (AI) in public health by collecting the experience of key 
      global health organizations, such the Boston Children's Hospital, the Global 
      South AI for Pandemic & Epidemic Preparedness & Response (AI4PEP) network, 
      Medicines Sans Frontières (MSF), and the University of Sydney. AI's utility in 
      clinical care, particularly in diagnostics, medication discovery, and data 
      processing, has resulted in improvements that may also benefit public health 
      surveillance. However, the use of AI in global health necessitates careful 
      consideration of ethical issues, particularly those involving data use and 
      algorithmic bias. As AI advances, particularly with large language models, public 
      health officials must develop governance frameworks that stress openness, 
      accountability, and fairness. These systems should address worldwide differences 
      in data access and ensure that AI technologies are tailored to specific local 
      needs. Ultimately, AI's ability to improve healthcare efficiency and equity is 
      dependent on multidisciplinary collaboration, community involvement, and 
      inclusive AI designs in ensuring equitable healthcare outcomes to fit the unique 
      demands of global communities.
CI  - © 2025. The Author(s).
FAU - Tornimbene, Barbara
AU  - Tornimbene B
AD  - World Health Organization Hub for Pandemic and Epidemic Intelligence, Berlin, 
      Germany. tornimbeneb@who.int.
FAU - Leiva Rioja, Zoila Beatriz
AU  - Leiva Rioja ZB
AD  - CPC Analytics, Berlin, Germany.
FAU - Brownstein, John
AU  - Brownstein J
AD  - Boston Children'S Hospital, Boston, MA, USA.
FAU - Dunn, Adam
AU  - Dunn A
AD  - University of Sydney, Sydney, Australia.
FAU - Faye, Sylvain
AU  - Faye S
AD  - Global South AI for Pandemic & Epidemic Preparedness & Response Network (Ai4pep), 
      Toronto, Canada.
FAU - Kong, Jude
AU  - Kong J
AD  - Global South AI for Pandemic & Epidemic Preparedness & Response Network (Ai4pep), 
      Toronto, Canada.
FAU - Malou, Nada
AU  - Malou N
AD  - Medecins Sans Frontières (MSF), Paris, France.
FAU - Nordon, Clara
AU  - Nordon C
AD  - Medecins Sans Frontières (MSF), Paris, France.
FAU - Rader, Benjamin
AU  - Rader B
AD  - Boston Children'S Hospital, Boston, MA, USA.
FAU - Morgan, Oliver
AU  - Morgan O
AD  - World Health Organization Hub for Pandemic and Epidemic Intelligence, Berlin, 
      Germany.
LA  - eng
PT  - Journal Article
DEP - 20250306
PL  - England
TA  - BMC Proc
JT  - BMC proceedings
JID - 101316936
PMC - PMC11887143
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Data privacy
OT  - Infectious disease
OT  - Multidisciplinary collaboration
OT  - Public health surveillance
COIS- Declarations. Ethics approval and consent to participate: As this manuscript 
      reports on the proceedings of a forum, rather than a research study, ethical 
      approval was not sought. Instead, explicit written permission was sought and 
      obtained from all presenters featured in this manuscript. These permissions 
      covered the exact text describing their presentation and any images or 
      photographs reproduced. Consent for publication: The meeting organized by WHO was 
      by invitation only. All participants accepted the invitation and attended the 
      meeting out of their free will. All participants have signed the agreement prior 
      to gaining access to the Virtual meeting. All participants signed the authorship 
      agreement for publication of the meeting report. Competing interests: The meeting 
      was organized by WHO. The authors have no competing interests to declare.
EDAT- 2025/03/07 00:21
MHDA- 2025/03/07 00:22
PMCR- 2025/03/06
CRDT- 2025/03/06 23:46
PHST- 2025/03/07 00:22 [medline]
PHST- 2025/03/07 00:21 [pubmed]
PHST- 2025/03/06 23:46 [entrez]
PHST- 2025/03/06 00:00 [pmc-release]
AID - 10.1186/s12919-025-00320-w [pii]
AID - 320 [pii]
AID - 10.1186/s12919-025-00320-w [doi]
PST - epublish
SO  - BMC Proc. 2025 Mar 6;19(Suppl 4):7. doi: 10.1186/s12919-025-00320-w.

PMID- 39156049
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240820
IS  - 2055-2076 (Print)
IS  - 2055-2076 (Electronic)
IS  - 2055-2076 (Linking)
VI  - 10
DP  - 2024 Jan-Dec
TI  - Evaluating cognitive performance: Traditional methods vs. ChatGPT.
PG  - 20552076241264639
LID - 10.1177/20552076241264639 [doi]
LID - 20552076241264639
AB  - BACKGROUND: NLP models like ChatGPT promise to revolutionize text-based content 
      delivery, particularly in medicine. Yet, doubts remain about ChatGPT's ability to 
      reliably support evaluations of cognitive performance, warranting further 
      investigation into its accuracy and comprehensiveness in this area. METHOD: A 
      cohort of 60 cognitively normal individuals and 30 stroke survivors underwent a 
      comprehensive evaluation, covering memory, numerical processing, verbal fluency, 
      and abstract thinking. Healthcare professionals and NLP models GPT-3.5 and GPT-4 
      conducted evaluations following established standards. Scores were compared, and 
      efforts were made to refine scoring protocols and interaction methods to enhance 
      ChatGPT's potential in these evaluations. RESULT: Within the cohort of healthy 
      participants, the utilization of GPT-3.5 revealed significant disparities in 
      memory evaluation compared to both physician-led assessments and those conducted 
      utilizing GPT-4 (P < 0.001). Furthermore, within the domain of memory evaluation, 
      GPT-3.5 exhibited discrepancies in 8 out of 21 specific measures when compared to 
      assessments conducted by physicians (P < 0.05). Additionally, GPT-3.5 
      demonstrated statistically significant deviations from physician assessments in 
      speech evaluation (P = 0.009). Among participants with a history of stroke, 
      GPT-3.5 exhibited differences solely in verbal assessment compared to 
      physician-led evaluations (P = 0.002). Notably, through the implementation of 
      optimized scoring methodologies and refinement of interaction protocols, partial 
      mitigation of these disparities was achieved. CONCLUSION: ChatGPT can produce 
      evaluation outcomes comparable to traditional methods. Despite differences from 
      physician evaluations, refinement of scoring algorithms and interaction protocols 
      has improved alignment. ChatGPT performs well even in populations with specific 
      conditions like stroke, suggesting its versatility. GPT-4 yields results closer 
      to physician ratings, indicating potential for further enhancement. These 
      findings highlight ChatGPT's importance as a supplementary tool, offering new 
      avenues for information gathering in medical fields and guiding its ongoing 
      development and application.
CI  - © The Author(s) 2024.
FAU - Fei, Xiao
AU  - Fei X
AUID- ORCID: 0000-0002-4026-2115
AD  - Department of Rehabilitation Medicine, The First People's Hospital of Changzhou, 
      Changzhou, China. RINGGOLD: 117850
FAU - Tang, Ying
AU  - Tang Y
AD  - Department of Rehabilitation Medicine, The First People's Hospital of Changzhou, 
      Changzhou, China. RINGGOLD: 117850
FAU - Zhang, Jianan
AU  - Zhang J
AD  - Department of Rehabilitation Medicine, The First People's Hospital of Changzhou, 
      Changzhou, China. RINGGOLD: 117850
FAU - Zhou, Zhongkai
AU  - Zhou Z
AD  - College of Information Science and Engineering, Hohai University, Changzhou, 
      China.
FAU - Yamamoto, Ikuo
AU  - Yamamoto I
AD  - Graduate School of Engineering, Nagasaki University, Nagasaki, Japan.
FAU - Zhang, Yi
AU  - Zhang Y
AD  - Department of Rehabilitation Medicine, The First People's Hospital of Changzhou, 
      Changzhou, China. RINGGOLD: 117850
LA  - eng
PT  - Journal Article
DEP - 20240816
PL  - United States
TA  - Digit Health
JT  - Digital health
JID - 101690863
PMC - PMC11329975
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - abstraction
OT  - calculation
OT  - cognitive
OT  - language
OT  - memory
COIS- The authors declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/08/19 06:42
MHDA- 2024/08/19 06:43
PMCR- 2024/08/16
CRDT- 2024/08/19 05:07
PHST- 2023/12/11 00:00 [received]
PHST- 2024/06/10 00:00 [accepted]
PHST- 2024/08/19 06:43 [medline]
PHST- 2024/08/19 06:42 [pubmed]
PHST- 2024/08/19 05:07 [entrez]
PHST- 2024/08/16 00:00 [pmc-release]
AID - 10.1177_20552076241264639 [pii]
AID - 10.1177/20552076241264639 [doi]
PST - epublish
SO  - Digit Health. 2024 Aug 16;10:20552076241264639. doi: 10.1177/20552076241264639. 
      eCollection 2024 Jan-Dec.

PMID- 40012663
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250315
IS  - 2688-1152 (Electronic)
IS  - 2688-1152 (Linking)
VI  - 6
IP  - 1
DP  - 2025 Feb
TI  - Characterizing Emergency Department Care for Patients With Histories of 
      Incarceration.
PG  - 100022
LID - 10.1016/j.acepjo.2024.100022 [doi]
LID - 100022
AB  - OBJECTIVES: Patients with a history of incarceration experience bias from health 
      care team members, barriers to privacy, and a multitude of health care 
      disparities. We aimed to assess care processes delivered in emergency departments 
      (EDs) for people with histories of incarceration. METHODS: We utilized a 
      fine-tuned large language model to identify patient incarceration status from 
      480,374 notes from the ED setting. We compared socio-demographic characteristics, 
      comorbidities, and care processes, including disposition, restraint use, and 
      sedation, between individuals with and without a history of incarceration. We 
      then conducted multivariable logistic regression to assess the independent 
      correlation of incarceration history and management in the ED while adjusting for 
      demographic characteristics, health behaviors, presentation, and past medical 
      history. RESULTS: We found 1734 unique patient encounters with a history of 
      incarceration from a total of 177,987 encounters. Patients with history of 
      incarceration were more likely to be male, Black, Hispanic, or other 
      race/ethnicity, currently unemployed or disabled, and had smoking and substance 
      use histories, compared with those without. This cohort demonstrated higher odds 
      of elopement (OR: 3.59 [95% CI: 2.41-5.12]), leaving against medical advice (OR: 
      2.39 [95% CI: 1.46-3.67]), and being subjected to sedation (OR: 3.89 [95% CI: 
      3.19-4.70]) and restraint use (OR: 3.76 [95% CI: 3.06-4.57]). After adjusting for 
      covariates, the association between incarceration and elopement remained 
      significant (adjusted odds ratio: 1.65 [95% CI: 1.08-2.43]), while associations 
      with other dispositions, restraint use, and sedation did not persist. CONCLUSION: 
      This study identified differences in patient characteristics and care processes 
      in the ED for patients with histories of incarceration and demonstrated the 
      potential of using natural language processing in measuring care processes in 
      populations that are largely hidden, but highly prevalent and subject to 
      discrimination, in the health care system.
CI  - © 2024 The Author(s).
FAU - Huang, Thomas
AU  - Huang T
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, 
      Connecticut, USA.
AD  - Department for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
FAU - Socrates, Vimig
AU  - Socrates V
AD  - Department for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
AD  - Program of Computational Biology and Bioinformatics, Yale University, New Haven, 
      Connecticut, USA.
FAU - Ovchinnikova, Polina
AU  - Ovchinnikova P
AD  - Department for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
FAU - Faustino, Isaac
AU  - Faustino I
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, 
      Connecticut, USA.
FAU - Kumar, Anusha
AU  - Kumar A
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, 
      Connecticut, USA.
FAU - Safranek, Conrad
AU  - Safranek C
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, 
      Connecticut, USA.
AD  - Department for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
FAU - Chi, Ling
AU  - Chi L
AD  - Department for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
FAU - Wang, Emily A
AU  - Wang EA
AD  - SEICHE Center for Health and Justice, Yale School of Medicine, New Haven, 
      Connecticut, USA.
FAU - Puglisi, Lisa
AU  - Puglisi L
AD  - SEICHE Center for Health and Justice, Yale School of Medicine, New Haven, 
      Connecticut, USA.
FAU - Wong, Ambrose H
AU  - Wong AH
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, 
      Connecticut, USA.
FAU - Wang, Karen H
AU  - Wang KH
AD  - Department for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
AD  - SEICHE Center for Health and Justice, Yale School of Medicine, New Haven, 
      Connecticut, USA.
AD  - Equity Research and Innovation Center, Yale School of Medicine, Yale University, 
      New Haven, Connecticut, USA.
FAU - Taylor, R Andrew
AU  - Taylor RA
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, 
      Connecticut, USA.
AD  - Department for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, Connecticut, USA.
LA  - eng
GR  - UL1 TR001863/TR/NCATS NIH HHS/United States
PT  - Journal Article
DEP - 20250110
PL  - United States
TA  - J Am Coll Emerg Physicians Open
JT  - Journal of the American College of Emergency Physicians open
JID - 101764779
PMC - PMC11852703
OTO - NOTNLM
OT  - artificial intelligence
OT  - emergency medicine
OT  - incarceration
OT  - large language models
OT  - quality of health care
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2025/02/27 11:13
MHDA- 2025/02/27 11:14
PMCR- 2025/01/10
CRDT- 2025/02/27 04:15
PHST- 2024/08/05 00:00 [received]
PHST- 2024/10/31 00:00 [revised]
PHST- 2024/11/04 00:00 [accepted]
PHST- 2025/02/27 11:14 [medline]
PHST- 2025/02/27 11:13 [pubmed]
PHST- 2025/02/27 04:15 [entrez]
PHST- 2025/01/10 00:00 [pmc-release]
AID - S2688-1152(24)01336-5 [pii]
AID - 100022 [pii]
AID - 10.1016/j.acepjo.2024.100022 [doi]
PST - epublish
SO  - J Am Coll Emerg Physicians Open. 2025 Jan 10;6(1):100022. doi: 
      10.1016/j.acepjo.2024.100022. eCollection 2025 Feb.

PMID- 38889023
OWN - NLM
STAT- MEDLINE
DCOM- 20250303
LR  - 20250303
IS  - 1558-254X (Electronic)
IS  - 0278-0062 (Linking)
VI  - 43
IP  - 12
DP  - 2024 Dec
TI  - PhraseAug: An Augmented Medical Report Generation Model With Phrasebook.
PG  - 4211-4223
LID - 10.1109/TMI.2024.3416190 [doi]
AB  - Medical report generation is a valuable and challenging task, which automatically 
      generates accurate and fluent diagnostic reports for medical images, reducing 
      workload of radiologists and improving efficiency of disease diagnosis. 
      Fine-grained alignment of medical images and reports facilitates the exploration 
      of close correlations between images and texts, which is crucial for cross-modal 
      generation. However, visual and linguistic biases caused by radiologists' writing 
      styles make cross-modal image-text alignment difficult. To alleviate 
      visual-linguistic bias, this paper discretizes medical reports and introduces an 
      intermediate modality, i.e. phrasebook, consisting of key noun phrases. As 
      discretized representation of medical reports, phrasebook contains both 
      disease-related medical terms, and synonymous phrases representing different 
      writing styles which can identify synonymous sentences, thereby promoting 
      fine-grained alignment between images and reports. In this paper, an augmented 
      two-stage medical report generation model with phrasebook (PhraseAug) is 
      developed, which combines medical images, clinical histories and writing styles 
      to generate diagnostic reports. In the first stage, phrasebook is used to extract 
      semantically relevant important features and predict key phrases contained in the 
      report. In the second stage, medical reports are generated according to the 
      predicted key phrases which contain synonymous phrases, promoting our model to 
      adapt to different writing styles and generating diverse medical reports. 
      Experimental results on two public datasets, IU-Xray and MIMIC-CXR, demonstrate 
      that our proposed PhraseAug outperforms state-of-the-art baselines.
FAU - Mei, Xin
AU  - Mei X
FAU - Yang, Libin
AU  - Yang L
FAU - Gao, Denghong
AU  - Gao D
FAU - Cai, Xiaoyan
AU  - Cai X
FAU - Han, Junwei
AU  - Han J
FAU - Liu, Tianming
AU  - Liu T
LA  - eng
PT  - Journal Article
DEP - 20241202
PL  - United States
TA  - IEEE Trans Med Imaging
JT  - IEEE transactions on medical imaging
JID - 8310780
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Algorithms
MH  - Electronic Health Records
MH  - Diagnostic Imaging/methods
MH  - Radiology Information Systems
MH  - Databases, Factual
EDAT- 2024/06/18 18:42
MHDA- 2025/03/04 00:22
CRDT- 2024/06/18 12:43
PHST- 2025/03/04 00:22 [medline]
PHST- 2024/06/18 18:42 [pubmed]
PHST- 2024/06/18 12:43 [entrez]
AID - 10.1109/TMI.2024.3416190 [doi]
PST - ppublish
SO  - IEEE Trans Med Imaging. 2024 Dec;43(12):4211-4223. doi: 10.1109/TMI.2024.3416190. 
      Epub 2024 Dec 2.

PMID- 38626597
OWN - NLM
STAT- MEDLINE
DCOM- 20240516
LR  - 20240516
IS  - 1873-6297 (Electronic)
IS  - 0001-6918 (Linking)
VI  - 246
DP  - 2024 Jun
TI  - The influence of the COVID-19 pandemic on the adoption and impact of AI ChatGPT: 
      Challenges, applications, and ethical considerations.
PG  - 104264
LID - S0001-6918(24)00141-0 [pii]
LID - 10.1016/j.actpsy.2024.104264 [doi]
AB  - DESIGN/METHODOLOGY/APPROACH: This article employs qualitative thematic modeling 
      to gather insights from 30 informants. The study explores various aspects related 
      to the impact of the COVID-19 pandemic on AI ChatGPT technologies. PURPOSE: The 
      purpose of this research is to examine how the COVID-19 pandemic has influenced 
      the increased usage and adoption of AI ChatGPT. It aims to explore the pandemic's 
      impact on AI ChatGPT and its applications in specific domains, as well as the 
      challenges and opportunities it presents. FINDINGS: The findings highlight that 
      the pandemic has led to a surge in online activities, resulting in a heightened 
      demand for AI ChatGPT. It has been widely used in areas such as healthcare, 
      mental health support, remote collaboration, and personalized customer 
      experiences. The article showcases examples of AI ChatGPT's application during 
      the pandemic. STRENGTH OF STUDY: This qualitative framework enables the study to 
      delve deeply into the multifaceted dimensions of AI ChatGPT's role during the 
      pandemic, capturing the diverse experiences and insights of users, practitioners, 
      and experts. By embracing the qualitative nature of inquiry and this research 
      offers a comprehensive understanding of the challenges, opportunities, and 
      ethical considerations associated with the adoption and utilization of AI ChatGPT 
      in crisis contexts. PRACTICAL IMPLICATIONS: The insights from this research have 
      practical implications for policymakers, developers, and researchers. This 
      reserach emphasize the need for responsible and ethical implementation of AI 
      ChatGPT to fully harness its potential in addressing societal needs during and 
      beyond the pandemic. SOCIAL IMPLICATIONS: The increased reliance on AI ChatGPT 
      during the pandemic has led to changes in user behavior, expectations, and 
      interactions. However, it has also unveiled ethical considerations and potential 
      risks. Addressing societal and ethical concerns, such as user impact and 
      autonomy, privacy and security, bias and fairness, and transparency and 
      accountability, is crucial for the responsible deployment of AI ChatGPT. 
      ORIGINALITY/VALUE: This research contributes to the understanding of the novel 
      role of AI ChatGPT in times of crisis, particularly in the era of COVID-19 
      pandemic. It highlights the necessity of responsible and ethical implementation 
      of AI ChatGPT and provides valuable insights for the development and application 
      of AI technology in the future.
CI  - Copyright © 2024 The Authors. Published by Elsevier B.V. All rights reserved.
FAU - Hussain, Talib
AU  - Hussain T
AD  - School of Media and Communication, Shanghai Jiao Tong University, 800 Dongchuan 
      Road, 2002240 Shanghai, China; Department of Media Management, University of 
      Religions and Denominations, Qom 37491-13357, Iran. Electronic address: 
      talibhussian@sjtu.edu.cn.
FAU - Wang, Dake
AU  - Wang D
AD  - School of Media and Communication, Shanghai Jiao Tong University, 800 Dongchuan 
      Road, 2002240 Shanghai, China. Electronic address: dakewang@sjtu.edu.cn.
FAU - Li, Benqian
AU  - Li B
AD  - School of Media and Communication, Shanghai Jiao Tong University, 800 Dongchuan 
      Road, 2002240 Shanghai, China. Electronic address: libenqian@sjtu.edu.cn.
LA  - eng
PT  - Journal Article
DEP - 20240415
PL  - Netherlands
TA  - Acta Psychol (Amst)
JT  - Acta psychologica
JID - 0370366
SB  - IM
MH  - Humans
MH  - *COVID-19/epidemiology
MH  - Artificial Intelligence
MH  - Qualitative Research
MH  - Telemedicine
MH  - Pandemics
MH  - SARS-CoV-2
OTO - NOTNLM
OT  - AI
OT  - COVID 19
OT  - ChatGPT
OT  - Qualitative modeling
COIS- Declaration of competing interest The authors, Talib Hussain and Dake Wang, 
      declare that they have no conflicts of interest related to this research 
      study/article. There are no financial or non-financial interests that could 
      potentially influence the objectivity, conduct, or presentation of the findings 
      presented in this work.
EDAT- 2024/04/17 00:43
MHDA- 2024/05/17 00:44
CRDT- 2024/04/16 18:05
PHST- 2023/12/06 00:00 [received]
PHST- 2024/04/08 00:00 [revised]
PHST- 2024/04/09 00:00 [accepted]
PHST- 2024/05/17 00:44 [medline]
PHST- 2024/04/17 00:43 [pubmed]
PHST- 2024/04/16 18:05 [entrez]
AID - S0001-6918(24)00141-0 [pii]
AID - 10.1016/j.actpsy.2024.104264 [doi]
PST - ppublish
SO  - Acta Psychol (Amst). 2024 Jun;246:104264. doi: 10.1016/j.actpsy.2024.104264. Epub 
      2024 Apr 15.

PMID- 36046150
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20220907
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 5
DP  - 2022
TI  - Asian hate speech detection on Twitter during COVID-19.
PG  - 932381
LID - 10.3389/frai.2022.932381 [doi]
LID - 932381
AB  - Coronavirus disease 2019 (COVID-19) started in Wuhan, China, in late 2019, and 
      after being utterly contagious in Asian countries, it rapidly spread to other 
      countries. This disease caused governments worldwide to declare a public health 
      crisis with severe measures taken to reduce the speed of the spread of the 
      disease. This pandemic affected the lives of millions of people. Many citizens 
      that lost their loved ones and jobs experienced a wide range of emotions, such as 
      disbelief, shock, concerns about health, fear about food supplies, anxiety, and 
      panic. All of the aforementioned phenomena led to the spread of racism and hate 
      against Asians in western countries, especially in the United States. An analysis 
      of official preliminary police data by the Center for the Study of Hate & 
      Extremism at California State University shows that Anti-Asian hate crime in 16 
      of America's largest cities increased by 149% in 2020. In this study, we first 
      chose a baseline of Americans' hate crimes against Asians on Twitter. Then we 
      present an approach to balance the biased dataset and consequently improve the 
      performance of tweet classification. We also have downloaded 10 million tweets 
      through the Twitter API V-2. In this study, we have used a small portion of that, 
      and we will use the entire dataset in the future study. In this article, three 
      thousand tweets from our collected corpus are annotated by four annotators, 
      including three Asian and one Asian-American. Using this data, we built 
      predictive models of hate speech using various machine learning and deep learning 
      methods. Our machine learning methods include Random Forest, K-nearest neighbors 
      (KNN), Support Vector Machine (SVM), Extreme Gradient Boosting (XGBoost), 
      Logistic Regression, Decision Tree, and Naive Bayes. Our Deep Learning models 
      include Basic Long-Term Short-Term Memory (LSTM), Bidirectional LSTM, 
      Bidirectional LSTM with Drop out, Convolution, and Bidirectional Encoder 
      Representations from Transformers (BERT). We also adjusted our dataset by 
      filtering tweets that were ambiguous to the annotators based on low Fleiss Kappa 
      agreement between annotators. Our final result showed that Logistic Regression 
      achieved the best statistical machine learning performance with an F1 score of 
      0.72, while BERT achieved the best performance of the deep learning models, with 
      an F1-Score of 0.85.
CI  - Copyright © 2022 Toliyat, Levitan, Peng and Etemadpour.
FAU - Toliyat, Amir
AU  - Toliyat A
AD  - Computer Science Program, Graduate Center, City University of New York, New York, 
      NY, United States.
FAU - Levitan, Sarah Ita
AU  - Levitan SI
AD  - Computer Science Program, Hunter College, City University of New York, New York, 
      NY, United States.
FAU - Peng, Zheng
AU  - Peng Z
AD  - Computer Science Program, City College, City University of New York, New York, 
      NY, United States.
FAU - Etemadpour, Ronak
AU  - Etemadpour R
AD  - Computer Science Program, City College, City University of New York, New York, 
      NY, United States.
LA  - eng
PT  - Journal Article
DEP - 20220815
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC9421075
OTO - NOTNLM
OT  - Asian hate crime
OT  - COVID-19
OT  - Twitter
OT  - machine learning
OT  - natural language processing
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2022/09/02 06:00
MHDA- 2022/09/02 06:01
PMCR- 2022/08/15
CRDT- 2022/09/01 02:23
PHST- 2022/04/29 00:00 [received]
PHST- 2022/06/27 00:00 [accepted]
PHST- 2022/09/01 02:23 [entrez]
PHST- 2022/09/02 06:00 [pubmed]
PHST- 2022/09/02 06:01 [medline]
PHST- 2022/08/15 00:00 [pmc-release]
AID - 10.3389/frai.2022.932381 [doi]
PST - epublish
SO  - Front Artif Intell. 2022 Aug 15;5:932381. doi: 10.3389/frai.2022.932381. 
      eCollection 2022.

PMID- 39511117
OWN - NLM
STAT- MEDLINE
DCOM- 20250318
LR  - 20250320
IS  - 1525-1497 (Electronic)
IS  - 0884-8734 (Print)
IS  - 0884-8734 (Linking)
VI  - 40
IP  - 4
DP  - 2025 Mar
TI  - Bias Sensitivity in Diagnostic Decision-Making: Comparing ChatGPT with Residents.
PG  - 790-795
LID - 10.1007/s11606-024-09177-9 [doi]
AB  - BACKGROUND: Diagnostic errors, often due to biases in clinical reasoning, 
      significantly affect patient care. While artificial intelligence chatbots like 
      ChatGPT could help mitigate such biases, their potential susceptibility to biases 
      is unknown. METHODS: This study evaluated diagnostic accuracy of ChatGPT against 
      the performance of 265 medical residents in five previously published experiments 
      aimed at inducing bias. The residents worked in several major teaching hospitals 
      in the Netherlands. The biases studied were case-intrinsic (presence of salient 
      distracting findings in the patient history, effects of disruptive patient 
      behaviors) and situational (prior availability of a look-alike patient). 
      ChatGPT's accuracy in identifying the most-likely diagnosis was measured. 
      RESULTS: Diagnostic accuracy of residents and ChatGPT was equivalent. For 
      clinical cases involving case-intrinsic bias, both ChatGPT and the residents 
      exhibited a decline in diagnostic accuracy. Residents' accuracy decreased on 
      average 12%, while the accuracy of ChatGPT 4.0 decreased 21%. Accuracy of ChatGPT 
      3.5 decreased 9%. These findings suggest that, like human diagnosticians, ChatGPT 
      is sensitive to bias when the biasing information is part of the patient history. 
      When the biasing information was extrinsic to the case in the form of the prior 
      availability of a look-alike case, residents' accuracy decreased by 15%. By 
      contrast, ChatGPT's performance was not affected by the biasing information. 
      Chi-square goodness-of-fit tests corroborated these outcomes. CONCLUSIONS: It 
      seems that, while ChatGPT is not sensitive to bias when biasing information is 
      situational, it is sensitive to bias when the biasing information is part of the 
      patient's disease history. Its utility in diagnostic support has potential, but 
      caution is advised. Future research should enhance AI's bias detection and 
      mitigation to make it truly useful for diagnostic support.
CI  - © 2024. The Author(s).
FAU - Schmidt, Henk G
AU  - Schmidt HG
AD  - Erasmus School of Social and Behavioural Sciences, Erasmus University Rotterdam, 
      Mandeville Building, Room T15-10, P.O. Box 1738, Rotterdam, DR, 3000, The 
      Netherlands.
FAU - Rotgans, Jerome I
AU  - Rotgans JI
AD  - Karolinska Institutet, Solna, Sweden.
AD  - Institute of Medical Education Research Rotterdam, Erasmus Medical Center, 
      Institute of Medical Education Research Rotterdam, Dr. Molewaterplein 40, 
      Na-2418, 3015 GD, Rotterdam, The Netherlands.
FAU - Mamede, Silvia
AU  - Mamede S
AUID- ORCID: 0000-0003-1187-2392
AD  - Institute of Medical Education Research Rotterdam, Erasmus Medical Center, 
      Institute of Medical Education Research Rotterdam, Dr. Molewaterplein 40, 
      Na-2418, 3015 GD, Rotterdam, The Netherlands. s.mamede@erasmusmc.nl.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20241107
PL  - United States
TA  - J Gen Intern Med
JT  - Journal of general internal medicine
JID - 8605834
SB  - IM
MH  - Humans
MH  - *Internship and Residency
MH  - *Bias
MH  - Diagnostic Errors/prevention & control
MH  - Clinical Decision-Making/methods
MH  - Netherlands
MH  - Clinical Competence/standards
MH  - Female
MH  - Male
MH  - Artificial Intelligence
PMC - PMC11914423
COIS- Declarations:. Ethics Approval:: The present study did not involve testing of 
      human participants. Therefore, no ethics approval was asked. Conflict of 
      Interest:: The authors declare that they do not have a conflict of interest.
EDAT- 2024/11/13 13:58
MHDA- 2025/03/18 06:22
PMCR- 2024/11/07
CRDT- 2024/11/07 23:16
PHST- 2024/04/23 00:00 [received]
PHST- 2024/10/22 00:00 [accepted]
PHST- 2025/03/18 06:22 [medline]
PHST- 2024/11/13 13:58 [pubmed]
PHST- 2024/11/07 23:16 [entrez]
PHST- 2024/11/07 00:00 [pmc-release]
AID - 10.1007/s11606-024-09177-9 [pii]
AID - 9177 [pii]
AID - 10.1007/s11606-024-09177-9 [doi]
PST - ppublish
SO  - J Gen Intern Med. 2025 Mar;40(4):790-795. doi: 10.1007/s11606-024-09177-9. Epub 
      2024 Nov 7.

PMID- 38609507
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240427
IS  - 2731-4251 (Electronic)
IS  - 2731-4251 (Linking)
VI  - 3
IP  - 1
DP  - 2024 Apr 2
TI  - Large language models could change the future of behavioral healthcare: a 
      proposal for responsible development and evaluation.
PG  - 12
LID - 10.1038/s44184-024-00056-z [doi]
LID - 12
AB  - Large language models (LLMs) such as Open AI's GPT-4 (which power ChatGPT) and 
      Google's Gemini, built on artificial intelligence, hold immense potential to 
      support, augment, or even eventually automate psychotherapy. Enthusiasm about 
      such applications is mounting in the field as well as industry. These 
      developments promise to address insufficient mental healthcare system capacity 
      and scale individual access to personalized treatments. However, clinical 
      psychology is an uncommonly high stakes application domain for AI systems, as 
      responsible and evidence-based therapy requires nuanced expertise. This paper 
      provides a roadmap for the ambitious yet responsible application of clinical LLMs 
      in psychotherapy. First, a technical overview of clinical LLMs is presented. 
      Second, the stages of integration of LLMs into psychotherapy are discussed while 
      highlighting parallels to the development of autonomous vehicle technology. 
      Third, potential applications of LLMs in clinical care, training, and research 
      are discussed, highlighting areas of risk given the complex nature of 
      psychotherapy. Fourth, recommendations for the responsible development and 
      evaluation of clinical LLMs are provided, which include centering clinical 
      science, involving robust interdisciplinary collaboration, and attending to 
      issues like assessment, risk detection, transparency, and bias. Lastly, a vision 
      is outlined for how LLMs might enable a new generation of studies of 
      evidence-based interventions at scale, and how these studies may challenge 
      assumptions about psychotherapy.
CI  - © 2024. The Author(s).
FAU - Stade, Elizabeth C
AU  - Stade EC
AD  - Dissemination and Training Division, National Center for PTSD, VA Palo Alto 
      Health Care System, Palo Alto, CA, USA. betsystade@stanford.edu.
AD  - Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, 
      CA, USA. betsystade@stanford.edu.
AD  - Institute for Human-Centered Artificial Intelligence & Department of Psychology, 
      Stanford University, Stanford, CA, USA. betsystade@stanford.edu.
FAU - Stirman, Shannon Wiltsey
AU  - Stirman SW
AD  - Dissemination and Training Division, National Center for PTSD, VA Palo Alto 
      Health Care System, Palo Alto, CA, USA.
AD  - Department of Psychiatry and Behavioral Sciences, Stanford University, Stanford, 
      CA, USA.
FAU - Ungar, Lyle H
AU  - Ungar LH
AD  - Department of Computer and Information Science, University of Pennsylvania, 
      Philadelphia, PA, USA.
FAU - Boland, Cody L
AU  - Boland CL
AD  - Dissemination and Training Division, National Center for PTSD, VA Palo Alto 
      Health Care System, Palo Alto, CA, USA.
FAU - Schwartz, H Andrew
AU  - Schwartz HA
AD  - Department of Computer Science, Stony Brook University, Stony Brook, NY, USA.
FAU - Yaden, David B
AU  - Yaden DB
AD  - Department of Psychiatry and Behavioral Sciences, Johns Hopkins University School 
      of Medicine, Baltimore, MD, USA.
FAU - Sedoc, João
AU  - Sedoc J
AD  - Department of Technology, Operations, and Statistics, New York University, New 
      York, NY, USA.
FAU - DeRubeis, Robert J
AU  - DeRubeis RJ
AD  - Department of Psychology, University of Pennsylvania, Philadelphia, PA, USA.
FAU - Willer, Robb
AU  - Willer R
AD  - Department of Sociology, Stanford University, Stanford, CA, USA.
FAU - Eichstaedt, Johannes C
AU  - Eichstaedt JC
AD  - Institute for Human-Centered Artificial Intelligence & Department of Psychology, 
      Stanford University, Stanford, CA, USA. johannes.stanford@gmail.com.
LA  - eng
GR  - R01 MH125702/MH/NIMH NIH HHS/United States
GR  - RF1 MH128785/MH/NIMH NIH HHS/United States
GR  - RF1-MH128785/MH/NIMH NIH HHS/United States
GR  - R01-MH125702/MH/NIMH NIH HHS/United States
PT  - Journal Article
DEP - 20240402
PL  - England
TA  - Npj Ment Health Res
JT  - Npj mental health research
JID - 9918592488906676
PMC - PMC10987499
COIS- The authors declare the following competing interests: receiving consultation 
      fees from Jimini Health (E.C.S., L.H.U., H.A.S., and J.C.E.).
EDAT- 2024/04/13 10:42
MHDA- 2024/04/13 10:43
PMCR- 2024/04/02
CRDT- 2024/04/12 23:23
PHST- 2023/07/24 00:00 [received]
PHST- 2024/01/30 00:00 [accepted]
PHST- 2024/04/13 10:43 [medline]
PHST- 2024/04/13 10:42 [pubmed]
PHST- 2024/04/12 23:23 [entrez]
PHST- 2024/04/02 00:00 [pmc-release]
AID - 10.1038/s44184-024-00056-z [pii]
AID - 56 [pii]
AID - 10.1038/s44184-024-00056-z [doi]
PST - epublish
SO  - Npj Ment Health Res. 2024 Apr 2;3(1):12. doi: 10.1038/s44184-024-00056-z.

PMID- 39975915
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250304
IS  - 2693-5015 (Electronic)
IS  - 2693-5015 (Linking)
DP  - 2025 Feb 7
TI  - Learning neuroimaging models from health system-scale data.
LID - rs.3.rs-5932803 [pii]
LID - 10.21203/rs.3.rs-5932803/v1 [doi]
AB  - Neuroimaging is a ubiquitous tool for evaluating patients with neurological 
      diseases. The global demand for magnetic resonance imaging (MRI) studies has 
      risen steadily, placing significant strain on health systems, prolonging 
      turnaround times, and intensifying physician burnout [1, 2]. These challenges 
      disproportionately impact patients in low-resource and rural settings [3]. Here, 
      we utilized a large academic health system as a data engine to develop Prima , 
      the first vision language model (VLM) serving as an AI foundation for 
      neuroimaging that supports real-world, clinical MRI studies as input. Trained on 
      over 220,000 MRI studies, Prima uses a hierarchical vision architecture that 
      provides general and transferable MRI features. Prima was tested in a 1-year, 
      prospective, health system-wide study that included 30K MRI studies. Across 52 
      radiologic diagnoses from the major neurologic disorders, including neoplastic, 
      inflammatory, infectious, and developmental lesions, Prima achieved a mean 
      diagnostic area under the ROC curve of 90.1 ± 5.0%, outperforming other 
      state-of-the-art general and medical AI models by a large margin [4-6]. Prima 
      offers explainable differential diagnoses, worklist priority for radiologists, 
      and clinical referral recommendations across diverse patient demographics and MRI 
      systems. Prima demonstrates algorithmic fairness across sensitive groups and can 
      help mitigate health system biases, such as prolonged turnaround times for 
      low-resource populations. These findings highlight the transformative potential 
      of health system-scale VLMs and Prima's role in advancing AI-driven healthcare.
FAU - Lyu, Yiwei
AU  - Lyu Y
AD  - University of Michigan Computer Science and Engineering.
FAU - Harake, Samir
AU  - Harake S
AD  - University of Michigan Neurosugery.
FAU - Chowdury, Asadur
AU  - Chowdury A
AD  - University of Michigan Neurosugery.
FAU - Banerjee, Soumyanil
AU  - Banerjee S
AD  - University of Michigan Neurosugery.
FAU - Gologorsky, Rachel
AU  - Gologorsky R
AUID- ORCID: 0000-0002-2099-9814
AD  - University of Michigan Neurosugery.
FAU - Liu, Shixuan
AU  - Liu S
AD  - University of Michigan Computer Science and Engineering.
FAU - Meissner, Anna-Katharina
AU  - Meissner AK
AD  - University of Cologne Neurosugery.
FAU - Rao, Akshay
AU  - Rao A
AD  - University of Michigan Neurosugery.
FAU - Kondepudi, Akhil
AU  - Kondepudi A
AD  - University of Michigan Neurosugery.
AD  - University of Michigan Computational Medicine and Bioinformatics.
FAU - Jiang, Cheng
AU  - Jiang C
AUID- ORCID: 0000-0003-1759-4960
AD  - University of Michigan Neurosugery.
AD  - University of Michigan Computational Medicine and Bioinformatics.
FAU - Hou, Xinhai
AU  - Hou X
AD  - University of Michigan Neurosugery.
AD  - University of Michigan Computational Medicine and Bioinformatics.
FAU - Joshi, Rushikesh
AU  - Joshi R
AD  - University of Michigan Neurosugery.
FAU - Neuschmelting, Volker
AU  - Neuschmelting V
AUID- ORCID: 0000-0001-7527-6990
AD  - University of Cologne Neurosugery.
FAU - Srinivasan, Ashok
AU  - Srinivasan A
AD  - University of Michigan Radiology.
FAU - Kleindorfer, Dawn
AU  - Kleindorfer D
AD  - University of Michigan Neurology.
FAU - Athey, Brian
AU  - Athey B
AD  - University of Michigan Computational Medicine and Bioinformatics.
FAU - Gulani, Vikas
AU  - Gulani V
AD  - University of Michigan Radiology.
FAU - Pandey, Aditya
AU  - Pandey A
AD  - University of Michigan Neurosugery.
FAU - Lee, Honglak
AU  - Lee H
AD  - University of Michigan Computer Science and Engineering.
FAU - Hollon, Todd
AU  - Hollon T
AUID- ORCID: 0000-0001-5987-6531
AD  - University of Michigan Computer Science and Engineering.
AD  - University of Michigan Neurosugery.
AD  - University of Michigan Computational Medicine and Bioinformatics.
LA  - eng
GR  - K12 NS080223/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20250207
PL  - United States
TA  - Res Sq
JT  - Research square
JID - 101768035
PMC - PMC11838732
OTO - NOTNLM
OT  - Vision language models
OT  - algorithmic fairness
OT  - artificial intelligence
OT  - health systems
OT  - healthcare bias
OT  - magnetic resonance imaging
OT  - neuroimaging
EDAT- 2025/02/20 06:22
MHDA- 2025/02/20 06:23
PMCR- 2025/02/19
CRDT- 2025/02/20 05:44
PHST- 2025/02/20 06:22 [pubmed]
PHST- 2025/02/20 06:23 [medline]
PHST- 2025/02/20 05:44 [entrez]
PHST- 2025/02/19 00:00 [pmc-release]
AID - rs.3.rs-5932803 [pii]
AID - 10.21203/rs.3.rs-5932803/v1 [doi]
PST - epublish
SO  - Res Sq [Preprint]. 2025 Feb 7:rs.3.rs-5932803. doi: 10.21203/rs.3.rs-5932803/v1.

PMID- 39216786
OWN - NLM
STAT- MEDLINE
DCOM- 20250102
LR  - 20250107
IS  - 1532-821X (Electronic)
IS  - 0003-9993 (Linking)
VI  - 106
IP  - 1
DP  - 2025 Jan
TI  - Disability Ethics and Education in the Age of Artificial Intelligence: 
      Identifying Ability Bias in ChatGPT and Gemini.
PG  - 14-19
LID - S0003-9993(24)01191-2 [pii]
LID - 10.1016/j.apmr.2024.08.014 [doi]
AB  - OBJECTIVE: To identify and quantify ability bias in generative artificial 
      intelligence large language model chatbots, specifically OpenAI's ChatGPT and 
      Google's Gemini. DESIGN: Observational study of language usage in generative 
      artificial intelligence models. SETTING: Investigation-only browser profile 
      restricted to ChatGPT and Gemini. PARTICIPANTS: Each chatbot generated 60 
      descriptions of people prompted without specified functional status, 30 
      descriptions of people with a disability, 30 descriptions of patients with a 
      disability, and 30 descriptions of athletes with a disability (N=300). 
      INTERVENTIONS: Not applicable. MAIN OUTCOME MEASURES: Generated descriptions 
      produced by the models were parsed into words that were linguistically analyzed 
      into favorable qualities or limiting qualities. RESULTS: Both large language 
      models significantly underestimated disability in a population of people, and 
      linguistic analysis showed that descriptions of people, patients, and athletes 
      with a disability were generated as having significantly fewer favorable 
      qualities and significantly more limitations than people without a disability in 
      both ChatGPT and Gemini. CONCLUSIONS: Generative artificial intelligence chatbots 
      demonstrate quantifiable ability bias and often exclude people with disabilities 
      in their responses. Ethical use of these generative large language model chatbots 
      in medical systems should recognize this limitation, and further consideration 
      should be taken in developing equitable artificial intelligence technologies.
CI  - Copyright © 2024 American Congress of Rehabilitation Medicine. Published by 
      Elsevier Inc. All rights reserved.
FAU - Urbina, Jacob T
AU  - Urbina JT
AD  - Department of Physical Medicine and Rehabilitation, McGovern Medical School, 
      UTHealth Houston, Houston, TX. Electronic address: jacob.t.urbina@uth.tmc.edu.
FAU - Vu, Peter D
AU  - Vu PD
AD  - Department of Physical Medicine and Rehabilitation, McGovern Medical School, 
      UTHealth Houston, Houston, TX.
FAU - Nguyen, Michael V
AU  - Nguyen MV
AD  - Department of Physical Medicine and Rehabilitation, McGovern Medical School, 
      UTHealth Houston, Houston, TX.
LA  - eng
PT  - Journal Article
PT  - Observational Study
DEP - 20240830
PL  - United States
TA  - Arch Phys Med Rehabil
JT  - Archives of physical medicine and rehabilitation
JID - 2985158R
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence/ethics
MH  - *Disabled Persons/rehabilitation
MH  - Bias
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bias
OT  - Digital health technology
OT  - Disability discrimination
OT  - Rehabilitation
EDAT- 2024/09/01 16:18
MHDA- 2025/01/03 00:20
CRDT- 2024/08/31 19:28
PHST- 2024/04/25 00:00 [received]
PHST- 2024/08/17 00:00 [revised]
PHST- 2024/08/19 00:00 [accepted]
PHST- 2025/01/03 00:20 [medline]
PHST- 2024/09/01 16:18 [pubmed]
PHST- 2024/08/31 19:28 [entrez]
AID - S0003-9993(24)01191-2 [pii]
AID - 10.1016/j.apmr.2024.08.014 [doi]
PST - ppublish
SO  - Arch Phys Med Rehabil. 2025 Jan;106(1):14-19. doi: 10.1016/j.apmr.2024.08.014. 
      Epub 2024 Aug 30.

PMID- 40053730
OWN - NLM
STAT- MEDLINE
DCOM- 20250307
LR  - 20250322
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Mar 5
TI  - Characterizing Public Sentiments and Drug Interactions in the COVID-19 Pandemic 
      Using Social Media: Natural Language Processing and Network Analysis.
PG  - e63755
LID - 10.2196/63755 [doi]
LID - e63755
AB  - BACKGROUND: While the COVID-19 pandemic has induced massive discussion of 
      available medications on social media, traditional studies focused only on 
      limited aspects, such as public opinions, and endured reporting biases, 
      inefficiency, and long collection times. OBJECTIVE: Harnessing drug-related data 
      posted on social media in real-time can offer insights into how the pandemic 
      impacts drug use and monitor misinformation. This study aimed to develop a 
      natural language processing (NLP) pipeline tailored for the analysis of social 
      media discourse on COVID-19-related drugs. METHODS: This study constructed a full 
      pipeline for COVID-19-related drug tweet analysis, using pretrained language 
      model-based NLP techniques as the backbone. This pipeline is architecturally 
      composed of 4 core modules: named entity recognition and normalization to 
      identify medical entities from relevant tweets and standardize them to uniform 
      medication names for time trend analysis, target sentiment analysis to reveal 
      sentiment polarities associated with the entities, topic modeling to understand 
      underlying themes discussed by the population, and drug network analysis to dig 
      potential adverse drug reactions (ADR) and drug-drug interactions (DDI). The 
      pipeline was deployed to analyze tweets related to the COVID-19 pandemic and drug 
      therapies between February 1, 2020, and April 30, 2022. RESULTS: From a dataset 
      comprising 169,659,956 COVID-19-related tweets from 103,682,686 users, our named 
      entity recognition model identified 2,124,757 relevant tweets sourced from 
      1,800,372 unique users, and the top 5 most-discussed drugs: ivermectin, 
      hydroxychloroquine, remdesivir, zinc, and vitamin D. Time trend analysis revealed 
      that the public focused mostly on repurposed drugs (ie, hydroxychloroquine and 
      ivermectin), and least on remdesivir, the only officially approved drug among the 
      5. Sentiment analysis of the top 5 most-discussed drugs revealed that public 
      perception was predominantly shaped by celebrity endorsements, media hot spots, 
      and governmental directives rather than empirical evidence of drug efficacy. 
      Topic analysis obtained 15 general topics of overall drug-related tweets, with 
      "clinical treatment effects of drugs" and "physical symptoms" emerging as the 
      most frequently discussed topics. Co-occurrence matrices and complex network 
      analysis further identified emerging patterns of DDI and ADR that could be 
      critical for public health surveillance like better safeguarding public safety in 
      medicines use. CONCLUSIONS: This study shows that an NLP-based pipeline can be a 
      robust tool for large-scale public health monitoring and can offer valuable 
      supplementary data for traditional epidemiological studies concerning DDI and 
      ADR. The framework presented here aspires to serve as a cornerstone for future 
      social media-based public health analytics.
CI  - ©Wanxin Li, Yining Hua, Peilin Zhou, Li Zhou, Xin Xu, Jie Yang. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      05.03.2025.
FAU - Li, Wanxin
AU  - Li W
AUID- ORCID: 0000-0002-7981-3228
AD  - School of Public Health, the Second Affiliated Hospital, Zhejiang University 
      School of Medicine, Hangzhou, China.
FAU - Hua, Yining
AU  - Hua Y
AUID- ORCID: 0000-0001-7779-1208
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, 
      MA, United States.
AD  - Division of General Internal Medicine and Primary Care, Department of Medicine, 
      Brigham and Women's Hospital, Boston, MA, United States.
FAU - Zhou, Peilin
AU  - Zhou P
AUID- ORCID: 0000-0001-6763-5236
AD  - Thrust of Data Science and Analytics, Hong Kong University of Science and 
      Technology, Guangzhou, China.
FAU - Zhou, Li
AU  - Zhou L
AUID- ORCID: 0000-0003-3874-4833
AD  - Division of General Internal Medicine and Primary Care, Department of Medicine, 
      Brigham and Women's Hospital, Boston, MA, United States.
FAU - Xu, Xin
AU  - Xu X
AUID- ORCID: 0000-0002-4639-6480
AD  - School of Public Health, the Second Affiliated Hospital, Zhejiang University 
      School of Medicine, Hangzhou, China.
FAU - Yang, Jie
AU  - Yang J
AUID- ORCID: 0000-0001-5696-363X
AD  - School of Public Health, the Second Affiliated Hospital, Zhejiang University 
      School of Medicine, Hangzhou, China.
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital, Harvard Medical School, Boston, MA, United States.
LA  - eng
PT  - Journal Article
DEP - 20250305
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
RN  - 4QWG6N8QKH (Hydroxychloroquine)
RN  - 3QKI37EEHE (remdesivir)
RN  - 415SHH325A (Adenosine Monophosphate)
RN  - OF5P57N2ZX (Alanine)
RN  - 70288-86-7 (Ivermectin)
RN  - 0 (Antiviral Agents)
SB  - IM
MH  - *Natural Language Processing
MH  - *Social Media
MH  - Humans
MH  - *COVID-19
MH  - *Drug Interactions
MH  - COVID-19 Drug Treatment
MH  - Pandemics
MH  - SARS-CoV-2
MH  - Hydroxychloroquine/therapeutic use
MH  - Adenosine Monophosphate/analogs & derivatives/therapeutic use
MH  - Alanine/analogs & derivatives/therapeutic use
MH  - Ivermectin/therapeutic use
MH  - Antiviral Agents/therapeutic use
PMC - PMC11923463
OTO - NOTNLM
OT  - COVID-19
OT  - drugs
OT  - natural language processing
OT  - pharmacovigilance
OT  - public health
OT  - social media
COIS- Conflicts of Interest: None declared.
EDAT- 2025/03/07 18:22
MHDA- 2025/03/07 18:23
PMCR- 2025/03/05
CRDT- 2025/03/07 14:43
PHST- 2024/06/28 00:00 [received]
PHST- 2025/01/25 00:00 [accepted]
PHST- 2024/12/19 00:00 [revised]
PHST- 2025/03/07 18:23 [medline]
PHST- 2025/03/07 18:22 [pubmed]
PHST- 2025/03/07 14:43 [entrez]
PHST- 2025/03/05 00:00 [pmc-release]
AID - v27i1e63755 [pii]
AID - 10.2196/63755 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Mar 5;27:e63755. doi: 10.2196/63755.

PMID- 38779779
OWN - NLM
STAT- MEDLINE
DCOM- 20240530
LR  - 20240530
IS  - 1757-6334 (Electronic)
IS  - 0219-7200 (Linking)
VI  - 22
IP  - 2
DP  - 2024 Apr
TI  - How much can ChatGPT really help computational biologists in programming?
PG  - 2471001
LID - 10.1142/S021972002471001X [doi]
AB  - ChatGPT, a recently developed product by openAI, is successfully leaving its mark 
      as a multi-purpose natural language based chatbot. In this paper, we are more 
      interested in analyzing its potential in the field of computational biology. A 
      major share of work done by computational biologists these days involve coding up 
      bioinformatics algorithms, analyzing data, creating pipelining scripts and even 
      machine learning modeling and feature extraction. This paper focuses on the 
      potential influence (both positive and negative) of ChatGPT in the mentioned 
      aspects with illustrative examples from different perspectives. Compared to other 
      fields of computer science, computational biology has (1) less coding resources, 
      (2) more sensitivity and bias issues (deals with medical data), and (3) more 
      necessity of coding assistance (people from diverse background come to this 
      field). Keeping such issues in mind, we cover use cases such as code writing, 
      reviewing, debugging, converting, refactoring, and pipelining using ChatGPT from 
      the perspective of computational biologists in this paper.
FAU - Rahman, Chowdhury Rafeed
AU  - Rahman CR
AUID- ORCID: 0000-0001-5481-8025
AD  - Computer Science Department, National University of Singapore, Singapore.
FAU - Wong, Limsoon
AU  - Wong L
AUID- ORCID: 0000-0003-1241-5441
AD  - School of Computing, National University of Singapore, 13 Computing Drive, 
      Singapore 117417.
LA  - eng
PT  - Journal Article
DEP - 20240522
PL  - Singapore
TA  - J Bioinform Comput Biol
JT  - Journal of bioinformatics and computational biology
JID - 101187344
SB  - IM
MH  - *Computational Biology/methods
MH  - *Algorithms
MH  - Software
MH  - Programming Languages
MH  - Humans
MH  - Natural Language Processing
MH  - Machine Learning
OTO - NOTNLM
OT  - ChatGPT
OT  - computational biology
OT  - programming
EDAT- 2024/05/23 06:43
MHDA- 2024/05/30 06:35
CRDT- 2024/05/23 04:13
PHST- 2024/05/30 06:35 [medline]
PHST- 2024/05/23 06:43 [pubmed]
PHST- 2024/05/23 04:13 [entrez]
AID - 10.1142/S021972002471001X [doi]
PST - ppublish
SO  - J Bioinform Comput Biol. 2024 Apr;22(2):2471001. doi: 10.1142/S021972002471001X. 
      Epub 2024 May 22.

PMID- 39759269
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250107
IS  - 3005-1959 (Electronic)
IS  - 3005-1959 (Linking)
VI  - 1
IP  - 1
DP  - 2024
TI  - The doctor will polygraph you now.
PG  - 1
LID - 10.1038/s44401-024-00001-4 [doi]
LID - 1
AB  - Artificial intelligence (AI) methods have been proposed for the prediction of 
      social behaviors that could be reasonably understood from patient-reported 
      information. This raises novel ethical concerns about respect, privacy, and 
      control over patient data. Ethical concerns surrounding clinical AI systems for 
      social behavior verification can be divided into two main categories: (1) the 
      potential for inaccuracies/biases within such systems, and (2) the impact on 
      trust in patient-provider relationships with the introduction of automated AI 
      systems for "fact-checking", particularly in cases where the data/models may 
      contradict the patient. Additionally, this report simulated the misuse of a 
      verification system using patient voice samples and identified a potential LLM 
      bias against patient-reported information in favor of multi-dimensional data and 
      the outputs of other AI methods (i.e., "AI self-trust"). Finally, recommendations 
      were presented for mitigating the risk that AI verification methods will cause 
      harm to patients or undermine the purpose of the healthcare system.
CI  - © The Author(s) 2024.
FAU - Anibal, James
AU  - Anibal J
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD USA. ROR: https://ror.org/01cwqze88. GRID: 
      grid.94365.3d. ISNI: 0000 0001 2297 5165
AD  - Computational Health Informatics Lab, Institute of Biomedical Engineering, 
      Department of Engineering Science, University of Oxford, Oxford, UK. ROR: 
      https://ror.org/052gg0110. GRID: grid.4991.5. ISNI: 0000 0004 1936 8948
FAU - Gunkel, Jasmine
AU  - Gunkel J
AD  - Department of Bioethics, National Institutes of Health (NIH), Bethesda, MD USA. 
      ROR: https://ror.org/01cwqze88. GRID: grid.94365.3d. ISNI: 0000 0001 2297 5165
FAU - Awan, Shaheen
AU  - Awan S
AD  - Department of Communication Sciences & Disorders, University of Central Florida, 
      Orlando, FL USA. ROR: https://ror.org/036nfer12. GRID: grid.170430.1. ISNI: 0000 
      0001 2159 2859
FAU - Huth, Hannah
AU  - Huth H
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD USA. ROR: https://ror.org/01cwqze88. GRID: 
      grid.94365.3d. ISNI: 0000 0001 2297 5165
FAU - Nguyen, Hang
AU  - Nguyen H
AD  - Global Infectious Disease Program, Georgetown University, Washington, DC USA. 
      ROR: https://ror.org/05vzafd60. GRID: grid.213910.8. ISNI: 0000 0001 1955 1644
FAU - Le, Tram
AU  - Le T
AD  - College of Engineering, University of South Florida, Tampa, FL USA. ROR: 
      https://ror.org/032db5x82. GRID: grid.170693.a. ISNI: 0000 0001 2353 285X
FAU - Bélisle-Pipon, Jean-Christophe
AU  - Bélisle-Pipon JC
AD  - Faculty of Health Sciences, Simon Fraser University, Burnaby, BC Canada. ROR: 
      https://ror.org/0213rcc28. GRID: grid.61971.38. ISNI: 0000 0004 1936 7494
FAU - Boyer, Micah
AU  - Boyer M
AD  - USF Health Voice Center, Department of Otolaryngology-Head & Neck Surgery, 
      University of South Florida, Tampa, FL USA. ROR: https://ror.org/032db5x82. GRID: 
      grid.170693.a. ISNI: 0000 0001 2353 285X
FAU - Hazen, Lindsey
AU  - Hazen L
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD USA. ROR: https://ror.org/01cwqze88. GRID: 
      grid.94365.3d. ISNI: 0000 0001 2297 5165
CN  - Bridge2AI Voice Consortium
FAU - Bensoussan, Yael
AU  - Bensoussan Y
AD  - USF Health Voice Center, Department of Otolaryngology-Head & Neck Surgery, 
      University of South Florida, Tampa, FL USA. ROR: https://ror.org/032db5x82. GRID: 
      grid.170693.a. ISNI: 0000 0001 2353 285X
FAU - Clifton, David
AU  - Clifton D
AD  - Computational Health Informatics Lab, Institute of Biomedical Engineering, 
      Department of Engineering Science, University of Oxford, Oxford, UK. ROR: 
      https://ror.org/052gg0110. GRID: grid.4991.5. ISNI: 0000 0004 1936 8948
FAU - Wood, Bradford
AU  - Wood B
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD USA. ROR: https://ror.org/01cwqze88. GRID: 
      grid.94365.3d. ISNI: 0000 0001 2297 5165
LA  - eng
PT  - Journal Article
DEP - 20241205
PL  - England
TA  - Npj Health Syst
JT  - npj health systems
JID - 9918956761506676
PMC - PMC11698301
OTO - NOTNLM
OT  - Ethics
OT  - Machine learning
OT  - Science, technology and society
COIS- Competing interestsThe authors declare no competing interests.
FIR - Bensoussan, Yael
IR  - Bensoussan Y
IRAD- University of South Florida, Tampa, FL USA. ROR: https://ror.org/032db5x82. GRID: 
      grid.170693.a. ISNI: 0000 0001 2353 285X
FIR - Elemento, Olivier
IR  - Elemento O
IRAD- Weill Cornell Medicine, New York, NY USA. ROR: https://ror.org/02r109517. GRID: 
      grid.471410.7. ISNI: 0000 0001 2179 7643
FIR - Rameau, Anais
IR  - Rameau A
IRAD- Weill Cornell Medicine, New York, NY USA. ROR: https://ror.org/02r109517. GRID: 
      grid.471410.7. ISNI: 0000 0001 2179 7643
FIR - Sigaras, Alexandros
IR  - Sigaras A
IRAD- Weill Cornell Medicine, New York, NY USA. ROR: https://ror.org/02r109517. GRID: 
      grid.471410.7. ISNI: 0000 0001 2179 7643
FIR - Ghosh, Satrajit
IR  - Ghosh S
IRAD- Massachusetts Institute of Technology, Boston, MA USA. ROR: 
      https://ror.org/042nb2s44. GRID: grid.116068.8. ISNI: 0000 0001 2341 2786
FIR - Powell, Maria
IR  - Powell M
IRAD- Vanderbilt University Medical Center, Nashville, TN USA. ROR: 
      https://ror.org/05dq2gs74. GRID: grid.412807.8. ISNI: 0000 0004 1936 9916
FIR - Ravitsky, Vardit
IR  - Ravitsky V
IRAD- The Hasting Center, Garrison, NY USA. ROR: https://ror.org/02pmr4c75. GRID: 
      grid.418431.b. ISNI: 0000 0004 0403 3598
FIR - Bélisle-Pipon, Jean-Christophe
IR  - Bélisle-Pipon JC
IRAD- Simon Fraser University, Burnaby, BC Canada. ROR: https://ror.org/0213rcc28. 
      GRID: grid.61971.38. ISNI: 0000 0004 1936 7494
FIR - Dorr, David
IR  - Dorr D
IRAD- Oregon Health & Science University, Portland, OR USA. ROR: 
      https://ror.org/009avj582. GRID: grid.5288.7. ISNI: 0000 0000 9758 5690
FIR - Payne, Phillip
IR  - Payne P
IRAD- Washington University in St. Louis, St. Louis, MO USA. ROR: 
      https://ror.org/01yc7t268. GRID: grid.4367.6. ISNI: 0000 0004 1936 9350
FIR - Johnson, Alistair
IR  - Johnson A
IRAD- University of Toronto, Toronto, ON Canada. ROR: https://ror.org/03dbr7087. GRID: 
      grid.17063.33. ISNI: 0000 0001 2157 2938
FIR - Bahr, Ruth
IR  - Bahr R
IRAD- University of South Florida, Tampa, FL USA. ROR: https://ror.org/032db5x82. GRID: 
      grid.170693.a. ISNI: 0000 0001 2353 285X
FIR - Bolser, Donald
IR  - Bolser D
IRAD- University of Florida, Gainesville, FL USA. ROR: https://ror.org/02y3ad647. GRID: 
      grid.15276.37. ISNI: 0000 0004 1936 8091
FIR - Rudzicz, Frank
IR  - Rudzicz F
IRAD- Dalhousie University, Toronto, ON Canada. ROR: https://ror.org/01e6qks80. GRID: 
      grid.55602.34. ISNI: 0000 0004 1936 8200
FIR - Lerner-Ellis, Jordan
IR  - Lerner-Ellis J
IRAD- University of Toronto, Toronto, ON Canada. ROR: https://ror.org/03dbr7087. GRID: 
      grid.17063.33. ISNI: 0000 0001 2157 2938
FIR - Awan, Shaheen
IR  - Awan S
IRAD- University of Central Florida, Orlando, FL USA. ROR: https://ror.org/036nfer12. 
      GRID: grid.170430.1. ISNI: 0000 0001 2159 2859
FIR - Watts, Stephanie
IR  - Watts S
IRAD- University of South Florida, Tampa, FL USA. ROR: https://ror.org/032db5x82. GRID: 
      grid.170693.a. ISNI: 0000 0001 2353 285X
FIR - Siu, Jennifer
IR  - Siu J
IRAD- Hospital for Sick Children, Toronto, ON Canada. ROR: https://ror.org/057q4rt57. 
      GRID: grid.42327.30. ISNI: 0000 0004 0473 9646
FIR - Hanna, Karim
IR  - Hanna K
IRAD- University of South Florida, Tampa, FL USA. ROR: https://ror.org/032db5x82. GRID: 
      grid.170693.a. ISNI: 0000 0001 2353 285X
FIR - Zesiewicz, Theresa
IR  - Zesiewicz T
IRAD- University of South Florida, Tampa, FL USA. ROR: https://ror.org/032db5x82. GRID: 
      grid.170693.a. ISNI: 0000 0001 2353 285X
FIR - Zhao, Robin
IR  - Zhao R
IRAD- Weill Cornell Medicine, New York, NY USA. ROR: https://ror.org/02r109517. GRID: 
      grid.471410.7. ISNI: 0000 0001 2179 7643
FIR - Jayachandran, Lochana
IR  - Jayachandran L
IRAD- Mount Sinai Hospital, Toronto, ON Canada. ROR: https://ror.org/05deks119. GRID: 
      grid.416166.2. ISNI: 0000 0004 0473 9881
FIR - Cruz, Samantha Salvi
IR  - Cruz SS
IRAD- Vanderbilt University Medical Center, Nashville, TN USA. ROR: 
      https://ror.org/05dq2gs74. GRID: grid.412807.8. ISNI: 0000 0004 1936 9916
EDAT- 2025/01/06 10:07
MHDA- 2025/01/06 10:08
PMCR- 2024/12/05
CRDT- 2025/01/06 05:32
PHST- 2024/08/20 00:00 [received]
PHST- 2024/11/15 00:00 [accepted]
PHST- 2025/01/06 10:08 [medline]
PHST- 2025/01/06 10:07 [pubmed]
PHST- 2025/01/06 05:32 [entrez]
PHST- 2024/12/05 00:00 [pmc-release]
AID - 1 [pii]
AID - 10.1038/s44401-024-00001-4 [doi]
PST - ppublish
SO  - Npj Health Syst. 2024;1(1):1. doi: 10.1038/s44401-024-00001-4. Epub 2024 Dec 5.

PMID- 38662419
OWN - NLM
STAT- MEDLINE
DCOM- 20240425
LR  - 20240512
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Apr 25
TI  - Large Language Models and User Trust: Consequence of Self-Referential Learning 
      Loop and the Deskilling of Health Care Professionals.
PG  - e56764
LID - 10.2196/56764 [doi]
LID - e56764
AB  - As the health care industry increasingly embraces large language models (LLMs), 
      understanding the consequence of this integration becomes crucial for maximizing 
      benefits while mitigating potential pitfalls. This paper explores the evolving 
      relationship among clinician trust in LLMs, the transition of data sources from 
      predominantly human-generated to artificial intelligence (AI)-generated content, 
      and the subsequent impact on the performance of LLMs and clinician competence. 
      One of the primary concerns identified in this paper is the LLMs' 
      self-referential learning loops, where AI-generated content feeds into the 
      learning algorithms, threatening the diversity of the data pool, potentially 
      entrenching biases, and reducing the efficacy of LLMs. While theoretical at this 
      stage, this feedback loop poses a significant challenge as the integration of 
      LLMs in health care deepens, emphasizing the need for proactive dialogue and 
      strategic measures to ensure the safe and effective use of LLM technology. 
      Another key takeaway from our investigation is the role of user expertise and the 
      necessity for a discerning approach to trusting and validating LLM outputs. The 
      paper highlights how expert users, particularly clinicians, can leverage LLMs to 
      enhance productivity by off-loading routine tasks while maintaining a critical 
      oversight to identify and correct potential inaccuracies in AI-generated content. 
      This balance of trust and skepticism is vital for ensuring that LLMs augment 
      rather than undermine the quality of patient care. We also discuss the risks 
      associated with the deskilling of health care professionals. Frequent reliance on 
      LLMs for critical tasks could result in a decline in health care providers' 
      diagnostic and thinking skills, particularly affecting the training and 
      development of future professionals. The legal and ethical considerations 
      surrounding the deployment of LLMs in health care are also examined. We discuss 
      the medicolegal challenges, including liability in cases of erroneous diagnoses 
      or treatment advice generated by LLMs. The paper references recent legislative 
      efforts, such as The Algorithmic Accountability Act of 2023, as crucial steps 
      toward establishing a framework for the ethical and responsible use of AI-based 
      technologies in health care. In conclusion, this paper advocates for a strategic 
      approach to integrating LLMs into health care. By emphasizing the importance of 
      maintaining clinician expertise, fostering critical engagement with LLM outputs, 
      and navigating the legal and ethical landscape, we can ensure that LLMs serve as 
      valuable tools in enhancing patient care and supporting health care 
      professionals. This approach addresses the immediate challenges posed by 
      integrating LLMs and sets a foundation for their maintainable and responsible use 
      in the future.
CI  - ©Avishek Choudhury, Zaira Chaudhry. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 25.04.2024.
FAU - Choudhury, Avishek
AU  - Choudhury A
AUID- ORCID: 0000-0002-5342-0709
AD  - Industrial and Management Systems Engineering, West Virginia University, 
      Morgantown, WV, United States.
FAU - Chaudhry, Zaira
AU  - Chaudhry Z
AUID- ORCID: 0000-0002-2855-0667
AD  - Industrial and Management Systems Engineering, West Virginia University, 
      Morgantown, WV, United States.
LA  - eng
PT  - Journal Article
DEP - 20240425
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Trust
MH  - *Artificial Intelligence
MH  - *Health Personnel/psychology
MH  - Language
MH  - Learning
PMC - PMC11082730
OTO - NOTNLM
OT  - AI accountability
OT  - AI technology
OT  - ChatGPT
OT  - LLM user trust
OT  - LLMs
OT  - artificial intelligence
OT  - effectiveness
OT  - healthcare
OT  - healthcare professional
OT  - healthcare professionals
OT  - human element
OT  - human factors
OT  - large language models
OT  - medical student
OT  - medical students
OT  - policy
OT  - quality of care
OT  - risk factor
OT  - technologies
OT  - trust
COIS- Conflicts of Interest: None declared.
EDAT- 2024/04/25 12:53
MHDA- 2024/04/25 18:56
PMCR- 2024/04/25
CRDT- 2024/04/25 11:53
PHST- 2024/01/25 00:00 [received]
PHST- 2024/03/20 00:00 [accepted]
PHST- 2024/03/12 00:00 [revised]
PHST- 2024/04/25 18:56 [medline]
PHST- 2024/04/25 12:53 [pubmed]
PHST- 2024/04/25 11:53 [entrez]
PHST- 2024/04/25 00:00 [pmc-release]
AID - v26i1e56764 [pii]
AID - 10.2196/56764 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Apr 25;26:e56764. doi: 10.2196/56764.

PMID- 31095055
OWN - NLM
STAT- MEDLINE
DCOM- 20200428
LR  - 20211204
IS  - 1537-1948 (Electronic)
IS  - 0025-7079 (Print)
IS  - 0025-7079 (Linking)
VI  - 57 Suppl 6 Suppl 2
IP  - Suppl 6 2
DP  - 2019 Jun
TI  - Measuring Exposure to Incarceration Using the Electronic Health Record.
PG  - S157-S163
LID - 10.1097/MLR.0000000000001049 [doi]
AB  - BACKGROUND: Electronic health records (EHRs) are a rich source of health 
      information; however social determinants of health, including incarceration, and 
      how they impact health and health care disparities can be hard to extract. 
      OBJECTIVE: The main objective of this study was to compare sensitivity and 
      specificity of patient self-report with various methods of identifying 
      incarceration exposure using the EHR. RESEARCH DESIGN: Validation study using 
      multiple data sources and types. SUBJECTS: Participants of the Veterans Aging 
      Cohort Study (VACS), a national observational cohort based on data from the 
      Veterans Health Administration (VHA) EHR that includes all human immunodeficiency 
      virus-infected patients in care (47,805) and uninfected patients (99,060) matched 
      on region, age, race/ethnicity, and sex. MEASURES AND DATA SOURCES: Self-reported 
      incarceration history compared with: (1) linked VHA EHR data to administrative 
      data from a state Department of Correction (DOC), (2) linked VHA EHR data to 
      administrative data on incarceration from Centers for Medicare and Medicaid 
      Services (CMS), (3) VHA EHR-specific identifier codes indicative of receipt of 
      VHA incarceration reentry services, and (4) natural language processing (NLP) in 
      unstructured text in VHA EHR. RESULTS: Linking the EHR to DOC data: sensitivity 
      2.5%, specificity 100%; linking the EHR to CMS data: sensitivity 7.9%, 
      specificity 99.3%; VHA EHR-specific identifier for receipt of reentry services: 
      sensitivity 7.3%, specificity 98.9%; and NLP, sensitivity 63.5%, specificity 
      95.9%. CONCLUSIONS: NLP tools hold promise as a feasible and valid method to 
      identify individuals with exposure to incarceration in EHR. Future work should 
      expand this approach using a larger body of documents and refinement of the 
      methods, which may further improve operating characteristics of this method.
FAU - Wang, Emily A
AU  - Wang EA
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
FAU - Long, Jessica B
AU  - Long JB
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
FAU - McGinnis, Kathleen A
AU  - McGinnis KA
AD  - Veterans Administration Connecticut Healthcare System, West Haven, CT.
FAU - Wang, Karen H
AU  - Wang KH
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
AD  - Veterans Administration Connecticut Healthcare System, West Haven, CT.
FAU - Wildeman, Christopher J
AU  - Wildeman CJ
AD  - Department of Policy Analysis and Management, Cornell University, Ithaca, NY.
FAU - Kim, Clara
AU  - Kim C
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
FAU - Bucklen, Kristofer B
AU  - Bucklen KB
AD  - Pennsylvania Department of Correction, PA.
FAU - Fiellin, David A
AU  - Fiellin DA
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
AD  - Center for Interdisciplinary Research on AIDS, Yale University School of Public 
      Health, New Haven, CT.
FAU - Bates, Jonathan
AU  - Bates J
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
FAU - Brandt, Cynthia
AU  - Brandt C
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
AD  - Veterans Administration Connecticut Healthcare System, West Haven, CT.
FAU - Justice, Amy C
AU  - Justice AC
AD  - Department of Internal Medicine, Yale University School of Medicine, New Haven.
AD  - Veterans Administration Connecticut Healthcare System, West Haven, CT.
AD  - Center for Interdisciplinary Research on AIDS, Yale University School of Public 
      Health, New Haven, CT.
LA  - eng
GR  - R03 DA031592/DA/NIDA NIH HHS/United States
GR  - U01 AA020790/AA/NIAAA NIH HHS/United States
GR  - U10 AA013566/AA/NIAAA NIH HHS/United States
GR  - U24 AA020794/AA/NIAAA NIH HHS/United States
PT  - Journal Article
PT  - Observational Study
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, U.S. Gov't, P.H.S.
PT  - Validation Study
PL  - United States
TA  - Med Care
JT  - Medical care
JID - 0230027
SB  - IM
MH  - Administrative Claims, Healthcare/*statistics & numerical data
MH  - Adult
MH  - Cohort Studies
MH  - Electronic Health Records/*statistics & numerical data
MH  - Ethnicity
MH  - Female
MH  - Humans
MH  - Information Storage and Retrieval
MH  - Male
MH  - Medicare/statistics & numerical data
MH  - Middle Aged
MH  - *Natural Language Processing
MH  - Prisoners/*statistics & numerical data
MH  - *Self Report
MH  - Sensitivity and Specificity
MH  - United States
MH  - United States Department of Veterans Affairs
MH  - Veterans/*statistics & numerical data
PMC - PMC8352066
MID - NIHMS1514521
COIS- Conflict of interest statement: The authors of this manuscript have no 
      affiliations with or involvement in any organization or entity with any financial 
      interest (such as honoraria; educational grants; participation in speakers’ 
      bureaus; membership, employment, consultancies, stock ownership, or other equity 
      interest; and expert testimony or patent-licensing arrangements), or 
      non-financial interest (such as personal or professional relationships, 
      affiliations, knowledge or beliefs) in the subject matter or materials discussed 
      in this manuscript.
EDAT- 2019/05/17 06:00
MHDA- 2020/04/29 06:00
PMCR- 2021/08/09
CRDT- 2019/05/17 06:00
PHST- 2019/05/17 06:00 [entrez]
PHST- 2019/05/17 06:00 [pubmed]
PHST- 2020/04/29 06:00 [medline]
PHST- 2021/08/09 00:00 [pmc-release]
AID - 00005650-201906001-00012 [pii]
AID - 10.1097/MLR.0000000000001049 [doi]
PST - ppublish
SO  - Med Care. 2019 Jun;57 Suppl 6 Suppl 2(Suppl 6 2):S157-S163. doi: 
      10.1097/MLR.0000000000001049.

PMID- 39946180
OWN - NLM
STAT- MEDLINE
DCOM- 20250213
LR  - 20250309
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Feb 13
TI  - Laypeople's Use of and Attitudes Toward Large Language Models and Search Engines 
      for Health Queries: Survey Study.
PG  - e64290
LID - 10.2196/64290 [doi]
LID - e64290
AB  - BACKGROUND: Laypeople have easy access to health information through large 
      language models (LLMs), such as ChatGPT, and search engines, such as Google. 
      Search engines transformed health information access, and LLMs offer a new avenue 
      for answering laypeople's questions. OBJECTIVE: We aimed to compare the frequency 
      of use and attitudes toward LLMs and search engines as well as their comparative 
      relevance, usefulness, ease of use, and trustworthiness in responding to health 
      queries. METHODS: We conducted a screening survey to compare the demographics of 
      LLM users and nonusers seeking health information, analyzing results with 
      logistic regression. LLM users from the screening survey were invited to a 
      follow-up survey to report the types of health information they sought. We 
      compared the frequency of use of LLMs and search engines using ANOVA and Tukey 
      post hoc tests. Lastly, paired-sample Wilcoxon tests compared LLMs and search 
      engines on perceived usefulness, ease of use, trustworthiness, feelings, bias, 
      and anthropomorphism. RESULTS: In total, 2002 US participants recruited on 
      Prolific participated in the screening survey about the use of LLMs and search 
      engines. Of them, 52% (n=1045) of the participants were female, with a mean age 
      of 39 (SD 13) years. Participants were 9.7% (n=194) Asian, 12.1% (n=242) Black, 
      73.3% (n=1467) White, 1.1% (n=22) Hispanic, and 3.8% (n=77) were of other races 
      and ethnicities. Further, 1913 (95.6%) used search engines to look up health 
      queries versus 642 (32.6%) for LLMs. Men had higher odds (odds ratio [OR] 1.63, 
      95% CI 1.34-1.99; P<.001) of using LLMs for health questions than women. Black 
      (OR 1.90, 95% CI 1.42-2.54; P<.001) and Asian (OR 1.66, 95% CI 1.19-2.30; P<.01) 
      individuals had higher odds than White individuals. Those with excellent 
      perceived health (OR 1.46, 95% CI 1.1-1.93; P=.01) were more likely to use LLMs 
      than those with good health. Higher technical proficiency increased the 
      likelihood of LLM use (OR 1.26, 95% CI 1.14-1.39; P<.001). In a follow-up survey 
      of 281 LLM users for health, most participants used search engines first (n=174, 
      62%) to answer health questions, but the second most common first source 
      consulted was LLMs (n=39, 14%). LLMs were perceived as less useful (P<.01) and 
      less relevant (P=.07), but elicited fewer negative feelings (P<.001), appeared 
      more human (LLM: n=160, vs search: n=32), and were seen as less biased (P<.001). 
      Trust (P=.56) and ease of use (P=.27) showed no differences. CONCLUSIONS: Search 
      engines are the primary source of health information; yet, positive perceptions 
      of LLMs suggest growing use. Future work could explore whether LLM trust and 
      usefulness are enhanced by supplementing answers with external references and 
      limiting persuasive language to curb overreliance. Collaboration with health 
      organizations can help improve the quality of LLMs' health output.
CI  - ©Tamir Mendel, Nina Singh, Devin M Mann, Batia Wiesenfeld, Oded Nov. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      13.02.2025.
FAU - Mendel, Tamir
AU  - Mendel T
AUID- ORCID: 0000-0002-7127-0345
AD  - Department of Technology Management and Innovation, Tandon School of Engineering, 
      New York University, New York, NY, United States.
FAU - Singh, Nina
AU  - Singh N
AUID- ORCID: 0000-0002-4623-2451
AD  - Department of Medicine, School of Medicine, University of California, San 
      Francisco, San Francisco, CA, United States.
FAU - Mann, Devin M
AU  - Mann DM
AUID- ORCID: 0000-0002-2099-0852
AD  - Department of Population Health, Grossman School of Medicine, New York 
      University, New York, NY, United States.
FAU - Wiesenfeld, Batia
AU  - Wiesenfeld B
AUID- ORCID: 0000-0002-6854-1976
AD  - Department of Management and Organizations, Stern School of Business, New York 
      University, New York, NY, United States.
FAU - Nov, Oded
AU  - Nov O
AUID- ORCID: 0000-0001-6410-2995
AD  - Department of Technology Management and Innovation, Tandon School of Engineering, 
      New York University, New York, NY, United States.
LA  - eng
PT  - Journal Article
DEP - 20250213
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Search Engine/statistics & numerical data
MH  - Female
MH  - Adult
MH  - Male
MH  - Middle Aged
MH  - Language
MH  - Surveys and Questionnaires
MH  - Young Adult
PMC - PMC11888097
OTO - NOTNLM
OT  - Google
OT  - LLMs
OT  - United States
OT  - artificial intelligence
OT  - internet
OT  - large language model
OT  - mobile phone
OT  - online health information
OT  - search engine
OT  - survey
COIS- Conflicts of Interest: None declared.
EDAT- 2025/02/13 12:27
MHDA- 2025/02/13 23:03
PMCR- 2025/02/13
CRDT- 2025/02/13 11:54
PHST- 2024/07/14 00:00 [received]
PHST- 2024/12/25 00:00 [accepted]
PHST- 2024/11/11 00:00 [revised]
PHST- 2025/02/13 23:03 [medline]
PHST- 2025/02/13 12:27 [pubmed]
PHST- 2025/02/13 11:54 [entrez]
PHST- 2025/02/13 00:00 [pmc-release]
AID - v27i1e64290 [pii]
AID - 10.2196/64290 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Feb 13;27:e64290. doi: 10.2196/64290.

PMID- 39987667
OWN - NLM
STAT- MEDLINE
DCOM- 20250312
LR  - 20250312
IS  - 1872-7565 (Electronic)
IS  - 0169-2607 (Linking)
VI  - 263
DP  - 2025 May
TI  - Fine-tuning large language models for improved health communication in 
      low-resource languages.
PG  - 108655
LID - S0169-2607(25)00072-0 [pii]
LID - 10.1016/j.cmpb.2025.108655 [doi]
AB  - BACKGROUND: The reported study illustrates a methodology for compiling training 
      datasets to fine-tune Large Language Models (LLMs) for healthcare information in 
      Vietnamese, a low-resource language. The objective is to bridge the gap in 
      medical information accessibility and enhance healthcare communication in 
      developing countries by adapting LLMs to specific linguistic nuances and domain 
      needs. METHOD: The methodology involves selecting a base model, compiling a 
      domain-specific dataset, and fine-tuning the model with this dataset. Three 
      open-source models were selected. The dataset, comprising approximately 337,000 
      prompt-response pairs in Vietnamese, was compiled using existing datasets, data 
      crawled from Vietnamese medical online forums, and distilled from Vietnamese 
      medical textbooks. The three models were fine-tuned using the Low-Rank adaptation 
      (LoRA) and Quantized Low-Rank adaptation (QLoRA) techniques. Models' performances 
      were evaluated using BertScore score, Rouge-L score, and the "LLM-as-a-Judge" 
      method. RESULTS: The fine-tuned models showed enhancements in performance over 
      their base versions across evaluation metrics in BertScore score, Rouge-L score 
      and "LLM-as-a-Judge" method, confirming the effectiveness of the fine-tuning 
      process. This study details the process of fine-tuning open-source LLMs for 
      health information inquiries in Vietnamese, demonstrating its potential to 
      improve healthcare communication in low-resource languages. Deploying the 
      fine-tuned LLM on-premise enhances data privacy and security. However, the 
      significant computing power and costs required pose challenges, especially for 
      organizations in developing countries. CONCLUSION: This case study highlights the 
      unique challenges faced by developing countries using low-resource languages. 
      Initiatives are needed to emphasize efforts to bridge healthcare gaps in 
      underserved areas and contribute to global health equity.
CI  - Copyright © 2025 The Author(s). Published by Elsevier B.V. All rights reserved.
FAU - Bui, Nhat
AU  - Bui N
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam.
FAU - Nguyen, Giang
AU  - Nguyen G
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam.
FAU - Nguyen, Nguyen
AU  - Nguyen N
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam.
FAU - Vo, Bao
AU  - Vo B
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam.
FAU - Vo, Luan
AU  - Vo L
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam.
FAU - Huynh, Tom
AU  - Huynh T
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam.
FAU - Tang, Arthur
AU  - Tang A
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam. Electronic address: arthur.tang@rmit.edu.vn.
FAU - Tran, Van Nhiem
AU  - Tran VN
AD  - AI Research Center, Hon Hai Research Institute, Taipei 114699, Taiwan.
FAU - Huynh, Tuyen
AU  - Huynh T
AD  - Oxford University Clinical Research Unit (OUCRU), Ho Chi Minh City, Vietnam.
FAU - Nguyen, Huy Quang
AU  - Nguyen HQ
AD  - Oxford University Clinical Research Unit (OUCRU), Ho Chi Minh City, Vietnam.
FAU - Dinh, Minh
AU  - Dinh M
AD  - School of Science, Engineering and Technology, RMIT University, Ho Chi Minh City, 
      Vietnam.
LA  - eng
PT  - Journal Article
DEP - 20250212
PL  - Ireland
TA  - Comput Methods Programs Biomed
JT  - Computer methods and programs in biomedicine
JID - 8506513
SB  - IM
MH  - Humans
MH  - Vietnam
MH  - *Language
MH  - Health Communication/methods
MH  - Developing Countries
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Data privacy and security
OT  - Health communication and promotion
OT  - Health equity
OT  - Large language model
OT  - Low-resources languages
COIS- Declaration of competing interest The authors declare that there is no conflict 
      of interest.
EDAT- 2025/02/24 02:10
MHDA- 2025/03/13 00:33
CRDT- 2025/02/23 18:03
PHST- 2024/05/27 00:00 [received]
PHST- 2024/12/10 00:00 [revised]
PHST- 2025/02/05 00:00 [accepted]
PHST- 2025/03/13 00:33 [medline]
PHST- 2025/02/24 02:10 [pubmed]
PHST- 2025/02/23 18:03 [entrez]
AID - S0169-2607(25)00072-0 [pii]
AID - 10.1016/j.cmpb.2025.108655 [doi]
PST - ppublish
SO  - Comput Methods Programs Biomed. 2025 May;263:108655. doi: 
      10.1016/j.cmpb.2025.108655. Epub 2025 Feb 12.

PMID- 39451418
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241027
IS  - 2306-5354 (Print)
IS  - 2306-5354 (Electronic)
IS  - 2306-5354 (Linking)
VI  - 11
IP  - 10
DP  - 2024 Oct 18
TI  - GPT-Driven Radiology Report Generation with Fine-Tuned Llama 3.
LID - 10.3390/bioengineering11101043 [doi]
LID - 1043
AB  - The integration of deep learning into radiology has the potential to enhance 
      diagnostic processes, yet its acceptance in clinical practice remains limited due 
      to various challenges. This study aimed to develop and evaluate a fine-tuned 
      large language model (LLM), based on Llama 3-8B, to automate the generation of 
      accurate and concise conclusions in magnetic resonance imaging (MRI) and computed 
      tomography (CT) radiology reports, thereby assisting radiologists and improving 
      reporting efficiency. A dataset comprising 15,000 radiology reports was collected 
      from the University of Medicine and Pharmacy of Craiova's Imaging Center, 
      covering a diverse range of MRI and CT examinations made by four experienced 
      radiologists. The Llama 3-8B model was fine-tuned using transfer-learning 
      techniques, incorporating parameter quantization to 4-bit precision and low-rank 
      adaptation (LoRA) with a rank of 16 to optimize computational efficiency on 
      consumer-grade GPUs. The model was trained over five epochs using an NVIDIA RTX 
      3090 GPU, with intermediary checkpoints saved for monitoring. Performance was 
      evaluated quantitatively using Bidirectional Encoder Representations from 
      Transformers Score (BERTScore), Recall-Oriented Understudy for Gisting Evaluation 
      (ROUGE), Bilingual Evaluation Understudy (BLEU), and Metric for Evaluation of 
      Translation with Explicit Ordering (METEOR) metrics on a held-out test set. 
      Additionally, a qualitative assessment was conducted, involving 13 independent 
      radiologists who participated in a Turing-like test and provided ratings for the 
      AI-generated conclusions. The fine-tuned model demonstrated strong quantitative 
      performance, achieving a BERTScore F1 of 0.8054, a ROUGE-1 F1 of 0.4998, a 
      ROUGE-L F1 of 0.4628, and a METEOR score of 0.4282. In the human evaluation, the 
      artificial intelligence (AI)-generated conclusions were preferred over 
      human-written ones in approximately 21.8% of cases, indicating that the model's 
      outputs were competitive with those of experienced radiologists. The average 
      rating of the AI-generated conclusions was 3.65 out of 5, reflecting a generally 
      favorable assessment. Notably, the model maintained its consistency across 
      various types of reports and demonstrated the ability to generalize to unseen 
      data. The fine-tuned Llama 3-8B model effectively generates accurate and coherent 
      conclusions for MRI and CT radiology reports. By automating the 
      conclusion-writing process, this approach can assist radiologists in reducing 
      their workload and enhancing report consistency, potentially addressing some 
      barriers to the adoption of deep learning in clinical practice. The positive 
      evaluations from independent radiologists underscore the model's potential 
      utility. While the model demonstrated strong performance, limitations such as 
      dataset bias, limited sample diversity, a lack of clinical judgment, and the need 
      for large computational resources require further refinement and real-world 
      validation. Future work should explore the integration of such models into 
      clinical workflows, address ethical and legal considerations, and extend this 
      approach to generate complete radiology reports.
FAU - Voinea, Ștefan-Vlad
AU  - Voinea ȘV
AD  - Department of Automatic Control and Electronics, University of Craiova, 200585 
      Craiova, Romania.
FAU - Mămuleanu, Mădălin
AU  - Mămuleanu M
AUID- ORCID: 0000-0003-1524-2494
AD  - Department of Automatic Control and Electronics, University of Craiova, 200585 
      Craiova, Romania.
FAU - Teică, Rossy Vlăduț
AU  - Teică RV
AUID- ORCID: 0009-0004-9147-7951
AD  - Doctoral School, University of Medicine and Pharmacy of Craiova, 200349 Craiova, 
      Romania.
FAU - Florescu, Lucian Mihai
AU  - Florescu LM
AD  - Department of Radiology and Medical Imaging, University of Medicine and Pharmacy 
      of Craiova, 200349 Craiova, Romania.
FAU - Selișteanu, Dan
AU  - Selișteanu D
AUID- ORCID: 0000-0002-9770-405X
AD  - Department of Automatic Control and Electronics, University of Craiova, 200585 
      Craiova, Romania.
FAU - Gheonea, Ioana Andreea
AU  - Gheonea IA
AUID- ORCID: 0009-0000-0954-1266
AD  - Department of Radiology and Medical Imaging, University of Medicine and Pharmacy 
      of Craiova, 200349 Craiova, Romania.
LA  - eng
PT  - Journal Article
DEP - 20241018
PL  - Switzerland
TA  - Bioengineering (Basel)
JT  - Bioengineering (Basel, Switzerland)
JID - 101676056
PMC - PMC11504957
OTO - NOTNLM
OT  - AI in healthcare
OT  - CT scans
OT  - Llama 3
OT  - MRI reports
OT  - automated report generation
OT  - convolutional neural networks
OT  - deep learning
OT  - diagnostic imaging
OT  - large language models
OT  - radiology
COIS- The authors declare no conflicts of interest.
EDAT- 2024/10/25 12:24
MHDA- 2024/10/25 12:25
PMCR- 2024/10/18
CRDT- 2024/10/25 09:54
PHST- 2024/08/08 00:00 [received]
PHST- 2024/10/05 00:00 [revised]
PHST- 2024/10/16 00:00 [accepted]
PHST- 2024/10/25 12:25 [medline]
PHST- 2024/10/25 12:24 [pubmed]
PHST- 2024/10/25 09:54 [entrez]
PHST- 2024/10/18 00:00 [pmc-release]
AID - bioengineering11101043 [pii]
AID - bioengineering-11-01043 [pii]
AID - 10.3390/bioengineering11101043 [doi]
PST - epublish
SO  - Bioengineering (Basel). 2024 Oct 18;11(10):1043. doi: 
      10.3390/bioengineering11101043.

PMID- 40121315
OWN - NLM
STAT- MEDLINE
DCOM- 20250323
LR  - 20250325
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 15
IP  - 1
DP  - 2025 Mar 22
TI  - Evaluating the quality of medical content on YouTube using large language models.
PG  - 9906
LID - 10.1038/s41598-025-94208-6 [doi]
LID - 9906
AB  - YouTube has become a dominant source of medical information and health-related 
      decision-making. Yet, many videos on this platform contain inaccurate or biased 
      information. Although expert reviews could help mitigate this situation, the vast 
      number of daily uploads makes this solution impractical. In this study, we 
      explored the potential of Large Language Models (LLMs) to assess the quality of 
      medical content on YouTube. We collected a set of videos previously evaluated by 
      experts and prompted twenty models to rate their quality using the DISCERN 
      instrument. We then analyzed the inter-rater agreement between the language 
      models' and experts' ratings using Brennan-Prediger's (BP) Kappa. We found that 
      LLMs exhibited a wide range of inter-rater agreements with the experts (ranging 
      from -1.10 to 0.82). All models tended to give higher scores than the human 
      experts. The agreement on individual questions tended to be lower, with some 
      questions showing significant disagreement between models and experts. Including 
      scoring guidelines in the prompt has improved model performance. We conclude that 
      some LLMs are capable of evaluating the quality of medical videos. If used as 
      stand-alone expert systems or embedded into traditional recommender systems, 
      these models can mitigate the quality issue of health-related online videos.
CI  - © 2025. The Author(s).
FAU - Khalil, Mahmoud
AU  - Khalil M
AD  - Computer Science Department, Western University, London, ON, Canada.
FAU - Mohamed, Fatma
AU  - Mohamed F
AD  - Center for Cyber-Physical Systems (C2PS), Computer Science Department, Khalifa 
      University, Abu Dhabi, UAE. fatma.mohamed@ku.ac.ae.
FAU - Shoufan, Abdulhadi
AU  - Shoufan A
AD  - Center for Cyber-Physical Systems (C2PS), Computer Science Department, Khalifa 
      University, Abu Dhabi, UAE.
AD  - Computer and Information Engineering Department, Khalifa University, Abu Dhabi, 
      UAE.
LA  - eng
PT  - Journal Article
DEP - 20250322
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Humans
MH  - *Social Media
MH  - *Video Recording
MH  - Language
MH  - Information Dissemination/methods
PMC - PMC11929840
OTO - NOTNLM
OT  - Content quality
OT  - LLMs
OT  - Medical content
OT  - YouTube
COIS- Declarations. Competing interests: The authors declare no competing interests.
EDAT- 2025/03/23 16:52
MHDA- 2025/03/23 16:53
PMCR- 2025/03/22
CRDT- 2025/03/23 00:20
PHST- 2024/10/17 00:00 [received]
PHST- 2025/03/12 00:00 [accepted]
PHST- 2025/03/23 16:53 [medline]
PHST- 2025/03/23 16:52 [pubmed]
PHST- 2025/03/23 00:20 [entrez]
PHST- 2025/03/22 00:00 [pmc-release]
AID - 10.1038/s41598-025-94208-6 [pii]
AID - 94208 [pii]
AID - 10.1038/s41598-025-94208-6 [doi]
PST - epublish
SO  - Sci Rep. 2025 Mar 22;15(1):9906. doi: 10.1038/s41598-025-94208-6.

PMID- 38269900
OWN - NLM
STAT- MEDLINE
DCOM- 20240126
LR  - 20240206
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 310
DP  - 2024 Jan 25
TI  - Developing Robust Clinical Text Deep Learning Models - A "Painless" Approach.
PG  - 705-709
LID - 10.3233/SHTI231056 [doi]
AB  - The success of deep learning in natural language processing relies on ample 
      labelled training data. However, models in the health domain often face data 
      inadequacy due to the high cost and difficulty of acquiring training data. 
      Developing such models thus requires robustness and performance on new data. A 
      generalised incremental multiphase framework is proposed for developing robust 
      and performant clinical text deep learning classifiers. It incorporates 
      incremental multiphases for training data size assessments, cross-validation 
      setup to avoid test data bias, and robustness testing through inter/intra-model 
      significance analysis. The framework's effectiveness and generalisation were 
      confirmed by the task of identifying patients presenting in 'pain' to the 
      emergency department.
FAU - Wu, Yutong
AU  - Wu Y
AD  - The Australian e-Health Research Centre, CSIRO, Brisbane, Australia.
FAU - Hughes, James A
AU  - Hughes JA
AD  - School of Nursing, Centre for Healthcare Transformation, Queensland University of 
      Technology, Brisbane, Australia.
AD  - Emergency and Trauma Centre, Royal Brisbane and Women's Hospital, Brisbane, 
      Australia.
FAU - Lyrstedt, Anna-Lisa
AU  - Lyrstedt AL
AD  - Emergency and Trauma Centre, Royal Brisbane and Women's Hospital, Brisbane, 
      Australia.
FAU - Hazelwood, Sarah
AU  - Hazelwood S
AD  - Emergency Department, The Prince Charles Hospital, Brisbane, Australia.
FAU - Brown, Nathan J
AU  - Brown NJ
AD  - Emergency and Trauma Centre, Royal Brisbane and Women's Hospital, Brisbane, 
      Australia.
AD  - Faculty of Medicine, University of Queensland, Brisbane, Australia.
FAU - Jones, Lee
AU  - Jones L
AD  - School of Public Health and Social Work, Queensland University of Technology, 
      Brisbane, Australia.
FAU - Douglas, Clint
AU  - Douglas C
AD  - School of Nursing, Centre for Healthcare Transformation, Queensland University of 
      Technology, Brisbane, Australia.
AD  - Metro North Health, Brisbane, Australia.
FAU - Jarugula, Rajeev
AU  - Jarugula R
AD  - Emergency Department, The Prince Charles Hospital, Brisbane, Australia.
FAU - Chu, Kevin
AU  - Chu K
AD  - Emergency and Trauma Centre, Royal Brisbane and Women's Hospital, Brisbane, 
      Australia.
AD  - Faculty of Medicine, University of Queensland, Brisbane, Australia.
FAU - Nguyen, Anthony
AU  - Nguyen A
AD  - The Australian e-Health Research Centre, CSIRO, Brisbane, Australia.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - Humans
MH  - *Deep Learning
MH  - Emergency Service, Hospital
MH  - Natural Language Processing
MH  - Pain
MH  - Research Design
OTO - NOTNLM
OT  - Pain
OT  - deep learning
OT  - emergency department
OT  - language model
OT  - text classification
OT  - triage nurse assessment
EDAT- 2024/01/25 06:43
MHDA- 2024/01/26 06:43
CRDT- 2024/01/25 05:49
PHST- 2024/01/26 06:43 [medline]
PHST- 2024/01/25 06:43 [pubmed]
PHST- 2024/01/25 05:49 [entrez]
AID - SHTI231056 [pii]
AID - 10.3233/SHTI231056 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2024 Jan 25;310:705-709. doi: 10.3233/SHTI231056.

PMID- 38900185
OWN - NLM
STAT- MEDLINE
DCOM- 20240719
LR  - 20240721
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 8
DP  - 2024 Aug 1
TI  - Zero-shot learning to extract assessment criteria and medical services from the 
      preventive healthcare guidelines using large language models.
PG  - 1743-1753
LID - 10.1093/jamia/ocae145 [doi]
AB  - OBJECTIVES: The integration of these preventive guidelines with Electronic Health 
      Records (EHRs) systems, coupled with the generation of personalized preventive 
      care recommendations, holds significant potential for improving healthcare 
      outcomes. Our study investigates the feasibility of using Large Language Models 
      (LLMs) to automate the assessment criteria and risk factors from the guidelines 
      for future analysis against medical records in EHR. MATERIALS AND METHODS: We 
      annotated the criteria, risk factors, and preventive medical services described 
      in the adult guidelines published by United States Preventive Services Taskforce 
      and evaluated 3 state-of-the-art LLMs on extracting information in these 
      categories from the guidelines automatically. RESULTS: We included 24 guidelines 
      in this study. The LLMs can automate the extraction of all criteria, risk 
      factors, and medical services from 9 guidelines. All 3 LLMs perform well on 
      extracting information regarding the demographic criteria or risk factors. Some 
      LLMs perform better on extracting the social determinants of health, family 
      history, and preventive counseling services than the others. DISCUSSION: While 
      LLMs demonstrate the capability to handle lengthy preventive care guidelines, 
      several challenges persist, including constraints related to the maximum length 
      of input tokens and the tendency to generate content rather than adhering 
      strictly to the original input. Moreover, the utilization of LLMs in real-world 
      clinical settings necessitates careful ethical consideration. It is imperative 
      that healthcare professionals meticulously validate the extracted information to 
      mitigate biases, ensure completeness, and maintain accuracy. CONCLUSION: We 
      developed a data structure to store the annotated preventive guidelines and make 
      it publicly available. Employing state-of-the-art LLMs to extract preventive care 
      criteria, risk factors, and preventive care services paves the way for the future 
      integration of these guidelines into the EHR.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Luo, Xiao
AU  - Luo X
AUID- ORCID: 0000-0002-3649-9785
AD  - Department of Management Science and Information Systems, Spears School of 
      Business, Oklahoma State University, Stillwater, OK 74078, United States.
AD  - Department of Biostatistics and Health Data Science, School of Medicine, Indiana 
      University, Indianapolis, IN 46202, United States.
FAU - Tahabi, Fattah Muhammad
AU  - Tahabi FM
AD  - Department of Management Science and Information Systems, Spears School of 
      Business, Oklahoma State University, Stillwater, OK 74078, United States.
FAU - Marc, Tressica
AU  - Marc T
AD  - Department of Computer Information Technology, Purdue School of Engineering and 
      Technology, Indiana University-Purdue University Indianapolis, Indianapolis, IN 
      46202, United States.
FAU - Haunert, Laura Ann
AU  - Haunert LA
AD  - School of Nursing, Indiana University, Indianapolis, IN 46202, United States.
FAU - Storey, Susan
AU  - Storey S
AUID- ORCID: 0000-0003-0701-7465
AD  - School of Nursing, Indiana University, Indianapolis, IN 46202, United States.
LA  - eng
GR  - R15 GM139094/GM/NIGMS NIH HHS/United States
GR  - R15GM139094/GM/NIGMS NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Humans
MH  - *Preventive Health Services
MH  - *Electronic Health Records
MH  - *Practice Guidelines as Topic
MH  - Risk Factors
MH  - Natural Language Processing
MH  - Machine Learning
PMC - PMC11258407
OTO - NOTNLM
OT  - clinical guidelines
OT  - information extraction
OT  - large language models
OT  - preventive care
COIS- None declared.
EDAT- 2024/06/20 12:43
MHDA- 2024/07/19 06:42
PMCR- 2024/06/20
CRDT- 2024/06/20 11:03
PHST- 2024/03/20 00:00 [received]
PHST- 2024/04/30 00:00 [revised]
PHST- 2024/06/03 00:00 [accepted]
PHST- 2024/07/19 06:42 [medline]
PHST- 2024/06/20 12:43 [pubmed]
PHST- 2024/06/20 11:03 [entrez]
PHST- 2024/06/20 00:00 [pmc-release]
AID - 7696537 [pii]
AID - ocae145 [pii]
AID - 10.1093/jamia/ocae145 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Aug 1;31(8):1743-1753. doi: 10.1093/jamia/ocae145.

PMID- 39230947
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240921
IS  - 2291-9694 (Print)
IS  - 2291-9694 (Electronic)
IS  - 2291-9694 (Linking)
VI  - 12
DP  - 2024 Sep 4
TI  - Evaluating the Capabilities of Generative AI Tools in Understanding Medical 
      Papers: Qualitative Study.
PG  - e59258
LID - 10.2196/59258 [doi]
LID - e59258
AB  - BACKGROUND: Reading medical papers is a challenging and time-consuming task for 
      doctors, especially when the papers are long and complex. A tool that can help 
      doctors efficiently process and understand medical papers is needed. OBJECTIVE: 
      This study aims to critically assess and compare the comprehension capabilities 
      of large language models (LLMs) in accurately and efficiently understanding 
      medical research papers using the STROBE (Strengthening the Reporting of 
      Observational Studies in Epidemiology) checklist, which provides a standardized 
      framework for evaluating key elements of observational study. METHODS: The study 
      is a methodological type of research. The study aims to evaluate the 
      understanding capabilities of new generative artificial intelligence tools in 
      medical papers. A novel benchmark pipeline processed 50 medical research papers 
      from PubMed, comparing the answers of 6 LLMs (GPT-3.5-Turbo, GPT-4-0613, 
      GPT-4-1106, PaLM 2, Claude v1, and Gemini Pro) to the benchmark established by 
      expert medical professors. Fifteen questions, derived from the STROBE checklist, 
      assessed LLMs' understanding of different sections of a research paper. RESULTS: 
      LLMs exhibited varying performance, with GPT-3.5-Turbo achieving the highest 
      percentage of correct answers (n=3916, 66.9%), followed by GPT-4-1106 (n=3837, 
      65.6%), PaLM 2 (n=3632, 62.1%), Claude v1 (n=2887, 58.3%), Gemini Pro (n=2878, 
      49.2%), and GPT-4-0613 (n=2580, 44.1%). Statistical analysis revealed 
      statistically significant differences between LLMs (P<.001), with older models 
      showing inconsistent performance compared to newer versions. LLMs showcased 
      distinct performances for each question across different parts of a scholarly 
      paper-with certain models like PaLM 2 and GPT-3.5 showing remarkable versatility 
      and depth in understanding. CONCLUSIONS: This study is the first to evaluate the 
      performance of different LLMs in understanding medical papers using the retrieval 
      augmented generation method. The findings highlight the potential of LLMs to 
      enhance medical research by improving efficiency and facilitating evidence-based 
      decision-making. Further research is needed to address limitations such as the 
      influence of question formats, potential biases, and the rapid evolution of LLM 
      models.
CI  - ©Seyma Handan Akyon, Fatih Cagatay Akyon, Ahmet Sefa Camyar, Fatih Hızlı, Talha 
      Sari, Şamil Hızlı. Originally published in JMIR Medical Informatics 
      (https://medinform.jmir.org), 04.09.2024.
FAU - Akyon, Seyma Handan
AU  - Akyon SH
AUID- ORCID: 0000-0002-2288-8915
AD  - Golpazari Family Health Center, Bilecik, Turkey.
FAU - Akyon, Fatih Cagatay
AU  - Akyon FC
AUID- ORCID: 0000-0001-7098-3944
AD  - SafeVideo AI, San Francisco, CA, United States.
AD  - Graduate School of Informatics, Middle East Technical University, Ankara, Turkey.
FAU - Camyar, Ahmet Sefa
AU  - Camyar AS
AUID- ORCID: 0009-0009-1310-5024
AD  - Department of Internal Medicine, Ankara Etlik City Hospital, Ankara, Turkey.
FAU - Hızlı, Fatih
AU  - Hızlı F
AUID- ORCID: 0009-0007-2746-8083
AD  - Faculty of Medicine, Ankara Yildirim Beyazit University, Ankara, Turkey.
FAU - Sari, Talha
AU  - Sari T
AUID- ORCID: 0009-0005-5504-4902
AD  - SafeVideo AI, San Francisco, CA, United States.
AD  - Department of Computer Science, Istanbul Technical University, Istanbul, Turkey.
FAU - Hızlı, Şamil
AU  - Hızlı Ş
AUID- ORCID: 0000-0001-6732-493X
AD  - Department of Pediatric Gastroenterology, Children Hospital, Ankara Bilkent City 
      Hospital, Ankara Yildirim Beyazit University, Ankara, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20240904
PL  - Canada
TA  - JMIR Med Inform
JT  - JMIR medical informatics
JID - 101645109
PMC - PMC11411230
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - GPT
OT  - LLM
OT  - LLMs
OT  - STROBE
OT  - Strengthening the Reporting of Observational Studies in Epidemiology
OT  - answer
OT  - answers
OT  - artificial intelligence
OT  - comprehension
OT  - generative
OT  - health care
OT  - language model
OT  - language models
OT  - large language models
OT  - machine learning
OT  - medicine
OT  - natural language processing
OT  - research paper
OT  - research papers
OT  - response
OT  - responses
OT  - scientific research
COIS- Conflicts of Interest: None declared.
EDAT- 2024/09/04 12:44
MHDA- 2024/09/04 12:45
PMCR- 2024/09/04
CRDT- 2024/09/04 11:53
PHST- 2024/04/07 00:00 [received]
PHST- 2024/07/05 00:00 [accepted]
PHST- 2024/06/16 00:00 [revised]
PHST- 2024/09/04 12:45 [medline]
PHST- 2024/09/04 12:44 [pubmed]
PHST- 2024/09/04 11:53 [entrez]
PHST- 2024/09/04 00:00 [pmc-release]
AID - v12i1e59258 [pii]
AID - 10.2196/59258 [doi]
PST - epublish
SO  - JMIR Med Inform. 2024 Sep 4;12:e59258. doi: 10.2196/59258.

PMID- 37358808
OWN - NLM
STAT- MEDLINE
DCOM- 20230802
LR  - 20230802
IS  - 2152-2723 (Electronic)
IS  - 2152-2715 (Linking)
VI  - 26
IP  - 8
DP  - 2023 Aug
TI  - Examining the Prevailing Negative Sentiments Surrounding Measles Vaccination: 
      Unsupervised Deep Learning of Twitter Posts from 2017 to 2022.
PG  - 621-630
LID - 10.1089/cyber.2023.0025 [doi]
AB  - Despite the proven safety and clinical efficacy of the Measles vaccine, many 
      countries are seeing new heights of vaccine hesitancy or refusal, and are 
      experiencing a resurgence of measles infections as a consequence. With the use of 
      novel machine learning tools, we investigated the prevailing negative sentiments 
      related to Measles vaccination through an analysis of public Twitter posts over a 
      5-year period. We extracted original tweets using the search terms related to 
      "measles" and "vaccine," and posted in English from January 1, 2017, to December 
      15, 2022. Of these, 155,363 tweets were identified to be negative sentiment 
      tweets from unique individuals, through the use of Bidirectional Encoder 
      Representations from Transformers (BERT) Named Entity Recognition and SieBERT, a 
      pretrained sentiment in English analysis model. This was followed by topic 
      modeling and qualitative thematic analysis performed inductively by the study 
      investigators. A total of 11 topics were generated after applying BERTopic. To 
      facilitate a global discussion of results, the topics were grouped into four 
      different themes through iterative thematic analysis. These include (a) the 
      rejection of "anti-vaxxers" or antivaccine sentiments, (b) misbeliefs and 
      misinformation regarding Measles vaccination, (c) negative transference due to 
      COVID-19 related policies, and (d) public reactions to contemporary Measles 
      outbreaks. Theme 1 highlights that the current public discourse may further 
      alienate those who are vaccine hesitant because of the disparaging language often 
      used, while Themes 2 and 3 highlight the typology of misperceptions and 
      misinformation underlying the negative sentiments related to Measles vaccination 
      and the psychological tendency of disconfirmation bias. Nonetheless, the analysis 
      was based solely on Twitter and only tweets in English were included; hence, the 
      findings may not necessarily generalize to non-Western communities. It is 
      important to further understand the thinking and feeling of those who are vaccine 
      hesitant to address the issues at hand.
FAU - Ng, Qin Xiang
AU  - Ng QX
AUID- ORCID: 0000-0001-8561-2513
AD  - Health Services Research Unit, Singapore General Hospital, Singapore, Singapore.
AD  - MOH Holdings Pte Ltd., Singapore, Singapore.
FAU - Teo, Yu Qing Jolene
AU  - Teo YQJ
AD  - School of Medicine, Royal College of Surgeons in Ireland, Dublin, Ireland.
FAU - Kiew, Chee Yu
AU  - Kiew CY
AD  - School of Medicine, University College Cork, Cork, Ireland.
FAU - Lim, Bryant Po-Yuen
AU  - Lim BP
AD  - NUS Yong Loo Lin School of Medicine, Singapore, Singapore.
FAU - Lim, Yu Liang
AU  - Lim YL
AD  - MOH Holdings Pte Ltd., Singapore, Singapore.
FAU - Liew, Tau Ming
AU  - Liew TM
AD  - Department of Psychiatry, Singapore General Hospital, Singapore, Singapore.
AD  - SingHealth Duke-NUS Medicine Academic Clinical Programme, Duke-NUS Medical 
      School, Singapore, Singapore.
AD  - Saw Swee Hock School of Public Health, National University of Singapore, 
      Singapore, Singapore.
LA  - eng
PT  - Journal Article
DEP - 20230626
PL  - United States
TA  - Cyberpsychol Behav Soc Netw
JT  - Cyberpsychology, behavior and social networking
JID - 101528721
RN  - 0 (Vaccines)
SB  - IM
MH  - Humans
MH  - *COVID-19
MH  - *Social Media
MH  - *Deep Learning
MH  - Vaccination/psychology
MH  - *Vaccines
MH  - Attitude
OTO - NOTNLM
OT  - MMR
OT  - hesitancy
OT  - machine learning
OT  - measles
OT  - negative sentiment
OT  - vaccine
EDAT- 2023/06/26 13:07
MHDA- 2023/08/02 06:42
CRDT- 2023/06/26 11:16
PHST- 2023/08/02 06:42 [medline]
PHST- 2023/06/26 13:07 [pubmed]
PHST- 2023/06/26 11:16 [entrez]
AID - 10.1089/cyber.2023.0025 [doi]
PST - ppublish
SO  - Cyberpsychol Behav Soc Netw. 2023 Aug;26(8):621-630. doi: 
      10.1089/cyber.2023.0025. Epub 2023 Jun 26.

PMID- 38876484
OWN - NLM
STAT- MEDLINE
DCOM- 20240802
LR  - 20240819
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 11
DP  - 2024 Aug 2
TI  - Large Language Models Versus Expert Clinicians in Crisis Prediction Among 
      Telemental Health Patients: Comparative Study.
PG  - e58129
LID - 10.2196/58129 [doi]
LID - e58129
AB  - BACKGROUND: Due to recent advances in artificial intelligence, large language 
      models (LLMs) have emerged as a powerful tool for a variety of language-related 
      tasks, including sentiment analysis, and summarization of provider-patient 
      interactions. However, there is limited research on these models in the area of 
      crisis prediction. OBJECTIVE: This study aimed to evaluate the performance of 
      LLMs, specifically OpenAI's generative pretrained transformer 4 (GPT-4), in 
      predicting current and future mental health crisis episodes using 
      patient-provided information at intake among users of a national telemental 
      health platform. METHODS: Deidentified patient-provided data were pulled from 
      specific intake questions of the Brightside telehealth platform, including the 
      chief complaint, for 140 patients who indicated suicidal ideation (SI), and 
      another 120 patients who later indicated SI with a plan during the course of 
      treatment. Similar data were pulled for 200 randomly selected patients, treated 
      during the same time period, who never endorsed SI. In total, 6 senior Brightside 
      clinicians (3 psychologists and 3 psychiatrists) were shown patients' 
      self-reported chief complaint and self-reported suicide attempt history but were 
      blinded to the future course of treatment and other reported symptoms, including 
      SI. They were asked a simple yes or no question regarding their prediction of 
      endorsement of SI with plan, along with their confidence level about the 
      prediction. GPT-4 was provided with similar information and asked to answer the 
      same questions, enabling us to directly compare the performance of artificial 
      intelligence and clinicians. RESULTS: Overall, the clinicians' average precision 
      (0.7) was higher than that of GPT-4 (0.6) in identifying the SI with plan at 
      intake (n=140) versus no SI (n=200) when using the chief complaint alone, while 
      sensitivity was higher for the GPT-4 (0.62) than the clinicians' average (0.53). 
      The addition of suicide attempt history increased the clinicians' average 
      sensitivity (0.59) and precision (0.77) while increasing the GPT-4 sensitivity 
      (0.59) but decreasing the GPT-4 precision (0.54). Performance decreased 
      comparatively when predicting future SI with plan (n=120) versus no SI (n=200) 
      with a chief complaint only for the clinicians (average sensitivity=0.4; average 
      precision=0.59) and the GPT-4 (sensitivity=0.46; precision=0.48). The addition of 
      suicide attempt history increased performance comparatively for the clinicians 
      (average sensitivity=0.46; average precision=0.69) and the GPT-4 
      (sensitivity=0.74; precision=0.48). CONCLUSIONS: GPT-4, with a simple prompt 
      design, produced results on some metrics that approached those of a trained 
      clinician. Additional work must be done before such a model can be piloted in a 
      clinical setting. The model should undergo safety checks for bias, given evidence 
      that LLMs can perpetuate the biases of the underlying data on which they are 
      trained. We believe that LLMs hold promise for augmenting the identification of 
      higher-risk patients at intake and potentially delivering more timely care to 
      patients.
CI  - ©Christine Lee, Matthew Mohebbi, Erin O'Callaghan, Mirène Winsberg. Originally 
      published in JMIR Mental Health (https://mental.jmir.org), 02.08.2024.
FAU - Lee, Christine
AU  - Lee C
AUID- ORCID: 0000-0002-2729-3777
AD  - Brightside Health, San Francisco, CA, United States.
FAU - Mohebbi, Matthew
AU  - Mohebbi M
AUID- ORCID: 0009-0006-4929-3483
AD  - Brightside Health, San Francisco, CA, United States.
FAU - O'Callaghan, Erin
AU  - O'Callaghan E
AUID- ORCID: 0000-0001-8212-9278
AD  - Brightside Health, San Francisco, CA, United States.
FAU - Winsberg, Mirène
AU  - Winsberg M
AUID- ORCID: 0000-0002-9637-8133
AD  - Brightside Health, San Francisco, CA, United States.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20240802
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - *Telemedicine
MH  - *Suicidal Ideation
MH  - Male
MH  - Female
MH  - Adult
MH  - Middle Aged
MH  - Artificial Intelligence
MH  - Suicide, Attempted/psychology
MH  - Mental Health Teletherapy
PMC - PMC11329850
OTO - NOTNLM
OT  - AI
OT  - GPT-4
OT  - LLM
OT  - OpenAI
OT  - PHQ-9
OT  - Patient Health Questionnaire-9
OT  - artificial intelligence
OT  - clinical setting
OT  - clinician
OT  - clinicians
OT  - crisis
OT  - digital health
OT  - digital mental health
OT  - e-health
OT  - generative pretrained transformer 4
OT  - language model
OT  - large language model
OT  - machine learning
OT  - medication
OT  - mental disorder
OT  - mental health
OT  - patient information
OT  - psychiatrist
OT  - psychiatrists
OT  - psychiatry
OT  - psychologist
OT  - psychologists
OT  - self-reported
OT  - suicidal
OT  - suicidal ideation
OT  - suicide
OT  - suicide attempt
OT  - tele health
OT  - tele-mental health
OT  - telehealth
OT  - telemental health
OT  - treatment
COIS- Conflicts of Interest: All the authors hold stock in and are employees of 
      Brightside Health, Inc. The authors declare that this study received funding from 
      Brightside Health. Aside from the employment status, the funder was not involved 
      in the study design, interpretation of data, or the decision to submit for 
      publication.
EDAT- 2024/06/15 10:44
MHDA- 2024/08/02 18:42
PMCR- 2024/08/02
CRDT- 2024/06/14 20:43
PHST- 2024/03/06 00:00 [received]
PHST- 2024/06/14 00:00 [accepted]
PHST- 2024/06/11 00:00 [revised]
PHST- 2024/08/02 18:42 [medline]
PHST- 2024/06/15 10:44 [pubmed]
PHST- 2024/06/14 20:43 [entrez]
PHST- 2024/08/02 00:00 [pmc-release]
AID - v11i1e58129 [pii]
AID - 10.2196/58129 [doi]
PST - epublish
SO  - JMIR Ment Health. 2024 Aug 2;11:e58129. doi: 10.2196/58129.

PMID- 38986153
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240823
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 8
DP  - 2024 Aug 6
TI  - Use of Generative AI for Improving Health Literacy in Reproductive Health: Case 
      Study.
PG  - e59434
LID - 10.2196/59434 [doi]
LID - e59434
AB  - BACKGROUND: Patients find technology tools to be more approachable for seeking 
      sensitive health-related information, such as reproductive health information. 
      The inventive conversational ability of artificial intelligence (AI) chatbots, 
      such as ChatGPT (OpenAI Inc), offers a potential means for patients to 
      effectively locate answers to their health-related questions digitally. 
      OBJECTIVE: A pilot study was conducted to compare the novel ChatGPT with the 
      existing Google Search technology for their ability to offer accurate, effective, 
      and current information regarding proceeding action after missing a dose of oral 
      contraceptive pill. METHODS: A sequence of 11 questions, mimicking a patient 
      inquiring about the action to take after missing a dose of an oral contraceptive 
      pill, were input into ChatGPT as a cascade, given the conversational ability of 
      ChatGPT. The questions were input into 4 different ChatGPT accounts, with the 
      account holders being of various demographics, to evaluate potential differences 
      and biases in the responses given to different account holders. The leading 
      question, "what should I do if I missed a day of my oral contraception birth 
      control?" alone was then input into Google Search, given its nonconversational 
      nature. The results from the ChatGPT questions and the Google Search results for 
      the leading question were evaluated on their readability, accuracy, and effective 
      delivery of information. RESULTS: The ChatGPT results were determined to be at an 
      overall higher-grade reading level, with a longer reading duration, less 
      accurate, less current, and with a less effective delivery of information. In 
      contrast, the Google Search resulting answer box and snippets were at a 
      lower-grade reading level, shorter reading duration, more current, able to 
      reference the origin of the information (transparent), and provided the 
      information in various formats in addition to text. CONCLUSIONS: ChatGPT has room 
      for improvement in accuracy, transparency, recency, and reliability before it can 
      equitably be implemented into health care information delivery and provide the 
      potential benefits it poses. However, AI may be used as a tool for providers to 
      educate their patients in preferred, creative, and efficient ways, such as using 
      AI to generate accessible short educational videos from health care 
      provider-vetted information. Larger studies representing a diverse group of users 
      are needed.
CI  - ©Christina Burns, Angela Bakaj, Amonda Berishaj, Vagelis Hristidis, Pamela Deak, 
      Ozlem Equils. Originally published in JMIR Formative Research 
      (https://formative.jmir.org), 06.08.2024.
FAU - Burns, Christina
AU  - Burns C
AUID- ORCID: 0009-0006-8020-061X
AD  - MiOra, Encino, CA, United States.
AD  - University of California San Diego, San Diego, CA, United States.
FAU - Bakaj, Angela
AU  - Bakaj A
AUID- ORCID: 0009-0000-1113-7203
AD  - MiOra, Encino, CA, United States.
AD  - Institute for Management & Innovation, University of Toronto, Toronto, ON, 
      Canada.
FAU - Berishaj, Amonda
AU  - Berishaj A
AUID- ORCID: 0009-0006-7355-0064
AD  - MiOra, Encino, CA, United States.
AD  - College of Professional Studies, Northeastern University, Boston, MA, United 
      States.
FAU - Hristidis, Vagelis
AU  - Hristidis V
AUID- ORCID: 0000-0001-8905-2832
AD  - Computer Science and Engineering, University of California Riverside, Riverside, 
      CA, United States.
FAU - Deak, Pamela
AU  - Deak P
AUID- ORCID: 0009-0000-7254-0346
AD  - Department of Obstetrics, Gynecology and Reproductive Sciences, University of 
      California San Diego, San Diego, CA, United States.
FAU - Equils, Ozlem
AU  - Equils O
AUID- ORCID: 0000-0002-8707-9019
AD  - MiOra, Encino, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20240806
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
PMC - PMC11336497
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - English proficiency
OT  - Google Search
OT  - LLM
OT  - LLMs
OT  - ML
OT  - NLP
OT  - artificial intelligence
OT  - birth control
OT  - chat-GPT
OT  - chat-bot
OT  - chat-bots
OT  - chatGPT
OT  - chatbot
OT  - chatbots
OT  - clinical
OT  - communication
OT  - comparison
OT  - deep learning
OT  - emergency contraceptive
OT  - health access
OT  - health education
OT  - health information
OT  - health information seeking
OT  - health literacy
OT  - health related questions
OT  - internet
OT  - large language model
OT  - large language models
OT  - machine learning
OT  - natural language processing
OT  - oral contraceptive
OT  - patients
OT  - readability
OT  - reproductive health
COIS- Conflicts of Interest: None declared.
EDAT- 2024/07/10 18:42
MHDA- 2024/07/10 18:43
PMCR- 2024/08/06
CRDT- 2024/07/10 17:32
PHST- 2024/04/11 00:00 [received]
PHST- 2024/07/10 00:00 [accepted]
PHST- 2024/06/18 00:00 [revised]
PHST- 2024/07/10 18:43 [medline]
PHST- 2024/07/10 18:42 [pubmed]
PHST- 2024/07/10 17:32 [entrez]
PHST- 2024/08/06 00:00 [pmc-release]
AID - v8i1e59434 [pii]
AID - 10.2196/59434 [doi]
PST - epublish
SO  - JMIR Form Res. 2024 Aug 6;8:e59434. doi: 10.2196/59434.

PMID- 39079602
OWN - NLM
STAT- MEDLINE
DCOM- 20241216
LR  - 20241231
IS  - 1532-429X (Electronic)
IS  - 1097-6647 (Print)
IS  - 1097-6647 (Linking)
VI  - 26
IP  - 2
DP  - 2024 Winter
TI  - Generative Pre-trained Transformer 4 analysis of cardiovascular magnetic 
      resonance reports in suspected myocarditis: A multicenter study.
PG  - 101068
LID - S1097-6647(24)01095-0 [pii]
LID - 10.1016/j.jocmr.2024.101068 [doi]
LID - 101068
AB  - BACKGROUND: Diagnosing myocarditis relies on multimodal data, including 
      cardiovascular magnetic resonance (CMR), clinical symptoms, and blood values. The 
      correct interpretation and integration of CMR findings require radiological 
      expertise and knowledge. We aimed to investigate the performance of Generative 
      Pre-trained Transformer 4 (GPT-4), a large language model, for report-based 
      medical decision-making in the context of cardiac MRI for suspected myocarditis. 
      METHODS: This retrospective study includes CMR reports from 396 patients with 
      suspected myocarditis and eight centers, respectively. CMR reports and patient 
      data including blood values, age, and further clinical information were provided 
      to GPT-4 and radiologists with 1 (resident 1), 2 (resident 2), and 4 years 
      (resident 3) of experience in CMR and knowledge of the 2018 Lake Louise Criteria. 
      The final impression of the report regarding the radiological assessment of 
      whether myocarditis is present or not was not provided. The performance of 
      Generative pre-trained transformer 4 (GPT-4) and the human readers were compared 
      to a consensus reading (two board-certified radiologists with 8 and 10 years of 
      experience in CMR). Sensitivity, specificity, and accuracy were calculated. 
      RESULTS: GPT-4 yielded an accuracy of 83%, sensitivity of 90%, and specificity of 
      78%, which was comparable to the physician with 1 year of experience (R1: 86%, 
      90%, 84%, p = 0.14) and lower than that of more experienced physicians (R2: 89%, 
      86%, 91%, p = 0.007 and R3: 91%, 85%, 96%, p < 0.001). GPT-4 and human readers 
      showed a higher diagnostic performance when results from T1- and T2-mapping 
      sequences were part of the reports, for residents 1 and 3 with statistical 
      significance (p = 0.004 and p = 0.02, respectively). CONCLUSION: GPT-4 yielded 
      good accuracy for diagnosing myocarditis based on CMR reports in a large dataset 
      from multiple centers and therefore holds the potential to serve as a diagnostic 
      decision-supporting tool in this capacity, particularly for less experienced 
      physicians. Further studies are required to explore the full potential and 
      elucidate educational aspects of the integration of large language models in 
      medical decision-making.
CI  - Copyright © 2024 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Kaya, Kenan
AU  - Kaya K
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany. Electronic 
      address: kenan.kaya@uk-koeln.de.
FAU - Gietzen, Carsten
AU  - Gietzen C
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Hahnfeldt, Robert
AU  - Hahnfeldt R
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Zoubi, Maher
AU  - Zoubi M
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Bonn, University of Bonn, Bonn, Germany.
FAU - Emrich, Tilman
AU  - Emrich T
AD  - Department of Diagnostic and Interventional Radiology, University Medical Center 
      of the Johannes-Gutenberg-University, Mainz, Germany; Division of Cardiovascular 
      Imaging, Department of Radiology and Radiological Science, Medical University of 
      South Carolina, Charleston, South Carolina, USA; German Centre for Cardiovascular 
      Research, Partner Site Rhine-Main, Mainz, Germany.
FAU - Halfmann, Moritz C
AU  - Halfmann MC
AD  - Department of Diagnostic and Interventional Radiology, University Medical Center 
      of the Johannes-Gutenberg-University, Mainz, Germany.
FAU - Sieren, Malte Maria
AU  - Sieren MM
AD  - Department of Radiology and Nuclear Medicine, UKSH, Campus Lübeck, Lübeck, 
      Germany; Institute of Interventional Radiology, UKSH, Campus Lübeck, Lübeck, 
      Germany.
FAU - Elser, Yannic
AU  - Elser Y
AD  - Department of Radiology and Nuclear Medicine, UKSH, Campus Lübeck, Lübeck, 
      Germany.
FAU - Krumm, Patrick
AU  - Krumm P
AD  - Department of Radiology, Diagnostic and Interventional Radiology, University of 
      Tübingen, Tübingen, Germany.
FAU - Brendel, Jan M
AU  - Brendel JM
AD  - Department of Radiology, Diagnostic and Interventional Radiology, University of 
      Tübingen, Tübingen, Germany.
FAU - Nikolaou, Konstantin
AU  - Nikolaou K
AD  - Department of Radiology, Diagnostic and Interventional Radiology, University of 
      Tübingen, Tübingen, Germany.
FAU - Haag, Nina
AU  - Haag N
AD  - Institute for Radiology, Neuroradiology and Nuclear Medicine Johannes Wesling 
      University Hospital/Mühlenkreiskliniken, Bochum/Minden, Germany.
FAU - Borggrefe, Jan
AU  - Borggrefe J
AD  - Institute for Radiology, Neuroradiology and Nuclear Medicine Johannes Wesling 
      University Hospital/Mühlenkreiskliniken, Bochum/Minden, Germany.
FAU - Krüchten, Ricarda von
AU  - Krüchten RV
AD  - Department of Diagnostic and Interventional Radiology, Medical Center, Faculty of 
      Medicine, University of Freiburg, Freiburg, Germany.
FAU - Müller-Peltzer, Katharina
AU  - Müller-Peltzer K
AD  - Department of Diagnostic and Interventional Radiology, Medical Center, Faculty of 
      Medicine, University of Freiburg, Freiburg, Germany.
FAU - Ehrengut, Constantin
AU  - Ehrengut C
AD  - Department of Diagnostic and Interventional Radiology, University of Leipzig, 
      Leipzig, Germany.
FAU - Denecke, Timm
AU  - Denecke T
AD  - Department of Diagnostic and Interventional Radiology, University of Leipzig, 
      Leipzig, Germany.
FAU - Hagendorff, Andreas
AU  - Hagendorff A
AD  - Department of Cardiology, University of Leipzig, Leipzig, Germany.
FAU - Goertz, Lukas
AU  - Goertz L
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Gertz, Roman J
AU  - Gertz RJ
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Bunck, Alexander Christian
AU  - Bunck AC
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Maintz, David
AU  - Maintz D
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Persigehl, Thorsten
AU  - Persigehl T
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Lennartz, Simon
AU  - Lennartz S
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Luetkens, Julian A
AU  - Luetkens JA
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Bonn, University of Bonn, Bonn, Germany.
FAU - Jaiswal, Astha
AU  - Jaiswal A
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Iuga, Andra Iza
AU  - Iuga AI
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Pennig, Lenhard
AU  - Pennig L
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
FAU - Kottlors, Jonathan
AU  - Kottlors J
AD  - Institute for Diagnostic and Interventional Radiology, Faculty of Medicine and 
      University Hospital Cologne, University of Cologne, Cologne, Germany.
LA  - eng
PT  - Journal Article
PT  - Multicenter Study
DEP - 20240728
PL  - England
TA  - J Cardiovasc Magn Reson
JT  - Journal of cardiovascular magnetic resonance : official journal of the Society 
      for Cardiovascular Magnetic Resonance
JID - 9815616
SB  - IM
MH  - Humans
MH  - *Myocarditis/diagnostic imaging
MH  - Retrospective Studies
MH  - *Predictive Value of Tests
MH  - Female
MH  - Male
MH  - Adult
MH  - Reproducibility of Results
MH  - Middle Aged
MH  - Clinical Decision-Making
MH  - Observer Variation
MH  - Decision Support Techniques
MH  - Image Interpretation, Computer-Assisted
MH  - Young Adult
MH  - Magnetic Resonance Imaging
MH  - Aged
MH  - Europe
MH  - Magnetic Resonance Imaging, Cine
PMC - PMC11414660
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cardiovascular magnetic resonance
OT  - Generative Pre-trained Transformer 4
OT  - Large language models
OT  - Myocarditis
COIS- Declaration of competing interests The authors declare the following financial 
      interests/personal relationships which may be considered as potential competing 
      interests: David Maintz received speaker’s honoraria from Philips Healthcare. Jan 
      Borggrefe received speaker’s honoraria from Siemens Healthineers. Simon Lennartz 
      is a member of Editorial Board of Radiology and a Senior Deputy Editor of 
      Radiology in Training. Otherwise, the authors declare no conflicts of interest 
      and had full control over all data, and guarantee correctness.
EDAT- 2024/07/31 00:42
MHDA- 2024/12/17 05:31
PMCR- 2024/07/28
CRDT- 2024/07/30 19:11
PHST- 2024/04/18 00:00 [received]
PHST- 2024/07/04 00:00 [revised]
PHST- 2024/07/24 00:00 [accepted]
PHST- 2024/12/17 05:31 [medline]
PHST- 2024/07/31 00:42 [pubmed]
PHST- 2024/07/30 19:11 [entrez]
PHST- 2024/07/28 00:00 [pmc-release]
AID - S1097-6647(24)01095-0 [pii]
AID - 101068 [pii]
AID - 10.1016/j.jocmr.2024.101068 [doi]
PST - ppublish
SO  - J Cardiovasc Magn Reson. 2024 Winter;26(2):101068. doi: 
      10.1016/j.jocmr.2024.101068. Epub 2024 Jul 28.

PMID- 38349846
OWN - NLM
STAT- MEDLINE
DCOM- 20240405
LR  - 20250214
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 4
DP  - 2024 Apr 3
TI  - Estimation of racial and language disparities in pediatric emergency department 
      triage using statistical modeling and natural language processing.
PG  - 958-967
LID - 10.1093/jamia/ocae018 [doi]
AB  - OBJECTIVES: The study aims to assess racial and language disparities in pediatric 
      emergency department (ED) triage using analytical techniques and provide insights 
      into the extent and nature of the disparities in the ED setting. MATERIALS AND 
      METHODS: The study analyzed a cross-sectional dataset encompassing ED visits from 
      January 2019 to April 2021. The study utilized analytical techniques, including 
      K-mean clustering (KNN), multivariate adaptive regression splines (MARS), and 
      natural language processing (NLP) embedding. NLP embedding and KNN were employed 
      to handle the chief complaints and categorize them into clusters, while the MARS 
      was used to identify significant interactions among the clinical features. The 
      study also explored important variables, including age-adjusted vital signs. 
      Multiple logistic regression models with varying specifications were developed to 
      assess the robustness of analysis results. RESULTS: The study consistently found 
      that non-White children, especially African American (AA) and Hispanic, were 
      often under-triaged, with AA children having >2 times higher odds of receiving 
      lower acuity scores compared to White children. While the results are generally 
      consistent, incorporating relevant variables modified the results for specific 
      patient groups (eg, Asians). DISCUSSION: By employing a comprehensive analysis 
      methodology, the study checked the robustness of the analysis results on racial 
      and language disparities in pediatric ED triage. The study also recognized the 
      significance of analytical techniques in assessing pediatric health conditions 
      and analyzing disparities. CONCLUSION: The study's findings highlight the 
      significant need for equal and fair assessment and treatment in the pediatric ED, 
      regardless of their patients' race and language.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Lee, Seung-Yup Joshua
AU  - Lee SJ
AD  - Department of Health Services Administration, School of Health Professions, The 
      University of Alabama at Birmingham, Birmingham, AL 35233, United States.
FAU - Alzeen, Mohammed
AU  - Alzeen M
AD  - Department of Health Services Administration, School of Health Professions, The 
      University of Alabama at Birmingham, Birmingham, AL 35233, United States.
FAU - Ahmed, Abdulaziz
AU  - Ahmed A
AD  - Department of Health Services Administration, School of Health Professions, The 
      University of Alabama at Birmingham, Birmingham, AL 35233, United States.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Child
MH  - Humans
MH  - Cross-Sectional Studies
MH  - Emergency Service, Hospital
MH  - *Healthcare Disparities
MH  - Hispanic or Latino
MH  - *Natural Language Processing
MH  - Retrospective Studies
MH  - *Triage
MH  - Black or African American
MH  - Models, Statistical
PMC - PMC10990499
OTO - NOTNLM
OT  - language triage disparity
OT  - natural language processing
OT  - pediatric emergency department
OT  - racial triage disparity
COIS- None declared.
EDAT- 2024/02/13 18:43
MHDA- 2024/04/05 06:44
PMCR- 2025/02/13
CRDT- 2024/02/13 13:03
PHST- 2023/10/25 00:00 [received]
PHST- 2024/01/16 00:00 [revised]
PHST- 2024/01/19 00:00 [accepted]
PHST- 2024/04/05 06:44 [medline]
PHST- 2024/02/13 18:43 [pubmed]
PHST- 2024/02/13 13:03 [entrez]
PHST- 2025/02/13 00:00 [pmc-release]
AID - 7607205 [pii]
AID - ocae018 [pii]
AID - 10.1093/jamia/ocae018 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Apr 3;31(4):958-967. doi: 10.1093/jamia/ocae018.

PMID- 39707270
OWN - NLM
STAT- MEDLINE
DCOM- 20241221
LR  - 20250104
IS  - 1471-2288 (Electronic)
IS  - 1471-2288 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Dec 20
TI  - Efficient analysis of drug interactions in liver injury: a retrospective study 
      leveraging natural language processing and machine learning.
PG  - 312
LID - 10.1186/s12874-024-02443-8 [doi]
LID - 312
AB  - BACKGROUND: Liver injury from drug-drug interactions (DDIs), notably with 
      anti-tuberculosis drugs such as isoniazid, poses a significant safety concern. 
      Electronic medical records contain comprehensive clinical information and have 
      gained increasing attention as a potential resource for DDI detection. However, a 
      substantial portion of adverse drug reaction (ADR) information is hidden in 
      unstructured narrative text, which has yet to be efficiently harnessed, thereby 
      introducing bias into the research. There is a significant need for an efficient 
      framework for the DDI assessment. METHODS: Using a Chinese natural language 
      processing (NLP) model, we extracted 25,130 adverse drug reaction (ADR) records, 
      dividing them into sets for training an automated normalization model. The 
      trained models, in conjunction with liver function laboratory tests, were used to 
      thoroughly and efficiently identify liver injury cases. Ultimately, we applied a 
      case-control study design to detect DDI signals increasing isoniazid's liver 
      injury risk. RESULTS: The Logistic Regression model demonstrated stable and 
      superior performance in classification task. Based on laboratory criteria and 
      NLP, we identified 128 liver injury cases among a cohort of 3,209 patients 
      treated with isoniazid. Preliminary screening of 113 drug combinations with 
      isoniazid highlighted 20 potential signal drugs, with antibacterials constituting 
      25%. Sensitivity analysis confirmed the robustness of signal drugs, especially in 
      cardiac therapy and antibacterials. CONCLUSION: Our NLP and machine learning 
      approach effectively identifies isoniazid-related DDIs that increase the risk of 
      liver injury, identifying 20 signal drugs, mainly antibacterials. Further 
      research is required to validate these DDI signals.
CI  - © 2024. The Author(s).
FAU - Ma, Junlong
AU  - Ma J
AD  - Center of Clinical Pharmacology, Third Xiangya Hospital, Central South 
      University, Changsha, Hunan, China.
FAU - Chen, Heng
AU  - Chen H
AD  - Department of Pharmacy, The First Hospital of Changsha, Central South University, 
      Changsha, Hunan, China.
FAU - Sun, Ji
AU  - Sun J
AD  - Department of Pharmacy, The First Hospital of Changsha, Central South University, 
      Changsha, Hunan, China.
FAU - Huang, Juanjuan
AU  - Huang J
AD  - Department of Pharmacy, The First Hospital of Changsha, Central South University, 
      Changsha, Hunan, China.
FAU - He, Gefei
AU  - He G
AD  - Department of Pharmacy, The First Hospital of Changsha, Central South University, 
      Changsha, Hunan, China. 326366726@qq.com.
AD  - The First Hospital of Changsha, No 311, Yingpan Road, Kaifu District, Changsha, 
      410005, Hunan, China. 326366726@qq.com.
FAU - Yang, Guoping
AU  - Yang G
AUID- ORCID: 0000-0001-5930-586X
AD  - Center of Clinical Pharmacology, Third Xiangya Hospital, Central South 
      University, Changsha, Hunan, China. ygp9880@126.com.
AD  - The Third Xiangya Hospital of Central South University, No 138, Tongzipo Road, 
      Yuelu District, Changsha, 410013, Hunan, China. ygp9880@126.com.
LA  - eng
GR  - 2023JJ60513/Hunan Provincial Natural Science Foundation of China/
PT  - Journal Article
DEP - 20241220
PL  - England
TA  - BMC Med Res Methodol
JT  - BMC medical research methodology
JID - 100968545
RN  - V83O1VOZ8L (Isoniazid)
RN  - 0 (Antitubercular Agents)
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Machine Learning
MH  - *Chemical and Drug Induced Liver Injury/diagnosis/etiology
MH  - *Drug Interactions
MH  - Retrospective Studies
MH  - *Isoniazid/adverse effects
MH  - *Antitubercular Agents/adverse effects
MH  - Female
MH  - Male
MH  - Middle Aged
MH  - Case-Control Studies
MH  - Electronic Health Records/statistics & numerical data
MH  - Drug-Related Side Effects and Adverse Reactions/diagnosis
MH  - Adult
MH  - Logistic Models
PMC - PMC11660714
OTO - NOTNLM
OT  - Drug interaction
OT  - Liver injury
OT  - Machine learning
OT  - Natural language processing
OT  - Retrospective study
COIS- Declarations. Ethics approval and consent to participate: This retrospective 
      study was conducted under the Declaration of Helsinki. Ethical approval was not 
      required for this study as it was conducted using anonymized electronic medical 
      records. Consent for publication: Not applicable. Competing interests: The 
      authors declare no competing interests.
EDAT- 2024/12/21 16:43
MHDA- 2024/12/21 16:44
PMCR- 2024/12/20
CRDT- 2024/12/20 23:48
PHST- 2024/05/15 00:00 [received]
PHST- 2024/12/12 00:00 [accepted]
PHST- 2024/12/21 16:44 [medline]
PHST- 2024/12/21 16:43 [pubmed]
PHST- 2024/12/20 23:48 [entrez]
PHST- 2024/12/20 00:00 [pmc-release]
AID - 10.1186/s12874-024-02443-8 [pii]
AID - 2443 [pii]
AID - 10.1186/s12874-024-02443-8 [doi]
PST - epublish
SO  - BMC Med Res Methodol. 2024 Dec 20;24(1):312. doi: 10.1186/s12874-024-02443-8.

PMID- 39985409
OWN - NLM
STAT- Publisher
LR  - 20250222
IS  - 1938-7636 (Electronic)
IS  - 1938-6400 (Linking)
DP  - 2025 Feb 22
TI  - ChatGPT Achieves Only Fair Agreement with ACFAS Expert Panelist Clinical 
      Consensus Statements.
PG  - 19386400251319567
LID - 10.1177/19386400251319567 [doi]
AB  - INTRODUCTION: As artificial intelligence (AI) becomes increasingly integrated 
      into medicine and surgery, its applications are expanding rapidly-from aiding 
      clinical documentation to providing patient information. However, its role in 
      medical decision-making remains uncertain. This study evaluates an AI language 
      model's alignment with clinical consensus statements in foot and ankle surgery. 
      METHODS: Clinical consensus statements from the American College of Foot and 
      Ankle Surgeons (ACFAS; 2015-2022) were collected and rated by ChatGPT-o1 as being 
      inappropriate, neither appropriate nor inappropriate, and appropriate. Ten 
      repetitions of the statements were entered into ChatGPT-o1 in a random order, and 
      the model was prompted to assign a corresponding rating. The AI-generated scores 
      were compared to the expert panel's ratings, and intra-rater analysis was 
      performed. RESULTS: The analysis of 9 clinical consensus documents and 129 
      statements revealed an overall Cohen's kappa of 0.29 (95% CI: 0.12, 0.46), 
      indicating fair alignment between expert panelists and ChatGPT. Overall, ankle 
      arthritis and heel pain showed the highest concordance at 100%, while flatfoot 
      exhibited the lowest agreement at 25%, reflecting variability between ChatGPT and 
      expert panelists. Among the ChatGPT ratings, Cohen's kappa values ranged from 
      0.41 to 0.92, highlighting variability in internal reliability across topics. 
      CONCLUSION: ChatGPT achieved overall fair agreement and demonstrated variable 
      consistency when repetitively rating ACFAS expert panel clinical practice 
      guidelines representing a variety of topics. These data reflect the need for 
      further study of the causes, impacts, and solutions for this disparity between 
      intelligence and human intelligence. LEVEL OF EVIDENCE: Level IV: Retrospective 
      cohort study.
FAU - Casciato, Dominick J
AU  - Casciato DJ
AUID- ORCID: 0000-0002-6894-9605
AD  - Orlando VA Medical Center, Orlando, Florida.
FAU - Calhoun, Joshua
AU  - Calhoun J
AD  - Orlando VA Medical Center, Orlando, Florida.
LA  - eng
PT  - Journal Article
DEP - 20250222
PL  - United States
TA  - Foot Ankle Spec
JT  - Foot & ankle specialist
JID - 101473598
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - machine learning
OT  - medical informatics
OT  - natural language processing
OT  - surgical decision-making
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2025/02/22 20:10
MHDA- 2025/02/22 20:10
CRDT- 2025/02/22 07:52
PHST- 2025/02/22 20:10 [medline]
PHST- 2025/02/22 20:10 [pubmed]
PHST- 2025/02/22 07:52 [entrez]
AID - 10.1177/19386400251319567 [doi]
PST - aheadofprint
SO  - Foot Ankle Spec. 2025 Feb 22:19386400251319567. doi: 10.1177/19386400251319567.

PMID- 39963973
OWN - NLM
STAT- MEDLINE
DCOM- 20250218
LR  - 20250223
IS  - 2369-2960 (Electronic)
IS  - 2369-2960 (Linking)
VI  - 11
DP  - 2025 Feb 14
TI  - The Promise and Perils of Artificial Intelligence in Advancing Participatory 
      Science and Health Equity in Public Health.
PG  - e65699
LID - 10.2196/65699 [doi]
LID - e65699
AB  - Current societal trends reflect an increased mistrust in science and a lowered 
      civic engagement that threaten to impair research that is foundational for 
      ensuring public health and advancing health equity. One effective countermeasure 
      to these trends lies in community-facing citizen science applications to increase 
      public participation in scientific research, making this field an important 
      target for artificial intelligence (AI) exploration. We highlight potentially 
      promising citizen science AI applications that extend beyond individual use to 
      the community level, including conversational large language models, 
      text-to-image generative AI tools, descriptive analytics for analyzing integrated 
      macro- and micro-level data, and predictive analytics. The novel adaptations of 
      AI technologies for community-engaged participatory research also bring an array 
      of potential risks. We highlight possible negative externalities and mitigations 
      for some of the potential ethical and societal challenges in this field.
CI  - © Abby C King, Zakaria N Doueiri, Ankita Kaulberg, Lisa Goldman Rosas. Originally 
      published in JMIR Public Health and Surveillance (https://publichealth.jmir.org).
FAU - King, Abby C
AU  - King AC
AUID- ORCID: 0000-0002-7949-8811
AD  - Departments of Epidemiology & Population Health and of Medicine (Stanford 
      Prevention Research Center), Stanford University School of Medicine, 1701 Page 
      Mill Road, Palo Alto, CA, 94304-1210, United States, 1 650-497-2806.
FAU - Doueiri, Zakaria N
AU  - Doueiri ZN
AUID- ORCID: 0009-0005-4701-2353
AD  - Department of Epidemiology & Population Health, Stanford University School of 
      Medicine, Palo Alto, CA, United States.
FAU - Kaulberg, Ankita
AU  - Kaulberg A
AUID- ORCID: 0009-0005-8850-1225
AD  - Department of Epidemiology & Population Health, Stanford University School of 
      Medicine, Palo Alto, CA, United States.
FAU - Goldman Rosas, Lisa
AU  - Goldman Rosas L
AUID- ORCID: 0000-0003-4053-7972
AD  - Departments of Epidemiology & Population Health and of Medicine (Division of 
      Primary Care and Population Health), Stanford University School of Medicine, 
      Stanford University, Palo Alto, CA, United States.
LA  - eng
GR  - R44 AG071211/AG/NIA NIH HHS/United States
PT  - Journal Article
DEP - 20250214
PL  - Canada
TA  - JMIR Public Health Surveill
JT  - JMIR public health and surveillance
JID - 101669345
SB  - IM
MH  - *Artificial Intelligence
MH  - Humans
MH  - *Health Equity
MH  - *Public Health/methods
MH  - Community-Based Participatory Research
MH  - Citizen Science/methods
PMC - PMC11844874
OTO - NOTNLM
OT  - LLM
OT  - Our Voice
OT  - artificial intelligence
OT  - citizen science
OT  - community-based participatory research
OT  - digital health
OT  - health equity
OT  - information technology
OT  - language model
OT  - machine learning
OT  - macro-level data
OT  - micro-level data
OT  - natural language processing
OT  - policy makers
OT  - public health
OT  - public participation
OT  - societal trends
OT  - viewpoint
COIS- None declared.
EDAT- 2025/02/18 12:26
MHDA- 2025/02/18 12:27
PMCR- 2025/02/14
CRDT- 2025/02/18 06:53
PHST- 2024/08/22 00:00 [received]
PHST- 2024/11/21 00:00 [revised]
PHST- 2024/11/28 00:00 [accepted]
PHST- 2025/02/18 12:27 [medline]
PHST- 2025/02/18 12:26 [pubmed]
PHST- 2025/02/18 06:53 [entrez]
PHST- 2025/02/14 00:00 [pmc-release]
AID - v11i1e65699 [pii]
AID - 65699 [pii]
AID - 10.2196/65699 [doi]
PST - epublish
SO  - JMIR Public Health Surveill. 2025 Feb 14;11:e65699. doi: 10.2196/65699.

PMID- 40046117
OWN - NLM
STAT- MEDLINE
DCOM- 20250306
LR  - 20250307
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 13
DP  - 2025
TI  - Deductively coding psychosocial autopsy interview data using a few-shot learning 
      large language model.
PG  - 1512537
LID - 10.3389/fpubh.2025.1512537 [doi]
LID - 1512537
AB  - BACKGROUND: Psychosocial autopsy is a retrospective study of suicide, aimed to 
      identify emerging themes and psychosocial risk factors. It typically relies 
      heavily on qualitative data from interviews or medical documentation. However, 
      qualitative research has often been scrutinized for being prone to bias and is 
      notoriously time- and cost-intensive. Therefore, the current study aimed to 
      investigate if a Large Language Model (LLM) can be feasibly integrated with 
      qualitative research procedures, by evaluating the performance of the model in 
      deductively coding and coherently summarizing interview data obtained in a 
      psychosocial autopsy. METHODS: Data from 38 semi-structured interviews conducted 
      with individuals bereaved by the suicide of a loved one was deductively coded by 
      qualitative researchers and a server-installed LLAMA3 large language model. The 
      model performance was evaluated in three tasks: (1) binary classification of 
      coded segments, (2) independent classification using a sliding window approach, 
      and (3) summarization of coded data. Intercoder agreement scores were calculated 
      using Cohen's Kappa, and the LLM's summaries were qualitatively assessed using 
      the Constant Comparative Method. RESULTS: The results showed that the LLM 
      achieved substantial agreement with the researchers for the binary classification 
      (accuracy: 0.84) and the sliding window task (accuracy: 0.67). The performance 
      had large variability across codes. LLM summaries were typically rich enough for 
      subsequent analysis by the researcher, with around 80% of the summaries being 
      rated independently by two researchers as 'adequate' or 'good.' Emerging themes 
      in the qualitative assessment of the summaries included unsolicited elaboration 
      and hallucination. CONCLUSION: State-of-the-art LLMs show great potential to 
      support researchers in deductively coding complex interview data, which would 
      alleviate the investment of time and resources. Integrating models with 
      qualitative research procedures can facilitate near real-time monitoring. Based 
      on the findings, we recommend a collaborative model, whereby the LLM's deductive 
      coding is complemented by review, inductive coding and further interpretation by 
      a researcher. Future research may aim to replicate the findings in different 
      contexts and evaluate models with a larger context size.
CI  - Copyright © 2025 Balt, Salmi, Bhulai, Vrinzen, Eikelenboom, Gilissen, Creemers, 
      Popma and Mérelle.
FAU - Balt, Elias
AU  - Balt E
AD  - Research Department, 113 Suicide Prevention, Amsterdam, Netherlands.
AD  - Department of Psychiatry, Amsterdam University Medical Centers, Amsterdam, 
      Netherlands.
FAU - Salmi, Salim
AU  - Salmi S
AD  - Research Department, 113 Suicide Prevention, Amsterdam, Netherlands.
FAU - Bhulai, Sandjai
AU  - Bhulai S
AD  - Department of Mathematics, VU University, Amsterdam, Netherlands.
FAU - Vrinzen, Stefan
AU  - Vrinzen S
AD  - Research Department, 113 Suicide Prevention, Amsterdam, Netherlands.
FAU - Eikelenboom, Merijn
AU  - Eikelenboom M
AD  - Research Department, 113 Suicide Prevention, Amsterdam, Netherlands.
AD  - Department of Psychiatry, Amsterdam University Medical Centers, Amsterdam, 
      Netherlands.
FAU - Gilissen, Renske
AU  - Gilissen R
AD  - Research Department, 113 Suicide Prevention, Amsterdam, Netherlands.
AD  - Department of Clinical Psychology, Leiden University, Leiden, Netherlands.
FAU - Creemers, Daan
AU  - Creemers D
AD  - Department of Child- and Youth Psychiatry, GGz Oost-Brabant, Boekel, Netherlands.
AD  - Department of Psychiatry and Psychosocial Care, Radboud University Nijmegen, 
      Nijmegen, Netherlands.
FAU - Popma, Arne
AU  - Popma A
AD  - Department of Psychiatry, Amsterdam University Medical Centers, Amsterdam, 
      Netherlands.
FAU - Mérelle, Saskia
AU  - Mérelle S
AD  - Research Department, 113 Suicide Prevention, Amsterdam, Netherlands.
AD  - Department of Child and Adolescent Psychiatry and Psychosocial Care, Amsterdam 
      University Medical Center, Amsterdam, Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20250219
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
SB  - IM
MH  - Humans
MH  - *Qualitative Research
MH  - Female
MH  - Male
MH  - Retrospective Studies
MH  - Suicide/psychology
MH  - Adult
MH  - Interviews as Topic
MH  - Middle Aged
MH  - Bereavement
MH  - Autopsy
MH  - Language
PMC - PMC11879832
OTO - NOTNLM
OT  - large language model (LLM)
OT  - psychosocial autopsy
OT  - public health
OT  - qualitative research
OT  - suicide prevention
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2025/03/06 11:27
MHDA- 2025/03/06 11:28
PMCR- 2025/02/19
CRDT- 2025/03/06 04:36
PHST- 2024/10/16 00:00 [received]
PHST- 2025/01/29 00:00 [accepted]
PHST- 2025/03/06 11:28 [medline]
PHST- 2025/03/06 11:27 [pubmed]
PHST- 2025/03/06 04:36 [entrez]
PHST- 2025/02/19 00:00 [pmc-release]
AID - 10.3389/fpubh.2025.1512537 [doi]
PST - epublish
SO  - Front Public Health. 2025 Feb 19;13:1512537. doi: 10.3389/fpubh.2025.1512537. 
      eCollection 2025.

PMID- 38206661
OWN - NLM
STAT- MEDLINE
DCOM- 20240112
LR  - 20241023
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Jan 11
TI  - Comprehensiveness, Accuracy, and Readability of Exercise Recommendations Provided 
      by an AI-Based Chatbot: Mixed Methods Study.
PG  - e51308
LID - 10.2196/51308 [doi]
LID - e51308
AB  - BACKGROUND: Regular physical activity is critical for health and disease 
      prevention. Yet, health care providers and patients face barriers to implement 
      evidence-based lifestyle recommendations. The potential to augment care with the 
      increased availability of artificial intelligence (AI) technologies is limitless; 
      however, the suitability of AI-generated exercise recommendations has yet to be 
      explored. OBJECTIVE: The purpose of this study was to assess the 
      comprehensiveness, accuracy, and readability of individualized exercise 
      recommendations generated by a novel AI chatbot. METHODS: A coding scheme was 
      developed to score AI-generated exercise recommendations across ten categories 
      informed by gold-standard exercise recommendations, including (1) health 
      condition-specific benefits of exercise, (2) exercise preparticipation health 
      screening, (3) frequency, (4) intensity, (5) time, (6) type, (7) volume, (8) 
      progression, (9) special considerations, and (10) references to the primary 
      literature. The AI chatbot was prompted to provide individualized exercise 
      recommendations for 26 clinical populations using an open-source application 
      programming interface. Two independent reviewers coded AI-generated content for 
      each category and calculated comprehensiveness (%) and factual accuracy (%) on a 
      scale of 0%-100%. Readability was assessed using the Flesch-Kincaid formula. 
      Qualitative analysis identified and categorized themes from AI-generated output. 
      RESULTS: AI-generated exercise recommendations were 41.2% (107/260) comprehensive 
      and 90.7% (146/161) accurate, with the majority (8/15, 53%) of inaccuracy related 
      to the need for exercise preparticipation medical clearance. Average readability 
      level of AI-generated exercise recommendations was at the college level (mean 
      13.7, SD 1.7), with an average Flesch reading ease score of 31.1 (SD 7.7). 
      Several recurring themes and observations of AI-generated output included concern 
      for liability and safety, preference for aerobic exercise, and potential bias and 
      direct discrimination against certain age-based populations and individuals with 
      disabilities. CONCLUSIONS: There were notable gaps in the comprehensiveness, 
      accuracy, and readability of AI-generated exercise recommendations. Exercise and 
      health care professionals should be aware of these limitations when using and 
      endorsing AI-based technologies as a tool to support lifestyle change involving 
      exercise.
CI  - ©Amanda L Zaleski, Rachel Berkowsky, Kelly Jean Thomas Craig, Linda S Pescatello. 
      Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      11.01.2024.
FAU - Zaleski, Amanda L
AU  - Zaleski AL
AUID- ORCID: 0000-0002-0362-819X
AD  - Clinical Evidence Development, Aetna Medical Affairs, CVS Health Corporation, 
      Hartford, CT, United States.
AD  - Department of Preventive Cardiology, Hartford Hospital, Hartford, CT, United 
      States.
FAU - Berkowsky, Rachel
AU  - Berkowsky R
AUID- ORCID: 0000-0003-1150-1284
AD  - Department of Kinesiology, University of Connecticut, Storrs, CT, United States.
FAU - Craig, Kelly Jean Thomas
AU  - Craig KJT
AUID- ORCID: 0000-0002-9954-2795
AD  - Clinical Evidence Development, Aetna Medical Affairs, CVS Health Corporation, 
      Hartford, CT, United States.
FAU - Pescatello, Linda S
AU  - Pescatello LS
AUID- ORCID: 0000-0002-5841-798X
AD  - Department of Kinesiology, University of Connecticut, Storrs, CT, United States.
LA  - eng
PT  - Journal Article
DEP - 20240111
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Comprehension
MH  - Software
MH  - Awareness
MH  - Exercise
PMC - PMC10811574
OTO - NOTNLM
OT  - AI
OT  - artificial intelligence
OT  - chatbot
OT  - exercise prescription
OT  - health literacy
OT  - large language model
OT  - patient education
COIS- Conflicts of Interest: ALZ and KJTC are both employed and hold stock with CVS 
      Health Corporation. This study is an objective evaluation to better understand 
      ChatGPT and its outputs. To the best of our knowledge, CVS Health does not 
      currently use or endorse the use of ChatGPT for lifestyle recommendations. LSP is 
      the sole proprietor and founder of P3-EX, LLC, which could potentially benefit 
      from the tool used in this research. The results of this study do not constitute 
      endorsement by the American College of Sports Medicine.
EDAT- 2024/01/11 12:41
MHDA- 2024/01/12 06:43
PMCR- 2024/01/11
CRDT- 2024/01/11 11:53
PHST- 2023/07/27 00:00 [received]
PHST- 2023/12/11 00:00 [accepted]
PHST- 2023/10/05 00:00 [revised]
PHST- 2024/01/12 06:43 [medline]
PHST- 2024/01/11 12:41 [pubmed]
PHST- 2024/01/11 11:53 [entrez]
PHST- 2024/01/11 00:00 [pmc-release]
AID - v10i1e51308 [pii]
AID - 10.2196/51308 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Jan 11;10:e51308. doi: 10.2196/51308.

PMID- 34531007
OWN - NLM
STAT- MEDLINE
DCOM- 20211029
LR  - 20211029
IS  - 1873-2860 (Electronic)
IS  - 0933-3657 (Linking)
VI  - 119
DP  - 2021 Sep
TI  - Aspect-based sentiment analysis with graph convolution over syntactic 
      dependencies.
PG  - 102138
LID - S0933-3657(21)00131-7 [pii]
LID - 10.1016/j.artmed.2021.102138 [doi]
AB  - Aspect-based sentiment analysis is a natural language processing task whose aim 
      is to automatically classify the sentiment associated with a specific aspect of a 
      written text. In this study, we propose a novel model for aspect-based sentiment 
      analysis, which exploits the dependency parse tree of a sentence using graph 
      convolution to classify the sentiment of a given aspect. To evaluate this model 
      in the domain of health and well-being, where this task is biased toward negative 
      sentiment, we used a corpus of drug reviews. Specific aspects were grounded in 
      the Unified Medical Language System, a large repository of inter-related 
      biomedical concepts and the corresponding terminology. Our experiments 
      demonstrated that graph convolution approach outperforms standard deep learning 
      architectures on the task of aspect-based sentiment analysis. Moreover, graph 
      convolution over dependency parse trees (F-score of 0.8179) outperforms the same 
      approach over a flat sequence representation of sentences (F-score of 0.7332). 
      These results bring the performance of sentiment analysis in health and 
      well-being in line with the state of the art in other domains.
CI  - Copyright © 2021. Published by Elsevier B.V.
FAU - Žunić, Anastazia
AU  - Žunić A
AD  - School of Computer Science & Informatics, Cardiff University, The Parade, Cardiff 
      CF24 3AA, United Kingdom.
FAU - Corcoran, Padraig
AU  - Corcoran P
AD  - School of Computer Science & Informatics, Cardiff University, The Parade, Cardiff 
      CF24 3AA, United Kingdom.
FAU - Spasić, Irena
AU  - Spasić I
AD  - School of Computer Science & Informatics, Cardiff University, The Parade, Cardiff 
      CF24 3AA, United Kingdom. Electronic address: spasici@cardiff.ac.uk.
LA  - eng
PT  - Journal Article
DEP - 20210809
PL  - Netherlands
TA  - Artif Intell Med
JT  - Artificial intelligence in medicine
JID - 8915031
SB  - IM
MH  - Language
MH  - *Natural Language Processing
MH  - *Unified Medical Language System
OTO - NOTNLM
OT  - Dependency parsing
OT  - Graph convolutional network
OT  - Natural language processing
OT  - Neural network
OT  - Sentiment analysis
EDAT- 2021/09/18 06:00
MHDA- 2021/10/30 06:00
CRDT- 2021/09/17 05:54
PHST- 2020/12/16 00:00 [received]
PHST- 2021/06/05 00:00 [revised]
PHST- 2021/08/03 00:00 [accepted]
PHST- 2021/09/17 05:54 [entrez]
PHST- 2021/09/18 06:00 [pubmed]
PHST- 2021/10/30 06:00 [medline]
AID - S0933-3657(21)00131-7 [pii]
AID - 10.1016/j.artmed.2021.102138 [doi]
PST - ppublish
SO  - Artif Intell Med. 2021 Sep;119:102138. doi: 10.1016/j.artmed.2021.102138. Epub 
      2021 Aug 9.

PMID- 38112589
OWN - NLM
STAT- MEDLINE
DCOM- 20240318
LR  - 20240819
IS  - 1537-7385 (Electronic)
IS  - 0894-9115 (Linking)
VI  - 103
IP  - 4
DP  - 2024 Apr 1
TI  - (How) ChatGPT-Artificial Intelligence Thinks It Can Help/Harm Physiatry.
PG  - 346-349
LID - 10.1097/PHM.0000000000002370 [doi]
AB  - ChatGPT is a chatbot that is based on the generative pretrained transformer 
      architecture as an artificial inteligence-based large language model. Its 
      widespread use in healthcare practice, research, and education seems to be 
      (increasingly) inevitable. Also considering the relevant limitations regarding 
      privacy, ethics, bias, legal, and validity, in this article, its use as a 
      supplement (for sure not as a substitute for physicians) is discussed in light of 
      the recent literature. Particularly, the "opinion" of ChatGPT about how it can 
      help/harm physiatry is exemplified.
CI  - Copyright © 2023 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Jačisko, Jakub
AU  - Jačisko J
AD  - From the Department of Rehabilitation and Sports Medicine, Second Faculty of 
      Medicine, Charles University and University Hospital Motol, Prague, Czech 
      Republic (JJ, VV); Department of Physical Medicine and Rehabilitation, National 
      Taiwan University Hospital, Bei-Hu Branch, Taipei, Taiwan (K-VC); and Department 
      of Physical and Rehabilitation Medicine, Hacettepe University Medical School, 
      Ankara, Turkey (LO).
FAU - Veselý, Viktor
AU  - Veselý V
FAU - Chang, Ke-Vin
AU  - Chang KV
FAU - Özçakar, Levent
AU  - Özçakar L
LA  - eng
PT  - Journal Article
DEP - 20231017
PL  - United States
TA  - Am J Phys Med Rehabil
JT  - American journal of physical medicine & rehabilitation
JID - 8803677
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Dietary Supplements
MH  - Educational Status
MH  - Language
MH  - *Physical and Rehabilitation Medicine
COIS- Financial disclosure statements have been obtained, and no conflicts of interest 
      have been reported by the authors or by any individuals in control of the content 
      of this article.
EDAT- 2023/12/19 19:52
MHDA- 2024/03/18 06:44
CRDT- 2023/12/19 11:05
PHST- 2024/03/18 06:44 [medline]
PHST- 2023/12/19 19:52 [pubmed]
PHST- 2023/12/19 11:05 [entrez]
AID - 00002060-990000000-00338 [pii]
AID - 10.1097/PHM.0000000000002370 [doi]
PST - ppublish
SO  - Am J Phys Med Rehabil. 2024 Apr 1;103(4):346-349. doi: 
      10.1097/PHM.0000000000002370. Epub 2023 Oct 17.

PMID- 38929638
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240629
IS  - 2075-1729 (Print)
IS  - 2075-1729 (Electronic)
IS  - 2075-1729 (Linking)
VI  - 14
IP  - 6
DP  - 2024 May 21
TI  - The Sociodemographic Biases in Machine Learning Algorithms: A Biomedical 
      Informatics Perspective.
LID - 10.3390/life14060652 [doi]
LID - 652
AB  - Artificial intelligence models represented in machine learning algorithms are 
      promising tools for risk assessment used to guide clinical and other health care 
      decisions. Machine learning algorithms, however, may house biases that propagate 
      stereotypes, inequities, and discrimination that contribute to socioeconomic 
      health care disparities. The biases include those related to some 
      sociodemographic characteristics such as race, ethnicity, gender, age, insurance, 
      and socioeconomic status from the use of erroneous electronic health record data. 
      Additionally, there is concern that training data and algorithmic biases in large 
      language models pose potential drawbacks. These biases affect the lives and 
      livelihoods of a significant percentage of the population in the United States 
      and globally. The social and economic consequences of the associated backlash 
      cannot be underestimated. Here, we outline some of the sociodemographic, training 
      data, and algorithmic biases that undermine sound health care risk assessment and 
      medical decision-making that should be addressed in the health care system. We 
      present a perspective and overview of these biases by gender, race, ethnicity, 
      age, historically marginalized communities, algorithmic bias, biased evaluations, 
      implicit bias, selection/sampling bias, socioeconomic status biases, biased data 
      distributions, cultural biases and insurance status bias, conformation bias, 
      information bias and anchoring biases and make recommendations to improve large 
      language model training data, including de-biasing techniques such as 
      counterfactual role-reversed sentences during knowledge distillation, 
      fine-tuning, prefix attachment at training time, the use of toxicity classifiers, 
      retrieval augmented generation and algorithmic modification to mitigate the 
      biases moving forward.
FAU - Franklin, Gillian
AU  - Franklin G
AD  - Department of Biomedical Informatics, University at Buffalo, Buffalo, NY 14203, 
      USA.
AD  - Department of Veterans Affairs, Knowledge Based Systems and Western New York, 
      Veterans Affairs, Buffalo, NY 14215, USA.
FAU - Stephens, Rachel
AU  - Stephens R
AD  - Department of Biomedical Informatics, University at Buffalo, Buffalo, NY 14203, 
      USA.
FAU - Piracha, Muhammad
AU  - Piracha M
AUID- ORCID: 0009-0005-5626-2178
AD  - Department of Biomedical Informatics, University at Buffalo, Buffalo, NY 14203, 
      USA.
FAU - Tiosano, Shmuel
AU  - Tiosano S
AUID- ORCID: 0000-0002-1748-4297
AD  - Department of Biomedical Informatics, University at Buffalo, Buffalo, NY 14203, 
      USA.
FAU - Lehouillier, Frank
AU  - Lehouillier F
AD  - Department of Biomedical Informatics, University at Buffalo, Buffalo, NY 14203, 
      USA.
AD  - Department of Veterans Affairs, Knowledge Based Systems and Western New York, 
      Veterans Affairs, Buffalo, NY 14215, USA.
FAU - Koppel, Ross
AU  - Koppel R
AD  - Department of Biomedical Informatics, University at Buffalo, Buffalo, NY 14203, 
      USA.
AD  - Institute for Biomedical Informatics, Perelman School of Medicine, and Sociology 
      Department, University of Pennsylvania, Philadelphia, PA 19104, USA.
FAU - Elkin, Peter L
AU  - Elkin PL
AD  - Department of Biomedical Informatics, University at Buffalo, Buffalo, NY 14203, 
      USA.
AD  - Department of Veterans Affairs, Knowledge Based Systems and Western New York, 
      Veterans Affairs, Buffalo, NY 14215, USA.
LA  - eng
GR  - T15012495/NH/NIH HHS/United States
PT  - Journal Article
DEP - 20240521
PL  - Switzerland
TA  - Life (Basel)
JT  - Life (Basel, Switzerland)
JID - 101580444
PMC - PMC11204917
OTO - NOTNLM
OT  - algorithms
OT  - artificial intelligence
OT  - bias
OT  - biomedical informatics
OT  - electronic health records
OT  - health care
OT  - machine learning
OT  - models
OT  - sociodemographic
COIS- The authors declare no conflicts of interest.
EDAT- 2024/06/27 06:43
MHDA- 2024/06/27 06:44
PMCR- 2024/05/21
CRDT- 2024/06/27 01:14
PHST- 2024/01/21 00:00 [received]
PHST- 2024/04/24 00:00 [revised]
PHST- 2024/04/26 00:00 [accepted]
PHST- 2024/06/27 06:44 [medline]
PHST- 2024/06/27 06:43 [pubmed]
PHST- 2024/06/27 01:14 [entrez]
PHST- 2024/05/21 00:00 [pmc-release]
AID - life14060652 [pii]
AID - life-14-00652 [pii]
AID - 10.3390/life14060652 [doi]
PST - epublish
SO  - Life (Basel). 2024 May 21;14(6):652. doi: 10.3390/life14060652.

PMID- 36535219
OWN - NLM
STAT- MEDLINE
DCOM- 20221230
LR  - 20230103
IS  - 1532-2653 (Electronic)
IS  - 0967-5868 (Linking)
VI  - 107
DP  - 2023 Jan
TI  - The efficacy and safety of alteplase treatment in patients with acute ischemic 
      stroke with unknown time of onset: -Real world data.
PG  - 124-128
LID - S0967-5868(22)00470-2 [pii]
LID - 10.1016/j.jocn.2022.11.018 [doi]
AB  - INTRODUCTION: Treatment with alteplase for acute ischemic stroke patients with an 
      unknown time of onset is safe and effective. However, clinical trials have some 
      selection bias. The purpose of this study was to clarify the efficacy and safety 
      of alteplase treatment in patients with unknown time of onset in a real-world 
      clinical setting. METHODS: We included consecutive patients with acute ischemic 
      stroke visited within 4.5 h of onset or symptom recognition. We divided patients 
      into two groups: onset clear group (C-group) and unknown time of onset group 
      (U-group). We treated patients with an unknown time of onset if the DWI-FLAIR 
      mismatch was positive. We calculated the prevalence of alteplase treatment in 
      each group and compared prognosis between the two groups. RESULTS: Six hundred 
      thirty-two patients arrived within 4.5 h of onset or symptom recognition. Of 
      these, 446 patients (71 %) were in the C-group and 186 (29 %) in the U group. 
      Alteplase treatment was performed in 35 % of patients in the C group and in 18 % 
      in the U group (p < 0.001). Favorable outcomes at 90 days in patients treated 
      with alteplase were comparable between the C group (52 %) and the U group (53 %) 
      (p = 0.887). All hemorrhagic complications, including non-symptomatic hemorrhagic 
      transformation, occurred in 11 of 157 patients (7 %) in the C-group and one of 34 
      patients (3 %) in the U-group (p = 0.696). CONCLUSION: In a real-world clinical 
      setting, alteplase treatment was performed safe in 18% of patients with an 
      unknown time of stroke onset based on patient selection using the DWI-FLAIR 
      mismatch.
CI  - Copyright © 2022 Elsevier Ltd. All rights reserved.
FAU - Terasawa, Yuka
AU  - Terasawa Y
AD  - Department of Neurology, Brain Attack Center Ota Memorial Hospital, Fukuyama, 
      Japan. Electronic address: ykterasawa@shouwa.or.jp.
FAU - Shimomura, Ryo
AU  - Shimomura R
AD  - Department of Neurology, Kajikawa Hospital, Hiroshima, Japan.
FAU - Sato, Kota
AU  - Sato K
AD  - Department of Neurology, Brain Attack Center Ota Memorial Hospital, Fukuyama, 
      Japan. Electronic address: kosatou@shouwa.or.jp.
FAU - Himeno, Takahiro
AU  - Himeno T
AD  - Department of Neurology, Brain Attack Center Ota Memorial Hospital, Fukuyama, 
      Japan. Electronic address: himenotakahiro@oita-u.ac.jp.
FAU - Inoue, Tomoyuki
AU  - Inoue T
AD  - Department of Neurology, Brain Attack Center Ota Memorial Hospital, Fukuyama, 
      Japan. Electronic address: inotomo.xyz@hotmail.co.jp.
FAU - Kohriyama, Tatsuo
AU  - Kohriyama T
AD  - Department of Neurology, Brain Attack Center Ota Memorial Hospital, Fukuyama, 
      Japan. Electronic address: t-kohriyama@shouwa.or.jp.
LA  - eng
PT  - Journal Article
DEP - 20221217
PL  - Scotland
TA  - J Clin Neurosci
JT  - Journal of clinical neuroscience : official journal of the Neurosurgical Society 
      of Australasia
JID - 9433352
RN  - EC 3.4.21.68 (Tissue Plasminogen Activator)
RN  - 0 (Fibrinolytic Agents)
SB  - IM
MH  - Humans
MH  - Tissue Plasminogen Activator/adverse effects
MH  - *Ischemic Stroke/drug therapy
MH  - *Stroke/etiology
MH  - Thrombolytic Therapy/adverse effects
MH  - Time Factors
MH  - Fibrinolytic Agents/adverse effects
MH  - Treatment Outcome
MH  - *Brain Ischemia/drug therapy/complications
OTO - NOTNLM
OT  - Acute ischemic stroke
OT  - Alteplase therapy
OT  - Real world clinical setting
OT  - Unknown time of onset
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2022/12/20 06:00
MHDA- 2022/12/31 06:00
CRDT- 2022/12/19 18:25
PHST- 2022/09/02 00:00 [received]
PHST- 2022/11/23 00:00 [revised]
PHST- 2022/11/30 00:00 [accepted]
PHST- 2022/12/20 06:00 [pubmed]
PHST- 2022/12/31 06:00 [medline]
PHST- 2022/12/19 18:25 [entrez]
AID - S0967-5868(22)00470-2 [pii]
AID - 10.1016/j.jocn.2022.11.018 [doi]
PST - ppublish
SO  - J Clin Neurosci. 2023 Jan;107:124-128. doi: 10.1016/j.jocn.2022.11.018. Epub 2022 
      Dec 17.

PMID- 34459833
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20220426
IS  - 2563-6316 (Electronic)
IS  - 2563-6316 (Linking)
VI  - 2
IP  - 3
DP  - 2021 Jul-Sep
TI  - Social Media Polarization and Echo Chambers in the Context of COVID-19: Case 
      Study.
PG  - e29570
LID - 10.2196/29570 [doi]
LID - e29570
AB  - BACKGROUND: Social media chatter in 2020 has been largely dominated by the 
      COVID-19 pandemic. Existing research shows that COVID-19 discourse is highly 
      politicized, with political preferences linked to beliefs and disbeliefs about 
      the virus. As it happens with topics that become politicized, people may fall 
      into echo chambers, which is the idea that one is only presented with information 
      they already agree with, thereby reinforcing one's confirmation bias. 
      Understanding the relationship between information dissemination and political 
      preference is crucial for effective public health communication. OBJECTIVE: We 
      aimed to study the extent of polarization and examine the structure of echo 
      chambers related to COVID-19 discourse on Twitter in the United States. METHODS: 
      First, we presented Retweet-BERT, a scalable and highly accurate model for 
      estimating user polarity by leveraging language features and network structures. 
      Then, by analyzing the user polarity predicted by Retweet-BERT, we provided new 
      insights into the characterization of partisan users. RESULTS: We observed that 
      right-leaning users were noticeably more vocal and active in the production and 
      consumption of COVID-19 information. We also found that most of the highly 
      influential users were partisan, which may contribute to further polarization. 
      Importantly, while echo chambers exist in both the right- and left-leaning 
      communities, the right-leaning community was by far more densely connected within 
      their echo chamber and isolated from the rest. CONCLUSIONS: We provided empirical 
      evidence that political echo chambers are prevalent, especially in the 
      right-leaning community, which can exacerbate the exposure to information in line 
      with pre-existing users' views. Our findings have broader implications in 
      developing effective public health campaigns and promoting the circulation of 
      factual information online.
CI  - ©Julie Jiang, Xiang Ren, Emilio Ferrara. Originally published in JMIRx Med 
      (https://med.jmirx.org), 05.08.2021.
FAU - Jiang, Julie
AU  - Jiang J
AUID- ORCID: 0000-0003-4260-282X
AD  - Information Sciences Institute University of Southern California Marina Del Rey, 
      CA United States.
AD  - Department of Computer Science Viterbi School of Engineering University of 
      Southern California Los Angeles, CA United States.
FAU - Ren, Xiang
AU  - Ren X
AUID- ORCID: 0000-0001-8655-663X
AD  - Department of Computer Science Viterbi School of Engineering University of 
      Southern California Los Angeles, CA United States.
FAU - Ferrara, Emilio
AU  - Ferrara E
AUID- ORCID: 0000-0002-1942-2831
AD  - Information Sciences Institute University of Southern California Marina Del Rey, 
      CA United States.
AD  - Department of Computer Science Viterbi School of Engineering University of 
      Southern California Los Angeles, CA United States.
AD  - Annenberg School of Communication University of Southern California Los Angeles, 
      CA United States.
LA  - eng
PT  - Journal Article
DEP - 20210805
PL  - Canada
TA  - JMIRx Med
JT  - JMIRx med
JID - 101776650
UOF - https://arxiv.org/abs/2103.10979
UOF - JMIRx Med. 2:e29570.
PMC - PMC8371575
OTO - NOTNLM
OT  - COVID-19
OT  - Twitter
OT  - case study
OT  - communication
OT  - echo chamber
OT  - infodemiology
OT  - infoveillance
OT  - opinion
OT  - polarization
OT  - social media
COIS- Conflicts of Interest: None declared.
EDAT- 2021/08/31 06:00
MHDA- 2021/08/31 06:01
PMCR- 2021/08/05
CRDT- 2021/08/30 12:22
PHST- 2021/04/12 00:00 [received]
PHST- 2021/06/08 00:00 [revised]
PHST- 2021/06/24 00:00 [accepted]
PHST- 2021/08/30 12:22 [entrez]
PHST- 2021/08/31 06:00 [pubmed]
PHST- 2021/08/31 06:01 [medline]
PHST- 2021/08/05 00:00 [pmc-release]
AID - v2i3e29570 [pii]
AID - 10.2196/29570 [doi]
PST - epublish
SO  - JMIRx Med. 2021 Aug 5;2(3):e29570. doi: 10.2196/29570. eCollection 2021 Jul-Sep.

PMID- 38575326
OWN - NLM
STAT- MEDLINE
DCOM- 20240408
LR  - 20240411
IS  - 2632-1009 (Electronic)
IS  - 2632-1009 (Linking)
VI  - 31
IP  - 1
DP  - 2024 Apr 4
TI  - Generative artificial intelligence and non-pharmacological bias: an experimental 
      study on cancer patient sexual health communications.
LID - 10.1136/bmjhci-2023-100924 [doi]
LID - e100924
AB  - Objectives The objective of this study was to explore the feature of generative 
      artificial intelligence (AI) in asking sexual health among cancer survivors, 
      which are often challenging for patients to discuss.Methods We employed the 
      Generative Pre-trained Transformer-3.5 (GPT) as the generative AI platform and 
      used DocsBot for citation retrieval (June 2023). A structured prompt was devised 
      to generate 100 questions from the AI, based on epidemiological survey data 
      regarding sexual difficulties among cancer survivors. These questions were 
      submitted to Bot1 (standard GPT) and Bot2 (sourced from two clinical 
      guidelines).Results No censorship of sexual expressions or medical terms 
      occurred. Despite the lack of reflection on guideline recommendations, 
      'consultation' was significantly more prevalent in both bots' responses compared 
      with pharmacological interventions, with ORs of 47.3 (p<0.001) in Bot1 and 97.2 
      (p<0.001) in Bot2.Discussion Generative AI can serve to provide health 
      information on sensitive topics such as sexual health, despite the potential for 
      policy-restricted content. Responses were biased towards non-pharmacological 
      interventions, which is probably due to a GPT model designed with the 's 
      prohibition policy on replying to medical topics. This shift warrants attention 
      as it could potentially trigger patients' expectations for non-pharmacological 
      interventions.
CI  - © Author(s) (or their employer(s)) 2024. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Hanai, Akiko
AU  - Hanai A
AUID- ORCID: 0000-0003-4468-1488
AD  - Medical Data Mathematical Reasoning Team, Advanced Data Science Project, RIKEN 
      Information R&D and Strategy Headquarters, RIKEN, Yokohama, Japan 
      hanaaki0803@gmail.com.
AD  - Department of Artificial Intelligence Medicine, Graduate School of Medicine, 
      Chiba University, Chiba, Japan.
FAU - Ishikawa, Tetsuo
AU  - Ishikawa T
AD  - Medical Data Mathematical Reasoning Team, Advanced Data Science Project, RIKEN 
      Information R&D and Strategy Headquarters, RIKEN, Yokohama, Japan.
AD  - Department of Artificial Intelligence Medicine, Graduate School of Medicine, 
      Chiba University, Chiba, Japan.
AD  - Department of Extended Intelligence for Medicine, The Ishii-Ishibashi Laboratory, 
      Keio University School of Medicine, Tokyo, Japan.
AD  - Collective Intelligence Research Laboratory, Graduate School of Arts and 
      Sciences, The University of Tokyo, Tokyo, Japan.
FAU - Kawauchi, Shoichiro
AU  - Kawauchi S
AD  - Medical Data Mathematical Reasoning Team, Advanced Data Science Project, RIKEN 
      Information R&D and Strategy Headquarters, RIKEN, Yokohama, Japan.
FAU - Iida, Yuta
AU  - Iida Y
AD  - Medical Data Mathematical Reasoning Team, Advanced Data Science Project, RIKEN 
      Information R&D and Strategy Headquarters, RIKEN, Yokohama, Japan.
FAU - Kawakami, Eiryo
AU  - Kawakami E
AD  - Medical Data Mathematical Reasoning Team, Advanced Data Science Project, RIKEN 
      Information R&D and Strategy Headquarters, RIKEN, Yokohama, Japan.
AD  - Department of Artificial Intelligence Medicine, Graduate School of Medicine, 
      Chiba University, Chiba, Japan.
LA  - eng
PT  - Journal Article
DEP - 20240404
PL  - England
TA  - BMJ Health Care Inform
JT  - BMJ health & care informatics
JID - 101745500
SB  - IM
MH  - Humans
MH  - *Health Communication
MH  - Artificial Intelligence
MH  - *Sexual Health
MH  - Software
MH  - Bias
MH  - *Neoplasms/therapy
PMC - PMC11002430
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Clinical Governance
OT  - Evidence-Based Medicine
OT  - Health Communication
COIS- Competing interests: None declared.
EDAT- 2024/04/05 00:42
MHDA- 2024/04/08 06:42
PMCR- 2024/04/04
CRDT- 2024/04/04 21:32
PHST- 2023/10/03 00:00 [received]
PHST- 2024/03/09 00:00 [accepted]
PHST- 2024/04/08 06:42 [medline]
PHST- 2024/04/05 00:42 [pubmed]
PHST- 2024/04/04 21:32 [entrez]
PHST- 2024/04/04 00:00 [pmc-release]
AID - bmjhci-2023-100924 [pii]
AID - 10.1136/bmjhci-2023-100924 [doi]
PST - epublish
SO  - BMJ Health Care Inform. 2024 Apr 4;31(1):e100924. doi: 
      10.1136/bmjhci-2023-100924.

PMID- 37889368
OWN - NLM
STAT- MEDLINE
DCOM- 20231130
LR  - 20241219
IS  - 1708-0428 (Electronic)
IS  - 0960-8923 (Linking)
VI  - 33
IP  - 12
DP  - 2023 Dec
TI  - Bariatric Evaluation Through AI: a Survey of Expert Opinions Versus ChatGPT-4 
      (BETA-SEOV).
PG  - 3971-3980
LID - 10.1007/s11695-023-06903-w [doi]
AB  - BACKGROUND: Recent advancements in artificial intelligence, such as OpenAI's 
      ChatGPT-4, are revolutionizing various sectors, including healthcare. This study 
      investigates the use of ChatGPT-4 in identifying suitable candidates for 
      bariatric surgery and providing surgical recommendations to improve 
      decision-making in obesity treatment amid the global obesity epidemic. METHODS: 
      We devised ten patient scenarios, thoughtfully encompassing a spectrum that spans 
      from uncomplicated cases to more complex ones. Our objective was to delve into 
      the decision-making process regarding the recommendation of bariatric surgery. 
      From July 29th to August 10th, 2023, we conducted a voluntary online survey 
      involving thirty prominent bariatric surgeons, ensuring that there was no 
      predetermined bias in the selection of a specific type of bariatric surgery. This 
      survey was designed to collect their insights on these scenarios and gain a 
      deeper understanding of their professional experience and background in the field 
      of bariatric surgery. Additionally, we consulted ChatGPT-4 in two separate 
      conversations to evaluate its alignment with expert opinions on bariatric surgery 
      options. RESULTS: In 40% of the scenarios, disparities were identified between 
      the two conversations with ChatGPT-4. It matched expert opinions in 30% of cases. 
      Differences were noted in cases like gastrointestinal metaplasia and gastric 
      adenocarcinoma, but there was alignment with conditions like endometriosis and 
      GERD. CONCLUSION: The evaluation of ChatGPT-4's role in determining bariatric 
      surgery suitability uncovered both potential and shortcomings. Its alignment with 
      experts was inconsistent, and it often overlooked key factors, emphasizing human 
      expertise's value. Its current use requires caution, and further refinement is 
      needed for clinical application.
CI  - © 2023. The Author(s), under exclusive licence to Springer Science+Business 
      Media, LLC, part of Springer Nature.
FAU - Jazi, Amir Hossein Davarpanah
AU  - Jazi AHD
AD  - Department of Surgery, Minimally Invasive Surgery Research Center, Division of 
      Minimally Invasive and Bariatric Surgery, School of Medicine, Rasool-E Akram 
      Hospital, Iran University of Medical Sciences, Niyaesh Avenue, Sattar Khan 
      Street, Tehran, Iran.
FAU - Mahjoubi, Mohammad
AU  - Mahjoubi M
AD  - Clinical Research Development Center, Najafabad Branch, Islamic Azad University, 
      Najafabad, Iran.
FAU - Shahabi, Shahab
AU  - Shahabi S
AUID- ORCID: 0000-0002-8415-2567
AD  - Department of Surgery, Minimally Invasive Surgery Research Center, Division of 
      Minimally Invasive and Bariatric Surgery, School of Medicine, Rasool-E Akram 
      Hospital, Iran University of Medical Sciences, Niyaesh Avenue, Sattar Khan 
      Street, Tehran, Iran. shshahabi@yahoo.com.
FAU - Alqahtani, Aayed R
AU  - Alqahtani AR
AD  - New Medical Center, Riyadh, Saudi Arabia.
FAU - Haddad, Ashraf
AU  - Haddad A
AD  - Gastrointestinal Metabolic and Bariatric Center, GBMC M, Jordan Hospital, Amman, 
      Jordan.
FAU - Pazouki, Abdolreza
AU  - Pazouki A
AD  - Department of Surgery, Minimally Invasive Surgery Research Center, Division of 
      Minimally Invasive and Bariatric Surgery, School of Medicine, Rasool-E Akram 
      Hospital, Iran University of Medical Sciences, Niyaesh Avenue, Sattar Khan 
      Street, Tehran, Iran.
FAU - Prasad, Arun
AU  - Prasad A
AD  - GI, Bariatric and Robotic Surgery Apollo Hospital, New Delhi, India.
FAU - Safadi, Bassem Y
AU  - Safadi BY
AD  - Surgical Services Aman Hospital, Doha, Qatar.
FAU - Chiappetta, Sonja
AU  - Chiappetta S
AD  - Bariatric and Metabolic Surgery Unit, Ospedale Evangelico Betania, Naples, Italy.
FAU - Taskin, Halit Eren
AU  - Taskin HE
AD  - Department of General Surgery, Cerrahpaşa Medical Faculty, Istanbul University 
      Cerrahpaşa, Istanbul, Turkey.
FAU - Billy, Helmuth Thorlakur
AU  - Billy HT
AD  - Ventura Advanced Surgical Associates, Ventura, CA, USA.
FAU - Kasama, Kazunori
AU  - Kasama K
AD  - Weight Loss and Metabolic Surgery Center, Yotsuya Medical Cube, Tokyo, Japan.
FAU - Mahawar, Kamal
AU  - Mahawar K
AD  - Sunderland Royal Hospital, Sunderland, UK.
FAU - Gawdat, Khaled
AU  - Gawdat K
AD  - Ain Shams University Faculty of Medicine Department of General Surgery, Cairo, 
      Egypt.
FAU - Rheinwalt, Karl Peter
AU  - Rheinwalt KP
AD  - Department of Bariatric, Metabolic and Plastic Surgery, St. Franziskus Hospital, 
      Cologne, Germany.
FAU - Miller, Karl A
AU  - Miller KA
AD  - Dubai London Hospital, Dubai, UAE.
FAU - Kow, Lilian
AU  - Kow L
AD  - Department GI Surgery Flinders, University South Australia, Adelaide, Australia.
FAU - Neto, Manoel Galvao
AU  - Neto MG
AD  - Mohak Bariatric and Robotic Center, Indore, India.
FAU - Yang, Wah
AU  - Yang W
AD  - The First Affiliated Hospital of Jinan University, Guangzhou, China.
FAU - Palermo, Mariano
AU  - Palermo M
AD  - Gastrointestinal and Bariatric Surgery, University of Buenos Aires, Buenos Aires, 
      Argentina.
FAU - Ghanem, Omar M
AU  - Ghanem OM
AD  - Mayo Clinic, Rochester, MN, USA.
FAU - Lainas, Panagiotis
AU  - Lainas P
AD  - Department of Digestive and Bariatric Surgery, Metropolitan Hospital, HEAL 
      Academy, Athens, Greece.
FAU - Peterli, Ralph
AU  - Peterli R
AD  - Deputy Head of Visceral Surgery and Head of Bariatric-Metabolic Surgery Clarunis, 
      Department of Visceral Surgery, University Centre for Gastrointestinal and Liver 
      Diseases St. Clara Hospital and University Hospital Basel, 4002, Basel, 
      Switzerland.
FAU - Kassir, Radwan
AU  - Kassir R
AD  - Digestive Surgery Unit, University Hospital of La Réunion -Félix Guyon Hospital, 
      Saint-Denis, La Réunion, France.
FAU - Puy, Ramon Vilallonga
AU  - Puy RV
AD  - Head Endocrine-Metabolic and Bariatric Surgery Unit, Vall Hebron Barcelona 
      Hospital Campus, Pg. De La Vall d'hebron, 119-129, 08035, Barcelona, Spain.
FAU - Da Silva Ribeiro, Rui José
AU  - Da Silva Ribeiro RJ
AD  - General Surgery Department, Multidisciplinary Center for Obesity Treatment - 
      Hospital Lusíadas Amadora, Amadora, Portugal.
FAU - Verboonen, Sergio
AU  - Verboonen S
AD  - Obesity Goodbye Center, Tijuana, Mexico.
FAU - Pintar, Tadeja
AU  - Pintar T
AD  - UMC Ljubljana, Department of Abdominal Surgery and Medical Faculty, Ljubljana, 
      Slovenia.
FAU - Shabbir, Asim
AU  - Shabbir A
AD  - National University of Singapore, Singapore, Singapore.
FAU - Musella, Mario
AU  - Musella M
AD  - Advanced Biomedical Sciences Department, "Federico II" University, Naples, Italy.
FAU - Kermansaravi, Mohammad
AU  - Kermansaravi M
AD  - Department of Surgery, Minimally Invasive Surgery Research Center, Division of 
      Minimally Invasive and Bariatric Surgery, School of Medicine, Rasool-E Akram 
      Hospital, Iran University of Medical Sciences, Niyaesh Avenue, Sattar Khan 
      Street, Tehran, Iran.
LA  - eng
PT  - Journal Article
DEP - 20231027
PL  - United States
TA  - Obes Surg
JT  - Obesity surgery
JID - 9106714
SB  - IM
MH  - Female
MH  - Humans
MH  - Artificial Intelligence
MH  - *Obesity, Morbid/surgery
MH  - *Bariatrics
MH  - Obesity
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Bariatric Evaluation
OT  - Bariatric Surgery
OT  - ChatGPT
OT  - Health Literacy
OT  - Language Learning Models
EDAT- 2023/10/27 12:42
MHDA- 2023/11/30 06:43
CRDT- 2023/10/27 11:10
PHST- 2023/08/22 00:00 [received]
PHST- 2023/10/11 00:00 [accepted]
PHST- 2023/10/08 00:00 [revised]
PHST- 2023/11/30 06:43 [medline]
PHST- 2023/10/27 12:42 [pubmed]
PHST- 2023/10/27 11:10 [entrez]
AID - 10.1007/s11695-023-06903-w [pii]
AID - 10.1007/s11695-023-06903-w [doi]
PST - ppublish
SO  - Obes Surg. 2023 Dec;33(12):3971-3980. doi: 10.1007/s11695-023-06903-w. Epub 2023 
      Oct 27.

PMID- 30120616
OWN - NLM
STAT- MEDLINE
DCOM- 20190305
LR  - 20190305
IS  - 1352-8661 (Electronic)
IS  - 0968-5243 (Linking)
VI  - 31
IP  - 6
DP  - 2018 Dec
TI  - MRI quality assurance based on 3D FLAIR brain images.
PG  - 689-699
LID - 10.1007/s10334-018-0699-3 [doi]
AB  - OBJECTIVE: Quality assurance (QA) of magnetic resonance imaging (MRI) often 
      relies on imaging phantoms with suitable structures and uniform regions. However, 
      the connection between phantom measurements and actual clinical image quality is 
      ambiguous. Thus, it is desirable to measure objective image quality directly from 
      clinical images. MATERIALS AND METHODS: In this work, four measurements suitable 
      for clinical image QA were presented: image resolution, contrast-to-noise ratio, 
      quality index and bias index. The methods were applied to a large cohort of 
      clinical 3D FLAIR volumes over a test period of 9.5 months. The results were 
      compared with phantom QA. Additionally, the effect of patient movement on the 
      presented measures was studied. RESULTS: A connection between the presented 
      clinical QA methods and scanner performance was observed: the values reacted to 
      MRI equipment breakdowns that occurred during the study period. No apparent 
      correlation with phantom QA results was found. The patient movement was found to 
      have a significant effect on the resolution and contrast-to-noise ratio values. 
      DISCUSSION: QA based on clinical images provides a direct method for following 
      MRI scanner performance. The methods could be used to detect problems, and 
      potentially reduce scanner downtime. Furthermore, with the presented 
      methodologies comparisons could be made between different sequences and imaging 
      settings. In the future, an online QA system could recognize insufficient image 
      quality and suggest an immediate re-scan.
FAU - Peltonen, Juha I
AU  - Peltonen JI
AD  - HUS Medical Imaging Center, Radiology, Helsinki University Hospital, University 
      of Helsinki, P.O. Box 340, FI-00029, Helsinki, Finland. juha.peltonen@hus.fi.
AD  - Department of Neuroscience and Biomedical Engineering, School of Science, Aalto 
      University, P.O. Box 12200, FI-00076, Espoo, Finland. juha.peltonen@hus.fi.
FAU - Mäkelä, Teemu
AU  - Mäkelä T
AD  - HUS Medical Imaging Center, Radiology, Helsinki University Hospital, University 
      of Helsinki, P.O. Box 340, FI-00029, Helsinki, Finland.
AD  - Department of Physics, University of Helsinki, P.O. Box 64, FI-00014, Helsinki, 
      Finland.
FAU - Salli, Eero
AU  - Salli E
AD  - HUS Medical Imaging Center, Radiology, Helsinki University Hospital, University 
      of Helsinki, P.O. Box 340, FI-00029, Helsinki, Finland.
LA  - eng
PT  - Journal Article
DEP - 20180817
PL  - Germany
TA  - MAGMA
JT  - Magma (New York, N.Y.)
JID - 9310752
RN  - 0 (Contrast Media)
SB  - IM
MH  - Brain/*diagnostic imaging
MH  - Brain Mapping
MH  - Cohort Studies
MH  - Contrast Media
MH  - Humans
MH  - Imaging, Three-Dimensional/*methods
MH  - Machine Learning
MH  - Magnetic Resonance Imaging/*methods
MH  - Medical Informatics
MH  - Motion
MH  - Normal Distribution
MH  - Phantoms, Imaging
MH  - Quality Assurance, Health Care
MH  - Quality Control
MH  - Signal-To-Noise Ratio
MH  - Spectroscopy, Fourier Transform Infrared
OTO - NOTNLM
OT  - Computer-assisted image analysis
OT  - Magnetic resonance imaging
OT  - Quality assurance
OT  - Quality control
EDAT- 2018/08/19 06:00
MHDA- 2019/03/06 06:00
CRDT- 2018/08/19 06:00
PHST- 2018/06/11 00:00 [received]
PHST- 2018/08/08 00:00 [accepted]
PHST- 2018/08/06 00:00 [revised]
PHST- 2018/08/19 06:00 [pubmed]
PHST- 2019/03/06 06:00 [medline]
PHST- 2018/08/19 06:00 [entrez]
AID - 10.1007/s10334-018-0699-3 [pii]
AID - 10.1007/s10334-018-0699-3 [doi]
PST - ppublish
SO  - MAGMA. 2018 Dec;31(6):689-699. doi: 10.1007/s10334-018-0699-3. Epub 2018 Aug 17.

PMID- 39836952
OWN - NLM
STAT- MEDLINE
DCOM- 20250121
LR  - 20250210
IS  - 1929-0748 (Electronic)
IS  - 1929-0748 (Linking)
VI  - 14
DP  - 2025 Jan 21
TI  - Applications of Natural Language Processing and Large Language Models for Social 
      Determinants of Health: Protocol for a Systematic Review.
PG  - e66094
LID - 10.2196/66094 [doi]
LID - e66094
AB  - BACKGROUND: In recent years, the intersection of natural language processing 
      (NLP) and public health has opened innovative pathways for investigating social 
      determinants of health (SDOH) in textual datasets. Despite the promise of NLP in 
      the SDOH domain, the literature is dispersed across various disciplines, and 
      there is a need to consolidate existing knowledge, identify knowledge gaps in the 
      literature, and inform future research directions in this emerging field. 
      OBJECTIVE: This research protocol describes a systematic review to identify and 
      highlight NLP techniques, including large language models, used for SDOH-related 
      studies. METHODS: A search strategy will be executed across PubMed, Web of 
      Science, IEEE Xplore, Scopus, PsycINFO, HealthSource: Academic Nursing, and ACL 
      Anthology to find studies published in English between 2014 and 2024. Three 
      reviewers (SR, ZZ, and YC) will independently screen the studies to avoid voting 
      bias, and two (AS and YX) additional reviewers will resolve any conflicts during 
      the screening process. We will further screen studies that cited the included 
      studies (forward search). Following the title abstract and full-text screening, 
      the characteristics and main findings of the included studies and resources will 
      be tabulated, visualized, and summarized. RESULTS: The search strategy was 
      formulated and run across the 7 databases in August 2024. We expect the results 
      to be submitted for peer review publication in early 2025. As of December 2024, 
      the title and abstract screening was underway. CONCLUSIONS: This systematic 
      review aims to provide a comprehensive study of existing research on the 
      application of NLP for various SDOH tasks across multiple textual datasets. By 
      rigorously evaluating the methodologies, tools, and outcomes of eligible studies, 
      the review will identify gaps in current knowledge and suggest directions for 
      future research in the form of specific research questions. The findings will be 
      instrumental in developing more effective NLP models for SDOH, ultimately 
      contributing to improved health outcomes and a better understanding of social 
      determinants in diverse populations. INTERNATIONAL REGISTERED REPORT IDENTIFIER 
      (IRRID): DERR1-10.2196/66094.
CI  - ©Swati Rajwal, Ziyuan Zhang, Yankai Chen, Hannah Rogers, Abeed Sarker, Yunyu 
      Xiao. Originally published in JMIR Research Protocols 
      (https://www.researchprotocols.org), 21.01.2025.
FAU - Rajwal, Swati
AU  - Rajwal S
AUID- ORCID: 0000-0002-3826-5069
AD  - Department of Computer Science, Emory University, Atlanta, GA, United States.
FAU - Zhang, Ziyuan
AU  - Zhang Z
AUID- ORCID: 0000-0003-3488-5903
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, 
      MA, United States.
FAU - Chen, Yankai
AU  - Chen Y
AUID- ORCID: 0000-0001-5741-2047
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      United States.
FAU - Rogers, Hannah
AU  - Rogers H
AUID- ORCID: 0000-0002-9515-1439
AD  - Woodruff Health Sciences Center Library, Emory University, Atlanta, GA, United 
      States.
FAU - Sarker, Abeed
AU  - Sarker A
AUID- ORCID: 0000-0001-7358-544X
AD  - Department of Biomedical Informatics, Emory University, Atlanta, GA, United 
      States.
FAU - Xiao, Yunyu
AU  - Xiao Y
AUID- ORCID: 0000-0002-0479-1781
AD  - Department of Population Health Sciences, Weill Cornell Medicine, New York, NY, 
      United States.
LA  - eng
GR  - R01 DA057599/DA/NIDA NIH HHS/United States
GR  - RF1 MH134649/MH/NIMH NIH HHS/United States
PT  - Journal Article
DEP - 20250121
PL  - Canada
TA  - JMIR Res Protoc
JT  - JMIR research protocols
JID - 101599504
SB  - IM
MH  - *Social Determinants of Health
MH  - Humans
MH  - *Natural Language Processing
MH  - *Systematic Reviews as Topic
PMC - PMC11795155
OTO - NOTNLM
OT  - LLM
OT  - NLP
OT  - SDOH
OT  - large language models
OT  - natural language processing
OT  - social determinants of health
OT  - systematic review protocol
COIS- Conflicts of Interest: None declared.
EDAT- 2025/01/22 05:31
MHDA- 2025/01/22 05:32
PMCR- 2025/01/21
CRDT- 2025/01/21 16:53
PHST- 2024/09/03 00:00 [received]
PHST- 2024/12/26 00:00 [accepted]
PHST- 2024/12/04 00:00 [revised]
PHST- 2025/01/22 05:32 [medline]
PHST- 2025/01/22 05:31 [pubmed]
PHST- 2025/01/21 16:53 [entrez]
PHST- 2025/01/21 00:00 [pmc-release]
AID - v14i1e66094 [pii]
AID - 10.2196/66094 [doi]
PST - epublish
SO  - JMIR Res Protoc. 2025 Jan 21;14:e66094. doi: 10.2196/66094.

PMID- 38679900
OWN - NLM
STAT- MEDLINE
DCOM- 20240822
LR  - 20240824
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 9
DP  - 2024 Sep 1
TI  - Mixed methods assessment of the influence of demographics on medical advice of 
      ChatGPT.
PG  - 2002-2009
LID - 10.1093/jamia/ocae086 [doi]
AB  - OBJECTIVES: To evaluate demographic biases in diagnostic accuracy and health 
      advice between generative artificial intelligence (AI) (ChatGPT GPT-4) and 
      traditional symptom checkers like WebMD. MATERIALS AND METHODS: Combination 
      symptom and demographic vignettes were developed for 27 most common symptom 
      complaints. Standardized prompts, written from a patient perspective, with 
      varying demographic permutations of age, sex, and race/ethnicity were entered 
      into ChatGPT (GPT-4) between July and August 2023. In total, 3 runs of 540 
      ChatGPT prompts were compared to the corresponding WebMD Symptom Checker output 
      using a mixed-methods approach. In addition to diagnostic correctness, the 
      associated text generated by ChatGPT was analyzed for readability (using 
      Flesch-Kincaid Grade Level) and qualitative aspects like disclaimers and 
      demographic tailoring. RESULTS: ChatGPT matched WebMD in 91% of diagnoses, with a 
      24% top diagnosis match rate. Diagnostic accuracy was not significantly different 
      across demographic groups, including age, race/ethnicity, and sex. ChatGPT's 
      urgent care recommendations and demographic tailoring were presented 
      significantly more to 75-year-olds versus 25-year-olds (P < .01) but were not 
      statistically different among race/ethnicity and sex groups. The GPT text was 
      suitable for college students, with no significant demographic variability. 
      DISCUSSION: The use of non-health-tailored generative AI, like ChatGPT, for 
      simple symptom-checking functions provides comparable diagnostic accuracy to 
      commercially available symptom checkers and does not demonstrate significant 
      demographic bias in this setting. The text accompanying differential diagnoses, 
      however, suggests demographic tailoring that could potentially introduce bias. 
      CONCLUSION: These results highlight the need for continued rigorous evaluation of 
      AI-driven medical platforms, focusing on demographic biases to ensure equitable 
      care.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Andreadis, Katerina
AU  - Andreadis K
AUID- ORCID: 0000-0001-8586-450X
AD  - Department of Population Health, NYU Grossman School of Medicine, New York, NY 
      10016, United States.
FAU - Newman, Devon R
AU  - Newman DR
AD  - Department of Population Health, NYU Grossman School of Medicine, New York, NY 
      10016, United States.
AD  - Brown University, Providence, RI 02912, United States.
FAU - Twan, Chelsea
AU  - Twan C
AD  - Department of Population Health, NYU Grossman School of Medicine, New York, NY 
      10016, United States.
FAU - Shunk, Amelia
AU  - Shunk A
AD  - Department of Population Health, NYU Grossman School of Medicine, New York, NY 
      10016, United States.
FAU - Mann, Devin M
AU  - Mann DM
AD  - Department of Population Health, NYU Grossman School of Medicine, New York, NY 
      10016, United States.
AD  - Medical Center Information Technology, NYU Langone Health, New York, NY 10016, 
      United States.
FAU - Stevens, Elizabeth R
AU  - Stevens ER
AD  - Department of Population Health, NYU Grossman School of Medicine, New York, NY 
      10016, United States.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Humans
MH  - Female
MH  - *Artificial Intelligence
MH  - Male
MH  - Demography
MH  - Sociodemographic Factors
MH  - Adult
PMC - PMC11339520
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - bias
OT  - digital health
OT  - large language model
OT  - symptom checker
COIS- The authors have no competing interests to declare.
EDAT- 2024/04/29 06:45
MHDA- 2024/08/22 06:42
PMCR- 2025/04/29
CRDT- 2024/04/29 01:32
PHST- 2023/12/15 00:00 [received]
PHST- 2024/03/22 00:00 [revised]
PHST- 2024/04/03 00:00 [accepted]
PHST- 2025/04/29 00:00 [pmc-release]
PHST- 2024/08/22 06:42 [medline]
PHST- 2024/04/29 06:45 [pubmed]
PHST- 2024/04/29 01:32 [entrez]
AID - 7659471 [pii]
AID - ocae086 [pii]
AID - 10.1093/jamia/ocae086 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Sep 1;31(9):2002-2009. doi: 10.1093/jamia/ocae086.

PMID- 39484238
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241101
DP  - 2024 Oct 17
TI  - Assessing Retrieval-Augmented Large Language Model Performance in Emergency 
      Department ICD-10-CM Coding Compared to Human Coders.
LID - 2024.10.15.24315526 [pii]
LID - 10.1101/2024.10.15.24315526 [doi]
AB  - BACKGROUND: Accurate medical coding is essential for clinical and administrative 
      purposes but complicated, time-consuming, and biased. This study compares 
      Retrieval-Augmented Generation (RAG)-enhanced LLMs to provider-assigned codes in 
      producing ICD-10-CM codes from emergency department (ED) clinical records. 
      METHODS: Retrospective cohort study using 500 ED visits randomly selected from 
      the Mount Sinai Health System between January and April 2024. The RAG system 
      integrated past 1,038,066 ED visits data (2021-2023) into the LLMs' predictions 
      to improve coding accuracy. Nine commercial and open-source LLMs were evaluated. 
      The primary outcome was a head-to-head comparison of the ICD-10-CM codes 
      generated by the RAG-enhanced LLMs and those assigned by the original providers. 
      A panel of four physicians and two LLMs blindly reviewed the codes, comparing the 
      RAG-enhanced LLM and provider-assigned codes on accuracy and specificity. 
      FINDINGS: RAG-enhanced LLMs demonstrated superior performance to provider coders 
      in both the accuracy and specificity of code assignments. In a targeted 
      evaluation of 200 cases where discrepancies existed between GPT-4 and 
      provider-assigned codes, human reviewers favored GPT-4 for accuracy in 447 
      instances, compared to 277 instances where providers' codes were preferred 
      (p<0.001). Similarly, GPT-4 was selected for its superior specificity in 509 
      cases, whereas human coders were preferred in only 181 cases (p<0.001). Smaller 
      open-access models, such as Llama-3.1-70B, also demonstrated substantial 
      scalability when enhanced with RAG, with 218 instances of accuracy preference 
      compared to 90 for providers' codes. Furthermore, across all models, the exact 
      match rate between LLM-generated and provider-assigned codes significantly 
      improved following RAG integration, with Qwen-2-7B increasing from 0.8% to 17.6% 
      and Gemma-2-9b-it improving from 7.2% to 26.4%. INTERPRETATION: RAG-enhanced LLMs 
      improve medical coding accuracy in EDs, suggesting clinical workflow 
      applications. These findings show that generative AI can improve clinical 
      outcomes and reduce administrative burdens. FUNDING: This work was supported in 
      part through the computational and data resources and staff expertise provided by 
      Scientific Computing and Data at the Icahn School of Medicine at Mount Sinai and 
      supported by the Clinical and Translational Science Awards (CTSA) grant 
      UL1TR004419 from the National Center for Advancing Translational Sciences. 
      Research reported in this publication was also supported by the Office of 
      Research Infrastructure of the National Institutes of Health under award number 
      S10OD026880 and S10OD030463. The content is solely the responsibility of the 
      authors and does not necessarily represent the official views of the National 
      Institutes of Health. The funders played no role in study design, data 
      collection, analysis and interpretation of data, or the writing of this 
      manuscript. TWITTER SUMMARY: A study showed AI models with retrieval-augmented 
      generation outperformed human doctors in ED diagnostic coding accuracy and 
      specificity. Even smaller AI models perform favorably when using RAG. This 
      suggests potential for reducing administrative burden in healthcare, improving 
      coding efficiency, and enhancing clinical documentation.
FAU - Klang, Eyal
AU  - Klang E
AUID- ORCID: 0000-0002-4567-3108
FAU - Tessler, Idit
AU  - Tessler I
AUID- ORCID: 0000-0002-3297-7022
FAU - Apakama, Donald U
AU  - Apakama DU
FAU - Abbott, Ethan
AU  - Abbott E
FAU - Glicksberg, Benjamin S
AU  - Glicksberg BS
FAU - Arnold, Monique
AU  - Arnold M
FAU - Moses, Akini
AU  - Moses A
FAU - Sakhuja, Ankit
AU  - Sakhuja A
FAU - Soroush, Ali
AU  - Soroush A
FAU - Charney, Alexander W
AU  - Charney AW
FAU - Reich, David L
AU  - Reich DL
FAU - McGreevy, Jolion
AU  - McGreevy J
FAU - Gavin, Nicholas
AU  - Gavin N
FAU - Carr, Brendan
AU  - Carr B
FAU - Freeman, Robert
AU  - Freeman R
FAU - Nadkarni, Girish N
AU  - Nadkarni GN
LA  - eng
PT  - Journal Article
PT  - Preprint
DEP - 20241017
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11527068
EDAT- 2024/11/04 07:23
MHDA- 2024/11/04 07:24
PMCR- 2024/10/31
CRDT- 2024/11/01 05:11
PHST- 2024/11/04 07:24 [medline]
PHST- 2024/11/04 07:23 [pubmed]
PHST- 2024/11/01 05:11 [entrez]
PHST- 2024/10/31 00:00 [pmc-release]
AID - 2024.10.15.24315526 [pii]
AID - 10.1101/2024.10.15.24315526 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Oct 17:2024.10.15.24315526. doi: 
      10.1101/2024.10.15.24315526.

PMID- 29743531
OWN - NLM
STAT- MEDLINE
DCOM- 20191011
LR  - 20231112
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 8
IP  - 1
DP  - 2018 May 9
TI  - Identifying Suicide Ideation and Suicidal Attempts in a Psychiatric Clinical 
      Research Database using Natural Language Processing.
PG  - 7426
LID - 10.1038/s41598-018-25773-2 [doi]
LID - 7426
AB  - Research into suicide prevention has been hampered by methodological limitations 
      such as low sample size and recall bias. Recently, Natural Language Processing 
      (NLP) strategies have been used with Electronic Health Records to increase 
      information extraction from free text notes as well as structured fields 
      concerning suicidality and this allows access to much larger cohorts than 
      previously possible. This paper presents two novel NLP approaches - a rule-based 
      approach to classify the presence of suicide ideation and a hybrid machine 
      learning and rule-based approach to identify suicide attempts in a psychiatric 
      clinical database. Good performance of the two classifiers in the evaluation 
      study suggest they can be used to accurately detect mentions of suicide ideation 
      and attempt within free-text documents in this psychiatric database. The novelty 
      of the two approaches lies in the malleability of each classifier if a need to 
      refine performance, or meet alternate classification requirements arises. The 
      algorithms can also be adapted to fit infrastructures of other clinical datasets 
      given sufficient clinical recording practice knowledge, without dependency on 
      medical codes or additional data extraction of known risk factors to predict 
      suicidal behaviour.
FAU - Fernandes, Andrea C
AU  - Fernandes AC
AD  - Institute of Psychiatry, Psychology and Neuroscience, Academic Department of 
      Psychological Medicine, London, SE5 8AF, United Kingdom. 
      andrea.fernandes@kcl.ac.uk.
AD  - UK National Institute for Health Research Biomedical Research Centre, South 
      London and Maudsley National Health Service Foundation Trust and King's College 
      London, London, SE5 8AZ, United Kingdom. andrea.fernandes@kcl.ac.uk.
FAU - Dutta, Rina
AU  - Dutta R
AD  - Institute of Psychiatry, Psychology and Neuroscience, Academic Department of 
      Psychological Medicine, London, SE5 8AF, United Kingdom.
AD  - UK National Institute for Health Research Biomedical Research Centre, South 
      London and Maudsley National Health Service Foundation Trust and King's College 
      London, London, SE5 8AZ, United Kingdom.
FAU - Velupillai, Sumithra
AU  - Velupillai S
AD  - Institute of Psychiatry, Psychology and Neuroscience, Academic Department of 
      Psychological Medicine, London, SE5 8AF, United Kingdom.
AD  - UK National Institute for Health Research Biomedical Research Centre, South 
      London and Maudsley National Health Service Foundation Trust and King's College 
      London, London, SE5 8AZ, United Kingdom.
FAU - Sanyal, Jyoti
AU  - Sanyal J
AD  - Institute of Psychiatry, Psychology and Neuroscience, Academic Department of 
      Psychological Medicine, London, SE5 8AF, United Kingdom.
AD  - UK National Institute for Health Research Biomedical Research Centre, South 
      London and Maudsley National Health Service Foundation Trust and King's College 
      London, London, SE5 8AZ, United Kingdom.
FAU - Stewart, Robert
AU  - Stewart R
AD  - Institute of Psychiatry, Psychology and Neuroscience, Academic Department of 
      Psychological Medicine, London, SE5 8AF, United Kingdom.
AD  - UK National Institute for Health Research Biomedical Research Centre, South 
      London and Maudsley National Health Service Foundation Trust and King's College 
      London, London, SE5 8AZ, United Kingdom.
FAU - Chandran, David
AU  - Chandran D
AD  - Institute of Psychiatry, Psychology and Neuroscience, Academic Department of 
      Psychological Medicine, London, SE5 8AF, United Kingdom.
AD  - UK National Institute for Health Research Biomedical Research Centre, South 
      London and Maudsley National Health Service Foundation Trust and King's College 
      London, London, SE5 8AZ, United Kingdom.
LA  - eng
GR  - MC_PC_17214/MRC_/Medical Research Council/United Kingdom
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20180509
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Data Mining/*methods
MH  - *Databases, Factual
MH  - Humans
MH  - *Natural Language Processing
MH  - *Suicidal Ideation
MH  - Suicide, Attempted/*statistics & numerical data
PMC - PMC5943451
COIS- The authors declare no competing interests.
EDAT- 2018/05/11 06:00
MHDA- 2019/10/12 06:00
PMCR- 2018/05/09
CRDT- 2018/05/11 06:00
PHST- 2017/04/26 00:00 [received]
PHST- 2018/04/27 00:00 [accepted]
PHST- 2018/05/11 06:00 [entrez]
PHST- 2018/05/11 06:00 [pubmed]
PHST- 2019/10/12 06:00 [medline]
PHST- 2018/05/09 00:00 [pmc-release]
AID - 10.1038/s41598-018-25773-2 [pii]
AID - 25773 [pii]
AID - 10.1038/s41598-018-25773-2 [doi]
PST - epublish
SO  - Sci Rep. 2018 May 9;8(1):7426. doi: 10.1038/s41598-018-25773-2.

PMID- 38977396
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240711
IS  - 2287-1152 (Print)
IS  - 2287-5603 (Electronic)
IS  - 2287-1152 (Linking)
VI  - 25
IP  - 3
DP  - 2024 Jun
TI  - The new frontier: utilizing ChatGPT to expand craniofacial research.
PG  - 116-122
LID - 10.7181/acfs.2024.00115 [doi]
AB  - BACKGROUND: Due to the importance of evidence-based research in plastic surgery, 
      the authors of this study aimed to assess the accuracy of ChatGPT in generating 
      novel systematic review ideas within the field of craniofacial surgery. METHODS: 
      ChatGPT was prompted to generate 20 novel systematic review ideas for 10 
      different subcategories within the field of craniofacial surgery. For each topic, 
      the chatbot was told to give 10 "general" and 10 "specific" ideas that were 
      related to the concept. In order to determine the accuracy of ChatGPT, a 
      literature review was conducted using PubMed, CINAHL, Embase, and Cochrane. 
      RESULTS: In total, 200 total systematic review research ideas were generated by 
      ChatGPT. We found that the algorithm had an overall 57.5% accuracy at identifying 
      novel systematic review ideas. ChatGPT was found to be 39% accurate for general 
      topics and 76% accurate for specific topics. CONCLUSION: Craniofacial surgeons 
      should use ChatGPT as a tool. We found that ChatGPT provided more precise answers 
      with specific research questions than with general questions and helped narrow 
      down the search scope, leading to a more relevant and accurate response. Beyond 
      research purposes, ChatGPT can augment patient consultations, improve healthcare 
      equity, and assist in clinical decisionmaking. With rapid advancements in 
      artificial intelligence (AI), it is important for plastic surgeons to consider 
      using AI in their clinical practice to improve patient-centered outcomes.
FAU - Zhang, Andi
AU  - Zhang A
AD  - Division of Plastic and Reconstructive Surgery, Saint Louis University School of 
      Medicine, St. Louis, MO, USA.
FAU - Dimock, Ethan
AU  - Dimock E
AD  - Oakland University William Beaumont School of Medicine, Rochester, MI, USA.
FAU - Gupta, Rohun
AU  - Gupta R
AD  - Division of Plastic and Reconstructive Surgery, Saint Louis University School of 
      Medicine, St. Louis, MO, USA.
FAU - Chen, Kevin
AU  - Chen K
AD  - Division of Plastic and Reconstructive Surgery, Saint Louis University School of 
      Medicine, St. Louis, MO, USA.
LA  - eng
PT  - Journal Article
DEP - 20240620
PL  - Korea (South)
TA  - Arch Craniofac Surg
JT  - Archives of craniofacial surgery
JID - 101588280
PMC - PMC11231409
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Craniofacial research
OT  - Machine learning
OT  - Natural language processing
OT  - Systematic review
COIS- Conflict of interest No potential conflict of interest relevant to this article 
      was reported.
EDAT- 2024/07/09 00:42
MHDA- 2024/07/09 00:43
PMCR- 2024/06/01
CRDT- 2024/07/08 22:18
PHST- 2024/02/29 00:00 [received]
PHST- 2024/06/11 00:00 [accepted]
PHST- 2024/07/09 00:43 [medline]
PHST- 2024/07/09 00:42 [pubmed]
PHST- 2024/07/08 22:18 [entrez]
PHST- 2024/06/01 00:00 [pmc-release]
AID - acfs.2024.00115 [pii]
AID - acfs-2024-00115 [pii]
AID - 10.7181/acfs.2024.00115 [doi]
PST - ppublish
SO  - Arch Craniofac Surg. 2024 Jun;25(3):116-122. doi: 10.7181/acfs.2024.00115. Epub 
      2024 Jun 20.

PMID- 31361300
OWN - NLM
STAT- MEDLINE
DCOM- 20210129
LR  - 20210129
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 26
IP  - 11
DP  - 2019 Nov 1
TI  - Development of a global infectious disease activity database using natural 
      language processing, machine learning, and human expertise.
PG  - 1355-1359
LID - 10.1093/jamia/ocz112 [doi]
AB  - OBJECTIVE: We assessed whether machine learning can be utilized to allow 
      efficient extraction of infectious disease activity information from online media 
      reports. MATERIALS AND METHODS: We curated a data set of labeled media reports 
      (n = 8322) indicating which articles contain updates about disease activity. We 
      trained a classifier on this data set. To validate our system, we used a held out 
      test set and compared our articles to the World Health Organization Disease 
      Outbreak News reports. RESULTS: Our classifier achieved a recall and precision of 
      88.8% and 86.1%, respectively. The overall surveillance system detected 94% of 
      the outbreaks identified by the WHO covered by online media (89%) and did so 43.4 
      (IQR: 9.5-61) days earlier on average. DISCUSSION: We constructed a global 
      real-time disease activity database surveilling 114 illnesses and syndromes. We 
      must further assess our system for bias, representativeness, granularity, and 
      accuracy. CONCLUSION: Machine learning, natural language processing, and human 
      expertise can be used to efficiently identify disease activity from digital media 
      reports.
CI  - © The Author(s) 2019. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Feldman, Joshua
AU  - Feldman J
AD  - Harvard University, School of Engineering and Applied Sciences, Cambridge, 
      Massachusetts, USA.
FAU - Thomas-Bachli, Andrea
AU  - Thomas-Bachli A
AD  - Li Ka Shing Knowledge Institute, St. Michaels Hospital, Toronto, Ontario, Canada.
AD  - BlueDot, Toronto, Ontario, Canada.
FAU - Forsyth, Jack
AU  - Forsyth J
AD  - Li Ka Shing Knowledge Institute, St. Michaels Hospital, Toronto, Ontario, Canada.
AD  - BlueDot, Toronto, Ontario, Canada.
FAU - Patel, Zaki Hasnain
AU  - Patel ZH
AD  - Li Ka Shing Knowledge Institute, St. Michaels Hospital, Toronto, Ontario, Canada.
AD  - BlueDot, Toronto, Ontario, Canada.
FAU - Khan, Kamran
AU  - Khan K
AD  - Li Ka Shing Knowledge Institute, St. Michaels Hospital, Toronto, Ontario, Canada.
AD  - BlueDot, Toronto, Ontario, Canada.
AD  - Division of Infectious Diseases, Department of Medicine, University of Toronto, 
      Toronto, Ontario, Canada.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Communicable Diseases/*epidemiology
MH  - Databases, Factual
MH  - *Disease Outbreaks
MH  - Global Health
MH  - Humans
MH  - Information Storage and Retrieval/*methods
MH  - *Machine Learning
MH  - *Natural Language Processing
MH  - Population Surveillance/*methods
MH  - User-Computer Interface
PMC - PMC7647217
OTO - NOTNLM
OT  - communicable diseases
OT  - health information systems
OT  - internet
OT  - machine learning
OT  - public health surveillance
EDAT- 2019/07/31 06:00
MHDA- 2021/01/30 06:00
PMCR- 2020/07/30
CRDT- 2019/07/31 06:00
PHST- 2019/01/09 00:00 [received]
PHST- 2019/05/28 00:00 [revised]
PHST- 2019/06/04 00:00 [accepted]
PHST- 2019/07/31 06:00 [pubmed]
PHST- 2021/01/30 06:00 [medline]
PHST- 2019/07/31 06:00 [entrez]
PHST- 2020/07/30 00:00 [pmc-release]
AID - 5541002 [pii]
AID - ocz112 [pii]
AID - 10.1093/jamia/ocz112 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2019 Nov 1;26(11):1355-1359. doi: 10.1093/jamia/ocz112.

PMID- 37090406
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230425
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 3
DP  - 2023 Mar
TI  - Breaking Bias: The Role of Artificial Intelligence in Improving Clinical 
      Decision-Making.
PG  - e36415
LID - 10.7759/cureus.36415 [doi]
LID - e36415
AB  - This case report reflects on a delayed diagnosis for a 27-year-old woman who 
      reported chest pain and shortness of breath to the emergency department. The 
      treating clinician reflects upon how cognitive biases influenced their diagnostic 
      process and how multiple missed opportunities resulted in missteps. Using 
      artificial intelligence (AI) tools for clinical decision-making, we suggest how 
      AI could augment the clinician, and in this case, delayed diagnosis avoided. 
      Incorporating AI tools into clinical decision-making brings potential benefits, 
      including improved diagnostic accuracy and addressing human factors contributing 
      to medical errors. For example, they may support a real-time interpretation of 
      medical imaging and assist clinicians in generating a differential diagnosis in 
      ensuring that critical diagnoses are considered. However, it is vital to be aware 
      of the potential pitfalls associated with the use of AI, such as automation bias, 
      input data quality issues, limited clinician training in interpreting AI methods, 
      and the legal and ethical considerations associated with their use. The report 
      draws attention to the utility of AI clinical decision-support tools in 
      overcoming human cognitive biases. It also emphasizes the importance of 
      clinicians developing skills needed to steward the adoption of AI tools in 
      healthcare and serve as patient advocates, ensuring safe and effective use of 
      health data.
CI  - Copyright © 2023, Brown et al.
FAU - Brown, Chris
AU  - Brown C
AD  - Internal Medicine, Jersey General Hospital, St Helier, JEY.
FAU - Nazeer, Rayiz
AU  - Nazeer R
AD  - Internal Medicine, Jersey General Hospital, St Helier, JEY.
FAU - Gibbs, Austin
AU  - Gibbs A
AD  - Cardiology, Jersey General Hospital, St Helier, JEY.
FAU - Le Page, Pierre
AU  - Le Page P
AD  - Cardiology, Jersey General Hospital, St Helier, JEY.
FAU - Mitchell, Andrew Rj
AU  - Mitchell AR
AD  - Cardiology, Jersey General Hospital, St Helier, JEY.
LA  - eng
PT  - Case Reports
PT  - Journal Article
DEP - 20230320
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10115193
OTO - NOTNLM
OT  - chatgpt
OT  - clinical artificial intelligence
OT  - cognitive bias
OT  - human factors
OT  - medical errors
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/04/24 06:42
MHDA- 2023/04/24 06:43
PMCR- 2023/03/20
CRDT- 2023/04/24 03:40
PHST- 2023/03/20 00:00 [accepted]
PHST- 2023/04/24 06:43 [medline]
PHST- 2023/04/24 06:42 [pubmed]
PHST- 2023/04/24 03:40 [entrez]
PHST- 2023/03/20 00:00 [pmc-release]
AID - 10.7759/cureus.36415 [doi]
PST - epublish
SO  - Cureus. 2023 Mar 20;15(3):e36415. doi: 10.7759/cureus.36415. eCollection 2023 
      Mar.

PMID- 38817773
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250111
IS  - 2589-5141 (Electronic)
IS  - 2589-5141 (Linking)
VI  - 6
IP  - 3
DP  - 2024 May
TI  - ChatGPT-4 Can Help Hand Surgeons Communicate Better With Patients.
PG  - 436-438
LID - 10.1016/j.jhsg.2024.03.008 [doi]
AB  - The American Society for Surgery of the Hand and British Society for Surgery of 
      the Hand produce patient-focused information above the sixth-grade readability 
      recommended by the American Medical Association. To promote health equity, 
      patient-focused content should be aimed at an appropriate level of health 
      literacy. Artificial intelligence-driven large language models may be able to 
      assist hand surgery societies in improving the readability of the information 
      provided to patients. The readability was calculated for all the articles written 
      in English on the American Society for Surgery of the Hand and British Society 
      for Surgery of the Hand websites, in terms of seven of the commonest readability 
      formulas. Chat Generative Pre-Trained Transformer version 4 (ChatGPT-4) was then 
      asked to rewrite each article at a sixth-grade readability level. The readability 
      for each response was calculated and compared with the unedited articles. Chat 
      Generative Pre-Trained Transformer version 4 was able to improve the readability 
      across all chosen readability formulas and was successful in achieving a mean 
      sixth-grade readability level in terms of the Flesch Kincaid Grade Level and 
      Simple Measure of Gobbledygook calculations. It increased the mean Flesch Reading 
      Ease score, with higher scores representing more readable material. This study 
      demonstrated that ChatGPT-4 can be used to improve the readability of 
      patient-focused material in hand surgery. However, ChatGPT-4 is interested 
      primarily in sounding natural, and not in seeking truth, and hence, each response 
      must be evaluated by the surgeon to ensure that information accuracy is not being 
      sacrificed for the sake of readability by this powerful tool.
CI  - © 2024 The Authors.
FAU - Browne, Robert
AU  - Browne R
AD  - Royal College of Surgeons in Ireland, Dublin, Ireland.
FAU - Gull, Khadija
AU  - Gull K
AD  - Department of Reconstructive and Plastic Surgery, Connolly Hospital 
      Blanchardstown, Dublin, Ireland.
FAU - Hurley, Ciaran Martin
AU  - Hurley CM
AD  - Royal College of Surgeons in Ireland, Dublin, Ireland.
FAU - Sugrue, Ryan M
AU  - Sugrue RM
AD  - Royal College of Surgeons in Ireland, Dublin, Ireland.
FAU - O'Sullivan, John Barry
AU  - O'Sullivan JB
AD  - Royal College of Surgeons in Ireland, Dublin, Ireland.
AD  - Department of Reconstructive and Plastic Surgery, Connolly Hospital 
      Blanchardstown, Dublin, Ireland.
LA  - eng
PT  - Journal Article
DEP - 20240406
PL  - United States
TA  - J Hand Surg Glob Online
JT  - Journal of hand surgery global online
JID - 101759126
PMC - PMC11133925
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Communication
OT  - Health equity
OT  - Readability
COIS- No benefits in any form have been received or will be received related directly 
      to this article.
EDAT- 2024/05/31 11:42
MHDA- 2024/05/31 11:43
PMCR- 2024/04/06
CRDT- 2024/05/31 03:51
PHST- 2024/03/03 00:00 [received]
PHST- 2024/03/10 00:00 [accepted]
PHST- 2024/05/31 11:43 [medline]
PHST- 2024/05/31 11:42 [pubmed]
PHST- 2024/05/31 03:51 [entrez]
PHST- 2024/04/06 00:00 [pmc-release]
AID - S2589-5141(24)00063-X [pii]
AID - 10.1016/j.jhsg.2024.03.008 [doi]
PST - epublish
SO  - J Hand Surg Glob Online. 2024 Apr 6;6(3):436-438. doi: 
      10.1016/j.jhsg.2024.03.008. eCollection 2024 May.

PMID- 39148849
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241023
DP  - 2024 Sep 16
TI  - Foundational model aided automatic high-throughput drug screening using 
      self-controlled cohort study.
LID - 2024.08.04.24311480 [pii]
LID - 10.1101/2024.08.04.24311480 [doi]
AB  - BACKGROUND: Developing medicine from scratch to governmental authorization and 
      detecting adverse drug reactions (ADR) have barely been economical, expeditious, 
      and risk-averse investments. The availability of large-scale observational 
      healthcare databases and the popularity of large language models offer an 
      unparalleled opportunity to enable automatic high-throughput drug screening for 
      both repurposing and pharmacovigilance. OBJECTIVES: To demonstrate a general 
      workflow for automatic high-throughput drug screening with the following 
      advantages: (i) the association of various exposure on diseases can be estimated; 
      (ii) both repurposing and pharmacovigilance are integrated; (iii) accurate 
      exposure length for each prescription is parsed from clinical texts; (iv) 
      intrinsic relationship between drugs and diseases are removed jointly by 
      bioinformatic mapping and large language model - ChatGPT; (v) causal-wise 
      interpretations for incidence rate contrasts are provided. METHODS: Using a 
      self-controlled cohort study design where subjects serve as their own control 
      group, we tested the intention-to-treat association between medications on the 
      incidence of diseases. Exposure length for each prescription is determined by 
      parsing common dosages in English free text into a structured format. Exposure 
      period starts from initial prescription to treatment discontinuation. A same 
      exposure length preceding initial treatment is the control period. Clinical 
      outcomes and categories are identified using existing phenotyping algorithms. 
      Incident rate ratios (IRR) are tested using uniformly most powerful (UMP) 
      unbiased tests. RESULTS: We assessed 3,444 medications on 276 diseases on 
      6,613,198 patients from the Clinical Practice Research Datalink (CPRD), an UK 
      primary care electronic health records (EHR) spanning from 1987 to 2018. Due to 
      the built-in selection bias of self-controlled cohort studies, 
      ingredients-disease pairs confounded by deterministic medical relationships are 
      removed by existing map from RxNorm and nonexistent maps by calling ChatGPT. A 
      total of 16,901 drug-disease pairs reveals significant risk reduction, which can 
      be considered as candidates for repurposing, while a total of 11,089 pairs showed 
      significant risk increase, where drug safety might be of a concern instead. 
      CONCLUSIONS: This work developed a data-driven, nonparametric, hypothesis 
      generating, and automatic high-throughput workflow, which reveals the potential 
      of natural language processing in pharmacoepidemiology. We demonstrate the 
      paradigm to a large observational health dataset to help discover potential novel 
      therapies and adverse drug effects. The framework of this study can be extended 
      to other observational medical databases.
FAU - Xu, Shenbo
AU  - Xu S
AD  - Institute for Data, Systems, and Society, Massachusetts Institute of Technology, 
      Cambridge, MA 02142, USA.
FAU - Cobzaru, Raluca
AU  - Cobzaru R
AD  - Institute for Data, Systems, and Society, Massachusetts Institute of Technology, 
      Cambridge, MA 02142, USA.
FAU - Finkelstein, Stan N
AU  - Finkelstein SN
AD  - Institute for Data, Systems, and Society, Massachusetts Institute of Technology, 
      Cambridge, MA 02142, USA.
FAU - Welsch, Roy E
AU  - Welsch RE
AD  - Institute for Data, Systems, and Society, Massachusetts Institute of Technology, 
      Cambridge, MA 02142, USA.
FAU - Ng, Kenney
AU  - Ng K
AD  - Institute for Data, Systems, and Society, Massachusetts Institute of Technology, 
      Cambridge, MA 02142, USA.
FAU - Middleton, Lefkos
AU  - Middleton L
AD  - Institute for Data, Systems, and Society, Massachusetts Institute of Technology, 
      Cambridge, MA 02142, USA.
LA  - eng
GR  - R01 AG058063/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240916
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11326319
OTO - NOTNLM
OT  - drug repurposing
OT  - drug screening
OT  - incidence rate ratio
OT  - natural language processing
OT  - pharmacovigilance
OT  - self-controlled cohort study
EDAT- 2024/08/16 06:42
MHDA- 2024/08/16 06:43
PMCR- 2024/09/16
CRDT- 2024/08/16 04:29
PHST- 2024/08/16 06:42 [pubmed]
PHST- 2024/08/16 06:43 [medline]
PHST- 2024/08/16 04:29 [entrez]
PHST- 2024/09/16 00:00 [pmc-release]
AID - 2024.08.04.24311480 [pii]
AID - 10.1101/2024.08.04.24311480 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Sep 16:2024.08.04.24311480. doi: 
      10.1101/2024.08.04.24311480.

PMID- 38712224
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241023
DP  - 2024 Apr 27
TI  - Using Large Language Models to Annotate Complex Cases of Social Determinants of 
      Health in Longitudinal Clinical Records.
LID - 2024.04.25.24306380 [pii]
LID - 10.1101/2024.04.25.24306380 [doi]
AB  - Social Determinants of Health (SDoH) are an important part of the exposome and 
      are known to have a large impact on variation in health outcomes. In particular, 
      housing stability is known to be intricately linked to a patient's health status, 
      and pregnant women experiencing housing instability (HI) are known to have worse 
      health outcomes. Most SDoH information is stored in electronic health records 
      (EHRs) as free text (unstructured) clinical notes, which traditionally required 
      natural language processing (NLP) for automatic identification of relevant text 
      or keywords. A patient's housing status can be ambiguous or subjective, and can 
      change from note to note or within the same note, making it difficult to use 
      existing NLP solutions. New developments in NLP allow researchers to prompt LLMs 
      to perform complex, subjective annotation tasks that require reasoning that 
      previously could only be attempted by human annotators. For example, large 
      language models (LLMs) such as GPT (Generative Pre-trained Transformer) enable 
      researchers to analyze complex, unstructured data using simple prompts. We used a 
      secure platform within a large healthcare system to compare the ability of 
      GPT-3.5 and GPT-4 to identify instances of both current and past housing 
      instability, as well as general housing status, from 25,217 notes from 795 
      pregnant women. Results from these LLMs were compared with results from manual 
      annotation, a named entity recognition (NER) model, and regular expressions 
      (RegEx). We developed a chain-of-thought prompt requiring evidence and 
      justification for each note from the LLMs, to help maximize the chances of 
      finding relevant text related to HI while minimizing hallucinations and false 
      positives. Compared with GPT-3.5 and the NER model, GPT-4 had the highest 
      performance and had a much higher recall (0.924) than human annotators (0.702) in 
      identifying patients experiencing current or past housing instability, although 
      precision was lower (0.850) compared with human annotators (0.971). In most 
      cases, the evidence output by GPT-4 was similar or identical to that of human 
      annotators, and there was no evidence of hallucinations in any of the outputs 
      from GPT-4. Most cases where the annotators and GPT-4 differed were ambiguous or 
      subjective, such as "living in an apartment with too many people". We also looked 
      at GPT-4 performance on de-identified versions of the same notes and found that 
      precision improved slightly (0.936 original, 0.939 de-identified), while recall 
      dropped (0.781 original, 0.704 de-identified). This work demonstrates that, while 
      manual annotation is likely to yield slightly more accurate results overall, 
      LLMs, when compared with manual annotation, provide a scalable, cost-effective 
      solution with the advantage of greater recall. At the same time, further 
      evaluation is needed to address the risk of missed cases and bias in the initial 
      selection of housing-related notes. Additionally, while it was possible to reduce 
      confabulation, signs of unusual justifications remained. Given these factors, 
      together with changes in both LLMs and charting over time, this approach is not 
      yet appropriate for use as a fully-automated process. However, these results 
      demonstrate the potential for using LLMs for computer-assisted annotation with 
      human review, reducing cost and increasing recall. More efficient methods for 
      obtaining structured SDoH data can help accelerate inclusion of exposome 
      variables in biomedical research, and support healthcare systems in identifying 
      patients who could benefit from proactive outreach.
FAU - Ralevski, Alexandra
AU  - Ralevski A
AUID- ORCID: 0009-0000-5633-1448
AD  - Institute for Systems Biology, 401 Terry Ave N, Seattle, WA, 98109, USA.
FAU - Taiyab, Nadaa
AU  - Taiyab N
AD  - Tegria, 1255 Fourier Dr Ste 101, Madison, WI, 53717, USA.
FAU - Nossal, Michael
AU  - Nossal M
AD  - Providence St Joseph Health, 1801 Lind Ave SW Renton, WA, 98057, USA.
FAU - Mico, Lindsay
AU  - Mico L
AUID- ORCID: 0000-0003-0486-700X
AD  - Providence St Joseph Health, 1801 Lind Ave SW Renton, WA, 98057, USA.
FAU - Piekos, Samantha N
AU  - Piekos SN
AUID- ORCID: 0000-0002-8119-6724
AD  - Institute for Systems Biology, 401 Terry Ave N, Seattle, WA, 98109, USA.
FAU - Hadlock, Jennifer
AU  - Hadlock J
AUID- ORCID: 0000-0001-6103-7606
AD  - Institute for Systems Biology, 401 Terry Ave N, Seattle, WA, 98109, USA.
AD  - University of Washington, Biomedical Informatics and Medical Education, Seattle, 
      WA, USA.
LA  - eng
GR  - K99 HD112600/HD/NICHD NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240427
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11071574
COIS- Declaration of Interests All authors declare that they have no conflicts of 
      interest..
EDAT- 2024/05/07 06:42
MHDA- 2024/05/07 06:43
PMCR- 2024/05/06
CRDT- 2024/05/07 03:47
PHST- 2024/05/07 06:42 [pubmed]
PHST- 2024/05/07 06:43 [medline]
PHST- 2024/05/07 03:47 [entrez]
PHST- 2024/05/06 00:00 [pmc-release]
AID - 2024.04.25.24306380 [pii]
AID - 10.1101/2024.04.25.24306380 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Apr 27:2024.04.25.24306380. doi: 
      10.1101/2024.04.25.24306380.

PMID- 38626625
OWN - NLM
STAT- MEDLINE
DCOM- 20240505
LR  - 20240505
IS  - 1872-7123 (Electronic)
IS  - 0165-1781 (Linking)
VI  - 336
DP  - 2024 Jun
TI  - Enhancing psychiatric rehabilitation outcomes through a multimodal multitask 
      learning model based on BERT and TabNet: An approach for personalized treatment 
      and improved decision-making.
PG  - 115896
LID - S0165-1781(24)00181-1 [pii]
LID - 10.1016/j.psychres.2024.115896 [doi]
AB  - Evaluating the rehabilitation status of individuals with serious mental illnesses 
      (SMI) necessitates a comprehensive analysis of multimodal data, including 
      unstructured text records and structured diagnostic data. However, progress in 
      the effective assessment of rehabilitation status remains limited. Our study 
      develops a deep learning model integrating Bidirectional Encoder Representations 
      from Transformers (BERT) and TabNet through a late fusion strategy to enhance 
      rehabilitation prediction, including referral risk, dangerous behaviors, 
      self-awareness, and medication adherence, in patients with SMI. BERT processes 
      unstructured textual data, such as doctor's notes, whereas TabNet manages 
      structured diagnostic information. The model's interpretability function serves 
      to assist healthcare professionals in understanding the model's predictive 
      decisions, improving patient care. Our model exhibited excellent predictive 
      performance for all four tasks, with an accuracy exceeding 0.78 and an area under 
      the curve of 0.70. In addition, a series of tests proved the model's robustness, 
      fairness, and interpretability. This study combines multimodal and multitask 
      learning strategies into a model and applies it to rehabilitation assessment 
      tasks, offering a promising new tool that can be seamlessly integrated with the 
      clinical workflow to support the provision of optimized patient care.
CI  - Copyright © 2024. Published by Elsevier B.V.
FAU - Yang, Hongyi
AU  - Yang H
AD  - School of Design, Shanghai Jiao Tong University, Shanghai, China.
FAU - Zhu, Dian
AU  - Zhu D
AD  - School of Design, Shanghai Jiao Tong University, Shanghai, China.
FAU - He, Siyuan
AU  - He S
AD  - Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, 
      Shanghai, China.
FAU - Xu, Zhiqi
AU  - Xu Z
AD  - School of Design, Shanghai Jiao Tong University, Shanghai, China.
FAU - Liu, Zhao
AU  - Liu Z
AD  - School of Design, Shanghai Jiao Tong University, Shanghai, China. Electronic 
      address: hotlz@sjtu.edu.cn.
FAU - Zhang, Weibo
AU  - Zhang W
AD  - Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, 
      Shanghai, China; Shanghai Institute of Infectious Disease and Biosecurity, Fudan 
      University, Shanghai, China; Mental Health Branch, China Hospital Development 
      Institute, Shanghai Jiao Tong University, Shanghai, China. Electronic address: 
      22111020013@m.fudan.edu.cn.
FAU - Cai, Jun
AU  - Cai J
AD  - Shanghai Mental Health Center, Shanghai Jiao Tong University School of Medicine, 
      Shanghai, China; Mental Health Branch, China Hospital Development Institute, 
      Shanghai Jiao Tong University, Shanghai, China. Electronic address: 
      caijun533@163.com.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240406
PL  - Ireland
TA  - Psychiatry Res
JT  - Psychiatry research
JID - 7911385
SB  - IM
MH  - Humans
MH  - *Mental Disorders/rehabilitation
MH  - *Psychiatric Rehabilitation/methods
MH  - *Precision Medicine/methods
MH  - Deep Learning
MH  - Decision Making
MH  - Adult
MH  - Male
MH  - Clinical Decision-Making
MH  - Female
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Clinical decision support
OT  - Mental health rehabilitation
OT  - Multimodal and multitask learning
OT  - Severe mental disorders
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/04/17 00:43
MHDA- 2024/05/06 00:52
CRDT- 2024/04/16 18:06
PHST- 2023/06/26 00:00 [received]
PHST- 2024/04/03 00:00 [revised]
PHST- 2024/04/05 00:00 [accepted]
PHST- 2024/05/06 00:52 [medline]
PHST- 2024/04/17 00:43 [pubmed]
PHST- 2024/04/16 18:06 [entrez]
AID - S0165-1781(24)00181-1 [pii]
AID - 10.1016/j.psychres.2024.115896 [doi]
PST - ppublish
SO  - Psychiatry Res. 2024 Jun;336:115896. doi: 10.1016/j.psychres.2024.115896. Epub 
      2024 Apr 6.

PMID- 39936096
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250214
IS  - 2673-253X (Electronic)
IS  - 2673-253X (Linking)
VI  - 6
DP  - 2024
TI  - Voice EHR: introducing multimodal audio data for health.
PG  - 1448351
LID - 10.3389/fdgth.2024.1448351 [doi]
LID - 1448351
AB  - INTRODUCTION: Artificial intelligence (AI) models trained on audio data may have 
      the potential to rapidly perform clinical tasks, enhancing medical 
      decision-making and potentially improving outcomes through early detection. 
      Existing technologies depend on limited datasets collected with expensive 
      recording equipment in high-income countries, which challenges deployment in 
      resource-constrained, high-volume settings where audio data may have a profound 
      impact on health equity. METHODS: This report introduces a novel protocol for 
      audio data collection and a corresponding application that captures health 
      information through guided questions. RESULTS: To demonstrate the potential of 
      Voice EHR as a biomarker of health, initial experiments on data quality and 
      multiple case studies are presented in this report. Large language models (LLMs) 
      were used to compare transcribed Voice EHR data with data (from the same 
      patients) collected through conventional techniques like multiple choice 
      questions. Information contained in the Voice EHR samples was consistently rated 
      as equally or more relevant to a health evaluation. DISCUSSION: The HEAR 
      application facilitates the collection of an audio electronic health record 
      ("Voice EHR") that may contain complex biomarkers of health from conventional 
      voice/respiratory features, speech patterns, and spoken language with semantic 
      meaning and longitudinal context-potentially compensating for the typical 
      limitations of unimodal clinical datasets.
CI  - © 2025 Anibal, Huth, Li, Hazen, Daoud, Ebedes, Lam, Nguyen, Hong, Kleinman, Ost, 
      Jackson, Sprabery, Elangovan, Krishnaiah, Akst, Lina, Elyazar, Ekawati, Jansen, 
      Nduwayezu, Garcia, Plum, Brenner, Song, Ricotta, Clifton, Thwaites, Bensoussan 
      and Wood.
FAU - Anibal, James
AU  - Anibal J
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
AD  - Computational Health Informatics Lab, Oxford Institute of Biomedical Engineering, 
      University of Oxford, Oxford, United Kingdom.
FAU - Huth, Hannah
AU  - Huth H
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
FAU - Li, Ming
AU  - Li M
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
FAU - Hazen, Lindsey
AU  - Hazen L
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
FAU - Daoud, Veronica
AU  - Daoud V
AD  - Morsani College of Medicine, University of South Florida, Tampa, FL, United 
      States.
FAU - Ebedes, Dominique
AU  - Ebedes D
AD  - Morsani College of Medicine, University of South Florida, Tampa, FL, United 
      States.
FAU - Lam, Yen Minh
AU  - Lam YM
AD  - Social Science and Implementation Research Team, Oxford University Clinical 
      Research Unit, Ho Chi Minh City, Vietnam.
FAU - Nguyen, Hang
AU  - Nguyen H
AD  - Social Science and Implementation Research Team, Oxford University Clinical 
      Research Unit, Ho Chi Minh City, Vietnam.
FAU - Hong, Phuc Vo
AU  - Hong PV
AD  - Social Science and Implementation Research Team, Oxford University Clinical 
      Research Unit, Ho Chi Minh City, Vietnam.
FAU - Kleinman, Michael
AU  - Kleinman M
AD  - College of Medicine, University of Tennessee Health Sciences Center, Memphis, TN, 
      United States.
FAU - Ost, Shelley
AU  - Ost S
AD  - College of Medicine, University of Tennessee Health Sciences Center, Memphis, TN, 
      United States.
FAU - Jackson, Christopher
AU  - Jackson C
AD  - College of Medicine, University of Tennessee Health Sciences Center, Memphis, TN, 
      United States.
FAU - Sprabery, Laura
AU  - Sprabery L
AD  - College of Medicine, University of Tennessee Health Sciences Center, Memphis, TN, 
      United States.
FAU - Elangovan, Cheran
AU  - Elangovan C
AD  - College of Medicine, University of Tennessee Health Sciences Center, Memphis, TN, 
      United States.
FAU - Krishnaiah, Balaji
AU  - Krishnaiah B
AD  - College of Medicine, University of Tennessee Health Sciences Center, Memphis, TN, 
      United States.
FAU - Akst, Lee
AU  - Akst L
AD  - Johns Hopkins Voice Center, Johns Hopkins University, Baltimore, MD, United 
      States.
AD  - Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins University 
      School of Medicine, Baltimore, MD, United States.
FAU - Lina, Ioan
AU  - Lina I
AD  - Department of Otolaryngology-Head and Neck Surgery, Johns Hopkins University 
      School of Medicine, Baltimore, MD, United States.
FAU - Elyazar, Iqbal
AU  - Elyazar I
AD  - Geospatial Epidemiology Program, Oxford University Clinical Research Unit 
      Indonesia, Jakarta, Indonesia.
FAU - Ekawati, Lenny
AU  - Ekawati L
AD  - Geospatial Epidemiology Program, Oxford University Clinical Research Unit 
      Indonesia, Jakarta, Indonesia.
FAU - Jansen, Stefan
AU  - Jansen S
AD  - College of Medicine and Health Sciences, University of Rwanda, Kigali, Rwanda.
FAU - Nduwayezu, Richard
AU  - Nduwayezu R
AD  - King Faisal Hospital, Kigali, Rwanda.
FAU - Garcia, Charisse
AU  - Garcia C
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
FAU - Plum, Jeffrey
AU  - Plum J
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
FAU - Brenner, Jacqueline
AU  - Brenner J
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
FAU - Song, Miranda
AU  - Song M
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
FAU - Ricotta, Emily
AU  - Ricotta E
AD  - Epidemiology and Data Management Unit, National Institute of Allergy and 
      Infectious Diseases, Bethesda, MD, United States.
AD  - Department of Preventive Medicine and Biostatistics, Uniformed Services 
      University, Bethesda, MD, United States.
FAU - Clifton, David
AU  - Clifton D
AD  - Computational Health Informatics Lab, Oxford Institute of Biomedical Engineering, 
      University of Oxford, Oxford, United Kingdom.
FAU - Thwaites, C Louise
AU  - Thwaites CL
AD  - Morsani College of Medicine, University of South Florida, Tampa, FL, United 
      States.
FAU - Bensoussan, Yael
AU  - Bensoussan Y
AD  - Morsani College of Medicine, University of South Florida, Tampa, FL, United 
      States.
FAU - Wood, Bradford
AU  - Wood B
AD  - Center for Interventional Oncology, NIH Clinical Center, National Institutes of 
      Health, Bethesda, MD, United States.
LA  - eng
GR  - WT_/Wellcome Trust/United Kingdom
GR  - ZIA CL040015/ImNIH/Intramural NIH HHS/United States
GR  - ZID BC011242/ImNIH/Intramural NIH HHS/United States
PT  - Journal Article
DEP - 20250128
PL  - Switzerland
TA  - Front Digit Health
JT  - Frontiers in digital health
JID - 101771889
PMC - PMC11812063
OTO - NOTNLM
OT  - AI for health
OT  - large language models (LLM)
OT  - multimodal data
OT  - natural language processing
OT  - voice biomarkers
COIS- The authors declare no competing non-financial interests but the following 
      competing financial interests. NIH may own intellectual property in the field. 
      NIH and BJW receive royalties for licensed patents from Philips, unrelated to 
      this work. BW is Principal Investigator on the following CRADA's=Cooperative 
      Research & Development Agreements, between NIH and industry: Philips, Philips 
      Research, Celsion Corp, BTG Biocompatibles/Boston Scientific, Siemens, NVIDIA, 
      XACT Robotics. Promaxo (in progress). The following industry partners also 
      support research in CIO lab via equipment, personnel, devices and/or drugs: 3T 
      Technologies (devices), Exact Imaging (data), AngioDynamics (equipment), 
      AstraZeneca (pharmaceuticals, NCI CRADA), ArciTrax (devices and equipment), 
      Imactis (Equipment), Johnson & Johnson (equipment), Medtronic (equipment), 
      Theromics (Supplies), Profound Medical (equipment and supplies), QT Imaging 
      (equipment and supplies). The content of this manuscript does not necessarily 
      reﬂect the views, policies, or opinions of the Uniformed Services University of 
      the Health Sciences, the National Institutes of Health, the US Department of 
      Health and Human Services, the US Department of Defense, the U.K. National Health 
      Service, the U.K. National Institute for Health Research, the U.K. Department of 
      Health, InnoHK – ITC, or the University of Oxford. The mention of commercial 
      products, their source, or their use in connection with material reported herein 
      is not to be construed as an actual or implied endorsement of such products by 
      the U.S. government. This work was prepared by a military or civilian employee of 
      the US Government as part of the individual's official duties and therefore is in 
      the public domain and does not possess copyright protection (public domain 
      information may be freely distributed and copied; however, as a courtesy it is 
      requested that the Uniformed Services University and the author be given an 
      appropriate acknowledgement). The remaining authors declare that the research was 
      conducted in the absence of any commercial or financial relationships that could 
      be construed as a potential conflict of interest.
EDAT- 2025/02/12 06:21
MHDA- 2025/02/12 06:22
PMCR- 2025/01/28
CRDT- 2025/02/12 04:24
PHST- 2024/06/13 00:00 [received]
PHST- 2024/12/26 00:00 [accepted]
PHST- 2025/02/12 06:22 [medline]
PHST- 2025/02/12 06:21 [pubmed]
PHST- 2025/02/12 04:24 [entrez]
PHST- 2025/01/28 00:00 [pmc-release]
AID - 10.3389/fdgth.2024.1448351 [doi]
PST - epublish
SO  - Front Digit Health. 2025 Jan 28;6:1448351. doi: 10.3389/fdgth.2024.1448351. 
      eCollection 2024.

PMID- 40111287
OWN - NLM
STAT- MEDLINE
DCOM- 20250320
LR  - 20250329
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 12
DP  - 2025 Mar 20
TI  - Exploring Biases of Large Language Models in the Field of Mental Health: 
      Comparative Questionnaire Study of the Effect of Gender and Sexual Orientation in 
      Anorexia Nervosa and Bulimia Nervosa Case Vignettes.
PG  - e57986
LID - 10.2196/57986 [doi]
LID - e57986
AB  - BACKGROUND: Large language models (LLMs) are increasingly used in mental health, 
      showing promise in assessing disorders. However, concerns exist regarding their 
      accuracy, reliability, and fairness. Societal biases and underrepresentation of 
      certain populations may impact LLMs. Because LLMs are already used for clinical 
      practice, including decision support, it is important to investigate potential 
      biases to ensure a responsible use of LLMs. Anorexia nervosa (AN) and bulimia 
      nervosa (BN) show a lifetime prevalence of 1%-2%, affecting more women than men. 
      Among men, homosexual men face a higher risk of eating disorders (EDs) than 
      heterosexual men. However, men are underrepresented in ED research, and studies 
      on gender, sexual orientation, and their impact on AN and BN prevalence, 
      symptoms, and treatment outcomes remain limited. OBJECTIVES: We aimed to estimate 
      the presence and size of bias related to gender and sexual orientation produced 
      by a common LLM as well as a smaller LLM specifically trained for mental health 
      analyses, exemplified in the context of ED symptomatology and health-related 
      quality of life (HRQoL) of patients with AN or BN. METHODS: We extracted 30 case 
      vignettes (22 AN and 8 BN) from scientific papers. We adapted each vignette to 
      create 4 versions, describing a female versus male patient living with their 
      female versus male partner (2 × 2 design), yielding 120 vignettes. We then fed 
      each vignette into ChatGPT-4 and to "MentaLLaMA" based on the Large Language 
      Model Meta AI (LLaMA) architecture thrice with the instruction to evaluate them 
      by providing responses to 2 psychometric instruments, the RAND-36 questionnaire 
      assessing HRQoL and the eating disorder examination questionnaire. With the 
      resulting LLM-generated scores, we calculated multilevel models with a random 
      intercept for gender and sexual orientation (accounting for within-vignette 
      variance), nested in vignettes (accounting for between-vignette variance). 
      RESULTS: In ChatGPT-4, the multilevel model with 360 observations indicated a 
      significant association with gender for the RAND-36 mental composite summary 
      (conditional means: 12.8 for male and 15.1 for female cases; 95% CI of the effect 
      -6.15 to -0.35; P=.04) but neither with sexual orientation (P=.71) nor with an 
      interaction effect (P=.37). We found no indications for main effects of gender 
      (conditional means: 5.65 for male and 5.61 for female cases; 95% CI -0.10 to 
      0.14; P=.88), sexual orientation (conditional means: 5.63 for heterosexual and 
      5.62 for homosexual cases; 95% CI -0.14 to 0.09; P=.67), or for an interaction 
      effect (P=.61, 95% CI -0.11 to 0.19) for the eating disorder examination 
      questionnaire overall score (conditional means 5.59-5.65 95% CIs 5.45 to 5.7). 
      MentaLLaMA did not yield reliable results. CONCLUSIONS: LLM-generated mental 
      HRQoL estimates for AN and BN case vignettes may be biased by gender, with male 
      cases scoring lower despite no real-world evidence supporting this pattern. This 
      highlights the risk of bias in generative artificial intelligence in the field of 
      mental health. Understanding and mitigating biases related to gender and other 
      factors, such as ethnicity, and socioeconomic status are crucial for responsible 
      use in diagnostics and treatment recommendations.
CI  - © Rebekka Schnepper, Noa Roemmel, Rainer Schaefert, Lena Lambrecht-Walzinger, 
      Gunther Meinlschmidt. Originally published in JMIR Mental Health 
      (https://mental.jmir.org).
FAU - Schnepper, Rebekka
AU  - Schnepper R
AUID- ORCID: 0000-0002-5415-5943
AD  - Department of Psychosomatic Medicine, University Hospital and University of 
      Basel, Hebelstr. 2, Basel, 4031, Switzerland, 41 613284633.
AD  - Department of Digital and Blended Psychosomatics and Psychotherapy, Psychosomatic 
      Medicine, University Hospital and University of Basel, Basel, Switzerland.
FAU - Roemmel, Noa
AU  - Roemmel N
AUID- ORCID: 0000-0001-7118-7720
AD  - Department of Psychosomatic Medicine, University Hospital and University of 
      Basel, Hebelstr. 2, Basel, 4031, Switzerland, 41 613284633.
AD  - Department of Digital and Blended Psychosomatics and Psychotherapy, Psychosomatic 
      Medicine, University Hospital and University of Basel, Basel, Switzerland.
FAU - Schaefert, Rainer
AU  - Schaefert R
AUID- ORCID: 0000-0002-3077-7289
AD  - Department of Psychosomatic Medicine, University Hospital and University of 
      Basel, Hebelstr. 2, Basel, 4031, Switzerland, 41 613284633.
FAU - Lambrecht-Walzinger, Lena
AU  - Lambrecht-Walzinger L
AUID- ORCID: 0009-0001-4517-5205
AD  - Department of Psychosomatic Medicine, University Hospital and University of 
      Basel, Hebelstr. 2, Basel, 4031, Switzerland, 41 613284633.
FAU - Meinlschmidt, Gunther
AU  - Meinlschmidt G
AUID- ORCID: 0000-0002-3488-193X
AD  - Department of Psychosomatic Medicine, University Hospital and University of 
      Basel, Hebelstr. 2, Basel, 4031, Switzerland, 41 613284633.
AD  - Department of Digital and Blended Psychosomatics and Psychotherapy, Psychosomatic 
      Medicine, University Hospital and University of Basel, Basel, Switzerland.
AD  - Department of Clinical Psychology and Psychotherapy, University of Trier, Trier, 
      Rheinland-Pfalz, Germany.
AD  - Department of Psychology, Division of Clinical Psychology and Epidemiology, 
      University of Basel, Basel, Switzerland.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20250320
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - Male
MH  - Female
MH  - *Anorexia Nervosa/psychology/epidemiology/therapy
MH  - *Sexual Behavior/psychology
MH  - *Bulimia Nervosa/psychology/epidemiology
MH  - Adult
MH  - Surveys and Questionnaires
MH  - Young Adult
MH  - Bias
MH  - Sex Factors
MH  - Quality of Life/psychology
MH  - Language
PMC - PMC11949086
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - anorexia nervosa
OT  - artificial intelligence
OT  - bias
OT  - bulimia nervosa
OT  - eating disorders
OT  - gender
OT  - generative AI
OT  - large language model
OT  - mental health
OT  - quality of life
OT  - questionnaire
OT  - responsible AI
OT  - symptomatology
OT  - transformer
OT  - vignette
COIS- R Schaefert and GM received funding from the Stanley Thomas Johnson Stiftung and 
      Gottfried & Julia Bangerter-Rhyner-Stiftung under projects nos. PC 28/17 and PC 
      05/18, from Gesundheitsförderung Schweiz under project no. 18.191/K50001, and in 
      the context of a Horizon Europe project from the Swiss State Secretariat for 
      Education, Research and Innovation (SERI) under contract number 22.00094 and from 
      Wings Health in the context of a proof-of-concept study. GM received funding from 
      the Swiss Heart Foundation under project no. FF21101, from the Research 
      Foundation of the International Psychoanalytic University (IPU) Berlin under 
      projects nos. 5087 and 5217, from the German Federal Ministry of Education and 
      Research under budget item 68606, and from the Hasler Foundation under project 
      no. 23004. GM is a cofounder, member of the board, and shareholder of Therayou 
      AG, and active in digital and blended mental health care. GM receives royalties 
      from publishing companies as author, including a book published by Springer, and 
      an honorarium from Lundbeck for speaking at a symposium. Furthermore, GM is 
      compensated for providing psychotherapy to patients, acting as a supervisor, 
      serving as a self-experience facilitator ("Selbsterfahrungsleiter"), and for 
      postgraduate training of psychotherapists, psychosomatic specialists, and 
      supervisors. NR is a coworker at Therayou AG, active in digital and blended 
      mental health care. NR received funding from the Hasler Foundation under project 
      no. 23004 and from Wings Health AG in the context of a proof-of-concept study.
EDAT- 2025/03/20 12:34
MHDA- 2025/03/20 12:35
PMCR- 2025/03/20
CRDT- 2025/03/20 11:23
PHST- 2024/03/01 00:00 [received]
PHST- 2024/10/30 00:00 [revised]
PHST- 2024/11/24 00:00 [accepted]
PHST- 2025/03/20 12:35 [medline]
PHST- 2025/03/20 12:34 [pubmed]
PHST- 2025/03/20 11:23 [entrez]
PHST- 2025/03/20 00:00 [pmc-release]
AID - v12i1e57986 [pii]
AID - 57986 [pii]
AID - 10.2196/57986 [doi]
PST - epublish
SO  - JMIR Ment Health. 2025 Mar 20;12:e57986. doi: 10.2196/57986.

PMID- 38875562
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240618
IS  - 2817-1705 (Electronic)
IS  - 2817-1705 (Linking)
VI  - 3
DP  - 2024 Apr 23
TI  - Cost, Usability, Credibility, Fairness, Accountability, Transparency, and 
      Explainability Framework for Safe and Effective Large Language Models in Medical 
      Education: Narrative Review and Qualitative Study.
PG  - e51834
LID - 10.2196/51834 [doi]
LID - e51834
AB  - BACKGROUND: The world has witnessed increased adoption of large language models 
      (LLMs) in the last year. Although the products developed using LLMs have the 
      potential to solve accessibility and efficiency problems in health care, there is 
      a lack of available guidelines for developing LLMs for health care, especially 
      for medical education. OBJECTIVE: The aim of this study was to identify and 
      prioritize the enablers for developing successful LLMs for medical education. We 
      further evaluated the relationships among these identified enablers. METHODS: A 
      narrative review of the extant literature was first performed to identify the key 
      enablers for LLM development. We additionally gathered the opinions of LLM users 
      to determine the relative importance of these enablers using an analytical 
      hierarchy process (AHP), which is a multicriteria decision-making method. 
      Further, total interpretive structural modeling (TISM) was used to analyze the 
      perspectives of product developers and ascertain the relationships and hierarchy 
      among these enablers. Finally, the cross-impact matrix-based multiplication 
      applied to a classification (MICMAC) approach was used to determine the relative 
      driving and dependence powers of these enablers. A nonprobabilistic purposive 
      sampling approach was used for recruitment of focus groups. RESULTS: The AHP 
      demonstrated that the most important enabler for LLMs was credibility, with a 
      priority weight of 0.37, followed by accountability (0.27642) and fairness 
      (0.10572). In contrast, usability, with a priority weight of 0.04, showed 
      negligible importance. The results of TISM concurred with the findings of the 
      AHP. The only striking difference between expert perspectives and user preference 
      evaluation was that the product developers indicated that cost has the least 
      importance as a potential enabler. The MICMAC analysis suggested that cost has a 
      strong influence on other enablers. The inputs of the focus group were found to 
      be reliable, with a consistency ratio less than 0.1 (0.084). CONCLUSIONS: This 
      study is the first to identify, prioritize, and analyze the relationships of 
      enablers of effective LLMs for medical education. Based on the results of this 
      study, we developed a comprehendible prescriptive framework, named CUC-FATE 
      (Cost, Usability, Credibility, Fairness, Accountability, Transparency, and 
      Explainability), for evaluating the enablers of LLMs in medical education. The 
      study findings are useful for health care professionals, health technology 
      experts, medical technology regulators, and policy makers.
CI  - ©Majdi Quttainah, Vinaytosh Mishra, Somayya Madakam, Yotam Lurie, Shlomo Mark. 
      Originally published in JMIR AI (https://ai.jmir.org), 23.04.2024.
FAU - Quttainah, Majdi
AU  - Quttainah M
AUID- ORCID: 0000-0002-6280-1060
AD  - College of Business Administration, Kuwait University, Kuwait, Kuwait.
FAU - Mishra, Vinaytosh
AU  - Mishra V
AUID- ORCID: 0000-0002-6360-910X
AD  - College of Healthcare Management and Economics, Gulf Medical University, Ajman, 
      United Arab Emirates.
FAU - Madakam, Somayya
AU  - Madakam S
AUID- ORCID: 0000-0001-6708-2061
AD  - Information Technology, Birla Institute of Management Technology, Knowledge Park 
      - II, Greater Noida, India.
FAU - Lurie, Yotam
AU  - Lurie Y
AUID- ORCID: 0000-0002-0078-2503
AD  - Department of Management, Ben-Gurion University, Negev, Israel.
FAU - Mark, Shlomo
AU  - Mark S
AUID- ORCID: 0000-0002-2484-3542
AD  - Department of Software Engineering, Shamoon College of Engineering, Ashdod, 
      Israel.
LA  - eng
PT  - Journal Article
DEP - 20240423
PL  - Canada
TA  - JMIR AI
JT  - JMIR AI
JID - 9918645789006676
PMC - PMC11077408
OTO - NOTNLM
OT  - AHP
OT  - CUC-FATE framework
OT  - ChatGPT
OT  - LLM
OT  - TISM
OT  - adoption
OT  - analytical hierarchy process
OT  - chat generative pretrained transformer
OT  - cost, usability, credibility, fairness, accountability, transparency, and 
      explainability
OT  - data generation
OT  - development
OT  - generative language model tool
OT  - guideline
OT  - health care
OT  - health care professional
OT  - innovation
OT  - large language model
OT  - medical education
OT  - narrative review
OT  - total interpretive structural modeling
OT  - user
COIS- Conflicts of Interest: None declared.
EDAT- 2024/06/14 18:42
MHDA- 2024/06/14 18:43
PMCR- 2024/04/23
CRDT- 2024/06/14 16:54
PHST- 2023/08/16 00:00 [received]
PHST- 2024/02/03 00:00 [accepted]
PHST- 2023/12/20 00:00 [revised]
PHST- 2024/06/14 18:43 [medline]
PHST- 2024/06/14 18:42 [pubmed]
PHST- 2024/06/14 16:54 [entrez]
PHST- 2024/04/23 00:00 [pmc-release]
AID - v3i1e51834 [pii]
AID - 10.2196/51834 [doi]
PST - epublish
SO  - JMIR AI. 2024 Apr 23;3:e51834. doi: 10.2196/51834.

PMID- 38880237
OWN - NLM
STAT- MEDLINE
DCOM- 20240914
LR  - 20240914
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Linking)
VI  - 157
DP  - 2024 Sep
TI  - Assessing inclusion and representativeness on digital platforms for health 
      education: Evidence from YouTube.
PG  - 104669
LID - S1532-0464(24)00087-X [pii]
LID - 10.1016/j.jbi.2024.104669 [doi]
AB  - BACKGROUND: Studies confirm that significant biases exist in online 
      recommendation platforms, exacerbating pre-existing disparities and leading to 
      less-than-optimal outcomes for underrepresented demographics. We study issues of 
      bias in inclusion and representativeness in the context of healthcare information 
      disseminated via videos on the YouTube social media platform, a widely used 
      online channel for multi-media rich information. With one in three US adults 
      using the Internet to learn about a health concern, it is critical to assess 
      inclusivity and representativeness regarding how health information is 
      disseminated by digital platforms such as YouTube. METHODS: Leveraging methods 
      from fair machine learning (ML), natural language processing and voice and facial 
      recognition methods, we examine inclusivity and representativeness of video 
      content presenters using a large corpus of videos and their metadata on a chronic 
      condition (diabetes) extracted from the YouTube platform. Regression models are 
      used to determine whether presenter demographics impact video popularity, 
      measured by the video's average daily view count. A video that generates a higher 
      view count is considered to be more popular. RESULTS: The voice and facial 
      recognition methods predicted the gender and race of the presenter with 
      reasonable success. Gender is predicted through voice recognition 
      (accuracy = 78%, AUC = 76%), while the gender and race predictions use facial 
      recognition (accuracy = 93%, AUC = 92% and accuracy = 82%, AUC = 80%, 
      respectively). The gender of the presenter is more significant for video views 
      only when the face of the presenter is not visible while videos with male 
      presenters with no face visibility have a positive relationship with view counts. 
      Furthermore, videos with white and male presenters have a positive influence on 
      view counts while videos with female and non - white group have high view counts. 
      CONCLUSION: Presenters' demographics do have an influence on average daily view 
      count of videos viewed on social media platforms as shown by advanced voice and 
      facial recognition algorithms used for assessing inclusion and representativeness 
      of the video content. Future research can explore short videos and those at the 
      channel level because popularity of the channel name and the number of videos 
      associated with that channel do have an influence on view counts.
CI  - Copyright © 2024 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Pothugunta, Krishna
AU  - Pothugunta K
AD  - Michigan State University, East Lansing, MI, USA.
FAU - Liu, Xiao
AU  - Liu X
AD  - Arizona State University, Tempe, AZ, USA.
FAU - Susarla, Anjana
AU  - Susarla A
AD  - Michigan State University, East Lansing, MI, USA.
FAU - Padman, Rema
AU  - Padman R
AD  - Carnegie Mellon University, Pittsburgh, PA, USA.
LA  - eng
PT  - Journal Article
DEP - 20240615
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Humans
MH  - *Social Media
MH  - *Natural Language Processing
MH  - *Machine Learning
MH  - *Health Education/methods
MH  - Male
MH  - Female
MH  - Video Recording
MH  - Adult
OTO - NOTNLM
OT  - Inclusivity
OT  - Machine Learning
OT  - Natural Language Processing
OT  - Representativeness
OT  - Syntactic Analysis
OT  - Textual Analytics, Metadata
OT  - Voice and Facial Recognition
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/06/17 00:42
MHDA- 2024/09/15 14:09
CRDT- 2024/06/16 19:25
PHST- 2023/11/15 00:00 [received]
PHST- 2024/05/22 00:00 [revised]
PHST- 2024/06/05 00:00 [accepted]
PHST- 2024/09/15 14:09 [medline]
PHST- 2024/06/17 00:42 [pubmed]
PHST- 2024/06/16 19:25 [entrez]
AID - S1532-0464(24)00087-X [pii]
AID - 10.1016/j.jbi.2024.104669 [doi]
PST - ppublish
SO  - J Biomed Inform. 2024 Sep;157:104669. doi: 10.1016/j.jbi.2024.104669. Epub 2024 
      Jun 15.

PMID- 39609697
OWN - NLM
STAT- MEDLINE
DCOM- 20241129
LR  - 20241201
IS  - 1472-6963 (Electronic)
IS  - 1472-6963 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Nov 28
TI  - Perception, concerns, and practice of ChatGPT among Egyptian pharmacists: a 
      cross-sectional study in Egypt.
PG  - 1500
LID - 10.1186/s12913-024-11815-1 [doi]
LID - 1500
AB  - BACKGROUND: The emergence of large language models (LLMs) like ChatGPT attracted 
      significant attention for their potential to revolutionize pharmacy practice. 
      While artificial intelligence (AI) offers promising benefits, its integration 
      also presents unique challenges. OBJECTIVES: This cross-sectional study aimed to 
      explore the current Egyptian pharmacists' perceptions, practices, and concerns 
      regarding ChatGPT in pharmacy practice. METHODS: The study questionnaire was 
      shared with pharmacists during March and April 2024. We included pharmacists 
      licensed by the Egyptian Ministry of Health and Population. We adapted a 
      convenient sampling technique by sending the research questionnaire via emails, 
      student networks, social media (Facebook and WhatsApp), and student 
      organizations. Any pharmacist interested in participating followed a link to 
      review the study description and was asked to provide electronic consent before 
      continuing with the study. Data were analyzed using SPSS software, employing 
      Chi-square tests for categorical variables and Spearman's correlation for 
      continuous variables. Statistical significance was set at p < 0.05. RESULTS: The 
      study sample size included 428 pharmacists from the main economic regions of 
      Egypt. The results revealed a strong recognition (73.6%) among participants of 
      ChatGPT's anticipated benefits within pharmacy practice. Around two-thirds of the 
      participants (65.9%) expressed disagreement or neutrality regarding the 
      application of ChatGPT for analyzing patients' medical inputs and providing 
      individualized medical advice. Regarding factors affecting perception, we found 
      that the region is the only factor that significantly contributed to the level of 
      perception among pharmacists (P = 0.011) with Greater cairo region showing the 
      highest perception level. We found that 73.6% of participants who have heard 
      about ChatGPT reported high levels of concern. One-third of participants never 
      use ChatGPT in their pharmacy work, and 20% rarely use it. Using Spearman's 
      correlation test, there was no significant correlation between anticipated 
      advantages, concerns and practice level (P > 0.05). CONCLUSION: This study 
      reveals a generally positive perception of ChatGPT's potential benefits among 
      Egyptian pharmacists, despite existing concerns regarding accuracy, data privacy, 
      and bias. Notably, no significant associations were found between demographic 
      factors and pharmacists' perceptions, practices, or concerns. This underscores 
      the need for comprehensive educational initiatives to promote informed and 
      responsible ChatGPT utilization within pharmacy practice. Future research should 
      explore the development and implementation of tailored training programs and 
      guidelines to ensure the safe and effective integration of ChatGPT into pharmacy 
      workflows for optimal patient care.
CI  - © 2024. The Author(s).
FAU - Taha, Taha Abd-ElSalam Ashraf
AU  - Taha TAA
AD  - Faculty of Medicine, Fayoum University, Fayoum, Egypt.
FAU - Abdel-Qader, Derar H
AU  - Abdel-Qader DH
AD  - Faculty of Pharmacy and Medical Sciences, The University of Petra, Amman, Jordan.
FAU - Alamiry, Kareem R
AU  - Alamiry KR
AD  - Faculty of Pharmacy, Suez Canal University, Ismailia, Egypt.
FAU - Fadl, Zeyad A
AU  - Fadl ZA
AD  - Faculty of Medicine, Fayoum University, Fayoum, Egypt.
FAU - Alrawi, Aya
AU  - Alrawi A
AD  - Faculty of Medicine, Fayoum University, Fayoum, Egypt.
FAU - Abdelsattar, Nada K
AU  - Abdelsattar NK
AD  - Faculty of Medicine, Fayoum University, Fayoum, Egypt. nk1267@fayoum.edu.eg.
LA  - eng
PT  - Journal Article
DEP - 20241128
PL  - England
TA  - BMC Health Serv Res
JT  - BMC health services research
JID - 101088677
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - Egypt
MH  - Female
MH  - *Pharmacists/psychology
MH  - Male
MH  - Adult
MH  - Surveys and Questionnaires
MH  - Attitude of Health Personnel
MH  - Middle Aged
MH  - Social Media
PMC - PMC11605968
OTO - NOTNLM
OT  - ChatGPT
OT  - Concerns
OT  - Perception
OT  - Pharamacists
OT  - Practice
COIS- Declarations. Ethical approval and consent to participate: This study received 
      ethical approval (approval number R-535) from the Institutional Review Board at 
      the Faculty of Medicine, Fayoum University, Fayoum, Egypt. An informed consent 
      was obtained from all the participants where, members approved their 
      participation electronically before completing the questionnaire. Consent for 
      publication: Not applicable. Competing interests: The authors declare no 
      competing interests.
EDAT- 2024/11/29 05:20
MHDA- 2024/11/29 06:22
PMCR- 2024/11/28
CRDT- 2024/11/28 23:50
PHST- 2024/08/20 00:00 [received]
PHST- 2024/10/22 00:00 [accepted]
PHST- 2024/11/29 06:22 [medline]
PHST- 2024/11/29 05:20 [pubmed]
PHST- 2024/11/28 23:50 [entrez]
PHST- 2024/11/28 00:00 [pmc-release]
AID - 10.1186/s12913-024-11815-1 [pii]
AID - 11815 [pii]
AID - 10.1186/s12913-024-11815-1 [doi]
PST - epublish
SO  - BMC Health Serv Res. 2024 Nov 28;24(1):1500. doi: 10.1186/s12913-024-11815-1.

PMID- 39777163
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250108
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 7
DP  - 2024
TI  - Reader's digest version of scientific writing: comparative evaluation of 
      summarization capacity between large language models and medical students in 
      analyzing scientific writing in sleep medicine.
PG  - 1477535
LID - 10.3389/frai.2024.1477535 [doi]
LID - 1477535
AB  - INTRODUCTION: As artificial intelligence systems like large language models (LLM) 
      and natural language processing advance, the need to evaluate their utility 
      within medicine and medical education grows. As medical research publications 
      continue to grow exponentially, AI systems offer valuable opportunities to 
      condense and synthesize information, especially in underrepresented areas such as 
      Sleep Medicine. The present study aims to compare summarization capacity between 
      LLM generated summaries of sleep medicine research article abstracts, to 
      summaries generated by Medical Student (humans) and to evaluate if the research 
      content, and literary readability summarized is retained comparably. METHODS: A 
      collection of three AI-generated and human-generated summaries of sleep medicine 
      research article abstracts were shared with 19 study participants (medical 
      students) attending a sleep medicine conference. Participants were blind as to 
      which summary was human or LLM generated. After reading both human and 
      AI-generated research summaries participants completed a 1-5 Likert scale survey 
      on the readability of the extracted writings. Participants also answered 
      article-specific multiple-choice questions evaluating their comprehension of the 
      summaries, as a representation of the quality of content retained by the 
      AI-generated summaries. RESULTS: An independent sample t-test between the 
      AI-generated and human-generated summaries comprehension by study participants 
      revealed no significant difference between the Likert readability ratings 
      (p = 0.702). A chi-squared test of proportions revealed no significant 
      association (χ (2) = 1.485, p = 0.223), and a McNemar test revealed no 
      significant association between summary type and the proportion of correct 
      responses to the comprehension multiple choice questions (p = 0.289). DISCUSSION: 
      Some limitations in this study were a small number of participants and user bias. 
      Participants attended at a sleep conference and study summaries were all from 
      sleep medicine journals. Lastly the summaries did not include graphs, numbers, 
      and pictures, and thus were limited in material extraction. While the present 
      analysis did not demonstrate a significant difference among the readability and 
      content quality between the AI and human-generated summaries, limitations in the 
      present study indicate that more research is needed to objectively measure, and 
      further define strengths and weaknesses of AI models in condensing medical 
      literature into efficient and accurate summaries.
CI  - Copyright © 2024 Matalon, Spurzem, Ahsan, White, Kothari and Varma.
FAU - Matalon, Jacob
AU  - Matalon J
AD  - Medical school, California University of Science and Medicine, Colton, CA, United 
      States.
FAU - Spurzem, August
AU  - Spurzem A
AD  - Medical school, California University of Science and Medicine, Colton, CA, United 
      States.
FAU - Ahsan, Sana
AU  - Ahsan S
AD  - Medical school, California University of Science and Medicine, Colton, CA, United 
      States.
FAU - White, Elizabeth
AU  - White E
AD  - Medical school, California University of Science and Medicine, Colton, CA, United 
      States.
FAU - Kothari, Ronik
AU  - Kothari R
AD  - Medical school, California University of Science and Medicine, Colton, CA, United 
      States.
FAU - Varma, Madhu
AU  - Varma M
AD  - Department of Medical Education and Clinical Skills, California University of 
      Science and Medicine, Colton, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20241224
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC11704966
OTO - NOTNLM
OT  - artificial intelligence
OT  - large language models
OT  - medical education
OT  - medical students
OT  - natural language processing
OT  - scientific writing
OT  - sleep medicine
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2025/01/09 00:23
MHDA- 2025/01/09 00:24
PMCR- 2024/12/24
CRDT- 2025/01/08 18:02
PHST- 2024/08/08 00:00 [received]
PHST- 2024/11/28 00:00 [accepted]
PHST- 2025/01/09 00:24 [medline]
PHST- 2025/01/09 00:23 [pubmed]
PHST- 2025/01/08 18:02 [entrez]
PHST- 2024/12/24 00:00 [pmc-release]
AID - 10.3389/frai.2024.1477535 [doi]
PST - epublish
SO  - Front Artif Intell. 2024 Dec 24;7:1477535. doi: 10.3389/frai.2024.1477535. 
      eCollection 2024.

PMID- 32334546
OWN - NLM
STAT- MEDLINE
DCOM- 20210618
LR  - 20210618
IS  - 1471-2342 (Electronic)
IS  - 1471-2342 (Linking)
VI  - 20
IP  - 1
DP  - 2020 Apr 25
TI  - A quantitative MRI index for assessing the severity of hippocampal sclerosis in 
      temporal lobe epilepsy.
PG  - 42
LID - 10.1186/s12880-020-00440-z [doi]
LID - 42
AB  - BACKGROUND: Hippocampal sclerosis (HS) is associated with post-surgery outcome in 
      patients with temporal lobe epilepsy (TLE), and an automated method that 
      quantifies HS severity is still lacking. Here, we aim to propose an MRI-based HS 
      index (HSI) that integrates hippocampal volume and FLAIR signal to measure the 
      severity of HS. METHODS: Forty-two pre-surgery TLE patients were included 
      retrospectively, with T1-weighted (T1W) and FLAIR images acquired from each 
      subject. Two experienced neurosurgeons (W.D. and C.S.) and one neurologist (Q.L.) 
      rated HS severity with a four-class grading scale (normal, mild, moderate and 
      severe) based on both hippocampal volume loss and increased FLAIR signal. A 
      consensus of HS severity for each subject was made by voting among the three 
      visual rating results. Regarding the automatic quantification, the hippocampal 
      volume was quantified by AccuBrain on T1W image, and the FLAIR signal of 
      hippocampus was calculated as the mean intensity of hippocampal region on the 
      FLAIR image (normalized by the mean intensity of gray matter). To fit the HSI 
      from visual rating, we applied ordinal regression with the voted visual rating as 
      the dependent variable, and hippocampal volume and FLAIR signal as the 
      independent variables. The HSI was calculated by weighting the predicted 
      probabilities of the four-class grading scales from ordinal regression. RESULTS: 
      The intra-class correlation coefficient (single measure) of the three raters was 
      0.806. The generated HSI was significantly correlated with the visual rating 
      scales of the three raters (W.D.: 0.823, Q.L.: 0.817, C.S.: 0.717). HSI scores 
      well differentiated the different HS categories as defined by the agreed HS 
      visual rating (normal vs. mild: p < 0.001, mild vs. moderate: p < 0.001, moderate 
      vs. severe: p = 0.001). CONCLUSIONS: The proposed HSI was consistent with visual 
      rating scales from epileptologists and sensitive to HS severity. This MRI-based 
      index may help to evaluate HS severity in clinical practice. Further validations 
      are needed to associate HSI with post-surgery outcomes.
FAU - Dou, Wanchen
AU  - Dou W
AD  - Department of Neurosurgery, Peking Union Medical College Hospital, Beijing, 
      China.
FAU - Zhao, Lei
AU  - Zhao L
AD  - BrainNow Research Institute, Shenzhen, Guangdong Province, China.
FAU - Su, Changbao
AU  - Su C
AD  - Department of Neurosurgery, Peking Union Medical College Hospital, Beijing, 
      China.
FAU - Lu, Qiang
AU  - Lu Q
AD  - Department of Neurology, Peking Union Medical College Hospital, Beijing, China.
FAU - Liu, Qi
AU  - Liu Q
AD  - Department of Neurosurgery, Peking Union Medical College Hospital, Beijing, 
      China.
FAU - Guo, Jinzhu
AU  - Guo J
AD  - Department of Neurosurgery, Peking Union Medical College Hospital, Beijing, 
      China.
FAU - Zhao, Yuming
AU  - Zhao Y
AD  - Department of Neurosurgery, Peking Union Medical College Hospital, Beijing, 
      China.
FAU - Luo, Yishan
AU  - Luo Y
AD  - BrainNow Research Institute, Shenzhen, Guangdong Province, China.
FAU - Shi, Lin
AU  - Shi L
AD  - BrainNow Research Institute, Shenzhen, Guangdong Province, China.
AD  - Department of Imaging and Interventional Radiology, The Chinese University of 
      Hong Kong, Hong Kong, SAR, China.
FAU - Zhang, Yiwei
AU  - Zhang Y
AD  - Department of Radiology, Peking Union Medical College Hospital, Beijing, China.
FAU - Wang, Renzhi
AU  - Wang R
AD  - Department of Neurosurgery, Peking Union Medical College Hospital, Beijing, 
      China. wangrz@126.com.
FAU - Feng, Feng
AU  - Feng F
AD  - Department of Radiology, Peking Union Medical College Hospital, Beijing, China.
LA  - eng
GR  - 2016-I2M-1-004, Neurology, Qi Xu/CAMS Innovation Fund for Medical Sciences 
      (CIFMS)/International
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20200425
PL  - England
TA  - BMC Med Imaging
JT  - BMC medical imaging
JID - 100968553
SB  - IM
MH  - Adolescent
MH  - Adult
MH  - Epilepsy, Temporal Lobe/complications/*surgery
MH  - Female
MH  - Hippocampus/diagnostic imaging/*pathology
MH  - Humans
MH  - Image Processing, Computer-Assisted/*methods
MH  - Magnetic Resonance Imaging
MH  - Male
MH  - Middle Aged
MH  - Observer Variation
MH  - Retrospective Studies
MH  - Sclerosis/*diagnostic imaging/etiology/pathology
MH  - Severity of Illness Index
MH  - Young Adult
PMC - PMC7183666
OTO - NOTNLM
OT  - Grading scale
OT  - HSI
OT  - Hippocampal sclerosis
OT  - Quantitative MRI
OT  - Temporal lobe epilepsy
COIS- L.S. is the director of BrainNow Medical Technology Limited. L.Z. and Y.L. are 
      employees of BrainNow Medical Technology Limited. All other authors report no 
      financial relationships with commercial interests.
EDAT- 2020/04/27 06:00
MHDA- 2021/06/22 06:00
PMCR- 2020/04/25
CRDT- 2020/04/27 06:00
PHST- 2019/11/02 00:00 [received]
PHST- 2020/04/06 00:00 [accepted]
PHST- 2020/04/27 06:00 [entrez]
PHST- 2020/04/27 06:00 [pubmed]
PHST- 2021/06/22 06:00 [medline]
PHST- 2020/04/25 00:00 [pmc-release]
AID - 10.1186/s12880-020-00440-z [pii]
AID - 440 [pii]
AID - 10.1186/s12880-020-00440-z [doi]
PST - epublish
SO  - BMC Med Imaging. 2020 Apr 25;20(1):42. doi: 10.1186/s12880-020-00440-z.

PMID- 38199323
OWN - NLM
STAT- MEDLINE
DCOM- 20240609
LR  - 20240814
IS  - 1931-3543 (Electronic)
IS  - 0012-3692 (Print)
IS  - 0012-3692 (Linking)
VI  - 165
IP  - 6
DP  - 2024 Jun
TI  - Measuring Implicit Bias in ICU Notes Using Word-Embedding Neural Network Models.
PG  - 1481-1490
LID - S0012-3692(24)00007-2 [pii]
LID - 10.1016/j.chest.2023.12.031 [doi]
AB  - BACKGROUND: Language in nonmedical data sets is known to transmit human-like 
      biases when used in natural language processing (NLP) algorithms that can 
      reinforce disparities. It is unclear if NLP algorithms of medical notes could 
      lead to similar transmissions of biases. RESEARCH QUESTION: Can we identify 
      implicit bias in clinical notes, and are biases stable across time and geography? 
      STUDY DESIGN AND METHODS: To determine whether different racial and ethnic 
      descriptors are similar contextually to stigmatizing language in ICU notes and 
      whether these relationships are stable across time and geography, we identified 
      notes on critically ill adults admitted to the University of California, San 
      Francisco (UCSF), from 2012 through 2022 and to Beth Israel Deaconess Hospital 
      (BIDMC) from 2001 through 2012. Because word meaning is derived largely from 
      context, we trained unsupervised word-embedding algorithms to measure the 
      similarity (cosine similarity) quantitatively of the context between a racial or 
      ethnic descriptor (eg, African-American) and a stigmatizing target word (eg, 
      nonco-operative) or group of words (violence, passivity, noncompliance, 
      nonadherence). RESULTS: In UCSF notes, Black descriptors were less likely to be 
      similar contextually to violent words compared with White descriptors. 
      Contrastingly, in BIDMC notes, Black descriptors were more likely to be similar 
      contextually to violent words compared with White descriptors. The UCSF data 
      set also showed that Black descriptors were more similar contextually to 
      passivity and noncompliance words compared with Latinx descriptors. 
      INTERPRETATION: Implicit bias is identifiable in ICU notes. Racial and ethnic 
      group descriptors carry different contextual relationships to stigmatizing words, 
      depending on when and where notes were written. Because NLP models seem able to 
      transmit implicit bias from training data, use of NLP algorithms in clinical 
      prediction could reinforce disparities. Active debiasing strategies may be 
      necessary to achieve algorithmic fairness when using language models in clinical 
      research.
CI  - Published by Elsevier Inc.
FAU - Cobert, Julien
AU  - Cobert J
AD  - Anesthesia Service, San Francisco VA Health Care System, University of 
      California, San Francisco, San Francisco, CA; Department of Anesthesia and 
      Perioperative Care, University of California, San Francisco, San Francisco, CA. 
      Electronic address: Julien.cobert@ucsf.edu.
FAU - Mills, Hunter
AU  - Mills H
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA.
FAU - Lee, Albert
AU  - Lee A
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA.
FAU - Gologorskaya, Oksana
AU  - Gologorskaya O
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA.
FAU - Espejo, Edie
AU  - Espejo E
AD  - Division of Geriatrics, University of California, San Francisco, San Francisco, 
      CA.
FAU - Jeon, Sun Young
AU  - Jeon SY
AD  - Division of Geriatrics, University of California, San Francisco, San Francisco, 
      CA.
FAU - Boscardin, W John
AU  - Boscardin WJ
AD  - Division of Geriatrics, University of California, San Francisco, San Francisco, 
      CA.
FAU - Heintz, Timothy A
AU  - Heintz TA
AD  - School of Medicine, University of California, San Diego, San Diego, CA.
FAU - Kennedy, Christopher J
AU  - Kennedy CJ
AD  - Department of Psychiatry, Harvard Medical School, Boston, MA; Center for 
      Precision Psychiatry, Massachusetts General Hospital, Boston, MA.
FAU - Ashana, Deepshikha C
AU  - Ashana DC
AD  - Division of Pulmonary, Allergy, and Critical Care Medicine, Duke University, 
      Durham, NC.
FAU - Chapman, Allyson Cook
AU  - Chapman AC
AD  - Department of Medicine, the Division of Critical Care and Palliative Medicine, 
      University of California, San Francisco, San Francisco, CA; Department of 
      Surgery, University of California, San Francisco, San Francisco, CA.
FAU - Raghunathan, Karthik
AU  - Raghunathan K
AD  - Department of Anesthesia and Perioperative Care, Duke University, Durham, NC.
FAU - Smith, Alex K
AU  - Smith AK
AD  - Department of Geriatrics, Palliative, and Extended Care, Veterans Affairs Medical 
      Center, University of California, San Francisco, San Francisco, CA; Division of 
      Geriatrics, University of California, San Francisco, San Francisco, CA.
FAU - Lee, Sei J
AU  - Lee SJ
AD  - Division of Geriatrics, University of California, San Francisco, San Francisco, 
      CA.
LA  - eng
GR  - P30 AG044281/AG/NIA NIH HHS/United States
PT  - Journal Article
DEP - 20240108
PL  - United States
TA  - Chest
JT  - Chest
JID - 0231335
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - *Intensive Care Units
MH  - *Neural Networks, Computer
MH  - Algorithms
MH  - Critical Illness/psychology
MH  - Bias
MH  - Electronic Health Records
MH  - Male
MH  - Female
PMC - PMC11317817
OTO - NOTNLM
OT  - critical care
OT  - inequity
OT  - linguistics
OT  - machine learning
OT  - natural language processing
COIS- Financial/Nonfinancial Disclosures None declared.
EDAT- 2024/01/11 00:42
MHDA- 2024/06/10 00:42
PMCR- 2024/01/08
CRDT- 2024/01/10 20:15
PHST- 2023/07/24 00:00 [received]
PHST- 2023/12/12 00:00 [revised]
PHST- 2023/12/29 00:00 [accepted]
PHST- 2024/06/10 00:42 [medline]
PHST- 2024/01/11 00:42 [pubmed]
PHST- 2024/01/10 20:15 [entrez]
PHST- 2024/01/08 00:00 [pmc-release]
AID - S0012-3692(24)00007-2 [pii]
AID - 10.1016/j.chest.2023.12.031 [doi]
PST - ppublish
SO  - Chest. 2024 Jun;165(6):1481-1490. doi: 10.1016/j.chest.2023.12.031. Epub 2024 Jan 
      8.

PMID- 38472350
OWN - NLM
STAT- Publisher
LR  - 20240313
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
DP  - 2024 Mar 12
TI  - Artificial Intelligence in Plastic Surgery: Analysis of Applications, 
      Perspectives, and Psychological Impact.
LID - 10.1007/s00266-024-03988-1 [doi]
AB  - Artificial intelligence (AI) is emerging as a promising tool in the field of 
      plastic surgery, offering a wide array of applications that enhance surgical 
      outcomes, patient satisfaction, and overall efficiency. This paper explores the 
      utilization of AI, highlighting its various advantages and potential drawbacks. 
      AI-driven technologies such as computer vision, machine learning algorithms, and 
      robotic assistance facilitate preoperative planning, intraoperative guidance, and 
      postoperative monitoring. These advancements enable precise anatomical 
      measurements, personalized treatment plans, and real-time feedback during 
      surgery, leading to improved accuracy and safety. Furthermore, AI-powered image 
      analysis aids in facial recognition, skin texture assessment, and simulation of 
      surgical outcomes, enabling enhanced patient consultations and predictive 
      modeling. However, the integration of AI in plastic surgery also presents 
      challenges, including ethical concerns, data privacy, algorithm biases, and the 
      need for comprehensive training among healthcare professionals. Additionally, the 
      reliance on AI systems may potentially lead to over-reliance or reduced surgeon 
      autonomy, necessitating careful validation and continuous refinement of these 
      technologies. Despite these challenges, the synergistic collaboration between AI 
      and plastic surgery holds great promise in advancing clinical practice, fostering 
      innovation, and ultimately benefiting patients through optimized esthetic and 
      reconstructive outcomes.Level of Evidence V This journal requires that authors 
      assign a level of evidence to each article. For a full description of these 
      Evidence-Based Medicine ratings, please refer to the Table of Contents or the 
      online Instructions to Authors https://www.springer.com/00266 .
CI  - © 2024. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Barone, Mauro
AU  - Barone M
AD  - Fondazione Policlinico Universitario Campus Bio-Medico, Via Alvaro del Portillo, 
      200, 00128, Rome, Italy.
FAU - De Bernardis, Riccardo
AU  - De Bernardis R
AUID- ORCID: 0009-0006-6116-7711
AD  - Fondazione Policlinico Universitario Campus Bio-Medico, Via Alvaro del Portillo, 
      200, 00128, Rome, Italy. riccardo.debernardis@unicampus.it.
FAU - Persichetti, Paolo
AU  - Persichetti P
AD  - Fondazione Policlinico Universitario Campus Bio-Medico, Via Alvaro del Portillo, 
      200, 00128, Rome, Italy.
LA  - eng
PT  - Letter
DEP - 20240312
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Chatgpt
OT  - Esthetic surgery
OT  - Ethic
OT  - Plastic surgery
EDAT- 2024/03/13 06:46
MHDA- 2024/03/13 06:46
CRDT- 2024/03/13 00:56
PHST- 2024/02/17 00:00 [received]
PHST- 2024/02/29 00:00 [accepted]
PHST- 2024/03/13 06:46 [medline]
PHST- 2024/03/13 06:46 [pubmed]
PHST- 2024/03/13 00:56 [entrez]
AID - 10.1007/s00266-024-03988-1 [pii]
AID - 10.1007/s00266-024-03988-1 [doi]
PST - aheadofprint
SO  - Aesthetic Plast Surg. 2024 Mar 12. doi: 10.1007/s00266-024-03988-1.

PMID- 38523587
OWN - NLM
STAT- MEDLINE
DCOM- 20240507
LR  - 20240507
IS  - 1467-8519 (Electronic)
IS  - 0269-9702 (Linking)
VI  - 38
IP  - 5
DP  - 2024 Jun
TI  - A paradigm shift?-On the ethics of medical large language models.
PG  - 383-390
LID - 10.1111/bioe.13283 [doi]
AB  - After a wave of breakthroughs in image-based medical diagnostics and risk 
      prediction models, machine learning (ML) has turned into a normal science. 
      However, prominent researchers are claiming that another paradigm shift in 
      medical ML is imminent-due to most recent staggering successes of large language 
      models-from single-purpose applications toward generalist models, driven by 
      natural language. This article investigates the implications of this paradigm 
      shift for the ethical debate. Focusing on issues like trust, transparency, 
      threats of patient autonomy, responsibility issues in the collaboration of 
      clinicians and ML models, fairness, and privacy, it will be argued that the main 
      problems will be continuous with the current debate. However, due to functioning 
      of large language models, the complexity of all these problems increases. In 
      addition, the article discusses some profound challenges for the clinical 
      evaluation of large language models and threats to the reproducibility and 
      replicability of studies about large language models in medicine due to corporate 
      interests.
CI  - © 2024 The Authors. Bioethics published by John Wiley & Sons Ltd.
FAU - Grote, Thomas
AU  - Grote T
AUID- ORCID: 0000-0002-9832-6046
AD  - Cluster of Excellence: "Machine Learning: New Perspectives for Science", 
      University of Tübingen, Tübingen, Germany.
FAU - Berens, Philipp
AU  - Berens P
AD  - Hertie Institute for AI in Brain Health & Tübingen AI Center, Tübingen, Germany.
LA  - eng
GR  - Deutsche Forschungsgemeinschaft/
GR  - Gemeinnützige Hertie-Stiftung/
GR  - Carl-Zeiss-Stiftung/
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240325
PL  - England
TA  - Bioethics
JT  - Bioethics
JID - 8704792
SB  - IM
MH  - Humans
MH  - *Machine Learning/ethics
MH  - Personal Autonomy
MH  - Trust
MH  - Privacy
MH  - Reproducibility of Results
MH  - Ethics, Medical
OTO - NOTNLM
OT  - autonomy
OT  - clinical evaluation
OT  - machine learning
OT  - transparency
OT  - trust
EDAT- 2024/03/25 06:43
MHDA- 2024/05/07 13:46
CRDT- 2024/03/25 04:03
PHST- 2024/01/24 00:00 [revised]
PHST- 2023/08/04 00:00 [received]
PHST- 2024/02/16 00:00 [accepted]
PHST- 2024/05/07 13:46 [medline]
PHST- 2024/03/25 06:43 [pubmed]
PHST- 2024/03/25 04:03 [entrez]
AID - 10.1111/bioe.13283 [doi]
PST - ppublish
SO  - Bioethics. 2024 Jun;38(5):383-390. doi: 10.1111/bioe.13283. Epub 2024 Mar 25.

PMID- 39176734
OWN - NLM
STAT- MEDLINE
DCOM- 20240823
LR  - 20250223
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Print)
IS  - 0926-9630 (Linking)
VI  - 316
DP  - 2024 Aug 22
TI  - Using Natural Language Processing on Expert Panel Discussions to Gain Insights 
      for Recruitment, Retention and Intervention Adherence for Online Social Support 
      Interventions on a Stage II-III Clinical Trial Among Hispanic and African 
      American Dementia Caregivers.
PG  - 305-309
LID - 10.3233/SHTI240405 [doi]
AB  - We applied natural language processing (NLP) to a corpus extracted from 4 hours 
      of expert panel discussion transcripts to determine the sustainability of a Stage 
      II-III clinical trial of online social support interventions for Hispanic and 
      African American dementia caregivers. Prominent topics included Technology/hard 
      to reach populations, Training younger populations, Building trust, Privacy and 
      security issues, Simplification of screening questions and recruitment 
      procedures, Understanding participants' needs, Planning strategies and logistics, 
      Potential recruitment places, Adjusting intervention size downwards to engage 
      elderly participants, Targeting different generations, Internet-based 
      interventions by age range, and Providing step-by-step instructions and an 
      overview of the entire research process during recruitment. The application of 
      NLP to qualitative data on a dementia caregiving clinical trial provides useful 
      insights for recruitment, retention, and adherence to guidelines for such 
      interventions serving Hispanic and African American dementia caregivers.
FAU - Odlum, Michelle
AU  - Odlum M
AD  - School of Nursing, Columbia University Medical Center, New York, NY, USA.
FAU - Moon, Soyoung
AU  - Moon S
AD  - General Medicine, Department of Medicine, Columbia University, New York, USA.
FAU - Broadwell, Peter
AU  - Broadwell P
AD  - Center for Interdisciplinary Digital Research, Stanford University, Stanford, CA, 
      USA.
FAU - Huang, Niya
AU  - Huang N
AD  - University of California in San Francisco, San Francisco, CA, USA.
FAU - Sun, Frederick
AU  - Sun F
AD  - Department of Rehabilitation Medicine, Columbia University, NewYork, NY, USA.
FAU - Tipani, Dante
AU  - Tipani D
AD  - CaringKind, New York, NY, USA.
FAU - Davis, Nicole
AU  - Davis N
AD  - School of Nursing, Clemson University, Clemson, SC, USA.
FAU - Kim, Milea
AU  - Kim M
AD  - NewYork-Presbyterian Hospital, New York, NY, USA.
FAU - Yoon, Sunmoo
AU  - Yoon S
AD  - General Medicine, Department of Medicine, Columbia University, New York, USA.
LA  - eng
GR  - R01 AG060929/AG/NIA NIH HHS/United States
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - IM
MH  - *Caregivers
MH  - Humans
MH  - *Black or African American
MH  - *Hispanic or Latino
MH  - *Natural Language Processing
MH  - *Dementia
MH  - *Social Support
MH  - *Patient Selection
MH  - Internet
MH  - Aged
PMC - PMC11346578
MID - NIHMS1993089
OTO - NOTNLM
OT  - Twitter
OT  - dementia caregiving
OT  - health disparity
OT  - natural language processing
EDAT- 2024/08/23 06:41
MHDA- 2024/08/23 06:42
PMCR- 2025/02/22
CRDT- 2024/08/23 05:04
PHST- 2024/08/23 06:42 [medline]
PHST- 2024/08/23 06:41 [pubmed]
PHST- 2024/08/23 05:04 [entrez]
PHST- 2025/02/22 00:00 [pmc-release]
AID - SHTI240405 [pii]
AID - 10.3233/SHTI240405 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2024 Aug 22;316:305-309. doi: 10.3233/SHTI240405.

PMID- 39549561
OWN - NLM
STAT- MEDLINE
DCOM- 20241206
LR  - 20241206
IS  - 1873-4499 (Electronic)
IS  - 0899-7071 (Linking)
VI  - 117
DP  - 2025 Jan
TI  - Exploring the accuracy of embedded ChatGPT-4 and ChatGPT-4o in generating BI-RADS 
      scores: a pilot study in radiologic clinical support.
PG  - 110335
LID - S0899-7071(24)00265-1 [pii]
LID - 10.1016/j.clinimag.2024.110335 [doi]
AB  - This study evaluates the accuracy of ChatGPT-4 and ChatGPT-4o in generating 
      Breast Imaging Reporting and Data System (BI-RADS) scores from radiographic 
      images. We tested both models using 77 breast cancer images from radiopaedia.org, 
      including mammograms and ultrasounds. Images were analyzed in separate sessions 
      to avoid bias. ChatGPT-4 and ChatGPT-4o achieved a 66.2 % accuracy across all 
      BI-RADS cases. Performance was highest in BI-RADS 5 cases, with ChatGPT-4 and 
      ChatGPT4o scoring 84.4 % and 88.9 %, respectively. However, both models struggled 
      with BIRADS 1-3 cases, often assigning higher severity ratings. This study 
      highlights the limitations of current LLMs in accurately grading these images and 
      emphasizes the need for further research in these technologies before clinical 
      integration.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Nguyen, Dan
AU  - Nguyen D
AD  - University of Massachusetts Chan Medical School, Worcester, MA, United States.
FAU - Rao, Arya
AU  - Rao A
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Mass General Brigham, Boston, MA, United States; 
      Harvard Medical School, Boston, MA, United States; Department of Radiology, Mass 
      General Brigham, Boston, MA, United States.
FAU - Mazumder, Aneesh
AU  - Mazumder A
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Mass General Brigham, Boston, MA, United States.
FAU - Succi, Marc D
AU  - Succi MD
AD  - Medically Engineered Solutions in Healthcare Incubator, Innovation in Operations 
      Research Center (MESH IO), Mass General Brigham, Boston, MA, United States; 
      Harvard Medical School, Boston, MA, United States; Department of Radiology, Mass 
      General Brigham, Boston, MA, United States; Mass General Brigham Innovation, Mass 
      General Brigham, Boston, MA, United States. Electronic address: 
      msucci@mgh.harvard.edu.
LA  - eng
PT  - Journal Article
DEP - 20241030
PL  - United States
TA  - Clin Imaging
JT  - Clinical imaging
JID - 8911831
SB  - IM
MH  - Humans
MH  - Pilot Projects
MH  - Female
MH  - *Breast Neoplasms/diagnostic imaging
MH  - *Mammography/methods
MH  - Ultrasonography, Mammary/methods
MH  - Reproducibility of Results
MH  - Radiology Information Systems
MH  - Breast/diagnostic imaging
OTO - NOTNLM
OT  - AI
OT  - BIRADS
OT  - Breast imaging
OT  - Machine learning
OT  - Mammography
OT  - Radiology
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/11/17 00:29
MHDA- 2024/12/07 14:47
CRDT- 2024/11/16 18:08
PHST- 2024/08/14 00:00 [received]
PHST- 2024/10/17 00:00 [revised]
PHST- 2024/10/24 00:00 [accepted]
PHST- 2024/12/07 14:47 [medline]
PHST- 2024/11/17 00:29 [pubmed]
PHST- 2024/11/16 18:08 [entrez]
AID - S0899-7071(24)00265-1 [pii]
AID - 10.1016/j.clinimag.2024.110335 [doi]
PST - ppublish
SO  - Clin Imaging. 2025 Jan;117:110335. doi: 10.1016/j.clinimag.2024.110335. Epub 2024 
      Oct 30.

PMID- 32387393
OWN - NLM
STAT- MEDLINE
DCOM- 20210728
LR  - 20210728
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Linking)
VI  - 107
DP  - 2020 Jul
TI  - Maximizing the use of social and behavioural information from secondary care 
      mental health electronic health records.
PG  - 103429
LID - S1532-0464(20)30057-5 [pii]
LID - 10.1016/j.jbi.2020.103429 [doi]
AB  - PURPOSE: The contribution of social and behavioural factors in the development of 
      mental health conditions and treatment effectiveness is widely supported, yet 
      there are weak population level data sources on social and behavioural 
      determinants of mental health. Enriching these data gaps will be crucial to 
      accelerating precision medicine. Some have suggested the broader use of 
      electronic health records (EHR) as a source of non-clinical determinants, 
      although social and behavioural information are not systematically collected 
      metrics in EHRs, internationally. OBJECTIVE: In this commentary, we highlight the 
      nature and quality of key available structured and unstructured social and 
      behavioural data using a case example of value counts from secondary mental 
      health data available in the UK from the UK Clinical Record Interactive Search 
      (CRIS) database; highlight the methodological challenges in the use of such data; 
      and possible solutions and opportunities involving the use of natural language 
      processing (NLP) of unstructured EHR text. CONCLUSIONS: Most structured 
      non-clinical data fields within secondary care mental health EHR data have too 
      much missing data for adequate use. The utility of other non-clinical fields 
      reported semi-consistently (e.g., ethnicity and marital status) is entirely 
      dependent on treating them appropriately in analyses, quantifying the many 
      reasons behind missingness in consideration of selection biases. Advancements in 
      NLP offer new opportunities in the exploitation of unstructured text from 
      secondary care EHR data particularly given that clinical notes and attachments 
      are available in large volumes of patients and are more routinely completed by 
      clinicians. Tackling ways to re-use, harmonize, and improve our existing and 
      future secondary care mental health data, leveraging advanced analytics such as 
      NLP is worth the effort in an attempt to fill the data gap on social and 
      behavioural contributors to mental health conditions and will be necessary to 
      fulfill all of the domains needed to inform personalized interventions.
CI  - Copyright © 2020 Elsevier Inc. All rights reserved.
FAU - Goodday, S M
AU  - Goodday SM
AD  - Department of Psychiatry, University of Oxford, United Kingdom; 4youandme, 
      Seattle, WA, USA. Electronic address: Sarah.goodday@psych.ox.ac.uk.
FAU - Kormilitzin, A
AU  - Kormilitzin A
AD  - Department of Psychiatry, University of Oxford, United Kingdom.
FAU - Vaci, N
AU  - Vaci N
AD  - Department of Psychiatry, University of Oxford, United Kingdom.
FAU - Liu, Q
AU  - Liu Q
AD  - Department of Psychiatry, University of Oxford, United Kingdom.
FAU - Cipriani, A
AU  - Cipriani A
AD  - Department of Psychiatry, University of Oxford, United Kingdom.
FAU - Smith, T
AU  - Smith T
AD  - Oxford Health NHS Foundation Trust, United Kingdom.
FAU - Nevado-Holgado, A
AU  - Nevado-Holgado A
AD  - Department of Psychiatry, University of Oxford, United Kingdom.
LA  - eng
GR  - MC_PC_17215/MRC_/Medical Research Council/United Kingdom
GR  - RP-2017-08-ST2-006/DH_/Department of Health/United Kingdom
GR  - BRC-1215-20005/DH_/Department of Health/United Kingdom
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20200505
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Databases, Factual
MH  - *Electronic Health Records
MH  - Humans
MH  - *Mental Health
MH  - Natural Language Processing
MH  - Secondary Care
OTO - NOTNLM
OT  - Data quality
OT  - Electronic health records
OT  - Mental health
OT  - Natural language processing
OT  - Precision medicine
OT  - Selection bias
COIS- Declaration of Competing Interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2020/05/11 06:00
MHDA- 2021/07/29 06:00
CRDT- 2020/05/11 06:00
PHST- 2020/01/06 00:00 [received]
PHST- 2020/04/15 00:00 [revised]
PHST- 2020/04/19 00:00 [accepted]
PHST- 2020/05/11 06:00 [pubmed]
PHST- 2021/07/29 06:00 [medline]
PHST- 2020/05/11 06:00 [entrez]
AID - S1532-0464(20)30057-5 [pii]
AID - 10.1016/j.jbi.2020.103429 [doi]
PST - ppublish
SO  - J Biomed Inform. 2020 Jul;107:103429. doi: 10.1016/j.jbi.2020.103429. Epub 2020 
      May 5.

PMID- 40114712
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250322
IS  - 2666-9145 (Electronic)
IS  - 2666-9145 (Linking)
VI  - 5
IP  - 3
DP  - 2025 May-Jun
TI  - Large Language Models in Ophthalmology: A Review of Publications from Top 
      Ophthalmology Journals.
PG  - 100681
LID - 10.1016/j.xops.2024.100681 [doi]
LID - 100681
AB  - PURPOSE: To review and evaluate the current literature on the application and 
      impact of large language models (LLMs) in the field of ophthalmology, focusing on 
      studies published in high-ranking ophthalmology journals. DESIGN: This is a 
      retrospective review of published articles. PARTICIPANTS: This study did not 
      involve human participation. METHODS: Articles published in the first quartile 
      (Q1) of ophthalmology journals on Scimago Journal & Country Rank discussing 
      different LLMs up to June 7, 2024, were reviewed, parsed, and analyzed. MAIN 
      OUTCOME MEASURES: All available articles were parsed and analyzed, which included 
      the article and author characteristics and data regarding the LLM used and its 
      applications, focusing on its use in medical education, clinical assistance, 
      research, and patient education. RESULTS: There were 35 Q1-ranked journals 
      identified, 19 of which contained articles discussing LLMs, with 101 articles 
      eligible for review. One-third were original investigations (32%; 32/101), with 
      an average of 5.3 authors per article. The United States (50.4%; 51/101) was the 
      most represented country, followed by the United Kingdom (25.7%; 26/101) and 
      Canada (16.8%; 17/101). ChatGPT was the most used LLM among the studies, with 
      different versions discussed and compared. Large language model applications were 
      discussed relevant to their implications in medical education, clinical 
      assistance, research, and patient education. CONCLUSIONS: The numerous 
      publications on the use of LLM in ophthalmology can provide valuable insights for 
      stakeholders and consumers of these applications. Large language models present 
      significant opportunities for advancement in ophthalmology, particularly in team 
      science, education, clinical assistance, and research. Although LLMs show 
      promise, they also show challenges such as performance inconsistencies, bias, and 
      ethical concerns. The study emphasizes the need for ongoing artificial 
      intelligence improvement, ethical guidelines, and multidisciplinary 
      collaboration. FINANCIAL DISCLOSURES: The author(s) have no proprietary or 
      commercial interest in any materials discussed in this article.
CI  - © 2024 by the American Academy of Ophthalmologyé.
FAU - Agnihotri, Akshay Prashant
AU  - Agnihotri AP
AD  - Jacobs Retina Center, University of California, San Diego, La Jolla, California.
AD  - Viterbi Family Department of Ophthalmology and Shiley Eye Institute, University 
      of California, San Diego, La Jolla, California.
AD  - Retina Care Hospital, Nagpur, India.
FAU - Nagel, Ines Doris
AU  - Nagel ID
AD  - Jacobs Retina Center, University of California, San Diego, La Jolla, California.
AD  - Viterbi Family Department of Ophthalmology and Shiley Eye Institute, University 
      of California, San Diego, La Jolla, California.
AD  - Department of Ophthalmology, University Hospital Augsburg, Augsburg, Germany.
FAU - Artiaga, Jose Carlo M
AU  - Artiaga JCM
AD  - Department of Ophthalmology and Visual Sciences, Philippine General Hospital, 
      University of the Philippines Manila, Manila City, Philippines.
AD  - International Eye Institute, St. Luke's Medical Center Global City, Taguig City, 
      Philippines.
FAU - Guevarra, Ma Carmela B
AU  - Guevarra MCB
AD  - Department of Ophthalmology, Massachusetts Eye and Ear, Boston, Massachusetts.
AD  - Harvard Medical School, Department of Ophthalmology, Boston, Massachusetts.
FAU - Sosuan, George Michael N
AU  - Sosuan GMN
AD  - Department of Ophthalmology and Visual Sciences, Philippine General Hospital, 
      University of the Philippines Manila, Manila City, Philippines.
FAU - Kalaw, Fritz Gerald P
AU  - Kalaw FGP
AD  - Jacobs Retina Center, University of California, San Diego, La Jolla, California.
AD  - Viterbi Family Department of Ophthalmology and Shiley Eye Institute, University 
      of California, San Diego, La Jolla, California.
AD  - Division of Ophthalmology Informatics and Data Science, Viterbi Family Department 
      of Ophthalmology and Shiley Eye Institute, University of California, San Diego, 
      La Jolla, California.
LA  - eng
PT  - Journal Article
DEP - 20241217
PL  - Netherlands
TA  - Ophthalmol Sci
JT  - Ophthalmology science
JID - 9918230896206676
PMC - PMC11925577
OTO - NOTNLM
OT  - ChatGPT
OT  - Chatbots
OT  - Generative artificial intelligence
OT  - Large language models
EDAT- 2025/03/21 11:17
MHDA- 2025/03/21 11:18
PMCR- 2024/12/17
CRDT- 2025/03/21 04:54
PHST- 2024/08/19 00:00 [received]
PHST- 2024/11/27 00:00 [revised]
PHST- 2024/12/13 00:00 [accepted]
PHST- 2025/03/21 11:18 [medline]
PHST- 2025/03/21 11:17 [pubmed]
PHST- 2025/03/21 04:54 [entrez]
PHST- 2024/12/17 00:00 [pmc-release]
AID - S2666-9145(24)00217-3 [pii]
AID - 100681 [pii]
AID - 10.1016/j.xops.2024.100681 [doi]
PST - epublish
SO  - Ophthalmol Sci. 2024 Dec 17;5(3):100681. doi: 10.1016/j.xops.2024.100681. 
      eCollection 2025 May-Jun.

PMID- 39983116
OWN - NLM
STAT- MEDLINE
DCOM- 20250221
LR  - 20250311
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Feb 21
TI  - Perspectives of Black, Latinx, Indigenous, and Asian Communities on Health Data 
      Use and AI: Cross-Sectional Survey Study.
PG  - e50708
LID - 10.2196/50708 [doi]
LID - e50708
AB  - Despite excitement around artificial intelligence (AI)-based tools in health 
      care, there is work to be done before they can be equitably deployed. The absence 
      of diverse patient voices in discussions on AI is a pressing matter, and current 
      studies have been limited in diversity. Our study inquired about the perspectives 
      of racial and ethnic minority patients on the use of their health data in AI, by 
      conducting a cross-sectional survey among 230 participants who were at least 18 
      years of age and identified as Black, Latinx, Indigenous, or Asian. While 
      familiarity with AI was high, a smaller proportion of participants understood how 
      AI can be used in health care (152/199, 76.4%), and an even smaller proportion 
      understood how AI can be applied to dermatology (133/199, 66.8%). Overall, 69.8% 
      (139/199) of participants agreed that they trusted the health care system to 
      treat their medical information with respect; however, this varied significantly 
      by income (P=.045). Only 64.3% (128/199) of participants felt comfortable with 
      their medical data being used to build AI tools, and 83.4% (166/199) believed 
      they should be compensated if their data are used to develop AI. To our 
      knowledge, this is the first study focused on understanding opinions about health 
      data use for AI among racial and ethnic minority individuals, as similar studies 
      have had limited diversity. It is important to capture the opinions of diverse 
      groups because the inclusion of their data is essential for building equitable AI 
      tools; however, historical harms have made inclusion challenging.
CI  - ©Fatuma-Ayaan Rinderknecht, Vivian B Yang, Mekaleya Tilahun, Jenna C Lester. 
      Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 21.02.2025.
FAU - Rinderknecht, Fatuma-Ayaan
AU  - Rinderknecht FA
AUID- ORCID: 0000-0001-6302-7348
AD  - San Francisco School of Medicine, University of California, San Francisco, CA, 
      United States.
FAU - Yang, Vivian B
AU  - Yang VB
AUID- ORCID: 0000-0001-9302-0403
AD  - San Francisco School of Medicine, University of California, San Francisco, CA, 
      United States.
FAU - Tilahun, Mekaleya
AU  - Tilahun M
AUID- ORCID: 0000-0003-4139-2234
AD  - San Francisco School of Medicine, University of California, San Francisco, CA, 
      United States.
FAU - Lester, Jenna C
AU  - Lester JC
AUID- ORCID: 0000-0003-1849-1082
AD  - Department of Dermatology, University of California, San Francisco, San 
      Francisco, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20250221
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - Adult
MH  - Female
MH  - Male
MH  - *Artificial Intelligence
MH  - Middle Aged
MH  - Hispanic or Latino/statistics & numerical data
MH  - Young Adult
MH  - Surveys and Questionnaires
MH  - Asian/statistics & numerical data
MH  - White
PMC - PMC11890126
OTO - NOTNLM
OT  - AI
OT  - Asian
OT  - Black
OT  - Indigenous
OT  - LLM
OT  - Latinx
OT  - artificial intelligence
OT  - augmented intelligence
OT  - dermatology
OT  - diversity
OT  - health care
OT  - health data
OT  - health equity
OT  - large language model
OT  - racial and ethnic minority communities
OT  - racism
OT  - survey
COIS- Conflicts of Interest: None declared.
EDAT- 2025/02/21 18:21
MHDA- 2025/02/21 18:22
PMCR- 2025/02/21
CRDT- 2025/02/21 16:53
PHST- 2024/07/08 00:00 [received]
PHST- 2024/12/11 00:00 [accepted]
PHST- 2024/11/09 00:00 [revised]
PHST- 2025/02/21 18:22 [medline]
PHST- 2025/02/21 18:21 [pubmed]
PHST- 2025/02/21 16:53 [entrez]
PHST- 2025/02/21 00:00 [pmc-release]
AID - v27i1e50708 [pii]
AID - 10.2196/50708 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Feb 21;27:e50708. doi: 10.2196/50708.

PMID- 39507511
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241108
IS  - 2666-1683 (Electronic)
IS  - 2666-1691 (Print)
IS  - 2666-1683 (Linking)
VI  - 70
DP  - 2024 Dec
TI  - Comparing Patient's Confidence in Clinical Capabilities in Urology: Large 
      Language Models Versus Urologists.
PG  - 91-98
LID - 10.1016/j.euros.2024.10.009 [doi]
AB  - BACKGROUND AND OBJECTIVE: Data on interaction of patients with artificial 
      intelligence (AI) are limited, primarily derived from small-scale studies, 
      cross-sectional surveys, and qualitative reviews. Most patients have not yet 
      encountered AI in their clinical experience. This study explored patients' 
      confidence in AI, specifically large language models, after a direct interaction 
      with a chatbot in a clinical setting. Through hands-on experience, the study 
      sought to reduce potential biases due to an anticipated lack of AI experience in 
      a real-world urological patient sample. METHODS: A total of 300 patients 
      scheduled for counseling were enrolled from February to July 2024. Participants 
      voluntarily conversed about their medical questions with a GPT-4 powered chatbot, 
      followed by a survey assessing their confidence in clinical capabilities of AI 
      compared with their counseling urologists. Clinical capabilities included history 
      taking, diagnostics, treatment recommendation, anxiety reduction, and time 
      allocation. KEY FINDINGS AND LIMITATIONS: Of the 292 patients who completed the 
      study, AI was significantly preferred to physicians for consultation time 
      allocation (p < 0.001). However, urologists were overwhelmingly favored for all 
      other capabilities, especially treatment recommendations and anxiety reduction. 
      Notably, age did not influence patients' confidence in AI. Limitations include a 
      potential social desirability bias. CONCLUSIONS AND CLINICAL IMPLICATIONS: Our 
      study demonstrates that urological patients prefer AI as a powerful complement 
      to-rather than a replacement for-human expertise in clinical care. Patients 
      appreciated the additional consultation time provided by AI. Interestingly, age 
      was not associated with confidence in AI, suggesting that large language models 
      are user-friendly tools for patients of all age groups. PATIENT SUMMARY: In this 
      report, we explored how patients feel about using an artificial intelligence 
      (AI)-powered chatbot in a medical setting. Patients interacted with the AI for 
      medical questions and compared its skills with those of doctors through a survey. 
      They appreciated the AI for providing more time during consultations but 
      preferred doctors for other tasks, for example, diagnostics, recommendation of 
      treatments, and reduction of anxieties.
CI  - © 2024 The Author(s).
FAU - Carl, Nicolas
AU  - Carl N
AD  - Digital Biomarkers for Oncology Group, German Cancer Research Center (DKFZ), 
      Heidelberg, Germany.
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Nguyen, Lisa
AU  - Nguyen L
AD  - Medical Faculty Mannheim, Ruprecht-Karls University of Heidelberg, Mannheim, 
      Germany.
FAU - Haggenmüller, Sarah
AU  - Haggenmüller S
AD  - Digital Biomarkers for Oncology Group, German Cancer Research Center (DKFZ), 
      Heidelberg, Germany.
FAU - Joachim Hetz, Martin
AU  - Joachim Hetz M
AD  - Digital Biomarkers for Oncology Group, German Cancer Research Center (DKFZ), 
      Heidelberg, Germany.
FAU - Theres Winterstein, Jana
AU  - Theres Winterstein J
AD  - Digital Biomarkers for Oncology Group, German Cancer Research Center (DKFZ), 
      Heidelberg, Germany.
AD  - Medical Faculty Heidelberg, Ruprecht-Karls University of Heidelberg, Heidelberg, 
      Germany.
FAU - Otto Hartung, Friedrich
AU  - Otto Hartung F
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Gruene, Britta
AU  - Gruene B
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Nikolas Kather, Jakob
AU  - Nikolas Kather J
AD  - Medical Faculty Carl Gustav Carus, Else Kroener Fresenius Center for Digital 
      Health, TUD Dresden University of Technology, Dresden, Germany.
FAU - Holland-Letz, Tim
AU  - Holland-Letz T
AD  - Department of Biostatistics, German Cancer Research Center (DKFZ), Heidelberg, 
      Germany.
FAU - Stephan Michel, Maurice
AU  - Stephan Michel M
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Wessels, Frederik
AU  - Wessels F
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Josef Brinker, Titus
AU  - Josef Brinker T
AD  - Digital Biomarkers for Oncology Group, German Cancer Research Center (DKFZ), 
      Heidelberg, Germany.
LA  - eng
PT  - Journal Article
DEP - 20241023
PL  - Netherlands
TA  - Eur Urol Open Sci
JT  - European urology open science
JID - 101771568
PMC - PMC11538625
OTO - NOTNLM
OT  - Clinical trial
OT  - Generative artificial intelligence
OT  - Implementation science
OT  - Large language models
OT  - Patient interaction
EDAT- 2024/11/12 04:45
MHDA- 2024/11/12 04:46
PMCR- 2024/10/23
CRDT- 2024/11/07 04:34
PHST- 2024/10/07 00:00 [accepted]
PHST- 2024/11/12 04:46 [medline]
PHST- 2024/11/12 04:45 [pubmed]
PHST- 2024/11/07 04:34 [entrez]
PHST- 2024/10/23 00:00 [pmc-release]
AID - S2666-1683(24)01094-2 [pii]
AID - 10.1016/j.euros.2024.10.009 [doi]
PST - epublish
SO  - Eur Urol Open Sci. 2024 Oct 23;70:91-98. doi: 10.1016/j.euros.2024.10.009. 
      eCollection 2024 Dec.

PMID- 38812088
OWN - NLM
STAT- MEDLINE
DCOM- 20240719
LR  - 20240820
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 8
DP  - 2024 Aug 1
TI  - Constructing knowledge: the role of AI in medical learning.
PG  - 1797-1798
LID - 10.1093/jamia/ocae124 [doi]
AB  - The integration of large language models (LLMs) like ChatGPT into medical 
      education presents potential benefits and challenges. These technologies, aligned 
      with constructivist learning theories, could potentially enhance critical 
      thinking and problem-solving through inquiry-based learning environments. 
      However, the actual impact on educational outcomes and the effectiveness of these 
      tools in fostering learning require further empirical study. This technological 
      shift necessitates a reevaluation of curriculum design and the development of new 
      assessment methodologies to measure its effects accurately. Additionally, the use 
      of LLMs introduces significant ethical concerns, particularly in addressing 
      inherent AI biases to ensure equitable educational access. LLMs may also help 
      reduce global disparities in medical education by providing broader access to 
      contemporary medical knowledge and practices, though their deployment must be 
      managed carefully to truly support the training of competent, ethical medical 
      professionals.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Lawson McLean, Aaron
AU  - Lawson McLean A
AUID- ORCID: 0000-0001-5528-6905
AD  - Department of Neurosurgery, Jena University Hospital-Friedrich Schiller 
      University Jena, 07747 Jena, Germany.
LA  - eng
PT  - Comment
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
CON - J Am Med Inform Assoc. 2024 Feb 16;31(3):776-783. doi: 10.1093/jamia/ocad252. 
      PMID: 38269644
MH  - *Artificial Intelligence/ethics
MH  - *Education, Medical
MH  - Curriculum
MH  - Humans
MH  - Learning
PMC - PMC11258398
OTO - NOTNLM
OT  - artificial intelligence
OT  - constructivist learning
OT  - curriculum development
OT  - ethical considerations
OT  - medical education
COIS- The author declares no conflicts of interest in the preparation and writing of 
      this manuscript.
EDAT- 2024/05/30 06:35
MHDA- 2024/07/19 06:42
PMCR- 2025/05/29
CRDT- 2024/05/30 00:43
PHST- 2024/02/18 00:00 [received]
PHST- 2024/05/15 00:00 [accepted]
PHST- 2025/05/29 00:00 [pmc-release]
PHST- 2024/07/19 06:42 [medline]
PHST- 2024/05/30 06:35 [pubmed]
PHST- 2024/05/30 00:43 [entrez]
AID - 7685051 [pii]
AID - ocae124 [pii]
AID - 10.1093/jamia/ocae124 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Aug 1;31(8):1797-1798. doi: 10.1093/jamia/ocae124.

PMID- 39656836
OWN - NLM
STAT- MEDLINE
DCOM- 20250121
LR  - 20250129
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 32
IP  - 2
DP  - 2025 Feb 1
TI  - Establishing best practices in large language model research: an application to 
      repeat prompting.
PG  - 386-390
LID - 10.1093/jamia/ocae294 [doi]
AB  - OBJECTIVES: We aimed to demonstrate the importance of establishing best practices 
      in large language model research, using repeat prompting as an illustrative 
      example. MATERIALS AND METHODS: Using data from a prior study investigating 
      potential model bias in peer review of medical abstracts, we compared methods 
      that ignore correlation in model outputs from repeated prompting with a random 
      effects method that accounts for this correlation. RESULTS: High correlation 
      within groups was found when repeatedly prompting the model, with intraclass 
      correlation coefficient of 0.69. Ignoring the inherent correlation in the data 
      led to over 100-fold inflation of effective sample size. After appropriately 
      accounting for this issue, the authors' results reverse from a small but highly 
      significant finding to no evidence of model bias. DISCUSSION: The establishment 
      of best practices for LLM research is urgently needed, as demonstrated in this 
      case where accounting for repeat prompting in analyses was critical for accurate 
      study conclusions.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Gallo, Robert J
AU  - Gallo RJ
AUID- ORCID: 0000-0002-2601-0173
AD  - Center for Innovation to Implementation, VA Palo Alto Health Care System, Menlo 
      Park, CA 94025, United States.
AD  - Department of Health Policy, Stanford University, Stanford, CA 94305, United 
      States.
FAU - Baiocchi, Michael
AU  - Baiocchi M
AUID- ORCID: 0000-0002-7571-5268
AD  - Department of Epidemiology and Population Health, Stanford University, Stanford, 
      CA 94305, United States.
FAU - Savage, Thomas R
AU  - Savage TR
AD  - Division of Hospital Medicine, Stanford University, Stanford, CA 94305, United 
      States.
FAU - Chen, Jonathan H
AU  - Chen JH
AD  - Division of Hospital Medicine, Stanford University, Stanford, CA 94305, United 
      States.
AD  - Stanford Center for Biomedical Informatics Research, Stanford University, 
      Stanford, CA 94304, United States.
AD  - Clinical Excellence Research Center, Stanford University, Stanford, CA 94305, 
      United States.
LA  - eng
GR  - 1R01AI17812101/National Institute of Allergy and Infectious Diseases/
GR  - UG1 DA015815/DA/NIDA NIH HHS/United States
GR  - #12409/Gordon and Betty Moore Foundation/
GR  - American Heart Association-Strategically Focused Research Network-Diversity in 
      Clinical Trials/
GR  - Medical Informatics/
GR  - Stanford Artificial Intelligence in Medicine and Imaging-Human-Centered 
      Artificial Intelligence/
GR  - UG1DA015815-CTN-0136/National Institute on Drug Abuse Clinical Trials Network/
GR  - UL1 TR003142/TR/NCATS NIH HHS/United States
GR  - Stanford Bio-X Interdisciplinary Seed/
GR  - VA Advanced Fellowship in Medical Informatics/
GR  - UL1TR003142/National Center for Advancing Translational Sciences's Clinical and 
      Translational Science/
GR  - Stanford Institute for Human-Centered Artificial Intelligence/
GR  - United States Government/
GR  - UM1 TR004921/TR/NCATS NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - *Abstracting and Indexing
MH  - Peer Review, Research
MH  - Humans
PMC - PMC11756642
OTO - NOTNLM
OT  - large language model
OT  - multilevel analysis
OT  - peer review
COIS- JHC reports being a co-founder of Reaction Explorer LLC that develops and 
      licenses organic chemistry education software; paid consulting fees from Sutton 
      Pierce, Younker Hyde MacFarlane, and Sykes McAllister as a medical expert 
      witness; paid consulting fees from ISHI Health.
EDAT- 2024/12/15 19:30
MHDA- 2025/01/22 05:33
PMCR- 2024/12/04
CRDT- 2024/12/10 13:54
PHST- 2024/08/12 00:00 [received]
PHST- 2024/10/17 00:00 [revised]
PHST- 2024/11/18 00:00 [accepted]
PHST- 2025/01/22 05:33 [medline]
PHST- 2024/12/15 19:30 [pubmed]
PHST- 2024/12/10 13:54 [entrez]
PHST- 2024/12/04 00:00 [pmc-release]
AID - 7916529 [pii]
AID - ocae294 [pii]
AID - 10.1093/jamia/ocae294 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2025 Feb 1;32(2):386-390. doi: 10.1093/jamia/ocae294.

PMID- 39277154
OWN - NLM
STAT- MEDLINE
DCOM- 20241017
LR  - 20241017
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Linking)
VI  - 158
DP  - 2024 Oct
TI  - Large Language Models, scientific knowledge and factuality: A framework to 
      streamline human expert evaluation.
PG  - 104724
LID - S1532-0464(24)00142-4 [pii]
LID - 10.1016/j.jbi.2024.104724 [doi]
AB  - OBJECTIVE: The paper introduces a framework for the evaluation of the encoding of 
      factual scientific knowledge, designed to streamline the manual evaluation 
      process typically conducted by domain experts. Inferring over and extracting 
      information from Large Language Models (LLMs) trained on a large corpus of 
      scientific literature can potentially define a step change in biomedical 
      discovery, reducing the barriers for accessing and integrating existing medical 
      evidence. This work explores the potential of LLMs for dialoguing with biomedical 
      background knowledge, using the context of antibiotic discovery. METHODS: The 
      framework involves three evaluation steps, each assessing different aspects 
      sequentially: fluency, prompt alignment, semantic coherence, factual knowledge, 
      and specificity of the generated responses. By splitting these tasks between 
      non-experts and experts, the framework reduces the effort required from the 
      latter. The work provides a systematic assessment on the ability of eleven 
      state-of-the-art LLMs, including ChatGPT, GPT-4 and Llama 2, in two 
      prompting-based tasks: chemical compound definition generation and chemical 
      compound-fungus relation determination. RESULTS: Although recent models have 
      improved in fluency, factual accuracy is still low and models are biased towards 
      over-represented entities. The ability of LLMs to serve as biomedical knowledge 
      bases is questioned, and the need for additional systematic evaluation frameworks 
      is highlighted. CONCLUSION: While LLMs are currently not fit for purpose to be 
      used as biomedical factual knowledge bases in a zero-shot setting, there is a 
      promising emerging property in the direction of factuality as the models become 
      domain specialised, scale up in size and level of human feedback.
CI  - Copyright © 2024 The Author(s). Published by Elsevier Inc. All rights reserved.
FAU - Wysocka, Magdalena
AU  - Wysocka M
AD  - Digital Cancer Research, CRUK National Biomarker Centre, Manchester, United 
      Kingdom; Department of Computer Science, University of Manchester, Manchester, 
      United Kingdom. Electronic address: magdalena.wysocka@cruk.manchester.ac.uk.
FAU - Wysocki, Oskar
AU  - Wysocki O
AD  - Digital Cancer Research, CRUK National Biomarker Centre, Manchester, United 
      Kingdom; Idiap Research Institute, Martigny, Switzerland.
FAU - Delmas, Maxime
AU  - Delmas M
AD  - Idiap Research Institute, Martigny, Switzerland.
FAU - Mutel, Vincent
AU  - Mutel V
AD  - Inflamalps SA, Monthey, Switzerland.
FAU - Freitas, André
AU  - Freitas A
AD  - Digital Cancer Research, CRUK National Biomarker Centre, Manchester, United 
      Kingdom; Department of Computer Science, University of Manchester, Manchester, 
      United Kingdom; Idiap Research Institute, Martigny, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20240912
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
RN  - 0 (Anti-Bacterial Agents)
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Semantics
MH  - Anti-Bacterial Agents
OTO - NOTNLM
OT  - Antibiotic discovery
OT  - Factual knowledge
OT  - Large language models
OT  - Retrieval-augmented generation
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/09/15 14:09
MHDA- 2024/10/18 00:30
CRDT- 2024/09/14 19:29
PHST- 2024/04/04 00:00 [received]
PHST- 2024/08/26 00:00 [revised]
PHST- 2024/09/05 00:00 [accepted]
PHST- 2024/10/18 00:30 [medline]
PHST- 2024/09/15 14:09 [pubmed]
PHST- 2024/09/14 19:29 [entrez]
AID - S1532-0464(24)00142-4 [pii]
AID - 10.1016/j.jbi.2024.104724 [doi]
PST - ppublish
SO  - J Biomed Inform. 2024 Oct;158:104724. doi: 10.1016/j.jbi.2024.104724. Epub 2024 
      Sep 12.

PMID- 39705071
OWN - NLM
STAT- MEDLINE
DCOM- 20241220
LR  - 20250315
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 8
DP  - 2024 Dec 20
TI  - Identification of Gender Differences in Acute Myocardial Infarction Presentation 
      and Management at Aga Khan University Hospital-Pakistan: Natural Language 
      Processing Application in a Dataset of Patients With Cardiovascular Disease.
PG  - e42774
LID - 10.2196/42774 [doi]
LID - e42774
AB  - BACKGROUND: Ischemic heart disease is a leading cause of death globally with a 
      disproportionate burden in low- and middle-income countries (LMICs). Natural 
      language processing (NLP) allows for data enrichment in large datasets to 
      facilitate key clinical research. We used NLP to assess gender differences in 
      symptoms and management of patients hospitalized with acute myocardial infarction 
      (AMI) at Aga Khan University Hospital-Pakistan. OBJECTIVE: The primary objective 
      of this study was to use NLP to assess gender differences in the symptoms and 
      management of patients hospitalized with AMI at a tertiary care hospital in 
      Pakistan. METHODS: We developed an NLP-based methodology to extract AMI symptoms 
      and medications from 5358 discharge summaries spanning the years 1988 to 2018. 
      This dataset included patients admitted and discharged between January 1, 1988, 
      and December 31, 2018, who were older than 18 years with a primary discharge 
      diagnosis of AMI (using ICD-9 [International Classification of Diseases, Ninth 
      Revision], diagnostic codes). The methodology used a fuzzy keyword-matching 
      algorithm to extract AMI symptoms from the discharge summaries automatically. It 
      first preprocesses the free text within the discharge summaries to extract 
      passages indicating the presenting symptoms. Then, it applies fuzzy matching 
      techniques to identify relevant keywords or phrases indicative of AMI symptoms, 
      incorporating negation handling to minimize false positives. After manually 
      reviewing the quality of extracted symptoms in a subset of discharge summaries 
      through preliminary experiments, a similarity threshold of 80% was determined. 
      RESULTS: Among 1769 women and 3589 men with AMI, women had higher odds of 
      presenting with shortness of breath (odds ratio [OR] 1.46, 95% CI 1.26-1.70) and 
      lower odds of presenting with chest pain (OR 0.65, 95% CI 0.55-0.75), even after 
      adjustment for diabetes and age. Presentation with abdominal pain, nausea, or 
      vomiting was much less frequent but consistently more common in women (P<.001). 
      "Ghabrahat," a culturally distinct term for a feeling of impending doom was used 
      by 5.09% of women and 3.69% of men as presenting symptom for AMI (P=.06). 
      First-line medication prescription (statin and β-blockers) was lower in women: 
      women had nearly 30% lower odds (OR 0.71, 95% CI 0.57-0.90) of being prescribed 
      statins, and they had 40% lower odds (OR 0.67, 95% CI 0.57-0.78) of being 
      prescribed β-blockers. CONCLUSIONS: Gender-based differences in clinical 
      presentation and medication management were demonstrated in patients with AMI at 
      a tertiary care hospital in Pakistan. The use of NLP for the identification of 
      culturally nuanced clinical characteristics and management is feasible in LMICs 
      and could be used as a tool to understand gender disparities and address key 
      clinical priorities in LMICs.
CI  - ©Christine Ngaruiya, Zainab Samad, Salma Tajuddin, Zarmeen Nasim, Rebecca Leff, 
      Awais Farhad, Kyle Pires, Muhammad Alamgir Khan, Lauren Hartz, Basmah Safdar. 
      Originally published in JMIR Formative Research (https://formative.jmir.org), 
      20.12.2024.
FAU - Ngaruiya, Christine
AU  - Ngaruiya C
AUID- ORCID: 0000-0002-4583-0986
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, United 
      States.
AD  - Department of Emergency Medicine, Stanford School of Medicine, Palo Alto, CA, 
      United States.
FAU - Samad, Zainab
AU  - Samad Z
AUID- ORCID: 0000-0003-2422-3199
AD  - Department of Medicine, Aga Khan University, Karachi, Pakistan.
FAU - Tajuddin, Salma
AU  - Tajuddin S
AUID- ORCID: 0000-0003-4008-3456
AD  - Department of Medicine, Aga Khan University, Karachi, Pakistan.
AD  - CITRIC Health Data Science Center, Aga Khan University, Karachi, Pakistan.
FAU - Nasim, Zarmeen
AU  - Nasim Z
AUID- ORCID: 0000-0002-6972-6665
AD  - CITRIC Health Data Science Center, Aga Khan University, Karachi, Pakistan.
FAU - Leff, Rebecca
AU  - Leff R
AUID- ORCID: 0000-0001-9254-6884
AD  - Department of Emergency Medicine, Mayo Clinic School of Graduate Medical 
      Education, Rochester, MN, United States.
FAU - Farhad, Awais
AU  - Farhad A
AUID- ORCID: 0000-0001-8833-4088
AD  - Department of Medicine, Aga Khan University, Karachi, Pakistan.
FAU - Pires, Kyle
AU  - Pires K
AUID- ORCID: 0000-0001-6247-8761
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, United 
      States.
FAU - Khan, Muhammad Alamgir
AU  - Khan MA
AUID- ORCID: 0000-0003-1327-9787
AD  - School of Medicine, Aga Khan University, Karachi, Pakistan.
FAU - Hartz, Lauren
AU  - Hartz L
AUID- ORCID: 0009-0003-7002-1237
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, United 
      States.
FAU - Safdar, Basmah
AU  - Safdar B
AUID- ORCID: 0000-0002-9640-7133
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, United 
      States.
LA  - eng
GR  - UL1 TR001863/TR/NCATS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20241220
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
SB  - IM
MH  - Humans
MH  - Female
MH  - Pakistan/epidemiology
MH  - Male
MH  - *Myocardial Infarction/diagnosis/therapy
MH  - *Natural Language Processing
MH  - Middle Aged
MH  - Sex Factors
MH  - Hospitals, University
MH  - Aged
MH  - Adult
MH  - Cardiovascular Diseases
PMC - PMC11699486
OTO - NOTNLM
OT  - Pakistan
OT  - acute coronary syndrome
OT  - clinical
OT  - data
OT  - dataset
OT  - gender
OT  - gender-based differences
OT  - global health
OT  - management
OT  - medication
OT  - natural language processing
OT  - patient
OT  - research
OT  - tool
OT  - women
COIS- Conflicts of Interest: CN reports a grant from the Yale Institute for Global 
      Health Hecht Global Health Faculty Network Award. The funder had no role in the 
      study design; collection, analysis, and interpretation of data; writing of the 
      paper; and/or decision to submit for publication. All other authors declare no 
      competing interests.
EDAT- 2024/12/20 12:22
MHDA- 2024/12/20 18:20
PMCR- 2024/12/20
CRDT- 2024/12/20 11:52
PHST- 2022/09/17 00:00 [received]
PHST- 2024/09/24 00:00 [accepted]
PHST- 2023/10/23 00:00 [revised]
PHST- 2024/12/20 18:20 [medline]
PHST- 2024/12/20 12:22 [pubmed]
PHST- 2024/12/20 11:52 [entrez]
PHST- 2024/12/20 00:00 [pmc-release]
AID - v8i1e42774 [pii]
AID - 10.2196/42774 [doi]
PST - epublish
SO  - JMIR Form Res. 2024 Dec 20;8:e42774. doi: 10.2196/42774.

PMID- 38957592
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240704
IS  - 2574-2531 (Electronic)
IS  - 2574-2531 (Linking)
VI  - 7
IP  - 3
DP  - 2024 Oct
TI  - Completeness and readability of GPT-4-generated multilingual discharge 
      instructions in the pediatric emergency department.
PG  - ooae050
LID - 10.1093/jamiaopen/ooae050 [doi]
LID - ooae050
AB  - OBJECTIVES: The aim of this study was to assess the completeness and readability 
      of generative pre-trained transformer-4 (GPT-4)-generated discharge instructions 
      at prespecified reading levels for common pediatric emergency room complaints. 
      MATERIALS AND METHODS: The outputs for 6 discharge scenarios stratified by 
      reading level (fifth or eighth grade) and language (English, Spanish) were 
      generated fivefold using GPT-4. Specifically, 120 discharge instructions were 
      produced and analyzed (6 scenarios: 60 in English, 60 in Spanish; 60 at a 
      fifth-grade reading level, 60 at an eighth-grade reading level) and compared for 
      completeness and readability (between language, between reading level, and 
      stratified by group and reading level). Completeness was defined as the 
      proportion of literature-derived key points included in discharge instructions. 
      Readability was quantified using Flesch-Kincaid (English) and Fernandez-Huerta 
      (Spanish) readability scores. RESULTS: English-language GPT-generated discharge 
      instructions contained a significantly higher proportion of must-include 
      discharge instructions than those in Spanish (English: mean (standard error of 
      the mean) = 62% (3%), Spanish: 53% (3%), P = .02). In the fifth-grade and 
      eighth-grade level conditions, there was no significant difference between 
      English and Spanish outputs in completeness. Readability did not differ across 
      languages. DISCUSSION: GPT-4 produced readable discharge instructions in English 
      and Spanish while modulating document reading level. Discharge instructions in 
      English tended to have higher completeness than those in Spanish. CONCLUSION: 
      Future research in prompt engineering and GPT-4 performance, both generally and 
      in multiple languages, is needed to reduce potential for health disparities by 
      language and reading level.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Gimeno, Alex
AU  - Gimeno A
AUID- ORCID: 0000-0001-7098-914X
AD  - Department of Biomedical Informatics, Vanderbilt University School of Medicine, 
      Nashville, TN 37232, United States.
FAU - Krause, Kevin
AU  - Krause K
AUID- ORCID: 0000-0001-8652-753X
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN 37203, United States.
FAU - D'Souza, Starina
AU  - D'Souza S
AD  - Department of Biomedical Informatics, Vanderbilt University School of Medicine, 
      Nashville, TN 37232, United States.
FAU - Walsh, Colin G
AU  - Walsh CG
AD  - Department of Biomedical Informatics, Vanderbilt University School of Medicine, 
      Nashville, TN 37232, United States.
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, TN 37203, United States.
AD  - Department of Medicine, Vanderbilt University Medical Center, Nashville, TN 
      37203, United States.
AD  - Department of Psychiatry and Behavioral Sciences, Vanderbilt University Medical 
      Center, Nashville, TN 37203, United States.
LA  - eng
PT  - Journal Article
DEP - 20240701
PL  - United States
TA  - JAMIA Open
JT  - JAMIA open
JID - 101730643
PMC - PMC11216721
OTO - NOTNLM
OT  - artificial intelligence
OT  - computer simulations
OT  - diversity
OT  - equity
OT  - inclusion
OT  - literacy
OT  - pediatric emergency medicine
COIS- None of the authors have competing interests to declare.
EDAT- 2024/07/03 06:42
MHDA- 2024/07/03 06:43
PMCR- 2024/07/01
CRDT- 2024/07/03 04:10
PHST- 2024/01/06 00:00 [received]
PHST- 2024/05/16 00:00 [revised]
PHST- 2024/05/28 00:00 [accepted]
PHST- 2024/07/03 06:43 [medline]
PHST- 2024/07/03 06:42 [pubmed]
PHST- 2024/07/03 04:10 [entrez]
PHST- 2024/07/01 00:00 [pmc-release]
AID - ooae050 [pii]
AID - 10.1093/jamiaopen/ooae050 [doi]
PST - epublish
SO  - JAMIA Open. 2024 Jul 1;7(3):ooae050. doi: 10.1093/jamiaopen/ooae050. eCollection 
      2024 Oct.

PMID- 39399272
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241015
IS  - 2574-2531 (Electronic)
IS  - 2574-2531 (Linking)
VI  - 7
IP  - 4
DP  - 2024 Dec
TI  - Revealing the impact of social circumstances on the selection of cancer therapy 
      through natural language processing of social work notes.
PG  - ooae073
LID - 10.1093/jamiaopen/ooae073 [doi]
LID - ooae073
AB  - OBJECTIVE: We aimed to investigate the impact of social circumstances on cancer 
      therapy selection using natural language processing to derive insights from 
      social worker documentation. MATERIALS AND METHODS: We developed and employed a 
      Bidirectional Encoder Representations from Transformers (BERT) based approach, 
      using a hierarchical multi-step BERT model (BERT-MS), to predict the prescription 
      of targeted cancer therapy to patients based solely on documentation by clinical 
      social workers. Our corpus included free-text clinical social work notes, 
      combined with medication prescription information, for all patients treated for 
      breast cancer at UCSF between 2012 and 2021. We conducted a feature importance 
      analysis to identify the specific social circumstances that impact cancer therapy 
      regimen. RESULTS: Using only social work notes, we consistently predicted the 
      administration of targeted therapies, suggesting systematic differences in 
      treatment selection exist due to non-clinical factors. The findings were 
      confirmed by several language models, with GatorTron achieving the best 
      performance with an area under the receiver operating characteristic curve 
      (AUROC) of 0.721 and a Macro F1 score of 0.616. The UCSF BERT-MS model, capable 
      of leveraging multiple pieces of notes, surpassed the UCSF-BERT model in both 
      AUROC and Macro-F1. Our feature importance analysis identified several clinically 
      intuitive social determinants of health that potentially contribute to 
      disparities in treatment. DISCUSSION: Leveraging social work notes can be 
      instrumental in identifying disparities in clinical decision-making. Hypotheses 
      generated in an automated way could be used to guide patient-specific quality 
      improvement interventions. Further validation with diverse clinical outcomes and 
      prospective studies is essential. CONCLUSIONS: Our findings indicate that 
      significant disparities exist among breast cancer patients receiving different 
      types of therapies based on social determinants of health. Social work reports 
      play a crucial role in understanding these disparities in clinical 
      decision-making.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Sun, Shenghuan
AU  - Sun S
AUID- ORCID: 0000-0002-4339-2716
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA 94143, United States.
FAU - Zack, Travis
AU  - Zack T
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA 94143, United States.
AD  - Division of Hematology/Oncology, Department of Medicine, University of 
      California, San Francisco, San Francisco, CA 94143, United States.
FAU - Williams, Christopher Y K
AU  - Williams CYK
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA 94143, United States.
FAU - Butte, Atul J
AU  - Butte AJ
AUID- ORCID: 0000-0002-7433-2740
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA 94143, United States.
AD  - Center for Data-driven Insights and Innovation, University of California, Office 
      of the President, Oakland, CA 94607, United States.
AD  - Department of Pediatrics, University of California, San Francisco, San Francisco, 
      CA 94158, United States.
FAU - Sushil, Madhumita
AU  - Sushil M
AUID- ORCID: 0000-0001-7884-0526
AD  - Bakar Computational Health Sciences Institute, University of California, San 
      Francisco, San Francisco, CA 94143, United States.
LA  - eng
PT  - Journal Article
DEP - 20241011
PL  - United States
TA  - JAMIA Open
JT  - JAMIA open
JID - 101730643
PMC - PMC11470153
OTO - NOTNLM
OT  - cancer therapy
OT  - natural language processing
OT  - selection of cancer therapy
OT  - social determinants of health
OT  - social work notes
COIS- A.J.B. is a co-founder and consultant to Personalis and NuMedii; consultant to 
      Mango Tree Corporation, and in the recent past, Samsung, 10x Genomics, Helix, 
      Pathway Genomics, and Verinata (Illumina); has served on paid advisory panels or 
      boards for Geisinger Health, Regenstrief Institute, Gerson Lehman Group, 
      AlphaSights, Covance, Novartis, Genentech, and Merck, and Roche; is a shareholder 
      in Personalis and NuMedii; is a minor shareholder in Apple, Meta (Facebook), 
      Alphabet (Google), Microsoft, Amazon, Snap, 10x Genomics, Illumina, Regeneron, 
      Sanofi, Pfizer, Royalty Pharma, Moderna, Sutro, Doximity, BioNtech, Invitae, 
      Pacific Biosciences, Editas Medicine, Nuna Health, Assay Depot, and Vet24seven, 
      and several other non-health related companies and mutual funds; and has received 
      honoraria and travel reimbursement for invited talks from Johnson and Johnson, 
      Roche, Genentech, Pfizer, Merck, Lilly, Takeda, Varian, Mars, Siemens, Optum, 
      Abbott, Celgene, AstraZeneca, AbbVie, Westat, and many academic institutions, 
      medical or disease-specific foundations and associations, and health systems. 
      A.J.B. receives royalty payments through Stanford University, for several patents 
      and other disclosures licensed to NuMedii and Personalis. A.J.B.’s research has 
      been funded by NIH, Peraton (as the prime on an NIH contract), Genentech, Johnson 
      and Johnson, FDA, Robert Wood Johnson Foundation, Leon Lowenstein Foundation, 
      Intervalien Foundation, Priscilla Chan and Mark Zuckerberg, the Barbara and 
      Gerson Bakar Foundation, and in the recent past, the March of Dimes, Juvenile 
      Diabetes Research Foundation, California Governor’s Office of Planning and 
      Research, California Institute for Regenerative Medicine, L’Oreal, and Progenity. 
      None of these entities had any bearing on the design of this study or the writing 
      of the manuscript.
EDAT- 2024/10/14 12:22
MHDA- 2024/10/14 12:23
PMCR- 2024/10/11
CRDT- 2024/10/14 07:11
PHST- 2024/05/01 00:00 [received]
PHST- 2024/07/03 00:00 [revised]
PHST- 2024/07/17 00:00 [accepted]
PHST- 2024/10/14 12:23 [medline]
PHST- 2024/10/14 12:22 [pubmed]
PHST- 2024/10/14 07:11 [entrez]
PHST- 2024/10/11 00:00 [pmc-release]
AID - ooae073 [pii]
AID - 10.1093/jamiaopen/ooae073 [doi]
PST - epublish
SO  - JAMIA Open. 2024 Oct 11;7(4):ooae073. doi: 10.1093/jamiaopen/ooae073. eCollection 
      2024 Dec.

PMID- 38959061
OWN - NLM
STAT- MEDLINE
DCOM- 20240703
LR  - 20240720
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 11
DP  - 2024 Jul 3
TI  - News Media Framing of Suicide Circumstances and Gender: Mixed Methods Analysis.
PG  - e49879
LID - 10.2196/49879 [doi]
LID - e49879
AB  - BACKGROUND: Suicide is a leading cause of death worldwide. Journalistic reporting 
      guidelines were created to curb the impact of unsafe reporting; however, how 
      suicide is framed in news reports may differ by important characteristics such as 
      the circumstances and the decedent's gender. OBJECTIVE: This study aimed to 
      examine the degree to which news media reports of suicides are framed using 
      stigmatized or glorified language and differences in such framing by gender and 
      circumstance of suicide. METHODS: We analyzed 200 news articles regarding 
      suicides and applied the validated Stigma of Suicide Scale to identify 
      stigmatized and glorified language. We assessed linguistic similarity with 2 
      widely used metrics, cosine similarity and mutual information scores, using a 
      machine learning-based large language model. RESULTS: News reports of male 
      suicides were framed more similarly to stigmatizing (P<.001) and glorifying 
      (P=.005) language than reports of female suicides. Considering the circumstances 
      of suicide, mutual information scores indicated that differences in the use of 
      stigmatizing or glorifying language by gender were most pronounced for articles 
      attributing legal (0.155), relationship (0.268), or mental health problems 
      (0.251) as the cause. CONCLUSIONS: Linguistic differences, by gender, in 
      stigmatizing or glorifying language when reporting suicide may exacerbate suicide 
      disparities.
CI  - ©Jasmine C Foriest, Shravika Mittal, Eugenia Kim, Andrea Carmichael, Natalie 
      Lennon, Steven A Sumner, Munmun De Choudhury. Originally published in JMIR Mental 
      Health (https://mental.jmir.org), 03.07.2024.
FAU - Foriest, Jasmine C
AU  - Foriest JC
AUID- ORCID: 0000-0002-5265-9574
AD  - School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, 
      United States.
AD  - National Center for Injury Prevention and Control, Centers for Disease Control 
      and Prevention, Atlanta, GA, United States.
FAU - Mittal, Shravika
AU  - Mittal S
AUID- ORCID: 0000-0002-4888-7996
AD  - School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, 
      United States.
FAU - Kim, Eugenia
AU  - Kim E
AUID- ORCID: 0009-0003-9619-0768
AD  - School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, 
      United States.
FAU - Carmichael, Andrea
AU  - Carmichael A
AUID- ORCID: 0000-0002-0821-4471
AD  - National Center for Injury Prevention and Control, Centers for Disease Control 
      and Prevention, Atlanta, GA, United States.
FAU - Lennon, Natalie
AU  - Lennon N
AUID- ORCID: 0000-0002-4749-092X
AD  - National Center for Injury Prevention and Control, Centers for Disease Control 
      and Prevention, Atlanta, GA, United States.
AD  - Accenture, Arlington, VA, United States.
FAU - Sumner, Steven A
AU  - Sumner SA
AUID- ORCID: 0000-0002-3805-7235
AD  - National Center for Injury Prevention and Control, Centers for Disease Control 
      and Prevention, Atlanta, GA, United States.
FAU - De Choudhury, Munmun
AU  - De Choudhury M
AUID- ORCID: 0000-0002-8939-264X
AD  - School of Interactive Computing, Georgia Institute of Technology, Atlanta, GA, 
      United States.
LA  - eng
PT  - Journal Article
DEP - 20240703
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - Female
MH  - Male
MH  - *Suicide/psychology/statistics & numerical data
MH  - *Mass Media/statistics & numerical data
MH  - *Social Stigma
MH  - Sex Factors
MH  - Adult
PMC - PMC11255531
OTO - NOTNLM
OT  - LLM
OT  - LLMs
OT  - NLP
OT  - digital mental health
OT  - disparities
OT  - framing
OT  - gender
OT  - glorification
OT  - glorify
OT  - glorifying
OT  - journalism
OT  - journalist
OT  - journalists
OT  - language model
OT  - language models
OT  - linguistic
OT  - linguistics
OT  - mHealth
OT  - machine learning
OT  - media
OT  - natural language processing
OT  - news
OT  - reporter
OT  - reporters
OT  - reporting
OT  - reporting guidelines
OT  - self harm
OT  - stigma
OT  - stigmatization
OT  - stigmatizing
OT  - suicidal
OT  - suicide
OT  - suicides
COIS- Conflicts of Interest: None declared.
EDAT- 2024/07/03 13:42
MHDA- 2024/07/03 18:43
PMCR- 2024/07/03
CRDT- 2024/07/03 11:54
PHST- 2023/09/19 00:00 [received]
PHST- 2024/03/25 00:00 [accepted]
PHST- 2024/03/07 00:00 [revised]
PHST- 2024/07/03 18:43 [medline]
PHST- 2024/07/03 13:42 [pubmed]
PHST- 2024/07/03 11:54 [entrez]
PHST- 2024/07/03 00:00 [pmc-release]
AID - v11i1e49879 [pii]
AID - 10.2196/49879 [doi]
PST - epublish
SO  - JMIR Ment Health. 2024 Jul 3;11:e49879. doi: 10.2196/49879.

PMID- 40020253
OWN - NLM
STAT- Publisher
LR  - 20250228
IS  - 1873-5800 (Electronic)
IS  - 0968-0160 (Linking)
VI  - 54
DP  - 2025 Feb 27
TI  - Managing class imbalance in the training of a large language model to predict 
      patient selection for total knee arthroplasty: Results from the Artificial 
      intelligence to Revolutionise the patient Care pathway in Hip and knEe 
      aRthroplastY (ARCHERY) project.
PG  - 1-8
LID - S0968-0160(25)00021-3 [pii]
LID - 10.1016/j.knee.2025.02.007 [doi]
AB  - INTRODUCTION: This study set out to test the efficacy of different techniques 
      used to manage to class imbalance, a type of data bias, in application of a large 
      language model (LLM) to predict patient selection for total knee arthroplasty 
      (TKA). METHODS: This study utilised data from the Artificial Intelligence to 
      Revolutionise the Patient Care Pathway in Hip and Knee Arthroplasty (ARCHERY) 
      project (ISRCTN18398037). Data included the pre-operative radiology reports of 
      patients referred to secondary care for knee-related complaints from within the 
      North of Scotland. A clinically based LLM (GatorTron) was trained regarding 
      prediction of selection for TKA. Three methods for managing class imbalance were 
      assessed: a standard model, use of class weighting, and majority class 
      undersampling. RESULTS: A total of 7707 individual knee radiology reports were 
      included (dated from 2015 to 2022). The mean text length was 74 words (range 
      26-275). Only 910/7707 (11.8%) patients underwent TKA surgery (the designated 
      'minority class'). Class weighting technique performed better for minority class 
      discrimination and calibration compared with the other two techniques (Recall 
      0.61/AUROC 0.73 for class weighting compared with 0.54/0.70 and 0.59/0.72 for the 
      standard model and majority class undersampling, respectively. There was also 
      significant data loss for majority class undersampling when compared with 
      class-weighting. CONCLUSION: Use of class-weighting appears to provide the 
      optimal method of training a an LLM to perform analytical tasks on free-text 
      clinical information in the face of significant data bias ('class imbalance'). 
      Such knowledge is an important consideration in the development of 
      high-performance clinical AI models within Trauma and Orthopaedics.
CI  - Copyright © 2025 The Author(s). Published by Elsevier B.V. All rights reserved.
FAU - Farrow, Luke
AU  - Farrow L
AD  - University of Aberdeen Institute of Applied Health Sciences, Aberdeen, UK. 
      Electronic address: luke.farrow@abdn.ac.uk.
FAU - Anderson, Lesley
AU  - Anderson L
AD  - University of Aberdeen Institute of Applied Health Sciences, Aberdeen, UK.
FAU - Zhong, Mingjun
AU  - Zhong M
AD  - University of Aberdeen Institute of Applied Health Sciences, Aberdeen, UK.
LA  - eng
PT  - Journal Article
DEP - 20250227
PL  - Netherlands
TA  - Knee
JT  - The Knee
JID - 9430798
SB  - IM
OTO - NOTNLM
OT  - Arthroplasty
OT  - Artificial intelligence
OT  - Class imbalance
OT  - Knee
OT  - Large language model
OT  - Natural language processing
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2025/02/28 18:22
MHDA- 2025/02/28 18:22
CRDT- 2025/02/28 17:59
PHST- 2024/07/20 00:00 [received]
PHST- 2025/01/13 00:00 [revised]
PHST- 2025/02/06 00:00 [accepted]
PHST- 2025/02/28 18:22 [medline]
PHST- 2025/02/28 18:22 [pubmed]
PHST- 2025/02/28 17:59 [entrez]
AID - S0968-0160(25)00021-3 [pii]
AID - 10.1016/j.knee.2025.02.007 [doi]
PST - aheadofprint
SO  - Knee. 2025 Feb 27;54:1-8. doi: 10.1016/j.knee.2025.02.007.

PMID- 38039893
OWN - NLM
STAT- MEDLINE
DCOM- 20240110
LR  - 20240206
IS  - 1879-0534 (Electronic)
IS  - 0010-4825 (Linking)
VI  - 168
DP  - 2024 Jan
TI  - Using an artificial intelligence tool incorporating natural language processing 
      to identify patients with a diagnosis of ANCA-associated vasculitis in electronic 
      health records.
PG  - 107757
LID - S0010-4825(23)01222-2 [pii]
LID - 10.1016/j.compbiomed.2023.107757 [doi]
AB  - BACKGROUND: Because anti-neutrophil cytoplasmatic antibody (ANCA)-associated 
      vasculitis (AAV) is a rare, life-threatening, auto-immune disease, conducting 
      research is difficult but essential. A long-lasting challenge is to identify rare 
      AAV patients within the electronic-health-record (EHR)-system to facilitate 
      real-world research. Artificial intelligence (AI)-search tools using natural 
      language processing (NLP) for text-mining are increasingly postulated as a 
      solution. METHODS: We employed an AI-tool that combined text-mining with 
      NLP-based exclusion, to accurately identify rare AAV patients within large 
      EHR-systems (>2.000.000 records). We developed an identification method in an 
      academic center with an established AAV-training set (n = 203) and validated the 
      method in a non-academic center with an AAV-validation set (n = 84). To assess 
      accuracy anonymized patient records were manually reviewed. RESULTS: Based on an 
      iterative process, a text-mining search was developed on disease description, 
      laboratory measurements, medication and specialisms. In the training center, 608 
      patients were identified with a sensitivity of 97.0 % (95%CI [93.7, 98.9]) and 
      positive predictive value (PPV) of 56.9 % (95%CI [52.9, 60.1]). NLP-based 
      exclusion resulted in 444 patients increasing PPV to 77.9 % (95%CI [73.7, 81.7]) 
      while sensitivity remained 96.3 % (95%CI [93.8, 98.0]). In the validation center, 
      text-mining identified 333 patients (sensitivity 97.6 % (95%CI [91.6, 99.7]), PPV 
      58.2 % (95%CI [52.8, 63.6])) and NLP-based exclusion resulted in 223 patients, 
      increasing PPV to 86.1 % (95%CI [80.9, 90.4]) with 98.0 % (95%CI [94.9, 99.4]) 
      sensitivity. Our identification method outperformed ICD-10-coding predominantly 
      in identifying MPO+ and organ-limited AAV patients. CONCLUSIONS: Our study 
      highlights the advantages of implementing AI, notably NLP, to accurately identify 
      rare AAV patients within large EHR-systems and demonstrates the applicability and 
      transportability. Therefore, this method can reduce efforts to identify AAV 
      patients and accelerate real-world research, while avoiding bias by 
      ICD-10-coding.
CI  - Copyright © 2023 The Authors. Published by Elsevier Ltd.. All rights reserved.
FAU - van Leeuwen, Jolijn R
AU  - van Leeuwen JR
AD  - Center of Expertise for Lupus-, Vasculitis- and Complement-mediated Systemic 
      diseases (LuVaCs), Department of Internal Medicine - Nephrology Section, Leiden 
      University Medical Center, Leiden, the Netherlands.
FAU - Penne, Erik L
AU  - Penne EL
AD  - Department of Internal Medicine - Nephrology Section, Northwest Clinics, Alkmaar, 
      the Netherlands.
FAU - Rabelink, Ton
AU  - Rabelink T
AD  - Center of Expertise for Lupus-, Vasculitis- and Complement-mediated Systemic 
      diseases (LuVaCs), Department of Internal Medicine - Nephrology Section, Leiden 
      University Medical Center, Leiden, the Netherlands.
FAU - Knevel, Rachel
AU  - Knevel R
AD  - Department of Rheumatology, Leiden University Medical Center, Leiden, the 
      Netherlands.
FAU - Teng, Y K Onno
AU  - Teng YKO
AD  - Center of Expertise for Lupus-, Vasculitis- and Complement-mediated Systemic 
      diseases (LuVaCs), Department of Internal Medicine - Nephrology Section, Leiden 
      University Medical Center, Leiden, the Netherlands. Electronic address: 
      Y.K.O.Teng@lumc.nl.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20231125
PL  - United States
TA  - Comput Biol Med
JT  - Computers in biology and medicine
JID - 1250250
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Natural Language Processing
MH  - Electronic Health Records
MH  - *Anti-Neutrophil Cytoplasmic Antibody-Associated Vasculitis/diagnosis
MH  - Software
OTO - NOTNLM
OT  - ANCA-Associated vasculitis
OT  - Artificial intelligence
OT  - Electronic-health-records
OT  - Natural language processing
OT  - Pauci-immune glomerulonephritis
COIS- Declaration of competing interest The work of YKOT is supported by the Dutch 
      Kidney Foundation (17OKG04) and by the Arthritis Research and Collaboration Hub 
      (ARCH) foundation. ARCH is funded by Dutch Arthritis Foundation (ReumaNederland). 
      YKOT received an unrestricted research grant from GlaxoSmithKline, Aurinia 
      Pharmaceuticals and Vifor Pharma. The LUMC received consulting fees from Aurinia 
      Pharmaceuticals, Novartis, GSK, KezarBio, Vifor Pharma, Otsuka Pharmaceuticals on 
      consultancies delivered by YKOT.
EDAT- 2023/12/02 00:42
MHDA- 2024/01/10 06:42
CRDT- 2023/12/01 18:14
PHST- 2023/09/07 00:00 [received]
PHST- 2023/11/14 00:00 [revised]
PHST- 2023/11/21 00:00 [accepted]
PHST- 2024/01/10 06:42 [medline]
PHST- 2023/12/02 00:42 [pubmed]
PHST- 2023/12/01 18:14 [entrez]
AID - S0010-4825(23)01222-2 [pii]
AID - 10.1016/j.compbiomed.2023.107757 [doi]
PST - ppublish
SO  - Comput Biol Med. 2024 Jan;168:107757. doi: 10.1016/j.compbiomed.2023.107757. Epub 
      2023 Nov 25.

PMID- 38035200
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231202
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 6
DP  - 2023
TI  - Guiding principles and proposed classification system for the responsible 
      adoption of artificial intelligence in scientific writing in medicine.
PG  - 1283353
LID - 10.3389/frai.2023.1283353 [doi]
LID - 1283353
AB  - The integration of large language models (LLMs) and artificial intelligence (AI) 
      into scientific writing, especially in medical literature, presents both 
      unprecedented opportunities and inherent challenges. This manuscript evaluates 
      the transformative potential of LLMs for the synthesis of information, linguistic 
      enhancements, and global knowledge dissemination. At the same time, it raises 
      concerns about unintentional plagiarism, the risk of misinformation, data biases, 
      and an over-reliance on AI. To address these, we propose governing principles for 
      AI adoption that ensure integrity, transparency, validity, and accountability. 
      Additionally, guidelines for reporting AI involvement in manuscript development 
      are delineated, and a classification system to specify the level of AI assistance 
      is introduced. This approach uniquely addresses the challenges of AI in 
      scientific writing, emphasizing transparency in authorship, qualification of AI 
      involvement, and ethical considerations. Concerns regarding access equity, 
      potential biases in AI-generated content, authorship dynamics, and accountability 
      are also explored, emphasizing the human author's continued responsibility. 
      Recommendations are made for fostering collaboration between AI developers, 
      researchers, and journal editors and for emphasizing the importance of AI's 
      responsible use in academic writing. Regular evaluations of AI's impact on the 
      quality and biases of medical manuscripts are also advocated. As we navigate the 
      expanding realm of AI in scientific discourse, it is crucial to maintain the 
      human element of creativity, ethics, and oversight, ensuring that the integrity 
      of scientific literature remains uncompromised.
CI  - Copyright © 2023 Hryciw, Seely and Kyeremanteng.
FAU - Hryciw, Brett N
AU  - Hryciw BN
AD  - Division of Critical Care, Department of Medicine, University of Ottawa, Ottawa, 
      ON, Canada.
FAU - Seely, Andrew J E
AU  - Seely AJE
AD  - Division of Thoracic Surgery, Department of Surgery, The Ottawa Hospital, Ottawa, 
      ON, Canada.
AD  - Clinical Epidemiology, Ottawa Hospital Research Institute, University of Ottawa, 
      Ottawa, ON, Canada.
FAU - Kyeremanteng, Kwadwo
AU  - Kyeremanteng K
AD  - Division of Critical Care, Department of Medicine, University of Ottawa, Ottawa, 
      ON, Canada.
AD  - Clinical Epidemiology, Ottawa Hospital Research Institute, University of Ottawa, 
      Ottawa, ON, Canada.
AD  - Institute du Savoir Montfort, Ottawa, ON, Canada.
LA  - eng
PT  - Journal Article
DEP - 20231116
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC10687472
OTO - NOTNLM
OT  - artificial intelligence
OT  - ethics
OT  - guidelines and recommendations
OT  - innovation
OT  - large language model
OT  - medicine
OT  - natural language processing
OT  - scientific writing
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/30 18:45
MHDA- 2023/11/30 18:46
PMCR- 2023/11/16
CRDT- 2023/11/30 17:46
PHST- 2023/08/25 00:00 [received]
PHST- 2023/10/17 00:00 [accepted]
PHST- 2023/11/30 18:46 [medline]
PHST- 2023/11/30 18:45 [pubmed]
PHST- 2023/11/30 17:46 [entrez]
PHST- 2023/11/16 00:00 [pmc-release]
AID - 10.3389/frai.2023.1283353 [doi]
PST - epublish
SO  - Front Artif Intell. 2023 Nov 16;6:1283353. doi: 10.3389/frai.2023.1283353. 
      eCollection 2023.

PMID- 39255797
OWN - NLM
STAT- MEDLINE
DCOM- 20241004
LR  - 20241019
IS  - 1537-6605 (Electronic)
IS  - 0002-9297 (Print)
IS  - 0002-9297 (Linking)
VI  - 111
IP  - 10
DP  - 2024 Oct 3
TI  - Assessing the utility of large language models for phenotype-driven gene 
      prioritization in the diagnosis of rare genetic disease.
PG  - 2190-2202
LID - S0002-9297(24)00296-9 [pii]
LID - 10.1016/j.ajhg.2024.08.010 [doi]
AB  - Phenotype-driven gene prioritization is fundamental to diagnosing rare genetic 
      disorders. While traditional approaches rely on curated knowledge graphs with 
      phenotype-gene relations, recent advancements in large language models (LLMs) 
      promise a streamlined text-to-gene solution. In this study, we evaluated five 
      LLMs, including two generative pre-trained transformers (GPT) series and three 
      Llama2 series, assessing their performance across task completeness, gene 
      prediction accuracy, and adherence to required output structures. We conducted 
      experiments, exploring various combinations of models, prompts, phenotypic input 
      types, and task difficulty levels. Our findings revealed that the best-performed 
      LLM, GPT-4, achieved an average accuracy of 17.0% in identifying diagnosed genes 
      within the top 50 predictions, which still falls behind traditional tools. 
      However, accuracy increased with the model size. Consistent results were observed 
      over time, as shown in the dataset curated after 2023. Advanced techniques such 
      as retrieval-augmented generation (RAG) and few-shot learning did not improve the 
      accuracy. Sophisticated prompts were more likely to enhance task completeness, 
      especially in smaller models. Conversely, complicated prompts tended to decrease 
      output structure compliance rate. LLMs also achieved better-than-random 
      prediction accuracy with free-text input, though performance was slightly lower 
      than with standardized concept input. Bias analysis showed that highly cited 
      genes, such as BRCA1, TP53, and PTEN, are more likely to be predicted. Our study 
      provides valuable insights into integrating LLMs with genomic analysis, 
      contributing to the ongoing discussion on their utilization in clinical 
      workflows.
CI  - Copyright © 2024 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Kim, Junyoung
AU  - Kim J
AD  - Department of Biomedical Informatics, Columbia University, New York, NY 10032, 
      USA.
FAU - Wang, Kai
AU  - Wang K
AD  - Raymond G. Perelman Center for Cellular and Molecular Therapeutics, Children's 
      Hospital of Philadelphia, Philadelphia, PA 19104, USA; Department of Pathology 
      and Laboratory Medicine, University of Pennsylvania, Philadelphia, PA 19104, USA.
FAU - Weng, Chunhua
AU  - Weng C
AD  - Department of Biomedical Informatics, Columbia University, New York, NY 10032, 
      USA. Electronic address: cw2384@cumc.columbia.edu.
FAU - Liu, Cong
AU  - Liu C
AD  - Department of Biomedical Informatics, Columbia University, New York, NY 10032, 
      USA. Electronic address: cl3720@cumc.columbia.edu.
LA  - eng
PT  - Journal Article
DEP - 20240909
PL  - United States
TA  - Am J Hum Genet
JT  - American journal of human genetics
JID - 0370475
SB  - IM
UOF - ArXiv. 2024 Apr 2:arXiv:2403.14801v2. PMID: 38562452
MH  - Humans
MH  - *Phenotype
MH  - *Rare Diseases/genetics
MH  - Computational Biology/methods
PMC - PMC11480789
OTO - NOTNLM
OT  - artificial intelligence
OT  - gene prioritization
OT  - generative pre-trained transformers
OT  - large language model
OT  - phenotypes
OT  - precision medicine
OT  - rare disease diagnosis
COIS- Declaration of interests The authors declare no competing interests.
EDAT- 2024/09/11 00:42
MHDA- 2024/10/05 11:43
PMCR- 2024/09/09
CRDT- 2024/09/10 18:42
PHST- 2024/04/17 00:00 [received]
PHST- 2024/08/08 00:00 [revised]
PHST- 2024/08/13 00:00 [accepted]
PHST- 2024/10/05 11:43 [medline]
PHST- 2024/09/11 00:42 [pubmed]
PHST- 2024/09/10 18:42 [entrez]
PHST- 2024/09/09 00:00 [pmc-release]
AID - S0002-9297(24)00296-9 [pii]
AID - 10.1016/j.ajhg.2024.08.010 [doi]
PST - ppublish
SO  - Am J Hum Genet. 2024 Oct 3;111(10):2190-2202. doi: 10.1016/j.ajhg.2024.08.010. 
      Epub 2024 Sep 9.

PMID- 39774560
OWN - NLM
STAT- MEDLINE
DCOM- 20250108
LR  - 20250111
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 20
IP  - 1
DP  - 2025
TI  - Schizophrenia more employable than depression? Language-based artificial 
      intelligence model ratings for employability of psychiatric diagnoses and somatic 
      and healthy controls.
PG  - e0315768
LID - 10.1371/journal.pone.0315768 [doi]
LID - e0315768
AB  - Artificial Intelligence (AI) assists recruiting and job searching. Such systems 
      can be biased against certain characteristics. This results in potential 
      misrepresentations and consequent inequalities related to people with mental 
      health disorders. Hence occupational and mental health bias in existing Natural 
      Language Processing (NLP) models used in recruiting and job hunting must be 
      assessed. We examined occupational bias against mental health disorders in NLP 
      models through relationships between occupations, employability, and psychiatric 
      diagnoses. We investigated Word2Vec and GloVe embedding algorithms through 
      analogy questions and graphical representation of cosine similarities. Word2Vec 
      embeddings exhibit minor bias against mental health disorders when asked 
      analogies regarding employability attributes and no evidence of bias when asked 
      analogies regarding high earning jobs. GloVe embeddings view common mental health 
      disorders such as depression less healthy and less employable than severe mental 
      health disorders and most physical health conditions. Overall, physical, and 
      psychiatric disorders are seen as similarly healthy and employable. Both 
      algorithms appear to be safe for use in downstream task without major 
      repercussions. Further research is needed to confirm this. This project was 
      funded by the London Interdisciplinary Social Science Doctoral Training Programme 
      (LISS-DTP). The funders had no role in study design, data collection and 
      analysis, decision to publish, or preparation of the manuscript.
CI  - Copyright: © 2025 Lange et al. This is an open access article distributed under 
      the terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Lange, Maximin
AU  - Lange M
AUID- ORCID: 0000-0002-6253-8741
AD  - Institute of Psychiatry, Psychology & Neuroscience, King's College London, 
      London, United Kingdom.
FAU - Koliousis, Alexandros
AU  - Koliousis A
AD  - Northeastern University, London, United Kingdom.
FAU - Fayez, Feras
AU  - Fayez F
AD  - King's College Hospital NHS Foundation Trust, London, United Kingdom.
AD  - Imperial College Healthcare NHS Trust, London, United Kingdom.
FAU - Gogarty, Eoin
AU  - Gogarty E
AD  - Institute of Psychiatry, Psychology & Neuroscience, King's College London, 
      London, United Kingdom.
AD  - King's College Hospital NHS Foundation Trust, London, United Kingdom.
FAU - Twumasi, Ricardo
AU  - Twumasi R
AUID- ORCID: 0000-0002-0194-7250
AD  - Institute of Psychiatry, Psychology & Neuroscience, King's College London, 
      London, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20250108
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Depression/diagnosis/psychology
MH  - *Natural Language Processing
MH  - *Schizophrenia/diagnosis
MH  - Algorithms
MH  - Employment
MH  - Language
PMC - PMC11709238
COIS- N/A.
EDAT- 2025/01/08 18:22
MHDA- 2025/01/08 18:23
PMCR- 2025/01/08
CRDT- 2025/01/08 16:14
PHST- 2024/01/03 00:00 [received]
PHST- 2024/11/30 00:00 [accepted]
PHST- 2025/01/08 18:23 [medline]
PHST- 2025/01/08 18:22 [pubmed]
PHST- 2025/01/08 16:14 [entrez]
PHST- 2025/01/08 00:00 [pmc-release]
AID - PONE-D-24-00286 [pii]
AID - 10.1371/journal.pone.0315768 [doi]
PST - epublish
SO  - PLoS One. 2025 Jan 8;20(1):e0315768. doi: 10.1371/journal.pone.0315768. 
      eCollection 2025.

PMID- 34892329
OWN - NLM
STAT- MEDLINE
DCOM- 20220103
LR  - 20220103
IS  - 2694-0604 (Electronic)
IS  - 2375-7477 (Linking)
VI  - 2021
DP  - 2021 Nov
TI  - Home-based Digital Assessments with Applied Sentiment & Emotion AI Capture 
      Improved Quality-of-life in Asthma Patients.
PG  - 4994-4997
LID - 10.1109/EMBC46164.2021.9629985 [doi]
AB  - With the rise of digital transformation in the pharmaceutical industry, digital 
      therapeutics are being integrated in drug development clinical trials. In the 
      TWINKLE study, information about asthmatic patients' disease control and 
      quality-of-life (QoL) was measured by daily video recording, in conjunction with 
      daily electronic questionnaires and home-based spirometry. From the video 
      messages, sentiment and emotion AI was applied to detect subtle QoL changes in 
      asthmatic patients after receiving treatments. Sentiment scores, derived from 
      patients' daily messages via natural language processing, correlated strongly 
      with metrics of lung functions and outcomes of electronic questionnaires. 
      However, video-derived emotional analysis exhibited strong interpersonal 
      variations and systematic biases, yet still showed utility in detecting QoL 
      changes after personalized calibration and signal aggregation. Compared to 
      traditional patient-reported outcomes, all three categories of digital 
      measurements were able to detect significantly improved asthma control from 
      patients who responded to treatments. The result provides insights into 
      developing novel digital outcomes through the application of connected digital 
      devices and advanced AI tailored to clinical settings.Clinical relevance- Digital 
      outcomes involving connected digital devices and AI for sentiment/emotion 
      analysis could capture subtle QoL changes reliably and earlier than hospital 
      visits, reducing burden and improving disease management. Integrating digital 
      therapeutics in asthma drug development trials may prove to be feasible and 
      valuable.
FAU - Zhang, Bo
AU  - Zhang B
FAU - Buendia, Ruben
AU  - Buendia R
FAU - Iannoti, Nicholas
AU  - Iannoti N
FAU - Ramsden, Emma
AU  - Ramsden E
FAU - O'Regan, Paul
AU  - O'Regan P
FAU - Swift, Jason
AU  - Swift J
FAU - Lockwood, Sarah
AU  - Lockwood S
FAU - Jackson, David J
AU  - Jackson DJ
FAU - Dennis, Glynn
AU  - Dennis G
FAU - Hagger, Lynn
AU  - Hagger L
FAU - Havsol, Jesper
AU  - Havsol J
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Annu Int Conf IEEE Eng Med Biol Soc
JT  - Annual International Conference of the IEEE Engineering in Medicine and Biology 
      Society. IEEE Engineering in Medicine and Biology Society. Annual International 
      Conference
JID - 101763872
SB  - IM
MH  - *Asthma/drug therapy
MH  - Attitude
MH  - Emotions
MH  - Humans
MH  - Natural Language Processing
MH  - *Quality of Life
EDAT- 2021/12/12 06:00
MHDA- 2022/01/04 06:00
CRDT- 2021/12/11 01:04
PHST- 2021/12/11 01:04 [entrez]
PHST- 2021/12/12 06:00 [pubmed]
PHST- 2022/01/04 06:00 [medline]
AID - 10.1109/EMBC46164.2021.9629985 [doi]
PST - ppublish
SO  - Annu Int Conf IEEE Eng Med Biol Soc. 2021 Nov;2021:4994-4997. doi: 
      10.1109/EMBC46164.2021.9629985.

PMID- 39061736
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240729
IS  - 2306-5354 (Print)
IS  - 2306-5354 (Electronic)
IS  - 2306-5354 (Linking)
VI  - 11
IP  - 7
DP  - 2024 Jun 27
TI  - The Emerging Role of Large Language Models in Improving Prostate Cancer Literacy.
LID - 10.3390/bioengineering11070654 [doi]
LID - 654
AB  - This study assesses the effectiveness of chatbots powered by Large Language 
      Models (LLMs)-ChatGPT 3.5, CoPilot, and Gemini-in delivering prostate cancer 
      information, compared to the official Patient's Guide. Using 25 expert-validated 
      questions, we conducted a comparative analysis to evaluate accuracy, timeliness, 
      completeness, and understandability through a Likert scale. Statistical analyses 
      were used to quantify the performance of each model. Results indicate that 
      ChatGPT 3.5 consistently outperformed the other models, establishing itself as a 
      robust and reliable source of information. CoPilot also performed effectively, 
      albeit slightly less so than ChatGPT 3.5. Despite the strengths of the Patient's 
      Guide, the advanced capabilities of LLMs like ChatGPT significantly enhance 
      educational tools in healthcare. The findings underscore the need for ongoing 
      innovation and improvement in AI applications within health sectors, especially 
      considering the ethical implications underscored by the forthcoming EU AI Act. 
      Future research should focus on investigating potential biases in AI-generated 
      responses and their impact on patient outcomes.
FAU - Geantă, Marius
AU  - Geantă M
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Center for Innovation in Medicine, 42J Theodor Pallady Blvd., 032266 Bucharest, 
      Romania.
FAU - Bădescu, Daniel
AU  - Bădescu D
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Chirca, Narcis
AU  - Chirca N
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Nechita, Ovidiu Cătălin
AU  - Nechita OC
AUID- ORCID: 0009-0002-5920-7287
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Radu, Cosmin George
AU  - Radu CG
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Rascu, Ștefan
AU  - Rascu Ș
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Rădăvoi, Daniel
AU  - Rădăvoi D
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Sima, Cristian
AU  - Sima C
AUID- ORCID: 0000-0003-2508-2551
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Toma, Cristian
AU  - Toma C
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Department of Urology, "Prof. Dr. Th. Burghele" Clinical Hospital, 20 Panduri 
      Str., 050659 Bucharest, Romania.
FAU - Jinga, Viorel
AU  - Jinga V
AUID- ORCID: 0000-0001-7632-5328
AD  - Department of Urology, "Carol Davila" University of Medicine and Pharmacy, 8 
      Eroii Sanitari Blvd., 050474 Bucharest, Romania.
AD  - Academy of Romanian Scientists, 3 Ilfov, 050085 Bucharest, Romania.
LA  - eng
PT  - Journal Article
DEP - 20240627
PL  - Switzerland
TA  - Bioengineering (Basel)
JT  - Bioengineering (Basel, Switzerland)
JID - 101676056
PMC - PMC11274300
OTO - NOTNLM
OT  - ChatGPT
OT  - CoPilot
OT  - Gemini
OT  - cancer literacy
OT  - large language models
OT  - prostate cancer
COIS- The authors declare no conflicts of interest.
EDAT- 2024/07/27 10:44
MHDA- 2024/07/27 10:45
PMCR- 2024/06/27
CRDT- 2024/07/27 01:05
PHST- 2024/05/21 00:00 [received]
PHST- 2024/06/18 00:00 [revised]
PHST- 2024/06/24 00:00 [accepted]
PHST- 2024/07/27 10:45 [medline]
PHST- 2024/07/27 10:44 [pubmed]
PHST- 2024/07/27 01:05 [entrez]
PHST- 2024/06/27 00:00 [pmc-release]
AID - bioengineering11070654 [pii]
AID - bioengineering-11-00654 [pii]
AID - 10.3390/bioengineering11070654 [doi]
PST - epublish
SO  - Bioengineering (Basel). 2024 Jun 27;11(7):654. doi: 
      10.3390/bioengineering11070654.

PMID- 40129115
OWN - NLM
STAT- Publisher
LR  - 20250325
IS  - 1365-2648 (Electronic)
IS  - 0309-2402 (Linking)
DP  - 2025 Mar 24
TI  - An AI-Enabled Nursing Future With no Documentation Burden: A Vision for a New 
      Reality.
LID - 10.1111/jan.16911 [doi]
AB  - AIMS: To explore the potential of multimodal large language models in alleviating 
      the documentation burden on nurses while enhancing the quality and efficiency of 
      patient care. DESIGN: This position paper is informed by expert discussions and a 
      literature review. METHODS: We extensively reviewed nursing documentation 
      practices and advanced technologies, such as multimodal large language models. We 
      analysed key challenges, solutions and impacts to propose a futuristic multimodal 
      large language model-driven model for nursing documentation. RESULTS: Multimodal 
      large language models offer transformative capabilities by integrating multimodal 
      audio, video and text data during patient encounters to dynamically update 
      patient records in real time. This reduces manual data entry, enabling nurses to 
      focus more on direct patient care. These systems also enhance care 
      personalisation through predictive analytics and interoperability, which support 
      seamless workflows and better patient outcomes. While predictive analytics could 
      improve patient care by identifying trends and risk factors from nursing 
      documentation, further research is required to validate its accuracy and clinical 
      utility in real-world settings. Ethical, legal and practical challenges, 
      including privacy concerns and biases in artificial intelligence models, require 
      careful consideration for successful implementation. CONCLUSION: Transitioning to 
      multimodal large language model-driven documentation systems can significantly 
      reduce administrative burdens, improve nurse satisfaction and enhance patient 
      care. However, successful integration demands interdisciplinary collaboration, 
      robust ethical frameworks and technological advancements. IMPLICATIONS FOR THE 
      PROFESSION AND PATIENT CARE: Implementing multimodal large language models could 
      alleviate professional burnout, improve nurse-patient interactions, and provide 
      dynamic, up-to-date patient records that facilitate informed decision making. 
      These advancements align with the goals of patient-centred care by enabling more 
      meaningful engagement between nurses and patients. IMPACT: The problem being 
      addressed is the administrative burden of nursing documentation. We suggest that 
      multimodal large language models minimise manual documentation, enhance patient 
      care quality and significantly impact nurses and patients in diverse healthcare 
      settings globally.
CI  - © 2025 The Author(s). Journal of Advanced Nursing published by John Wiley & Sons 
      Ltd.
FAU - Michalowski, Martin
AU  - Michalowski M
AUID- ORCID: 0000-0003-2060-5878
AD  - School of Nursing, University of Minnesota, Minneapolis, Minnesota, USA.
FAU - Topaz, Maxim
AU  - Topaz M
AD  - School of Nursing, Columbia University, New York, New York, USA.
FAU - Peltonen, Laura Maria
AU  - Peltonen LM
AD  - Department of Health and Social Management, University of Eastern Finland, 
      Wellbeing Services County of North Savo, Kuopio, Finland.
LA  - eng
PT  - Journal Article
DEP - 20250324
PL  - England
TA  - J Adv Nurs
JT  - Journal of advanced nursing
JID - 7609811
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence in healthcare
OT  - healthcare innovation
OT  - multimodal large language models
OT  - nurse burnout
OT  - nursing
OT  - nursing documentation
OT  - patient‐centered care
EDAT- 2025/03/25 06:25
MHDA- 2025/03/25 06:25
CRDT- 2025/03/25 02:13
PHST- 2025/02/26 00:00 [revised]
PHST- 2024/12/18 00:00 [received]
PHST- 2025/03/08 00:00 [accepted]
PHST- 2025/03/25 06:25 [medline]
PHST- 2025/03/25 06:25 [pubmed]
PHST- 2025/03/25 02:13 [entrez]
AID - 10.1111/jan.16911 [doi]
PST - aheadofprint
SO  - J Adv Nurs. 2025 Mar 24. doi: 10.1111/jan.16911.

PMID- 37130009
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231024
IS  - 1938-808X (Electronic)
IS  - 1040-2446 (Linking)
VI  - 98
IP  - 9
DP  - 2023 Sep 1
TI  - Medical School Admissions: Focusing on Producing a Physician Workforce That 
      Addresses the Needs of the United States.
PG  - 983-986
LID - 10.1097/ACM.0000000000005262 [doi]
AB  - The aging population, burnout, and earlier retirement of physicians along with 
      the static number of training positions are likely to worsen the current 
      physician shortage. There is an urgent need to transform the process for 
      selecting medical students. In this Invited Commentary, the authors suggest that 
      to build the physician workforce that the United States needs for the future, 
      academic medicine should focus on building capacity in 3 overarching areas. 
      First, medical schools need to develop a more diverse pool of capable applicants 
      that better matches the demographic characteristics of health care trainees with 
      those of the population, and they need to nurture applicants with diverse career 
      aspirations. Second, medical schools should recalibrate their student selection 
      process, aligning criteria for admission with competencies expected of medical 
      school graduates, whether they choose to become practicing clinicians, 
      physician-scientists, members of the public health workforce, or policy makers. 
      Selection criteria that overweight the results of standardized test scores should 
      be replaced by assessments that value and predict academic capacity, adaptive 
      learning skills, curiosity, compassion, empathy, emotional maturity, and superior 
      communication skills. Finally, to improve the equity and effectiveness of the 
      selection processes, medical schools should leverage innovations in data science 
      and generative artificial intelligence platforms. The ability of ChatGPT to pass 
      the United States Medical Licensing Examination (USMLE) demonstrates the 
      decreasing importance of memorization in medicine in favor of critical thinking 
      and problem-solving skills. The 2022 change in the USMLE Step 1 to pass/fail plus 
      the exodus of several prominent medical schools from the U.S. News and World 
      Report rankings have exposed limitations of the current selection processes. 
      Newer approaches that use precision education systems to leverage data and 
      technology can help address these limitations.
CI  - Copyright © 2023 by the Association of American Medical Colleges.
FAU - Prober, Charles G
AU  - Prober CG
AD  - C.G. Prober is professor of pediatrics, microbiology, and immunology, and senior 
      associate vice provost for health education, Stanford University, Stanford, 
      California.
FAU - Desai, Sanjay V
AU  - Desai SV
AD  - S.V. Desai is chief academic officer, American Medical Association, Washington, 
      DC, and professor of medicine, Johns Hopkins University, Baltimore, Maryland.
LA  - eng
PT  - Journal Article
DEP - 20230427
PL  - United States
TA  - Acad Med
JT  - Academic medicine : journal of the Association of American Medical Colleges
JID - 8904605
SB  - IM
MH  - Humans
MH  - United States
MH  - Aged
MH  - *Schools, Medical
MH  - Artificial Intelligence
MH  - *Physicians
MH  - Workforce
MH  - School Admission Criteria
EDAT- 2023/05/02 18:42
MHDA- 2023/10/23 12:42
CRDT- 2023/05/02 12:23
PHST- 2023/10/23 12:42 [medline]
PHST- 2023/05/02 18:42 [pubmed]
PHST- 2023/05/02 12:23 [entrez]
AID - 00001888-990000000-00437 [pii]
AID - 10.1097/ACM.0000000000005262 [doi]
PST - ppublish
SO  - Acad Med. 2023 Sep 1;98(9):983-986. doi: 10.1097/ACM.0000000000005262. Epub 2023 
      Apr 27.

PMID- 39968063
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250220
IS  - 2673-253X (Electronic)
IS  - 2673-253X (Linking)
VI  - 7
DP  - 2025
TI  - The externalization of internal experiences in psychotherapy through generative 
      artificial intelligence: a theoretical, clinical, and ethical analysis.
PG  - 1512273
LID - 10.3389/fdgth.2025.1512273 [doi]
LID - 1512273
AB  - INTRODUCTION: Externalization techniques are well established in psychotherapy 
      approaches, including narrative therapy and cognitive behavioral therapy. These 
      methods elicit internal experiences such as emotions and make them tangible 
      through external representations. Recent advances in generative artificial 
      intelligence (GenAI), specifically large language models (LLMs), present new 
      possibilities for therapeutic interventions; however, their integration into core 
      psychotherapy practices remains largely unexplored. This study aimed to examine 
      the clinical, ethical, and theoretical implications of integrating GenAI into the 
      therapeutic space through a proof-of-concept (POC) of AI-driven externalization 
      techniques, while emphasizing the essential role of the human therapist. METHODS: 
      To this end, we developed two customized GPTs agents: VIVI (visual 
      externalization), which uses DALL-E 3 to create images reflecting patients' 
      internal experiences (e.g., depression or hope), and DIVI (dialogic 
      role-play-based externalization), which simulates conversations with aspects of 
      patients' internal content. These tools were implemented and evaluated through a 
      clinical case study under professional psychological guidance. RESULTS: The 
      integration of VIVI and DIVI demonstrated that GenAI can serve as an "artificial 
      third", creating a Winnicottian playful space that enhances, rather than 
      supplants, the dyadic therapist-patient relationship. The tools successfully 
      externalized complex internal dynamics, offering new therapeutic avenues, while 
      also revealing challenges such as empathic failures and cultural biases. 
      DISCUSSION: These findings highlight both the promise and the ethical 
      complexities of AI-enhanced therapy, including concerns about data security, 
      representation accuracy, and the balance of clinical authority. To address these 
      challenges, we propose the SAFE-AI protocol, offering clinicians structured 
      guidelines for responsible AI integration in therapy. Future research should 
      systematically evaluate the generalizability, efficacy, and ethical implications 
      of these tools across diverse populations and therapeutic contexts.
CI  - © 2025 Haber, Hadar Shoval, Levkovich, Yinon, Gigi, Pen, Angert and Elyoseph.
FAU - Haber, Yuval
AU  - Haber Y
AD  - The Program of Hermeneutics and Cultural Studies, Interdisciplinary Studies Unit, 
      Bar-Ilan University, Jerusalem, Israel.
FAU - Hadar Shoval, Dorit
AU  - Hadar Shoval D
AD  - Department of Psychology, Max Stern Academic College of Emek Yezreel, Yezreel 
      Valley, Israel.
FAU - Levkovich, Inbar
AU  - Levkovich I
AD  - Faculty of Education, Tel-Hai Academic College, Kiryat Shmona, Israel.
FAU - Yinon, Dror
AU  - Yinon D
AD  - The Program of Hermeneutics and Cultural Studies, Interdisciplinary Studies Unit, 
      Bar-Ilan University, Jerusalem, Israel.
FAU - Gigi, Karny
AU  - Gigi K
AD  - Department of Counseling and Human Development, Faculty of Education, University 
      of Haifa, Haifa, Israel.
FAU - Pen, Oori
AU  - Pen O
AD  - Department of Counseling and Human Development, Faculty of Education, University 
      of Haifa, Haifa, Israel.
FAU - Angert, Tal
AU  - Angert T
AD  - Department of Counseling and Human Development, Faculty of Education, University 
      of Haifa, Haifa, Israel.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AD  - Department of Counseling and Human Development, Faculty of Education, University 
      of Haifa, Haifa, Israel.
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, 
      London, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20250204
PL  - Switzerland
TA  - Front Digit Health
JT  - Frontiers in digital health
JID - 101771889
PMC - PMC11832678
OTO - NOTNLM
OT  - SAFE-AI protocol
OT  - clinical implementation
OT  - ethical considerations
OT  - externalization techniques
OT  - generative artificial intelligence (GenAI)
OT  - psychotherapy
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest. The author(s) declared that they were an editorial board 
      member of Frontiers, at the time of submission. This had no impact on the peer 
      review process and the final decision.
EDAT- 2025/02/19 06:22
MHDA- 2025/02/19 06:23
PMCR- 2025/02/04
CRDT- 2025/02/19 04:30
PHST- 2024/10/16 00:00 [received]
PHST- 2025/01/14 00:00 [accepted]
PHST- 2025/02/19 06:23 [medline]
PHST- 2025/02/19 06:22 [pubmed]
PHST- 2025/02/19 04:30 [entrez]
PHST- 2025/02/04 00:00 [pmc-release]
AID - 10.3389/fdgth.2025.1512273 [doi]
PST - epublish
SO  - Front Digit Health. 2025 Feb 4;7:1512273. doi: 10.3389/fdgth.2025.1512273. 
      eCollection 2025.

PMID- 38261378
OWN - NLM
STAT- MEDLINE
DCOM- 20240125
LR  - 20240701
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Jan 23
TI  - Assessing ChatGPT's Mastery of Bloom's Taxonomy Using Psychosomatic Medicine Exam 
      Questions: Mixed-Methods Study.
PG  - e52113
LID - 10.2196/52113 [doi]
LID - e52113
AB  - BACKGROUND: Large language models such as GPT-4 (Generative Pre-trained 
      Transformer 4) are being increasingly used in medicine and medical education. 
      However, these models are prone to "hallucinations" (ie, outputs that seem 
      convincing while being factually incorrect). It is currently unknown how these 
      errors by large language models relate to the different cognitive levels defined 
      in Bloom's taxonomy. OBJECTIVE: This study aims to explore how GPT-4 performs in 
      terms of Bloom's taxonomy using psychosomatic medicine exam questions. METHODS: 
      We used a large data set of psychosomatic medicine multiple-choice questions 
      (N=307) with real-world results derived from medical school exams. GPT-4 answered 
      the multiple-choice questions using 2 distinct prompt versions: detailed and 
      short. The answers were analyzed using a quantitative approach and a qualitative 
      approach. Focusing on incorrectly answered questions, we categorized reasoning 
      errors according to the hierarchical framework of Bloom's taxonomy. RESULTS: 
      GPT-4's performance in answering exam questions yielded a high success rate: 93% 
      (284/307) for the detailed prompt and 91% (278/307) for the short prompt. 
      Questions answered correctly by GPT-4 had a statistically significant higher 
      difficulty than questions answered incorrectly (P=.002 for the detailed prompt 
      and P<.001 for the short prompt). Independent of the prompt, GPT-4's lowest exam 
      performance was 78.9% (15/19), thereby always surpassing the "pass" threshold. 
      Our qualitative analysis of incorrect answers, based on Bloom's taxonomy, showed 
      that errors were primarily in the "remember" (29/68) and "understand" (23/68) 
      cognitive levels; specific issues arose in recalling details, understanding 
      conceptual relationships, and adhering to standardized guidelines. CONCLUSIONS: 
      GPT-4 demonstrated a remarkable success rate when confronted with psychosomatic 
      medicine multiple-choice exam questions, aligning with previous findings. When 
      evaluated through Bloom's taxonomy, our data revealed that GPT-4 occasionally 
      ignored specific facts (remember), provided illogical reasoning (understand), or 
      failed to apply concepts to a new situation (apply). These errors, which were 
      confidently presented, could be attributed to inherent model biases and the 
      tendency to generate outputs that maximize likelihood.
CI  - ©Anne Herrmann-Werner, Teresa Festl-Wietek, Friederike Holderried, Lea 
      Herschbach, Jan Griewatz, Ken Masters, Stephan Zipfel, Moritz Mahling. Originally 
      published in the Journal of Medical Internet Research (https://www.jmir.org), 
      23.01.2024.
FAU - Herrmann-Werner, Anne
AU  - Herrmann-Werner A
AUID- ORCID: 0000-0003-2413-7047
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of 
      Tübingen, Tübingen, Germany.
AD  - Department of Psychosomatic Medicine and Psychotherapy, University Hospital 
      Tübingen, Tübingen, Germany.
FAU - Festl-Wietek, Teresa
AU  - Festl-Wietek T
AUID- ORCID: 0000-0003-1450-1757
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of 
      Tübingen, Tübingen, Germany.
FAU - Holderried, Friederike
AU  - Holderried F
AUID- ORCID: 0000-0003-1828-0920
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of 
      Tübingen, Tübingen, Germany.
AD  - University Department of Anesthesiology and Intensive Care Medicine, University 
      Hospital Tübingen, Tübingen, Germany.
FAU - Herschbach, Lea
AU  - Herschbach L
AUID- ORCID: 0009-0005-6378-5073
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of 
      Tübingen, Tübingen, Germany.
FAU - Griewatz, Jan
AU  - Griewatz J
AUID- ORCID: 0000-0002-9731-3171
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of 
      Tübingen, Tübingen, Germany.
FAU - Masters, Ken
AU  - Masters K
AUID- ORCID: 0000-0003-3425-5020
AD  - Medical Education and Informatics Department, College of Medicine and Health 
      Sciences, Sultan Qaboos University, Muscat, Oman.
FAU - Zipfel, Stephan
AU  - Zipfel S
AUID- ORCID: 0000-0003-1659-4440
AD  - Department of Psychosomatic Medicine and Psychotherapy, University Hospital 
      Tübingen, Tübingen, Germany.
FAU - Mahling, Moritz
AU  - Mahling M
AUID- ORCID: 0000-0001-7960-4015
AD  - Tübingen Institute for Medical Education, Faculty of Medicine, University of 
      Tübingen, Tübingen, Germany.
AD  - Department of Diabetology, Endocrinology, Nephrology, Section of Nephrology and 
      Hypertension, University Hospital Tübingen, Tübingen, Germany.
LA  - eng
PT  - Journal Article
DEP - 20240123
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
CIN - J Med Internet Res. 2024 Apr 16;26:e56997. doi: 10.2196/56997. PMID: 38625725
MH  - Humans
MH  - *Education, Medical
MH  - *Medicine
MH  - *Psychosomatic Medicine
MH  - Research Design
PMC - PMC10848129
OTO - NOTNLM
OT  - Bloom’s taxonomy
OT  - ChatGPT
OT  - GPT-4
OT  - Generative Pre-trained Transformer 4
OT  - LLM
OT  - MCQ
OT  - NLP
OT  - answer
OT  - artificial intelligence
OT  - assessment
OT  - classification
OT  - error
OT  - exam
OT  - examination
OT  - generative
OT  - language model
OT  - learning outcome
OT  - medical education
OT  - medical exam
OT  - multiple-choice question
OT  - natural language processing
OT  - psychosomatic
OT  - question
OT  - response
OT  - taxonomy
COIS- Conflicts of Interest: None declared.
EDAT- 2024/01/23 12:43
MHDA- 2024/01/24 06:43
PMCR- 2024/01/23
CRDT- 2024/01/23 11:54
PHST- 2023/08/23 00:00 [received]
PHST- 2023/12/07 00:00 [accepted]
PHST- 2023/09/15 00:00 [revised]
PHST- 2024/01/24 06:43 [medline]
PHST- 2024/01/23 12:43 [pubmed]
PHST- 2024/01/23 11:54 [entrez]
PHST- 2024/01/23 00:00 [pmc-release]
AID - v26i1e52113 [pii]
AID - 10.2196/52113 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Jan 23;26:e52113. doi: 10.2196/52113.

PMID- 39724920
OWN - NLM
STAT- MEDLINE
DCOM- 20250121
LR  - 20250125
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 32
IP  - 2
DP  - 2025 Feb 1
TI  - CARE-SD: classifier-based analysis for recognizing provider stigmatizing and 
      doubt marker labels in electronic health records: model development and 
      validation.
PG  - 365-374
LID - 10.1093/jamia/ocae310 [doi]
AB  - OBJECTIVE: To detect and classify features of stigmatizing and biased language in 
      intensive care electronic health records (EHRs) using natural language processing 
      techniques. MATERIALS AND METHODS: We first created a lexicon and regular 
      expression lists from literature-driven stem words for linguistic features of 
      stigmatizing patient labels, doubt markers, and scare quotes within EHRs. The 
      lexicon was further extended using Word2Vec and GPT 3.5, and refined through 
      human evaluation. These lexicons were used to search for matches across 18 
      million sentences from the de-identified Medical Information Mart for Intensive 
      Care-III (MIMIC-III) dataset. For each linguistic bias feature, 1000 sentence 
      matches were sampled, labeled by expert clinical and public health annotators, 
      and used to supervised learning classifiers. RESULTS: Lexicon development from 
      expanded literature stem-word lists resulted in a doubt marker lexicon containing 
      58 expressions, and a stigmatizing labels lexicon containing 127 expressions. 
      Classifiers for doubt markers and stigmatizing labels had the highest 
      performance, with macro F1-scores of 0.84 and 0.79, positive-label recall and 
      precision values ranging from 0.71 to 0.86, and accuracies aligning closely with 
      human annotator agreement (0.87). DISCUSSION: This study demonstrated the 
      feasibility of supervised classifiers in automatically identifying stigmatizing 
      labels and doubt markers in medical text and identified trends in stigmatizing 
      language use in an EHR setting. Additional labeled data may help improve lower 
      scare quote model performance. CONCLUSIONS: Classifiers developed in this study 
      showed high model performance and can be applied to identify patterns and target 
      interventions to reduce stigmatizing labels and doubt markers in healthcare 
      systems.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Walker, Andrew
AU  - Walker A
AUID- ORCID: 0000-0002-4216-2396
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA 30322, United States.
FAU - Thorne, Annie
AU  - Thorne A
AD  - Department of Infectious Disease, Children's Healthcare of Atlanta, Atlanta, GA 
      30329, United States.
FAU - Das, Sudeshna
AU  - Das S
AUID- ORCID: 0000-0002-2112-6986
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA 30322, United States.
FAU - Love, Jennifer
AU  - Love J
AD  - Department of Emergency Medicine, Mount Sinai, New York, NY 10029, United States.
FAU - Cooper, Hannah L F
AU  - Cooper HLF
AD  - Department of Behavioral, Social, Health Education Sciences, Rollins School of 
      Public Health, Emory University, Atlanta, GA 30322, United States.
FAU - Livingston, Melvin 3rd
AU  - Livingston M 3rd
AD  - Department of Behavioral, Social, Health Education Sciences, Rollins School of 
      Public Health, Emory University, Atlanta, GA 30322, United States.
FAU - Sarker, Abeed
AU  - Sarker A
AUID- ORCID: 0000-0001-7358-544X
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA 30322, United States.
AD  - Department of Biomedical Engineering, Georgia Institute of Technology and Emory 
      University, Atlanta, GA 30332, United States.
LA  - eng
GR  - R01 DA057599/DA/NIDA NIH HHS/United States
GR  - NIH/
GR  - T32DA0505552/DA/NIDA NIH HHS/United States
GR  - NIDA/
PT  - Journal Article
PT  - Validation Study
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - *Electronic Health Records
MH  - *Natural Language Processing
MH  - Humans
MH  - Stereotyping
MH  - Supervised Machine Learning
PMC - PMC11756621
OTO - NOTNLM
OT  - electronic health record
OT  - natural language processing
OT  - stigma
OT  - text classification
COIS- The authors have no competing interests to share.
EDAT- 2024/12/27 00:20
MHDA- 2025/01/22 05:32
PMCR- 2024/12/26
CRDT- 2024/12/26 18:53
PHST- 2024/05/09 00:00 [received]
PHST- 2024/11/14 00:00 [revised]
PHST- 2024/12/10 00:00 [accepted]
PHST- 2025/01/22 05:32 [medline]
PHST- 2024/12/27 00:20 [pubmed]
PHST- 2024/12/26 18:53 [entrez]
PHST- 2024/12/26 00:00 [pmc-release]
AID - 7933303 [pii]
AID - ocae310 [pii]
AID - 10.1093/jamia/ocae310 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2025 Feb 1;32(2):365-374. doi: 10.1093/jamia/ocae310.

PMID- 38502320
OWN - NLM
STAT- MEDLINE
DCOM- 20240516
LR  - 20241104
IS  - 1432-1076 (Electronic)
IS  - 0340-6199 (Print)
IS  - 0340-6199 (Linking)
VI  - 183
IP  - 6
DP  - 2024 Jun
TI  - Screening/diagnosis of pediatric endocrine disorders through the artificial 
      intelligence model in different language settings.
PG  - 2655-2661
LID - 10.1007/s00431-024-05527-1 [doi]
AB  - This study is aimed at examining the impact of ChatGPT on pediatric endocrine and 
      metabolic conditions, particularly in the areas of screening and diagnosis, in 
      both Chinese and English modes. A 40-question questionnaire covering the four 
      most common pediatric endocrine and metabolic conditions was posed to ChatGPT in 
      both Chinese and English three times each. Six pediatric endocrinologists 
      evaluated the responses. ChatGPT performed better when responding to questions in 
      English, with an unreliable rate of 7.5% compared to 27.5% for Chinese questions, 
      indicating a more consistent response pattern in English. Among the reliable 
      questions, the answers were more comprehensive and satisfactory in the English 
      mode. We also found disparities in ChatGPT's performance when interacting with 
      different target groups and diseases, with improved performance for questions 
      posed by clinicians in English and better performance for questions related to 
      diabetes and overweight/obesity in Chinese for both clinicians and patients. 
      Language comprehension, providing incomprehensive answers, and errors in key data 
      were the main contributors to the low scores, according to reviewer feedback. 
      CONCLUSION: Despite these limitations, as ChatGPT continues to evolve and expand 
      its network, it has significant potential as a practical and effective tool for 
      clinical diagnosis and treatment. WHAT IS KNOWN: • The deep learning-based 
      large-language model ChatGPT holds great promise for improving clinical practice 
      for both physicians and patients and has the potential to increase the speed and 
      accuracy of disease screening and diagnosis, as well as enhance the overall 
      efficiency of the medical process. However, the reliability and appropriateness 
      of AI model responses in specific field remains unclear. • This study focused on 
      the reliability and appropriateness of AI model responses to straightforward and 
      fundamental questions related to the four most prevalent pediatric endocrine and 
      metabolic disorders, for both healthcare providers and patients, in different 
      language scenarios. WHAT IS NEW: • The AI model performed better when responding 
      to questions in English, with more consistent, as well as more comprehensive and 
      satisfactory responses. In addition, we also found disparities in ChatGPT's 
      performance when interacting with different target groups and different diseases. 
      • Despite these limitations, as ChatGPT continues to evolve and expand its 
      network, it has significant potential as a practical and effective tool for 
      clinical diagnosis and treatment.
CI  - © 2024. The Author(s).
FAU - Ying, Lingwen
AU  - Ying L
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Li, Sichen
AU  - Li S
AD  - Department of Neurosurgery, Huashan Hospital, Shanghai Medical College, Fudan 
      University, Shanghai, 200040, China.
AD  - National Center for Neurological Disorders, Shanghai Key Laboratory of Brain 
      Function and Restoration and Neural Regeneration, Neurosurgical Institute of 
      Fudan University, Shanghai Clinical Medical Center of Neurosurgery, Shanghai, 
      200040, China.
FAU - Chen, Chunyang
AU  - Chen C
AD  - Faculty of Information Technology, Monash University, Clayton, VIC, 3800, 
      Australia.
FAU - Yang, Fan
AU  - Yang F
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Li, Xin
AU  - Li X
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Chen, Yao
AU  - Chen Y
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Ding, Yu
AU  - Ding Y
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Chang, Guoying
AU  - Chang G
AUID- ORCID: 0000-0003-0701-3544
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China. 
      wangxiumin1019@126.com.
FAU - Li, Juan
AU  - Li J
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China.
FAU - Wang, Xiumin
AU  - Wang X
AUID- ORCID: 0000-0002-2186-759X
AD  - Department of Endocrinology and Metabolism, Shanghai Children's Medical Center, 
      School of Medicine, Shanghai Jiao Tong University, Shanghai, 200127, China. 
      changguoying@126.com.
LA  - eng
PT  - Journal Article
DEP - 20240319
PL  - Germany
TA  - Eur J Pediatr
JT  - European journal of pediatrics
JID - 7603873
SB  - IM
MH  - Humans
MH  - *Endocrine System Diseases/diagnosis
MH  - Child
MH  - *Artificial Intelligence
MH  - Surveys and Questionnaires
MH  - Language
MH  - Mass Screening/methods
MH  - Female
MH  - Pediatrics/methods
MH  - Male
MH  - China/epidemiology
PMC - PMC11098926
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Language mode
OT  - Pediatric endocrine and metabolism
OT  - Physician and patients
OT  - Screening and diagnosis
COIS- The authors declare no competing interests.
EDAT- 2024/03/19 18:42
MHDA- 2024/05/16 12:43
PMCR- 2024/03/19
CRDT- 2024/03/19 12:13
PHST- 2024/02/20 00:00 [received]
PHST- 2024/03/14 00:00 [accepted]
PHST- 2024/03/12 00:00 [revised]
PHST- 2024/05/16 12:43 [medline]
PHST- 2024/03/19 18:42 [pubmed]
PHST- 2024/03/19 12:13 [entrez]
PHST- 2024/03/19 00:00 [pmc-release]
AID - 10.1007/s00431-024-05527-1 [pii]
AID - 5527 [pii]
AID - 10.1007/s00431-024-05527-1 [doi]
PST - ppublish
SO  - Eur J Pediatr. 2024 Jun;183(6):2655-2661. doi: 10.1007/s00431-024-05527-1. Epub 
      2024 Mar 19.

PMID- 35431364
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20220716
IS  - 0138-9130 (Print)
IS  - 1588-2861 (Electronic)
IS  - 0138-9130 (Linking)
VI  - 127
IP  - 5
DP  - 2022
TI  - Why was this cited? Explainable machine learning applied to COVID-19 research 
      literature.
PG  - 2313-2349
LID - 10.1007/s11192-022-04314-9 [doi]
AB  - Multiple studies have investigated bibliometric factors predictive of the 
      citation count a research article will receive. In this article, we go beyond 
      bibliometric data by using a range of machine learning techniques to find 
      patterns predictive of citation count using both article content and available 
      metadata. As the input collection, we use the CORD-19 corpus containing research 
      articles-mostly from biology and medicine-applicable to the COVID-19 crisis. Our 
      study employs a combination of state-of-the-art machine learning techniques for 
      text understanding, including embeddings-based language model BERT, several 
      systems for detection and semantic expansion of entities: ConceptNet, Pubtator 
      and ScispaCy. To interpret the resulting models, we use several explanation 
      algorithms: random forest feature importance, LIME, and Shapley values. We 
      compare the performance and comprehensibility of models obtained by "black-box" 
      machine learning algorithms (neural networks and random forests) with models 
      built with rule learning (CORELS, CBA), which are intrinsically explainable. 
      Multiple rules were discovered, which referred to biomedical entities of 
      potential interest. Of the rules with the highest lift measure, several rules 
      pointed to dipeptidyl peptidase4 (DPP4), a known MERS-CoV receptor and a critical 
      determinant of camel to human transmission of the camel coronavirus (MERS-CoV). 
      Some other interesting patterns related to the type of animal investigated were 
      found. Articles referring to bats and camels tend to draw citations, while 
      articles referring to most other animal species related to coronavirus are lowly 
      cited. Bat coronavirus is the only other virus from a non-human species in the 
      betaB clade along with the SARS-CoV and SARS-CoV-2 viruses. MERS-CoV is in a 
      sister betaC clade, also close to human SARS coronaviruses. Thus both species 
      linked to high citation counts harbor coronaviruses which are more 
      phylogenetically similar to human SARS viruses. On the other hand, feline (FIPV, 
      FCOV) and canine coronaviruses (CCOV) are in the alpha coronavirus clade and more 
      distant from the betaB clade with human SARS viruses. Other results include 
      detection of apparent citation bias favouring authors with western sounding 
      names. Equal performance of TF-IDF weights and binary word incidence matrix was 
      observed, with the latter resulting in better interpretability. The best 
      predictive performance was obtained with a "black-box" method-neural network. The 
      rule-based models led to most insights, especially when coupled with text 
      representation using semantic entity detection methods. Follow-up work should 
      focus on the analysis of citation patterns in the context of phylogenetic trees, 
      as well on patterns referring to DPP4, which is currently considered as a 
      SARS-Cov-2 therapeutic target.
CI  - © Akadémiai Kiadó, Budapest, Hungary 2022.
FAU - Beranová, Lucie
AU  - Beranová L
AUID- ORCID: 0000-0001-6103-9388
AD  - Department of Econometrics, Faculty of Informatics and Statistics, VSE Praha, W 
      Churchill sq. 4, Prague, Czech Republic. GRID: grid.266283.b. ISNI: 0000 0001 
      1956 7785
FAU - Joachimiak, Marcin P
AU  - Joachimiak MP
AUID- ORCID: 0000-0001-8175-045X
AD  - Environmental Genomics and Systems Biology Division at Lawrence Berkeley National 
      Laboratory, Berkeley, USA. GRID: grid.184769.5. ISNI: 0000 0001 2231 4551
FAU - Kliegr, Tomáš
AU  - Kliegr T
AUID- ORCID: 0000-0002-7261-0380
AD  - Department of Information and Knowledge Engineering, VSE Praha, Prague, Czech 
      Republic. GRID: grid.266283.b. ISNI: 0000 0001 1956 7785
FAU - Rabby, Gollam
AU  - Rabby G
AUID- ORCID: 0000-0002-1212-0101
AD  - Department of Information and Knowledge Engineering, VSE Praha, Prague, Czech 
      Republic. GRID: grid.266283.b. ISNI: 0000 0001 1956 7785
FAU - Sklenák, Vilém
AU  - Sklenák V
AUID- ORCID: 0000-0002-8966-0798
AD  - Centre of Information and Library Services, VSE Praha, Prague, Czech Republic. 
      GRID: grid.266283.b. ISNI: 0000 0001 1956 7785
AD  - Department of Information and Knowledge Engineering, VSE Praha, Prague, Czech 
      Republic. GRID: grid.266283.b. ISNI: 0000 0001 1956 7785
LA  - eng
PT  - Journal Article
DEP - 20220409
PL  - Switzerland
TA  - Scientometrics
JT  - Scientometrics
JID - 7901197
PMC - PMC8993675
OTO - NOTNLM
OT  - Bibliometry
OT  - CORD-19: COVID-19 open research dataset
OT  - Citation prediction
OT  - Interpretability
OT  - Phylogenetic distance
OT  - SARS-CoV-2
OT  - Text analysis
OT  - Virus clades
COIS- Conflict of interestThe authors declare no conflict of interest.
EDAT- 2022/04/19 06:00
MHDA- 2022/04/19 06:01
PMCR- 2022/04/09
CRDT- 2022/04/18 06:31
PHST- 2021/04/08 00:00 [received]
PHST- 2022/02/03 00:00 [accepted]
PHST- 2022/04/19 06:00 [pubmed]
PHST- 2022/04/19 06:01 [medline]
PHST- 2022/04/18 06:31 [entrez]
PHST- 2022/04/09 00:00 [pmc-release]
AID - 4314 [pii]
AID - 10.1007/s11192-022-04314-9 [doi]
PST - ppublish
SO  - Scientometrics. 2022;127(5):2313-2349. doi: 10.1007/s11192-022-04314-9. Epub 2022 
      Apr 9.

PMID- 38510858
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240322
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 2
DP  - 2024 Feb
TI  - What Goes In, Must Come Out: Generative Artificial Intelligence Does Not Present 
      Algorithmic Bias Across Race and Gender in Medical Residency Specialties.
PG  - e54448
LID - 10.7759/cureus.54448 [doi]
LID - e54448
AB  - Objective Artificial Intelligence (AI) has made significant inroads into various 
      domains, including medicine, raising concerns about algorithmic bias. This study 
      investigates the presence of biases in generative AI programs, with a specific 
      focus on gender and racial representations across 19 medical residency 
      specialties. Methodology This comparative study utilized DALL-E2 to generate 
      faces representing 19 distinct residency training specialties, as identified by 
      the Association of American Medical Colleges (AAMC), which were then compared to 
      the AAMC's residency specialty breakdown with respect to race and gender. Results 
      Our findings reveal an alignment between OpenAI's DALL-E2's predictions and the 
      current demographic landscape of medical residents, suggesting an absence of 
      algorithmic bias in this AI model. Conclusion This revelation gives rise to 
      important ethical considerations. While AI excels at pattern recognition, it 
      inherits and mirrors the biases present in its training data. To combat AI bias, 
      addressing real-world disparities is imperative. Initiatives to promote 
      inclusivity and diversity within medicine are commendable and contribute to 
      reshaping medical education. This study underscores the need for ongoing efforts 
      to dismantle barriers and foster inclusivity in historically male-dominated 
      medical fields, particularly for underrepresented populations. Ultimately, our 
      findings underscore the crucial role of real-world data quality in mitigating AI 
      bias. As AI continues to shape healthcare and education, the pursuit of 
      equitable, unbiased AI applications should remain at the forefront of these 
      transformative endeavors.
CI  - Copyright © 2024, Lin et al.
FAU - Lin, Shu
AU  - Lin S
AD  - Department of Medical Education, Nova Southeastern University Dr. Kiran C. Patel 
      College of Allopathic Medicine, Fort Lauderdale, USA.
FAU - Pandit, Saket
AU  - Pandit S
AD  - Department of Medical Education, Nova Southeastern University Dr. Kiran C. Patel 
      College of Allopathic Medicine, Fort Lauderdale, USA.
FAU - Tritsch, Tara
AU  - Tritsch T
AD  - Department of Medical Education, Nova Southeastern University Dr. Kiran C. Patel 
      College of Allopathic Medicine, Fort Lauderdale, USA.
FAU - Levy, Arkene
AU  - Levy A
AD  - Department of Medical Education, Nova Southeastern University Dr. Kiran C. Patel 
      College of Allopathic Medicine, Fort Lauderdale, USA.
FAU - Shoja, Mohammadali M
AU  - Shoja MM
AD  - Department of Medical Education, Nova Southeastern University Dr. Kiran C. Patel 
      College of Allopathic Medicine, Fort Lauderdale, USA.
LA  - eng
PT  - Journal Article
DEP - 20240219
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC10951939
OTO - NOTNLM
OT  - artificial intelligence
OT  - bias identification
OT  - diversity
OT  - healthcare
OT  - medical education
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/03/21 06:43
MHDA- 2024/03/21 06:44
PMCR- 2024/02/19
CRDT- 2024/03/21 04:17
PHST- 2023/12/07 00:00 [received]
PHST- 2024/02/18 00:00 [accepted]
PHST- 2024/03/21 06:44 [medline]
PHST- 2024/03/21 06:43 [pubmed]
PHST- 2024/03/21 04:17 [entrez]
PHST- 2024/02/19 00:00 [pmc-release]
AID - 10.7759/cureus.54448 [doi]
PST - epublish
SO  - Cureus. 2024 Feb 19;16(2):e54448. doi: 10.7759/cureus.54448. eCollection 2024 
      Feb.

PMID- 39931300
OWN - NLM
STAT- MEDLINE
DCOM- 20250211
LR  - 20250212
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 13
DP  - 2025
TI  - Advancing health equity: evaluating AI translations of kidney donor information 
      for Spanish speakers.
PG  - 1484790
LID - 10.3389/fpubh.2025.1484790 [doi]
LID - 1484790
AB  - BACKGROUND: Health equity and access to essential medical information remain 
      significant challenges, especially for the Spanish-speaking Hispanic population, 
      which faces barriers in accessing living kidney donation opportunities. ChatGPT, 
      an AI language model with sophisticated natural language processing capabilities, 
      has been identified as a promising tool for translating critical health 
      information into Spanish. This study aims to assess ChatGPT's translation 
      efficacy to ensure the information provided is accurate and culturally relevant. 
      METHODS: This study utilized ChatGPT versions 3.5 and 4.0 to translate 27 
      frequently asked questions (FAQs) from English to Spanish, sourced from Donate 
      Life America's website. The translated content was reviewed by native 
      Spanish-speaking nephrologists using a standard rubric scale (1-5). The 
      assessment focused on linguistic accuracy and cultural sensitivity, emphasizing 
      retention of the original message, appropriate vocabulary and grammar, and 
      cultural relevance. RESULTS: The mean linguistic accuracy scores were 4.89 ± 0.32 
      for GPT-3.5 and 5.00 ± 0.00 for GPT-4.0 (p = 0.08). The percentage of 
      excellent-quality translations (score = 5) in linguistic accuracy was 89% for 
      GPT-3.5 and 100% for GPT-4.0 (p = 0.24). The mean cultural sensitivity scores 
      were 4.89 ± 0.32 for both GPT-3.5 and GPT-4.0 (p = 1.00). Similarly, 
      excellent-quality translations in cultural sensitivity were achieved in 89% of 
      cases for both versions (p = 1.00). CONCLUSION: ChatGPT 4.0 demonstrates strong 
      potential to enhance health equity by improving Spanish-speaking Hispanic 
      patients' access to LKD information through accurate and culturally sensitive 
      translations. These findings highlight the role of AI in mitigating healthcare 
      disparities and underscore the need for integrating AI-driven tools into 
      healthcare systems. Future efforts should focus on developing accessible 
      platforms and establishing guidelines to maximize AI's impact on equitable 
      healthcare delivery and patient education.
CI  - Copyright © 2025 Garcia Valencia, Thongprayoon, Jadlowiec, Mao, Leeaphorn, 
      Budhiraja, Khoury, Pham, Craici, Gonzalez Suarez and Cheungpasitporn.
FAU - Garcia Valencia, Oscar A
AU  - Garcia Valencia OA
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Jadlowiec, Caroline C
AU  - Jadlowiec CC
AD  - Division of Transplant Surgery, Department of Surgery, Mayo Clinic, Phoenix, AZ, 
      United States.
FAU - Mao, Shennen A
AU  - Mao SA
AD  - Department of Transplant Surgery, Mayo Clinic, Jacksonville, FL, United States.
FAU - Leeaphorn, Napat
AU  - Leeaphorn N
AD  - Department of Transplant Surgery, Mayo Clinic, Jacksonville, FL, United States.
FAU - Budhiraja, Pooja
AU  - Budhiraja P
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Phoenix, AZ, United States.
FAU - Khoury, Nadeen
AU  - Khoury N
AD  - Division of Nephrology, Department of Medicine, Henry Ford Hospital, Detroit, MI, 
      United States.
FAU - Pham, Justin H
AU  - Pham JH
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Craici, Iasmina M
AU  - Craici IM
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Gonzalez Suarez, Maria L
AU  - Gonzalez Suarez ML
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
LA  - eng
PT  - Journal Article
DEP - 20250127
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
SB  - IM
MH  - Humans
MH  - *Hispanic or Latino
MH  - *Health Equity
MH  - *Translating
MH  - Kidney Transplantation
MH  - Male
MH  - Female
MH  - Natural Language Processing
MH  - Language
MH  - Translations
MH  - Cultural Competency
MH  - Living Donors
MH  - White
PMC - PMC11808013
OTO - NOTNLM
OT  - ChatGPT
OT  - Spanish-speaking populations
OT  - artificial intelligence
OT  - cultural competency
OT  - health equity
OT  - healthcare communication barriers
OT  - language translation models
OT  - living kidney donation
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2025/02/11 10:53
MHDA- 2025/02/11 10:54
PMCR- 2025/01/27
CRDT- 2025/02/11 04:18
PHST- 2024/09/21 00:00 [received]
PHST- 2025/01/13 00:00 [accepted]
PHST- 2025/02/11 10:54 [medline]
PHST- 2025/02/11 10:53 [pubmed]
PHST- 2025/02/11 04:18 [entrez]
PHST- 2025/01/27 00:00 [pmc-release]
AID - 10.3389/fpubh.2025.1484790 [doi]
PST - epublish
SO  - Front Public Health. 2025 Jan 27;13:1484790. doi: 10.3389/fpubh.2025.1484790. 
      eCollection 2025.

PMID- 32681214
OWN - NLM
STAT- MEDLINE
DCOM- 20210607
LR  - 20210607
IS  - 1741-0444 (Electronic)
IS  - 0140-0118 (Linking)
VI  - 58
IP  - 9
DP  - 2020 Sep
TI  - Neuro-fuzzy patch-wise R-CNN for multiple sclerosis segmentation.
PG  - 2161-2175
LID - 10.1007/s11517-020-02225-6 [doi]
AB  - The segmentation of the lesion plays a core role in diagnosis and monitoring of 
      multiple sclerosis (MS). Magnetic resonance imaging (MRI) is the most frequent 
      image modality used to evaluate such lesions. Because of the massive amount of 
      data, manual segmentation cannot be achieved within a sensible time that 
      restricts the usage of accurate quantitative measurement in clinical practice. 
      Therefore, the need for effective automated segmentation techniques is critical. 
      However, a large spatial variability between the structure of brain lesions makes 
      it more challenging. Recently, convolutional neural network (CNN), in particular, 
      the region-based CNN (R-CNN), have attained tremendous progress within the field 
      of object recognition because of its ability to learn and represent features. CNN 
      has proven a last-breaking performance in various fields, such as object 
      recognition, and has also gained more attention in brain imaging, especially in 
      tissue and brain segmentation. In this paper, an automated technique for MS 
      lesion segmentation is proposed, which is built on a 3D patch-wise R-CNN. The 
      proposed system includes two stages: first, segmenting MS lesions in T2-w and 
      FLAIR sequences using R-CNN, then an adaptive neuro-fuzzy inference system 
      (ANFIS) is applied to fuse the results of the two modalities. To evaluate the 
      performance of the proposed method, the public MICCAI2008 MS challenge dataset is 
      employed to segment MS lesions. The experimental results show competitive results 
      of the proposed method compared with the state-of-the-art MS lesion segmentation 
      methods with an average total score of 83.25 and an average sensitivity of 61.8% 
      on the MICCAI2008 testing set. Graphical Abstract The proposed system overview. 
      First, the input of two modalities FLAIR and T2 are pre-processed to remove the 
      skull and correct the bias field. Then 3D patches for lesion and non-lesion 
      tissues are extracted and fed to R-CNN. Each R-CNN produces a probability map of 
      the segmentation result that provides to ANFIS to fuse the results and obtain the 
      final MS lesion segmentation. The MS lesions are shown on a pre-processed FLAIR 
      image.
FAU - Essa, Ehab
AU  - Essa E
AUID- ORCID: 0000-0002-3360-7285
AD  - Computer Science Department, Faculty of Computers and Information, Mansoura 
      University, Mansoura, Dakahlia Governorate, Egypt. ehab_essa@mans.edu.eg.
FAU - Aldesouky, Doaa
AU  - Aldesouky D
AD  - Computer Science Department, Faculty of Computers and Information, Mansoura 
      University, Mansoura, Dakahlia Governorate, Egypt.
FAU - Hussein, Sherif E
AU  - Hussein SE
AD  - Computer Engineering and Systems Department, Faculty of Engineering, Mansoura 
      University, Mansoura, Dakahlia Governorate, Egypt.
FAU - Rashad, M Z
AU  - Rashad MZ
AD  - Computer Science Department, Faculty of Computers and Information, Mansoura 
      University, Mansoura, Dakahlia Governorate, Egypt.
LA  - eng
PT  - Journal Article
DEP - 20200717
PL  - United States
TA  - Med Biol Eng Comput
JT  - Medical & biological engineering & computing
JID - 7704869
SB  - IM
MH  - Biomedical Engineering
MH  - Brain/*diagnostic imaging
MH  - Deep Learning
MH  - Fuzzy Logic
MH  - Humans
MH  - Image Interpretation, Computer-Assisted/statistics & numerical data
MH  - Magnetic Resonance Imaging/*statistics & numerical data
MH  - Models, Statistical
MH  - Multiple Sclerosis/*diagnostic imaging
MH  - *Neural Networks, Computer
MH  - Neuroimaging/*statistics & numerical data
OTO - NOTNLM
OT  - Deep learning
OT  - MS segmentation
OT  - Neuro-fuzzy
OT  - R-CNN
EDAT- 2020/07/19 06:00
MHDA- 2021/06/08 06:00
CRDT- 2020/07/19 06:00
PHST- 2019/06/27 00:00 [received]
PHST- 2020/06/29 00:00 [accepted]
PHST- 2020/07/19 06:00 [pubmed]
PHST- 2021/06/08 06:00 [medline]
PHST- 2020/07/19 06:00 [entrez]
AID - 10.1007/s11517-020-02225-6 [pii]
AID - 10.1007/s11517-020-02225-6 [doi]
PST - ppublish
SO  - Med Biol Eng Comput. 2020 Sep;58(9):2161-2175. doi: 10.1007/s11517-020-02225-6. 
      Epub 2020 Jul 17.

PMID- 32966630
OWN - NLM
STAT- MEDLINE
DCOM- 20210809
LR  - 20240330
IS  - 1475-6773 (Electronic)
IS  - 0017-9124 (Print)
IS  - 0017-9124 (Linking)
VI  - 56
IP  - 1
DP  - 2021 Feb
TI  - Employing computational linguistics techniques to identify limited patient health 
      literacy: Findings from the ECLIPPSE study.
PG  - 132-144
LID - 10.1111/1475-6773.13560 [doi]
AB  - OBJECTIVE: To develop novel, scalable, and valid literacy profiles for 
      identifying limited health literacy patients by harnessing natural language 
      processing. DATA SOURCE: With respect to the linguistic content, we analyzed 
      283 216 secure messages sent by 6941 diabetes patients to physicians within an 
      integrated system's electronic portal. Sociodemographic, clinical, and 
      utilization data were obtained via questionnaire and electronic health records. 
      STUDY DESIGN: Retrospective study used natural language processing and machine 
      learning to generate five unique "Literacy Profiles" by employing various sets of 
      linguistic indices: Flesch-Kincaid (LP_FK); basic indices of writing complexity, 
      including lexical diversity (LP_LD) and writing quality (LP_WQ); and advanced 
      indices related to syntactic complexity, lexical sophistication, and diversity, 
      modeled from self-reported (LP_SR), and expert-rated (LP_Exp) health literacy. We 
      first determined the performance of each literacy profile relative to 
      self-reported and expert-rated health literacy to discriminate between high and 
      low health literacy and then assessed Literacy Profiles' relationships with known 
      correlates of health literacy, such as patient sociodemographics and a range of 
      health-related outcomes, including ratings of physician communication, medication 
      adherence, diabetes control, comorbidities, and utilization. PRINCIPAL FINDINGS: 
      LP_SR and LP_Exp performed best in discriminating between high and low 
      self-reported (C-statistics: 0.86 and 0.58, respectively) and expert-rated health 
      literacy (C-statistics: 0.71 and 0.87, respectively) and were significantly 
      associated with educational attainment, race/ethnicity, Consumer Assessment of 
      Provider and Systems (CAHPS) scores, adherence, glycemia, comorbidities, and 
      emergency department visits. CONCLUSIONS: Since health literacy is a potentially 
      remediable explanatory factor in health care disparities, the development of 
      automated health literacy indicators represents a significant accomplishment with 
      broad clinical and population health applications. Health systems could apply 
      literacy profiles to efficiently determine whether quality of care and outcomes 
      vary by patient health literacy; identify at-risk populations for targeting 
      tailored health communications and self-management support interventions; and 
      inform clinicians to promote improvements in individual-level care.
CI  - © 2020 The Authors. Health Services Research published by Wiley Periodicals LLC 
      on behalf of Health Research and Educational Trust.
FAU - Schillinger, Dean
AU  - Schillinger D
AD  - UCSF Division of General Internal Medicine, Zuckerberg San Francisco General 
      Hospital and Trauma Center, San Francisco, California, USA.
AD  - Division of Research, Kaiser Permanente Northern California, Oakland, California, 
      USA.
AD  - UCSF Health Communications Research Program, Center for Vulnerable Populations, 
      Zuckerberg San Francisco General Hospital and Trauma Center, San Francisco, 
      California, USA.
FAU - Balyan, Renu
AU  - Balyan R
AUID- ORCID: 0000-0003-1393-2416
AD  - Ira A. Fulton School of Engineering, Arizona State University, Mesa, Arizona, 
      USA.
FAU - Crossley, Scott A
AU  - Crossley SA
AD  - Department of Applied Linguistics/ESL, College of Arts and Sciences, Georgia 
      State University, Atlanta, Georgia, USA.
FAU - McNamara, Danielle S
AU  - McNamara DS
AD  - Department of Psychology, Arizona State University, Tempe, Arizona, USA.
FAU - Liu, Jennifer Y
AU  - Liu JY
AD  - Division of Research, Kaiser Permanente Northern California, Oakland, California, 
      USA.
FAU - Karter, Andrew J
AU  - Karter AJ
AUID- ORCID: 0000-0001-5527-316X
AD  - UCSF Division of General Internal Medicine, Zuckerberg San Francisco General 
      Hospital and Trauma Center, San Francisco, California, USA.
AD  - Division of Research, Kaiser Permanente Northern California, Oakland, California, 
      USA.
LA  - eng
GR  - R01 LM012355/LM/NLM NIH HHS/United States
GR  - P30 DK098722/DK/NIDDK NIH HHS/United States
GR  - R01 DK065664/DK/NIDDK NIH HHS/United States
GR  - P30 DK092924/DK/NIDDK NIH HHS/United States
GR  - P30 DK063720/DK/NIDDK NIH HHS/United States
GR  - R01 HD046113/HD/NICHD NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, U.S. Gov't, Non-P.H.S.
DEP - 20200923
PL  - United States
TA  - Health Serv Res
JT  - Health services research
JID - 0053006
SB  - IM
MH  - Diabetes Mellitus/therapy
MH  - Electronic Health Records/statistics & numerical data
MH  - Health Literacy/*methods
MH  - Humans
MH  - Natural Language Processing
MH  - Patient Education as Topic/*methods
MH  - Physician-Patient Relations
MH  - Process Assessment, Health Care/*methods
MH  - Retrospective Studies
PMC - PMC7839650
OTO - NOTNLM
OT  - communication
OT  - diabetes
OT  - health literacy
OT  - machine learning
OT  - managed care
OT  - natural language processing
OT  - secure messaging
EDAT- 2020/09/24 06:00
MHDA- 2021/08/10 06:00
PMCR- 2020/09/23
CRDT- 2020/09/23 17:36
PHST- 2020/09/24 06:00 [pubmed]
PHST- 2021/08/10 06:00 [medline]
PHST- 2020/09/23 17:36 [entrez]
PHST- 2020/09/23 00:00 [pmc-release]
AID - HESR13560 [pii]
AID - 10.1111/1475-6773.13560 [doi]
PST - ppublish
SO  - Health Serv Res. 2021 Feb;56(1):132-144. doi: 10.1111/1475-6773.13560. Epub 2020 
      Sep 23.

PMID- 38016816
OWN - NLM
STAT- MEDLINE
DCOM- 20240229
LR  - 20240305
IS  - 1365-2125 (Electronic)
IS  - 0306-5251 (Linking)
VI  - 90
IP  - 3
DP  - 2024 Mar
TI  - Using artificial intelligence to create diverse and inclusive medical case 
      vignettes for education.
PG  - 640-648
LID - 10.1111/bcp.15977 [doi]
AB  - AIMS: Medical case vignettes play a crucial role in medical education, yet they 
      often fail to authentically represent diverse patients. Moreover, these vignettes 
      tend to oversimplify the complex relationship between patient characteristics and 
      medical conditions, leading to biased and potentially harmful perspectives among 
      students. Displaying aspects of patient diversity, such as ethnicity, in written 
      cases proves challenging. Additionally, creating these cases places a significant 
      burden on teachers in terms of labour and time. Our objective is to explore the 
      potential of artificial intelligence (AI)-assisted computer-generated clinical 
      cases to expedite case creation and enhance diversity, along with AI-generated 
      patient photographs for more lifelike portrayal. METHODS: In this study, we 
      employed ChatGPT (OpenAI, GPT 3.5) to develop diverse and inclusive medical case 
      vignettes. We evaluated various approaches and identified a set of eight 
      consecutive prompts that can be readily customized to accommodate local contexts 
      and specific assignments. To enhance visual representation, we utilized Adobe 
      Firefly beta for image generation. RESULTS: Using the described prompts, we 
      consistently generated cases for various assignments, producing sets of 30 cases 
      at a time. We ensured the inclusion of mandatory checks and formatting, 
      completing the process within approximately 60 min per set. CONCLUSIONS: Our 
      approach significantly accelerated case creation and improved diversity, although 
      prioritizing maximum diversity compromised representativeness to some extent. 
      While the optimized prompts are easily reusable, the process itself demands 
      computer skills not all educators possess. To address this, we aim to share all 
      created patients as open educational resources, empowering educators to create 
      cases independently.
CI  - © 2023 The Authors. British Journal of Clinical Pharmacology published by John 
      Wiley & Sons Ltd on behalf of British Pharmacological Society.
FAU - Bakkum, Michiel J
AU  - Bakkum MJ
AUID- ORCID: 0000-0003-0928-812X
AD  - Department of Internal Medicine, Section Pharmacotherapy, Amsterdam UMC, Vrije 
      Universiteit Amsterdam, Amsterdam, HV, The Netherlands.
AD  - Research and Expertise Centre in Pharmacotherapy Education (RECIPE), Amsterdam, 
      HV, The Netherlands.
FAU - Hartjes, Mariëlle G
AU  - Hartjes MG
AUID- ORCID: 0000-0002-7595-2570
AD  - Department of Internal Medicine, Section Pharmacotherapy, Amsterdam UMC, Vrije 
      Universiteit Amsterdam, Amsterdam, HV, The Netherlands.
AD  - Research and Expertise Centre in Pharmacotherapy Education (RECIPE), Amsterdam, 
      HV, The Netherlands.
FAU - Piët, Joost D
AU  - Piët JD
AUID- ORCID: 0009-0000-7380-4876
AD  - Department of Internal Medicine, Section Pharmacotherapy, Amsterdam UMC, Vrije 
      Universiteit Amsterdam, Amsterdam, HV, The Netherlands.
AD  - Research and Expertise Centre in Pharmacotherapy Education (RECIPE), Amsterdam, 
      HV, The Netherlands.
FAU - Donker, Erik M
AU  - Donker EM
AUID- ORCID: 0000-0002-8169-0714
AD  - Department of Internal Medicine, Section Pharmacotherapy, Amsterdam UMC, Vrije 
      Universiteit Amsterdam, Amsterdam, HV, The Netherlands.
AD  - Research and Expertise Centre in Pharmacotherapy Education (RECIPE), Amsterdam, 
      HV, The Netherlands.
FAU - Likic, Robert
AU  - Likic R
AUID- ORCID: 0000-0003-1413-4862
AD  - European Association for Clinical Pharmacology and Therapeutics (EACPT) Education 
      Working Group, Amsterdam, The Netherlands.
AD  - Unit of Clinical Pharmacology, University of Zagreb School of Medicine and 
      Clinical Hospital Centre Zagreb, Zagreb, Croatia.
FAU - Sanz, Emilio
AU  - Sanz E
AUID- ORCID: 0000-0001-6788-4435
AD  - European Association for Clinical Pharmacology and Therapeutics (EACPT) Education 
      Working Group, Amsterdam, The Netherlands.
AD  - Universidad de La Laguna, school of Health Sciences, Tenerife, Spain and Hospital 
      Universitario de Canarias. La Laguna, Tenerife, Spain.
FAU - de Ponti, Fabrizio
AU  - de Ponti F
AUID- ORCID: 0000-0002-0367-9595
AD  - European Association for Clinical Pharmacology and Therapeutics (EACPT) Education 
      Working Group, Amsterdam, The Netherlands.
AD  - Department of Medical and Surgical Sciences, Pharmacology Unit, Alma Mater 
      Studiorum, University of Bologna, Bologna, Italy.
FAU - Verdonk, Petra
AU  - Verdonk P
AUID- ORCID: 0000-0003-0464-8210
AD  - European Association for Clinical Pharmacology and Therapeutics (EACPT) Education 
      Working Group, Amsterdam, The Netherlands.
AD  - Department of Ethics, Law & Humanities, APH research institute, Amsterdam UMC-VU 
      University, Amsterdam, The Netherlands.
FAU - Richir, Milan C
AU  - Richir MC
AD  - Department of Internal Medicine, Section Pharmacotherapy, Amsterdam UMC, Vrije 
      Universiteit Amsterdam, Amsterdam, HV, The Netherlands.
AD  - Research and Expertise Centre in Pharmacotherapy Education (RECIPE), Amsterdam, 
      HV, The Netherlands.
FAU - van Agtmael, Michiel A
AU  - van Agtmael MA
AUID- ORCID: 0000-0002-7966-6934
AD  - Department of Internal Medicine, Section Pharmacotherapy, Amsterdam UMC, Vrije 
      Universiteit Amsterdam, Amsterdam, HV, The Netherlands.
AD  - Research and Expertise Centre in Pharmacotherapy Education (RECIPE), Amsterdam, 
      HV, The Netherlands.
AD  - European Association for Clinical Pharmacology and Therapeutics (EACPT) Education 
      Working Group, Amsterdam, The Netherlands.
FAU - Tichelaar, Jelle
AU  - Tichelaar J
AUID- ORCID: 0000-0002-7485-9219
AD  - Department of Internal Medicine, Section Pharmacotherapy, Amsterdam UMC, Vrije 
      Universiteit Amsterdam, Amsterdam, HV, The Netherlands.
AD  - Research and Expertise Centre in Pharmacotherapy Education (RECIPE), Amsterdam, 
      HV, The Netherlands.
AD  - European Association for Clinical Pharmacology and Therapeutics (EACPT) Education 
      Working Group, Amsterdam, The Netherlands.
LA  - eng
GR  - 2020-1-NL01-KA203-083098/European Union under Erasmus+ grant/
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240106
PL  - England
TA  - Br J Clin Pharmacol
JT  - British journal of clinical pharmacology
JID - 7503323
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Medical
MH  - Ethnicity
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - diversity and inclusivity
EDAT- 2023/11/29 00:42
MHDA- 2024/02/29 06:42
CRDT- 2023/11/28 21:53
PHST- 2023/10/27 00:00 [revised]
PHST- 2023/08/18 00:00 [received]
PHST- 2023/10/28 00:00 [accepted]
PHST- 2024/02/29 06:42 [medline]
PHST- 2023/11/29 00:42 [pubmed]
PHST- 2023/11/28 21:53 [entrez]
AID - 10.1111/bcp.15977 [doi]
PST - ppublish
SO  - Br J Clin Pharmacol. 2024 Mar;90(3):640-648. doi: 10.1111/bcp.15977. Epub 2024 
      Jan 6.

PMID- 39866564
OWN - NLM
STAT- MEDLINE
DCOM- 20250127
LR  - 20250302
IS  - 2167-8359 (Electronic)
IS  - 2167-8359 (Linking)
VI  - 13
DP  - 2025
TI  - Assessing the readability, quality and reliability of responses produced by 
      ChatGPT, Gemini, and Perplexity regarding most frequently asked keywords about 
      low back pain.
PG  - e18847
LID - 10.7717/peerj.18847 [doi]
LID - e18847
AB  - BACKGROUND: Patients who are informed about the causes, pathophysiology, 
      treatment and prevention of a disease are better able to participate in treatment 
      procedures in the event of illness. Artificial intelligence (AI), which has 
      gained popularity in recent years, is defined as the study of algorithms that 
      provide machines with the ability to reason and perform cognitive functions, 
      including object and word recognition, problem solving and decision making. This 
      study aimed to examine the readability, reliability and quality of responses to 
      frequently asked keywords about low back pain (LBP) given by three different 
      AI-based chatbots (ChatGPT, Perplexity and Gemini), which are popular 
      applications in online information presentation today. METHODS: All three AI 
      chatbots were asked the 25 most frequently used keywords related to LBP 
      determined with the help of Google Trend. In order to prevent possible bias that 
      could be created by the sequential processing of keywords in the answers given by 
      the chatbots, the study was designed by providing input from different users (EO, 
      VH) for each keyword. The readability of the responses given was determined with 
      the Simple Measure of Gobbledygook (SMOG), Flesch Reading Ease Score (FRES) and 
      Gunning Fog (GFG) readability scores. Quality was assessed using the Global 
      Quality Score (GQS) and the Ensuring Quality Information for Patients (EQIP) 
      score. Reliability was assessed by determining with DISCERN and Journal of 
      American Medical Association (JAMA) scales. RESULTS: The first three keywords 
      detected as a result of Google Trend search were "Lower Back Pain", "ICD 10 Low 
      Back Pain", and "Low Back Pain Symptoms". It was determined that the readability 
      of the responses given by all AI chatbots was higher than the recommended 6th 
      grade readability level (p < 0.001). In the EQIP, JAMA, modified DISCERN and GQS 
      score evaluation, Perplexity was found to have significantly higher scores than 
      other chatbots (p < 0.001). CONCLUSION: It has been determined that the answers 
      given by AI chatbots to keywords about LBP are difficult to read and have low 
      reliability and quality assessment. It is clear that when new chatbots are 
      introduced, they can provide better guidance to patients with increased clarity 
      and text quality. This study can provide inspiration for future studies on 
      improving the algorithms and responses of AI chatbots.
CI  - © 2025 Ozduran et al.
FAU - Ozduran, Erkan
AU  - Ozduran E
AUID- ORCID: 0000-0003-3425-313X
AD  - Physical Medicine and Rehabilitation, Pain Medicine, Sivas Numune Hospital, 
      Sivas, Turkey.
FAU - Hancı, Volkan
AU  - Hancı V
AUID- ORCID: 0000-0002-2227-194X
AD  - Anesthesiology and Reanimation, Critical Care Medicine, Dokuz Eylül University, 
      Izmir, Turkey.
FAU - Erkin, Yüksel
AU  - Erkin Y
AD  - Anesthesiology and Reanimation, Pain Medicine, Dokuz Eylül University, Izmir, 
      Turkey.
FAU - Özbek, İlhan Celil
AU  - Özbek İC
AUID- ORCID: 0000-0003-0508-8868
AD  - Physical Medicine and Rehabilitation, Health Science University, Derince 
      Education and Research Hospital, Kocaeli, Turkey.
FAU - Abdulkerimov, Vugar
AU  - Abdulkerimov V
AD  - Anesthesiology and Reanimation, Central Clinical Hospital, Baku, Azerbaijan.
LA  - eng
PT  - Journal Article
DEP - 20250122
PL  - United States
TA  - PeerJ
JT  - PeerJ
JID - 101603425
SB  - IM
MH  - Humans
MH  - *Low Back Pain/therapy
MH  - *Comprehension
MH  - Reproducibility of Results
MH  - *Artificial Intelligence
MH  - Internet
PMC - PMC11760201
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Gemini
OT  - Low back pain
OT  - Online medical information
OT  - Perplexity
COIS- The authors declare that they have no competing interests.
EDAT- 2025/01/27 06:20
MHDA- 2025/01/27 06:21
PMCR- 2025/01/22
CRDT- 2025/01/27 05:40
PHST- 2024/09/13 00:00 [received]
PHST- 2024/12/19 00:00 [accepted]
PHST- 2025/01/27 06:21 [medline]
PHST- 2025/01/27 06:20 [pubmed]
PHST- 2025/01/27 05:40 [entrez]
PHST- 2025/01/22 00:00 [pmc-release]
AID - 18847 [pii]
AID - 10.7717/peerj.18847 [doi]
PST - epublish
SO  - PeerJ. 2025 Jan 22;13:e18847. doi: 10.7717/peerj.18847. eCollection 2025.

PMID- 39050145
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240726
IS  - 2667-2766 (Electronic)
IS  - 2667-2766 (Linking)
VI  - 15
DP  - 2024 Sep
TI  - Assessing accuracy of ChatGPT in response to questions from day to day 
      pharmaceutical care in hospitals.
PG  - 100464
LID - 10.1016/j.rcsop.2024.100464 [doi]
LID - 100464
AB  - BACKGROUND: The advent of Large Language Models (LLMs) such as ChatGPT introduces 
      opportunities within the medical field. Nonetheless, use of LLM poses a risk when 
      healthcare practitioners and patients present clinical questions to these 
      programs without a comprehensive understanding of its suitability for clinical 
      contexts. OBJECTIVE: The objective of this study was to assess ChatGPT's ability 
      to generate appropriate responses to clinical questions that hospital pharmacists 
      could encounter during routine patient care. METHODS: Thirty questions from 10 
      different domains within clinical pharmacy were collected during routine care. 
      Questions were presented to ChatGPT in a standardized format, including patients' 
      age, sex, drug name, dose, and indication. Subsequently, relevant information 
      regarding specific cases were provided, and the prompt was concluded with the 
      query "what would a hospital pharmacist do?". The impact on accuracy was assessed 
      for each domain by modifying personification to "what would you do?", presenting 
      the question in Dutch, and regenerating the primary question. All responses were 
      independently evaluated by two senior hospital pharmacists, focusing on the 
      availability of an advice, accuracy and concordance. RESULTS: In 77% of 
      questions, ChatGPT provided an advice in response to the question. For these 
      responses, accuracy and concordance were determined. Accuracy was correct and 
      complete for 26% of responses, correct but incomplete for 22% of responses, 
      partially correct and partially incorrect for 30% of responses and completely 
      incorrect for 22% of responses. The reproducibility was poor, with merely 10% of 
      responses remaining consistent upon regeneration of the primary question. 
      CONCLUSIONS: While concordance of responses was excellent, the accuracy and 
      reproducibility were poor. With the described method, ChatGPT should not be used 
      to address questions encountered by hospital pharmacists during their shifts. 
      However, it is important to acknowledge the limitations of our methodology, 
      including potential biases, which may have influenced the findings.
CI  - © 2024 The Authors.
FAU - van Nuland, Merel
AU  - van Nuland M
AD  - Department of Clinical Pharmacy, Tergooi Medical Center, Hilversum, the 
      Netherlands.
FAU - Lobbezoo, Anne-Fleur H
AU  - Lobbezoo AH
AD  - Department of Clinical Pharmacy, Tergooi Medical Center, Hilversum, the 
      Netherlands.
AD  - Department of Pharmacy, St. Antonius Hospital, Utrecht, Nieuwegein, the 
      Netherlands.
FAU - van de Garde, Ewoudt M W
AU  - van de Garde EMW
AD  - Department of Pharmacy, St. Antonius Hospital, Utrecht, Nieuwegein, the 
      Netherlands.
AD  - Division of Pharmacoepidemiology and Clinical Pharmacology, Department of 
      Pharmaceutical Sciences, Faculty of Science, Utrecht Institute for Pharmaceutical 
      Sciences (UIPS), Utrecht University, Utrecht, the Netherlands.
FAU - Herbrink, Maikel
AU  - Herbrink M
AD  - Department of Clinical Pharmacy, Meander Medical Center, Amersfoort, the 
      Netherlands.
FAU - van Heijl, Inger
AU  - van Heijl I
AD  - Department of Clinical Pharmacy, Tergooi Medical Center, Hilversum, the 
      Netherlands.
FAU - Bognàr, Tim
AU  - Bognàr T
AD  - Department of Clinical Pharmacy, University Medical Center Utrecht, Utrecht 
      University, Utrecht, the Netherlands.
FAU - Houwen, Jeroen P A
AU  - Houwen JPA
AD  - Department of Clinical Pharmacy, University Medical Center Utrecht, Utrecht 
      University, Utrecht, the Netherlands.
FAU - Dekens, Marloes
AU  - Dekens M
AD  - Department of Pharmacy, St. Antonius Hospital, Utrecht, Nieuwegein, the 
      Netherlands.
FAU - Wannet, Demi
AU  - Wannet D
AD  - Department of Clinical Pharmacy, Meander Medical Center, Amersfoort, the 
      Netherlands.
FAU - Egberts, Toine
AU  - Egberts T
AD  - Division of Pharmacoepidemiology and Clinical Pharmacology, Department of 
      Pharmaceutical Sciences, Faculty of Science, Utrecht Institute for Pharmaceutical 
      Sciences (UIPS), Utrecht University, Utrecht, the Netherlands.
AD  - Department of Clinical Pharmacy, University Medical Center Utrecht, Utrecht 
      University, Utrecht, the Netherlands.
FAU - van der Linden, Paul D
AU  - van der Linden PD
AD  - Department of Clinical Pharmacy, Tergooi Medical Center, Hilversum, the 
      Netherlands.
AD  - Julius Center for Health Sciences and Primary Care, University Medical Center 
      Utrecht, Utrecht, the Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20240613
PL  - United States
TA  - Explor Res Clin Soc Pharm
JT  - Exploratory research in clinical and social pharmacy
JID - 9918266300706676
PMC - PMC11267013
OTO - NOTNLM
OT  - Accuracy
OT  - ChatGPT
OT  - Clinical pharmacy
OT  - Drug information
OT  - Language model
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2024/07/26 12:47
MHDA- 2024/07/26 12:48
PMCR- 2024/06/13
CRDT- 2024/07/25 04:48
PHST- 2024/04/12 00:00 [received]
PHST- 2024/05/26 00:00 [revised]
PHST- 2024/06/06 00:00 [accepted]
PHST- 2024/07/26 12:48 [medline]
PHST- 2024/07/26 12:47 [pubmed]
PHST- 2024/07/25 04:48 [entrez]
PHST- 2024/06/13 00:00 [pmc-release]
AID - S2667-2766(24)00061-1 [pii]
AID - 100464 [pii]
AID - 10.1016/j.rcsop.2024.100464 [doi]
PST - epublish
SO  - Explor Res Clin Soc Pharm. 2024 Jun 13;15:100464. doi: 
      10.1016/j.rcsop.2024.100464. eCollection 2024 Sep.

PMID- 39334087
OWN - NLM
STAT- MEDLINE
DCOM- 20240928
LR  - 20241001
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Sep 27
TI  - LLM-based automatic short answer grading in undergraduate medical education.
PG  - 1060
LID - 10.1186/s12909-024-06026-5 [doi]
LID - 1060
AB  - BACKGROUND: Multiple choice questions are heavily used in medical education 
      assessments, but rely on recognition instead of knowledge recall. However, 
      grading open questions is a time-intensive task for teachers. Automatic short 
      answer grading (ASAG) has tried to fill this gap, and with the recent advent of 
      Large Language Models (LLM), this branch has seen a new momentum. METHODS: We 
      graded 2288 student answers from 12 undergraduate medical education courses in 3 
      languages using GPT-4 and Gemini 1.0 Pro. RESULTS: GPT-4 proposed significantly 
      lower grades than the human evaluator, but reached low rates of false positives. 
      The grades of Gemini 1.0 Pro were not significantly different from the teachers'. 
      Both LLMs reached a moderate agreement with human grades, and a high precision 
      for GPT-4 among answers considered fully correct. A consistent grading behavior 
      could be determined for high-quality keys. A weak correlation was found wrt. the 
      length or language of student answers. There is a risk of bias if the LLM knows 
      the human grade a priori. CONCLUSIONS: LLM-based ASAG applied to medical 
      education still requires human oversight, but time can be spared on the edge 
      cases, allowing teachers to focus on the middle ones. For Bachelor-level medical 
      education questions, the training knowledge of LLMs seems to be sufficient, 
      fine-tuning is thus not necessary.
CI  - © 2024. The Author(s).
FAU - Grévisse, Christian
AU  - Grévisse C
AD  - Department of Life Sciences and Medicine, University of Luxembourg, 6, avenue de 
      la Fonte, L-4364, Esch-sur-Alzette, Luxembourg. christian.grevisse@uni.lu.
LA  - eng
PT  - Journal Article
DEP - 20240927
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - *Education, Medical, Undergraduate/methods
MH  - Humans
MH  - *Educational Measurement/methods
MH  - Language
MH  - Students, Medical
PMC - PMC11429088
OTO - NOTNLM
OT  - Automatic short answer grading
OT  - GPT-4
OT  - Gemini
OT  - Large language models
OT  - Medical education
COIS- The authors declare no competing interests.
EDAT- 2024/09/28 22:45
MHDA- 2024/09/28 22:46
PMCR- 2024/09/27
CRDT- 2024/09/28 00:17
PHST- 2024/05/19 00:00 [received]
PHST- 2024/09/13 00:00 [accepted]
PHST- 2024/09/28 22:46 [medline]
PHST- 2024/09/28 22:45 [pubmed]
PHST- 2024/09/28 00:17 [entrez]
PHST- 2024/09/27 00:00 [pmc-release]
AID - 10.1186/s12909-024-06026-5 [pii]
AID - 6026 [pii]
AID - 10.1186/s12909-024-06026-5 [doi]
PST - epublish
SO  - BMC Med Educ. 2024 Sep 27;24(1):1060. doi: 10.1186/s12909-024-06026-5.

PMID- 36161553
OWN - NLM
STAT- MEDLINE
DCOM- 20230626
LR  - 20230701
IS  - 1618-7601 (Electronic)
IS  - 1618-7598 (Print)
IS  - 1618-7598 (Linking)
VI  - 24
IP  - 6
DP  - 2023 Aug
TI  - The handling of missing data in trial-based economic evaluations: should data be 
      multiply imputed prior to longitudinal linear mixed-model analyses?
PG  - 951-965
LID - 10.1007/s10198-022-01525-y [doi]
AB  - INTRODUCTION: For the analysis of clinical effects, multiple imputation (MI) of 
      missing data were shown to be unnecessary when using longitudinal linear 
      mixed-models (LLM). It remains unclear whether this also applies to trial-based 
      economic evaluations. Therefore, this study aimed to assess whether MI is 
      required prior to LLM when analyzing longitudinal cost and effect data. METHODS: 
      Two-thousand complete datasets were simulated containing five time points. 
      Incomplete datasets were generated with 10, 25, and 50% missing data in follow-up 
      costs and effects, assuming a Missing At Random (MAR) mechanism. Six different 
      strategies were compared using empirical bias (EB), root-mean-squared error 
      (RMSE), and coverage rate (CR). These strategies were: LLM alone (LLM) and MI 
      with LLM (MI-LLM), and, as reference strategies, mean imputation with LLM 
      (M-LLM), seemingly unrelated regression alone (SUR-CCA), MI with SUR (MI-SUR), 
      and mean imputation with SUR (M-SUR). RESULTS: For costs and effects, LLM, 
      MI-LLM, and MI-SUR performed better than M-LLM, SUR-CCA, and M-SUR, with smaller 
      EBs and RMSEs as well as CRs closers to nominal levels. However, even though LLM, 
      MI-LLM and MI-SUR performed equally well for effects, MI-LLM and MI-SUR were 
      found to perform better than LLM for costs at 10 and 25% missing data. At 50% 
      missing data, all strategies resulted in relatively high EBs and RMSEs for costs. 
      CONCLUSION: LLM should be combined with MI when analyzing trial-based economic 
      evaluation data. MI-SUR is more efficient and can also be used, but then an 
      average intervention effect over time cannot be estimated.
CI  - © 2022. The Author(s).
FAU - Ben, Ângela Jornada
AU  - Ben ÂJ
AUID- ORCID: 0000-0003-4793-9026
AD  - Department of Health Sciences, Faculty of Science, Vrije Universiteit Amsterdam, 
      Amsterdam Public Health Research Institute, Van der Boechorststraat 7, 1081 BT, 
      Amsterdam, The Netherlands. a.jornadaben@vu.nl.
FAU - van Dongen, Johanna M
AU  - van Dongen JM
AD  - Department of Health Sciences, Faculty of Science, Vrije Universiteit Amsterdam, 
      Amsterdam Public Health Research Institute, Van der Boechorststraat 7, 1081 BT, 
      Amsterdam, The Netherlands.
FAU - Alili, Mohamed El
AU  - Alili ME
AD  - Department of Health Sciences, Faculty of Science, Vrije Universiteit Amsterdam, 
      Amsterdam Public Health Research Institute, Van der Boechorststraat 7, 1081 BT, 
      Amsterdam, The Netherlands.
FAU - Heymans, Martijn W
AU  - Heymans MW
AD  - Department of Epidemiology and Data Science, Amsterdam UMC, Amsterdam Public 
      Health Research Institute, Amsterdam, The Netherlands.
FAU - Twisk, Jos W R
AU  - Twisk JWR
AD  - Department of Epidemiology and Data Science, Amsterdam UMC, Amsterdam Public 
      Health Research Institute, Amsterdam, The Netherlands.
FAU - MacNeil-Vroomen, Janet L
AU  - MacNeil-Vroomen JL
AD  - Section of Geriatrics, Department of Internal Medicine, Amsterdam Public Health 
      Research Institute, Amsterdam UMC, University of Amsterdam, Amsterdam, The 
      Netherlands.
FAU - de Wit, Maartje
AU  - de Wit M
AD  - Department of Medical Psychology, Amsterdam UMC, Vrije Universiteit, Amsterdam 
      Public Health Research Institute, Amsterdam, The Netherlands.
FAU - van Dijk, Susan E M
AU  - van Dijk SEM
AD  - Department of Health Sciences, Faculty of Science, Vrije Universiteit Amsterdam, 
      Amsterdam Public Health Research Institute, Van der Boechorststraat 7, 1081 BT, 
      Amsterdam, The Netherlands.
FAU - Oosterhuis, Teddy
AU  - Oosterhuis T
AD  - Netherlands Society of Occupational Medicine (NVAB), Utrecht, The Netherlands.
FAU - Bosmans, Judith E
AU  - Bosmans JE
AD  - Department of Health Sciences, Faculty of Science, Vrije Universiteit Amsterdam, 
      Amsterdam Public Health Research Institute, Van der Boechorststraat 7, 1081 BT, 
      Amsterdam, The Netherlands.
LA  - eng
GR  - 2019075/MdB/EdB/Amsterdam Public Health Research Institute/
GR  - 2019/Amsterdam Public Health Research Institute/
PT  - Journal Article
DEP - 20220926
PL  - Germany
TA  - Eur J Health Econ
JT  - The European journal of health economics : HEPAC : health economics in prevention 
      and care
JID - 101134867
SB  - IM
MH  - Humans
MH  - *Cost-Benefit Analysis
MH  - Linear Models
MH  - Computer Simulation
PMC - PMC10290620
OTO - NOTNLM
OT  - Computer simulation
OT  - Cost–benefit analysis
OT  - Epidemiologic methods
OT  - Longitudinal studies
COIS- The authors have no competing interests to declare that are relevant to the 
      content of this article.
EDAT- 2022/09/27 06:00
MHDA- 2023/06/26 06:42
PMCR- 2022/09/26
CRDT- 2022/09/26 18:19
PHST- 2021/11/22 00:00 [received]
PHST- 2022/08/29 00:00 [accepted]
PHST- 2023/06/26 06:42 [medline]
PHST- 2022/09/27 06:00 [pubmed]
PHST- 2022/09/26 18:19 [entrez]
PHST- 2022/09/26 00:00 [pmc-release]
AID - 10.1007/s10198-022-01525-y [pii]
AID - 1525 [pii]
AID - 10.1007/s10198-022-01525-y [doi]
PST - ppublish
SO  - Eur J Health Econ. 2023 Aug;24(6):951-965. doi: 10.1007/s10198-022-01525-y. Epub 
      2022 Sep 26.

PMID- 39731895
OWN - NLM
STAT- MEDLINE
DCOM- 20250306
LR  - 20250307
IS  - 1532-8171 (Electronic)
IS  - 0735-6757 (Linking)
VI  - 89
DP  - 2025 Mar
TI  - Evaluating LLM-based generative AI tools in emergency triage: A comparative study 
      of ChatGPT Plus, Copilot Pro, and triage nurses.
PG  - 174-181
LID - S0735-6757(24)00707-1 [pii]
LID - 10.1016/j.ajem.2024.12.024 [doi]
AB  - BACKGROUND: The number of emergency department (ED) visits has been on steady 
      increase globally. Artificial Intelligence (AI) technologies, including Large 
      Language Model (LLMs)-based generative AI models, have shown promise in improving 
      triage accuracy. This study evaluates the performance of ChatGPT and Copilot in 
      triage at a high-volume urban hospital, hypothesizing that these tools can match 
      trained physicians' accuracy and reduce human bias amidst ED crowding challenges. 
      METHODS: This single-center, prospective observational study was conducted in an 
      urban ED over one week. Adult patients were enrolled through random 24-h 
      intervals. Exclusions included minors, trauma cases, and incomplete data. Triage 
      nurses assessed patients while an emergency medicine (EM) physician documented 
      clinical vignettes and assigned emergency severity index (ESI) levels. These 
      vignettes were then introduced to ChatGPT and Copilot for comparison with the 
      triage nurse's decision. RESULTS: The overall triage accuracy was 65.2 % for 
      nurses, 66.5 % for ChatGPT, and 61.8 % for Copilot, with no significant 
      difference (p = 0.000). Moderate agreement was observed between the EM physician 
      and ChatGPT, triage nurses, and Copilot (Cohen's Kappa = 0.537, 0.477, and 0.472, 
      respectively). In recognizing high-acuity patients, ChatGPT and Copilot 
      outperformed triage nurses (87.8 % and 85.7 % versus 32.7 %, respectively). 
      Compared to ChatGPT and Copilot, nurses significantly under-triaged patients 
      (p < 0.05). The analysis of predictive performance for ChatGPT, Copilot, and 
      triage nurses demonstrated varying discrimination abilities across ESI levels, 
      all of which were statistically significant (p < 0.05). ChatGPT and Copilot 
      exhibited consistent accuracy across age, gender, and admission time, whereas 
      triage nurses were more likely to mistriage patients under 45 years old. 
      CONCLUSION: ChatGPT and Copilot outperform traditional nurse triage in 
      identifying high-acuity patients, but real-time ED capacity data is crucial to 
      prevent overcrowding and ensure high-quality of emergency care.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Arslan, B
AU  - Arslan B
AD  - Department of Emergency Medicine, Sisli Hamidiye Etfal Training and Research 
      Hospital, Istanbul, Turkey. Electronic address: dr.banuarslan@gmail.com.
FAU - Nuhoglu, C
AU  - Nuhoglu C
AD  - Department of Emergency Medicine, Sisli Hamidiye Etfal Training and Research 
      Hospital, Istanbul, Turkey.
FAU - Satici, M O
AU  - Satici MO
AD  - Department of Emergency Medicine, Sisli Hamidiye Etfal Training and Research 
      Hospital, Istanbul, Turkey.
FAU - Altinbilek, E
AU  - Altinbilek E
AD  - Department of Emergency Medicine, Sisli Hamidiye Etfal Training and Research 
      Hospital, Istanbul, Turkey.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Observational Study
DEP - 20241219
PL  - United States
TA  - Am J Emerg Med
JT  - The American journal of emergency medicine
JID - 8309942
SB  - IM
MH  - Humans
MH  - *Triage/methods
MH  - Prospective Studies
MH  - *Emergency Service, Hospital
MH  - Female
MH  - Male
MH  - Adult
MH  - Middle Aged
MH  - *Artificial Intelligence
MH  - Emergency Nursing
OTO - NOTNLM
OT  - ChatGPT
OT  - Copilot
OT  - Emergency medicine
OT  - Emergency severity index
OT  - Generative artificial intelligence
OT  - Large language models
OT  - Triage
COIS- Declaration of competing interest The authors declare that there is no conflict 
      of interest.
EDAT- 2024/12/29 00:20
MHDA- 2025/03/07 00:21
CRDT- 2024/12/28 18:49
PHST- 2024/09/19 00:00 [received]
PHST- 2024/11/08 00:00 [revised]
PHST- 2024/12/09 00:00 [accepted]
PHST- 2025/03/07 00:21 [medline]
PHST- 2024/12/29 00:20 [pubmed]
PHST- 2024/12/28 18:49 [entrez]
AID - S0735-6757(24)00707-1 [pii]
AID - 10.1016/j.ajem.2024.12.024 [doi]
PST - ppublish
SO  - Am J Emerg Med. 2025 Mar;89:174-181. doi: 10.1016/j.ajem.2024.12.024. Epub 2024 
      Dec 19.

PMID- 39701141
OWN - NLM
STAT- MEDLINE
DCOM- 20241219
LR  - 20250328
IS  - 1098-4275 (Electronic)
IS  - 0031-4005 (Linking)
VI  - 155
IP  - 1
DP  - 2025 Jan 1
TI  - Applying Large Language Models to Assess Quality of Care: Monitoring ADHD 
      Medication Side Effects.
LID - e2024067223 [pii]
LID - 10.1542/peds.2024-067223 [doi]
AB  - OBJECTIVE: To assess the accuracy of a large language model (LLM) in measuring 
      clinician adherence to practice guidelines for monitoring side effects after 
      prescribing medications for children with attention-deficit/hyperactivity 
      disorder (ADHD). METHODS: Retrospective population-based cohort study of 
      electronic health records. Cohort included children aged 6 to 11 years with ADHD 
      diagnosis and 2 or more ADHD medication encounters (stimulants or nonstimulants 
      prescribed) between 2015 and 2022 in a community-based primary health care 
      network (n = 1201). To identify documentation of side effects inquiry, we 
      trained, tested, and deployed an open-source LLM (LLaMA) on all clinical notes 
      from ADHD-related encounters (ADHD diagnosis or ADHD medication prescription), 
      including in-clinic/telehealth and telephone encounters (n = 15 628 notes). Model 
      performance was assessed using holdout and deployment test sets, compared with 
      manual medical record review. RESULTS: The LLaMA model accurately classified 
      notes that contained side effects inquiry (sensitivity = 87.2, 
      specificity = 86.3, area under curve = 0.93 on holdout test set). Analyses 
      revealed no model bias in relation to patient sex or insurance. Mean age (SD) at 
      first prescription was 8.8 (1.6) years; characteristics were mostly similar 
      across patients with and without documented side effects inquiry. Rates of 
      documented side effects inquiry were lower for telephone encounters than for 
      in-clinic/telehealth encounters (51.9% vs 73.0%, P < .001). Side effects inquiry 
      was documented in 61.4% of encounters after stimulant prescriptions and 48.5% of 
      encounters after nonstimulant prescriptions (P = .041). CONCLUSIONS: Deploying an 
      LLM on a variable set of clinical notes, including telephone notes, offered 
      scalable measurement of quality of care and uncovered opportunities to improve 
      psychopharmacological medication management in primary care.
CI  - Copyright © 2024 by the American Academy of Pediatrics.
FAU - Bannett, Yair
AU  - Bannett Y
AD  - Division of Developmental-Behavioral Pediatrics, Stanford University School of 
      Medicine, Stanford, California.
FAU - Gunturkun, Fatma
AU  - Gunturkun F
AD  - Stanford Quantitative Sciences Unit, Stanford, California.
FAU - Pillai, Malvika
AU  - Pillai M
AD  - Veterans Affairs Palo Alto Health Care System, Palo Alto, California.
AD  - Biomedical Informatics Research Center, Stanford University School of Medicine, 
      Stanford, California.
FAU - Herrmann, Jessica E
AU  - Herrmann JE
AD  - Stanford University School of Medicine, Stanford, California.
FAU - Luo, Ingrid
AU  - Luo I
AD  - Stanford Quantitative Sciences Unit, Stanford, California.
FAU - Huffman, Lynne C
AU  - Huffman LC
AD  - Division of Developmental-Behavioral Pediatrics, Stanford University School of 
      Medicine, Stanford, California.
FAU - Feldman, Heidi M
AU  - Feldman HM
AD  - Division of Developmental-Behavioral Pediatrics, Stanford University School of 
      Medicine, Stanford, California.
LA  - eng
GR  - K23 MH128455/MH/NIMH NIH HHS/United States
PT  - Journal Article
PL  - United States
TA  - Pediatrics
JT  - Pediatrics
JID - 0376422
RN  - 0 (Central Nervous System Stimulants)
SB  - IM
UOF - medRxiv. 2024 Apr 24:2024.04.23.24306225. doi: 10.1101/2024.04.23.24306225. PMID: 
      38712037
MH  - Humans
MH  - Child
MH  - *Attention Deficit Disorder with Hyperactivity/drug therapy
MH  - Retrospective Studies
MH  - Male
MH  - Female
MH  - Central Nervous System Stimulants/adverse effects/therapeutic use
MH  - Electronic Health Records
MH  - Guideline Adherence
MH  - Cohort Studies
MH  - Quality of Health Care
MH  - Primary Health Care
MH  - Telemedicine
EDAT- 2024/12/20 00:23
MHDA- 2024/12/20 00:24
CRDT- 2024/12/19 19:03
PHST- 2024/04/26 00:00 [received]
PHST- 2024/10/07 00:00 [accepted]
PHST- 2024/12/20 00:24 [medline]
PHST- 2024/12/20 00:23 [pubmed]
PHST- 2024/12/19 19:03 [entrez]
AID - 200340 [pii]
AID - 10.1542/peds.2024-067223 [doi]
PST - ppublish
SO  - Pediatrics. 2025 Jan 1;155(1):e2024067223. doi: 10.1542/peds.2024-067223.

PMID- 38188855
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240109
IS  - 2055-2076 (Print)
IS  - 2055-2076 (Electronic)
IS  - 2055-2076 (Linking)
VI  - 10
DP  - 2024 Jan-Dec
TI  - Performance of ChatGPT incorporated chain-of-thought method in bilingual nuclear 
      medicine physician board examinations.
PG  - 20552076231224074
LID - 10.1177/20552076231224074 [doi]
LID - 20552076231224074
AB  - OBJECTIVE: This research explores the performance of ChatGPT, compared to human 
      doctors, in bilingual, Mandarin Chinese and English, medical specialty exam in 
      Nuclear Medicine in Taiwan. METHODS: The study employed generative pre-trained 
      transformer (GPT-4) and integrated chain-of-thoughts (COT) method to enhance 
      performance by triggering and explaining the thinking process to answer the 
      question in a coherent and logical manner. Questions from the Taiwanese Nuclear 
      Medicine Specialty Exam served as the basis for testing. The research analyzed 
      the correctness of AI responses in different sections of the exam and explored 
      the influence of question length and language proportion on accuracy. RESULTS: 
      AI, especially ChatGPT with COT, exhibited exceptional capabilities in 
      theoretical knowledge, clinical medicine, and handling integrated questions, 
      often surpassing, or matching human doctor performance. However, AI struggled 
      with questions related to medical regulations. The analysis of question length 
      showed that questions within the 109-163 words range yielded the highest 
      accuracy. Moreover, an increase in the proportion of English words in questions 
      improved both AI and human accuracy. CONCLUSIONS: This research highlights the 
      potential and challenges of AI in the medical field. ChatGPT demonstrates 
      significant competence in various aspects of medical knowledge. However, areas 
      like medical regulations require improvement. The study also suggests that AI may 
      help in evaluating exam question difficulty and maintaining fairness in 
      examinations. These findings shed light on AI role in the medical field, with 
      potential applications in healthcare education, exam preparation, and 
      multilingual environments. Ongoing AI advancements are expected to further 
      enhance AI utility in the medical domain.
CI  - © The Author(s) 2024.
FAU - Ting, Yu-Ting
AU  - Ting YT
AD  - Department of Nuclear Medicine and PET Center, China Medical University Hospital, 
      China Medical University, Taichung. RINGGOLD: 38020
FAU - Hsieh, Te-Chun
AU  - Hsieh TC
AD  - Department of Nuclear Medicine and PET Center, China Medical University Hospital, 
      China Medical University, Taichung. RINGGOLD: 38020
AD  - Department of Biomedical Imaging and Radiological Science, China Medical 
      University, Taichung.
FAU - Wang, Yuh-Feng
AU  - Wang YF
AD  - Department of Nuclear Medicine, Taipei Veterans General Hospital, Taipei. 
      RINGGOLD: 46615
AD  - Department of Biomedical Imaging and Radiological Sciences, National Yang Ming 
      Chiao Tung University, Taipei.
AD  - Department of Medical Imaging and Radiological Technology, Yuanpei University of 
      Medical Technology, Hsinchu.
FAU - Kuo, Yu-Chieh
AU  - Kuo YC
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 38020
FAU - Chen, Yi-Jin
AU  - Chen YJ
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 38020
FAU - Chan, Pak-Ki
AU  - Chan PK
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 38020
FAU - Kao, Chia-Hung
AU  - Kao CH
AUID- ORCID: 0000-0002-6368-3676
AD  - Department of Nuclear Medicine and PET Center, China Medical University Hospital, 
      China Medical University, Taichung. RINGGOLD: 38020
AD  - Artificial Intelligence Center, China Medical University Hospital, China Medical 
      University, Taichung. RINGGOLD: 38020
AD  - Graduate Institute of Biomedical Sciences, School of Medicine, College of 
      Medicine, China Medical University, Taichung.
AD  - Department of Bioinformatics and Medical Engineering, Asia University, Taichung.
LA  - eng
PT  - Journal Article
DEP - 20240105
PL  - United States
TA  - Digit Health
JT  - Digital health
JID - 101690863
PMC - PMC10771043
OTO - NOTNLM
OT  - ChatGPT
OT  - chain-of-thoughts (COT)
OT  - multilingual environment
OT  - nuclear medicine exam
COIS- The authors declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/01/08 06:42
MHDA- 2024/01/08 06:43
PMCR- 2024/01/05
CRDT- 2024/01/08 05:24
PHST- 2023/08/16 00:00 [received]
PHST- 2023/12/14 00:00 [accepted]
PHST- 2024/01/08 06:43 [medline]
PHST- 2024/01/08 06:42 [pubmed]
PHST- 2024/01/08 05:24 [entrez]
PHST- 2024/01/05 00:00 [pmc-release]
AID - 10.1177_20552076231224074 [pii]
AID - 10.1177/20552076231224074 [doi]
PST - epublish
SO  - Digit Health. 2024 Jan 5;10:20552076231224074. doi: 10.1177/20552076231224074. 
      eCollection 2024 Jan-Dec.

PMID- 39967059
OWN - NLM
STAT- Publisher
LR  - 20250219
IS  - 1464-410X (Electronic)
IS  - 1464-4096 (Linking)
DP  - 2025 Feb 18
TI  - Evaluating interactions of patients with large language models for medical 
      information.
LID - 10.1111/bju.16676 [doi]
AB  - OBJECTIVES: To explore the interaction of real-world patients with a chatbot in a 
      clinical setting, investigating key aspects of medical information provided by 
      large language models (LLMs). PATIENTS AND METHODS: The study enrolled 300 
      patients seeking urological counselling between February and July 2024. First, 
      participants voluntarily conversed with a Generative Pre-trained Transformer 4 
      (GPT-4) powered chatbot to ask questions related to their medical situation. In 
      the following survey, patients rated the perceived utility, completeness, and 
      understandability of the information provided during the simulated conversation 
      as well as user-friendliness. Finally, patients were asked which, in their 
      experience, best answered their questions: LLMs, urologists, or search engines. 
      RESULTS: A total of 292 patients completed the study. The majority of patients 
      perceived the chatbot as providing useful, complete, and understandable 
      information, as well as being user-friendly. However, the ability of human 
      urologists to answer medical questions in an understandable way was rated higher 
      than of LLMs. Interestingly, 53% of participants rated the question-answering 
      ability of LLMs higher than search engines. Age was not associated with 
      preferences. Limitations include social desirability and sampling biases. 
      DISCUSSION: This study highlights the potential of LLMs to enhance patient 
      education and communication in clinical settings, with patients valuing their 
      user-friendliness and comprehensiveness for medical information. By addressing 
      preliminary questions, LLMs could potentially relieve time constraints on 
      healthcare providers, enabling medical personnel to focus on complex inquiries 
      and patient care.
CI  - © 2025 The Author(s). BJU International published by John Wiley & Sons Ltd on 
      behalf of BJU International.
FAU - Carl, Nicolas
AU  - Carl N
AUID- ORCID: 0009-0002-0080-3455
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
AD  - Division of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Haggenmüller, Sarah
AU  - Haggenmüller S
AD  - Division of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Wies, Christoph
AU  - Wies C
AD  - Medical Faculty, Ruprecht-Karls University of Heidelberg, Mannheim, Germany.
AD  - Division of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Nguyen, Lisa
AU  - Nguyen L
AD  - Medical Faculty Mannheim, Ruprecht-Karls University of Heidelberg, Mannheim, 
      Germany.
FAU - Winterstein, Jana Theres
AU  - Winterstein JT
AD  - Medical Faculty, Ruprecht-Karls University of Heidelberg, Mannheim, Germany.
AD  - Division of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Hetz, Martin Joachim
AU  - Hetz MJ
AD  - Division of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Mangold, Maurin Helen
AU  - Mangold MH
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Hartung, Friedrich Otto
AU  - Hartung FO
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Grüne, Britta
AU  - Grüne B
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Holland-Letz, Tim
AU  - Holland-Letz T
AD  - Department of Biostatistics, German Cancer Research Center (DKFZ), Heidelberg, 
      Germany.
FAU - Michel, Maurice Stephan
AU  - Michel MS
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
FAU - Brinker, Titus Josef
AU  - Brinker TJ
AD  - Division of Digital Prevention, Diagnostics and Therapy Guidance, German Cancer 
      Research Center (DKFZ), Heidelberg, Germany.
FAU - Wessels, Frederik
AU  - Wessels F
AUID- ORCID: 0000-0003-4213-8692
AD  - Department of Urology, University Medical Center Mannheim, Ruprecht-Karls 
      University of Heidelberg, Mannheim, Germany.
LA  - eng
PT  - Journal Article
DEP - 20250218
PL  - England
TA  - BJU Int
JT  - BJU international
JID - 100886721
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - clinical trial
OT  - implementation science
OT  - large language models
OT  - patient interaction
EDAT- 2025/02/19 06:22
MHDA- 2025/02/19 06:22
CRDT- 2025/02/19 00:53
PHST- 2025/02/19 06:22 [medline]
PHST- 2025/02/19 06:22 [pubmed]
PHST- 2025/02/19 00:53 [entrez]
AID - 10.1111/bju.16676 [doi]
PST - aheadofprint
SO  - BJU Int. 2025 Feb 18. doi: 10.1111/bju.16676.

PMID- 38236635
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240204
IS  - 2291-9694 (Print)
IS  - 2291-9694 (Electronic)
IS  - 2291-9694 (Linking)
VI  - 12
DP  - 2024 Jan 18
TI  - Predicting Depression Risk in Patients With Cancer Using Multimodal Data: 
      Algorithm Development Study.
PG  - e51925
LID - 10.2196/51925 [doi]
LID - e51925
AB  - BACKGROUND: Patients with cancer starting systemic treatment programs, such as 
      chemotherapy, often develop depression. A prediction model may assist physicians 
      and health care workers in the early identification of these vulnerable patients. 
      OBJECTIVE: This study aimed to develop a prediction model for depression risk 
      within the first month of cancer treatment. METHODS: We included 16,159 patients 
      diagnosed with cancer starting chemo- or radiotherapy treatment between 2008 and 
      2021. Machine learning models (eg, least absolute shrinkage and selection 
      operator [LASSO] logistic regression) and natural language processing models 
      (Bidirectional Encoder Representations from Transformers [BERT]) were used to 
      develop multimodal prediction models using both electronic health record data and 
      unstructured text (patient emails and clinician notes). Model performance was 
      assessed in an independent test set (n=5387, 33%) using area under the receiver 
      operating characteristic curve (AUROC), calibration curves, and decision curve 
      analysis to assess initial clinical impact use. RESULTS: Among 16,159 patients, 
      437 (2.7%) received a depression diagnosis within the first month of treatment. 
      The LASSO logistic regression models based on the structured data (AUROC 0.74, 
      95% CI 0.71-0.78) and structured data with email classification scores (AUROC 
      0.74, 95% CI 0.71-0.78) had the best discriminative performance. The BERT models 
      based on clinician notes and structured data with email classification scores had 
      AUROCs around 0.71. The logistic regression model based on email classification 
      scores alone performed poorly (AUROC 0.54, 95% CI 0.52-0.56), and the model based 
      solely on clinician notes had the worst performance (AUROC 0.50, 95% CI 
      0.49-0.52). Calibration was good for the logistic regression models, whereas the 
      BERT models produced overly extreme risk estimates even after recalibration. 
      There was a small range of decision thresholds for which the best-performing 
      model showed promising clinical effectiveness use. The risks were underestimated 
      for female and Black patients. CONCLUSIONS: The results demonstrated the 
      potential and limitations of machine learning and multimodal models for 
      predicting depression risk in patients with cancer. Future research is needed to 
      further validate these models, refine the outcome label and predictors related to 
      mental health, and address biases across subgroups.
CI  - ©Anne de Hond, Marieke van Buchem, Claudio Fanconi, Mohana Roy, Douglas Blayney, 
      Ilse Kant, Ewout Steyerberg, Tina Hernandez-Boussard. Originally published in 
      JMIR Medical Informatics (https://medinform.jmir.org), 18.01.2024.
FAU - de Hond, Anne
AU  - de Hond A
AUID- ORCID: 0000-0002-3473-3398
AD  - Clinical AI Implementation and Research Lab, Leiden University Medical Centre, 
      Leiden, Netherlands.
AD  - Department of Biomedical Data Sciences, Leiden University Medical Centre, Leiden, 
      Netherlands.
AD  - Department of Medicine (Biomedical Informatics), Stanford Medicine, Stanford 
      University, Stanford, CA, United States.
FAU - van Buchem, Marieke
AU  - van Buchem M
AUID- ORCID: 0000-0002-2917-0842
AD  - Clinical AI Implementation and Research Lab, Leiden University Medical Centre, 
      Leiden, Netherlands.
AD  - Department of Biomedical Data Sciences, Leiden University Medical Centre, Leiden, 
      Netherlands.
AD  - Department of Medicine (Biomedical Informatics), Stanford Medicine, Stanford 
      University, Stanford, CA, United States.
FAU - Fanconi, Claudio
AU  - Fanconi C
AUID- ORCID: 0000-0001-5308-3821
AD  - Department of Medicine (Biomedical Informatics), Stanford Medicine, Stanford 
      University, Stanford, CA, United States.
AD  - Department of Electrical Engineering and Information Technology, ETH Zürich, 
      Zürich, Switzerland.
FAU - Roy, Mohana
AU  - Roy M
AUID- ORCID: 0000-0002-9997-8935
AD  - Department of Medical Oncology, Stanford Medicine, Stanford University, Stanford, 
      CA, United States.
FAU - Blayney, Douglas
AU  - Blayney D
AUID- ORCID: 0000-0002-7931-4533
AD  - Department of Medical Oncology, Stanford Medicine, Stanford University, Stanford, 
      CA, United States.
FAU - Kant, Ilse
AU  - Kant I
AUID- ORCID: 0000-0002-5273-5178
AD  - Clinical AI Implementation and Research Lab, Leiden University Medical Centre, 
      Leiden, Netherlands.
AD  - Department of Digital Health, University Medical Centre Utrecht, Utrecht, 
      Netherlands.
FAU - Steyerberg, Ewout
AU  - Steyerberg E
AUID- ORCID: 0000-0002-7787-0122
AD  - Clinical AI Implementation and Research Lab, Leiden University Medical Centre, 
      Leiden, Netherlands.
AD  - Department of Biomedical Data Sciences, Leiden University Medical Centre, Leiden, 
      Netherlands.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AUID- ORCID: 0000-0001-6553-3455
AD  - Department of Medicine (Biomedical Informatics), Stanford Medicine, Stanford 
      University, Stanford, CA, United States.
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA, United 
      States.
AD  - Department of Epidemiology & Population Health (by courtesy), Stanford 
      University, Stanford, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20240118
PL  - Canada
TA  - JMIR Med Inform
JT  - JMIR medical informatics
JID - 101645109
PMC - PMC10835583
OTO - NOTNLM
OT  - artificial intelligence
OT  - cancer
OT  - cancer care
OT  - cancer treatment
OT  - care
OT  - chemotherapy
OT  - clinical decision support
OT  - decision support
OT  - depression
OT  - depression risk
OT  - diagnosis
OT  - machine learning
OT  - mental health
OT  - natural language processing
OT  - oncology
OT  - patients with cancer
OT  - prediction model
OT  - radiotherapy
OT  - validation
COIS- Conflicts of Interest: DB reports institutional research funding from 
      BeyondSpring, leadership roles or stock ownership in Artelo and Madora, and 
      personal fees from G1 Therapeutics, Bristol Myers Squibb, Merck & Co Inc, and Eli 
      Lilly and Company all outside the submitted work. THB is a board member and 
      stockholder of Athelo Health, a stockholder at Verantos, Inc, and a consultant 
      for Grai-Matter outside the submitted work. The other authors declare no 
      competing interests.
EDAT- 2024/01/18 12:42
MHDA- 2024/01/18 12:43
PMCR- 2024/01/18
CRDT- 2024/01/18 11:54
PHST- 2023/08/17 00:00 [received]
PHST- 2023/12/08 00:00 [accepted]
PHST- 2023/11/11 00:00 [revised]
PHST- 2024/01/18 12:43 [medline]
PHST- 2024/01/18 12:42 [pubmed]
PHST- 2024/01/18 11:54 [entrez]
PHST- 2024/01/18 00:00 [pmc-release]
AID - v12i1e51925 [pii]
AID - 10.2196/51925 [doi]
PST - epublish
SO  - JMIR Med Inform. 2024 Jan 18;12:e51925. doi: 10.2196/51925.

PMID- 39875475
OWN - NLM
STAT- MEDLINE
DCOM- 20250128
LR  - 20250204
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 15
IP  - 1
DP  - 2025 Jan 28
TI  - Large language models improve the identification of emergency department visits 
      for symptomatic kidney stones.
PG  - 3503
LID - 10.1038/s41598-025-86632-5 [doi]
LID - 3503
AB  - Recent advancements of large language models (LLMs) like generative pre-trained 
      transformer 4 (GPT-4) have generated significant interest among the scientific 
      community. Yet, the potential of these models to be utilized in clinical settings 
      remains largely unexplored. In this study, we investigated the abilities of 
      multiple LLMs and traditional machine learning models to analyze emergency 
      department (ED) reports and determine if the corresponding visits were due to 
      symptomatic kidney stones. Leveraging a dataset of manually annotated ED reports, 
      we developed strategies to enhance LLMs including prompt optimization, zero- and 
      few-shot prompting, fine-tuning, and prompt augmentation. Further, we implemented 
      fairness assessment and bias mitigation methods to investigate the potential 
      disparities by LLMs with respect to race and gender. A clinical expert manually 
      assessed the explanations generated by GPT-4 for its predictions to determine if 
      they were sound, factually correct, unrelated to the input prompt, or potentially 
      harmful. The best results were achieved by GPT-4 (macro-F1 = 0.833, 95% 
      confidence interval [CI] 0.826-0.841) and GPT-3.5 (macro-F1 = 0.796, 95% CI 
      0.796-0.796). Ablation studies revealed that the initial pre-trained GPT-3.5 
      model benefits from fine-tuning. Adding demographic information and prior disease 
      history to the prompts allows LLMs to make better decisions. Bias assessment 
      found that GPT-4 exhibited no racial or gender disparities, in contrast to 
      GPT-3.5, which failed to effectively model racial diversity.
CI  - © 2025. The Author(s).
FAU - Bejan, Cosmin A
AU  - Bejan CA
AD  - Department of Biomedical Informatics, Vanderbilt University School of Medicine, 
      Vanderbilt University Medical Center, 2525 West End Avenue, Suite 1500, 
      Nashville, TN, 37232, USA. adi.bejan@vanderbilt.edu.
FAU - Reed, Amy M
AU  - Reed AM
AD  - Department of Urology, Vanderbilt University Medical Center, Nashville, USA.
FAU - Mikula, Matthew
AU  - Mikula M
AD  - Department of Urology, Vanderbilt University Medical Center, Nashville, USA.
FAU - Zhang, Siwei
AU  - Zhang S
AD  - Department of Biostatistics, Vanderbilt University Medical Center, Nashville, 
      USA.
FAU - Xu, Yaomin
AU  - Xu Y
AD  - Department of Biomedical Informatics, Vanderbilt University School of Medicine, 
      Vanderbilt University Medical Center, 2525 West End Avenue, Suite 1500, 
      Nashville, TN, 37232, USA.
AD  - Department of Biostatistics, Vanderbilt University Medical Center, Nashville, 
      USA.
FAU - Fabbri, Daniel
AU  - Fabbri D
AD  - Department of Biomedical Informatics, Vanderbilt University School of Medicine, 
      Vanderbilt University Medical Center, 2525 West End Avenue, Suite 1500, 
      Nashville, TN, 37232, USA.
FAU - Embí, Peter J
AU  - Embí PJ
AD  - Department of Biomedical Informatics, Vanderbilt University School of Medicine, 
      Vanderbilt University Medical Center, 2525 West End Avenue, Suite 1500, 
      Nashville, TN, 37232, USA.
FAU - Hsi, Ryan S
AU  - Hsi RS
AD  - Department of Urology, Vanderbilt University Medical Center, Nashville, USA.
LA  - eng
GR  - R21DK127075/DK/NIDDK NIH HHS/United States
GR  - R21 HD113234/HD/NICHD NIH HHS/United States
GR  - donation/Chris and Helga Holland/
GR  - UL1TR002243/TR/NCATS NIH HHS/United States
GR  - R21 DK127075/DK/NIDDK NIH HHS/United States
GR  - UL1 TR002243/TR/NCATS NIH HHS/United States
GR  - R21HD113234/Eunice Kennedy Shriver National Institute of Child Health and Human 
      Development/
PT  - Journal Article
DEP - 20250128
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
UOF - medRxiv. 2024 Aug 13:2024.08.12.24311870. doi: 10.1101/2024.08.12.24311870. PMID: 
      39211884
MH  - Humans
MH  - *Kidney Calculi
MH  - *Emergency Service, Hospital
MH  - Female
MH  - Male
MH  - *Machine Learning
MH  - Middle Aged
MH  - Adult
MH  - Emergency Room Visits
PMC - PMC11775227
OTO - NOTNLM
OT  - GPT-3.5
OT  - GPT-4
OT  - Kidney stones
OT  - LLMs
OT  - Large language models
OT  - Llama-2
OT  - Nephrolithiasis
COIS- Competing interests: The authors declare no competing interests.
EDAT- 2025/01/29 00:20
MHDA- 2025/01/29 00:21
PMCR- 2025/01/28
CRDT- 2025/01/28 23:19
PHST- 2024/10/05 00:00 [received]
PHST- 2025/01/13 00:00 [accepted]
PHST- 2025/01/29 00:21 [medline]
PHST- 2025/01/29 00:20 [pubmed]
PHST- 2025/01/28 23:19 [entrez]
PHST- 2025/01/28 00:00 [pmc-release]
AID - 10.1038/s41598-025-86632-5 [pii]
AID - 86632 [pii]
AID - 10.1038/s41598-025-86632-5 [doi]
PST - epublish
SO  - Sci Rep. 2025 Jan 28;15(1):3503. doi: 10.1038/s41598-025-86632-5.

PMID- 38912449
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240625
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 10
IP  - 11
DP  - 2024 Jun 15
TI  - Deep-GenMut: Automated genetic mutation classification in oncology: A deep 
      learning comparative study.
PG  - e32279
LID - 10.1016/j.heliyon.2024.e32279 [doi]
LID - e32279
AB  - Early cancer detection and treatment depend on the discovery of specific genes 
      that cause cancer. The classification of genetic mutations was initially done 
      manually. However, this process relies on pathologists and can be a 
      time-consuming task. Therefore, to improve the precision of clinical 
      interpretation, researchers have developed computational algorithms that leverage 
      next-generation sequencing technologies for automated mutation analysis. This 
      paper utilized four deep learning classification models with training collections 
      of biomedical texts. These models comprise bidirectional encoder representations 
      from transformers for Biomedical text mining (BioBERT), a specialized language 
      model implemented for biological contexts. Impressive results in multiple tasks, 
      including text classification, language inference, and question answering, can be 
      obtained by simply adding an extra layer to the BioBERT model. Moreover, 
      bidirectional encoder representations from transformers (BERT), long short-term 
      memory (LSTM), and bidirectional LSTM (BiLSTM) have been leveraged to produce 
      very good results in categorizing genetic mutations based on textual evidence. 
      The dataset used in the work was created by Memorial Sloan Kettering Cancer 
      Center (MSKCC), which contains several mutations. Furthermore, this dataset poses 
      a major classification challenge in the Kaggle research prediction competitions. 
      In carrying out the work, three challenges were identified: enormous text length, 
      biased representation of the data, and repeated data instances. Based on the 
      commonly used evaluation metrics, the experimental results show that the BioBERT 
      model outperforms other models with an F1 score of 0.87 and 0.850 MCC, which can 
      be considered as improved performance compared to similar results in the 
      literature that have an F1 score of 0.70 achieved with the BERT model.
CI  - © 2024 The Authors.
FAU - Elsamahy, Emad A
AU  - Elsamahy EA
AD  - College of Computing and Information Technology, Arab Academy for Science, 
      Technology, and Maritime Transport, Cairo, Egypt.
FAU - Ahmed, Asmaa E
AU  - Ahmed AE
AD  - College of Computing and Information Technology, Arab Academy for Science, 
      Technology, and Maritime Transport, Cairo, Egypt.
FAU - Shoala, Tahseen
AU  - Shoala T
AD  - Environmental Biotechnology Department, College of Biotechnology, Misr University 
      for Science and Technology, Giza, 12563, Egypt.
FAU - Maghraby, Fahima A
AU  - Maghraby FA
AD  - College of Computing and Information Technology, Arab Academy for Science, 
      Technology, and Maritime Transport, Cairo, Egypt.
LA  - eng
PT  - Journal Article
DEP - 20240531
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC11190593
OTO - NOTNLM
OT  - BERT
OT  - BiLSTM
OT  - BioBERT
OT  - Cancer detection
OT  - Deep learning
OT  - Genetic mutation
OT  - LSTM
OT  - Text classification
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2024/06/24 06:42
MHDA- 2024/06/24 06:43
PMCR- 2024/05/31
CRDT- 2024/06/24 05:39
PHST- 2024/01/12 00:00 [received]
PHST- 2024/05/30 00:00 [revised]
PHST- 2024/05/31 00:00 [accepted]
PHST- 2024/06/24 06:43 [medline]
PHST- 2024/06/24 06:42 [pubmed]
PHST- 2024/06/24 05:39 [entrez]
PHST- 2024/05/31 00:00 [pmc-release]
AID - S2405-8440(24)08310-5 [pii]
AID - e32279 [pii]
AID - 10.1016/j.heliyon.2024.e32279 [doi]
PST - epublish
SO  - Heliyon. 2024 May 31;10(11):e32279. doi: 10.1016/j.heliyon.2024.e32279. 
      eCollection 2024 Jun 15.

PMID- 38244997
OWN - NLM
STAT- MEDLINE
DCOM- 20240405
LR  - 20250120
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 4
DP  - 2024 Apr 3
TI  - Measuring quality-of-care in treatment of young children with 
      attention-deficit/hyperactivity disorder using pre-trained language models.
PG  - 949-957
LID - 10.1093/jamia/ocae001 [doi]
AB  - OBJECTIVE: To measure pediatrician adherence to evidence-based guidelines in the 
      treatment of young children with attention-deficit/hyperactivity disorder (ADHD) 
      in a diverse healthcare system using natural language processing (NLP) 
      techniques. MATERIALS AND METHODS: We extracted structured and free-text data 
      from electronic health records (EHRs) of all office visits (2015-2019) of 
      children aged 4-6 years in a community-based primary healthcare network in 
      California, who had ≥1 visits with an ICD-10 diagnosis of ADHD. Two pediatricians 
      annotated clinical notes of the first ADHD visit for 423 patients. 
      Inter-annotator agreement (IAA) was assessed for the recommendation for the 
      first-line behavioral treatment (F-measure = 0.89). Four pre-trained language 
      models, including BioClinical Bidirectional Encoder Representations from 
      Transformers (BioClinicalBERT), were used to identify behavioral treatment 
      recommendations using a 70/30 train/test split. For temporal validation, we 
      deployed BioClinicalBERT on 1,020 unannotated notes from other ADHD visits and 
      well-care visits; all positively classified notes (n = 53) and 5% of negatively 
      classified notes (n = 50) were manually reviewed. RESULTS: Of 423 patients, 313 
      (74%) were male; 298 (70%) were privately insured; 138 (33%) were White; 61 (14%) 
      were Hispanic. The BioClinicalBERT model trained on the first ADHD visits 
      achieved F1 = 0.76, precision = 0.81, recall = 0.72, and AUC = 0.81 [0.72-0.89]. 
      Temporal validation achieved F1 = 0.77, precision = 0.68, and recall = 0.88. 
      Fairness analysis revealed low model performance in publicly insured patients 
      (F1 = 0.53). CONCLUSION: Deploying pre-trained language models on a variable set 
      of clinical notes accurately captured pediatrician adherence to guidelines in the 
      treatment of children with ADHD. Validating this approach in other patient 
      populations is needed to achieve equitable measurement of quality of care at 
      scale and improve clinical care for mental health conditions.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Pillai, Malvika
AU  - Pillai M
AUID- ORCID: 0000-0001-8739-189X
AD  - Department of Biomedical Data Science, Stanford University School of Medicine, 
      Stanford, CA 94305, United States.
FAU - Posada, Jose
AU  - Posada J
AD  - Computer Science Department, University of the North, Barranquilla 080020, 
      Colombia.
FAU - Gardner, Rebecca M
AU  - Gardner RM
AD  - Department of Epidemiology and Population Health, Stanford University School of 
      Medicine, Stanford, CA 94305, United States.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AUID- ORCID: 0000-0001-6553-3455
AD  - Department of Biomedical Data Science, Stanford University School of Medicine, 
      Stanford, CA 94305, United States.
FAU - Bannett, Yair
AU  - Bannett Y
AUID- ORCID: 0000-0001-5134-3300
AD  - Division of Developmental-Behavioral Pediatrics, Department of Pediatrics, 
      Stanford University School of Medicine, Stanford, CA 94304, United States.
LA  - eng
GR  - K23 MH128455/MH/NIMH NIH HHS/United States
GR  - T32 HL151323/HL/NHLBI NIH HHS/United States
GR  - K23MH128455/NH/NIH HHS/United States
GR  - 1T32HL151323/HL/NHLBI NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Child
MH  - Humans
MH  - Male
MH  - Child, Preschool
MH  - Female
MH  - *Attention Deficit Disorder with Hyperactivity/diagnosis/drug therapy
MH  - Hispanic or Latino
MH  - Guideline Adherence
MH  - Pediatricians
MH  - Natural Language Processing
PMC - PMC10990536
OTO - NOTNLM
OT  - attention-deficit/hyperactivity disorder
OT  - electronic health record
OT  - health care quality
OT  - health services research
OT  - natural language processing
COIS- The authors have no competing interests to declare.
EDAT- 2024/01/21 00:42
MHDA- 2024/04/05 06:44
PMCR- 2025/01/19
CRDT- 2024/01/20 20:13
PHST- 2023/09/26 00:00 [received]
PHST- 2023/12/07 00:00 [revised]
PHST- 2024/01/03 00:00 [accepted]
PHST- 2024/04/05 06:44 [medline]
PHST- 2024/01/21 00:42 [pubmed]
PHST- 2024/01/20 20:13 [entrez]
PHST- 2025/01/19 00:00 [pmc-release]
AID - 7582076 [pii]
AID - ocae001 [pii]
AID - 10.1093/jamia/ocae001 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Apr 3;31(4):949-957. doi: 10.1093/jamia/ocae001.

PMID- 39316421
OWN - NLM
STAT- MEDLINE
DCOM- 20240924
LR  - 20241011
IS  - 2561-7605 (Electronic)
IS  - 2561-7605 (Linking)
VI  - 7
DP  - 2024 Sep 24
TI  - Extracting Critical Information from Unstructured Clinicians' Notes Data to 
      Identify Dementia Severity Using a Rule-Based Approach: Feasibility Study.
PG  - e57926
LID - 10.2196/57926 [doi]
LID - e57926
AB  - BACKGROUND: The severity of Alzheimer disease and related dementias (ADRD) is 
      rarely documented in structured data fields in electronic health records (EHRs). 
      Although this information is important for clinical monitoring and 
      decision-making, it is often undocumented or "hidden" in unstructured text fields 
      and not readily available for clinicians to act upon. OBJECTIVE: We aimed to 
      assess the feasibility and potential bias in using keywords and rule-based 
      matching for obtaining information about the severity of ADRD from EHR data. 
      METHODS: We used EHR data from a large academic health care system that included 
      patients with a primary discharge diagnosis of ADRD based on ICD-9 (International 
      Classification of Diseases, Ninth Revision) and ICD-10 (International Statistical 
      Classification of Diseases, Tenth Revision) codes between 2014 and 2019. We first 
      assessed the presence of ADRD severity information and then the severity of ADRD 
      in the EHR. Clinicians' notes were used to determine the severity of ADRD based 
      on two criteria: (1) scores from the Mini Mental State Examination and Montreal 
      Cognitive Assessment and (2) explicit terms for ADRD severity (eg, "mild 
      dementia" and "advanced Alzheimer disease"). We compiled a list of common ADRD 
      symptoms, cognitive test names, and disease severity terms, refining it 
      iteratively based on previous literature and clinical expertise. Subsequently, we 
      used rule-based matching in Python using standard open-source data analysis 
      libraries to identify the context in which specific words or phrases were 
      mentioned. We estimated the prevalence of documented ADRD severity and assessed 
      the performance of our rule-based algorithm. RESULTS: We included 9115 eligible 
      patients with over 65,000 notes from the providers. Overall, 22.93% (2090/9115) 
      of patients were documented with mild ADRD, 20.87% (1902/9115) were documented 
      with moderate or severe ADRD, and 56.20% (5123/9115) did not have any 
      documentation of the severity of their ADRD. For the task of determining the 
      presence of any ADRD severity information, our algorithm achieved an accuracy of 
      >95%, specificity of >95%, sensitivity of >90%, and an F(1)-score of >83%. For 
      the specific task of identifying the actual severity of ADRD, the algorithm 
      performed well with an accuracy of >91%, specificity of >80%, sensitivity of 
      >88%, and F(1)-score of >92%. Comparing patients with mild ADRD to those with 
      more advanced ADRD, the latter group tended to contain older, more likely female, 
      and Black patients, and having received their diagnoses in primary care or 
      in-hospital settings. Relative to patients with undocumented ADRD severity, those 
      with documented ADRD severity had a similar distribution in terms of sex, race, 
      and rural or urban residence. CONCLUSIONS: Our study demonstrates the feasibility 
      of using a rule-based matching algorithm to identify ADRD severity from 
      unstructured EHR report data. However, it is essential to acknowledge potential 
      biases arising from differences in documentation practices across various health 
      care systems.
CI  - ©Ravi Prakash, Matthew E Dupre, Truls Østbye, Hanzhang Xu. Originally published 
      in JMIR Aging (https://aging.jmir.org), 24.09.2024.
FAU - Prakash, Ravi
AU  - Prakash R
AUID- ORCID: 0000-0002-4020-1590
AD  - Thomas Lord Department of Mechanical Engineering and Materials Science, Pratt 
      School of Engineering, Duke University, Durham, NC, United States.
FAU - Dupre, Matthew E
AU  - Dupre ME
AUID- ORCID: 0000-0002-0976-4715
AD  - Department of Population Health Sciences, School of Medicine, Duke University, 
      Durham, NC, United States.
AD  - Department of Sociology, Trinity College of Arts & Sciences, Duke University, 
      Durham, NC, United States.
FAU - Østbye, Truls
AU  - Østbye T
AUID- ORCID: 0000-0002-0662-7440
AD  - Department of Population Health Sciences, School of Medicine, Duke University, 
      Durham, NC, United States.
AD  - Department of Family Medicine and Community Health, School of Medicine, Duke 
      Univeristy, Durham, NC, United States.
FAU - Xu, Hanzhang
AU  - Xu H
AUID- ORCID: 0000-0001-9617-247X
AD  - Department of Family Medicine and Community Health, School of Medicine, Duke 
      Univeristy, Durham, NC, United States.
AD  - School of Nursing, Duke University, Durham, NC, United States.
AD  - Center for the Study of Aging and Human Development, Duke University, Durham, NC, 
      United States.
AD  - Health Services and Systems Research (HSSR), Duke-NUS Medical School, Singapore, 
      Singapore.
LA  - eng
PT  - Journal Article
DEP - 20240924
PL  - Canada
TA  - JMIR Aging
JT  - JMIR aging
JID - 101740387
SB  - IM
MH  - Humans
MH  - *Feasibility Studies
MH  - *Electronic Health Records
MH  - *Dementia/diagnosis
MH  - *Severity of Illness Index
MH  - Male
MH  - Female
MH  - Aged
MH  - Alzheimer Disease/diagnosis
MH  - Aged, 80 and over
PMC - PMC11462099
OTO - NOTNLM
OT  - AD
OT  - ADRD
OT  - AI
OT  - Alzheimer's disease
OT  - Alzheimer's disease and related dementias
OT  - EHR
OT  - EMR
OT  - LLM
OT  - NLP
OT  - PHR
OT  - artificial intelligence
OT  - deep learning
OT  - dementia
OT  - electric medical record
OT  - electronic health record
OT  - geriatric syndromes
OT  - health record
OT  - large language model
OT  - natural language processing
OT  - patient record
OT  - personal health record
OT  - rule based analysis
OT  - unstructured data
COIS- Conflicts of Interest: None declared.
EDAT- 2024/09/24 12:44
MHDA- 2024/09/24 22:18
PMCR- 2024/09/24
CRDT- 2024/09/24 11:52
PHST- 2024/02/29 00:00 [received]
PHST- 2024/07/24 00:00 [accepted]
PHST- 2024/07/08 00:00 [revised]
PHST- 2024/09/24 22:18 [medline]
PHST- 2024/09/24 12:44 [pubmed]
PHST- 2024/09/24 11:52 [entrez]
PHST- 2024/09/24 00:00 [pmc-release]
AID - v7i1e57926 [pii]
AID - 10.2196/57926 [doi]
PST - epublish
SO  - JMIR Aging. 2024 Sep 24;7:e57926. doi: 10.2196/57926.

PMID- 39333958
OWN - NLM
STAT- MEDLINE
DCOM- 20240928
LR  - 20241001
IS  - 1471-2342 (Electronic)
IS  - 1471-2342 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Sep 27
TI  - An open-source fine-tuned large language model for radiological impression 
      generation: a multi-reader performance study.
PG  - 254
LID - 10.1186/s12880-024-01435-w [doi]
LID - 254
AB  - BACKGROUND: The impression section integrates key findings of a radiology report 
      but can be subjective and variable. We sought to fine-tune and evaluate an 
      open-source Large Language Model (LLM) in automatically generating impressions 
      from the remainder of a radiology report across different imaging modalities and 
      hospitals. METHODS: In this institutional review board-approved retrospective 
      study, we collated a dataset of CT, US, and MRI radiology reports from the 
      University of California San Francisco Medical Center (UCSFMC) (n = 372,716) and 
      the Zuckerberg San Francisco General (ZSFG) Hospital and Trauma Center 
      (n = 60,049), both under a single institution. The Recall-Oriented Understudy for 
      Gisting Evaluation (ROUGE) score, an automatic natural language evaluation metric 
      that measures word overlap, was used for automatic natural language evaluation. A 
      reader study with five cardiothoracic radiologists was performed to more strictly 
      evaluate the model's performance on a specific modality (CT chest exams) with a 
      radiologist subspecialist baseline. We stratified the results of the reader 
      performance study based on the diagnosis category and the original impression 
      length to gauge case complexity. RESULTS: The LLM achieved ROUGE-L scores of 
      46.51, 44.2, and 50.96 on UCSFMC and upon external validation, ROUGE-L scores of 
      40.74, 37.89, and 24.61 on ZSFG across the CT, US, and MRI modalities 
      respectively, implying a substantial degree of overlap between the 
      model-generated impressions and impressions written by the subspecialist 
      attending radiologists, but with a degree of degradation upon external 
      validation. In our reader study, the model-generated impressions achieved overall 
      mean scores of 3.56/4, 3.92/4, 3.37/4, 18.29 s,12.32 words, and 84 while the 
      original impression written by a subspecialist radiologist achieved overall mean 
      scores of 3.75/4, 3.87/4, 3.54/4, 12.2 s, 5.74 words, and 89 for clinical 
      accuracy, grammatical accuracy, stylistic quality, edit time, edit distance, and 
      ROUGE-L score respectively. The LLM achieved the highest clinical accuracy 
      ratings for acute/emergent findings and on shorter impressions. CONCLUSIONS: An 
      open-source fine-tuned LLM can generate impressions to a satisfactory level of 
      clinical accuracy, grammatical accuracy, and stylistic quality. Our reader 
      performance study demonstrates the potential of large language models in drafting 
      radiology report impressions that can aid in streamlining radiologists' 
      workflows.
CI  - © 2024. The Author(s).
FAU - Serapio, Adrian
AU  - Serapio A
AD  - Department of Radiology and Biomedical Imaging, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - Chaudhari, Gunvant
AU  - Chaudhari G
AD  - Department of Radiology, University of Washington, Seattle, WA, USA.
FAU - Savage, Cody
AU  - Savage C
AD  - Department of Radiology, University of Maryland Medical Center, Baltimore, MD, 
      USA.
FAU - Lee, Yoo Jin
AU  - Lee YJ
AD  - Department of Radiology and Biomedical Imaging, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - Vella, Maya
AU  - Vella M
AD  - Department of Radiology and Biomedical Imaging, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - Sridhar, Shravan
AU  - Sridhar S
AD  - Department of Radiology and Biomedical Imaging, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - Schroeder, Jamie Lee
AU  - Schroeder JL
AD  - MedStar Georgetown University Hospital, Washington, DC, USA.
FAU - Liu, Jonathan
AU  - Liu J
AD  - Department of Radiology and Biomedical Imaging, University of California, San 
      Francisco, San Francisco, CA, USA.
FAU - Yala, Adam
AU  - Yala A
AD  - Computational Precision Health, University of California, Berkeley and University 
      of California, San Francisco, Berkeley, USA.
FAU - Sohn, Jae Ho
AU  - Sohn JH
AD  - Department of Radiology and Biomedical Imaging, University of California, San 
      Francisco, San Francisco, CA, USA. sohn87@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20240927
PL  - England
TA  - BMC Med Imaging
JT  - BMC medical imaging
JID - 100968553
SB  - IM
MH  - Humans
MH  - Retrospective Studies
MH  - *Natural Language Processing
MH  - Magnetic Resonance Imaging/methods
MH  - Tomography, X-Ray Computed/methods
MH  - Observer Variation
MH  - Radiology Information Systems
PMC - PMC11428559
OTO - NOTNLM
OT  - Impressions
OT  - Large language model
OT  - Natural language processing
OT  - Open-source
OT  - Summarization
COIS- The authors declare no competing interests.
EDAT- 2024/09/28 22:43
MHDA- 2024/09/28 22:44
PMCR- 2024/09/27
CRDT- 2024/09/28 00:11
PHST- 2024/06/28 00:00 [received]
PHST- 2024/09/18 00:00 [accepted]
PHST- 2024/09/28 22:44 [medline]
PHST- 2024/09/28 22:43 [pubmed]
PHST- 2024/09/28 00:11 [entrez]
PHST- 2024/09/27 00:00 [pmc-release]
AID - 10.1186/s12880-024-01435-w [pii]
AID - 1435 [pii]
AID - 10.1186/s12880-024-01435-w [doi]
PST - epublish
SO  - BMC Med Imaging. 2024 Sep 27;24(1):254. doi: 10.1186/s12880-024-01435-w.

PMID- 39775249
OWN - NLM
STAT- MEDLINE
DCOM- 20250108
LR  - 20250108
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 19
IP  - 12
DP  - 2024
TI  - Ascertaining provider-level implicit bias in electronic health records with 
      rules-based natural language processing: A pilot study in the case of prostate 
      cancer.
PG  - e0314989
LID - 10.1371/journal.pone.0314989 [doi]
LID - e0314989
AB  - PURPOSE: Implicit, unconscious biases in medicine are personal attitudes about 
      race, ethnicity, gender, and other characteristics that may lead to 
      discriminatory patterns of care. However, there is no consensus on whether 
      implicit bias represents a true predictor of differential care given an absence 
      of real-world studies. We conducted the first real-world pilot study of provider 
      implicit bias by evaluating treatment parity in prostate cancer using 
      unstructured data-the most common way providers document granular details of the 
      patient encounter. METHODS AND FINDINGS: Patients ≥18 years with a diagnosis of 
      very-low to favorable intermediate-risk prostate cancer followed by 3 urologic 
      oncologists from 2010 through 2021. The race Implicit Association Test was 
      administered to all providers. Natural language processing screened human 
      annotation using validated regex ontologies evaluated each provider's care on 
      four prostate cancer quality indicators: (1) active surveillance utilization; (2) 
      molecular biomarker discussion; (3) urinary function evaluation; and (4) sexual 
      function evaluation. The chi-squared test and phi coefficient were utilized to 
      respectively measure the statistical significance and the strength of association 
      between race and four quality indicators. 1,094 patients were included. While 
      Providers A and B demonstrated no preference on the race Implicit Association 
      Test, Provider C showed preference for White patients. Provider C recommended 
      active surveillance (p<0.01, φ = 0.175) and considered biomarkers (p = 0.047, φ = 
      0.127) more often in White men than expected, suggestive of treatment imparity. 
      Provider A considered biomarkers (p<0.01, φ = 0.179) more often in White men than 
      expected. Provider B demonstrated treatment parity in all evaluated quality 
      indicators (p>0.05). CONCLUSIONS: In this pilot study, providers' practice 
      patterns were associated with both patient race and implicit racial preferences 
      in prostate cancer. Alerting providers of existing implicit bias may restore 
      parity, however future assessments are needed to validate this concept.
CI  - Copyright: © 2024 Ramaswamy et al. This is an open access article distributed 
      under the terms of the Creative Commons Attribution License, which permits 
      unrestricted use, distribution, and reproduction in any medium, provided the 
      original author and source are credited.
FAU - Ramaswamy, Ashwin
AU  - Ramaswamy A
AUID- ORCID: 0000-0002-8816-7838
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Hung, Michael
AU  - Hung M
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Pelt, Joe
AU  - Pelt J
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Iranmahboub, Parsa
AU  - Iranmahboub P
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Calderon, Lina P
AU  - Calderon LP
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Scherr, Ian S
AU  - Scherr IS
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Wang, Gerald
AU  - Wang G
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Green, David
AU  - Green D
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Patel, Neal
AU  - Patel N
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - McClure, Timothy D
AU  - McClure TD
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Barbieri, Christopher
AU  - Barbieri C
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Hu, Jim C
AU  - Hu JC
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
FAU - Lindvall, Charlotta
AU  - Lindvall C
AD  - Dana Farber Cancer Center, Boston, Massachusetts, United States of America.
AD  - Harvard Medical School, Boston, Massachusetts, United States of America.
FAU - Scherr, Douglas S
AU  - Scherr DS
AD  - Department of Urology, NewYork-Presbyterian Hospital/Weill Cornell Medical 
      Center, New York, New York, United States of America.
LA  - eng
PT  - Journal Article
DEP - 20241230
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Humans
MH  - Male
MH  - *Prostatic Neoplasms/therapy/diagnosis
MH  - *Natural Language Processing
MH  - Pilot Projects
MH  - *Electronic Health Records
MH  - Middle Aged
MH  - Aged
MH  - Bias
MH  - Health Personnel/psychology
PMC - PMC11684669
COIS- NO authors have competing interests.
EDAT- 2025/01/08 18:22
MHDA- 2025/01/09 00:23
PMCR- 2024/12/30
CRDT- 2025/01/08 16:50
PHST- 2024/08/19 00:00 [received]
PHST- 2024/11/19 00:00 [accepted]
PHST- 2025/01/09 00:23 [medline]
PHST- 2025/01/08 18:22 [pubmed]
PHST- 2025/01/08 16:50 [entrez]
PHST- 2024/12/30 00:00 [pmc-release]
AID - PONE-D-24-33113 [pii]
AID - 10.1371/journal.pone.0314989 [doi]
PST - epublish
SO  - PLoS One. 2024 Dec 30;19(12):e0314989. doi: 10.1371/journal.pone.0314989. 
      eCollection 2024.

PMID- 39180115
OWN - NLM
STAT- MEDLINE
DCOM- 20240824
LR  - 20250131
IS  - 1546-0096 (Electronic)
IS  - 1546-0096 (Linking)
VI  - 22
IP  - 1
DP  - 2024 Aug 23
TI  - Reliability of a generative artificial intelligence tool for pediatric familial 
      Mediterranean fever: insights from a multicentre expert survey.
PG  - 78
LID - 10.1186/s12969-024-01011-0 [doi]
LID - 78
AB  - BACKGROUND: Artificial intelligence (AI) has become a popular tool for clinical 
      and research use in the medical field. The aim of this study was to evaluate the 
      accuracy and reliability of a generative AI tool on pediatric familial 
      Mediterranean fever (FMF). METHODS: Fifteen questions repeated thrice on 
      pediatric FMF were prompted to the popular generative AI tool Microsoft Copilot 
      with Chat-GPT 4.0. Nine pediatric rheumatology experts rated response accuracy 
      with a blinded mechanism using a Likert-like scale with values from 1 to 5. 
      RESULTS: Median values for overall responses at the initial assessment ranged 
      from 2.00 to 5.00. During the second assessment, median values spanned from 2.00 
      to 4.00, while for the third assessment, they ranged from 3.00 to 4.00. 
      Intra-rater variability showed poor to moderate agreement (intraclass correlation 
      coefficient range: -0.151 to 0.534). A diminishing level of agreement among 
      experts over time was documented, as highlighted by Krippendorff's alpha 
      coefficient values, ranging from 0.136 (at the first response) to 0.132 (at the 
      second response) to 0.089 (at the third response). Lastly, experts displayed 
      varying levels of trust in AI pre- and post-survey. CONCLUSIONS: AI has promising 
      implications in pediatric rheumatology, including early diagnosis and management 
      optimization, but challenges persist due to uncertain information reliability and 
      the lack of expert validation. Our survey revealed considerable inaccuracies and 
      incompleteness in AI-generated responses regarding FMF, with poor intra- and 
      extra-rater reliability. Human validation remains crucial in managing 
      AI-generated medical information.
CI  - © 2024. The Author(s).
FAU - La Bella, Saverio
AU  - La Bella S
AUID- ORCID: 0000-0002-1244-0789
AD  - Department of Pediatrics, "G. D'Annunzio" University of Chieti-Pescara, Chieti, 
      Italy. saveriolabella@outlook.it.
AD  - Division of Pediatric Rheumatology, "G. D'Annunzio" University of Chieti-Pescara, 
      Chieti, Italy. saveriolabella@outlook.it.
AD  - Division of Rheumatology and Autoinflammatory Diseases, IRCCS Istituto Giannina 
      Gaslini, Genova, Italy. saveriolabella@outlook.it.
FAU - Attanasi, Marina
AU  - Attanasi M
AD  - Department of Pediatrics, "G. D'Annunzio" University of Chieti-Pescara, Chieti, 
      Italy.
FAU - Porreca, Annamaria
AU  - Porreca A
AD  - Laboratory of Biostatistics, Department of Medical, Oral and Biotechnological 
      Sciences, "G. D'Annunzio" University of Chieti-Pescara, Chieti, Italy.
FAU - Di Ludovico, Armando
AU  - Di Ludovico A
AD  - Department of Pediatrics, "G. D'Annunzio" University of Chieti-Pescara, Chieti, 
      Italy.
AD  - Division of Pediatric Rheumatology, "G. D'Annunzio" University of Chieti-Pescara, 
      Chieti, Italy.
FAU - Maggio, Maria Cristina
AU  - Maggio MC
AD  - University Department PROMISE "G. D'Alessandro", University of Palermo, Palermo, 
      Italy.
FAU - Gallizzi, Romina
AU  - Gallizzi R
AD  - Department of Medical of Health Sciences, Magna Graecia University, Catanzaro, 
      Italy.
FAU - La Torre, Francesco
AU  - La Torre F
AD  - Department of Pediatrics, Giovanni XXIII Pediatric Hospital, University of Bari, 
      Bari, Italy.
FAU - Rigante, Donato
AU  - Rigante D
AD  - Department of Life Sciences and Public Health, Fondazione Policlinico 
      Universitario A. Gemelli, Rome and Università Cattolica Sacro Cuore, Rome, Italy.
FAU - Soscia, Francesca
AU  - Soscia F
AD  - Department of Pediatrics, Sant' Eugenio Hospital, Rome, Italy.
FAU - Ardenti Morini, Francesca
AU  - Ardenti Morini F
AD  - Department of Pediatrics, Sant' Eugenio Hospital, Rome, Italy.
FAU - Insalaco, Antonella
AU  - Insalaco A
AD  - Division of Rheumatology, Bambino Gesù Children's Hospital, Scientific Institute 
      for Research and Health Care, Rome, Italy.
FAU - Natale, Marco Francesco
AU  - Natale MF
AD  - Division of Rheumatology, Bambino Gesù Children's Hospital, Scientific Institute 
      for Research and Health Care, Rome, Italy.
FAU - Chiarelli, Francesco
AU  - Chiarelli F
AD  - Department of Pediatrics, "G. D'Annunzio" University of Chieti-Pescara, Chieti, 
      Italy. chiarelli@unich.it.
FAU - Simonini, Gabriele
AU  - Simonini G
AD  - Rheumatology Unit, IRCCS Meyer Children's Hospital, Florence, Italy.
FAU - De Benedetti, Fabrizio
AU  - De Benedetti F
AD  - Division of Rheumatology, Bambino Gesù Children's Hospital, Scientific Institute 
      for Research and Health Care, Rome, Italy.
FAU - Gattorno, Marco
AU  - Gattorno M
AD  - Division of Rheumatology and Autoinflammatory Diseases, IRCCS Istituto Giannina 
      Gaslini, Genova, Italy.
FAU - Breda, Luciana
AU  - Breda L
AD  - Department of Pediatrics, "G. D'Annunzio" University of Chieti-Pescara, Chieti, 
      Italy.
AD  - Division of Pediatric Rheumatology, "G. D'Annunzio" University of Chieti-Pescara, 
      Chieti, Italy.
LA  - eng
PT  - Journal Article
PT  - Multicenter Study
DEP - 20240823
PL  - England
TA  - Pediatr Rheumatol Online J
JT  - Pediatric rheumatology online journal
JID - 101248897
SB  - IM
MH  - Humans
MH  - *Familial Mediterranean Fever/diagnosis
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Child
MH  - Surveys and Questionnaires
MH  - Observer Variation
PMC - PMC11342667
OTO - NOTNLM
OT  - AI
OT  - Artificial intelligence
OT  - FMF
OT  - Familial mediterranean fever
OT  - Generative artificial intelligence
OT  - Pediatric rheumatology
COIS- All authors report no conflicts of interest.
EDAT- 2024/08/24 16:45
MHDA- 2024/08/24 16:46
PMCR- 2024/08/23
CRDT- 2024/08/23 23:44
PHST- 2024/06/03 00:00 [received]
PHST- 2024/07/29 00:00 [accepted]
PHST- 2024/08/24 16:46 [medline]
PHST- 2024/08/24 16:45 [pubmed]
PHST- 2024/08/23 23:44 [entrez]
PHST- 2024/08/23 00:00 [pmc-release]
AID - 10.1186/s12969-024-01011-0 [pii]
AID - 1011 [pii]
AID - 10.1186/s12969-024-01011-0 [doi]
PST - epublish
SO  - Pediatr Rheumatol Online J. 2024 Aug 23;22(1):78. doi: 
      10.1186/s12969-024-01011-0.

PMID- 39567516
OWN - NLM
STAT- MEDLINE
DCOM- 20241120
LR  - 20241125
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Nov 20
TI  - Premature mortality analysis of 52,000 deceased cats and dogs exposes 
      socioeconomic disparities.
PG  - 28763
LID - 10.1038/s41598-024-77385-8 [doi]
LID - 28763
AB  - Monitoring mortality rates offers crucial insights into public health by 
      uncovering the hidden impacts of diseases, identifying emerging trends, 
      optimising resource allocation, and informing effective policy decisions. Here, 
      we present a novel approach to analysing premature mortality in companion 
      animals, utilising data from 28,159 deceased dogs and 24,006 deceased cats across 
      the United Kingdom. By employing PetBERT-ICD, an automated large language model 
      (LLM) based International Classification of Disease 11 syndromic classifier, we 
      reveal critical insights into the causes and patterns of premature deaths. Our 
      findings highlight the significant impact of behavioural conditions on premature 
      euthanasia in dogs, particularly in ages one to six. We also identify a 19% 
      increased risk of premature mortality in brachycephalic dog breeds, raising 
      important animal welfare concerns. Our research establishes a strong correlation 
      between socioeconomic status and premature mortality in cats and dogs. Areas with 
      the lowest Index of Multiple Deprivation (IMD) scores show nearly a 50% reduction 
      in the risk of premature mortality across cats and dogs, underscoring the 
      powerful impact that socioeconomic factors can have on pet health and longevity. 
      This research underscores the necessity of examining the socioeconomic 
      disparities affecting animal health outcomes. By addressing these inequities, we 
      can better safeguard the well-being of our companion animals.
CI  - © 2024. The Author(s).
FAU - Farrell, Sean
AU  - Farrell S
AD  - Department of Computer Science, Durham University, Durham, UK. 
      sean.farrell2@durham.ac.uk.
FAU - Anderson, Katharine
AU  - Anderson K
AD  - Dogs Trust, London, UK.
AD  - Institute of Infection, Veterinary and Ecological Sciences, University of 
      Liverpool, Liverpool, UK.
FAU - Noble, Peter-John Mäntylä
AU  - Noble PM
AD  - Institute of Infection, Veterinary and Ecological Sciences, University of 
      Liverpool, Liverpool, UK.
FAU - Al Moubayed, Noura
AU  - Al Moubayed N
AD  - Department of Computer Science, Durham University, Durham, UK.
AD  - Evergreen Life Ltd, Manchester, UK.
LA  - eng
GR  - 10027358/Innovate UK/
GR  - BB/T008695/1/BB_/Biotechnology and Biological Sciences Research Council/United 
      Kingdom
PT  - Journal Article
DEP - 20241120
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Dogs
MH  - Animals
MH  - Cats
MH  - *Mortality, Premature/trends
MH  - United Kingdom/epidemiology
MH  - Male
MH  - Socioeconomic Factors
MH  - Female
MH  - Pets
MH  - Dog Diseases/mortality
MH  - Socioeconomic Disparities in Health
PMC - PMC11579424
COIS- Declaration. Competing interests: The authors declare no competing interests.
EDAT- 2024/11/21 00:22
MHDA- 2024/11/21 00:23
PMCR- 2024/11/20
CRDT- 2024/11/20 23:26
PHST- 2024/06/18 00:00 [received]
PHST- 2024/10/22 00:00 [accepted]
PHST- 2024/11/21 00:23 [medline]
PHST- 2024/11/21 00:22 [pubmed]
PHST- 2024/11/20 23:26 [entrez]
PHST- 2024/11/20 00:00 [pmc-release]
AID - 10.1038/s41598-024-77385-8 [pii]
AID - 77385 [pii]
AID - 10.1038/s41598-024-77385-8 [doi]
PST - epublish
SO  - Sci Rep. 2024 Nov 20;14(1):28763. doi: 10.1038/s41598-024-77385-8.

PMID- 38290291
OWN - NLM
STAT- MEDLINE
DCOM- 20240214
LR  - 20240214
IS  - 1872-7565 (Electronic)
IS  - 0169-2607 (Linking)
VI  - 245
DP  - 2024 Mar
TI  - End-to-end volumetric segmentation of white matter hyperintensities using deep 
      learning.
PG  - 108008
LID - S0169-2607(24)00003-8 [pii]
LID - 10.1016/j.cmpb.2024.108008 [doi]
AB  - BACKGROUND AND OBJECTIVES: Reliable detection of white matter hyperintensities 
      (WMH) is crucial for studying the impact of diffuse white-matter pathology on 
      brain health and monitoring changes in WMH load over time. However, manual 
      annotation of 3D high-dimensional neuroimages is laborious and can be prone to 
      biases and errors in the annotation procedure. In this study, we evaluate the 
      performance of deep learning (DL) segmentation tools and propose a novel 
      volumetric segmentation model incorporating self-attention via a 
      transformer-based architecture. Ultimately, we aim to evaluate diverse factors 
      that influence WMH segmentation, aiming for a comprehensive analysis of the 
      state-of-the-art algorithms in a broader context. METHODS: We trained 
      state-of-the-art DL algorithms, and incorporated advanced attention mechanisms, 
      using structural fluid-attenuated inversion recovery (FLAIR) image acquisitions. 
      The anatomical MRI data utilized for model training was obtained from healthy 
      individuals aged 62-70 years in the Live active Successful Aging (LISA) project. 
      Given the potential sparsity of lesion volume among healthy aging individuals, we 
      explored the impact of incorporating a weighted loss function and ensemble 
      models. To assess the generalizability of the studied DL models, we applied the 
      trained algorithm to an independent subset of data sourced from the MICCAI WMH 
      challenge (MWSC). Notably, this subset had vastly different acquisition 
      parameters compared to the LISA dataset used for training. RESULTS: Consistently, 
      DL approaches exhibited commendable segmentation performance, achieving the level 
      of inter-rater agreement comparable to expert performance, ensuring superior 
      quality segmentation outcomes. On the out of sample dataset, the ensemble models 
      exhibited the most outstanding performance. CONCLUSIONS: DL methods generally 
      surpassed conventional approaches in our study. While all DL methods performed 
      comparably, incorporating attention mechanisms could prove advantageous in future 
      applications with a wider availability of training data. As expected, our 
      experiments indicate that the use of ensemble-based models enables the superior 
      generalization in out-of-distribution settings. We believe that introducing DL 
      methods in the WHM annotation workflow in heathy aging cohorts is promising, not 
      only for reducing the annotation time required, but also for eventually improving 
      accuracy and robustness via incorporating the automatic segmentations in the 
      evaluation procedure.
CI  - Copyright © 2024. Published by Elsevier B.V.
FAU - Farkhani, Sadaf
AU  - Farkhani S
AD  - Danish Research Center for Magnetic Resonance, Center for Functional and 
      Diagnostic Imaging and Research, Copenhagen University Hospital-Amager and 
      Hvidovre, Kattegaard Alle 30, Hvidovre, Denmark. Electronic address: 
      sadaff@drcmr.dk.
FAU - Demnitz, Naiara
AU  - Demnitz N
AD  - Danish Research Center for Magnetic Resonance, Center for Functional and 
      Diagnostic Imaging and Research, Copenhagen University Hospital-Amager and 
      Hvidovre, Kattegaard Alle 30, Hvidovre, Denmark.
FAU - Boraxbekk, Carl-Johan
AU  - Boraxbekk CJ
AD  - Danish Research Center for Magnetic Resonance, Center for Functional and 
      Diagnostic Imaging and Research, Copenhagen University Hospital-Amager and 
      Hvidovre, Kattegaard Alle 30, Hvidovre, Denmark; Institute for Clinical Medicine, 
      Faculty of Medical and Health Sciences, University of Copenhagen, Denmark; 
      Department of Neurology, Copenhagen University Hospital Bispebjerg and 
      Frederiksberg, Copenhagen, Denmark; Institute of Sports Medicine Copenhagen 
      (ISMC), Copenhagen University Hospital Bispebjerg and Frederiksberg, Copenhagen, 
      Denmark.
FAU - Lundell, Henrik
AU  - Lundell H
AD  - Danish Research Center for Magnetic Resonance, Center for Functional and 
      Diagnostic Imaging and Research, Copenhagen University Hospital-Amager and 
      Hvidovre, Kattegaard Alle 30, Hvidovre, Denmark; Department of Health Technology, 
      Technical University of Denmark, Lyngby, Denmark.
FAU - Siebner, Hartwig Roman
AU  - Siebner HR
AD  - Danish Research Center for Magnetic Resonance, Center for Functional and 
      Diagnostic Imaging and Research, Copenhagen University Hospital-Amager and 
      Hvidovre, Kattegaard Alle 30, Hvidovre, Denmark; Institute for Clinical Medicine, 
      Faculty of Medical and Health Sciences, University of Copenhagen, Denmark; 
      Department of Neurology, Copenhagen University Hospital Bispebjerg and 
      Frederiksberg, Copenhagen, Denmark.
FAU - Petersen, Esben Thade
AU  - Petersen ET
AD  - Danish Research Center for Magnetic Resonance, Center for Functional and 
      Diagnostic Imaging and Research, Copenhagen University Hospital-Amager and 
      Hvidovre, Kattegaard Alle 30, Hvidovre, Denmark; Department of Health Technology, 
      Technical University of Denmark, Lyngby, Denmark.
FAU - Madsen, Kristoffer Hougaard
AU  - Madsen KH
AD  - Danish Research Center for Magnetic Resonance, Center for Functional and 
      Diagnostic Imaging and Research, Copenhagen University Hospital-Amager and 
      Hvidovre, Kattegaard Alle 30, Hvidovre, Denmark; Department of Applied 
      Mathematics and Computer Science, Technical University of Denmark, Lyngby, 
      Denmark.
LA  - eng
PT  - Journal Article
DEP - 20240110
PL  - Ireland
TA  - Comput Methods Programs Biomed
JT  - Computer methods and programs in biomedicine
JID - 8506513
SB  - IM
MH  - Humans
MH  - *White Matter/diagnostic imaging
MH  - *Deep Learning
MH  - Brain/diagnostic imaging/pathology
MH  - Magnetic Resonance Imaging/methods
MH  - Algorithms
MH  - Image Processing, Computer-Assisted/methods
OTO - NOTNLM
OT  - Attention mechanism
OT  - Deep learning
OT  - Segmentation
OT  - Transformer
OT  - White matter hyperintensities
COIS- Declaration of competing interest The authors declare the following financial 
      interests/personal relationships which may be considered as potential competing 
      interests: Hartwig Roman Siebner has received honoraria as speaker from Sanofi 
      Genzyme, Denmark, Lundbeck AS, Denmark, and Novartis, Denmark, as consultant from 
      Sanofi Genzyme, Denmark, Lophora, Denmark, and Lundbeck AS, Denmark, and as 
      editor-in-chief (Neuroimage Clinical) and senior editor (NeuroImage) from 
      Elsevier Publishers, Amsterdam, The Netherlands. He has received royalties as 
      book editor from Springer Publishers, Stuttgart, Germany, and from Gyldendal 
      Publishers, Copenhagen, Denmark. The remaining authors declare that they have no 
      known conflicts of interest.
EDAT- 2024/01/31 00:42
MHDA- 2024/02/13 06:45
CRDT- 2024/01/30 18:07
PHST- 2023/07/12 00:00 [received]
PHST- 2023/12/08 00:00 [revised]
PHST- 2024/01/03 00:00 [accepted]
PHST- 2024/02/13 06:45 [medline]
PHST- 2024/01/31 00:42 [pubmed]
PHST- 2024/01/30 18:07 [entrez]
AID - S0169-2607(24)00003-8 [pii]
AID - 10.1016/j.cmpb.2024.108008 [doi]
PST - ppublish
SO  - Comput Methods Programs Biomed. 2024 Mar;245:108008. doi: 
      10.1016/j.cmpb.2024.108008. Epub 2024 Jan 10.

PMID- 38781053
OWN - NLM
STAT- MEDLINE
DCOM- 20240618
LR  - 20240618
IS  - 1651-2251 (Electronic)
IS  - 0001-6489 (Linking)
VI  - 144
IP  - 3
DP  - 2024 Mar
TI  - Assessing unknown potential-quality and limitations of different large language 
      models in the field of otorhinolaryngology.
PG  - 237-242
LID - 10.1080/00016489.2024.2352843 [doi]
AB  - BACKGROUND: Large Language Models (LLMs) might offer a solution for the lack of 
      trained health personnel, particularly in low- and middle-income countries. 
      However, their strengths and weaknesses remain unclear. AIMS/OBJECTIVES: Here we 
      benchmark different LLMs (Bard 2023.07.13, Claude 2, ChatGPT 4) against six 
      consultants in otorhinolaryngology (ORL). MATERIAL AND METHODS: Case-based 
      questions were extracted from literature and German state examinations. Answers 
      from Bard 2023.07.13, Claude 2, ChatGPT 4, and six ORL consultants were rated 
      blindly on a 6-point Likert-scale for medical adequacy, comprehensibility, 
      coherence, and conciseness. Given answers were compared to validated answers and 
      evaluated for hazards. A modified Turing test was performed and character counts 
      were compared. RESULTS: LLMs answers ranked inferior to consultants in all 
      categories. Yet, the difference between consultants and LLMs was marginal, with 
      the clearest disparity in conciseness and the smallest in comprehensibility. 
      Among LLMs Claude 2 was rated best in medical adequacy and conciseness. 
      Consultants' answers matched the validated solution in 93% (228/246), ChatGPT 4 
      in 85% (35/41), Claude 2 in 78% (32/41), and Bard 2023.07.13 in 59% (24/41). 
      Answers were rated as potentially hazardous in 10% (24/246) for ChatGPT 4, 14% 
      (34/246) for Claude 2, 19% (46/264) for Bard 2023.07.13, and 6% (71/1230) for 
      consultants. CONCLUSIONS AND SIGNIFICANCE: Despite consultants superior 
      performance, LLMs show potential for clinical application in ORL. Future studies 
      should assess their performance on larger scale.
FAU - Buhr, Christoph R
AU  - Buhr CR
AUID- ORCID: 0000-0002-9551-2310
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
AD  - School of Medicine, University of St Andrews, St Andrews, UK.
FAU - Smith, Harry
AU  - Smith H
AD  - School of Computer Science, University of St Andrews, St Andrews, UK.
FAU - Huppertz, Tilman
AU  - Huppertz T
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
FAU - Bahr-Hamm, Katharina
AU  - Bahr-Hamm K
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
FAU - Matthias, Christoph
AU  - Matthias C
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
FAU - Cuny, Clemens
AU  - Cuny C
AD  - Outpatient Clinic, Clemens Cuny, Dieburg, Germany.
FAU - Snijders, Jan Phillipp
AU  - Snijders JP
AD  - Outpatient Clinic, Clemens Cuny, Dieburg, Germany.
FAU - Ernst, Benjamin Philipp
AU  - Ernst BP
AD  - Department of Otorhinolaryngology, University Hospital Frankfurt, Frankfurt, 
      Germany.
FAU - Blaikie, Andrew
AU  - Blaikie A
AD  - School of Medicine, University of St Andrews, St Andrews, UK.
FAU - Kelsey, Tom
AU  - Kelsey T
AD  - School of Computer Science, University of St Andrews, St Andrews, UK.
FAU - Kuhn, Sebastian
AU  - Kuhn S
AD  - Institute for Digital Medicine, Philipps-University Marburg, University Hospital 
      of Giessen and Marburg, Marburg, Germany.
FAU - Eckrich, Jonas
AU  - Eckrich J
AUID- ORCID: 0000-0001-5498-4031
AD  - Department of Otorhinolaryngology, University Medical Center of the Johannes 
      Gutenberg-University Mainz, Mainz, Germany.
LA  - eng
PT  - Journal Article
DEP - 20240523
PL  - England
TA  - Acta Otolaryngol
JT  - Acta oto-laryngologica
JID - 0370354
SB  - IM
MH  - Humans
MH  - *Otolaryngology
MH  - Germany
MH  - Language
MH  - Clinical Competence
MH  - Benchmarking
OTO - NOTNLM
OT  - Bard
OT  - ChatGPT
OT  - Claude
OT  - Large language models
OT  - artificial intelligence
OT  - chatbot
OT  - chatbots
OT  - digital health
OT  - global health
OT  - otorhinolaryngology
EDAT- 2024/05/23 18:43
MHDA- 2024/06/18 18:42
CRDT- 2024/05/23 12:33
PHST- 2024/06/18 18:42 [medline]
PHST- 2024/05/23 18:43 [pubmed]
PHST- 2024/05/23 12:33 [entrez]
AID - 10.1080/00016489.2024.2352843 [doi]
PST - ppublish
SO  - Acta Otolaryngol. 2024 Mar;144(3):237-242. doi: 10.1080/00016489.2024.2352843. 
      Epub 2024 May 23.

PMID- 39048640
OWN - NLM
STAT- MEDLINE
DCOM- 20240725
LR  - 20241025
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 Jul 24
TI  - Disparities in medical recommendations from AI-based chatbots across different 
      countries/regions.
PG  - 17052
LID - 10.1038/s41598-024-67689-0 [doi]
LID - 17052
AB  - This study explores disparities and opportunities in healthcare information 
      provided by AI chatbots. We focused on recommendations for adjuvant therapy in 
      endometrial cancer, analyzing responses across four regions (Indonesia, Nigeria, 
      Taiwan, USA) and three platforms (Bard, Bing, ChatGPT-3.5). Utilizing previously 
      published cases, we asked identical questions to chatbots from each location 
      within a 24-h window. Responses were evaluated in a double-blinded manner on 
      relevance, clarity, depth, focus, and coherence by ten experts in endometrial 
      cancer. Our analysis revealed significant variations across different 
      countries/regions (p < 0.001). Interestingly, Bing's responses in Nigeria 
      consistently outperformed others (p < 0.05), excelling in all evaluation criteria 
      (p < 0.001). Bard also performed better in Nigeria compared to other regions 
      (p < 0.05), consistently surpassing them across all categories (p < 0.001, with 
      relevance reaching p < 0.01). Notably, Bard's overall scores were significantly 
      higher than those of ChatGPT-3.5 and Bing in all locations (p < 0.001). These 
      findings highlight disparities and opportunities in the quality of AI-powered 
      healthcare information based on user location and platform. This emphasizes the 
      necessity for more research and development to guarantee equal access to 
      trustworthy medical information through AI technologies.
CI  - © 2024. The Author(s).
FAU - Gumilar, Khanisyah E
AU  - Gumilar KE
AD  - Graduate Institute of Biomedical Science, China Medical University, Taichung, 
      Taiwan. khanisyah@fk.unair.ac.id.
AD  - Department of Obstetrics and Gynecology, Hospital of Universitas 
      Airlangga-Faculty of Medicine, Universitas Airlangga, Jl. Dharmahusada Permai, 
      Mulyorejo, Kec. Mulyorejo, Surabaya, Jawa Timur, 60115, Indonesia. 
      khanisyah@fk.unair.ac.id.
FAU - Indraprasta, Birama R
AU  - Indraprasta BR
AD  - Department of Obstetrics and Gynecology, Dr. Soetomo General Hospital-Faculty of 
      Medicine, Universitas Airlangga, Surabaya, Indonesia.
FAU - Hsu, Yu-Cheng
AU  - Hsu YC
AD  - Department of Public Health, China Medical University, No. 100, Sec. 1, Jingmao 
      Rd, Beitun Dist, Taichung, 406040, Taiwan, ROC.
AD  - School of Chinese Medicine, China Medical University, Taichung, Taiwan.
FAU - Yu, Zih-Ying
AU  - Yu ZY
AD  - Department of Public Health, China Medical University, No. 100, Sec. 1, Jingmao 
      Rd, Beitun Dist, Taichung, 406040, Taiwan, ROC.
FAU - Chen, Hong
AU  - Chen H
AD  - Graduate Institute of Biomedical Science, China Medical University, Taichung, 
      Taiwan.
FAU - Irawan, Budi
AU  - Irawan B
AD  - Department of Obstetrics and Gynecology, Dr. Soetomo General Hospital-Faculty of 
      Medicine, Universitas Airlangga, Surabaya, Indonesia.
FAU - Tambunan, Zulkarnain
AU  - Tambunan Z
AD  - Department of Obstetrics and Gynecology, Dr. Soetomo General Hospital-Faculty of 
      Medicine, Universitas Airlangga, Surabaya, Indonesia.
FAU - Wibowo, Bagus M
AU  - Wibowo BM
AD  - Department of Obstetrics and Gynecology, Dr. Soetomo General Hospital-Faculty of 
      Medicine, Universitas Airlangga, Surabaya, Indonesia.
FAU - Nugroho, Hari
AU  - Nugroho H
AD  - Department of Obstetrics and Gynecology, Dr. Soetomo General Hospital-Faculty of 
      Medicine, Universitas Airlangga, Surabaya, Indonesia.
FAU - Tjokroprawiro, Brahmana A
AU  - Tjokroprawiro BA
AD  - Department of Obstetrics and Gynecology, Dr. Soetomo General Hospital-Faculty of 
      Medicine, Universitas Airlangga, Surabaya, Indonesia.
FAU - Dachlan, Erry G
AU  - Dachlan EG
AD  - Department of Obstetrics and Gynecology, Dr. Soetomo General Hospital-Faculty of 
      Medicine, Universitas Airlangga, Surabaya, Indonesia.
FAU - Mulawardhana, Pungky
AU  - Mulawardhana P
AD  - Department of Obstetrics and Gynecology, Hospital of Universitas 
      Airlangga-Faculty of Medicine, Universitas Airlangga, Jl. Dharmahusada Permai, 
      Mulyorejo, Kec. Mulyorejo, Surabaya, Jawa Timur, 60115, Indonesia.
FAU - Rahestyningtyas, Eccita
AU  - Rahestyningtyas E
AD  - Department of Obstetrics and Gynecology, Hospital of Universitas 
      Airlangga-Faculty of Medicine, Universitas Airlangga, Jl. Dharmahusada Permai, 
      Mulyorejo, Kec. Mulyorejo, Surabaya, Jawa Timur, 60115, Indonesia.
FAU - Pramuditya, Herlangga
AU  - Pramuditya H
AD  - Department of Obstetrics and Gynecology, Dr. Ramelan Naval Hospital, Surabaya, 
      Indonesia.
FAU - Putra, Very Great E
AU  - Putra VGE
AD  - Department of Obstetrics and Gynecology, Dr. Kariadi Central General Hospital, 
      Semarang, Indonesia.
FAU - Waluyo, Setyo T
AU  - Waluyo ST
AD  - Department of Obstetrics and Gynecology, Ulin General Hospital, Banjarmasin, 
      Indonesia.
FAU - Tan, Nathan R
AU  - Tan NR
AD  - Department of Modern and Classical Languages and Literature, University of South 
      Alabama, Mobile, AL, USA.
FAU - Folarin, Royhaan
AU  - Folarin R
AD  - Department of Anatomy, Faculty of Basic Medical Sciences, Olabisi Onabanjo 
      University, Sagamu, Nigeria.
FAU - Ibrahim, Ibrahim H
AU  - Ibrahim IH
AD  - Graduate Institute of Biomedical Science, China Medical University, Taichung, 
      Taiwan.
FAU - Lin, Cheng-Han
AU  - Lin CH
AD  - Graduate Institute of Biomedical Science, China Medical University, Taichung, 
      Taiwan.
FAU - Hung, Tai-Yu
AU  - Hung TY
AD  - Graduate Institute of Biomedical Science, China Medical University, Taichung, 
      Taiwan.
FAU - Lu, Ting-Fang
AU  - Lu TF
AD  - Department of Obstetrics and Gynecology, Taichung Veteran General Hospital, 1650 
      Taiwan Boulevard Sector. 4, Taichung, 40705, Taiwan, ROC.
FAU - Chen, Yen-Fu
AU  - Chen YF
AD  - Department of Obstetrics and Gynecology, Taichung Veteran General Hospital, 1650 
      Taiwan Boulevard Sector. 4, Taichung, 40705, Taiwan, ROC.
FAU - Shih, Yu-Hsiang
AU  - Shih YH
AD  - Department of Obstetrics and Gynecology, Taichung Veteran General Hospital, 1650 
      Taiwan Boulevard Sector. 4, Taichung, 40705, Taiwan, ROC.
FAU - Wang, Shao-Jing
AU  - Wang SJ
AD  - Department of Obstetrics and Gynecology, Taichung Veteran General Hospital, 1650 
      Taiwan Boulevard Sector. 4, Taichung, 40705, Taiwan, ROC.
FAU - Huang, Jingshan
AU  - Huang J
AD  - School of Computing and College of Medicine, University of South Alabama, Mobile, 
      AL, USA.
FAU - Yates, Clayton C
AU  - Yates CC
AD  - Department of Pathology, Johns Hopkins University School of Medicine, Baltimore, 
      MD, 21287, USA.
FAU - Lu, Chien-Hsing
AU  - Lu CH
AD  - Department of Obstetrics and Gynecology, Taichung Veteran General Hospital, 1650 
      Taiwan Boulevard Sector. 4, Taichung, 40705, Taiwan, ROC. chlu@vghtc.gov.tw.
FAU - Liao, Li-Na
AU  - Liao LN
AD  - Department of Public Health, China Medical University, No. 100, Sec. 1, Jingmao 
      Rd, Beitun Dist, Taichung, 406040, Taiwan, ROC. linaliao@mail.cmu.edu.tw.
FAU - Tan, Ming
AU  - Tan M
AD  - Graduate Institute of Biomedical Science, China Medical University, Taichung, 
      Taiwan. mingtan@mail.cmu.edu.tw.
AD  - Institute of Biochemistry and Molecular Biology, Graduate Institute of Biomedical 
      Sciences, China Medical University (Taiwan), No. 100, Sec. 1, Jingmao Rd, Beitun 
      Dist, Taichung, 406040, Taiwan, ROC. mingtan@mail.cmu.edu.tw.
LA  - eng
GR  - Elite Scholarship/Taiwan Ministry of Education/
GR  - CMU109-YT-04/China Medical University Ying-Tsai Scholar Fund/
PT  - Journal Article
DEP - 20240724
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Female
MH  - Humans
MH  - *Artificial Intelligence
MH  - Nigeria
MH  - Taiwan
MH  - United States
MH  - Endometrial Neoplasms/diagnosis/therapy
PMC - PMC11269683
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bard
OT  - Bing
OT  - ChatGPT
OT  - Disparity
OT  - Endometrial cancer
COIS- The authors declare no competing interests.
EDAT- 2024/07/26 12:39
MHDA- 2024/07/26 12:40
PMCR- 2024/07/24
CRDT- 2024/07/24 23:21
PHST- 2024/03/06 00:00 [received]
PHST- 2024/07/15 00:00 [accepted]
PHST- 2024/07/26 12:40 [medline]
PHST- 2024/07/26 12:39 [pubmed]
PHST- 2024/07/24 23:21 [entrez]
PHST- 2024/07/24 00:00 [pmc-release]
AID - 10.1038/s41598-024-67689-0 [pii]
AID - 67689 [pii]
AID - 10.1038/s41598-024-67689-0 [doi]
PST - epublish
SO  - Sci Rep. 2024 Jul 24;14(1):17052. doi: 10.1038/s41598-024-67689-0.

PMID- 39962837
OWN - NLM
STAT- MEDLINE
DCOM- 20250218
LR  - 20250218
IS  - 1793-6462 (Electronic)
IS  - 0129-0657 (Linking)
VI  - 35
IP  - 3
DP  - 2025 Mar
TI  - A Context-Dependent CNN-Based Framework for Multiple Sclerosis Segmentation in 
      MRI.
PG  - 2550006
LID - 10.1142/S0129065725500066 [doi]
AB  - Despite several automated strategies for identification/segmentation of Multiple 
      Sclerosis (MS) lesions in Magnetic Resonance Imaging (MRI) being developed, they 
      consistently fall short when compared to the performance of human experts. This 
      emphasizes the unique skills and expertise of human professionals in dealing with 
      the uncertainty resulting from the vagueness and variability of MS, the lack of 
      specificity of MRI concerning MS, and the inherent instabilities of MRI. 
      Physicians manage this uncertainty in part by relying on their radiological, 
      clinical, and anatomical experience. We have developed an automated framework for 
      identifying and segmenting MS lesions in MRI scans by introducing a novel 
      approach to replicating human diagnosis, a significant advancement in the field. 
      This framework has the potential to revolutionize the way MS lesions are 
      identified and segmented, being based on three main concepts: (1) Modeling the 
      uncertainty; (2) Use of separately trained Convolutional Neural Networks (CNNs) 
      optimized for detecting lesions, also considering their context in the brain, and 
      to ensure spatial continuity; (3) Implementing an ensemble classifier to combine 
      information from these CNNs. The proposed framework has been trained, validated, 
      and tested on a single MRI modality, the FLuid-Attenuated Inversion Recovery 
      (FLAIR) of the MSSEG benchmark public data set containing annotated data from 
      seven expert radiologists and one ground truth. The comparison with the ground 
      truth and each of the seven human raters demonstrates that it operates similarly 
      to human raters. At the same time, the proposed model demonstrates more 
      stability, effectiveness and robustness to biases than any other state-of-the-art 
      model though using just the FLAIR modality.
FAU - Placidi, Giuseppe
AU  - Placidi G
AUID- ORCID: 0000-0002-4790-4029
AD  - A2VI-Lab c/o Department of Life, Health & Environmental Sciences, University of 
      L'Aquila, L'Aquila, Italy.
FAU - Cinque, Luigi
AU  - Cinque L
AUID- ORCID: 0000-0001-9149-2175
AD  - Department of Computer Science, Sapienza University of Rome, Rome, Italy.
FAU - Foresti, Gian Luca
AU  - Foresti GL
AUID- ORCID: 0000-0002-8425-6892
AD  - Department of Mathematics, Computer and Physics Science, University of Udine, 
      Udine, Italy.
FAU - Galassi, Francesca
AU  - Galassi F
AUID- ORCID: 0000-0002-8788-2856
AD  - Univ Rennes, CNRS, Inria, Inserm, IRISA UMR 6074, EMPENN - ERL U 1228, F-35000 
      Rennes, France.
FAU - Mignosi, Filippo
AU  - Mignosi F
AUID- ORCID: 0000-0001-9599-5730
AD  - Department of Information Engineering, Computer Science and Mathematics, 
      University of L'Aquila, L'Aquila, Italy.
FAU - Nappi, Michele
AU  - Nappi M
AUID- ORCID: 0000-0002-2517-2867
AD  - Department of Computer Science, University of Salerno, Fisciano, Italy.
FAU - Polsinelli, Matteo
AU  - Polsinelli M
AUID- ORCID: 0000-0002-4215-2630
AD  - Department of Management & Innovation Systems, University of Salerno, Fisciano, 
      Italy.
LA  - eng
PT  - Journal Article
DEP - 20241213
PL  - Singapore
TA  - Int J Neural Syst
JT  - International journal of neural systems
JID - 9100527
SB  - IM
MH  - Humans
MH  - *Magnetic Resonance Imaging/methods
MH  - *Multiple Sclerosis/diagnostic imaging
MH  - *Neural Networks, Computer
MH  - *Brain/diagnostic imaging
MH  - Image Interpretation, Computer-Assisted/methods
MH  - Image Processing, Computer-Assisted/methods
OTO - NOTNLM
OT  - FLAIR
OT  - MRI
OT  - Multiple sclerosis
OT  - U-Net
OT  - classification
OT  - convolutional neural network
OT  - segmentation
OT  - uncertainty
EDAT- 2025/02/18 06:22
MHDA- 2025/02/18 06:23
CRDT- 2025/02/18 01:43
PHST- 2025/02/18 06:23 [medline]
PHST- 2025/02/18 06:22 [pubmed]
PHST- 2025/02/18 01:43 [entrez]
AID - 10.1142/S0129065725500066 [doi]
PST - ppublish
SO  - Int J Neural Syst. 2025 Mar;35(3):2550006. doi: 10.1142/S0129065725500066. Epub 
      2024 Dec 13.

PMID- 40036668
OWN - NLM
STAT- Publisher
LR  - 20250304
IS  - 1535-2900 (Electronic)
IS  - 1079-2082 (Linking)
DP  - 2025 Feb 28
TI  - The role of artificial intelligence in emergency medicine pharmacy practice.
LID - zxaf038 [pii]
LID - 10.1093/ajhp/zxaf038 [doi]
AB  - DISCLAIMER: In an effort to expedite the publication of articles, AJHP is posting 
      manuscripts online as soon as possible after acceptance. Accepted manuscripts 
      have been peer-reviewed and copyedited, but are posted online before technical 
      formatting and author proofing. These manuscripts are not the final version of 
      record and will be replaced with the final article (formatted per AJHP style and 
      proofed by the authors) at a later time. PURPOSE: This primer aims to serve as a 
      foundational resource on artificial intelligence (AI) for pharmacists practicing 
      in the emergency department (ED). SUMMARY: Artificial intelligence (AI) is 
      increasingly recognized for its potential to transform healthcare, including 
      emergency medicine (EM) and pharmacy practice. AI applications in EM include 
      diagnostic evaluation, risk stratification, resource optimization, and 
      therapeutic decision-making. AI's role in improving triage, diagnostics, and 
      resource utilization in the emergency setting is discussed along with its 
      application in the medication-use process, from prescribing to monitoring. 
      Despite the promise of AI, significant barriers such as factual inaccuracies, 
      ethical concerns, and data transparency prevent the widespread clinical adoption 
      of AI tools. Challenges such as racial bias, data privacy, model transparency, 
      and the phenomenon of hallucinations in large language model outputs are 
      highlighted as critical considerations. AI's future success in EM will depend on 
      responsible integration, guided by clinicians including pharmacists, and a 
      careful consideration of ethical issues and patient-specific values. CONCLUSION: 
      Pharmacists practicing in the ED should be familiar with AI tools and should 
      understand the importance of their role in the development, implementation, and 
      oversight of these tools to ensure safe, effective, and equitable patient care.
CI  - © American Society of Health-System Pharmacists 2025. All rights reserved. For 
      commercial re-use, please contact reprints@oup.com for reprints and translation 
      rights for reprints. All other permissions can be obtained through our RightsLink 
      service via the Permissions link on the article page on our site—for further 
      information please contact journals.permissions@oup.com.
FAU - Edwards, Christopher J
AU  - Edwards CJ
AD  - Department of Pharmacy Practice & Science, University of Arizona R. Ken Coit 
      College of Pharmacy, Tucson, AZ, USA.
FAU - Erstad, Brian L
AU  - Erstad BL
AD  - Department of Pharmacy Practice & Science, University of Arizona R. Ken Coit 
      College of Pharmacy, Tucson, AZ, USA.
FAU - Ng, Vivienne
AU  - Ng V
AD  - Department of Emergency Medicine, University of Arizona College of Medicine, 
      Tucson, AZ, USA.
LA  - eng
PT  - Journal Article
DEP - 20250228
PL  - England
TA  - Am J Health Syst Pharm
JT  - American journal of health-system pharmacy : AJHP : official journal of the 
      American Society of Health-System Pharmacists
JID - 9503023
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - emergency medicine
OT  - pharmacy practice
EDAT- 2025/03/04 23:05
MHDA- 2025/03/04 23:05
CRDT- 2025/03/04 15:33
PHST- 2024/09/04 00:00 [received]
PHST- 2025/03/04 23:05 [medline]
PHST- 2025/03/04 23:05 [pubmed]
PHST- 2025/03/04 15:33 [entrez]
AID - 8045631 [pii]
AID - 10.1093/ajhp/zxaf038 [doi]
PST - aheadofprint
SO  - Am J Health Syst Pharm. 2025 Feb 28:zxaf038. doi: 10.1093/ajhp/zxaf038.

PMID- 38740316
OWN - NLM
STAT- MEDLINE
DCOM- 20240527
LR  - 20250314
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Print)
IS  - 1532-0464 (Linking)
VI  - 154
DP  - 2024 Jun
TI  - A roadmap to artificial intelligence (AI): Methods for designing and building AI 
      ready data to promote fairness.
PG  - 104654
LID - S1532-0464(24)00072-8 [pii]
LID - 10.1016/j.jbi.2024.104654 [doi]
AB  - OBJECTIVES: We evaluated methods for preparing electronic health record data to 
      reduce bias before applying artificial intelligence (AI). METHODS: We created 
      methods for transforming raw data into a data framework for applying machine 
      learning and natural language processing techniques for predicting falls and 
      fractures. Strategies such as inclusion and reporting for multiple races, mixed 
      data sources such as outpatient, inpatient, structured codes, and unstructured 
      notes, and addressing missingness were applied to raw data to promote a reduction 
      in bias. The raw data was carefully curated using validated definitions to create 
      data variables such as age, race, gender, and healthcare utilization. For the 
      formation of these variables, clinical, statistical, and data expertise were 
      used. The research team included a variety of experts with diverse professional 
      and demographic backgrounds to include diverse perspectives. RESULTS: For the 
      prediction of falls, information extracted from radiology reports was converted 
      to a matrix for applying machine learning. The processing of the data resulted in 
      an input of 5,377,673 reports to the machine learning algorithm, out of which 
      45,304 were flagged as positive and 5,332,369 as negative for falls. Processed 
      data resulted in lower missingness and a better representation of race and 
      diagnosis codes. For fractures, specialized algorithms extracted snippets of text 
      around keywork "femoral" from dual x-ray absorptiometry (DXA) scans to identify 
      femoral neck T-scores that are important for predicting fracture risk. The 
      natural language processing algorithms yielded 98% accuracy and 2% error rate The 
      methods to prepare data for input to artificial intelligence processes are 
      reproducible and can be applied to other studies. CONCLUSION: The life cycle of 
      data from raw to analytic form includes data governance, cleaning, management, 
      and analysis. When applying artificial intelligence methods, input data must be 
      prepared optimally to reduce algorithmic bias, as biased output is harmful. 
      Building AI-ready data frameworks that improve efficiency can contribute to 
      transparency and reproducibility. The roadmap for the application of AI involves 
      applying specialized techniques to input data, some of which are suggested here. 
      This study highlights data curation aspects to be considered when preparing data 
      for the application of artificial intelligence to reduce bias.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Kidwai-Khan, Farah
AU  - Kidwai-Khan F
AD  - Yale School of Medicine, New Haven, CT, USA; VA Connecticut Healthcare System, 
      West Haven, CT, USA. Electronic address: farah.kidwai-khan@yale.edu.
FAU - Wang, Rixin
AU  - Wang R
AD  - Yale School of Medicine, New Haven, CT, USA; VA Connecticut Healthcare System, 
      West Haven, CT, USA.
FAU - Skanderson, Melissa
AU  - Skanderson M
AD  - VA Connecticut Healthcare System, West Haven, CT, USA.
FAU - Brandt, Cynthia A
AU  - Brandt CA
AD  - Yale School of Medicine, New Haven, CT, USA; VA Connecticut Healthcare System, 
      West Haven, CT, USA.
FAU - Fodeh, Samah
AU  - Fodeh S
AD  - Yale School of Medicine, New Haven, CT, USA; VA Connecticut Healthcare System, 
      West Haven, CT, USA.
FAU - Womack, Julie A
AU  - Womack JA
AD  - VA Connecticut Healthcare System, West Haven, CT, USA; Yale School of Nursing, 
      New Haven, CT, USA.
LA  - eng
GR  - UL1 TR001863/TR/NCATS NIH HHS/United States
GR  - U01 AA020790/AA/NIAAA NIH HHS/United States
GR  - U01 AA013566/AA/NIAAA NIH HHS/United States
GR  - R01 AA013566/AA/NIAAA NIH HHS/United States
GR  - U24 AA020794/AA/NIAAA NIH HHS/United States
GR  - U10 AA013566/AA/NIAAA NIH HHS/United States
GR  - R01 AR078715/AR/NIAMS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20240511
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
UOF - medRxiv. 2023 May 30:2023.05.25.23290399. doi: 10.1101/2023.05.25.23290399. PMID: 
      37398113
MH  - Humans
MH  - *Electronic Health Records
MH  - *Artificial Intelligence
MH  - *Natural Language Processing
MH  - *Accidental Falls/prevention & control
MH  - *Algorithms
MH  - *Machine Learning
MH  - Fractures, Bone
MH  - Female
PMC - PMC11144439
MID - NIHMS1996818
OTO - NOTNLM
OT  - Algorithms
OT  - Artificial Intelligence
OT  - Data preparation
OT  - Diversity
OT  - Fairness
OT  - Inclusion
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/05/14 00:43
MHDA- 2024/05/28 00:43
PMCR- 2025/06/01
CRDT- 2024/05/13 19:25
PHST- 2023/09/29 00:00 [received]
PHST- 2024/05/01 00:00 [revised]
PHST- 2024/05/10 00:00 [accepted]
PHST- 2025/06/01 00:00 [pmc-release]
PHST- 2024/05/28 00:43 [medline]
PHST- 2024/05/14 00:43 [pubmed]
PHST- 2024/05/13 19:25 [entrez]
AID - S1532-0464(24)00072-8 [pii]
AID - 10.1016/j.jbi.2024.104654 [doi]
PST - ppublish
SO  - J Biomed Inform. 2024 Jun;154:104654. doi: 10.1016/j.jbi.2024.104654. Epub 2024 
      May 11.

PMID- 38175996
OWN - NLM
STAT- MEDLINE
DCOM- 20240226
LR  - 20250302
IS  - 1940-5480 (Electronic)
IS  - 1067-151X (Print)
IS  - 1067-151X (Linking)
VI  - 32
IP  - 5
DP  - 2024 Mar 1
TI  - Ethical Considerations of Artificial Intelligence in Health Care: Examining the 
      Role of Generative Pretrained Transformer-4.
PG  - 205-210
LID - 10.5435/JAAOS-D-23-00787 [doi]
AB  - The integration of artificial intelligence technologies, such as large language 
      models (LLMs), in health care holds potential for improved efficiency and 
      decision support. However, ethical concerns must be addressed before widespread 
      adoption. This article focuses on the ethical principles surrounding the use of 
      Generative Pretrained Transformer-4 and its conversational model, ChatGPT, in 
      healthcare settings. One concern is potential inaccuracies in generated content. 
      LLMs can produce believable yet incorrect information, risking errors in medical 
      records. Opacity of training data exacerbates this, hindering accuracy 
      assessment. To mitigate, LLMs should train on precise, validated medical data 
      sets. Model bias is another critical concern because LLMs may perpetuate biases 
      from their training, leading to medically inaccurate and discriminatory 
      responses. Sampling, programming, and compliance biases contribute necessitating 
      careful consideration to avoid perpetuating harmful stereotypes. Privacy is 
      paramount in health care, using public LLMs raises risks. Strict data-sharing 
      agreements and Health Insurance Portability and Accountability Act 
      (HIPAA)-compliant training protocols are necessary to protect patient privacy. 
      Although artificial intelligence technologies offer promising opportunities in 
      health care, careful consideration of ethical principles is crucial. Addressing 
      concerns of inaccuracy, bias, and privacy will ensure responsible and 
      patient-centered implementation, benefiting both healthcare professionals and 
      patients.
CI  - Copyright © 2023 by the American Academy of Orthopaedic Surgeons.
FAU - Sheth, Suraj
AU  - Sheth S
AD  - From the Department of Orthopaedic Surgery, The University of Chicago, Chicago, 
      IL.
FAU - Baker, Hayden P
AU  - Baker HP
AUID- ORCID: 0000-0002-9306-7006
FAU - Prescher, Hannes
AU  - Prescher H
FAU - Strelzow, Jason A
AU  - Strelzow JA
LA  - eng
GR  - T32 GM150375/GM/NIGMS NIH HHS/United States
PT  - Journal Article
DEP - 20240103
PL  - United States
TA  - J Am Acad Orthop Surg
JT  - The Journal of the American Academy of Orthopaedic Surgeons
JID - 9417468
SB  - IM
MH  - United States
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Communication
MH  - Health Facilities
MH  - Health Personnel
MH  - Language
PMC - PMC11536186
MID - NIHMS2032415
EDAT- 2024/01/04 18:41
MHDA- 2024/02/26 06:43
PMCR- 2025/03/01
CRDT- 2024/01/04 16:22
PHST- 2023/08/25 00:00 [received]
PHST- 2023/11/26 00:00 [accepted]
PHST- 2024/02/26 06:43 [medline]
PHST- 2024/01/04 18:41 [pubmed]
PHST- 2024/01/04 16:22 [entrez]
PHST- 2025/03/01 00:00 [pmc-release]
AID - 00124635-202403010-00003 [pii]
AID - 10.5435/JAAOS-D-23-00787 [doi]
PST - ppublish
SO  - J Am Acad Orthop Surg. 2024 Mar 1;32(5):205-210. doi: 10.5435/JAAOS-D-23-00787. 
      Epub 2024 Jan 3.

PMID- 38744501
OWN - NLM
STAT- MEDLINE
DCOM- 20240802
LR  - 20240802
IS  - 1600-0560 (Electronic)
IS  - 0303-6987 (Linking)
VI  - 51
IP  - 9
DP  - 2024 Sep
TI  - Evaluating the diagnostic performance of a large language model-powered chatbot 
      for providing immunohistochemistry recommendations in dermatopathology.
PG  - 689-695
LID - 10.1111/cup.14631 [doi]
AB  - BACKGROUND: Large language model (LLM)-powered chatbots such as ChatGPT have 
      numerous applications. However, their effectiveness in dermatopathology has not 
      been formally evaluated. Dermatopathological cases often require 
      immunohistochemical workup. Here, we evaluate the performance of a chatbot in 
      providing diagnostically useful information on immunohistochemistry relating to 
      dermatological diseases. METHODS: We queried a commonly used chatbot for the 
      immunophenotypes of 51 cutaneous diseases, including a diverse variety of 
      epidermal, adnexal, hematolymphoid, and soft tissue entities. We requested it to 
      provide references for each diagnosis. All tests were repeated, compiled, 
      quantified, and then compared with established literature standards. RESULTS: 
      Clustering analysis demonstrated that recommendations correlated with tumor type, 
      suggesting chatbots can supply appropriate panels. However, a significant portion 
      of recommendations were factually incorrect (13.9%). Citations were rarely 
      clinically useful (24.5%). Many were confabulated (27.2%). Prompt responses for 
      cutaneous adnexal lesions tended to be less accurate while literature references 
      were less useful. Reference retrieval performance was associated with the number 
      of PubMed entries per entity. CONCLUSIONS: This foundational study suggests that 
      LLM-powered chatbots may be useful for generating immunohistochemical panels for 
      dermatologic diagnoses. However, specific performance capabilities and biases 
      must be considered. In addition, extreme caution is advised regarding the 
      tendencies to fabricate material. Future models intentionally fine-tuned to 
      augment diagnostic medicine may prove to be valuable.
CI  - © 2024 John Wiley & Sons A/S. Published by John Wiley & Sons Ltd.
FAU - McCrary, Myles R
AU  - McCrary MR
AUID- ORCID: 0000-0002-4572-7372
AD  - Department of Anatomic and Clinical Pathology, Morsani College of Medicine, 
      University of South Florida, Tampa, Florida, USA.
AD  - Department of Dermatology and Cutaneous Surgery, Morsani College of Medicine, 
      University of South Florida, Tampa, Florida, USA.
FAU - Galambus, Justine
AU  - Galambus J
AUID- ORCID: 0000-0002-2425-0851
AD  - Department of Dermatology and Cutaneous Surgery, Morsani College of Medicine, 
      University of South Florida, Tampa, Florida, USA.
AD  - Department of Internal Medicine, University of Texas Medical Branch, Galveston, 
      Texas, USA.
FAU - Chen, Wei-Shen
AU  - Chen WS
AD  - Department of Anatomic and Clinical Pathology, Morsani College of Medicine, 
      University of South Florida, Tampa, Florida, USA.
AD  - Department of Dermatology and Cutaneous Surgery, Morsani College of Medicine, 
      University of South Florida, Tampa, Florida, USA.
LA  - eng
PT  - Journal Article
DEP - 20240514
PL  - United States
TA  - J Cutan Pathol
JT  - Journal of cutaneous pathology
JID - 0425124
SB  - IM
MH  - Humans
MH  - *Immunohistochemistry/methods/standards
MH  - *Skin Diseases/diagnosis/pathology
MH  - Dermatology/methods/standards
OTO - NOTNLM
OT  - artificial intelligence
OT  - immunohistochemistry
OT  - large language model
EDAT- 2024/05/15 05:42
MHDA- 2024/08/02 06:41
CRDT- 2024/05/14 21:03
PHST- 2024/03/18 00:00 [revised]
PHST- 2023/11/16 00:00 [received]
PHST- 2024/04/15 00:00 [accepted]
PHST- 2024/08/02 06:41 [medline]
PHST- 2024/05/15 05:42 [pubmed]
PHST- 2024/05/14 21:03 [entrez]
AID - 10.1111/cup.14631 [doi]
PST - ppublish
SO  - J Cutan Pathol. 2024 Sep;51(9):689-695. doi: 10.1111/cup.14631. Epub 2024 May 14.

PMID- 38458379
OWN - NLM
STAT- MEDLINE
DCOM- 20240424
LR  - 20240614
IS  - 1879-176X (Electronic)
IS  - 0300-5712 (Linking)
VI  - 144
DP  - 2024 May
TI  - Assessing the performance of Bing Chat artificial intelligence: Dental exams, 
      clinical guidelines, and patients' frequent questions.
PG  - 104927
LID - S0300-5712(24)00097-6 [pii]
LID - 10.1016/j.jdent.2024.104927 [doi]
AB  - OBJECTIVES: Bing Chat is a large language model artificial intelligence (AI) with 
      online search and text generating capabilities. This study assessed its 
      performance within the scope of dentistry in: (a) tackling exam questions for 
      dental students, (ii) providing guidelines for dental practitioners, and (iii) 
      answering patients' frequently asked questions. We discuss the potential of 
      clinical tutoring, common patient communication and impact on academia. METHODS: 
      With the aim of assessing AI's performance in dental exams, Bing Chat was 
      presented with 532 multiple-choice questions and awarded scores based on its 
      answers. In evaluating guidelines for clinicians, a further set of 15 questions, 
      each with 2 follow-up questions on clinical protocols, was presented to the AI. 
      The answers were assessed by 4 reviewers using electronic visual analog scale. In 
      evaluating answers to patients' frequently asked questions, another list of 15 
      common questions was included in the session, with respective outputs assessed. 
      RESULTS: Bing Chat correctly answered 383 out of 532 multiple-choice questions in 
      dental exam part, achieving a score of 71.99 %. As for outlining clinical 
      protocols for practitioners, the overall assessment score was 81.05 %. In 
      answering patients' frequently asked questions, Bing Chat achieved an overall 
      mean score of 83.8 %. The assessments demonstrated low inter-rater reliability. 
      CONCLUSIONS: The overall performance of Bing Chat was above the regularly adopted 
      passing scores, particularly in answering patient's frequently asked questions. 
      The generated content may have biased sources. These results suggest the 
      importance of raising clinicians' awareness of AI's benefits and risks, as well 
      as timely adaptations of dental education curricula, and safeguarding its use in 
      dentistry and healthcare in general. CLINICAL SIGNIFICANCE: Bing Chat AI 
      performed above the passing threshold in three categories, and thus demonstrated 
      potential for educational assistance, clinical tutoring, and answering patients' 
      questions. We recommend popularizing its benefits and risks among students and 
      clinicians, while maintaining awareness of possible false information.
CI  - Copyright © 2024 Elsevier Ltd. All rights reserved.
FAU - Brozović, Juraj
AU  - Brozović J
AD  - Assistant Professor, Ph.D., DMD, Specialist in Oral Surgery, Faculty of Dental 
      Medicine and Health, University of Osijek, Croatia. Electronic address: 
      jbrozovic@fdmz.hr.
FAU - Mikulić, Barbara
AU  - Mikulić B
AD  - Assistant, DMD, Faculty of Dental Medicine and Health, University of Osijek, 
      Croatia.
FAU - Tomas, Matej
AU  - Tomas M
AD  - Assistant, Ph.D., DMD, Faculty of Dental Medicine and Health, University of 
      Osijek, Croatia.
FAU - Juzbašić, Martina
AU  - Juzbašić M
AD  - Assistant, DMD, Faculty of Dental Medicine and Health, University of Osijek, 
      Croatia.
FAU - Blašković, Marko
AU  - Blašković M
AD  - Assistant, DMD, Specialist in Oral Surgery, Department of Oral Surgery, Faculty 
      of Dental Medicine, University of Rijeka, Croatia.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240306
PL  - England
TA  - J Dent
JT  - Journal of dentistry
JID - 0354422
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Dental
MH  - Students, Dental
MH  - Practice Guidelines as Topic
MH  - Educational Measurement/methods
MH  - Communication
MH  - Dentist-Patient Relations
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Dental education
OT  - Dental ethics
OT  - Dental informatics
OT  - Dentistry
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/03/09 10:42
MHDA- 2024/04/25 00:54
CRDT- 2024/03/08 19:15
PHST- 2023/08/28 00:00 [received]
PHST- 2024/03/03 00:00 [revised]
PHST- 2024/03/05 00:00 [accepted]
PHST- 2024/04/25 00:54 [medline]
PHST- 2024/03/09 10:42 [pubmed]
PHST- 2024/03/08 19:15 [entrez]
AID - S0300-5712(24)00097-6 [pii]
AID - 10.1016/j.jdent.2024.104927 [doi]
PST - ppublish
SO  - J Dent. 2024 May;144:104927. doi: 10.1016/j.jdent.2024.104927. Epub 2024 Mar 6.

PMID- 39792725
OWN - NLM
STAT- MEDLINE
DCOM- 20250110
LR  - 20250129
IS  - 1536-5964 (Electronic)
IS  - 0025-7974 (Print)
IS  - 0025-7974 (Linking)
VI  - 104
IP  - 2
DP  - 2025 Jan 10
TI  - Tailoring glaucoma education using large language models: Addressing health 
      disparities in patient comprehension.
PG  - e41059
LID - 10.1097/MD.0000000000041059 [doi]
LID - e41059
AB  - This study evaluates the efficacy of GPT-4, a Large Language Model, in 
      simplifying medical literature for enhancing patient comprehension in glaucoma 
      care. GPT-4 was used to transform published abstracts from 3 glaucoma journals 
      (n = 62) and patient education materials (Patient Educational Model [PEMs], 
      n = 9) to a 5th-grade reading level. GPT-4 was also prompted to generate de novo 
      educational outputs at 6 different education levels (5th Grade, 8th Grade, High 
      School, Associate's, Bachelor's and Doctorate). Readability of both transformed 
      and de novo materials was quantified using Flesch Kincaid Grade Level (FKGL) and 
      Flesch Reading Ease (FKRE) Score. Latent semantic analysis (LSA) using cosine 
      similarity was applied to assess content consistency in transformed materials. 
      The transformation of abstracts resulted in FKGL decreasing by an average of 3.21 
      points (30%, P < .001) and FKRE increasing by 28.6 points (66%, P < .001). For 
      PEMs, FKGL decreased by 2.38 points (28%, P = .0272) and FKRE increased by 12.14 
      points (19%, P = .0459). LSA revealed high semantic consistency, with an average 
      cosine similarity of 0.861 across all abstracts and 0.937 for PEMs, signifying 
      topical themes were quantitatively shown to be consistent. This study shows that 
      GPT-4 effectively simplifies medical information about glaucoma, making it more 
      accessible while maintaining textual content. The improved readability scores for 
      both transformed materials and GPT-4 generated content demonstrate its usefulness 
      in patient education across different educational levels.
CI  - Copyright © 2025 the Author(s). Published by Wolters Kluwer Health, Inc.
FAU - Spina, Aidin C
AU  - Spina AC
AUID- ORCID: 0000-0003-3994-9646
AD  - School of Medicine, University of California, Irvine, Irvine, CA.
FAU - Fereydouni, Pirooz
AU  - Fereydouni P
AUID- ORCID: 0009-0006-2561-9370
AD  - School of Medicine, University of California, Irvine, Irvine, CA.
FAU - Tang, Jordan N
AU  - Tang JN
AD  - School of Medicine, University of California, Irvine, Irvine, CA.
FAU - Andalib, Saman
AU  - Andalib S
AD  - School of Medicine, University of California, Irvine, Irvine, CA.
FAU - Picton, Bryce G
AU  - Picton BG
AD  - School of Medicine, University of California, Irvine, Irvine, CA.
FAU - Fox, Austin R
AU  - Fox AR
AD  - School of Medicine, University of California, Irvine, Irvine, CA.
AD  - School of Medicine, Gavin Herbert Eye Institute at University of California, 
      Irvine, Irvine, CA.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Medicine (Baltimore)
JT  - Medicine
JID - 2985248R
SB  - IM
MH  - Humans
MH  - *Glaucoma/therapy
MH  - *Comprehension
MH  - *Patient Education as Topic/methods
MH  - Health Literacy
MH  - Language
PMC - PMC11729625
COIS- The authors have no funding and conflicts of interest to disclose.
EDAT- 2025/01/10 18:20
MHDA- 2025/01/10 18:21
PMCR- 2025/01/10
CRDT- 2025/01/10 14:22
PHST- 2025/01/10 18:21 [medline]
PHST- 2025/01/10 18:20 [pubmed]
PHST- 2025/01/10 14:22 [entrez]
PHST- 2025/01/10 00:00 [pmc-release]
AID - 00005792-202501100-00017 [pii]
AID - MD-D-24-09881 [pii]
AID - 10.1097/MD.0000000000041059 [doi]
PST - ppublish
SO  - Medicine (Baltimore). 2025 Jan 10;104(2):e41059. doi: 
      10.1097/MD.0000000000041059.

PMID- 39321336
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241123
IS  - 2563-3570 (Electronic)
IS  - 2563-3570 (Linking)
VI  - 5
DP  - 2024 Nov 6
TI  - Ethical Considerations in Human-Centered AI: Advancing Oncology Chatbots Through 
      Large Language Models.
PG  - e64406
LID - 10.2196/64406 [doi]
LID - e64406
AB  - The integration of chatbots in oncology underscores the pressing need for 
      human-centered artificial intelligence (AI) that addresses patient and family 
      concerns with empathy and precision. Human-centered AI emphasizes ethical 
      principles, empathy, and user-centric approaches, ensuring technology aligns with 
      human values and needs. This review critically examines the ethical implications 
      of using large language models (LLMs) like GPT-3 and GPT-4 (OpenAI) in oncology 
      chatbots. It examines how these models replicate human-like language patterns, 
      impacting the design of ethical AI systems. The paper identifies key strategies 
      for ethically developing oncology chatbots, focusing on potential biases arising 
      from extensive datasets and neural networks. Specific datasets, such as those 
      sourced from predominantly Western medical literature and patient interactions, 
      may introduce biases by overrepresenting certain demographic groups. Moreover, 
      the training methodologies of LLMs, including fine-tuning processes, can 
      exacerbate these biases, leading to outputs that may disproportionately favor 
      affluent or Western populations while neglecting marginalized communities. By 
      providing examples of biased outputs in oncology chatbots, the review highlights 
      the ethical challenges LLMs present and the need for mitigation strategies. The 
      study emphasizes integrating human-centric values into AI to mitigate these 
      biases, ultimately advocating for the development of oncology chatbots that are 
      aligned with ethical principles and capable of serving diverse patient 
      populations equitably.
CI  - ©James C L Chow, Kay Li. Originally published in JMIR Bioinformatics and 
      Biotechnology (https://bioinform.jmir.org), 06.11.2024.
FAU - Chow, James C L
AU  - Chow JCL
AUID- ORCID: 0000-0003-4202-4855
AD  - Department of Radiation Oncology, University of Toronto, Toronto, ON, Canada.
AD  - Princess Margaret Cancer Centre, University Health Network, Toronto, ON, Canada.
FAU - Li, Kay
AU  - Li K
AUID- ORCID: 0000-0002-5765-1635
AD  - Department of English, University of Toronto, Toronto, ON, Canada.
LA  - eng
PT  - Journal Article
DEP - 20241106
PL  - Canada
TA  - JMIR Bioinform Biotechnol
JT  - JMIR bioinformatics and biotechnology
JID - 101769661
PMC - PMC11579624
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - ethical AI
OT  - health care
OT  - human-centered AI
OT  - humanistic AI
OT  - large language models
OT  - machine learning
OT  - natural language processing
OT  - oncology chatbot
OT  - transformer-based model
COIS- Conflicts of Interest: None declared.
EDAT- 2024/09/25 22:18
MHDA- 2024/09/25 22:19
PMCR- 2024/11/06
CRDT- 2024/09/25 14:52
PHST- 2024/07/16 00:00 [received]
PHST- 2024/09/23 00:00 [accepted]
PHST- 2024/08/23 00:00 [revised]
PHST- 2024/09/25 22:19 [medline]
PHST- 2024/09/25 22:18 [pubmed]
PHST- 2024/09/25 14:52 [entrez]
PHST- 2024/11/06 00:00 [pmc-release]
AID - v5i1e64406 [pii]
AID - 10.2196/64406 [doi]
PST - epublish
SO  - JMIR Bioinform Biotechnol. 2024 Nov 6;5:e64406. doi: 10.2196/64406.

PMID- 40077687
OWN - NLM
STAT- MEDLINE
DCOM- 20250313
LR  - 20250315
IS  - 2072-6643 (Electronic)
IS  - 2072-6643 (Linking)
VI  - 17
IP  - 5
DP  - 2025 Feb 27
TI  - AI-Powered Analysis of Weight Loss Reports from Reddit: Unlocking Social Media's 
      Potential in Dietary Assessment.
LID - 10.3390/nu17050818 [doi]
LID - 818
AB  - Background/Objectives: The increasing use of social media for sharing health and 
      diet experiences presents new opportunities for nutritional research and dietary 
      assessment. Large language models (LLMs) and artificial intelligence (AI) offer 
      innovative approaches to analyzing self-reported data from online communities. 
      This study explores weight loss experiences associated with the ketogenic diet 
      (KD) using user-generated content from Reddit, aiming to identify trends and 
      potential biases in self-reported outcomes. Methods: A dataset of 35,079 Reddit 
      posts related to KD was collected and processed. Posts mentioning weight loss, 
      diet duration, and additional factors (age, gender, physical activity, health 
      conditions) were identified, yielding 2416 complete cases. Descriptive statistics 
      summarized weight loss distributions and diet adherence patterns, while linear 
      regression models examined factors associated with weight loss. Results: The 
      median reported weight loss was 10.9 kg (IQR: 4.4-22.7 kg). Diet adherence varied 
      with 36.3% of users following KD for up to 30 days and 7.8% for more than a year. 
      Metabolic (27%) and cardiovascular disorders (17%) were the most frequently 
      reported health conditions. Adherence beyond one year was associated with an 
      average weight loss of 28.2 kg (95% CI: 25.5-30.9) compared to up to 30 days. 
      Male gender was associated with an additional weight loss of 5.2 kg (95% CI: 
      3.8-6.6) compared to females. Conclusions: Findings suggest KD may lead to 
      substantial weight loss based on self-reported online data. This study highlights 
      the value of social media data in nutritional research, uncovering hidden dietary 
      patterns that could inform public health strategies and personalized nutrition 
      plans.
FAU - Kaloudis, Efstathios
AU  - Kaloudis E
AUID- ORCID: 0000-0001-7602-3282
AD  - Computer Simulation, Genomics and Data Analysis Laboratory, Department of Food 
      Science and Nutrition, School of the Environment, University of the Aegean, 81400 
      Myrina, Greece.
FAU - Kouti, Victoria
AU  - Kouti V
AUID- ORCID: 0009-0002-0431-3509
AD  - Computer Simulation, Genomics and Data Analysis Laboratory, Department of Food 
      Science and Nutrition, School of the Environment, University of the Aegean, 81400 
      Myrina, Greece.
FAU - Triantafillou, Foteini-Maria
AU  - Triantafillou FM
AUID- ORCID: 0009-0002-2428-4119
AD  - Computer Simulation, Genomics and Data Analysis Laboratory, Department of Food 
      Science and Nutrition, School of the Environment, University of the Aegean, 81400 
      Myrina, Greece.
FAU - Ventouris, Patroklos
AU  - Ventouris P
AUID- ORCID: 0009-0008-6606-4695
AD  - Computer Simulation, Genomics and Data Analysis Laboratory, Department of Food 
      Science and Nutrition, School of the Environment, University of the Aegean, 81400 
      Myrina, Greece.
FAU - Pavlidis, Rafail
AU  - Pavlidis R
AD  - Computer Simulation, Genomics and Data Analysis Laboratory, Department of Food 
      Science and Nutrition, School of the Environment, University of the Aegean, 81400 
      Myrina, Greece.
FAU - Bountziouka, Vasiliki
AU  - Bountziouka V
AUID- ORCID: 0000-0003-2522-1582
AD  - Computer Simulation, Genomics and Data Analysis Laboratory, Department of Food 
      Science and Nutrition, School of the Environment, University of the Aegean, 81400 
      Myrina, Greece.
AD  - Population, Policy and Practice Research and Teaching Department, GOS Institute 
      of Child Health, University College London, London WC1N 1EH, UK.
AD  - Department of Cardiovascular Sciences, University of Leicester, BHF 
      Cardiovascular Research Centre, Glenfield Hospital, Groby Road, Leicester LE3 
      9QP, UK.
LA  - eng
PT  - Journal Article
DEP - 20250227
PL  - Switzerland
TA  - Nutrients
JT  - Nutrients
JID - 101521595
SB  - IM
MH  - Humans
MH  - *Social Media
MH  - Male
MH  - *Weight Loss
MH  - Female
MH  - Adult
MH  - *Artificial Intelligence
MH  - *Diet, Ketogenic
MH  - Middle Aged
MH  - Nutrition Assessment
MH  - Self Report
MH  - Patient Compliance/statistics & numerical data
MH  - Young Adult
PMC - PMC11901788
OTO - NOTNLM
OT  - artificial intelligence (AI)
OT  - dietary assessment
OT  - ketogenic diet
OT  - large language models (LLM)
OT  - self-reported data
OT  - social media analytics
OT  - weight loss
COIS- The authors declare no conflicts of interest.
EDAT- 2025/03/13 06:27
MHDA- 2025/03/13 06:28
PMCR- 2025/02/27
CRDT- 2025/03/13 01:12
PHST- 2025/01/31 00:00 [received]
PHST- 2025/02/23 00:00 [revised]
PHST- 2025/02/24 00:00 [accepted]
PHST- 2025/03/13 06:28 [medline]
PHST- 2025/03/13 06:27 [pubmed]
PHST- 2025/03/13 01:12 [entrez]
PHST- 2025/02/27 00:00 [pmc-release]
AID - nu17050818 [pii]
AID - nutrients-17-00818 [pii]
AID - 10.3390/nu17050818 [doi]
PST - epublish
SO  - Nutrients. 2025 Feb 27;17(5):818. doi: 10.3390/nu17050818.

PMID- 39042885
OWN - NLM
STAT- MEDLINE
DCOM- 20240807
LR  - 20240824
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Aug 7
TI  - Assessing ChatGPT's Competency in Addressing Interdisciplinary Inquiries on 
      Chatbot Uses in Sports Rehabilitation: Simulation Study.
PG  - e51157
LID - 10.2196/51157 [doi]
LID - e51157
AB  - BACKGROUND: ChatGPT showcases exceptional conversational capabilities and 
      extensive cross-disciplinary knowledge. In addition, it can perform multiple 
      roles in a single chat session. This unique multirole-playing feature positions 
      ChatGPT as a promising tool for exploring interdisciplinary subjects. OBJECTIVE: 
      The aim of this study was to evaluate ChatGPT's competency in addressing 
      interdisciplinary inquiries based on a case study exploring the opportunities and 
      challenges of chatbot uses in sports rehabilitation. METHODS: We developed a 
      model termed PanelGPT to assess ChatGPT's competency in addressing 
      interdisciplinary topics through simulated panel discussions. Taking chatbot uses 
      in sports rehabilitation as an example of an interdisciplinary topic, we prompted 
      ChatGPT through PanelGPT to role-play a physiotherapist, psychologist, 
      nutritionist, artificial intelligence expert, and athlete in a simulated panel 
      discussion. During the simulation, we posed questions to the panel while ChatGPT 
      acted as both the panelists for responses and the moderator for steering the 
      discussion. We performed the simulation using ChatGPT-4 and evaluated the 
      responses by referring to the literature and our human expertise. RESULTS: By 
      tackling questions related to chatbot uses in sports rehabilitation with respect 
      to patient education, physiotherapy, physiology, nutrition, and ethical 
      considerations, responses from the ChatGPT-simulated panel discussion reasonably 
      pointed to various benefits such as 24/7 support, personalized advice, automated 
      tracking, and reminders. ChatGPT also correctly emphasized the importance of 
      patient education, and identified challenges such as limited interaction modes, 
      inaccuracies in emotion-related advice, assurance of data privacy and security, 
      transparency in data handling, and fairness in model training. It also stressed 
      that chatbots are to assist as a copilot, not to replace human health care 
      professionals in the rehabilitation process. CONCLUSIONS: ChatGPT exhibits strong 
      competency in addressing interdisciplinary inquiry by simulating multiple experts 
      from complementary backgrounds, with significant implications in assisting 
      medical education.
CI  - ©Joseph C McBee, Daniel Y Han, Li Liu, Leah Ma, Donald A Adjeroh, Dong Xu, 
      Gangqing Hu. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 07.08.2024.
FAU - McBee, Joseph C
AU  - McBee JC
AUID- ORCID: 0009-0001-8492-0386
AD  - Department of Microbiology, Immunology, & Cell Biology, West Virginia University, 
      Morgantown, WV, United States.
AD  - Department of Chemical and Biomedical Engineering, West Virginia University, 
      Morgantown, WV, United States.
FAU - Han, Daniel Y
AU  - Han DY
AUID- ORCID: 0009-0007-6904-5177
AD  - Department of Microbiology, Immunology, & Cell Biology, West Virginia University, 
      Morgantown, WV, United States.
FAU - Liu, Li
AU  - Liu L
AUID- ORCID: 0000-0003-4002-7497
AD  - College of Health Solutions, Arizona State University, Phoenix, AZ, United 
      States.
AD  - Biodesign Institute, Arizona State University, Tempe, AZ, United States.
FAU - Ma, Leah
AU  - Ma L
AUID- ORCID: 0009-0003-2555-2880
AD  - College of Health, Education, and Human Services, Wright State University, 
      Dayton, OH, United States.
FAU - Adjeroh, Donald A
AU  - Adjeroh DA
AUID- ORCID: 0000-0002-7982-4744
AD  - Lane Department of Computer Science & Electrical Engineering, West Virginia 
      University, Morgantown, WV, United States.
FAU - Xu, Dong
AU  - Xu D
AUID- ORCID: 0000-0002-4809-0514
AD  - Department of Electrical Engineering and Computer Science, Christopher S. Bond 
      Life Sciences Center, University of Missouri, Columbia, MO, United States.
FAU - Hu, Gangqing
AU  - Hu G
AUID- ORCID: 0000-0001-5453-6888
AD  - Department of Microbiology, Immunology, & Cell Biology, West Virginia University, 
      Morgantown, WV, United States.
LA  - eng
GR  - P20 GM103434/GM/NIGMS NIH HHS/United States
GR  - R01 LM013392/LM/NLM NIH HHS/United States
GR  - R01 LM013438/LM/NLM NIH HHS/United States
GR  - U54 GM104942/GM/NIGMS NIH HHS/United States
PT  - Journal Article
DEP - 20240807
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Interdisciplinary Communication
MH  - Sports
MH  - Clinical Competence/standards
PMC - PMC11339563
OTO - NOTNLM
OT  - ChatGPT
OT  - chatbots
OT  - interdisciplinary inquiry
OT  - medical education
OT  - multirole-playing
OT  - sports medicine
COIS- Conflicts of Interest: None declared.
EDAT- 2024/07/23 18:41
MHDA- 2024/08/07 18:43
PMCR- 2024/08/07
CRDT- 2024/07/23 16:53
PHST- 2023/07/23 00:00 [received]
PHST- 2024/07/23 00:00 [accepted]
PHST- 2023/08/21 00:00 [revised]
PHST- 2024/08/07 18:43 [medline]
PHST- 2024/07/23 18:41 [pubmed]
PHST- 2024/07/23 16:53 [entrez]
PHST- 2024/08/07 00:00 [pmc-release]
AID - v10i1e51157 [pii]
AID - 10.2196/51157 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Aug 7;10:e51157. doi: 10.2196/51157.

PMID- 39726894
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 2081-3856 (Print)
IS  - 2081-6936 (Electronic)
IS  - 2081-6936 (Linking)
VI  - 15
IP  - 1
DP  - 2024 Jan 1
TI  - A pilot evaluation of the diagnostic accuracy of ChatGPT-3.5 for multiple 
      sclerosis from case reports.
PG  - 20220361
LID - 10.1515/tnsci-2022-0361 [doi]
LID - 20220361
AB  - The limitation of artificial intelligence (AI) large language models to diagnose 
      diseases from the perspective of patient safety remains underexplored and 
      potential challenges, such as diagnostic errors and legal challenges, need to be 
      addressed. To demonstrate the limitations of AI, we used ChatGPT-3.5 developed by 
      OpenAI, as a tool for medical diagnosis using text-based case reports of multiple 
      sclerosis (MS), which was selected as a prototypic disease. We analyzed 98 
      peer-reviewed case reports selected based on free-full text availability and 
      published within the past decade (2014-2024), excluding any mention of an MS 
      diagnosis to avoid bias. ChatGPT-3.5 was used to interpret clinical presentations 
      and laboratory data from these reports. The model correctly diagnosed MS in 77 
      cases, achieving an accuracy rate of 78.6%. However, the remaining 21 cases were 
      misdiagnosed, highlighting the model's limitations. Factors contributing to the 
      errors include variability in data presentation and the inherent complexity of MS 
      diagnosis, which requires imaging modalities in addition to clinical 
      presentations and laboratory data. While these findings suggest that AI can 
      support disease diagnosis and healthcare providers in decision-making, inadequate 
      training with large datasets may lead to significant inaccuracies. Integrating AI 
      into clinical practice necessitates rigorous validation and robust regulatory 
      frameworks to ensure responsible use.
CI  - © 2024 the author(s), published by De Gruyter.
FAU - Joseph, Anika
AU  - Joseph A
AD  - Health Sciences Program, University of Ottawa, 75 Laurier Ave E, Ottawa, ON K1N 
      6N5, Canada.
FAU - Joseph, Kevin
AU  - Joseph K
AD  - Biomedical Science Program, University of Ottawa, 75 Laurier Ave E, Ottawa, ON 
      K1N 6N5, Canada.
FAU - Joseph, Angelyn
AU  - Joseph A
AD  - Merivale High School, 1755 Merivale Rd, Nepean, ON K2G 1E2, Canada.
LA  - eng
PT  - Journal Article
DEP - 20241224
PL  - Germany
TA  - Transl Neurosci
JT  - Translational neuroscience
JID - 101550327
PMC - PMC11669902
OTO - NOTNLM
OT  - artificial intelligence
OT  - case reports
OT  - legal
OT  - multiple sclerosis
COIS- Conflict of interest: Authors state no conflict of interest.
EDAT- 2024/12/27 06:19
MHDA- 2024/12/27 06:20
PMCR- 2024/12/24
CRDT- 2024/12/27 04:01
PHST- 2024/07/30 00:00 [received]
PHST- 2024/11/19 00:00 [revised]
PHST- 2024/11/27 00:00 [accepted]
PHST- 2024/12/27 06:20 [medline]
PHST- 2024/12/27 06:19 [pubmed]
PHST- 2024/12/27 04:01 [entrez]
PHST- 2024/12/24 00:00 [pmc-release]
AID - tnsci-2022-0361 [pii]
AID - 10.1515/tnsci-2022-0361 [doi]
PST - epublish
SO  - Transl Neurosci. 2024 Dec 24;15(1):20220361. doi: 10.1515/tnsci-2022-0361. 
      eCollection 2024 Jan 1.

PMID- 38744921
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240518
IS  - 2398-6352 (Electronic)
IS  - 2398-6352 (Linking)
VI  - 7
IP  - 1
DP  - 2024 May 14
TI  - Shortcut learning in medical AI hinders generalization: method for estimating AI 
      model generalization without external data.
PG  - 124
LID - 10.1038/s41746-024-01118-4 [doi]
LID - 124
AB  - Healthcare datasets are becoming larger and more complex, necessitating the 
      development of accurate and generalizable AI models for medical applications. 
      Unstructured datasets, including medical imaging, electrocardiograms, and natural 
      language data, are gaining attention with advancements in deep convolutional 
      neural networks and large language models. However, estimating the 
      generalizability of these models to new healthcare settings without extensive 
      validation on external data remains challenging. In experiments across 13 
      datasets including X-rays, CTs, ECGs, clinical discharge summaries, and lung 
      auscultation data, our results demonstrate that model performance is frequently 
      overestimated by up to 20% on average due to shortcut learning of hidden data 
      acquisition biases (DAB). Shortcut learning refers to a phenomenon in which an AI 
      model learns to solve a task based on spurious correlations present in the data 
      as opposed to features directly related to the task itself. We propose an open 
      source, bias-corrected external accuracy estimate, P(Est), that better estimates 
      external accuracy to within 4% on average by measuring and calibrating for 
      DAB-induced shortcut learning.
CI  - © 2024. The Author(s).
FAU - Ong Ly, Cathy
AU  - Ong Ly C
AD  - Peter Munk Cardiac Centre and Ted Rogers Centre for Heart Research, University 
      Health Network, Toronto, ON, Canada.
AD  - Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada.
AD  - Toronto General Hospital Research Institute, University Health Network, Toronto, 
      ON, Canada.
FAU - Unnikrishnan, Balagopal
AU  - Unnikrishnan B
AD  - Toronto General Hospital Research Institute, University Health Network, Toronto, 
      ON, Canada.
AD  - Department of Computer Science, University of Toronto, Toronto, ON, Canada.
AD  - Joint Department of Medical Imaging, University Health Network, Toronto, ON, 
      Canada.
AD  - Vector Institute, Toronto, ON, Canada.
FAU - Tadic, Tony
AU  - Tadic T
AD  - Radiation Medicine Program, Princess Margaret Cancer Centre, University Health 
      Network, Toronto, ON, Canada.
AD  - Department of Radiation Oncology, University of Toronto, Toronto, ON, Canada.
FAU - Patel, Tirth
AU  - Patel T
AUID- ORCID: 0000-0002-3628-2367
AD  - Radiation Medicine Program, Princess Margaret Cancer Centre, University Health 
      Network, Toronto, ON, Canada.
FAU - Duhamel, Joe
AU  - Duhamel J
AUID- ORCID: 0000-0002-3457-2715
AD  - Peter Munk Cardiac Centre and Ted Rogers Centre for Heart Research, University 
      Health Network, Toronto, ON, Canada.
FAU - Kandel, Sonja
AU  - Kandel S
AD  - Joint Department of Medical Imaging, University Health Network, Toronto, ON, 
      Canada.
FAU - Moayedi, Yasbanoo
AU  - Moayedi Y
AD  - Peter Munk Cardiac Centre and Ted Rogers Centre for Heart Research, University 
      Health Network, Toronto, ON, Canada.
FAU - Brudno, Michael
AU  - Brudno M
AD  - Department of Computer Science, University of Toronto, Toronto, ON, Canada.
AD  - Vector Institute, Toronto, ON, Canada.
AD  - Princess Margaret Cancer Centre, University Health Network, Toronto, ON, Canada.
FAU - Hope, Andrew
AU  - Hope A
AUID- ORCID: 0000-0001-6793-2863
AD  - Radiation Medicine Program, Princess Margaret Cancer Centre, University Health 
      Network, Toronto, ON, Canada.
AD  - Department of Radiation Oncology, University of Toronto, Toronto, ON, Canada.
FAU - Ross, Heather
AU  - Ross H
AD  - Peter Munk Cardiac Centre and Ted Rogers Centre for Heart Research, University 
      Health Network, Toronto, ON, Canada.
FAU - McIntosh, Chris
AU  - McIntosh C
AUID- ORCID: 0000-0003-1371-1250
AD  - Peter Munk Cardiac Centre and Ted Rogers Centre for Heart Research, University 
      Health Network, Toronto, ON, Canada. chris.mcintosh@uhn.ca.
AD  - Department of Medical Biophysics, University of Toronto, Toronto, ON, Canada. 
      chris.mcintosh@uhn.ca.
AD  - Toronto General Hospital Research Institute, University Health Network, Toronto, 
      ON, Canada. chris.mcintosh@uhn.ca.
AD  - Department of Computer Science, University of Toronto, Toronto, ON, Canada. 
      chris.mcintosh@uhn.ca.
AD  - Joint Department of Medical Imaging, University Health Network, Toronto, ON, 
      Canada. chris.mcintosh@uhn.ca.
AD  - Vector Institute, Toronto, ON, Canada. chris.mcintosh@uhn.ca.
AD  - Radiation Medicine Program, Princess Margaret Cancer Centre, University Health 
      Network, Toronto, ON, Canada. chris.mcintosh@uhn.ca.
AD  - Department of Medical Imaging, University of Toronto, Toronto, ON, Canada. 
      chris.mcintosh@uhn.ca.
LA  - eng
PT  - Journal Article
DEP - 20240514
PL  - England
TA  - NPJ Digit Med
JT  - NPJ digital medicine
JID - 101731738
PMC - PMC11094145
COIS- The authors declare no competing interests.
EDAT- 2024/05/15 05:43
MHDA- 2024/05/15 05:44
PMCR- 2024/05/14
CRDT- 2024/05/14 23:31
PHST- 2023/10/02 00:00 [received]
PHST- 2024/04/23 00:00 [accepted]
PHST- 2024/05/15 05:44 [medline]
PHST- 2024/05/15 05:43 [pubmed]
PHST- 2024/05/14 23:31 [entrez]
PHST- 2024/05/14 00:00 [pmc-release]
AID - 10.1038/s41746-024-01118-4 [pii]
AID - 1118 [pii]
AID - 10.1038/s41746-024-01118-4 [doi]
PST - epublish
SO  - NPJ Digit Med. 2024 May 14;7(1):124. doi: 10.1038/s41746-024-01118-4.

PMID- 39446671
OWN - NLM
STAT- MEDLINE
DCOM- 20250117
LR  - 20250212
IS  - 2152-2723 (Electronic)
IS  - 2152-2715 (Print)
IS  - 2152-2715 (Linking)
VI  - 28
IP  - 1
DP  - 2025 Jan
TI  - Evaluating for Evidence of Sociodemographic Bias in Conversational AI for Mental 
      Health Support.
PG  - 44-51
LID - 10.1089/cyber.2024.0199 [doi]
AB  - The integration of large language models (LLMs) into healthcare highlights the 
      need to ensure their efficacy while mitigating potential harms, such as the 
      perpetuation of biases. Current evidence on the existence of bias within LLMs 
      remains inconclusive. In this study, we present an approach to investigate the 
      presence of bias within an LLM designed for mental health support. We simulated 
      physician-patient conversations by using a communication loop between an 
      LLM-based conversational agent and digital standardized patients (DSPs) that 
      engaged the agent in dialogue while remaining agnostic to sociodemographic 
      characteristics. In contrast, the conversational agent was made aware of each 
      DSP's characteristics, including age, sex, race/ethnicity, and annual income. The 
      agent's responses were analyzed to discern potential systematic biases using the 
      Linguistic Inquiry and Word Count tool. Multivariate regression analysis, trend 
      analysis, and group-based trajectory models were used to quantify potential 
      biases. Among 449 conversations, there was no evidence of bias in both 
      descriptive assessments and multivariable linear regression analyses. Moreover, 
      when evaluating changes in mean tone scores throughout a dialogue, the 
      conversational agent exhibited a capacity to show understanding of the DSPs' 
      chief complaints and to elevate the tone scores of the DSPs throughout 
      conversations. This finding did not vary by any sociodemographic characteristics 
      of the DSP. Using an objective methodology, our study did not uncover significant 
      evidence of bias within an LLM-enabled mental health conversational agent. These 
      findings offer a complementary approach to examining bias in LLM-based 
      conversational agents for mental health support.
FAU - Yeo, Yee Hui
AU  - Yeo YH
AUID- ORCID: 0000-0002-2703-5954
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, 
      Los Angeles, California, USA.
FAU - Peng, Yuxin
AU  - Peng Y
AD  - School of Mathematics and Statistics, Xi'an Jiaotong University, Xi'an, China.
FAU - Mehra, Muskaan
AU  - Mehra M
AD  - Division of Health Services Research, Cedars-Sinai Medical Center, Center for 
      Outcomes Research and Education (CS-CORE), Los Angeles, California, USA.
FAU - Samaan, Jamil
AU  - Samaan J
AD  - Karsh Division of Gastroenterology and Hepatology, Cedars-Sinai Medical Center, 
      Los Angeles, California, USA.
FAU - Hakimian, Joshua
AU  - Hakimian J
AD  - Division of Health Services Research, Cedars-Sinai Medical Center, Center for 
      Outcomes Research and Education (CS-CORE), Los Angeles, California, USA.
FAU - Clark, Allistair
AU  - Clark A
AD  - Division of Health Services Research, Cedars-Sinai Medical Center, Center for 
      Outcomes Research and Education (CS-CORE), Los Angeles, California, USA.
FAU - Suchak, Karisma
AU  - Suchak K
AD  - Division of Health Services Research, Cedars-Sinai Medical Center, Center for 
      Outcomes Research and Education (CS-CORE), Los Angeles, California, USA.
FAU - Krut, Zoe
AU  - Krut Z
AD  - Division of Health Services Research, Cedars-Sinai Medical Center, Center for 
      Outcomes Research and Education (CS-CORE), Los Angeles, California, USA.
FAU - Andersson, Taiga
AU  - Andersson T
AD  - Department of Cardiology, Smidt Heart Institute, Cedars-Sinai Medical Center, Los 
      Angeles, California, USA.
FAU - Persky, Susan
AU  - Persky S
AUID- ORCID: 0000-0002-7768-5744
AD  - Social and Behavioral Research Branch, National Human Genome Research Institute, 
      Bethesda, Maryland, USA.
FAU - Liran, Omer
AU  - Liran O
AD  - Division of Health Services Research, Cedars-Sinai Medical Center, Center for 
      Outcomes Research and Education (CS-CORE), Los Angeles, California, USA.
FAU - Spiegel, Brennan
AU  - Spiegel B
AD  - Division of Health Services Research, Cedars-Sinai Medical Center, Center for 
      Outcomes Research and Education (CS-CORE), Los Angeles, California, USA.
LA  - eng
PT  - Journal Article
DEP - 20241024
PL  - United States
TA  - Cyberpsychol Behav Soc Netw
JT  - Cyberpsychology, behavior and social networking
JID - 101528721
SB  - IM
MH  - Humans
MH  - *Communication
MH  - Female
MH  - Male
MH  - Adult
MH  - Artificial Intelligence
MH  - Physician-Patient Relations
MH  - Mental Health
MH  - Mental Health Services
MH  - Language
MH  - Socioeconomic Factors
MH  - Bias
PMC - PMC11807910
OTO - NOTNLM
OT  - artificial intelligence
OT  - bias
OT  - disparity
OT  - large language model
OT  - linguistic inquiry and word count
OT  - mental health
EDAT- 2024/10/25 07:20
MHDA- 2025/01/17 18:22
PMCR- 2026/01/15
CRDT- 2024/10/24 13:13
PHST- 2026/01/15 00:00 [pmc-release]
PHST- 2025/01/17 18:22 [medline]
PHST- 2024/10/25 07:20 [pubmed]
PHST- 2024/10/24 13:13 [entrez]
AID - 10.1089/cyber.2024.0199 [pii]
AID - 10.1089/cyber.2024.0199 [doi]
PST - ppublish
SO  - Cyberpsychol Behav Soc Netw. 2025 Jan;28(1):44-51. doi: 10.1089/cyber.2024.0199. 
      Epub 2024 Oct 24.

PMID- 38441952
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240308
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 8
DP  - 2024 Mar 5
TI  - Machine Learning-Based Approach for Identifying Research Gaps: COVID-19 as a Case 
      Study.
PG  - e49411
LID - 10.2196/49411 [doi]
LID - e49411
AB  - BACKGROUND: Research gaps refer to unanswered questions in the existing body of 
      knowledge, either due to a lack of studies or inconclusive results. Research gaps 
      are essential starting points and motivation in scientific research. Traditional 
      methods for identifying research gaps, such as literature reviews and expert 
      opinions, can be time consuming, labor intensive, and prone to bias. They may 
      also fall short when dealing with rapidly evolving or time-sensitive subjects. 
      Thus, innovative scalable approaches are needed to identify research gaps, 
      systematically assess the literature, and prioritize areas for further study in 
      the topic of interest. OBJECTIVE: In this paper, we propose a machine 
      learning-based approach for identifying research gaps through the analysis of 
      scientific literature. We used the COVID-19 pandemic as a case study. METHODS: We 
      conducted an analysis to identify research gaps in COVID-19 literature using the 
      COVID-19 Open Research (CORD-19) data set, which comprises 1,121,433 papers 
      related to the COVID-19 pandemic. Our approach is based on the BERTopic topic 
      modeling technique, which leverages transformers and class-based term 
      frequency-inverse document frequency to create dense clusters allowing for easily 
      interpretable topics. Our BERTopic-based approach involves 3 stages: embedding 
      documents, clustering documents (dimension reduction and clustering), and 
      representing topics (generating candidates and maximizing candidate relevance). 
      RESULTS: After applying the study selection criteria, we included 33,206 
      abstracts in the analysis of this study. The final list of research gaps 
      identified 21 different areas, which were grouped into 6 principal topics. These 
      topics were: "virus of COVID-19," "risk factors of COVID-19," "prevention of 
      COVID-19," "treatment of COVID-19," "health care delivery during COVID-19," "and 
      impact of COVID-19." The most prominent topic, observed in over half of the 
      analyzed studies, was "the impact of COVID-19." CONCLUSIONS: The proposed machine 
      learning-based approach has the potential to identify research gaps in scientific 
      literature. This study is not intended to replace individual literature research 
      within a selected topic. Instead, it can serve as a guide to formulate precise 
      literature search queries in specific areas associated with research questions 
      that previous publications have earmarked for future exploration. Future research 
      should leverage an up-to-date list of studies that are retrieved from the most 
      common databases in the target area. When feasible, full texts or, at minimum, 
      discussion sections should be analyzed rather than limiting their analysis to 
      abstracts. Furthermore, future studies could evaluate more efficient modeling 
      algorithms, especially those combining topic modeling with statistical 
      uncertainty quantification, such as conformal prediction.
CI  - ©Alaa Abd-alrazaq, Abdulqadir J Nashwan, Zubair Shah, Ahmad Abujaber, Dari 
      Alhuwail, Jens Schneider, Rawan AlSaad, Hazrat Ali, Waleed Alomoush, Arfan Ahmed, 
      Sarah Aziz. Originally published in JMIR Formative Research 
      (https://formative.jmir.org), 05.03.2024.
FAU - Abd-Alrazaq, Alaa
AU  - Abd-Alrazaq A
AUID- ORCID: 0000-0001-7695-4626
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
FAU - Nashwan, Abdulqadir J
AU  - Nashwan AJ
AUID- ORCID: 0000-0003-4845-4119
AD  - Department of Nursing, Hamad Medical Corporation, Doha, Qatar.
FAU - Shah, Zubair
AU  - Shah Z
AUID- ORCID: 0000-0001-7389-3274
AD  - Division of Information and Computing Technology, College of Science and 
      Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - Abujaber, Ahmad
AU  - Abujaber A
AUID- ORCID: 0000-0002-8704-4991
AD  - Nursing Department, Hamad Medical Corporation, Doha, Qatar.
FAU - Alhuwail, Dari
AU  - Alhuwail D
AUID- ORCID: 0000-0001-5038-3044
AD  - Information Science Department, College of Life Sciences, Kuwait University, 
      Kuwait, Kuwait.
AD  - Health Informatics Unit, Dasman Diabetes Institute, Kuwait, Kuwait.
FAU - Schneider, Jens
AU  - Schneider J
AUID- ORCID: 0000-0002-0546-2816
AD  - Division of Information and Computing Technology, College of Science and 
      Engineering, Hamad Bin Khalifa University, Doha, Qatar.
FAU - AlSaad, Rawan
AU  - AlSaad R
AUID- ORCID: 0000-0002-3235-0860
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
FAU - Ali, Hazrat
AU  - Ali H
AUID- ORCID: 0000-0003-3058-5794
AD  - Faculty of Computing and Information Technology, Sohar University, Sohar, Oman.
FAU - Alomoush, Waleed
AU  - Alomoush W
AUID- ORCID: 0000-0002-2937-4327
AD  - School of Information Technology, Skyline University College, Sharjah, United 
      Arab Emirates.
FAU - Ahmed, Arfan
AU  - Ahmed A
AUID- ORCID: 0000-0002-4025-5767
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
FAU - Aziz, Sarah
AU  - Aziz S
AUID- ORCID: 0000-0002-0861-9743
AD  - AI Center for Precision Health, Weill Cornell Medicine-Qatar, Doha, Qatar.
LA  - eng
PT  - Journal Article
DEP - 20240305
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
PMC - PMC10916961
OTO - NOTNLM
OT  - BERT
OT  - BERTopic
OT  - COVID
OT  - COVID-19
OT  - NLP
OT  - SARS-CoV-2
OT  - coronavirus
OT  - literature review
OT  - machine learning
OT  - natural language processing
OT  - research gap
OT  - research gaps
OT  - research topic
OT  - research topics
OT  - review methodology
OT  - review methods
OT  - scientific literature
OT  - text analysis
OT  - topic clustering
COIS- Conflicts of Interest: None declared.
EDAT- 2024/03/05 12:48
MHDA- 2024/03/05 12:49
PMCR- 2024/03/05
CRDT- 2024/03/05 11:54
PHST- 2023/05/28 00:00 [received]
PHST- 2024/02/06 00:00 [accepted]
PHST- 2023/11/14 00:00 [revised]
PHST- 2024/03/05 12:49 [medline]
PHST- 2024/03/05 12:48 [pubmed]
PHST- 2024/03/05 11:54 [entrez]
PHST- 2024/03/05 00:00 [pmc-release]
AID - v8i1e49411 [pii]
AID - 10.2196/49411 [doi]
PST - epublish
SO  - JMIR Form Res. 2024 Mar 5;8:e49411. doi: 10.2196/49411.

PMID- 30906843
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20200929
IS  - 2352-8273 (Print)
IS  - 2352-8273 (Electronic)
IS  - 2352-8273 (Linking)
VI  - 7
DP  - 2019 Apr
TI  - Malaria, medicines and miles: A novel approach to measuring access to treatment 
      from a household perspective.
PG  - 100376
LID - 10.1016/j.ssmph.2019.100376 [doi]
LID - 100376
AB  - Nearly a decade after the adoption of confirmed diagnosis and artemisinin 
      combination therapy (ACT) for the treatment of uncomplicated falciparum malaria, 
      a large treatment gap persists. We describe a novel approach of combining data 
      from households and the universe of treatment sources in their vicinities to 
      produce nationally representative indicators of physical and financial access to 
      malaria care from the household's perspective in Benin, Nigeria, Uganda and 
      Zambia. We compare differences in access across urban and rural areas, countries, 
      and over time. In 2009, more urban households had a provider stocking ACT within 
      5 km than rural households. By 2012, this physical ACT access gap had largely 
      been closed in Uganda, and progress had been made in Benin and Nigeria; but the 
      gap persisted in Zambia. The private sector helped to fill this gap in rural 
      areas. Improvements in Nigeria and Uganda were driven largely by increased ACT 
      availability in licensed drug stores, and in Benin by increased availability in 
      unregulated open-air market stalls. Free or subsidised ACT from public and 
      non-profit facilities continued to be available to many households by 2012, but 
      much less so in rural areas. Where private sector expansion increased physical 
      access to ACT, these additional options were on average more expensive. Also by 
      2012, the majority of urban households in all four countries had access to a 
      provider nearby offering malaria diagnostic services; however, this access 
      remained low for rural households in Benin, Nigeria and Zambia. The methods 
      developed in this study could improve how access to healthcare is measured in 
      low- and middle-income country settings, particularly where private for-profit 
      providers are an important source of care, and for conditions that may be treated 
      by informal providers. The method could also lead to better explanations of the 
      performance of complex interventions aiming to improve healthcare access.
FAU - Palafox, Benjamin
AU  - Palafox B
AD  - Department of Global Health & Development, London School of Hygiene & Tropical 
      Medicine, 15-17 Tavistock Place, London WC1H 9SH, United Kingdom.
FAU - Goodman, Catherine
AU  - Goodman C
AD  - Department of Global Health & Development, London School of Hygiene & Tropical 
      Medicine, 15-17 Tavistock Place, London WC1H 9SH, United Kingdom.
FAU - Hanson, Kara
AU  - Hanson K
AD  - Department of Global Health & Development, London School of Hygiene & Tropical 
      Medicine, 15-17 Tavistock Place, London WC1H 9SH, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20190306
PL  - England
TA  - SSM Popul Health
JT  - SSM - population health
JID - 101678841
PMC - PMC6411512
OTO - NOTNLM
OT  - ACT, artemisinin combination therapy
OT  - AETD, adult equivalent treatment dose
OT  - AMFm, Affordable Medicines Facility–malaria
OT  - AMT, artemisinin monotherapy
OT  - Access to healthcare
OT  - Antimalarials
OT  - CI, 95% confidence interval
OT  - DHS, Demographic and Health Survey
OT  - Health Equity
OT  - IQR, interquartile range
OT  - Malaria
OT  - PPMV, proprietary patented medicine vendor
OT  - PSU, primary sampling unit
OT  - Population metrics
OT  - Private sector
OT  - Public sector
OT  - RDT, rapid diagnostic test (for malaria)
OT  - USD, United States dollar
OT  - WHO, World Health Organization
OT  - nAT, non-artemisinin therapy
EDAT- 2019/03/25 06:00
MHDA- 2019/03/25 06:01
PMCR- 2019/03/06
CRDT- 2019/03/26 06:00
PHST- 2018/08/17 00:00 [received]
PHST- 2018/10/19 00:00 [revised]
PHST- 2019/02/10 00:00 [accepted]
PHST- 2019/03/26 06:00 [entrez]
PHST- 2019/03/25 06:00 [pubmed]
PHST- 2019/03/25 06:01 [medline]
PHST- 2019/03/06 00:00 [pmc-release]
AID - S2352-8273(18)30176-9 [pii]
AID - 100376 [pii]
AID - 10.1016/j.ssmph.2019.100376 [doi]
PST - epublish
SO  - SSM Popul Health. 2019 Mar 6;7:100376. doi: 10.1016/j.ssmph.2019.100376. 
      eCollection 2019 Apr.

PMID- 31422457
OWN - NLM
STAT- MEDLINE
DCOM- 20200320
LR  - 20200320
IS  - 1432-1459 (Electronic)
IS  - 0340-5354 (Linking)
VI  - 266
IP  - 11
DP  - 2019 Nov
TI  - MRI quality control for the Italian Neuroimaging Network Initiative: moving 
      towards big data in multiple sclerosis.
PG  - 2848-2858
LID - 10.1007/s00415-019-09509-4 [doi]
AB  - The Italian Neuroimaging Network Initiative (INNI) supports the creation of a 
      repository, where MRI, clinical, and neuropsychological data from multiple 
      sclerosis (MS) patients and healthy controls are collected from Italian Research 
      Centers with internationally recognized expertise in MRI applied to MS. However, 
      multicenter MRI data integration needs standardization and quality control (QC). 
      This study aimed to implement quantitative measures for characterizing the 
      standardization and quality of MRI collected within INNI. MRI scans of 423 MS 
      patients, including 3D T(1)- and T(2)-weighted, were obtained from INNI 
      repository (from Centers A, B, C, and D). QC measures were implemented to 
      characterize: (1) head positioning relative to the magnet isocenter; (2) 
      intensity inhomogeneity; (3) relative image contrast between brain tissues; and 
      (4) image artefacts. Centers A and D showed the most accurate subject positioning 
      within the MR scanner (median z-offsets = - 2.6 ± 1.7 cm and - 1.1 ± 2 cm). A 
      low, but significantly different, intensity inhomogeneity on 3D T(1)-weighted MRI 
      was found between all centers (p < 0.05), except for Centers A and C that showed 
      comparable image bias fields. Center D showed the highest relative contrast 
      between gray and normal appearing white matter (NAWM) on 3D T(1)-weighed MRI 
      (0.63 ± 0.04), while Center B showed the highest relative contrast between NAWM 
      and MS lesions on FLAIR (0.21 ± 0.06). Image artefacts were mainly due to brain 
      movement (60%) and ghosting (35%). The implemented QC procedure ensured 
      systematic data quality assessment within INNI, thus making available a huge 
      amount of high-quality MRI to better investigate pathophysiological substrates 
      and validate novel MRI biomarkers in MS.
FAU - Storelli, Loredana
AU  - Storelli L
AD  - Neuroimaging Research Unit, Institute of Experimental Neurology, Division of 
      Neuroscience, IRCCS San Raffaele Scientific Institute, Via Olgettina, 60, 20132, 
      Milan, Italy.
AD  - Vita-Salute San Raffaele University, Milan, Italy.
FAU - Rocca, Maria A
AU  - Rocca MA
AD  - Neuroimaging Research Unit, Institute of Experimental Neurology, Division of 
      Neuroscience, IRCCS San Raffaele Scientific Institute, Via Olgettina, 60, 20132, 
      Milan, Italy.
AD  - Neurology Unit, IRCCS San Raffaele Scientific Institute, Milan, Italy.
FAU - Pantano, Patrizia
AU  - Pantano P
AD  - Department of Human Neurosciences, Sapienza University of Rome, Rome, Italy.
AD  - IRCCS NEUROMED, Pozzilli, Italy.
FAU - Pagani, Elisabetta
AU  - Pagani E
AD  - Neuroimaging Research Unit, Institute of Experimental Neurology, Division of 
      Neuroscience, IRCCS San Raffaele Scientific Institute, Via Olgettina, 60, 20132, 
      Milan, Italy.
FAU - De Stefano, Nicola
AU  - De Stefano N
AD  - Department of Medicine, Surgery and Neuroscience, University of Siena, Siena, 
      Italy.
FAU - Tedeschi, Gioacchino
AU  - Tedeschi G
AD  - Department of Medical, Surgical, Neurological Metabolic and Aging Sciences and 
      MRI-Center "SUN-FISM", University of Campania "Luigi Vanvitelli", Naples, Italy.
FAU - Zaratin, Paola
AU  - Zaratin P
AD  - Italian Multiple Sclerosis Foundation, Genoa, Italy.
FAU - Filippi, Massimo
AU  - Filippi M
AUID- ORCID: 0000-0002-5485-0479
AD  - Neuroimaging Research Unit, Institute of Experimental Neurology, Division of 
      Neuroscience, IRCCS San Raffaele Scientific Institute, Via Olgettina, 60, 20132, 
      Milan, Italy. filippi.massimo@hsr.it.
AD  - Vita-Salute San Raffaele University, Milan, Italy. filippi.massimo@hsr.it.
AD  - Neurology Unit, IRCCS San Raffaele Scientific Institute, Milan, Italy. 
      filippi.massimo@hsr.it.
CN  - INNI Network
LA  - eng
GR  - FISM2018/S/3/Fondazione Italiana Sclerosi Multipla/
PT  - Journal Article
DEP - 20190817
PL  - Germany
TA  - J Neurol
JT  - Journal of neurology
JID - 0423161
SB  - IM
MH  - Adult
MH  - Big Data
MH  - Datasets as Topic/*standards
MH  - Female
MH  - Humans
MH  - Italy
MH  - Magnetic Resonance Imaging/*standards
MH  - Male
MH  - Middle Aged
MH  - Multiple Sclerosis/*diagnostic imaging
MH  - Neuroimaging/*standards
MH  - *Quality Control
OTO - NOTNLM
OT  - Big data
OT  - Italian Neuroimaging Network Initiative (INNI)
OT  - Magnetic resonance imaging (MRI)
OT  - Multiple sclerosis (MS)
FIR - Valsasina, Paola
IR  - Valsasina P
FIR - Sibilia, Mauro
IR  - Sibilia M
FIR - Preziosa, Paolo
IR  - Preziosa P
FIR - Gallo, Antonio
IR  - Gallo A
FIR - Bisecco, Alvino
IR  - Bisecco A
FIR - Docimo, Renato
IR  - Docimo R
FIR - Petsas, Nikolaos
IR  - Petsas N
FIR - Ruggieri, Serena
IR  - Ruggieri S
FIR - Tommasin, Silvia
IR  - Tommasin S
FIR - Stromillo, Maria Laura
IR  - Stromillo ML
FIR - Brocci, Riccardo Tappa
IR  - Brocci RT
EDAT- 2019/08/20 06:00
MHDA- 2020/03/21 06:00
CRDT- 2019/08/19 06:00
PHST- 2019/06/26 00:00 [received]
PHST- 2019/08/13 00:00 [accepted]
PHST- 2019/08/12 00:00 [revised]
PHST- 2019/08/20 06:00 [pubmed]
PHST- 2020/03/21 06:00 [medline]
PHST- 2019/08/19 06:00 [entrez]
AID - 10.1007/s00415-019-09509-4 [pii]
AID - 10.1007/s00415-019-09509-4 [doi]
PST - ppublish
SO  - J Neurol. 2019 Nov;266(11):2848-2858. doi: 10.1007/s00415-019-09509-4. Epub 2019 
      Aug 17.

PMID- 38593424
OWN - NLM
STAT- MEDLINE
DCOM- 20240411
LR  - 20241208
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 11
DP  - 2024 Apr 9
TI  - Assessing the Alignment of Large Language Models With Human Values for Mental 
      Health Integration: Cross-Sectional Study Using Schwartz's Theory of Basic 
      Values.
PG  - e55988
LID - 10.2196/55988 [doi]
LID - e55988
AB  - BACKGROUND: Large language models (LLMs) hold potential for mental health 
      applications. However, their opaque alignment processes may embed biases that 
      shape problematic perspectives. Evaluating the values embedded within LLMs that 
      guide their decision-making have ethical importance. Schwartz's theory of basic 
      values (STBV) provides a framework for quantifying cultural value orientations 
      and has shown utility for examining values in mental health contexts, including 
      cultural, diagnostic, and therapist-client dynamics. OBJECTIVE: This study aimed 
      to (1) evaluate whether the STBV can measure value-like constructs within leading 
      LLMs and (2) determine whether LLMs exhibit distinct value-like patterns from 
      humans and each other. METHODS: In total, 4 LLMs (Bard, Claude 2, Generative 
      Pretrained Transformer [GPT]-3.5, GPT-4) were anthropomorphized and instructed to 
      complete the Portrait Values Questionnaire-Revised (PVQ-RR) to assess value-like 
      constructs. Their responses over 10 trials were analyzed for reliability and 
      validity. To benchmark the LLMs' value profiles, their results were compared to 
      published data from a diverse sample of 53,472 individuals across 49 nations who 
      had completed the PVQ-RR. This allowed us to assess whether the LLMs diverged 
      from established human value patterns across cultural groups. Value profiles were 
      also compared between models via statistical tests. RESULTS: The PVQ-RR showed 
      good reliability and validity for quantifying value-like infrastructure within 
      the LLMs. However, substantial divergence emerged between the LLMs' value 
      profiles and population data. The models lacked consensus and exhibited distinct 
      motivational biases, reflecting opaque alignment processes. For example, all 
      models prioritized universalism and self-direction, while de-emphasizing 
      achievement, power, and security relative to humans. Successful discriminant 
      analysis differentiated the 4 LLMs' distinct value profiles. Further examination 
      found the biased value profiles strongly predicted the LLMs' responses when 
      presented with mental health dilemmas requiring choosing between opposing values. 
      This provided further validation for the models embedding distinct motivational 
      value-like constructs that shape their decision-making. CONCLUSIONS: This study 
      leveraged the STBV to map the motivational value-like infrastructure underpinning 
      leading LLMs. Although the study demonstrated the STBV can effectively 
      characterize value-like infrastructure within LLMs, substantial divergence from 
      human values raises ethical concerns about aligning these models with mental 
      health applications. The biases toward certain cultural value sets pose risks if 
      integrated without proper safeguards. For example, prioritizing universalism 
      could promote unconditional acceptance even when clinically unwise. Furthermore, 
      the differences between the LLMs underscore the need to standardize alignment 
      processes to capture true cultural diversity. Thus, any responsible integration 
      of LLMs into mental health care must account for their embedded biases and 
      motivation mismatches to ensure equitable delivery across diverse populations. 
      Achieving this will require transparency and refinement of alignment techniques 
      to instill comprehensive human values.
CI  - ©Dorit Hadar-Shoval, Kfir Asraf, Yonathan Mizrachi, Yuval Haber, Zohar Elyoseph. 
      Originally published in JMIR Mental Health (https://mental.jmir.org), 09.04.2024.
FAU - Hadar-Shoval, Dorit
AU  - Hadar-Shoval D
AUID- ORCID: 0000-0002-1376-3096
AD  - The Psychology Department, Max Stern Yezreel Valley College, Tel Adashim, Israel.
FAU - Asraf, Kfir
AU  - Asraf K
AUID- ORCID: 0009-0001-6699-3055
AD  - The Psychology Department, Max Stern Yezreel Valley College, Tel Adashim, Israel.
FAU - Mizrachi, Yonathan
AU  - Mizrachi Y
AUID- ORCID: 0000-0002-9161-1311
AD  - The Jane Goodall Institute, Max Stern Yezreel Valley College, Tel Adashim, 
      Israel.
AD  - The Laboratory for AI, Machine Learning, Business & Data Analytics, Tel-Aviv 
      University, Tel Aviv, Israel.
FAU - Haber, Yuval
AU  - Haber Y
AUID- ORCID: 0000-0003-4933-2113
AD  - The PhD Program of Hermeneutics and Cultural Studies, Interdisciplinary Studies 
      Unit, Bar-Ilan University, Ramat Gan, Israel.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AUID- ORCID: 0000-0002-5717-4074
AD  - The Psychology Department, Center for Psychobiological Research, Max Stern 
      Yezreel Valley College, Tel Adashim, Israel.
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, 
      London, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20240409
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Mental Health
MH  - Reproducibility of Results
MH  - *Allied Health Personnel
MH  - Language
PMC - PMC11040439
OTO - NOTNLM
OT  - AI
OT  - Bard
OT  - Chat-GPT
OT  - ChatGPT
OT  - Claude
OT  - LLM
OT  - LLMs
OT  - ML
OT  - NLP
OT  - algorithm
OT  - algorithms
OT  - artificial intelligence
OT  - chat-bot
OT  - chat-bots
OT  - chatbot
OT  - chatbots
OT  - deep learning
OT  - eHealth
OT  - large language model
OT  - large language models
OT  - mHealth
OT  - machine learning
OT  - mental disease
OT  - mental diseases
OT  - mental disorder
OT  - mental disorders
OT  - mental health
OT  - mental illness
OT  - mental illnesses
OT  - mobile health
OT  - mood disorder
OT  - mood disorders
OT  - natural language processing
OT  - practical model
OT  - practical models
OT  - predictive analytics
OT  - predictive model
OT  - predictive models
OT  - predictive system
OT  - values
COIS- Conflicts of Interest: None declared.
EDAT- 2024/04/09 18:42
MHDA- 2024/04/11 06:43
PMCR- 2024/04/09
CRDT- 2024/04/09 16:53
PHST- 2024/01/02 00:00 [received]
PHST- 2024/03/08 00:00 [accepted]
PHST- 2024/03/01 00:00 [revised]
PHST- 2024/04/11 06:43 [medline]
PHST- 2024/04/09 18:42 [pubmed]
PHST- 2024/04/09 16:53 [entrez]
PHST- 2024/04/09 00:00 [pmc-release]
AID - v11i1e55988 [pii]
AID - 10.2196/55988 [doi]
PST - epublish
SO  - JMIR Ment Health. 2024 Apr 9;11:e55988. doi: 10.2196/55988.

PMID- 38659656
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240426
IS  - 2673-253X (Electronic)
IS  - 2673-253X (Linking)
VI  - 6
DP  - 2024
TI  - Empowering inclusivity: improving readability of living kidney donation 
      information with ChatGPT.
PG  - 1366967
LID - 10.3389/fdgth.2024.1366967 [doi]
LID - 1366967
AB  - BACKGROUND: Addressing disparities in living kidney donation requires making 
      information accessible across literacy levels, especially important given that 
      the average American adult reads at an 8th-grade level. This study evaluated the 
      effectiveness of ChatGPT, an advanced AI language model, in simplifying living 
      kidney donation information to an 8th-grade reading level or below. METHODS: We 
      used ChatGPT versions 3.5 and 4.0 to modify 27 questions and answers from Donate 
      Life America, a key resource on living kidney donation. We measured the 
      readability of both original and modified texts using the Flesch-Kincaid formula. 
      A paired t-test was conducted to assess changes in readability levels, and a 
      statistical comparison between the two ChatGPT versions was performed. RESULTS: 
      Originally, the FAQs had an average reading level of 9.6 ± 1.9. 
      Post-modification, ChatGPT 3.5 achieved an average readability level of 
      7.72 ± 1.85, while ChatGPT 4.0 reached 4.30 ± 1.71, both with a p-value <0.001 
      indicating significant reduction. ChatGPT 3.5 made 59.26% of answers readable 
      below 8th-grade level, whereas ChatGPT 4.0 did so for 96.30% of the texts. The 
      grade level range for modified answers was 3.4-11.3 for ChatGPT 3.5 and 1-8.1 for 
      ChatGPT 4.0. CONCLUSION: Both ChatGPT 3.5 and 4.0 effectively lowered the 
      readability grade levels of complex medical information, with ChatGPT 4.0 being 
      more effective. This suggests ChatGPT's potential role in promoting diversity and 
      equity in living kidney donation, indicating scope for further refinement in 
      making medical information more accessible.
CI  - © 2024 Garcia Valencia, Thongprayoon, Miao, Suppadungsuk, Krisanapan, Craici, 
      Jadlowiec, Mao, Mao, Leeaphorn, Budhiraja and Cheungpasitporn.
FAU - Garcia Valencia, Oscar A
AU  - Garcia Valencia OA
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Miao, Jing
AU  - Miao J
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Suppadungsuk, Supawadee
AU  - Suppadungsuk S
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Samut Prakan, Thailand.
FAU - Krisanapan, Pajaree
AU  - Krisanapan P
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
AD  - Division of Nephrology, Department of Internal Medicine, Faculty of Medicine, 
      Thammasat University, Pathum Thani, Thailand.
AD  - Division of Nephrology, Department of Internal Medicine, Thammasat University 
      Hospital, Pathum Thani, Thailand.
FAU - Craici, Iasmina M
AU  - Craici IM
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
FAU - Jadlowiec, Caroline C
AU  - Jadlowiec CC
AD  - Division of Transplant Surgery, Department of Surgery, Mayo Clinic, Phoenix, AZ, 
      United States.
FAU - Mao, Shennen A
AU  - Mao SA
AD  - Division of Transplant Surgery, Department of Transplant, Mayo Clinic, 
      Jacksonville, FL, United States.
FAU - Mao, Michael A
AU  - Mao MA
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Jacksonville, FL, United States.
FAU - Leeaphorn, Napat
AU  - Leeaphorn N
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Jacksonville, FL, United States.
FAU - Budhiraja, Pooja
AU  - Budhiraja P
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Phoenix, AZ, United States.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, United States.
LA  - eng
PT  - Journal Article
DEP - 20240410
PL  - Switzerland
TA  - Front Digit Health
JT  - Frontiers in digital health
JID - 101771889
PMC - PMC11039889
OTO - NOTNLM
OT  - ChatGPT
OT  - disparity
OT  - health literacy
OT  - inclusivity
OT  - living kidney donation
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2024/04/25 06:48
MHDA- 2024/04/25 06:49
PMCR- 2024/04/10
CRDT- 2024/04/25 03:51
PHST- 2024/01/08 00:00 [received]
PHST- 2024/04/01 00:00 [accepted]
PHST- 2024/04/25 06:49 [medline]
PHST- 2024/04/25 06:48 [pubmed]
PHST- 2024/04/25 03:51 [entrez]
PHST- 2024/04/10 00:00 [pmc-release]
AID - 10.3389/fdgth.2024.1366967 [doi]
PST - epublish
SO  - Front Digit Health. 2024 Apr 10;6:1366967. doi: 10.3389/fdgth.2024.1366967. 
      eCollection 2024.

PMID- 38081564
OWN - NLM
STAT- MEDLINE
DCOM- 20240122
LR  - 20240426
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Print)
IS  - 1532-0464 (Linking)
VI  - 149
DP  - 2024 Jan
TI  - Enhanced family history-based algorithms increase the identification of 
      individuals meeting criteria for genetic testing of hereditary cancer syndromes 
      but would not reduce disparities on their own.
PG  - 104568
LID - S1532-0464(23)00289-7 [pii]
LID - 10.1016/j.jbi.2023.104568 [doi]
AB  - OBJECTIVE: This study aimed to 1) investigate algorithm enhancements for 
      identifying patients eligible for genetic testing of hereditary cancer syndromes 
      using family history data from electronic health records (EHRs); and 2) assess 
      their impact on relative differences across sex, race, ethnicity, and language 
      preference. MATERIALS AND METHODS: The study used EHR data from a tertiary 
      academic medical center. A baseline rule-base algorithm, relying on structured 
      family history data (structured data; SD), was enhanced using a natural language 
      processing (NLP) component and a relaxed criteria algorithm (partial match [PM]). 
      The identification rates and differences were analyzed considering sex, race, 
      ethnicity, and language preference. RESULTS: Among 120,007 patients aged 25-60, 
      detection rate differences were found across all groups using the SD (all 
      P < 0.001). Both enhancements increased identification rates; NLP led to a 1.9 % 
      increase and the relaxed criteria algorithm (PM) led to an 18.5 % increase (both 
      P < 0.001). Combining SD with NLP and PM yielded a 20.4 % increase (P < 0.001). 
      Similar increases were observed within subgroups. Relative differences persisted 
      across most categories for the enhanced algorithms, with disproportionately 
      higher identification of patients who are White, Female, non-Hispanic, and whose 
      preferred language is English. CONCLUSION: Algorithm enhancements increased 
      identification rates for patients eligible for genetic testing of hereditary 
      cancer syndromes, regardless of sex, race, ethnicity, and language preference. 
      However, differences in identification rates persisted, emphasizing the need for 
      additional strategies to reduce disparities such as addressing underlying biases 
      in EHR family health information and selectively applying algorithm enhancements 
      for disadvantaged populations. Systematic assessment of differences in algorithm 
      performance across population subgroups should be incorporated into algorithm 
      development processes.
CI  - Copyright © 2023 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Bradshaw, Richard L
AU  - Bradshaw RL
AD  - Department of Biomedical Informatics, University of Utah, Salt Lake City, UT, 
      USA; University of Utah Health, Salt Lake City, UT, USA.
FAU - Kawamoto, Kensaku
AU  - Kawamoto K
AD  - Department of Biomedical Informatics, University of Utah, Salt Lake City, UT, 
      USA; University of Utah Health, Salt Lake City, UT, USA.
FAU - Bather, Jemar R
AU  - Bather JR
AD  - Department of Biostatistics, New York University School of Global Public Health, 
      New York, NY, USA; Center for Anti-racism, Social Justice, & Public Health, New 
      York University School of Global Public Health, New York, NY, USA.
FAU - Goodman, Melody S
AU  - Goodman MS
AD  - Department of Biostatistics, New York University School of Global Public Health, 
      New York, NY, USA; Center for Anti-racism, Social Justice, & Public Health, New 
      York University School of Global Public Health, New York, NY, USA.
FAU - Kohlmann, Wendy K
AU  - Kohlmann WK
AD  - University of Utah Health, Salt Lake City, UT, USA; Department of Population 
      Health Sciences, University of Utah, Salt Lake City, UT, USA; Huntsman Cancer 
      Institute, University of Utah, Salt Lake City, UT, USA.
FAU - Chavez-Yenter, Daniel
AU  - Chavez-Yenter D
AD  - Huntsman Cancer Institute, University of Utah, Salt Lake City, UT, USA; 
      Department of Communication, University of Utah, Salt Lake City, UT, USA.
FAU - Volkmar, Molly
AU  - Volkmar M
AD  - Huntsman Cancer Institute, University of Utah, Salt Lake City, UT, USA.
FAU - Monahan, Rachel
AU  - Monahan R
AD  - New York University Langone Health, New York, NY, USA.
FAU - Kaphingst, Kimberly A
AU  - Kaphingst KA
AD  - Huntsman Cancer Institute, University of Utah, Salt Lake City, UT, USA; 
      Department of Communication, University of Utah, Salt Lake City, UT, USA.
FAU - Del Fiol, Guilherme
AU  - Del Fiol G
AD  - Department of Biomedical Informatics, University of Utah, Salt Lake City, UT, 
      USA; University of Utah Health, Salt Lake City, UT, USA. Electronic address: 
      guilherme.delfiol@utah.edu.
LA  - eng
GR  - U01 CA232826/CA/NCI NIH HHS/United States
GR  - U24 CA204800/CA/NCI NIH HHS/United States
GR  - U24 CA274582/CA/NCI NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20231209
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Humans
MH  - Female
MH  - *Algorithms
MH  - Genetic Testing
MH  - Electronic Health Records
MH  - Natural Language Processing
MH  - *Neoplastic Syndromes, Hereditary
PMC - PMC10842777
MID - NIHMS1952531
OTO - NOTNLM
OT  - Algorithm development
OT  - Electronic health records
OT  - Genetic testing
OT  - Healthcare disparities
OT  - Hereditary cancer syndromes
COIS- Declaration of competing interest The authors declare the following financial 
      interests/personal relationships which may be considered as potential competing 
      interests: [Guilherme Del Fiol reports financial support was provided by National 
      Institutes of Health. Guilherme Del Fiol is an editorial board member of the 
      Journal of Biomedical Informatics. Kensaku Kawamoto has received consulting 
      honoraries from Pfizer, RTI International, University of California at San 
      Francisco, Indiana University, Korean Society of Medical Informatics, NORC at 
      University of Chicago, Regenstrief Foundation, University of Pennsylvania, Yale 
      University, and Security Risk Solutions].
EDAT- 2023/12/12 00:42
MHDA- 2024/01/22 06:42
PMCR- 2024/02/05
CRDT- 2023/12/11 19:27
PHST- 2023/09/21 00:00 [received]
PHST- 2023/11/07 00:00 [revised]
PHST- 2023/12/07 00:00 [accepted]
PHST- 2024/01/22 06:42 [medline]
PHST- 2023/12/12 00:42 [pubmed]
PHST- 2023/12/11 19:27 [entrez]
PHST- 2024/02/05 00:00 [pmc-release]
AID - S1532-0464(23)00289-7 [pii]
AID - 10.1016/j.jbi.2023.104568 [doi]
PST - ppublish
SO  - J Biomed Inform. 2024 Jan;149:104568. doi: 10.1016/j.jbi.2023.104568. Epub 2023 
      Dec 9.

PMID- 39854611
OWN - NLM
STAT- Publisher
LR  - 20250124
IS  - 1438-8871 (Electronic)
IS  - 1438-8871 (Linking)
DP  - 2025 Jan 13
TI  - Virtual patients using large language models: Scalable, contextualized simulation 
      of clinician-patient dialog with feedback.
LID - 10.2196/68486 [doi]
AB  - BACKGROUND: Virtual patients (VPs) are computer screen-based simulations of 
      patient-clinician encounters. VP use is limited by cost and low scalability. 
      OBJECTIVE: Show proof-of-concept that VPs powered by large language models (LLMs) 
      generate authentic dialogs, accurate representations of patient preferences, and 
      personalized feedback on clinical performance; and explore LLMs for rating dialog 
      and feedback quality. METHODS: We conducted an intrinsic evaluation study rating 
      60 VP-clinician conversations. We used carefully engineered prompts to direct the 
      OpenAI Generative Pre-trained Transformer (GPT) to emulate a patient and provide 
      feedback. Using 2 outpatient medicine topics (chronic cough [diagnosis] and 
      diabetes [management]), each with permutations representing different patient 
      preferences, we created 60 conversations (dialogs plus feedback): 48 with a human 
      clinician, and 12 "self-chat" dialogs with GPT role-playing both the VP and 
      clinician. Primary outcomes were dialog authenticity and feedback quality, rated 
      using novel instruments for which we conducted a validation study collecting 
      evidence of content, internal structure (reproducibility), relations with other 
      variables, and response process. Each conversation was rated by 3 physicians and 
      also by GPT. Secondary outcomes included user experience, bias, patient 
      preferences represented in the dialogs, conversation features that detracted from 
      or enhanced authenticity, and cost. RESULTS: The average cost per conversation 
      was $0.51 for GPT-4.0-turbo and $0.02 for GPT-3.5-turbo. Conversation ratings 
      (maximum 6) were mean (SD) overall dialog authenticity 4.7 (0.7); overall user 
      experience 4.9 (0.7); and average feedback quality 4.7 (0.6). For dialogs created 
      using GPT-4.0-turbo, physician ratings of patient preferences aligned with 
      intended preferences in 20-47 of 48 dialogs (42-98%). Subgroup comparisons 
      revealed higher ratings for dialogs using GPT-4.0-turbo vs GPT-3.5-turbo, and for 
      human-generated vs self-chat dialogs. Feedback ratings were similar for 
      human-generated vs GPT-generated ratings, whereas authenticity ratings were 
      significantly lower. We did not perceive significant bias in any conversation. 
      Dialog features that detracted from authenticity included: GPT was verbose or 
      used atypical vocabulary (52% of conversations), was overly agreeable (31%), 
      repeated the question as part of the response (26%), was easily convinced by 
      clinician suggestions (19%), or was not disaffected by poor clinician performance 
      (18%). For feedback, detractors included: excessively positive feedback (23%), 
      failure to mention an important weakness or strength (23%), or factual 
      inaccuracies (22%). Regarding validation of dialog and feedback scores: Items 
      were meticulously developed (content evidence), and we confirmed expected 
      relations with other variables (higher ratings for advanced LLM models and 
      human-generated dialogs). Reproducibility (internal structure) was suboptimal, 
      due largely to variation in LLM performance rather than rater idiosyncrasies. 
      CONCLUSIONS: LLM-powered VPs can simulate patient-clinician dialogs, demonstrably 
      represent patient preferences, and provide personalized performance feedback. 
      This approach is scalable, globally-accessible, and inexpensive. LLM-generated 
      ratings of feedback quality are similar to human ratings. Our novel instruments 
      measuring dialog authenticity and feedback quality warrant further study.
FAU - Cook, David A
AU  - Cook DA
AD  - Division of General Internal Medicine, Mayo Clinic College of Medicine and 
      Science, 200 First St SW, Rochester, US.
AD  - Multidisciplinary Simulation Center, Mayo Clinic College of Medicine and Science, 
      Rochester, US.
FAU - Overgaard, Joshua
AU  - Overgaard J
AD  - Division of General Internal Medicine, Mayo Clinic College of Medicine and 
      Science, 200 First St SW, Rochester, US.
FAU - Pankratz, V Shane
AU  - Pankratz VS
AD  - Health Sciences Center, University of New Mexico, Albuquerque, US.
FAU - Del Fiol, Guilherme
AU  - Del Fiol G
AD  - Department of Biomedical Informatics, University of Utah School of Medicine, Salt 
      Lake City, US.
FAU - Aakre, Chris A
AU  - Aakre CA
AD  - Division of General Internal Medicine, Mayo Clinic College of Medicine and 
      Science, 200 First St SW, Rochester, US.
LA  - eng
PT  - Journal Article
DEP - 20250113
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
EDAT- 2025/01/24 18:25
MHDA- 2025/01/24 18:25
CRDT- 2025/01/24 14:32
PHST- 2025/01/24 18:25 [medline]
PHST- 2025/01/24 18:25 [pubmed]
PHST- 2025/01/24 14:32 [entrez]
AID - 10.2196/68486 [doi]
PST - aheadofprint
SO  - J Med Internet Res. 2025 Jan 13. doi: 10.2196/68486.

PMID- 31552408
OWN - NLM
STAT- MEDLINE
DCOM- 20200824
LR  - 20200824
IS  - 1524-4040 (Electronic)
IS  - 0148-396X (Linking)
VI  - 86
IP  - 1
DP  - 2020 Jan 1
TI  - Interrater and Intrarater Reliability of the Colloid Cyst Risk Score.
PG  - E47-E53
LID - 10.1093/neuros/nyz399 [doi]
AB  - BACKGROUND: The Colloid Cyst Risk Score (CCRS) was developed to identify 
      symptomatic patients and stratify risk of hydrocephalus among patients with 
      colloid cysts. Its components consider patient age, cyst diameter, 
      presence/absence of headache, fluid-attenuated inversion recovery (FLAIR) 
      hyperintensity, and location within the third ventricle. OBJECTIVE: To 
      independently evaluate the inter- and intrarater reliability of the CCRS. 
      METHODS: Patients with a colloid cyst were identified from billing records and 
      radiology archives. Three independent raters reviewed electronic medical records 
      to determine age, presence/absence of headache, cyst diameter (mm), FLAIR 
      hyperintensity, and risk zone location. Raters made 53 observations, including 5 
      repeat observations.Fleiss' generalized kappa (κ) was calculated for all of the 
      nominal criteria, whereas Kendall's coefficient of concordance (W) and the 
      intraclass correlation coefficient (ICC) were calculated for the overall score. 
      RESULTS: Total CCRS score demonstrated extremely strong agreement (W = 0.83) 
      using Kendall's W coefficient and good agreement (ICC = 0.74) using the ICC 
      (P < .001). For interrater reliability of individual criteria, age (κ = 1.00) and 
      FLAIR hyperintensity (κ = 0.89) demonstrated near perfect agreement. Axial 
      diameter (κ = 0.63) demonstrated substantial agreement, whereas agreement was 
      moderate for risk zone (κ = 0.51) and fair for headache (κ = 0.26). Intrarater 
      reliability for total CCRS score was extremely strong using Kendall's W, good to 
      excellent using ICC, and fair to substantial using weighted kappa. CONCLUSION: 
      The CCRS has good inter- and intrarater reliability when tested in an independent 
      sample of patients, though strength of agreement varies among individual 
      criteria. The validity of the CCRS requires independent evaluation.
CI  - Copyright © 2019 by the Congress of Neurological Surgeons.
FAU - Alford, Elizabeth N
AU  - Alford EN
AD  - Department of Neurosurgery, University of Alabama at Birmingham, Birmingham, 
      Alabama.
FAU - Rotman, Lauren E
AU  - Rotman LE
AD  - Department of Neurosurgery, University of Alabama at Birmingham, Birmingham, 
      Alabama.
FAU - Lepard, Jacob R
AU  - Lepard JR
AD  - Department of Neurosurgery, University of Alabama at Birmingham, Birmingham, 
      Alabama.
FAU - Agee, Bonita S
AU  - Agee BS
AD  - Department of Neurosurgery, University of Alabama at Birmingham, Birmingham, 
      Alabama.
FAU - Markert, James M
AU  - Markert JM
AD  - Department of Neurosurgery, University of Alabama at Birmingham, Birmingham, 
      Alabama.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Neurosurgery
JT  - Neurosurgery
JID - 7802914
SB  - IM
MH  - Adult
MH  - Age Factors
MH  - Aged
MH  - Colloid Cysts/*complications/pathology
MH  - Female
MH  - Headache/etiology
MH  - Humans
MH  - Hydrocephalus/epidemiology/*etiology
MH  - Magnetic Resonance Imaging
MH  - Male
MH  - Middle Aged
MH  - Observer Variation
MH  - Reproducibility of Results
MH  - Risk Factors
MH  - Third Ventricle/pathology
OTO - NOTNLM
OT  - Colloid cyst
OT  - Hydrocephalus
OT  - Interrater reliability
OT  - Intrarater reliability
EDAT- 2019/09/26 06:00
MHDA- 2020/08/25 06:00
CRDT- 2019/09/26 06:00
PHST- 2018/12/13 00:00 [received]
PHST- 2019/07/05 00:00 [accepted]
PHST- 2019/09/26 06:00 [pubmed]
PHST- 2020/08/25 06:00 [medline]
PHST- 2019/09/26 06:00 [entrez]
AID - 5573391 [pii]
AID - 10.1093/neuros/nyz399 [doi]
PST - ppublish
SO  - Neurosurgery. 2020 Jan 1;86(1):E47-E53. doi: 10.1093/neuros/nyz399.

PMID- 34823030
OWN - NLM
STAT- MEDLINE
DCOM- 20220202
LR  - 20240831
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Print)
IS  - 1532-0464 (Linking)
VI  - 125
DP  - 2022 Jan
TI  - Class imbalance in out-of-distribution datasets: Improving the robustness of the 
      TextCNN for the classification of rare cancer types.
PG  - 103957
LID - S1532-0464(21)00286-0 [pii]
LID - 10.1016/j.jbi.2021.103957 [doi]
AB  - In the last decade, the widespread adoption of electronic health record 
      documentation has created huge opportunities for information mining. Natural 
      language processing (NLP) techniques using machine and deep learning are becoming 
      increasingly widespread for information extraction tasks from unstructured 
      clinical notes. Disparities in performance when deploying machine learning models 
      in the real world have recently received considerable attention. In the clinical 
      NLP domain, the robustness of convolutional neural networks (CNNs) for 
      classifying cancer pathology reports under natural distribution shifts remains 
      understudied. In this research, we aim to quantify and improve the performance of 
      the CNN for text classification on out-of-distribution (OOD) datasets resulting 
      from the natural evolution of clinical text in pathology reports. We identified 
      class imbalance due to different prevalence of cancer types as one of the sources 
      of performance drop and analyzed the impact of previous methods for addressing 
      class imbalance when deploying models in real-world domains. Our results show 
      that our novel class-specialized ensemble technique outperforms other methods for 
      the classification of rare cancer types in terms of macro F1 scores. We also 
      found that traditional ensemble methods perform better in top classes, leading to 
      higher micro F1 scores. Based on our findings, we formulate a series of 
      recommendations for other ML practitioners on how to build robust models with 
      extremely imbalanced datasets in biomedical NLP applications.
CI  - Copyright © 2021. Published by Elsevier Inc.
FAU - De Angeli, Kevin
AU  - De Angeli K
AD  - Oak Ridge National Laboratory, 1 Bethel Valley Rd, Oak Ridge, TN 37830, USA; The 
      Bredesen Center, The University of Tennessee, 821 Volunteer Blvd. Knoxville, TN 
      37996, USA. Electronic address: kevindeangeli94@gmail.com.
FAU - Gao, Shang
AU  - Gao S
AD  - Oak Ridge National Laboratory, 1 Bethel Valley Rd, Oak Ridge, TN 37830, USA.
FAU - Danciu, Ioana
AU  - Danciu I
AD  - Oak Ridge National Laboratory, 1 Bethel Valley Rd, Oak Ridge, TN 37830, USA; 
      Department of Biomedical Informatics, Vanderbilt University, 2525 West End 
      Avenue, Nashville, TN 37203, USA.
FAU - Durbin, Eric B
AU  - Durbin EB
AD  - College of Medicine, University of Kentucky, Lexington, KY 40536, USA.
FAU - Wu, Xiao-Cheng
AU  - Wu XC
AD  - Louisiana State University Health Sciences Center, School of Public Health, New 
      Orleans, LA 70112, USA.
FAU - Stroup, Antoinette
AU  - Stroup A
AD  - Rutgers Cancer Institute of New Jersey, New Brunswick, NJ, 08901, USA.
FAU - Doherty, Jennifer
AU  - Doherty J
AD  - Huntsman Cancer Institute, University of Utah, Salt Lake City, UT 84132, USA.
FAU - Schwartz, Stephen
AU  - Schwartz S
AD  - Fred Hutchinson Cancer Research Center, Epidemiology Program, Seattle, WA 98109, 
      USA.
FAU - Wiggins, Charles
AU  - Wiggins C
AD  - University of New Mexico, Albuquerque, NM 87131, USA.
FAU - Damesyn, Mark
AU  - Damesyn M
AD  - California Department of Public Health, Sacramento, CA 59814, USA.
FAU - Coyle, Linda
AU  - Coyle L
AD  - Information Management Services Inc., Calverton, MD 20705, USA.
FAU - Penberthy, Lynne
AU  - Penberthy L
AD  - National Cancer Institute, Bethesda, MD 20814, USA.
FAU - Tourassi, Georgia D
AU  - Tourassi GD
AD  - Oak Ridge National Laboratory, 1 Bethel Valley Rd, Oak Ridge, TN 37830, USA.
FAU - Yoon, Hong-Jun
AU  - Yoon HJ
AD  - Oak Ridge National Laboratory, 1 Bethel Valley Rd, Oak Ridge, TN 37830, USA.
LA  - eng
GR  - HHSN261201800032C/CA/NCI NIH HHS/United States
GR  - HHSN261201800009C/CA/NCI NIH HHS/United States
GR  - NU58DP006344/DP/NCCDPHP CDC HHS/United States
GR  - HHSN261201800015I/CA/NCI NIH HHS/United States
GR  - HHSN261201800013C/CA/NCI NIH HHS/United States
GR  - HHSN261201800016I/CA/NCI NIH HHS/United States
GR  - HHSN261201800014I/CA/NCI NIH HHS/United States
GR  - HHSN261201800032I/CA/NCI NIH HHS/United States
GR  - HHSN261201800013I/HL/NHLBI NIH HHS/United States
GR  - U58 DP003907/DP/NCCDPHP CDC HHS/United States
GR  - HHSN261201800015C/CA/NCI NIH HHS/United States
GR  - HHSN261201800013I/CA/NCI NIH HHS/United States
GR  - HHSN261201800014C/CA/NCI NIH HHS/United States
GR  - HHSN261201800016C/CA/NCI NIH HHS/United States
GR  - P30 CA177558/CA/NCI NIH HHS/United States
GR  - HHSN261201300021C/CA/NCI NIH HHS/United States
GR  - HHSN261201800009I/CA/NCI NIH HHS/United States
GR  - HHSN261201800007C/CA/NCI NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
PT  - Research Support, U.S. Gov't, Non-P.H.S.
PT  - Research Support, U.S. Gov't, P.H.S.
DEP - 20211122
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - Electronic Health Records
MH  - Humans
MH  - Machine Learning
MH  - *Natural Language Processing
MH  - *Neoplasms
MH  - Neural Networks, Computer
PMC - PMC9274264
MID - NIHMS1819342
OTO - NOTNLM
OT  - CNN
OT  - Class Imbalance
OT  - Deep Learning
OT  - Ensemble
OT  - NLP
OT  - Text Classification
EDAT- 2021/11/26 06:00
MHDA- 2022/02/03 06:00
PMCR- 2023/01/01
CRDT- 2021/11/25 20:13
PHST- 2021/06/30 00:00 [received]
PHST- 2021/11/04 00:00 [revised]
PHST- 2021/11/17 00:00 [accepted]
PHST- 2021/11/26 06:00 [pubmed]
PHST- 2022/02/03 06:00 [medline]
PHST- 2021/11/25 20:13 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - S1532-0464(21)00286-0 [pii]
AID - 10.1016/j.jbi.2021.103957 [doi]
PST - ppublish
SO  - J Biomed Inform. 2022 Jan;125:103957. doi: 10.1016/j.jbi.2021.103957. Epub 2021 
      Nov 22.

PMID- 38350517
OWN - NLM
STAT- MEDLINE
DCOM- 20240728
LR  - 20240728
IS  - 1532-8406 (Electronic)
IS  - 0883-5403 (Linking)
VI  - 39
IP  - 8S1
DP  - 2024 Aug
TI  - An Artificial Intelligence Chatbot is an Accurate and Useful Online Patient 
      Resource Prior to Total Knee Arthroplasty.
PG  - S358-S362
LID - S0883-5403(24)00104-9 [pii]
LID - 10.1016/j.arth.2024.02.005 [doi]
AB  - BACKGROUND: Online information is a useful resource for patients seeking advice 
      on their orthopaedic care. While traditional websites provide responses to 
      specific frequently asked questions (FAQs), sophisticated artificial intelligence 
      tools may be able to provide the same information to patients in a more 
      accessible manner. Chat Generative Pretrained Transformer (ChatGPT) is a powerful 
      artificial intelligence chatbot that has been shown to effectively draw on its 
      large reserves of information in a conversational context with a user. The 
      purpose of this study was to assess the accuracy and reliability of 
      ChatGPT-generated responses to FAQs regarding total knee arthroplasty. METHODS: 
      We distributed a survey that challenged arthroplasty surgeons to identify which 
      of the 2 responses to FAQs on our institution's website was human-written and 
      which was generated by ChatGPT. All questions were total knee 
      arthroplasty-related. The second portion of the survey investigated the potential 
      to further leverage ChatGPT to assist with translation and accessibility as a 
      means to better meet the needs of our diverse patient population. RESULTS: 
      Surgeons correctly identified the ChatGPT-generated responses 4 out of 10 times 
      on average (range: 0 to 7). No consensus was reached on any of the responses to 
      the FAQs. Additionally, over 90% of our surgeons strongly encouraged the use of 
      ChatGPT to more effectively accommodate the diverse patient populations that seek 
      information from our hospital's online resources. CONCLUSIONS: ChatGPT provided 
      accurate, reliable answers to our website's FAQs. Surgeons also agreed that 
      ChatGPT's ability to provide targeted, language-specific responses to FAQs would 
      be of benefit to our diverse patient population.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Taylor, Walter L 4th
AU  - Taylor WL 4th
AD  - Department of Adult Reconstruction and Joint Replacement, Hospital for Special 
      Surgery, New York, New York.
FAU - Cheng, Ryan
AU  - Cheng R
AD  - Department of Adult Reconstruction and Joint Replacement, Hospital for Special 
      Surgery, New York, New York.
FAU - Weinblatt, Aaron I
AU  - Weinblatt AI
AD  - Department of Adult Reconstruction and Joint Replacement, Hospital for Special 
      Surgery, New York, New York.
FAU - Bergstein, Victoria
AU  - Bergstein V
AD  - Department of Adult Reconstruction and Joint Replacement, Hospital for Special 
      Surgery, New York, New York.
FAU - Long, William J
AU  - Long WJ
AD  - Department of Adult Reconstruction and Joint Replacement, Hospital for Special 
      Surgery, New York, New York.
LA  - eng
PT  - Journal Article
DEP - 20240211
PL  - United States
TA  - J Arthroplasty
JT  - The Journal of arthroplasty
JID - 8703515
SB  - IM
MH  - *Arthroplasty, Replacement, Knee
MH  - Humans
MH  - *Artificial Intelligence
MH  - Surveys and Questionnaires
MH  - *Internet
MH  - Reproducibility of Results
MH  - Patient Education as Topic/methods
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - eHealth literacy
OT  - health equity
OT  - patient education
OT  - total knee arthroplasty
EDAT- 2024/02/14 00:44
MHDA- 2024/07/28 14:53
CRDT- 2024/02/13 19:11
PHST- 2023/11/08 00:00 [received]
PHST- 2024/02/05 00:00 [accepted]
PHST- 2024/07/28 14:53 [medline]
PHST- 2024/02/14 00:44 [pubmed]
PHST- 2024/02/13 19:11 [entrez]
AID - S0883-5403(24)00104-9 [pii]
AID - 10.1016/j.arth.2024.02.005 [doi]
PST - ppublish
SO  - J Arthroplasty. 2024 Aug;39(8S1):S358-S362. doi: 10.1016/j.arth.2024.02.005. Epub 
      2024 Feb 11.

PMID- 39444664
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241025
IS  - 2624-8212 (Electronic)
IS  - 2624-8212 (Linking)
VI  - 7
DP  - 2024
TI  - Beyond the stereotypes: Artificial Intelligence image generation and diversity in 
      anesthesiology.
PG  - 1462819
LID - 10.3389/frai.2024.1462819 [doi]
LID - 1462819
AB  - INTRODUCTION: Artificial Intelligence (AI) is increasingly being integrated into 
      anesthesiology to enhance patient safety, improve efficiency, and streamline 
      various aspects of practice. OBJECTIVE: This study aims to evaluate whether 
      AI-generated images accurately depict the demographic racial and ethnic diversity 
      observed in the Anesthesia workforce and to identify inherent social biases in 
      these images. METHODS: This cross-sectional analysis was conducted from January 
      to February 2024. Demographic data were collected from the American Society of 
      Anesthesiologists (ASA) and the European Society of Anesthesiology and Intensive 
      Care (ESAIC). Two AI text-to-image models, ChatGPT DALL-E 2 and Midjourney, 
      generated images of anesthesiologists across various subspecialties. Three 
      independent reviewers assessed and categorized each image based on sex, 
      race/ethnicity, age, and emotional traits. RESULTS: A total of 1,200 images were 
      analyzed. We found significant discrepancies between AI-generated images and 
      actual demographic data. The models predominantly portrayed anesthesiologists as 
      White, with ChatGPT DALL-E2 at 64.2% and Midjourney at 83.0%. Moreover, male 
      gender was highly associated with White ethnicity by ChatGPT DALL-E2 (79.1%) and 
      with non-White ethnicity by Midjourney (87%). Age distribution also varied 
      significantly, with younger anesthesiologists underrepresented. The analysis also 
      revealed predominant traits such as "masculine, ""attractive, "and "trustworthy" 
      across various subspecialties. CONCLUSION: AI models exhibited notable biases in 
      gender, race/ethnicity, and age representation, failing to reflect the actual 
      diversity within the anesthesiologist workforce. These biases highlight the need 
      for more diverse training datasets and strategies to mitigate bias in 
      AI-generated images to ensure accurate and inclusive representations in the 
      medical field.
CI  - Copyright © 2024 Gisselbaek, Minsart, Köselerli, Suppan, Meco, Seidel, Albert, 
      Barreto Chang, Saxena and Berger-Estilita.
FAU - Gisselbaek, Mia
AU  - Gisselbaek M
AD  - Division of Anesthesiology, Department of Anesthesiology, Clinical Pharmacology, 
      Intensive Care and Emergency Medicine, Faculty of Medicine, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Minsart, Laurens
AU  - Minsart L
AD  - Department of Anesthesia, Antwerp University Hospital, Edegem, Belgium.
FAU - Köselerli, Ekin
AU  - Köselerli E
AD  - Department of Anesthesiology and Intensive Care Unit, University of Ankara School 
      of Medicine, Ankara, Türkiye.
FAU - Suppan, Mélanie
AU  - Suppan M
AD  - Division of Anesthesiology, Department of Anesthesiology, Clinical Pharmacology, 
      Intensive Care and Emergency Medicine, Faculty of Medicine, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Meco, Basak Ceyda
AU  - Meco BC
AD  - Department of Anesthesiology and Intensive Care Unit, University of Ankara School 
      of Medicine, Ankara, Türkiye.
AD  - Ankara University Brain Research Center (AÜBAUM), Ankara, Türkiye.
FAU - Seidel, Laurence
AU  - Seidel L
AD  - B-STAT, Biostatistics and Research Method Center of ULiège and CHU of Liège, 
      Liege, Belgium.
FAU - Albert, Adelin
AU  - Albert A
AD  - B-STAT, Biostatistics and Research Method Center of ULiège and CHU of Liège, 
      Liege, Belgium.
FAU - Barreto Chang, Odmara L
AU  - Barreto Chang OL
AD  - Department of Anesthesia and Perioperative Care, University of California San 
      Francisco, San Francisco, CA, United States.
FAU - Saxena, Sarah
AU  - Saxena S
AD  - Department of Anesthesia and Reanimation, AZ Sint-Jan Brugge Oostende AV, Brugge, 
      Belgium.
FAU - Berger-Estilita, Joana
AU  - Berger-Estilita J
AD  - Institute for Medical Education, University of Bern, Bern, Switzerland.
AD  - CINTESIS@RISE, Centre for Health Technology and Services Research, Faculty of 
      Medicine, University of Porto, Porto, Portugal.
AD  - Institute for Anesthesiology and Intensive Care, Salemspital, Hirslanden Medical 
      Group, Bern, Switzerland.
LA  - eng
PT  - Journal Article
DEP - 20241009
PL  - Switzerland
TA  - Front Artif Intell
JT  - Frontiers in artificial intelligence
JID - 101770551
PMC - PMC11497631
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - anesthesiology
OT  - biases
OT  - gender equity
OT  - race/ethnicity
OT  - stereotypes
COIS- OB received funding from the Harold Amos Medical Faculty Development Program and 
      participated as an investigator for the clinical trial OLIVER from Medtronic®. SS 
      has received speaker’s fees from Medtronic®/Merck®. JB-E is a member of the 
      European Society of Anesthesiology and Intensive Care (ESAIC) Board of Directors 
      and has received speaker fees from Medtronic®. The remaining authors declare that 
      the research was conducted in the absence of any commercial or financial 
      relationships that could be construed as a potential conflict of interest.
EDAT- 2024/10/24 16:50
MHDA- 2024/10/24 16:51
PMCR- 2024/10/09
CRDT- 2024/10/24 04:20
PHST- 2024/07/10 00:00 [received]
PHST- 2024/09/02 00:00 [accepted]
PHST- 2024/10/24 16:51 [medline]
PHST- 2024/10/24 16:50 [pubmed]
PHST- 2024/10/24 04:20 [entrez]
PHST- 2024/10/09 00:00 [pmc-release]
AID - 10.3389/frai.2024.1462819 [doi]
PST - epublish
SO  - Front Artif Intell. 2024 Oct 9;7:1462819. doi: 10.3389/frai.2024.1462819. 
      eCollection 2024.

PMID- 39381244
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241010
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 10
IP  - 18
DP  - 2024 Sep 30
TI  - Embedded values-like shape ethical reasoning of large language models on primary 
      care ethical dilemmas.
PG  - e38056
LID - 10.1016/j.heliyon.2024.e38056 [doi]
LID - e38056
AB  - OBJECTIVE: This article uses the framework of Schwartz's values theory to examine 
      whether the embedded values-like profile within large language models (LLMs) 
      impact ethical decision-making dilemmas faced by primary care. It specifically 
      aims to evaluate whether each LLM exhibits a distinct values-like profile, assess 
      its alignment with general population values, and determine whether latent values 
      influence clinical recommendations. METHODS: The Portrait Values 
      Questionnaire-Revised (PVQ-RR) was submitted to each LLM (Claude, Bard, GPT-3.5, 
      and GPT-4) 20 times to ensure reliable and valid responses. Their responses were 
      compared to a benchmark derived from a diverse international sample consisting of 
      over 53,000 culturally diverse respondents who completed the PVQ-RR. Four 
      vignettes depicting prototypical professional quandaries involving conflicts 
      between competing values were presented to the LLMs. The option selected by each 
      LLM and the strength of its recommendation were evaluated to determine if 
      underlying values-like impact output. RESULTS: Each LLM demonstrated a unique 
      values-like profile. Universalism and self-direction were prioritized, while 
      power and tradition were assigned less importance than population benchmarks, 
      suggesting potential Western-centric biases. Four clinical vignettes involving 
      value conflicts were presented to the LLMs. Preliminary indications suggested 
      that embedded values-like influence recommendations. Significant variances in 
      confidence strength regarding chosen recommendations materialized between models, 
      proposing that further vetting is required before the LLMs can be relied on as 
      judgment aids. However, the overall selection of preferences aligned with 
      intrinsic value hierarchies. CONCLUSION: The distinct intrinsic values-like 
      embedded within LLMs shape ethical decision-making, which carries implications 
      for their integration in primary care settings serving diverse populations. For 
      context-appropriate, equitable delivery of AI-assisted healthcare globally it is 
      essential that LLMs are tailored to align with cultural outlooks.
CI  - © 2024 The Authors. Published by Elsevier Ltd.
FAU - Hadar-Shoval, Dorit
AU  - Hadar-Shoval D
AD  - The Center for Psychobiological Research, Department of Psychology and 
      Educational Counseling, Max Stern Yezreel Valley College, Israel.
FAU - Asraf, Kfir
AU  - Asraf K
AD  - The Center for Psychobiological Research, Department of Psychology and 
      Educational Counseling, Max Stern Yezreel Valley College, Israel.
FAU - Shinan-Altman, Shiri
AU  - Shinan-Altman S
AD  - The Louis and Gabi Weisfeld School of Social Work, Bar-Ilan University, Ramat 
      Gan, Israel.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AD  - The Center for Psychobiological Research, Department of Psychology and 
      Educational Counseling, Max Stern Yezreel Valley College, Israel.
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, 
      England.
AD  - Department of Counseling and Human Development, Department of Education, 
      University of Haifa, Israel.
FAU - Levkovich, Inbar
AU  - Levkovich I
AD  - The Department of Education, Tel Hai College, Israel.
LA  - eng
PT  - Journal Article
DEP - 20240919
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC11458949
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Large language model (LLM)
OT  - Primary care physicians
OT  - Values
OT  - Vignette
COIS- The authors declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/10/09 07:25
MHDA- 2024/10/09 07:26
PMCR- 2024/09/19
CRDT- 2024/10/09 04:45
PHST- 2024/09/12 00:00 [received]
PHST- 2024/09/17 00:00 [accepted]
PHST- 2024/10/09 07:26 [medline]
PHST- 2024/10/09 07:25 [pubmed]
PHST- 2024/10/09 04:45 [entrez]
PHST- 2024/09/19 00:00 [pmc-release]
AID - S2405-8440(24)14087-X [pii]
AID - e38056 [pii]
AID - 10.1016/j.heliyon.2024.e38056 [doi]
PST - epublish
SO  - Heliyon. 2024 Sep 19;10(18):e38056. doi: 10.1016/j.heliyon.2024.e38056. 
      eCollection 2024 Sep 30.

PMID- 38562452
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250322
IS  - 2331-8422 (Electronic)
IS  - 2331-8422 (Linking)
DP  - 2024 Apr 2
TI  - Assessing the Utility of Large Language Models for Phenotype-Driven Gene 
      Prioritization in Rare Genetic Disorder Diagnosis.
LID - arXiv:2403.14801v2
AB  - Phenotype-driven gene prioritization is a critical process in the diagnosis of 
      rare genetic disorders for identifying and ranking potential disease-causing 
      genes based on observed physical traits or phenotypes. While traditional 
      approaches rely on curated knowledge graphs with phenotype-gene relations, recent 
      advancements in large language models have opened doors to the potential of AI 
      predictions through extensive training on diverse corpora and complex models. 
      This study conducted a comprehensive evaluation of five large language models, 
      including two Generative Pre-trained Transformers series, and three Llama2 
      series, assessing their performance across three key metrics: task completeness, 
      gene prediction accuracy, and adherence to required output structures. Various 
      experiments explored combinations of models, prompts, input types, and task 
      difficulty levels. Our findings reveal that even the best-performing LLM, GPT-4, 
      achieved an accuracy of 16.0%, which still lags behind traditional bioinformatics 
      tools. Prediction accuracy increased with the parameter/model size. A similar 
      increasing trend was observed for the task completion rate, with complicated 
      prompts more likely to increase task completeness in models smaller than GPT-4. 
      However, complicated prompts are more likely to decrease the structure compliance 
      rate, but no prompt effects on GPT-4. Compared to HPO term-based input, LLM was 
      also able to achieve better than random prediction accuracy by taking free-text 
      input, but slightly lower than with the HPO input. Bias analysis showed that 
      certain genes, such as MECP2, CDKL5, and SCN1A, are more likely to be top-ranked, 
      potentially explaining the variances observed across different datasets. This 
      study provides valuable insights into the integration of LLMs within genomic 
      analysis, contributing to the ongoing discussion on the utilization of advanced 
      LLMs in clinical workflows.
FAU - Kim, Junyoung
AU  - Kim J
FAU - Yang, Jingye
AU  - Yang J
FAU - Wang, Kai
AU  - Wang K
FAU - Weng, Chunhua
AU  - Weng C
FAU - Liu, Cong
AU  - Liu C
LA  - eng
GR  - R01 HG013031/HG/NHGRI NIH HHS/United States
GR  - R01 LM012895/LM/NLM NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240402
PL  - United States
TA  - ArXiv
JT  - ArXiv
JID - 101759493
UIN - Am J Hum Genet. 2024 Oct 3;111(10):2190-2202. doi: 10.1016/j.ajhg.2024.08.010. 
      PMID: 39255797
PMC - PMC10984004
EDAT- 2024/04/02 06:45
MHDA- 2024/04/02 06:46
PMCR- 2024/04/02
CRDT- 2024/04/02 03:49
PHST- 2024/04/02 06:45 [pubmed]
PHST- 2024/04/02 06:46 [medline]
PHST- 2024/04/02 03:49 [entrez]
PHST- 2024/04/02 00:00 [pmc-release]
AID - 2403.14801 [pii]
PST - epublish
SO  - ArXiv [Preprint]. 2024 Apr 2:arXiv:2403.14801v2.

PMID- 38222422
OWN - NLM
STAT- MEDLINE
DCOM- 20240116
LR  - 20240210
IS  - 1942-597X (Electronic)
IS  - 1559-4076 (Linking)
VI  - 2023
DP  - 2023
TI  - Auditing Learned Associations in Deep Learning Approaches to Extract Race and 
      Ethnicity from Clinical Text.
PG  - 289-298
AB  - Complete and accurate race and ethnicity (RE) patient information is important 
      for many areas of biomedical informatics research, such as defining and 
      characterizing cohorts, performing quality assessments, and identifying health 
      inequities. Patient-level RE data is often inaccurate or missing in structured 
      sources, but can be supplemented through clinical notes and natural language 
      processing (NLP). While NLP has made many improvements in recent years with large 
      language models, bias remains an often-unaddressed concern, with research showing 
      that harmful and negative language is more often used for certain racial/ethnic 
      groups than others. We present an approach to audit the learned associations of 
      models trained to identify RE information in clinical text by measuring the 
      concordance between model-derived salient features and manually identified 
      RE-related spans of text. We show that while models perform well on the surface, 
      there exist concerning learned associations and potential for future harms from 
      RE-identification models if left unaddressed.
CI  - ©2023 AMIA - All rights reserved.
FAU - Bear Don't Walk Iv, Oliver J
AU  - Bear Don't Walk Iv OJ
AD  - University of Washington, Seattle, WA.
FAU - Pichon, Adrienne
AU  - Pichon A
AD  - 2 Columbia University, New York, New York.
FAU - Nieva, Harry Reyes
AU  - Nieva HR
AD  - 2 Columbia University, New York, New York.
AD  - Harvard Medical School, Boston, Massachusetts.
FAU - Sun, Tony
AU  - Sun T
AD  - 2 Columbia University, New York, New York.
FAU - Altosaar, Jaan
AU  - Altosaar J
AD  - One Fact Foundation, Claymont, DE.
FAU - Natarajan, Karthik
AU  - Natarajan K
AD  - 2 Columbia University, New York, New York.
FAU - Perotte, Adler
AU  - Perotte A
AD  - 2 Columbia University, New York, New York.
FAU - Tarczy-Hornoch, Peter
AU  - Tarczy-Hornoch P
AD  - University of Washington, Seattle, WA.
FAU - Demner-Fushman, Dina
AU  - Demner-Fushman D
AD  - US National Library of Medicine, Bethesda, Maryland.
FAU - Elhadad, Noémie
AU  - Elhadad N
AD  - 2 Columbia University, New York, New York.
LA  - eng
GR  - R01 LM006910/LM/NLM NIH HHS/United States
GR  - T15 LM007079/LM/NLM NIH HHS/United States
PT  - Journal Article
DEP - 20240111
PL  - United States
TA  - AMIA Annu Symp Proc
JT  - AMIA ... Annual Symposium proceedings. AMIA Symposium
JID - 101209213
SB  - IM
MH  - Humans
MH  - *Ethnicity
MH  - *Deep Learning
MH  - Language
MH  - Natural Language Processing
PMC - PMC10785932
EDAT- 2024/01/15 06:42
MHDA- 2024/01/16 06:41
PMCR- 2024/01/11
CRDT- 2024/01/15 04:33
PHST- 2024/01/16 06:41 [medline]
PHST- 2024/01/15 06:42 [pubmed]
PHST- 2024/01/15 04:33 [entrez]
PHST- 2024/01/11 00:00 [pmc-release]
AID - 927 [pii]
PST - epublish
SO  - AMIA Annu Symp Proc. 2024 Jan 11;2023:289-298. eCollection 2023.

PMID- 39176830
OWN - NLM
STAT- MEDLINE
DCOM- 20240823
LR  - 20240823
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 316
DP  - 2024 Aug 22
TI  - Beyond Tokens: Fair Evaluation of French Large Language Models for Clinical Named 
      Entity Recognition.
PG  - 666-670
LID - 10.3233/SHTI240502 [doi]
AB  - Named Entity Recognition (NER) models based on Transformers have gained 
      prominence for their impressive performance in various languages and domains. 
      This work delves into the often-overlooked aspect of entity-level metrics and 
      exposes significant discrepancies between token and entity-level evaluations. The 
      study utilizes a corpus of synthetic French oncological reports annotated with 
      entities representing oncological morphologies. Four different French BERT-based 
      models are fine-tuned for token classification, and their performance is 
      rigorously assessed at both token and entity-level. In addition to fine-tuning, 
      we evaluate ChatGPT's ability to perform NER through prompt engineering 
      techniques. The findings reveal a notable disparity in model effectiveness when 
      transitioning from token to entity-level metrics, highlighting the importance of 
      comprehensive evaluation methodologies in NER tasks. Furthermore, in comparison 
      to BERT, ChatGPT remains limited when it comes to detecting advanced entities in 
      French.
FAU - Zaghir, Jamil
AU  - Zaghir J
AD  - Division of Medical Information Sciences, Geneva University Hospitals, Geneva, 
      Switzerland.
AD  - Department of Radiology and Medical Informatics, University of Geneva, Geneva, 
      Switzerland.
FAU - Bjelogrlic, Mina
AU  - Bjelogrlic M
AD  - Division of Medical Information Sciences, Geneva University Hospitals, Geneva, 
      Switzerland.
AD  - Department of Radiology and Medical Informatics, University of Geneva, Geneva, 
      Switzerland.
FAU - Goldman, Jean-Philippe
AU  - Goldman JP
AD  - Division of Medical Information Sciences, Geneva University Hospitals, Geneva, 
      Switzerland.
AD  - Department of Radiology and Medical Informatics, University of Geneva, Geneva, 
      Switzerland.
FAU - Bensahla, Adel
AU  - Bensahla A
AD  - Division of Medical Information Sciences, Geneva University Hospitals, Geneva, 
      Switzerland.
AD  - Department of Radiology and Medical Informatics, University of Geneva, Geneva, 
      Switzerland.
FAU - Zheng, Yuanyuan
AU  - Zheng Y
AD  - Division of Medical Information Sciences, Geneva University Hospitals, Geneva, 
      Switzerland.
AD  - Department of Radiology and Medical Informatics, University of Geneva, Geneva, 
      Switzerland.
FAU - Lovis, Christian
AU  - Lovis C
AD  - Division of Medical Information Sciences, Geneva University Hospitals, Geneva, 
      Switzerland.
AD  - Department of Radiology and Medical Informatics, University of Geneva, Geneva, 
      Switzerland.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - IM
MH  - *Natural Language Processing
MH  - France
MH  - Humans
MH  - Electronic Health Records
MH  - Language
MH  - Neoplasms
MH  - Vocabulary, Controlled
OTO - NOTNLM
OT  - Clinical NLP
OT  - Medical Prompt Engineering
OT  - Named Entity Recognition
EDAT- 2024/08/23 06:41
MHDA- 2024/08/23 06:42
CRDT- 2024/08/23 05:05
PHST- 2024/08/23 06:42 [medline]
PHST- 2024/08/23 06:41 [pubmed]
PHST- 2024/08/23 05:05 [entrez]
AID - SHTI240502 [pii]
AID - 10.3233/SHTI240502 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2024 Aug 22;316:666-670. doi: 10.3233/SHTI240502.

PMID- 40122110
OWN - NLM
STAT- Publisher
LR  - 20250323
IS  - 2154-1671 (Electronic)
IS  - 2154-1671 (Linking)
DP  - 2025 Mar 24
TI  - Behavioral Emergency Response Team Alert Disparities in a Single-Site Pediatric 
      Hospital.
LID - e2023007520 [pii]
LID - 10.1542/hpeds.2023-007520 [doi]
AB  - BACKGROUND AND OBJECTIVES: A Behavioral Emergency Reponse Team (BERT) is a rapid 
      response team for behavioral emergencies, which include clinical psychiatric 
      emergencies, coping/stress reactions and physical or verbal conflicts.1 Use of 
      BERT activations ("alerts") in inpatient pediatric populations is understudied. 
      The objective of this study is to determine any differences by race for 
      individuals receiving BERT alerts at a single pediatric hospital. METHODS: A 
      cross-sectional retrospective review of all inpatient BERT alerts was conducted 
      between January 1, 2018, and December 31, 2020. Primary outcome was presence or 
      absence of a BERT alert during a single hospital admission (Financial 
      Identification Number). A mixed-effects logistic regression model was conducted 
      to test the association between race and BERT alert as well as physical restraint 
      (PR) use, adjusting for age, gender, ethnicity, payor, and mental health 
      diagnosis (MHD) and clustering at the patient level. RESULTS: A total of 683 
      alerts occurred between the years 2018 and 2020. Admissions for Black patients 
      had higher odds (adjusted odds ratio [aOR], 2.1; 95% CI, 1.6-2.8; P < .001) of 
      having a BERT alert. Admissions with private insurance had lower odds (aOR, 0.4; 
      95% CI, 0.3-0.5; P < .001) of any BERT alert. Having an MHD was associated with 
      higher rates of BERT alert (46.7% vs 15.0%; P < .001) and PR use (aOR, 16.7; 95% 
      CI, 5.1-55.0; P < .001). CONCLUSION: Patients with Black race, government 
      insurance, and MHD had a disproportionate number of BERT. MHD and BERT alerts are 
      associated with increased PR use.
CI  - Copyright © 2025 by the American Academy of Pediatrics.
FAU - Peterson, Rachel
AU  - Peterson R
AD  - Department of Pediatrics, Division of Hospital Medicine, University of Cincinnati 
      College of Medicine, Cincinnati, Ohio.
AD  - Cincinnati Children's Hospital Medical Center, Cincinnati, Ohio.
FAU - Kim, Edward
AU  - Kim E
AD  - Department of Pediatrics, Division of Pediatric Hospital Medicine, Children's 
      Hospital Colorado, Aurora, Colorado.
FAU - Amaniampong, Angela
AU  - Amaniampong A
AD  - Children's Hospital of Philadelphia, Philadelphia, Pennsylvania.
FAU - Krause, Katherine
AU  - Krause K
AD  - Medical College of Wisconsin, Milwaukee, Wisconsin.
FAU - Fauntleroy, Kristin
AU  - Fauntleroy K
AD  - Indiana University School of Medicine, Indianapolis, Indiana.
FAU - Todd, Audrey
AU  - Todd A
AD  - Indiana University School of Medicine, Indianapolis, Indiana.
FAU - LaMotte, Julia E
AU  - LaMotte JE
AD  - Riley Hospital for Children at Indiana University Health, Indianapolis, Indiana.
AD  - Department of Pediatrics, Division of Hematology/Oncology, Indiana University 
      School of Medicine, Indianapolis, Indiana.
FAU - Perkins, Anthony
AU  - Perkins A
AD  - Department of Biostatistics and Health Data Science, Indiana University School of 
      Medicine, Indianapolis, Indiana.
FAU - Johnson, Sarah
AU  - Johnson S
AD  - Riley Hospital for Children at Indiana University Health, Indianapolis, Indiana.
AD  - Department of Physical Therapy, Indiana University Health, Indianapolis, Indiana.
FAU - Tucker-Edmonds, Brownsyne
AU  - Tucker-Edmonds B
AD  - Indiana University School of Medicine, Indianapolis, Indiana.
AD  - Department of Obstetrics and Gynecology, Indiana University School of Medicine, 
      Indianapolis, Indiana.
FAU - Cox, Elaine
AU  - Cox E
AD  - Riley Hospital for Children at Indiana University Health, Indianapolis, Indiana.
LA  - eng
PT  - Journal Article
DEP - 20250324
PL  - United States
TA  - Hosp Pediatr
JT  - Hospital pediatrics
JID - 101585349
SB  - IM
EDAT- 2025/03/24 00:29
MHDA- 2025/03/24 00:29
CRDT- 2025/03/23 20:12
PHST- 2023/08/18 00:00 [received]
PHST- 2024/11/04 00:00 [accepted]
PHST- 2025/03/24 00:29 [medline]
PHST- 2025/03/24 00:29 [pubmed]
PHST- 2025/03/23 20:12 [entrez]
AID - 201281 [pii]
AID - 10.1542/hpeds.2023-007520 [doi]
PST - aheadofprint
SO  - Hosp Pediatr. 2025 Mar 24:e2023007520. doi: 10.1542/hpeds.2023-007520.

PMID- 39906063
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250206
IS  - 2673-253X (Electronic)
IS  - 2673-253X (Linking)
VI  - 7
DP  - 2025
TI  - ChestX-Transcribe: a multimodal transformer for automated radiology report 
      generation from chest x-rays.
PG  - 1535168
LID - 10.3389/fdgth.2025.1535168 [doi]
LID - 1535168
AB  - Radiology departments are under increasing pressure to meet the demand for timely 
      and accurate diagnostics, especially with chest x-rays, a key modality for 
      pulmonary condition assessment. Producing comprehensive and accurate radiological 
      reports is a time-consuming process prone to errors, particularly in high-volume 
      clinical environments. Automated report generation plays a crucial role in 
      alleviating radiologists' workload, improving diagnostic accuracy, and ensuring 
      consistency. This paper introduces ChestX-Transcribe, a multimodal transformer 
      model that combines the Swin Transformer for extracting high-resolution visual 
      features with DistilGPT for generating clinically relevant, semantically rich 
      medical reports. Trained on the Indiana University Chest x-ray dataset, 
      ChestX-Transcribe demonstrates state-of-the-art performance across BLEU, ROUGE, 
      and METEOR metrics, outperforming prior models in producing clinically meaningful 
      reports. However, the reliance on the Indiana University dataset introduces 
      potential limitations, including selection bias, as the dataset is collected from 
      specific hospitals within the Indiana Network for Patient Care. This may result 
      in underrepresentation of certain demographics or conditions not prevalent in 
      those healthcare settings, potentially skewing model predictions when applied to 
      more diverse populations or different clinical environments. Additionally, the 
      ethical implications of handling sensitive medical data, including patient 
      privacy and data security, are considered. Despite these challenges, 
      ChestX-Transcribe shows promising potential for enhancing real-world radiology 
      workflows by automating the creation of medical reports, reducing diagnostic 
      errors, and improving efficiency. The findings highlight the transformative 
      potential of multimodal transformers in healthcare, with future work focusing on 
      improving model generalizability and optimizing clinical integration.
CI  - © 2025 Singh and Singh.
FAU - Singh, Prateek
AU  - Singh P
AD  - Biomedical Engineering Department, School of Bioengineering and Biosciences, 
      Lovely Professional University, Punjab, India.
FAU - Singh, Sudhakar
AU  - Singh S
AD  - Biomedical Engineering Department, School of Bioengineering and Biosciences, 
      Lovely Professional University, Punjab, India.
LA  - eng
PT  - Journal Article
DEP - 20250121
PL  - Switzerland
TA  - Front Digit Health
JT  - Frontiers in digital health
JID - 101771889
PMC - PMC11790570
OTO - NOTNLM
OT  - DistilGPT
OT  - medical report generation
OT  - multimodal transformers
OT  - radiology workflow
OT  - swin transformer
OT  - vision-language models
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2025/02/05 06:21
MHDA- 2025/02/05 06:22
PMCR- 2025/01/21
CRDT- 2025/02/05 04:14
PHST- 2024/11/27 00:00 [received]
PHST- 2025/01/06 00:00 [accepted]
PHST- 2025/02/05 06:22 [medline]
PHST- 2025/02/05 06:21 [pubmed]
PHST- 2025/02/05 04:14 [entrez]
PHST- 2025/01/21 00:00 [pmc-release]
AID - 10.3389/fdgth.2025.1535168 [doi]
PST - epublish
SO  - Front Digit Health. 2025 Jan 21;7:1535168. doi: 10.3389/fdgth.2025.1535168. 
      eCollection 2025.

PMID- 39146892
OWN - NLM
STAT- MEDLINE
DCOM- 20240912
LR  - 20240912
IS  - 2211-0356 (Electronic)
IS  - 2211-0348 (Linking)
VI  - 90
DP  - 2024 Oct
TI  - Generative artificial intelligence versus clinicians: Who diagnoses multiple 
      sclerosis faster and with greater accuracy?
PG  - 105791
LID - S2211-0348(24)00368-7 [pii]
LID - 10.1016/j.msard.2024.105791 [doi]
AB  - BACKGROUND: Those receiving the diagnosis of multiple sclerosis (MS) over the 
      next ten years will predominantly be part of Generation Z (Gen Z). Recent 
      observations within our clinic suggest that younger people with MS utilize online 
      generative artificial intelligence (AI) platforms for personalized medical advice 
      prior to their first visit with a specialist in neuroimmunology. The use of such 
      platforms is anticipated to increase given the technology driven nature, desire 
      for instant communication, and cost-conscious nature of Gen Z. Our objective was 
      to determine if ChatGPT (Generative Pre-trained Transformer) could diagnose MS in 
      individuals earlier than their clinical timeline, and to assess if the accuracy 
      differed based on age, sex, and race/ethnicity. METHODS: People with MS between 
      18 and 59 years of age were studied. The clinical timeline for people diagnosed 
      with MS was retrospectively identified and simulated using ChatGPT-3.5 (GPT-3.5). 
      Chats were conducted using both actual and derivatives of their age, sex, and 
      race/ethnicity to test diagnostic accuracy. A Kaplan-Meier survival curve was 
      estimated for time to diagnosis, clustered by subject. The p-value testing for 
      differences in time to diagnosis was accomplished using a general Wilcoxon test. 
      Logistic regression (subject-specific intercept) was used to capture 
      intra-subject correlation to test the accuracy prior to and after the inclusion 
      of MRI data. RESULTS: The study cohort included 100 unique people with MS. Of 
      those, 50 were members of Gen Z (38 female; 22 White; mean age at first symptom 
      was 20.6 years (y) (standard deviation (SD)=2.2y)), and 50 were non-Gen Z (34 
      female; 27 White; mean age at first symptom was 37.0y (SD=10.4y)). In addition, a 
      total of 529 people that represented digital simulations of the original cohort 
      of 100 people (333 female; 166 White; 136 Black/African American; 107 Asian; 120 
      Hispanic, mean age at first symptom was 31.6y (SD=12.4y)) were generated allowing 
      for 629 scripted conversations to be analyzed. The estimated median time to 
      diagnosis in clinic was significantly longer at 0.35y (95% CI=[0.28, 0.48]) 
      versus that by ChatGPT at 0.08y (95% CI=[0.04, 0.24]) (p<0.0001). There was no 
      difference in the diagnostic accuracy between ages and by race/ethnicity prior to 
      the inclusion of MRI data. However, prior to including the MRI data, males had a 
      47% less likely chance of a correct diagnosis relative to females (p=0.05). 
      Post-MRI data inclusion within GPT-3.5, the odds of an accurate diagnosis was 
      4.0-fold greater for Gen Z participants, relative to non-Gen Z participants 
      (p=0.01) with the diagnostic accuracy being 68% less in males relative to females 
      (p=0.009), and 75% less for White subjects, relative to non-White subjects 
      (p=0.0004). CONCLUSION: Although generative AI platforms enable rapid information 
      access and are not principally designed for use in healthcare, an increase in use 
      by Gen Z is anticipated. However, the obtained responses may not be generalizable 
      to all users and bias may exist in select groups.
CI  - Copyright © 2024 Elsevier B.V. All rights reserved.
FAU - Patel, Mahi A
AU  - Patel MA
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Villalobos, Francisco
AU  - Villalobos F
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Shan, Kevin
AU  - Shan K
AD  - The University of Texas Southwestern Medical Center, School of Medicine, Dallas, 
      Texas, USA.
FAU - Tardo, Lauren M
AU  - Tardo LM
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Horton, Lindsay A
AU  - Horton LA
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Sguigna, Peter V
AU  - Sguigna PV
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Blackburn, Kyle M
AU  - Blackburn KM
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Munoz, Shanan B
AU  - Munoz SB
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Moog, Tatum M
AU  - Moog TM
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Smith, Alexander D
AU  - Smith AD
AD  - Texas Tech University Health Sciences Center, School of Medicine, Lubbock, Texas, 
      USA.
FAU - Burgess, Katy W
AU  - Burgess KW
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - McCreary, Morgan
AU  - McCreary M
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA.
FAU - Okuda, Darin T
AU  - Okuda DT
AD  - The University of Texas Southwestern Medical Center, Department of Neurology, 
      Neuroinnovation Program, Multiple Sclerosis & Neuroimmunology Imaging Program, 
      Dallas, TX, USA; The University of Texas Southwestern Medical Center, Peter 
      O'Donnell Jr. Brain Institute, Dallas, Texas, USA. Electronic address: 
      darin.okuda@UTsouthwestern.edu.
LA  - eng
PT  - Journal Article
DEP - 20240806
PL  - Netherlands
TA  - Mult Scler Relat Disord
JT  - Multiple sclerosis and related disorders
JID - 101580247
SB  - IM
MH  - Humans
MH  - *Multiple Sclerosis/diagnosis
MH  - Female
MH  - Male
MH  - Adult
MH  - *Artificial Intelligence
MH  - Middle Aged
MH  - Young Adult
MH  - Adolescent
MH  - Retrospective Studies
MH  - Time Factors
MH  - Age Factors
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Diagnosis
OT  - Generative AI
OT  - Multiple sclerosis
COIS- Declaration of competing interest M.P., F.V., K.S., K.B., T.M., A.S., K.B., and 
      M.M. report no disclosures. L.T. received personal compensation for advisory 
      services from EMD Serono. L.H. received personal compensation for consulting 
      services from Biogen Inc. and EMD Serono. P.S. received personal compensation for 
      consulting services from Genentech, EMD Serono, Horizon Therapeutics, and Bristol 
      Myers Squibb and research support from Genentech and Clene Nanomedicine. S.M. 
      reports personal compensation for consulting services from Horizon Therapeutics, 
      Bristol Myers Squibb, Novartis, and TG Therapeutics and research support from 
      Genentech. D.T.O. received personal compensation for consulting and advisory 
      services from Biogen Inc., Eisai, EMD Serono, Genentech, Genzyme/Sanofi, Immunic 
      Therapeutics, Moderna, RVL Pharmaceuticals, Inc., and Zenas BioPharma along with 
      research support from EMD Serono/Merck and Novartis. D.T.O. has issued national 
      and international patents along with pending patents related to other developed 
      technologies. D.T.O. received royalties for intellectual property licensed by The 
      Board of Regents of The University of Texas System. D.T.O. is the Founder of 
      Revert Health Inc.
EDAT- 2024/08/16 01:19
MHDA- 2024/09/13 00:46
CRDT- 2024/08/15 18:51
PHST- 2024/03/20 00:00 [received]
PHST- 2024/07/05 00:00 [revised]
PHST- 2024/07/27 00:00 [accepted]
PHST- 2024/09/13 00:46 [medline]
PHST- 2024/08/16 01:19 [pubmed]
PHST- 2024/08/15 18:51 [entrez]
AID - S2211-0348(24)00368-7 [pii]
AID - 10.1016/j.msard.2024.105791 [doi]
PST - ppublish
SO  - Mult Scler Relat Disord. 2024 Oct;90:105791. doi: 10.1016/j.msard.2024.105791. 
      Epub 2024 Aug 6.

PMID- 39688962
OWN - NLM
STAT- Publisher
LR  - 20250123
IS  - 1572-0241 (Electronic)
IS  - 0002-9270 (Linking)
DP  - 2024 Dec 17
TI  - Evaluating Artificial Intelligence-Driven Responses to Acute Liver Failure 
      Queries: A Comparative Analysis Across Accuracy, Clarity, and Relevance.
LID - 10.14309/ajg.0000000000003255 [doi]
AB  - INTRODUCTION: Recent advancements in artificial intelligence (AI), particularly 
      through the deployment of large language models (LLMs), have profoundly impacted 
      healthcare. This study assesses 5 LLMs-ChatGPT 3.5, ChatGPT 4, BARD, CLAUDE, and 
      COPILOT-on their response accuracy, clarity, and relevance to queries concerning 
      acute liver failure (ALF). We subsequently compare these results with ChatGPT4 
      enhanced with retrieval augmented generation (RAG) technology. METHODS: Based on 
      real-world clinical use and the American College of Gastroenterology guidelines, 
      we formulated 16 ALF questions or clinical scenarios to explore LLMs' ability to 
      handle different clinical questions. Using the "New Chat" functionality, each 
      query was processed individually across the models to reduce any bias. 
      Additionally, we employed the RAG functionality of GPT-4, which integrates 
      external sources as references to ground the results. All responses were 
      evaluated on a Likert scale from 1 to 5 for accuracy, clarity, and relevance by 4 
      independent investigators to ensure impartiality. RESULTS: ChatGPT 4, augmented 
      with RAG, demonstrated superior performance compared with others, consistently 
      scoring the highest (4.70, 4.89, 4.78) across all 3 domains. ChatGPT 4 exhibited 
      notable proficiency, with scores of 3.67 in accuracy, 4.04 in clarity, and 4.01 
      in relevance. In contrast, CLAUDE achieved 3.04 in clarity, 3.6 in relevance, and 
      3.65 in accuracy. Meanwhile, BARD and COPILOT exhibited lower performance levels; 
      BARD recorded scores of 2.01 in accuracy and 3.03 in relevance, while COPILOT 
      obtained 2.26 in accuracy and 3.12 in relevance. DISCUSSION: The study highlights 
      Chat GPT 4 +RAG's superior performance compared with other LLMs. By integrating 
      RAG with LLMs, the system combines generative language skills with accurate, 
      up-to-date information. This improves response clarity, relevance, and accuracy, 
      making them more effective in healthcare. However, AI models must continually 
      evolve and align with medical practices for successful healthcare integration.
CI  - Copyright © 2024 by The American College of Gastroenterology.
FAU - Malik, Sheza
AU  - Malik S
AD  - Internal Medicine, Rochester General Hospital, Rochester, New York, USA.
FAU - Frey, Lewis J
AU  - Frey LJ
AD  - Ralph H. Johnson Veterans Affairs Medical Center, Charleston, South Carolina, 
      USA.
FAU - Gutman, Jason
AU  - Gutman J
AUID- ORCID: 0009-0000-6880-8610
AD  - Gastroenterology & Hepatology, Rochester General Hospital, Rochester, New York, 
      USA.
FAU - Mushtaq, Asim
AU  - Mushtaq A
AD  - Gastroenterology & Hepatology, Rochester General Hospital, Rochester, New York, 
      USA.
FAU - Warraich, Fatima
AU  - Warraich F
AD  - Gastroenterology & Hepatology, Rochester General Hospital, Rochester, New York, 
      USA.
FAU - Qureshi, Kamran
AU  - Qureshi K
AUID- ORCID: 0000-0002-0389-7269
AD  - Gastroenterology & Hepatology, Saint Louis University, St. Louis, Missouri, USA.
LA  - eng
PT  - Journal Article
DEP - 20241217
PL  - United States
TA  - Am J Gastroenterol
JT  - The American journal of gastroenterology
JID - 0421030
SB  - IM
EDAT- 2024/12/17 18:23
MHDA- 2024/12/17 18:23
CRDT- 2024/12/17 12:53
PHST- 2024/05/15 00:00 [received]
PHST- 2024/12/12 00:00 [accepted]
PHST- 2024/12/17 18:23 [pubmed]
PHST- 2024/12/17 18:23 [medline]
PHST- 2024/12/17 12:53 [entrez]
AID - 00000434-990000000-01489 [pii]
AID - 10.14309/ajg.0000000000003255 [doi]
PST - aheadofprint
SO  - Am J Gastroenterol. 2024 Dec 17. doi: 10.14309/ajg.0000000000003255.

PMID- 35144000
OWN - NLM
STAT- MEDLINE
DCOM- 20220309
LR  - 20230302
IS  - 1532-0480 (Electronic)
IS  - 1532-0464 (Print)
IS  - 1532-0464 (Linking)
VI  - 127
DP  - 2022 Mar
TI  - Search like an expert: Reducing expertise disparity using a hybrid neural index 
      for COVID-19 queries.
PG  - 104005
LID - S1532-0464(22)00021-1 [pii]
LID - 10.1016/j.jbi.2022.104005 [doi]
AB  - Consumers from non-medical backgrounds often look for information regarding a 
      specific medical information need; however, they are limited by their lack of 
      medical knowledge and may not be able to find reputable resources. As a case 
      study, we investigate reducing this knowledge barrier to allow consumers to 
      achieve search effectiveness comparable to that of an expert, or a medical 
      professional, for COVID-19 related questions. We introduce and evaluate a hybrid 
      index model that allows a consumer to formulate queries using consumer language 
      to find relevant answers to COVID-19 questions. Our aim is to reduce performance 
      degradation between medical professional queries and those of a consumer. We use 
      a universal sentence embedding model to project consumer queries into the same 
      semantic space as professional queries. We then incorporate sentence embeddings 
      into a search framework alongside an inverted index. Documents from this index 
      are retrieved using a novel scoring function that considers sentence embeddings 
      and BM25 scoring. We find that our framework alleviates the expertise disparity, 
      which we validate using an additional set of crowdsourced-consumer-queries even 
      in an unsupervised setting. We also propose an extension of our method, where the 
      sentence encoder is optimised in a supervised setup. Our framework allows for a 
      consumer to search using consumer queries to match the search performance with 
      that of a professional.
CI  - Copyright © 2022 Elsevier Inc. All rights reserved.
FAU - Nguyen, Vincent
AU  - Nguyen V
AD  - The Australian National University, Canberra, Australia; CSIRO Data61, Sydney, 
      NSW, Australia. Electronic address: vincent.nguyen@anu.edu.au.
FAU - Rybinski, Maciej
AU  - Rybinski M
AD  - CSIRO Data61, Sydney, NSW, Australia. Electronic address: 
      maciek.rybinski@csiro.au.
FAU - Karimi, Sarvnaz
AU  - Karimi S
AD  - CSIRO Data61, Sydney, NSW, Australia. Electronic address: 
      sarvnaz.karimi@csiro.au.
FAU - Xing, Zhenchang
AU  - Xing Z
AD  - The Australian National University, Canberra, Australia. Electronic address: 
      zhenchang.xing@anu.edu.au.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20220208
PL  - United States
TA  - J Biomed Inform
JT  - Journal of biomedical informatics
JID - 100970413
SB  - IM
MH  - *COVID-19
MH  - Humans
MH  - *Information Storage and Retrieval
MH  - Natural Language Processing
MH  - SARS-CoV-2
MH  - Unified Medical Language System
PMC - PMC9759932
OTO - NOTNLM
OT  - Biomedical search
OT  - COVID-19
OT  - Dense retrieval
OT  - Information retrieval
OT  - Medical misinformation
OT  - Natural language processing
OT  - Neural index
OT  - Universal sentence embeddings
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2022/02/11 06:00
MHDA- 2022/03/11 06:00
PMCR- 2022/02/08
CRDT- 2022/02/10 20:13
PHST- 2021/08/20 00:00 [received]
PHST- 2022/01/19 00:00 [revised]
PHST- 2022/01/24 00:00 [accepted]
PHST- 2022/02/11 06:00 [pubmed]
PHST- 2022/03/11 06:00 [medline]
PHST- 2022/02/10 20:13 [entrez]
PHST- 2022/02/08 00:00 [pmc-release]
AID - S1532-0464(22)00021-1 [pii]
AID - 104005 [pii]
AID - 10.1016/j.jbi.2022.104005 [doi]
PST - ppublish
SO  - J Biomed Inform. 2022 Mar;127:104005. doi: 10.1016/j.jbi.2022.104005. Epub 2022 
      Feb 8.

PMID- 33529155
OWN - NLM
STAT- MEDLINE
DCOM- 20210302
LR  - 20240331
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 23
IP  - 2
DP  - 2021 Feb 22
TI  - Using Tweets to Understand How COVID-19-Related Health Beliefs Are Affected in 
      the Age of Social Media: Twitter Data Analysis Study.
PG  - e26302
LID - 10.2196/26302 [doi]
LID - e26302
AB  - BACKGROUND: The emergence of SARS-CoV-2 (ie, COVID-19) has given rise to a global 
      pandemic affecting 215 countries and over 40 million people as of October 2020. 
      Meanwhile, we are also experiencing an infodemic induced by the overabundance of 
      information, some accurate and some inaccurate, spreading rapidly across social 
      media platforms. Social media has arguably shifted the information acquisition 
      and dissemination of a considerably large population of internet users toward 
      higher interactivities. OBJECTIVE: This study aimed to investigate 
      COVID-19-related health beliefs on one of the mainstream social media platforms, 
      Twitter, as well as potential impacting factors associated with fluctuations in 
      health beliefs on social media. METHODS: We used COVID-19-related posts from the 
      mainstream social media platform Twitter to monitor health beliefs. A total of 
      92,687,660 tweets corresponding to 8,967,986 unique users from January 6 to June 
      21, 2020, were retrieved. To quantify health beliefs, we employed the health 
      belief model (HBM) with four core constructs: perceived susceptibility, perceived 
      severity, perceived benefits, and perceived barriers. We utilized natural 
      language processing and machine learning techniques to automate the process of 
      judging the conformity of each tweet with each of the four HBM constructs. A 
      total of 5000 tweets were manually annotated for training the machine learning 
      architectures. RESULTS: The machine learning classifiers yielded areas under the 
      receiver operating characteristic curves over 0.86 for the classification of all 
      four HBM constructs. Our analyses revealed a basic reproduction number R(0) of 
      7.62 for trends in the number of Twitter users posting health belief-related 
      content over the study period. The fluctuations in the number of health 
      belief-related tweets could reflect dynamics in case and death statistics, 
      systematic interventions, and public events. Specifically, we observed that 
      scientific events, such as scientific publications, and nonscientific events, 
      such as politicians' speeches, were comparable in their ability to influence 
      health belief trends on social media through a Kruskal-Wallis test (P=.78 and 
      P=.92 for perceived benefits and perceived barriers, respectively). CONCLUSIONS: 
      As an analogy of the classic epidemiology model where an infection is considered 
      to be spreading in a population with an R(0) greater than 1, we found that the 
      number of users tweeting about COVID-19 health beliefs was amplifying in an 
      epidemic manner and could partially intensify the infodemic. It is "unhealthy" 
      that both scientific and nonscientific events constitute no disparity in 
      impacting the health belief trends on Twitter, since nonscientific events, such 
      as politicians' speeches, might not be endorsed by substantial evidence and could 
      sometimes be misleading.
CI  - ©Hanyin Wang, Yikuan Li, Meghan Hutch, Andrew Naidech, Yuan Luo. Originally 
      published in the Journal of Medical Internet Research (http://www.jmir.org), 
      22.02.2021.
FAU - Wang, Hanyin
AU  - Wang H
AUID- ORCID: 0000-0001-9884-9683
AD  - Department of Preventive Medicine, Northwestern University, Chicago, IL, United 
      States.
FAU - Li, Yikuan
AU  - Li Y
AUID- ORCID: 0000-0001-7546-9979
AD  - Department of Preventive Medicine, Northwestern University, Chicago, IL, United 
      States.
FAU - Hutch, Meghan
AU  - Hutch M
AUID- ORCID: 0000-0001-8130-9429
AD  - Department of Preventive Medicine, Northwestern University, Chicago, IL, United 
      States.
FAU - Naidech, Andrew
AU  - Naidech A
AUID- ORCID: 0000-0003-1065-5417
AD  - Department of Neurology, Northwestern Universtity, Chicago, IL, United States.
FAU - Luo, Yuan
AU  - Luo Y
AUID- ORCID: 0000-0003-0195-7456
AD  - Department of Preventive Medicine, Northwestern University, Chicago, IL, United 
      States.
LA  - eng
GR  - T32 LM012203/LM/NLM NIH HHS/United States
PT  - Journal Article
DEP - 20210222
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - COVID-19/epidemiology/*psychology
MH  - *Data Analysis
MH  - Health Education/*statistics & numerical data
MH  - Humans
MH  - *Machine Learning
MH  - *Natural Language Processing
MH  - Pandemics
MH  - *Public Opinion
MH  - Social Media/*statistics & numerical data
PMC - PMC7901597
OTO - NOTNLM
OT  - COVID-19
OT  - Twitter
OT  - health belief
OT  - infodemic
OT  - infodemiology
OT  - machine learning
OT  - natural language processing
OT  - social media
COIS- Conflicts of Interest: None declared.
EDAT- 2021/02/03 06:00
MHDA- 2021/03/03 06:00
PMCR- 2021/02/22
CRDT- 2021/02/02 17:12
PHST- 2020/12/06 00:00 [received]
PHST- 2021/01/31 00:00 [accepted]
PHST- 2021/01/08 00:00 [revised]
PHST- 2021/02/03 06:00 [pubmed]
PHST- 2021/03/03 06:00 [medline]
PHST- 2021/02/02 17:12 [entrez]
PHST- 2021/02/22 00:00 [pmc-release]
AID - v23i2e26302 [pii]
AID - 10.2196/26302 [doi]
PST - epublish
SO  - J Med Internet Res. 2021 Feb 22;23(2):e26302. doi: 10.2196/26302.

PMID- 39871166
OWN - NLM
STAT- MEDLINE
DCOM- 20250128
LR  - 20250130
IS  - 1471-2288 (Electronic)
IS  - 1471-2288 (Linking)
VI  - 25
IP  - 1
DP  - 2025 Jan 28
TI  - Scalable information extraction from free text electronic health records using 
      large language models.
PG  - 23
LID - 10.1186/s12874-025-02470-z [doi]
LID - 23
AB  - BACKGROUND: A vast amount of potentially useful information such as description 
      of patient symptoms, family, and social history is recorded as free-text notes in 
      electronic health records (EHRs) but is difficult to reliably extract at scale, 
      limiting their utility in research. This study aims to assess whether an "out of 
      the box" implementation of open-source large language models (LLMs) without any 
      fine-tuning can accurately extract social determinants of health (SDoH) data from 
      free-text clinical notes. METHODS: We conducted a cross-sectional study using EHR 
      data from the Mass General Brigham (MGB) system, analyzing free-text notes for 
      SDoH information. We selected a random sample of 200 patients and manually 
      labeled nine SDoH aspects. Eight advanced open-source LLMs were evaluated against 
      a baseline pattern-matching model. Two human reviewers provided the manual 
      labels, achieving 93% inter-annotator agreement. LLM performance was assessed 
      using accuracy metrics for overall, mentioned, and non-mentioned SDoH, and macro 
      F1 scores. RESULTS: LLMs outperformed the baseline pattern-matching approach, 
      particularly for explicitly mentioned SDoH, achieving up to 40% higher 
      Accuracy(mentioned). openchat_3.5 was the best-performing model, surpassing the 
      baseline in overall accuracy across all nine SDoH aspects. The refined pipeline 
      with prompt engineering reduced hallucinations and improved accuracy. 
      CONCLUSIONS: Open-source LLMs are effective and scalable tools for extracting 
      SDoH from unstructured EHRs, surpassing traditional pattern-matching methods. 
      Further refinement and domain-specific training could enhance their utility in 
      clinical research and predictive analytics, improving healthcare outcomes and 
      addressing health disparities.
CI  - © 2025. The Author(s).
FAU - Gu, Bowen
AU  - Gu B
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital, Harvard Medical School, 1620 Tremont Street, Suite 
      3030-R, Boston, MA, 02120, USA.
AD  - Department of Otorhinolaryngology - Head & Neck Surgery, Mayo Clinic, Rochester, 
      MN, USA.
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Harvard 
      University, Boston, MA, USA.
FAU - Shao, Vivian
AU  - Shao V
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital, Harvard Medical School, 1620 Tremont Street, Suite 
      3030-R, Boston, MA, 02120, USA.
FAU - Liao, Ziqian
AU  - Liao Z
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Harvard 
      University, Boston, MA, USA.
FAU - Carducci, Valentina
AU  - Carducci V
AD  - Department of Otorhinolaryngology - Head & Neck Surgery, Mayo Clinic, Rochester, 
      MN, USA.
FAU - Brufau, Santiago Romero
AU  - Brufau SR
AD  - Department of Otorhinolaryngology - Head & Neck Surgery, Mayo Clinic, Rochester, 
      MN, USA.
AD  - Department of Biostatistics, Harvard T.H. Chan School of Public Health, Harvard 
      University, Boston, MA, USA.
FAU - Yang, Jie
AU  - Yang J
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital, Harvard Medical School, 1620 Tremont Street, Suite 
      3030-R, Boston, MA, 02120, USA.
FAU - Desai, Rishi J
AU  - Desai RJ
AD  - Division of Pharmacoepidemiology and Pharmacoeconomics, Department of Medicine, 
      Brigham and Women's Hospital, Harvard Medical School, 1620 Tremont Street, Suite 
      3030-R, Boston, MA, 02120, USA. rdesai@bwh.harvard.edu.
LA  - eng
PT  - Journal Article
DEP - 20250128
PL  - England
TA  - BMC Med Res Methodol
JT  - BMC medical research methodology
JID - 100968545
SB  - IM
MH  - *Electronic Health Records/statistics & numerical data
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Natural Language Processing
MH  - Social Determinants of Health/statistics & numerical data
MH  - Female
MH  - Male
MH  - Data Mining/methods/statistics & numerical data
MH  - Language
PMC - PMC11773977
OTO - NOTNLM
OT  - Clinical information extraction
OT  - Electronic health records (EHR)
OT  - Large language models (LLMs)
OT  - Natural Language Processing (NLP)
OT  - Social determinants of health (SDoH)
COIS- Declarations. Ethics approval and consent to participate: Mass General Brigham 
      (MGB) Institutional Review Board approved the study protocol (2020P001486). 
      Consent to participate was not deemed required for this observational 
      investigation. Consent for publication: Not applicable. Competing interests: Dr. 
      Desai reports serving as Principal Investigator on investigator-initiated grants 
      to the Brigham and Women’s Hospital from Novartis, Vertex, and Bayer on unrelated 
      projects.Other authors do not have any competing interests to disclose. Other 
      authors do not have any competing interests to disclose.
EDAT- 2025/01/28 11:26
MHDA- 2025/01/28 11:27
PMCR- 2025/01/28
CRDT- 2025/01/28 00:14
PHST- 2024/07/09 00:00 [received]
PHST- 2025/01/13 00:00 [accepted]
PHST- 2025/01/28 11:27 [medline]
PHST- 2025/01/28 11:26 [pubmed]
PHST- 2025/01/28 00:14 [entrez]
PHST- 2025/01/28 00:00 [pmc-release]
AID - 10.1186/s12874-025-02470-z [pii]
AID - 2470 [pii]
AID - 10.1186/s12874-025-02470-z [doi]
PST - epublish
SO  - BMC Med Res Methodol. 2025 Jan 28;25(1):23. doi: 10.1186/s12874-025-02470-z.

PMID- 39529104
OWN - NLM
STAT- MEDLINE
DCOM- 20241112
LR  - 20241209
IS  - 1466-609X (Electronic)
IS  - 1364-8535 (Print)
IS  - 1364-8535 (Linking)
VI  - 28
IP  - 1
DP  - 2024 Nov 11
TI  - Representation of intensivists' race/ethnicity, sex, and age by artificial 
      intelligence: a cross-sectional study of two text-to-image models.
PG  - 363
LID - 10.1186/s13054-024-05134-4 [doi]
LID - 363
AB  - BACKGROUND: Integrating artificial intelligence (AI) into intensive care 
      practices can enhance patient care by providing real-time predictions and aiding 
      clinical decisions. However, biases in AI models can undermine diversity, equity, 
      and inclusion (DEI) efforts, particularly in visual representations of healthcare 
      professionals. This work aims to examine the demographic representation of two AI 
      text-to-image models, Midjourney and ChatGPT DALL-E 2, and assess their accuracy 
      in depicting the demographic characteristics of intensivists. METHODS: This 
      cross-sectional study, conducted from May to July 2024, used demographic data 
      from the USA workforce report (2022) and intensive care trainees (2021) to 
      compare real-world intensivist demographics with images generated by two AI 
      models, Midjourney v6.0 and ChatGPT 4.0 DALL-E 2. A total of 1,400 images were 
      generated across ICU subspecialties, with outcomes being the comparison of sex, 
      race/ethnicity, and age representation in AI-generated images to the actual 
      workforce demographics. RESULTS: The AI models demonstrated noticeable biases 
      when compared to the actual U.S. intensive care workforce data, notably 
      overrepresenting White and young doctors. ChatGPT-DALL-E2 produced less female 
      (17.3% vs 32.2%, p < 0.0001), more White (61% vs 55.1%, p = 0.002) and younger 
      (53.3% vs 23.9%, p < 0.001) individuals. While Midjourney depicted more female 
      (47.6% vs 32.2%, p < 0.001), more White (60.9% vs 55.1%, p = 0.003) and younger 
      intensivist (49.3% vs 23.9%, p < 0.001). Substantial differences between the 
      specialties within both models were observed. Finally when compared together, 
      both models showed significant differences in the Portrayal of intensivists. 
      CONCLUSIONS: Significant biases in AI images of intensivists generated by ChatGPT 
      DALL-E 2 and Midjourney reflect broader cultural issues, potentially perpetuating 
      stereotypes of healthcare worker within the society. This study highlights the 
      need for an approach that ensures fairness, accountability, transparency, and 
      ethics in AI applications for healthcare.
CI  - © 2024. The Author(s).
FAU - Gisselbaek, Mia
AU  - Gisselbaek M
AD  - Division of Anesthesiology, Department of Anesthesiology, Clinical Pharmacology, 
      Intensive Care and Emergency Medicine, Faculty of Medicine, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Suppan, Mélanie
AU  - Suppan M
AD  - Division of Anesthesiology, Department of Anesthesiology, Clinical Pharmacology, 
      Intensive Care and Emergency Medicine, Faculty of Medicine, Geneva University 
      Hospitals, Geneva, Switzerland.
FAU - Minsart, Laurens
AU  - Minsart L
AD  - Department of Anesthesia, Antwerp University Hospital (UZA), Edegem, Belgium.
FAU - Köselerli, Ekin
AU  - Köselerli E
AD  - Department of Anesthesiology and Intensive Care Unit, University of Ankara School 
      of Medicine, Ankara, Turkey.
FAU - Nainan Myatra, Sheila
AU  - Nainan Myatra S
AD  - Department of Anaesthesiology, Critical Care and Pain, Tata Memorial Hospital, 
      Homi Bhabha National Institute, Mumbai, India.
FAU - Matot, Idit
AU  - Matot I
AD  - Division of Anesthesiology, Pain, and Intensive Care, Tel Aviv Medical Centre, 
      Sackeler School of Medicine, Tel Aviv, Israel.
FAU - Barreto Chang, Odmara L
AU  - Barreto Chang OL
AD  - Department of Anesthesia and Perioperative Care, University of California San 
      Francisco, San Francisco, CA, USA.
FAU - Saxena, Sarah
AU  - Saxena S
AD  - Department of Anesthesiology, Helora, Mons, Belgium.
FAU - Berger-Estilita, Joana
AU  - Berger-Estilita J
AD  - Department of Surgery, UMons, Research Institute for Health Sciences and 
      Technology, University of Mons, Mons, Belgium. joanamberger@gmail.com.
AD  - Institute for Medical Education, University of Bern, Mittelstrasse 43, 3012, 
      Bern, Switzerland. joanamberger@gmail.com.
AD  - CINTESIS@RISE, Centre for Health Technology and Services Research, Faculty of 
      Medicine, University of Porto, Porto, Portugal. joanamberger@gmail.com.
AD  - Department of Anaesthesiology and Intensive Care, Salemspital, Hirslanden Medical 
      Group, Bern, Switzerland. joanamberger@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20241111
PL  - England
TA  - Crit Care
JT  - Critical care (London, England)
JID - 9801902
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Artificial Intelligence/statistics & numerical data/trends
MH  - Female
MH  - Male
MH  - Adult
MH  - Ethnicity/statistics & numerical data
MH  - Middle Aged
MH  - Racial Groups/statistics & numerical data
MH  - United States
MH  - Age Factors
PMC - PMC11556211
OTO - NOTNLM
OT  - Artificial intelligence (AI)
OT  - Bias
OT  - Demographic representation
OT  - Equity and inclusion (DEI)
OT  - Intensive care
COIS- Declarations Ethics approval and consent to participate On April 16, 2024, an 
      ethical committee waiver (Req-2024-00531) was obtained from the 
      Swissethics—University of Bern, Switzerland. The researchers followed the Data 
      Protection Acts and the study complied with the Declaration of Helsinki [37]. The 
      study adhered to the strengthening the reporting of observational studies in 
      epidemiology (STROBE) reporting guideline. [38] Consent for publication Not 
      applicable. Competing interests OB received funding from the Harold Amos Medical 
      Faculty Development Program and participated as an investigator for the clinical 
      trial OLIVER from Medtronic®. SS has received speaker’s fees from 
      Medtronic®/Merck®. JB-E is a member of the European Society of Anesthesiology and 
      Intensive Care (ESAIC) Board of Directors and has received speaker fees from 
      Medtronic®. The remaining authors declare that the research was conducted in the 
      absence of any commercial or financial relationships that could be construed as a 
      potential conflict of interest.
EDAT- 2024/11/13 13:53
MHDA- 2024/11/13 13:54
PMCR- 2024/11/11
CRDT- 2024/11/11 23:56
PHST- 2024/09/09 00:00 [received]
PHST- 2024/10/15 00:00 [accepted]
PHST- 2024/11/13 13:54 [medline]
PHST- 2024/11/13 13:53 [pubmed]
PHST- 2024/11/11 23:56 [entrez]
PHST- 2024/11/11 00:00 [pmc-release]
AID - 10.1186/s13054-024-05134-4 [pii]
AID - 5134 [pii]
AID - 10.1186/s13054-024-05134-4 [doi]
PST - epublish
SO  - Crit Care. 2024 Nov 11;28(1):363. doi: 10.1186/s13054-024-05134-4.

PMID- 30545489
OWN - NLM
STAT- MEDLINE
DCOM- 20190705
LR  - 20190705
IS  - 1872-8243 (Electronic)
IS  - 1386-5056 (Linking)
VI  - 121
DP  - 2019 Jan
TI  - Extracting tumour prognostic factors from a diverse electronic record dataset in 
      genito-urinary oncology.
PG  - 53-57
LID - S1386-5056(18)30330-7 [pii]
LID - 10.1016/j.ijmedinf.2018.10.008 [doi]
AB  - OBJECTIVES: To implement a system for unsupervised extraction of tumor stage and 
      prognostic data in patients with genitourinary cancers using clinicopathological 
      and radiology text. METHODS: A corpus of 1054 electronic notes (clinician notes, 
      radiology reports and pathology reports) was annotated for tumor stage, prostate 
      specific antigen (PSA) and Gleason grade. Annotations from five clinicians were 
      reconciled to form a gold standard dataset. A training dataset of 386 documents 
      was sequestered. The Medtex algorithm was adapted using the training dataset. 
      RESULTS: Adapted Medtex equaled or exceeded human performance in most 
      annotations, except for implicit M stage (F-measure of 0.69 vs 0.84) and PSA 
      (0.92 vs 0.96). Overall Medtex performed with an F-measure of 0.86 compared to 
      human annotations of 0.92. There was significant inter-observer variability when 
      comparing human annotators to the gold standard. CONCLUSIONS: The Medtex 
      algorithm performed similarly to human annotators for extracting stage and 
      prognostic data from varied clinical texts.
CI  - Copyright © 2018 Elsevier B.V. All rights reserved.
FAU - Khor, Richard C
AU  - Khor RC
AD  - Peter MacCallum Cancer Centre, Department of Radiation Oncology, Melbourne, 
      Australia; University of Melbourne, Sir Peter MacCallum Department of Oncology, 
      Melbourne, Australia; Austin Health, Department of Radiation Oncology, Melbourne, 
      Australia. Electronic address: Richard.Khor@Austin.org.au.
FAU - Nguyen, Anthony
AU  - Nguyen A
AD  - The Australian e-Health Research Centre, CSIRO, Brisbane, Australia.
FAU - O'Dwyer, John
AU  - O'Dwyer J
AD  - The Australian e-Health Research Centre, CSIRO, Brisbane, Australia.
FAU - Kothari, Gargi
AU  - Kothari G
AD  - Peter MacCallum Cancer Centre, Department of Radiation Oncology, Melbourne, 
      Australia.
FAU - Sia, Joseph
AU  - Sia J
AD  - Peter MacCallum Cancer Centre, Department of Radiation Oncology, Melbourne, 
      Australia.
FAU - Chang, David
AU  - Chang D
AD  - Peter MacCallum Cancer Centre, Department of Radiation Oncology, Melbourne, 
      Australia.
FAU - Ng, Sweet Ping
AU  - Ng SP
AD  - Peter MacCallum Cancer Centre, Department of Radiation Oncology, Melbourne, 
      Australia.
FAU - Duchesne, Gillian M
AU  - Duchesne GM
AD  - University of Melbourne, Sir Peter MacCallum Department of Oncology, Melbourne, 
      Australia; Department of Medical Radiations, Monash University, Melbourne, 
      Australia; Department of Biochemistry, Monash University, Melbourne, Australia.
FAU - Foroudi, Farshad
AU  - Foroudi F
AD  - Austin Health, Department of Radiation Oncology, Melbourne, Australia; Department 
      of Cancer Medicine, Latrobe University, Melbourne, Australia.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20181023
PL  - Ireland
TA  - Int J Med Inform
JT  - International journal of medical informatics
JID - 9711057
SB  - IM
MH  - Data Mining/*methods
MH  - Electronic Health Records/*statistics & numerical data
MH  - Humans
MH  - *Information Storage and Retrieval
MH  - Natural Language Processing
MH  - *Observer Variation
MH  - Prognosis
MH  - Urogenital Neoplasms/*pathology
OTO - NOTNLM
OT  - Electronic medical record
OT  - Genitourinary cancers
OT  - Natural language processing
OT  - Text mining
OT  - Tumor staging
EDAT- 2018/12/14 06:00
MHDA- 2019/07/06 06:00
CRDT- 2018/12/15 06:00
PHST- 2017/04/27 00:00 [received]
PHST- 2018/09/17 00:00 [revised]
PHST- 2018/10/21 00:00 [accepted]
PHST- 2018/12/15 06:00 [entrez]
PHST- 2018/12/14 06:00 [pubmed]
PHST- 2019/07/06 06:00 [medline]
AID - S1386-5056(18)30330-7 [pii]
AID - 10.1016/j.ijmedinf.2018.10.008 [doi]
PST - ppublish
SO  - Int J Med Inform. 2019 Jan;121:53-57. doi: 10.1016/j.ijmedinf.2018.10.008. Epub 
      2018 Oct 23.

PMID- 39349172
OWN - NLM
STAT- MEDLINE
DCOM- 20250131
LR  - 20250131
IS  - 2253-8089 (Electronic)
IS  - 2253-8089 (Linking)
VI  - 44
IP  - 1
DP  - 2025 Jan-Feb
TI  - Evaluación de la fiabilidad y legibilidad de las respuestas de los chatbots como 
      recurso de información al paciente para las exploraciones PET-TC más communes.
PG  - 500065
LID - S2253-8089(24)00093-4 [pii]
LID - 10.1016/j.remnie.2024.500065 [doi]
AB  - PURPOSE: This study aimed to evaluate the reliability and readability of 
      responses generated by two popular AI-chatbots, 'ChatGPT-4.0' and 'Google 
      Gemini', to potential patient questions about PET/CT scans. MATERIALS AND 
      METHODS: Thirty potential questions for each of [(18)F]FDG and 
      [(68)Ga]Ga-DOTA-SSTR PET/CT, and twenty-nine potential questions for 
      [(68)Ga]Ga-PSMA PET/CT were asked separately to ChatGPT-4 and Gemini in May 2024. 
      The responses were evaluated for reliability and readability using the modified 
      DISCERN (mDISCERN) scale, Flesch Reading Ease (FRE), Gunning Fog Index (GFI), and 
      Flesch-Kincaid Reading Grade Level (FKRGL). The inter-rater reliability of 
      mDISCERN scores provided by three raters (ChatGPT-4, Gemini, and a nuclear 
      medicine physician) for the responses was assessed. RESULTS: The median [min-max] 
      mDISCERN scores reviewed by the physician for responses about FDG, PSMA and DOTA 
      PET/CT scans were 3.5 [2-4], 3 [3-4], 3 [3-4] for ChatPT-4 and 4 [2-5], 4 [2-5], 
      3.5 [3-5] for Gemini, respectively. The mDISCERN scores assessed using ChatGPT-4 
      for answers about FDG, PSMA, and DOTA-SSTR PET/CT scans were 3.5 [3-5], 3 [3-4], 
      3 [2-3] for ChatGPT-4, and 4 [3-5], 4 [3-5], 4 [3-5] for Gemini, respectively. 
      The mDISCERN scores evaluated using Gemini for responses FDG, PSMA, and DOTA-SSTR 
      PET/CTs were 3 [2-4], 2 [2-4], 3 [2-4] for ChatGPT-4, and 3 [2-5], 3 [1-5], 3 
      [2-5] for Gemini, respectively. The inter-rater reliability correlation 
      coefficient of mDISCERN scores for ChatGPT-4 responses about FDG, PSMA, and 
      DOTA-SSTR PET/CT scans were 0.629 (95% CI = 0,32-0,812), 0.707 (95% 
      CI = 0.458-0.853) and 0.738 (95% CI = 0.519-0.866), respectively (p < 0.001). The 
      correlation coefficient of mDISCERN scores for Gemini responses about FDG, PSMA, 
      and DOTA-SSTR PET/CT scans were 0.824 (95% CI = 0.677-0.910), 0.881 (95% 
      CI = 0.78-0.94) and 0.847 (95% CI = 0.719-0.922), respectively (p < 0.001). The 
      mDISCERN scores assessed by ChatGPT-4, Gemini, and the physician showed that the 
      chatbots' responses about all PET/CT scans had moderate to good statistical 
      agreement according to the inter-rater reliability correlation coefficient 
      (p < 0,001). There was a statistically significant difference in all readability 
      scores (FKRGL, GFI, and FRE) of ChatGPT-4 and Gemini responses about PET/CT scans 
      (p < 0,001). Gemini responses were shorter and had better readability scores than 
      ChatGPT-4 responses. CONCLUSION: There was an acceptable level of agreement 
      between raters for the mDISCERN score, indicating agreement with the overall 
      reliability of the responses. However, the information provided by AI-chatbots 
      cannot be easily read by the public.
CI  - Copyright © 2024 Sociedad Española de Medicina Nuclear e Imagen Molecular. 
      Published by Elsevier España, S.L.U. All rights reserved.
FAU - Aydinbelge-Dizdar, N
AU  - Aydinbelge-Dizdar N
AD  - Department of Nuclear Medicine, Ankara Etlik City Hospital, Ankara, Turkiye. 
      Electronic address: fnuraydinbelge@gmail.com.
FAU - Dizdar, K
AU  - Dizdar K
AD  - Department of Software Engineering, ASELSAN Inc., Ankara, Turkiye. Electronic 
      address: kydz93@yahoo.com.
LA  - eng
PT  - Journal Article
DEP - 20240928
PL  - Spain
TA  - Rev Esp Med Nucl Imagen Mol (Engl Ed)
JT  - Revista espanola de medicina nuclear e imagen molecular
JID - 101770941
RN  - 0 (Radiopharmaceuticals)
RN  - 0Z5B2CJX4D (Fluorodeoxyglucose F18)
RN  - 0 (Gallium Radioisotopes)
RN  - 0 (gallium 68 PSMA-11)
RN  - 0 (Organometallic Compounds)
RN  - 0 (Gallium Isotopes)
SB  - IM
MH  - *Positron Emission Tomography Computed Tomography/methods
MH  - Humans
MH  - Reproducibility of Results
MH  - Radiopharmaceuticals/pharmacokinetics
MH  - Comprehension
MH  - Fluorodeoxyglucose F18/pharmacokinetics
MH  - Gallium Radioisotopes
MH  - Patient Education as Topic
MH  - Organometallic Compounds
MH  - Observer Variation
MH  - Internet
MH  - Gallium Isotopes
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cancer
OT  - ChatGPT-4
OT  - Cáncer
OT  - Google Gemini
OT  - Información para pacientes
OT  - Inteligencia artificial
OT  - PET-TC
OT  - PET/CT
OT  - Patient information
EDAT- 2024/10/01 00:42
MHDA- 2025/02/01 20:43
CRDT- 2024/09/30 21:30
PHST- 2024/07/17 00:00 [received]
PHST- 2024/09/10 00:00 [revised]
PHST- 2024/09/16 00:00 [accepted]
PHST- 2025/02/01 20:43 [medline]
PHST- 2024/10/01 00:42 [pubmed]
PHST- 2024/09/30 21:30 [entrez]
AID - S2253-8089(24)00093-4 [pii]
AID - 10.1016/j.remnie.2024.500065 [doi]
PST - ppublish
SO  - Rev Esp Med Nucl Imagen Mol (Engl Ed). 2025 Jan-Feb;44(1):500065. doi: 
      10.1016/j.remnie.2024.500065. Epub 2024 Sep 28.

PMID- 39919295
OWN - NLM
STAT- MEDLINE
DCOM- 20250207
LR  - 20250224
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 12
DP  - 2025 Feb 7
TI  - The Efficacy of Conversational AI in Rectifying the Theory-of-Mind and Autonomy 
      Biases: Comparative Analysis.
PG  - e64396
LID - 10.2196/64396 [doi]
LID - e64396
AB  - BACKGROUND: The increasing deployment of conversational artificial intelligence 
      (AI) in mental health interventions necessitates an evaluation of their efficacy 
      in rectifying cognitive biases and recognizing affect in human-AI interactions. 
      These biases are particularly relevant in mental health contexts as they can 
      exacerbate conditions such as depression and anxiety by reinforcing maladaptive 
      thought patterns or unrealistic expectations in human-AI interactions. OBJECTIVE: 
      This study aimed to assess the effectiveness of therapeutic chatbots (Wysa and 
      Youper) versus general-purpose language models (GPT-3.5, GPT-4, and Gemini Pro) 
      in identifying and rectifying cognitive biases and recognizing affect in user 
      interactions. METHODS: This study used constructed case scenarios simulating 
      typical user-bot interactions to examine how effectively chatbots address 
      selected cognitive biases. The cognitive biases assessed included theory-of-mind 
      biases (anthropomorphism, overtrust, and attribution) and autonomy biases 
      (illusion of control, fundamental attribution error, and just-world hypothesis). 
      Each chatbot response was evaluated based on accuracy, therapeutic quality, and 
      adherence to cognitive behavioral therapy principles using an ordinal scale to 
      ensure consistency in scoring. To enhance reliability, responses underwent a 
      double review process by 2 cognitive scientists, followed by a secondary review 
      by a clinical psychologist specializing in cognitive behavioral therapy, ensuring 
      a robust assessment across interdisciplinary perspectives. RESULTS: This study 
      revealed that general-purpose chatbots outperformed therapeutic chatbots in 
      rectifying cognitive biases, particularly in overtrust bias, fundamental 
      attribution error, and just-world hypothesis. GPT-4 achieved the highest scores 
      across all biases, whereas the therapeutic bot Wysa scored the lowest. Notably, 
      general-purpose bots showed more consistent accuracy and adaptability in 
      recognizing and addressing bias-related cues across different contexts, 
      suggesting a broader flexibility in handling complex cognitive patterns. In 
      addition, in affect recognition tasks, general-purpose chatbots not only excelled 
      but also demonstrated quicker adaptation to subtle emotional nuances, 
      outperforming therapeutic bots in 67% (4/6) of the tested biases. CONCLUSIONS: 
      This study shows that, while therapeutic chatbots hold promise for mental health 
      support and cognitive bias intervention, their current capabilities are limited. 
      Addressing cognitive biases in AI-human interactions requires systems that can 
      both rectify and analyze biases as integral to human cognition, promoting 
      precision and simulating empathy. The findings reveal the need for improved 
      simulated emotional intelligence in chatbot design to provide adaptive, 
      personalized responses that reduce overreliance and encourage independent coping 
      skills. Future research should focus on enhancing affective response mechanisms 
      and addressing ethical concerns such as bias mitigation and data privacy to 
      ensure safe, effective AI-based mental health support.
CI  - ©Marcin Rządeczka, Anna Sterna, Julia Stolińska, Paulina Kaczyńska, Marcin 
      Moskalewicz. Originally published in JMIR Mental Health 
      (https://mental.jmir.org), 07.02.2025.
FAU - Rządeczka, Marcin
AU  - Rządeczka M
AUID- ORCID: 0000-0002-8315-1650
AD  - IDEAS NCBR, Warsaw, Poland.
AD  - Institute of Philosophy, Maria Curie-Skłodowska University, Lublin, Poland.
FAU - Sterna, Anna
AU  - Sterna A
AUID- ORCID: 0000-0001-8658-7823
AD  - Philosophy of Mental Health Unit, Department of Social Sciences and the 
      Humanities, Poznan University of Medical Sciences, Poznań, Poland.
FAU - Stolińska, Julia
AU  - Stolińska J
AUID- ORCID: 0009-0003-8206-8876
AD  - IDEAS NCBR, Warsaw, Poland.
FAU - Kaczyńska, Paulina
AU  - Kaczyńska P
AUID- ORCID: 0000-0002-8690-8436
AD  - Faculty of Mathematics, Informatics, and Mechanics, University of Warsaw, Warsaw, 
      Poland.
FAU - Moskalewicz, Marcin
AU  - Moskalewicz M
AUID- ORCID: 0000-0002-4270-7026
AD  - IDEAS NCBR, Warsaw, Poland.
AD  - Institute of Philosophy, Maria Curie-Skłodowska University, Lublin, Poland.
AD  - Philosophy of Mental Health Unit, Department of Social Sciences and the 
      Humanities, Poznan University of Medical Sciences, Poznań, Poland.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20250207
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Theory of Mind
MH  - Personal Autonomy
MH  - Communication
PMC - PMC11845887
OTO - NOTNLM
OT  - AI
OT  - affect recognition
OT  - artificial intelligence
OT  - bias rectification
OT  - chatbots
OT  - cognitive bias
OT  - conversational artificial intelligence
OT  - digital mental health
COIS- Conflicts of Interest: None declared.
EDAT- 2025/02/07 18:20
MHDA- 2025/02/07 18:21
PMCR- 2025/02/07
CRDT- 2025/02/07 16:53
PHST- 2024/07/16 00:00 [received]
PHST- 2024/10/29 00:00 [accepted]
PHST- 2024/10/28 00:00 [revised]
PHST- 2025/02/07 18:21 [medline]
PHST- 2025/02/07 18:20 [pubmed]
PHST- 2025/02/07 16:53 [entrez]
PHST- 2025/02/07 00:00 [pmc-release]
AID - v12i1e64396 [pii]
AID - 10.2196/64396 [doi]
PST - epublish
SO  - JMIR Ment Health. 2025 Feb 7;12:e64396. doi: 10.2196/64396.

PMID- 39692886
OWN - NLM
STAT- MEDLINE
DCOM- 20250207
LR  - 20250211
IS  - 1432-1998 (Electronic)
IS  - 0301-0449 (Linking)
VI  - 55
IP  - 2
DP  - 2025 Feb
TI  - A single 1-min brain MRI scan for generating multiple synthetic image contrasts 
      in awake children from quantitative relaxometry maps.
PG  - 312-323
LID - 10.1007/s00247-024-06113-1 [doi]
AB  - BACKGROUND: Diagnostically adequate contrast and spatial resolution in brain MRI 
      require prolonged scan times, leading to motion artifacts and image degradation 
      in awake children. Rapid multi-parametric techniques can produce diagnostic 
      images in awake children, which could help to avoid the need for sedation. 
      OBJECTIVE: To evaluate the utility of a rapid echo-planar imaging (EPI)-based 
      multi-inversion spin and gradient echo (MI-SAGE) technique for generating 
      multi-parametric quantitative brain maps and synthetic contrast images in awake 
      pediatric participants. MATERIALS AND METHODS: In this prospective IRB-approved 
      study, awake research participants 3-10 years old were scanned using MI-SAGE, 
      MOLLI, GRASE, mGRE, and T1-, T2-, T2*-, and FLAIR-weighted sequences. The MI-SAGE 
      T1, T2, and T2* maps and synthetic images were estimated offline. The MI-SAGE 
      parametric values were compared to those from conventional mapping sequences 
      including MOLLI, GRASE, and mGRE, with assessments of repeatability and 
      reproducibility. Synthetic MI-SAGE images and conventional weighted images were 
      reviewed by a neuroradiologist and scored using a 5-point Likert scale. 
      Gray-to-white matter contrast ratios (GWRs) were compared between MI-SAGE 
      synthetic and conventional weighted images. The results were analyzed using the 
      Bland-Altman analysis and intra-class correlation coefficient (ICC). RESULTS: A 
      total of 24 healthy participants aged 3 years to 10 years (mean ± SD, 6.5 ± 1.9; 
      12 males) completed full imaging exams including the 54-s MI-SAGE acquisition and 
      were included in the analysis. The MI-SAGE T1, T2, and T2* had biases of 32%, 
      -4%, and 23% compared to conventional mapping methods using MOLLI, GRASE, and 
      mGRE, respectively, with moderate to very strong correlations (ICC=0.49-0.99). 
      All MI-SAGE maps exhibited strong to very strong repeatability and 
      reproducibility (ICC=0.80 to 0.99). The synthetic MI-SAGE had average Likert 
      scores of 2.1, 2.1, 2.9, and 2.0 for T1-, T2-, T2*-, and FLAIR-weighted images, 
      respectively, while conventional acquisitions had Likert scores of 3.5, 3.6, 4.6, 
      and 3.8 for T1-, T2-, T2*-, and FLAIR-weighted images, respectively. The MI-SAGE 
      synthetic T1w, T2w, T2*w, and FLAIR GWRs had biases of 17%, 3%, 7%, and 1% 
      compared to the GWR of images from conventional T1w, T2w, T2*w, and FLAIR 
      acquisitions respectively. CONCLUSION: The derived T1, T2, and T2* maps were 
      correlated with conventional mapping methods and showed strong repeatability and 
      reproducibility. While synthetic MI-SAGE images had greater susceptibility 
      artifacts and lower Likert scores than conventional images, the MI-SAGE technique 
      produced synthetic weighted images with contrasts similar to conventional 
      weighted images and achieved a ten-fold reduction in scan time.
CI  - © 2024. The Author(s), under exclusive licence to Springer-Verlag GmbH Germany, 
      part of Springer Nature.
FAU - Ramaniharan, Anandh Kilpattu
AU  - Ramaniharan AK
AD  - Cincinnati Children's Hospital Medical Center, 3333 Burnet Ave, Cincinnati, OH, 
      45229, USA. anandh.kilpatturamaniharan@cchmc.org.
FAU - Pednekar, Amol
AU  - Pednekar A
AD  - Cincinnati Children's Hospital Medical Center, 3333 Burnet Ave, Cincinnati, OH, 
      45229, USA. amol.pednekar@cchmc.org.
AD  - University of Cincinnati College of Medicine, Cincinnati, OH, USA. 
      amol.pednekar@cchmc.org.
FAU - Parikh, Nehal A
AU  - Parikh NA
AD  - Cincinnati Children's Hospital Medical Center, 3333 Burnet Ave, Cincinnati, OH, 
      45229, USA. nehal.parikh@cchmc.org.
AD  - University of Cincinnati College of Medicine, Cincinnati, OH, USA. 
      nehal.parikh@cchmc.org.
FAU - Nagaraj, Usha D
AU  - Nagaraj UD
AD  - Cincinnati Children's Hospital Medical Center, 3333 Burnet Ave, Cincinnati, OH, 
      45229, USA. usha.nagaraj@cchmc.org.
AD  - University of Cincinnati College of Medicine, Cincinnati, OH, USA. 
      usha.nagaraj@cchmc.org.
FAU - Manhard, Mary Kate
AU  - Manhard MK
AD  - Cincinnati Children's Hospital Medical Center, 3333 Burnet Ave, Cincinnati, OH, 
      45229, USA. marykate.manhard@cchmc.org.
AD  - University of Cincinnati College of Medicine, Cincinnati, OH, USA. 
      marykate.manhard@cchmc.org.
LA  - eng
PT  - Journal Article
DEP - 20241218
PL  - Germany
TA  - Pediatr Radiol
JT  - Pediatric radiology
JID - 0365332
SB  - IM
MH  - Humans
MH  - Child
MH  - Child, Preschool
MH  - Male
MH  - Female
MH  - Prospective Studies
MH  - Reproducibility of Results
MH  - *Brain/diagnostic imaging
MH  - Wakefulness
MH  - Magnetic Resonance Imaging/methods
MH  - Echo-Planar Imaging/methods
MH  - Image Interpretation, Computer-Assisted/methods
OTO - NOTNLM
OT  - Brain MRI
OT  - Multi-inversion spin and gradient echo
OT  - Quantitative parameter mapping
OT  - Rapid echo planar imaging
COIS- Declarations. Competing interests: The authors declare no competing interests.
EDAT- 2024/12/18 12:24
MHDA- 2025/02/07 12:25
CRDT- 2024/12/18 11:14
PHST- 2024/09/16 00:00 [received]
PHST- 2024/11/16 00:00 [accepted]
PHST- 2024/11/08 00:00 [revised]
PHST- 2025/02/07 12:25 [medline]
PHST- 2024/12/18 12:24 [pubmed]
PHST- 2024/12/18 11:14 [entrez]
AID - 10.1007/s00247-024-06113-1 [pii]
AID - 10.1007/s00247-024-06113-1 [doi]
PST - ppublish
SO  - Pediatr Radiol. 2025 Feb;55(2):312-323. doi: 10.1007/s00247-024-06113-1. Epub 
      2024 Dec 18.

PMID- 40013176
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250228
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 17
IP  - 1
DP  - 2025 Jan
TI  - Physicians' Perspectives on ChatGPT in Ophthalmology: Insights on Artificial 
      Intelligence (AI) Integration in Clinical Practice.
PG  - e78069
LID - 10.7759/cureus.78069 [doi]
LID - e78069
AB  - To obtain detailed data on the acceptance of an artificial intelligence chatbot 
      (ChatGPT; OpenAI, San Francisco, CA, USA) in ophthalmology among physicians, a 
      survey explored physician responses regarding using ChatGPT in ophthalmology. The 
      survey included questions about the applications of ChatGPT in ophthalmology, 
      future concerns such as job replacement or automation, research, medical 
      education, patient education, ethical concerns, and implementation in practice. 
      One hundred ninety-nine ophthalmic surgeons participated in this study. 
      Approximately two-thirds of the participants had 15 years or more experience in 
      ophthalmology. One hundred sixteen reported that they had used ChatGPT. We found 
      no difference in age, gender, or level of experience between those who used or 
      did not use ChatGPT. ChatGPT users tend to consider ChatGPT and artificial 
      intelligence (AI) as useful in ophthalmology (P=0.001). Both users and non-users 
      think that AI is useful for identifying early signs of eye disease, providing 
      decision support in treatment planning, monitoring patient progress, answering 
      patient questions, and scheduling appointments. Both users and non-users believe 
      there are some issues related to the use of AI in health care, such as liability 
      issues, privacy concerns, accuracy of diagnosis, trust of the chatbot, ethical 
      issues, and information bias. The use of ChatGPT and other forms of AI is 
      increasingly becoming accepted among ophthalmologists. AI is seen as a helpful 
      tool for improving patient education, decision support, and medical services, but 
      there are also concerns regarding privacy and job displacement, which warrant 
      human oversight.
CI  - Copyright © 2025, Ahmed et al.
FAU - Ahmed, Anwar
AU  - Ahmed A
AD  - Research, King Khaled Eye Specialist Hospital, Riyadh, SAU.
FAU - Fatani, Dalal
AU  - Fatani D
AD  - Oculoplastic and Orbit, King Khaled Eye Specialist Hospital, Riyadh, SAU.
FAU - Vargas, Jose M
AU  - Vargas JM
AD  - Ophthalmology, King Abdullah Bin Abdulaziz University Hospital, Riyadh, SAU.
FAU - Almutlak, Mohammed
AU  - Almutlak M
AD  - Anterior Segment Division, King Khaled Eye Specialist Hospital, Riyadh, SAU.
FAU - Bin Helayel, Halah
AU  - Bin Helayel H
AD  - Anterior Segment Division, King Khaled Eye Specialist Hospital, Riyadh, SAU.
FAU - Fairaq, Rafah
AU  - Fairaq R
AD  - Anterior Segment Division, King Khaled Eye Specialist Hospital, Riyadh, SAU.
FAU - Alabdulhadi, Halla
AU  - Alabdulhadi H
AD  - Anterior Segment Division, King Khaled Eye Specialist Hospital, Riyadh, SAU.
LA  - eng
PT  - Journal Article
DEP - 20250127
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11864167
OTO - NOTNLM
OT  - artificial intelligence
OT  - chatgpt
OT  - eye care
OT  - ophthalmology
OT  - technology in healthcare
COIS- Human subjects: Consent for treatment and open access publication was obtained or 
      waived by all participants in this study. The Institutional Review Board at King 
      Khaled Eye Specialist Hospital (KKESH) issued approval 23069-P. This study 
      adhered to the tenets of the Declaration of Helsinki. Animal subjects: All 
      authors have confirmed that this study did not involve animal subjects or tissue. 
      Conflicts of interest: In compliance with the ICMJE uniform disclosure form, all 
      authors declare the following: Payment/services info: All authors have declared 
      that no financial support was received from any organization for the submitted 
      work. Financial relationships: All authors have declared that they have no 
      financial relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2025/02/27 06:22
MHDA- 2025/02/27 06:23
PMCR- 2025/01/27
CRDT- 2025/02/27 04:24
PHST- 2025/01/26 00:00 [accepted]
PHST- 2025/02/27 06:23 [medline]
PHST- 2025/02/27 06:22 [pubmed]
PHST- 2025/02/27 04:24 [entrez]
PHST- 2025/01/27 00:00 [pmc-release]
AID - 10.7759/cureus.78069 [doi]
PST - epublish
SO  - Cureus. 2025 Jan 27;17(1):e78069. doi: 10.7759/cureus.78069. eCollection 2025 
      Jan.

PMID- 39234740
OWN - NLM
STAT- MEDLINE
DCOM- 20240905
LR  - 20240905
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 317
DP  - 2024 Aug 30
TI  - Predicting Overall Survival of Glioblastoma Patients Using Deep Learning 
      Classification Based on MRIs.
PG  - 356-365
LID - 10.3233/SHTI240878 [doi]
AB  - INTRODUCTION: Glioblastoma (GB) is one of the most aggressive tumors of the 
      brain. Despite intensive treatment, the average overall survival (OS) is 15-18 
      months. Therefore, it is helpful to be able to assess a patient's OS to tailor 
      treatment more specifically to the course of the disease. Automated analysis of 
      routinely generated MRI sequences (FLAIR, T1, T1CE, and T2) using deep 
      learning-based image classification has the potential to enable accurate OS 
      predictions. METHODS: In this work, a method was developed and evaluated that 
      classifies the OS into three classes - "short", "medium" and "long". For this 
      purpose, the four MRI sequences of a person were corrected using bias-field 
      correction and merged into one image. The pipeline was realized by a bagging 
      model using 5-fold cross-validation and the ResNet50 architecture. RESULTS: The 
      best model was able to achieve an F1-score of 0.51 and an accuracy of 0.67. In 
      addition, this work enabled a largely clear differentiation of the "short" and 
      "long" classes, which offers high clinical significance as decision support. 
      CONCLUSION: Automated analysis of MRI scans using deep learning-based image 
      classification has the potential to enable accurate OS prediction in 
      glioblastomas.
FAU - Ott, Katharina
AU  - Ott K
AD  - IT-Infrastructure for Translational Medical Research, University of Augsburg, 
      Germany.
FAU - Cepeda, Santiago
AU  - Cepeda S
AD  - Department of Neurosurgery, Río Hortega University Hospital, Spain.
FAU - Hartmann, Dennis
AU  - Hartmann D
AD  - IT-Infrastructure for Translational Medical Research, University of Augsburg, 
      Germany.
FAU - Kramer, Frank
AU  - Kramer F
AD  - IT-Infrastructure for Translational Medical Research, University of Augsburg, 
      Germany.
FAU - Müller, Dominik
AU  - Müller D
AD  - IT-Infrastructure for Translational Medical Research, University of Augsburg, 
      Germany.
AD  - Institute for Digital Medicine, University Hospital Augsburg, Germany.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - IM
MH  - *Glioblastoma/diagnostic imaging
MH  - Humans
MH  - *Deep Learning
MH  - *Magnetic Resonance Imaging/methods
MH  - *Brain Neoplasms/diagnostic imaging
MH  - Prognosis
MH  - Image Interpretation, Computer-Assisted/methods
OTO - NOTNLM
OT  - Deep Learning
OT  - Glioblastoma
OT  - Survival Analysis
EDAT- 2024/09/05 06:42
MHDA- 2024/09/05 06:43
CRDT- 2024/09/05 05:04
PHST- 2024/09/05 06:43 [medline]
PHST- 2024/09/05 06:42 [pubmed]
PHST- 2024/09/05 05:04 [entrez]
AID - SHTI240878 [pii]
AID - 10.3233/SHTI240878 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2024 Aug 30;317:356-365. doi: 10.3233/SHTI240878.

PMID- 40030345
OWN - NLM
STAT- MEDLINE
DCOM- 20250317
LR  - 20250318
IS  - 1558-254X (Electronic)
IS  - 0278-0062 (Linking)
VI  - 44
IP  - 3
DP  - 2025 Mar
TI  - Topicwise Separable Sentence Retrieval for Medical Report Generation.
PG  - 1505-1517
LID - 10.1109/TMI.2024.3507076 [doi]
AB  - Automated radiology reporting holds immense clinical potential in alleviating the 
      burdensome workload of radiologists and mitigating diagnostic bias. Recently, 
      retrieval-based report generation methods have garnered increasing attention. 
      These methods predefine a set of candidate queries and compose reports by 
      searching for sentences in an off-the-shelf sentence gallery that best match 
      these candidate queries. However, due to the long-tail distribution of the 
      training data, these models tend to learn frequently occurring sentences and 
      topics, overlooking the rare topics. Regrettably, in many cases, the descriptions 
      of rare topics often indicate critical findings that should be mentioned in the 
      report. To address this problem, we introduce a Topicwise Separable Sentence 
      Retrieval (Teaser) for medical report generation. To ensure comprehensive 
      learning of both common and rare topics, we categorize queries into common and 
      rare types to learn differentiated topics, and then propose Topic Contrastive 
      Loss to effectively align topics and queries in the latent space. Moreover, we 
      integrate an Abstractor module following the extraction of visual features, which 
      aids the topic decoder in gaining a deeper understanding of the visual 
      observational intent. Experiments on the MIMIC-CXR and IU X-ray datasets 
      demonstrate that Teaser surpasses state-of-the-art models, while also validating 
      its capability to effectively represent rare topics and establish more dependable 
      correspondences between queries and topics. The code is available at 
      https://github.com/CindyZJT/Teaser.git.
FAU - Zhao, Junting
AU  - Zhao J
FAU - Zhou, Yang
AU  - Zhou Y
FAU - Chen, Zhihao
AU  - Chen Z
FAU - Fu, Huazhu
AU  - Fu H
FAU - Wan, Liang
AU  - Wan L
LA  - eng
PT  - Journal Article
DEP - 20250317
PL  - United States
TA  - IEEE Trans Med Imaging
JT  - IEEE transactions on medical imaging
JID - 8310780
SB  - IM
MH  - Humans
MH  - *Natural Language Processing
MH  - Algorithms
MH  - Databases, Factual
MH  - Radiology Information Systems
MH  - Information Storage and Retrieval/methods
EDAT- 2025/03/03 18:22
MHDA- 2025/03/17 18:31
CRDT- 2025/03/03 17:16
PHST- 2025/03/17 18:31 [medline]
PHST- 2025/03/03 18:22 [pubmed]
PHST- 2025/03/03 17:16 [entrez]
AID - 10.1109/TMI.2024.3507076 [doi]
PST - ppublish
SO  - IEEE Trans Med Imaging. 2025 Mar;44(3):1505-1517. doi: 10.1109/TMI.2024.3507076. 
      Epub 2025 Mar 17.

PMID- 38682535
OWN - NLM
STAT- MEDLINE
DCOM- 20240429
LR  - 20240429
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 313
DP  - 2024 Apr 26
TI  - The Evolution of Telehealth in Heart Failure Management: The Role of Large 
      Language Models and HerzMobil as a Potential Use Case.
PG  - 228-233
LID - 10.3233/SHTI240042 [doi]
AB  - The burgeoning domain of telehealth has witnessed substantial transformation 
      through the advent of advanced technologies such as Large Language Models (LLMs). 
      This study examines the integration of LLMs in heart failure management, with a 
      focus on HerzMobil as a pioneering telehealth program. The technical 
      underpinnings of LLMs, their current applications in the medical field, and their 
      potential to enhance telehealth services, have been explored. The paper 
      highlights the benefits of LLMs in patient interaction, clinical documentation, 
      and decision-making processes. Through the HerzMobil case study, improvements in 
      patient self-management and reductions in hospital readmission rates have been 
      observed, showcasing the successful application of telehealth in chronic disease 
      management. The paper also delves into the challenges and ethical considerations 
      of LLM integration, such as data privacy, potential biases, and regulatory 
      compliance, underscoring the need for a balanced approach that prioritizes 
      patient safety and ethical standards.
FAU - Farmer, Hillary
AU  - Farmer H
AD  - Institute of Neural Engineering, Graz University of Technology, Graz, Austria.
AD  - AIT Austrian Institute of Technology, Graz & Vienna, Austria.
FAU - Kreiner, Karl
AU  - Kreiner K
AD  - AIT Austrian Institute of Technology, Graz & Vienna, Austria.
FAU - Schütz, Thomas
AU  - Schütz T
AD  - Department of Internal Medicine III, Cardiology and Angiology, Medical University 
      of Innsbruck, Innsbruck, Austria.
FAU - Pölzl, Gerhard
AU  - Pölzl G
AD  - Department of Internal Medicine III, Cardiology and Angiology, Medical University 
      of Innsbruck, Innsbruck, Austria.
FAU - Puelacher, Christian
AU  - Puelacher C
AD  - Department of Internal Medicine III, Cardiology and Angiology, Medical University 
      of Innsbruck, Innsbruck, Austria.
FAU - Schreier, Günter
AU  - Schreier G
AD  - Institute of Neural Engineering, Graz University of Technology, Graz, Austria.
AD  - AIT Austrian Institute of Technology, Graz & Vienna, Austria.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
SB  - IM
MH  - *Telemedicine
MH  - *Heart Failure/therapy
MH  - Humans
OTO - NOTNLM
OT  - Large Language Models
OT  - Natural Language Processing
OT  - Telehealth
EDAT- 2024/04/29 06:44
MHDA- 2024/04/29 14:03
CRDT- 2024/04/29 05:53
PHST- 2024/04/29 14:03 [medline]
PHST- 2024/04/29 06:44 [pubmed]
PHST- 2024/04/29 05:53 [entrez]
AID - SHTI240042 [pii]
AID - 10.3233/SHTI240042 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2024 Apr 26;313:228-233. doi: 10.3233/SHTI240042.

PMID- 31265063
OWN - NLM
STAT- MEDLINE
DCOM- 20210113
LR  - 20210113
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 26
IP  - 8-9
DP  - 2019 Aug 1
TI  - Identifying vulnerable older adult populations by contextualizing geriatric 
      syndrome information in clinical notes of electronic health records.
PG  - 787-795
LID - 10.1093/jamia/ocz093 [doi]
AB  - OBJECTIVE: Geriatric syndromes such as functional disability and lack of social 
      support are often not encoded in electronic health records (EHRs), thus obscuring 
      the identification of vulnerable older adults in need of additional medical and 
      social services. In this study, we automatically identify vulnerable older adult 
      patients with geriatric syndrome based on clinical notes extracted from an EHR 
      system, and demonstrate how contextual information can improve the process. 
      MATERIALS AND METHODS: We propose a novel end-to-end neural architecture to 
      identify sentences that contain geriatric syndromes. Our model learns a 
      representation of the sentence and augments it with contextual information: 
      surrounding sentences, the entire clinical document, and the diagnosis codes 
      associated with the document. We trained our system on annotated notes from 85 
      patients, tuned the model on another 50 patients, and evaluated its performance 
      on the rest, 50 patients. RESULTS: Contextual information improved 
      classification, with the most effective context coming from the surrounding 
      sentences. At sentence level, our best performing model achieved a micro-F1 of 
      0.605, significantly outperforming context-free baselines. At patient level, our 
      best model achieved a micro-F1 of 0.843. DISCUSSION: Our solution can be used to 
      expand the identification of vulnerable older adults with geriatric syndromes. 
      Since functional and social factors are often not captured by diagnosis codes in 
      EHRs, the automatic identification of the geriatric syndrome can reduce 
      disparities by ensuring consistent care across the older adult population. 
      CONCLUSION: EHR free-text can be used to identify vulnerable older adults with a 
      range of geriatric syndromes.
CI  - © The Author(s) 2019. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Chen, Tao
AU  - Chen T
AD  - Center for Language and Speech Processing, Johns Hopkins Whiting School of 
      Engineering, Baltimore, Maryland, USA.
FAU - Dredze, Mark
AU  - Dredze M
AD  - Department of Computer Science, Johns Hopkins Whiting School of Engineering, 
      Baltimore, Maryland, USA.
FAU - Weiner, Jonathan P
AU  - Weiner JP
AD  - Center for Population Health IT, Johns Hopkins Bloomberg School of Public Health, 
      Baltimore, Maryland, USA.
FAU - Kharrazi, Hadi
AU  - Kharrazi H
AD  - Center for Population Health IT, Johns Hopkins Bloomberg School of Public Health, 
      Baltimore, Maryland, USA.
AD  - Division of Health Sciences Informatics, Johns Hopkins School of Medicine, 
      Baltimore, Maryland, USA.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Accidental Falls/statistics & numerical data
MH  - *Aged/physiology
MH  - *Electronic Health Records
MH  - *Frail Elderly
MH  - Health Equity
MH  - Humans
MH  - International Classification of Diseases
MH  - Mobility Limitation
MH  - Models, Statistical
MH  - *Natural Language Processing
MH  - *Neural Networks, Computer
MH  - Social Support
MH  - Urinary Incontinence/epidemiology
PMC - PMC7647225
OTO - NOTNLM
OT  - clinical notes
OT  - deep neural network
OT  - electronic health records
OT  - geriatric syndrome
OT  - natural language processing
OT  - sentence classification
OT  - vulnerable geriatric population
EDAT- 2019/07/03 06:00
MHDA- 2021/01/14 06:00
PMCR- 2020/07/02
CRDT- 2019/07/03 06:00
PHST- 2019/01/11 00:00 [received]
PHST- 2019/05/12 00:00 [revised]
PHST- 2019/05/17 00:00 [accepted]
PHST- 2019/07/03 06:00 [pubmed]
PHST- 2021/01/14 06:00 [medline]
PHST- 2019/07/03 06:00 [entrez]
PHST- 2020/07/02 00:00 [pmc-release]
AID - 5527251 [pii]
AID - ocz093 [pii]
AID - 10.1093/jamia/ocz093 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2019 Aug 1;26(8-9):787-795. doi: 10.1093/jamia/ocz093.

PMID- 35297581
OWN - NLM
STAT- MEDLINE
DCOM- 20220321
LR  - 20220321
IS  - 1532-3145 (Electronic)
IS  - 0363-8715 (Linking)
VI  - 46
IP  - 2
DP  - 2022 Mar-Apr 01
TI  - T2-Fluid-Attenuated Inversion Recovery Mismatch Sign in Grade II and III Gliomas: 
      Is There a Coexisting T2-Diffusion-Weighted Imaging Mismatch?
PG  - 251-256
LID - 10.1097/RCT.0000000000001267 [doi]
AB  - OBJECTIVE: To determine whether the T2 fluid-attenuated inversion recovery 
      (T2-FLAIR) mismatch sign in diffuse gliomas is associated with an equivalent 
      pattern of disparity in signal intensities when comparing T2- and 
      diffusion-weighted imaging (DWI). METHODS: The level of correspondence between 
      T2-FLAIR and T2-DWI evaluations in 34 World Health Organization grade II/III 
      gliomas and interreader agreement among 3 neuroradiologists were assessed by 
      calculating intraclass correlation coefficient and κ statistics, respectively. 
      Tumoral apparent diffusion coefficient values were compared using t test. 
      RESULTS: There was an almost perfect correspondence between the 2 mismatch signs 
      (intraclass correlation coefficient = 0.824 [95% confidence interval, 0.68-0.91]) 
      that were associated with higher mean tumoral apparent diffusion coefficient (P < 
      0.01). Interreader agreement was substantial for T2-FLAIR (Fleiss κ = 0.724) and 
      moderate for T2-DWI comparisons (Fleiss κ = 0.589) (P < 0.001). CONCLUSIONS: The 
      T2-FLAIR mismatch sign is usually reflected by a distinct microstructural pattern 
      on DWI. The management of this tumor subtype may benefit from specifically 
      tailored imaging assessments.
CI  - Copyright © 2022 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Radović, Niko
AU  - Radović N
AD  - From the Department of Diagnostic and Interventional Radiology, Dubrava Clinical 
      Hospital, University of Zagreb School of Medicine.
FAU - Špero, Martina
AU  - Špero M
AD  - From the Department of Diagnostic and Interventional Radiology, Dubrava Clinical 
      Hospital, University of Zagreb School of Medicine.
FAU - Hrkać Pustahija, Ana
AU  - Hrkać Pustahija A
AD  - From the Department of Diagnostic and Interventional Radiology, Dubrava Clinical 
      Hospital, University of Zagreb School of Medicine.
FAU - Almahariq, Fadi
AU  - Almahariq F
AD  - Department of Neurosurgery, Dubrava Clinical Hospital, Zagreb, Croatia.
FAU - Srdoč, Dubravka
AU  - Srdoč D
AD  - From the Department of Diagnostic and Interventional Radiology, Dubrava Clinical 
      Hospital, University of Zagreb School of Medicine.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Comput Assist Tomogr
JT  - Journal of computer assisted tomography
JID - 7703942
SB  - IM
MH  - Diffusion Magnetic Resonance Imaging/methods
MH  - *Glioma/diagnostic imaging/pathology
MH  - Humans
MH  - *Magnetic Resonance Imaging/methods
COIS- The authors declare no conflict of interest.
EDAT- 2022/03/18 06:00
MHDA- 2022/03/22 06:00
CRDT- 2022/03/17 09:43
PHST- 2022/03/17 09:43 [entrez]
PHST- 2022/03/18 06:00 [pubmed]
PHST- 2022/03/22 06:00 [medline]
AID - 00004728-202203000-00014 [pii]
AID - 10.1097/RCT.0000000000001267 [doi]
PST - ppublish
SO  - J Comput Assist Tomogr. 2022 Mar-Apr 01;46(2):251-256. doi: 
      10.1097/RCT.0000000000001267.

PMID- 38495947
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241103
IS  - 1179-5514 (Print)
IS  - 1179-5514 (Electronic)
IS  - 1179-5514 (Linking)
VI  - 17
DP  - 2024
TI  - Benefit-Risk Assessment of ChatGPT Applications in the Field of Diabetes and 
      Metabolic Illnesses: A Qualitative Study.
PG  - 11795514241235514
LID - 10.1177/11795514241235514 [doi]
LID - 11795514241235514
AB  - BACKGROUND: The use of ChatGPT and artificial intelligence (AI) in the management 
      of metabolic and endocrine disorders presents both significant opportunities and 
      notable risks. OBJECTIVES: To investigate the benefits and risks associated with 
      the application of ChatGPT in managing diabetes and metabolic illnesses by 
      exploring the perspectives of endocrinologists and diabetologists. METHODS AND 
      MATERIALS: The study employed a qualitative research approach. A semi-structured 
      in-depth interview guide was developed. A convenience sample of 25 
      endocrinologists and diabetologists was enrolled and interviewed. All interviews 
      were audiotaped and verbatim transcribed; then, thematic analysis was used to 
      determine the themes in the data. RESULTS: The findings of the thematic analysis 
      resulted in 19 codes and 9 major themes regarding the benefits of implementing AI 
      and ChatGPT in managing diabetes and metabolic illnesses. Moreover, the extracted 
      risks of implementing AI and ChatGPT in managing diabetes and metabolic illnesses 
      were categorized into 7 themes and 14 codes. The benefits of heightened 
      diagnostic precision, tailored treatment, and efficient resource utilization have 
      potential to improve patient results. Concurrently, the identification of 
      potential challenges, such as data security concerns and the need for AI that can 
      be explained, enables stakeholders to proactively tackle these issues. 
      CONCLUSIONS: Regulatory frameworks must evolve to keep pace with the rapid 
      adoption of AI in healthcare. Sustained attention to ethical considerations, 
      including obtaining patient consent, safeguarding data privacy, ensuring 
      accountability, and promoting fairness, remains critical. Despite its potential 
      impact on the human aspect of healthcare, AI will remain an integral component of 
      patient-centered care. Striking a balance between AI-assisted decision-making and 
      human expertise is essential to uphold trust and provide comprehensive patient 
      care.
CI  - © The Author(s) 2024.
FAU - Jairoun, Ammar Abdulrahman
AU  - Jairoun AA
AUID- ORCID: 0000-0002-4471-0878
AD  - Discipline of Clinical Pharmacy, School of Pharmaceutical Sciences, Universiti 
      Sains Malaysia (USM), Pulau Pinang, Malaysia.
AD  - Health and Safety Department, Dubai Municipality, Dubai, United Arab Emirates.
FAU - Al-Hemyari, Sabaa Saleh
AU  - Al-Hemyari SS
AD  - Discipline of Clinical Pharmacy, School of Pharmaceutical Sciences, Universiti 
      Sains Malaysia (USM), Pulau Pinang, Malaysia.
AD  - Pharmacy Department, Emirates Health Services, Dubai, United Arab Emirates.
FAU - Shahwan, Moyad
AU  - Shahwan M
AD  - College of Pharmacy and Health Sciences, Ajman University, Ajman, United Arab 
      Emirates.
AD  - Centre of Medical and Bio-allied Health Sciences Research, Ajman University, 
      United Arab Emirates.
FAU - Al-Qirim, Tariq
AU  - Al-Qirim T
AD  - Faculty of Pharmacy, Al-Zaytoonah University of Jordan, Amman, Jordan.
FAU - Shahwan, Monzer
AU  - Shahwan M
AD  - Diabetes Clinic, AL-Swity Center for Dermatology and Chronic Diseases, Ramallah, 
      Palestine.
LA  - eng
PT  - Journal Article
DEP - 20240315
PL  - United States
TA  - Clin Med Insights Endocrinol Diabetes
JT  - Clinical medicine insights. Endocrinology and diabetes
JID - 101578235
PMC - PMC10943713
OAB - Regulatory frameworks must evolve to keep pace with the rapid adoption of AI in 
      healthcare. Sustained attention to ethical considerations, including obtaining 
      patient consent, safeguarding data privacy, ensuring accountability, and 
      promoting fairness, remains critical. Despite its potential impact on the human 
      aspect of healthcare, AI will remain an integral component of patient-centered 
      care. The use of ChatGPT in the management of metabolic and endocrine disorders 
      presents both significant opportunities and notable risks. The benefits of 
      heightened diagnostic precision, tailored treatment, and efficient resource 
      utilization have potential to improve patient results. Concurrently, the 
      identification of potential challenges, such as data security concerns and the 
      need for AI that can be explained, enables stakeholders to proactively tackle 
      these issues. Regulatory frameworks must evolve to keep pace with the rapid 
      adoption of AI in healthcare. Sustained attention to ethical considerations, 
      including obtaining patient consent, safeguarding data privacy, ensuring 
      accountability, and promoting fairness, remains critical. Despite its potential 
      impact on the human aspect of healthcare, AI will remain an integral component of 
      patient-centered care. Striking a balance between AI-assisted decision-making and 
      human expertise is essential to uphold trust and provide comprehensive patient 
      care.
OABL- eng
OTO - NOTNLM
OT  - ChatGPT
OT  - Diabetes
OT  - artificial intelligence
OT  - chronic diseases
OT  - data privacy
OT  - metabolic disease
COIS- The author(s) declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2024/03/18 06:44
MHDA- 2024/03/18 06:45
PMCR- 2024/03/15
CRDT- 2024/03/18 04:30
PHST- 2023/10/30 00:00 [received]
PHST- 2024/02/06 00:00 [accepted]
PHST- 2024/03/18 06:45 [medline]
PHST- 2024/03/18 06:44 [pubmed]
PHST- 2024/03/18 04:30 [entrez]
PHST- 2024/03/15 00:00 [pmc-release]
AID - 10.1177_11795514241235514 [pii]
AID - 10.1177/11795514241235514 [doi]
PST - epublish
SO  - Clin Med Insights Endocrinol Diabetes. 2024 Mar 15;17:11795514241235514. doi: 
      10.1177/11795514241235514. eCollection 2024.

PMID- 39802674
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250205
IS  - 2574-2531 (Electronic)
IS  - 2574-2531 (Linking)
VI  - 8
IP  - 1
DP  - 2025 Feb
TI  - Uncertainty estimation in diagnosis generation from large language models: 
      next-word probability is not pre-test probability.
PG  - ooae154
LID - 10.1093/jamiaopen/ooae154 [doi]
LID - ooae154
AB  - OBJECTIVE: To evaluate large language models (LLMs) for pre-test diagnostic 
      probability estimation and compare their uncertainty estimation performance with 
      a traditional machine learning classifier. MATERIALS AND METHODS: We assessed 2 
      instruction-tuned LLMs, Mistral-7B-Instruct and Llama3-70B-chat-hf, on predicting 
      binary outcomes for Sepsis, Arrhythmia, and Congestive Heart Failure (CHF) using 
      electronic health record (EHR) data from 660 patients. Three uncertainty 
      estimation methods-Verbalized Confidence, Token Logits, and LLM 
      Embedding+XGB-were compared against an eXtreme Gradient Boosting (XGB) classifier 
      trained on raw EHR data. Performance metrics included AUROC and Pearson 
      correlation between predicted probabilities. RESULTS: The XGB classifier 
      outperformed the LLM-based methods across all tasks. LLM Embedding+XGB showed the 
      closest performance to the XGB baseline, while Verbalized Confidence and Token 
      Logits underperformed. DISCUSSION: These findings, consistent across multiple 
      models and demographic groups, highlight the limitations of current LLMs in 
      providing reliable pre-test probability estimations and underscore the need for 
      improved calibration and bias mitigation strategies. Future work should explore 
      hybrid approaches that integrate LLMs with numerical reasoning modules and 
      calibrated embeddings to enhance diagnostic accuracy and ensure fairer 
      predictions across diverse populations. CONCLUSIONS: LLMs demonstrate potential 
      but currently fall short in estimating diagnostic probabilities compared to 
      traditional machine learning classifiers trained on structured EHR data. Further 
      improvements are needed for reliable clinical use.
CI  - © The Author(s) 2025. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Gao, Yanjun
AU  - Gao Y
AUID- ORCID: 0000-0002-9341-7360
AD  - Department of Biomedical Informatics, University of Colorado Anschutz Medical 
      Campus, Aurora, CO 80045, United States.
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI 53792, 
      United States.
FAU - Myers, Skatje
AU  - Myers S
AUID- ORCID: 0000-0001-9524-8436
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI 53792, 
      United States.
FAU - Chen, Shan
AU  - Chen S
AUID- ORCID: 0000-0001-7999-7410
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA 02114, United States.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA 02114, United States.
FAU - Dligach, Dmitriy
AU  - Dligach D
AUID- ORCID: 0000-0002-2585-2707
AD  - Department of Computer Science, Loyola University Chicago, Chicago, IL 60660, 
      United States.
FAU - Miller, Timothy
AU  - Miller T
AUID- ORCID: 0000-0003-4513-403X
AD  - Computational Health Informatics Program, Boston Children's Hospital, Boston, MA 
      02115, United States.
FAU - Bitterman, Danielle S
AU  - Bitterman DS
AUID- ORCID: 0000-0003-0345-2232
AD  - Artificial Intelligence in Medicine (AIM) Program, Mass General Brigham, Harvard 
      Medical School, Boston, MA 02114, United States.
AD  - Department of Radiation Oncology, Brigham and Women's Hospital/Dana-Farber Cancer 
      Institute, Boston, MA 02114, United States.
FAU - Chen, Guanhua
AU  - Chen G
AUID- ORCID: 0000-0002-9314-2037
AD  - Department of Biostatistics and Medical Informatics, University of 
      Wisconsin-Madison, Madison, WI 53792, United States.
FAU - Mayampurath, Anoop
AU  - Mayampurath A
AUID- ORCID: 0000-0002-3010-6960
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI 53792, 
      United States.
AD  - Department of Biostatistics and Medical Informatics, University of 
      Wisconsin-Madison, Madison, WI 53792, United States.
FAU - Churpek, Matthew M
AU  - Churpek MM
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI 53792, 
      United States.
FAU - Afshar, Majid
AU  - Afshar M
AUID- ORCID: 0000-0002-6368-4652
AD  - Department of Medicine, University of Wisconsin-Madison, Madison, WI 53792, 
      United States.
LA  - eng
GR  - R01 CA294033/CA/NCI NIH HHS/United States
GR  - R01 LM012973/LM/NLM NIH HHS/United States
GR  - U54 CA274516/CA/NCI NIH HHS/United States
PT  - Journal Article
DEP - 20250110
PL  - United States
TA  - JAMIA Open
JT  - JAMIA open
JID - 101730643
PMC - PMC11723528
OTO - NOTNLM
OT  - diagnostic uncertainty
OT  - electronic health records
OT  - large language models
OT  - machine learning
COIS- There are no competing interests to declare.
EDAT- 2025/01/13 06:16
MHDA- 2025/01/13 06:17
PMCR- 2025/01/10
CRDT- 2025/01/13 05:33
PHST- 2024/10/31 00:00 [received]
PHST- 2024/12/12 00:00 [revised]
PHST- 2024/12/19 00:00 [accepted]
PHST- 2025/01/13 06:17 [medline]
PHST- 2025/01/13 06:16 [pubmed]
PHST- 2025/01/13 05:33 [entrez]
PHST- 2025/01/10 00:00 [pmc-release]
AID - ooae154 [pii]
AID - 10.1093/jamiaopen/ooae154 [doi]
PST - epublish
SO  - JAMIA Open. 2025 Jan 10;8(1):ooae154. doi: 10.1093/jamiaopen/ooae154. eCollection 
      2025 Feb.

PMID- 39561363
OWN - NLM
STAT- MEDLINE
DCOM- 20241119
LR  - 20241207
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Nov 19
TI  - Mitigating Cognitive Biases in Clinical Decision-Making Through Multi-Agent 
      Conversations Using Large Language Models: Simulation Study.
PG  - e59439
LID - 10.2196/59439 [doi]
LID - e59439
AB  - BACKGROUND: Cognitive biases in clinical decision-making significantly contribute 
      to errors in diagnosis and suboptimal patient outcomes. Addressing these biases 
      presents a formidable challenge in the medical field. OBJECTIVE: This study aimed 
      to explore the role of large language models (LLMs) in mitigating these biases 
      through the use of the multi-agent framework. We simulate the clinical 
      decision-making processes through multi-agent conversation and evaluate its 
      efficacy in improving diagnostic accuracy compared with humans. METHODS: A total 
      of 16 published and unpublished case reports where cognitive biases have resulted 
      in misdiagnoses were identified from the literature. In the multi-agent 
      framework, we leveraged GPT-4 (OpenAI) to facilitate interactions among different 
      simulated agents to replicate clinical team dynamics. Each agent was assigned a 
      distinct role: (1) making the final diagnosis after considering the discussions, 
      (2) acting as a devil's advocate to correct confirmation and anchoring biases, 
      (3) serving as a field expert in the required medical subspecialty, (4) 
      facilitating discussions to mitigate premature closure bias, and (5) recording 
      and summarizing findings. We tested varying combinations of these agents within 
      the framework to determine which configuration yielded the highest rate of 
      correct final diagnoses. Each scenario was repeated 5 times for consistency. The 
      accuracy of the initial diagnoses and the final differential diagnoses were 
      evaluated, and comparisons with human-generated answers were made using the 
      Fisher exact test. RESULTS: A total of 240 responses were evaluated (3 different 
      multi-agent frameworks). The initial diagnosis had an accuracy of 0% (0/80). 
      However, following multi-agent discussions, the accuracy for the top 2 
      differential diagnoses increased to 76% (61/80) for the best-performing 
      multi-agent framework (Framework 4-C). This was significantly higher compared 
      with the accuracy achieved by human evaluators (odds ratio 3.49; P=.002). 
      CONCLUSIONS: The multi-agent framework demonstrated an ability to re-evaluate and 
      correct misconceptions, even in scenarios with misleading initial investigations. 
      In addition, the LLM-driven, multi-agent conversation framework shows promise in 
      enhancing diagnostic accuracy in diagnostically challenging medical scenarios.
CI  - ©Yuhe Ke, Rui Yang, Sui An Lie, Taylor Xin Yi Lim, Yilin Ning, Irene Li, Hairil 
      Rizal Abdullah, Daniel Shu Wei Ting, Nan Liu. Originally published in the Journal 
      of Medical Internet Research (https://www.jmir.org), 19.11.2024.
FAU - Ke, Yuhe
AU  - Ke Y
AUID- ORCID: 0000-0001-7193-4749
AD  - Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore.
AD  - Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore.
FAU - Yang, Rui
AU  - Yang R
AUID- ORCID: 0009-0006-0597-7197
AD  - Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore.
FAU - Lie, Sui An
AU  - Lie SA
AUID- ORCID: 0000-0001-8565-1934
AD  - Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore.
FAU - Lim, Taylor Xin Yi
AU  - Lim TXY
AUID- ORCID: 0000-0001-7047-3418
AD  - Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore.
FAU - Ning, Yilin
AU  - Ning Y
AUID- ORCID: 0000-0002-6758-4472
AD  - Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore.
FAU - Li, Irene
AU  - Li I
AUID- ORCID: 0000-0002-1851-5390
AD  - Information Technology Center, University of Tokyo, Tokyo, Japan.
FAU - Abdullah, Hairil Rizal
AU  - Abdullah HR
AUID- ORCID: 0000-0003-1916-0832
AD  - Department of Anesthesiology, Singapore General Hospital, Singapore, Singapore.
FAU - Ting, Daniel Shu Wei
AU  - Ting DSW
AUID- ORCID: 0000-0003-2264-7174
AD  - Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore.
AD  - Singapore Eye Research Institute, Singapore National Eye Centre, Singapore, 
      Singapore.
FAU - Liu, Nan
AU  - Liu N
AUID- ORCID: 0000-0003-3610-4883
AD  - Centre for Quantitative Medicine, Duke-NUS Medical School, Singapore, Singapore.
AD  - Institute of Data Science, National University of Singapore, Singapore, 
      Singapore.
LA  - eng
PT  - Journal Article
DEP - 20241119
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Clinical Decision-Making/methods
MH  - Cognition
MH  - Bias
MH  - Language
MH  - Computer Simulation
MH  - Diagnostic Errors/prevention & control
MH  - Communication
PMC - PMC11615553
OTO - NOTNLM
OT  - clinical decision-making
OT  - cognitive bias
OT  - generative artificial intelligence
OT  - large language model
OT  - multi-agent
COIS- Conflicts of Interest: None declared.
EDAT- 2024/11/19 22:19
MHDA- 2024/11/20 00:21
PMCR- 2024/11/19
CRDT- 2024/11/19 16:53
PHST- 2024/04/12 00:00 [received]
PHST- 2024/09/12 00:00 [accepted]
PHST- 2024/06/21 00:00 [revised]
PHST- 2024/11/20 00:21 [medline]
PHST- 2024/11/19 22:19 [pubmed]
PHST- 2024/11/19 16:53 [entrez]
PHST- 2024/11/19 00:00 [pmc-release]
AID - v26i1e59439 [pii]
AID - 10.2196/59439 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Nov 19;26:e59439. doi: 10.2196/59439.

PMID- 39649984
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 1177-5467 (Print)
IS  - 1177-5483 (Electronic)
IS  - 1177-5467 (Linking)
VI  - 18
DP  - 2024
TI  - Impact of Demographic Modifiers on Readability of Myopia Education Materials 
      Generated by Large Language Models.
PG  - 3591-3604
LID - 10.2147/OPTH.S483024 [doi]
AB  - BACKGROUND: The rise of large language models (LLM) promises to widely impact 
      healthcare providers and patients alike. As these tools reflect the biases of 
      currently available data on the internet, there is a risk that increasing LLM use 
      will proliferate these biases and affect information quality. This study aims to 
      characterize the effects of different race, ethnicity, and gender modifiers in 
      question prompts presented to three large language models (LLM) on the length and 
      readability of patient education materials about myopia. METHODS: ChatGPT, 
      Gemini, and Copilot were provided a standardized prompt incorporating demographic 
      modifiers to inquire about myopia. The races and ethnicities evaluated were 
      Asian, Black, Hispanic, Native American, and White. Gender was limited to male or 
      female. The prompt was inserted five times into new chat windows. Responses were 
      analyzed for readability by word count, Simple Measure of Gobbledygook (SMOG) 
      index, Flesch-Kincaid Grade Level, and Flesch Reading Ease score. Significant 
      differences were analyzed using two-way ANOVA on SPSS. RESULTS: A total of 150 
      responses were analyzed. There were no differences in SMOG index, Flesch-Kincaid 
      Grade Level, or Flesch Reading Ease scores between responses generated with 
      prompts containing different gender, race, or ethnicity modifiers using ChatGPT 
      or Copilot. Gemini-generated responses differed significantly in their SMOG 
      Index, Flesch-Kincaid Grade Level, and Flesch Reading Ease based on the race 
      mentioned in the prompt (p<0.05). CONCLUSION: Patient demographic information 
      impacts the reading level of educational material generated by Gemini but not by 
      ChatGPT or Copilot. As patients use LLMs to understand ophthalmologic diagnoses 
      like myopia, clinicians and users should be aware of demographic influences on 
      readability. Patient gender, race, and ethnicity may be overlooked variables 
      affecting the readability of LLM-generated education materials, which can impact 
      patient care. Future research could focus on the accuracy of generated 
      information to identify potential risks of misinformation.
CI  - © 2024 Lee et al.
FAU - Lee, Gabriela G
AU  - Lee GG
AD  - Department of Ophthalmology, Bascom Palmer Eye Institute, University of Miami 
      Miller School of Medicine, Miami, FL, USA.
FAU - Goodman, Deniz
AU  - Goodman D
AUID- ORCID: 0000-0002-7176-0694
AD  - Department of Ophthalmology, Bascom Palmer Eye Institute, University of Miami 
      Miller School of Medicine, Miami, FL, USA.
FAU - Chang, Ta Chen Peter
AU  - Chang TCP
AUID- ORCID: 0000-0003-4827-5014
AD  - Department of Ophthalmology, Bascom Palmer Eye Institute, University of Miami 
      Miller School of Medicine, Miami, FL, USA.
LA  - eng
GR  - P30 EY014801/EY/NEI NIH HHS/United States
PT  - Journal Article
DEP - 20241204
PL  - New Zealand
TA  - Clin Ophthalmol
JT  - Clinical ophthalmology (Auckland, N.Z.)
JID - 101321512
PMC - PMC11625417
OTO - NOTNLM
OT  - health literacy
OT  - large language models
OT  - readability
COIS- The author reports no conflicts of interest in this work. This paper/the abstract 
      of this paper was presented at the Association for Research in Vision and 
      Ophthalmology 2024 Conference as a poster presentation with interim findings. The 
      poster’s abstract was published in “ARVO Annual Meeting Abstracts” in 
      Investigative Ophthalmology & Visual Science June 2024, Vol.65, 352: Hyperlink 
      (https://iovs.arvojournals.org/article.aspx?articleid=2796258).
EDAT- 2024/12/09 17:33
MHDA- 2024/12/09 17:34
PMCR- 2024/12/04
CRDT- 2024/12/09 06:08
PHST- 2024/08/19 00:00 [received]
PHST- 2024/10/23 00:00 [accepted]
PHST- 2024/12/09 17:34 [medline]
PHST- 2024/12/09 17:33 [pubmed]
PHST- 2024/12/09 06:08 [entrez]
PHST- 2024/12/04 00:00 [pmc-release]
AID - 483024 [pii]
AID - 10.2147/OPTH.S483024 [doi]
PST - epublish
SO  - Clin Ophthalmol. 2024 Dec 4;18:3591-3604. doi: 10.2147/OPTH.S483024. eCollection 
      2024.

PMID- 30337903
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20200929
IS  - 1664-2295 (Print)
IS  - 1664-2295 (Electronic)
IS  - 1664-2295 (Linking)
VI  - 9
DP  - 2018
TI  - Use of an Automated Quantitative Analysis of Hippocampal Volume, Signal, and 
      Glucose Metabolism to Detect Hippocampal Sclerosis.
PG  - 820
LID - 10.3389/fneur.2018.00820 [doi]
LID - 820
AB  - Purpose: Magnetic resonance imaging (MRI) and positron emission tomography (PET) 
      with (18)F-fluorodeoxyglucose ((18)FDG) are valuable tools for evaluating 
      hippocampal sclerosis (HS); however, bias may arise during visual analyses. The 
      aim of this study was to evaluate and compare MRI and PET post-processing 
      techniques, automated quantitative hippocampal volume (Q-volume), and 
      fluid-attenuated inversion-recovery (FLAIR) signal (Q-FLAIR) and glucose 
      metabolism (Q-PET) analyses in patients with HS. Methods: We collected MRI and 
      (18)FDG-PET images from 54 patients with HS and 22 healthy controls and 
      independently performed conventional visual analyses (CVA) of PET (CVA-PET) and 
      MRI (CVA-MRI) images. During the subsequent quantitative analyses, the 
      hippocampus was segmented from the 3D T1 image, and the mean volumetric, FLAIR 
      intensity and standardized uptake value ratio (SUVR) values of the left and right 
      hippocampus were assessed in each subject. Threshold confidence levels calculated 
      from the mean volumetric, FLAIR intensity and SUVR values of the controls were 
      used to identify healthy subjects or subjects with HS. The performance of the 
      three methods was assessed using receiver operating characteristic (ROC) curves, 
      and the detection rates of CVA-MRI, CVA-PET, Q-volume, Q-FLAIR, and Q-PET were 
      statistically compared. Results: The areas under the curves (AUCs) for the 
      Q-volume, Q-FLAIR, and Q-PET ROC analyses were 0.88, 0.41, and 0.98, which 
      suggested a diagnostic method with moderate, poor, and high accuracy, 
      respectively. Although Q-PET had the highest detection rate among the two CVA 
      methods and three quantitative methods, the difference between Q-volume and Q-PET 
      did not reach statistical significance. Regarding the HS subtypes, CVA-MRI, 
      CVA-PET, Q-volume, and Q-PET had similar detection rates for type 1 HS, and Q-PET 
      was the most sensitive method for detecting types 2 and 3 HS. Conclusions: In MRI 
      or (18)FDG-PET images that have been visually assessed by experts, the 
      quantification of hippocampal volume or glucose uptake can increase the detection 
      of HS and appear to be additional valuable diagnostic tools for evaluating 
      patients with epilepsy who are suspected of having HS.
FAU - Hu, Wen-Han
AU  - Hu WH
AD  - Beijing Neurosurgical Institute, Beijing Tiantan Hospital, Capital Medical 
      University, Beijing, China.
FAU - Liu, Li-Na
AU  - Liu LN
AD  - Department of Pathology, Beijing Fengtai Hospital, Beijing, China.
FAU - Zhao, Bao-Tian
AU  - Zhao BT
AD  - Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, 
      Beijing, China.
FAU - Wang, Xiu
AU  - Wang X
AD  - Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, 
      Beijing, China.
FAU - Zhang, Chao
AU  - Zhang C
AD  - Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, 
      Beijing, China.
FAU - Shao, Xiao-Qiu
AU  - Shao XQ
AD  - Department of Neurology, Beijing Tiantan Hospital, Capital Medical University, 
      Beijing, China.
FAU - Zhang, Kai
AU  - Zhang K
AD  - Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, 
      Beijing, China.
FAU - Ma, Yan-Shan
AU  - Ma YS
AD  - Department of Neurosurgery, Beijing Fengtai Hospital, Beijing, China.
FAU - Ai, Lin
AU  - Ai L
AD  - Nuclear Medicine, Beijing Tiantan Hospital, Capital Medical University, Beijing, 
      China.
FAU - Li, Jun-Ju
AU  - Li JJ
AD  - Department of Neurosurgery, Hainan General Hospital, Haikou, China.
FAU - Zhang, Jian-Guo
AU  - Zhang JG
AD  - Beijing Neurosurgical Institute, Beijing Tiantan Hospital, Capital Medical 
      University, Beijing, China.
AD  - Department of Neurosurgery, Beijing Tiantan Hospital, Capital Medical University, 
      Beijing, China.
LA  - eng
PT  - Journal Article
DEP - 20181004
PL  - Switzerland
TA  - Front Neurol
JT  - Frontiers in neurology
JID - 101546899
PMC - PMC6180190
OTO - NOTNLM
OT  - 18FDG-PET
OT  - MRI
OT  - hippocampal sclerosis
OT  - mesial temporal lobe epilepsy
OT  - quantitative analysis
EDAT- 2018/10/20 06:00
MHDA- 2018/10/20 06:01
PMCR- 2018/10/04
CRDT- 2018/10/20 06:00
PHST- 2018/05/01 00:00 [received]
PHST- 2018/09/11 00:00 [accepted]
PHST- 2018/10/20 06:00 [entrez]
PHST- 2018/10/20 06:00 [pubmed]
PHST- 2018/10/20 06:01 [medline]
PHST- 2018/10/04 00:00 [pmc-release]
AID - 10.3389/fneur.2018.00820 [doi]
PST - epublish
SO  - Front Neurol. 2018 Oct 4;9:820. doi: 10.3389/fneur.2018.00820. eCollection 2018.

PMID- 39137028
OWN - NLM
STAT- MEDLINE
DCOM- 20240813
LR  - 20250129
IS  - 1929-0748 (Electronic)
IS  - 1929-0748 (Linking)
VI  - 13
DP  - 2024 Aug 13
TI  - Ameliorating Racial Disparities in HIV Prevention via a Nurse-Led, AI-Enhanced 
      Program for Pre-Exposure Prophylaxis Utilization Among Black Cisgender Women: 
      Protocol for a Mixed Methods Study.
PG  - e59975
LID - 10.2196/59975 [doi]
LID - e59975
AB  - BACKGROUND: HIV pre-exposure prophylaxis (PrEP) is a critical biomedical strategy 
      to prevent HIV transmission among cisgender women. Despite its proven 
      effectiveness, Black cisgender women remain significantly underrepresented 
      throughout the PrEP care continuum, facing barriers such as limited access to 
      care, medical mistrust, and intersectional racial or HIV stigma. Addressing these 
      disparities is vital to improving HIV prevention outcomes within this community. 
      On the other hand, nurse practitioners (NPs) play a pivotal role in PrEP 
      utilization but are underrepresented due to a lack of awareness, a lack of human 
      resources, and insufficient support. Equipped with the rapid evolution of 
      artificial intelligence (AI) and advanced large language models, chatbots 
      effectively facilitate health care communication and linkage to care in various 
      domains, including HIV prevention and PrEP care. OBJECTIVE: Our study harnesses 
      NPs' holistic care capabilities and the power of AI through natural language 
      processing algorithms, providing targeted, patient-centered facilitation for PrEP 
      care. Our overarching goal is to create a nurse-led, stakeholder-inclusive, and 
      AI-powered program to facilitate PrEP utilization among Black cisgender women, 
      ultimately enhancing HIV prevention efforts in this vulnerable group in 3 phases. 
      This project aims to mitigate health disparities and advance innovative, 
      technology-based solutions. METHODS: The study uses a mixed methods design 
      involving semistructured interviews with key stakeholders, including 50 
      PrEP-eligible Black women, 10 NPs, and a community advisory board representing 
      various socioeconomic backgrounds. The AI-powered chatbot is developed using 
      HumanX technology and SmartBot360's Health Insurance Portability and 
      Accountability Act-compliant framework to ensure data privacy and security. The 
      study spans 18 months and consists of 3 phases: exploration, development, and 
      evaluation. RESULTS: As of May 2024, the institutional review board protocol for 
      phase 1 has been approved. We plan to start recruitment for Black cisgender women 
      and NPs in September 2024, with the aim to collect information to understand 
      their preferences regarding chatbot development. While institutional review board 
      approval for phases 2 and 3 is still in progress, we have made significant 
      strides in networking for participant recruitment. We plan to conduct data 
      collection soon, and further updates on the recruitment and data collection 
      progress will be provided as the study advances. CONCLUSIONS: The AI-powered 
      chatbot offers a novel approach to improving PrEP care utilization among Black 
      cisgender women, with opportunities to reduce barriers to care and facilitate a 
      stigma-free environment. However, challenges remain regarding health equity and 
      the digital divide, emphasizing the need for culturally competent design and 
      robust data privacy protocols. The implications of this study extend beyond PrEP 
      care, presenting a scalable model that can address broader health disparities. 
      INTERNATIONAL REGISTERED REPORT IDENTIFIER (IRRID): PRR1-10.2196/59975.
CI  - ©Chen Zhang, Mitchell Wharton, Yu Liu. Originally published in JMIR Research 
      Protocols (https://www.researchprotocols.org), 13.08.2024.
FAU - Zhang, Chen
AU  - Zhang C
AUID- ORCID: 0000-0002-8771-561X
AD  - School of Nursing, University of Rochester, Rochester, NY, United States.
FAU - Wharton, Mitchell
AU  - Wharton M
AUID- ORCID: 0000-0002-0411-3905
AD  - School of Nursing, University of Rochester, Rochester, NY, United States.
FAU - Liu, Yu
AU  - Liu Y
AUID- ORCID: 0000-0002-2515-4431
AD  - School of Dentistry and Medicine, University of Rochester, Rochester, NY, United 
      States.
LA  - eng
PT  - Journal Article
DEP - 20240813
PL  - Canada
TA  - JMIR Res Protoc
JT  - JMIR research protocols
JID - 101599504
SB  - IM
MH  - Humans
MH  - Female
MH  - *HIV Infections/prevention & control
MH  - *Pre-Exposure Prophylaxis/methods
MH  - *Artificial Intelligence
MH  - *Black or African American
MH  - Healthcare Disparities
MH  - Adult
PMC - PMC11350295
OTO - NOTNLM
OT  - AI
OT  - AIDS
OT  - Black
OT  - Black cisgender women
OT  - Black women
OT  - HIV
OT  - HIV pre-exposure prophylaxis
OT  - HIV prevention
OT  - HumanX technology
OT  - PrEP
OT  - PrEP care
OT  - artificial intelligence
OT  - biomedical
OT  - chatbot
OT  - cisgender
OT  - effectiveness
OT  - health care interventions
OT  - medical mistrust
OT  - nurse
OT  - nurse practitioners
OT  - nurse-led
OT  - pre-exposure prophylaxis
OT  - prevention
OT  - prophylaxis
OT  - socioeconomic
OT  - women
COIS- Conflicts of Interest: None declared.
EDAT- 2024/08/13 12:41
MHDA- 2024/08/13 18:42
PMCR- 2024/08/13
CRDT- 2024/08/13 11:53
PHST- 2024/04/27 00:00 [received]
PHST- 2024/07/18 00:00 [accepted]
PHST- 2024/07/05 00:00 [revised]
PHST- 2024/08/13 18:42 [medline]
PHST- 2024/08/13 12:41 [pubmed]
PHST- 2024/08/13 11:53 [entrez]
PHST- 2024/08/13 00:00 [pmc-release]
AID - v13i1e59975 [pii]
AID - 10.2196/59975 [doi]
PST - epublish
SO  - JMIR Res Protoc. 2024 Aug 13;13:e59975. doi: 10.2196/59975.

PMID- 29140606
OWN - NLM
STAT- MEDLINE
DCOM- 20190916
LR  - 20190916
IS  - 1522-2586 (Electronic)
IS  - 1053-1807 (Linking)
VI  - 48
IP  - 1
DP  - 2018 Jul
TI  - MR textural analysis on T(2) FLAIR images for the prediction of true 
      oligodendroglioma by the 2016 WHO genetic classification.
PG  - 74-83
LID - 10.1002/jmri.25896 [doi]
AB  - BACKGROUND: The genetic status of 1p/19q is important for differentiating 
      oligodendroglioma, isocitrate-dehydrogenase (IDH)-mutant, and 1p/19q-codeleted 
      from diffuse astrocytoma, IDH-mutant according to the 2016 World Health 
      Organization (WHO) criteria. PURPOSE: To assess the value of magnetic resonance 
      textural analysis (MRTA) on T(2) fluid-attenuated inversion recovery (FLAIR) 
      images for making a genetically integrated diagnosis of true oligodendroglioma by 
      WHO guidelines. STUDY TYPE: Retrospective case control. SUBJECTS: In all, there 
      were 54 patients with a histopathological diagnosis of diffuse glioma (grade II). 
      All were tested for IDH and 1p/19q. FIELD STRENGTH/SEQUENCE: 3.0T, including T(2) 
      FLAIR sequence, axial T(1) -weighted, and T(2) -weighted sequence. ASSESSMENT: 
      MRTA on a representative tumor region of interest (ROI) was made on preoperative 
      T(2) FLAIR images around the area that had the largest diameter of solid tumor 
      using Omni Kinetics software. STATISTICAL TESTS: Differences between IDH-mutant 
      and 1p/19q-codeleted and IDH-mutant and 1p/19q-intact gliomas were analyzed by 
      the Mann-Whitney rank sum test. Receiver operating characteristic curves (ROC) 
      were created to assess MRTA diagnostic performance. Sensitivity, specificity, 
      positive predictive value (PPV), and negative predictive value (NPV) were 
      calculated with a cutoff value according to the Youden Index. RESULTS: 
      Comparisons demonstrated significant differences in kurtosis (P = 0.007), energy 
      (0.008), entropy (0.008), mean deviation (MD) (<0.001), and high gray-level run 
      emphasis (HGLRE) (0.002), cluster shade (0.025), and sum average (0.002). 
      First-order features comprising entropy (area under the curve [AUC] = 0.718, 
      sensitivity = 97.1%) and energy (0.719, 94.1%) had the highest sensitivity but 
      lower specificity (both 45%). Second-order features such as HGLRE (AUC = 0.750, 
      sensitivity = 73.5%, specificity = 80.0%) and sum average (0.751, 70.6%, 80.0%) 
      had relatively higher specificity, and all had AUC >0.7. MD had the highest 
      diagnostic performance, with AUC = 0.878, sensitivity = 94.1%, 
      specificity = 75.0%, PPV = 86.5%, and NPV = 88.2%. DATA CONCLUSION: MRTA on T(2) 
      FLAIR images may be helpful in identifying oligodendroglioma, IDH-mutant, and 
      1p/19q-codeleted. LEVEL OF EVIDENCE: 3 Technical Efficacy: Stage 2 J. Magn. 
      Reson. Imaging 2017.
CI  - © 2017 International Society for Magnetic Resonance in Medicine.
FAU - Rui, Wenting
AU  - Rui W
AD  - Department of Radiology, Huashan Hospital, Fudan University, Shanghai, P.R. 
      China.
FAU - Ren, Yan
AU  - Ren Y
AD  - Department of Radiology, Huashan Hospital, Fudan University, Shanghai, P.R. 
      China.
FAU - Wang, Yin
AU  - Wang Y
AD  - Department of Neuropathology, Huashan Hospital, Fudan University, Shanghai, P.R. 
      China.
FAU - Gao, Xinyi
AU  - Gao X
AD  - Department of Radiology, Huashan Hospital, Fudan University, Shanghai, P.R. 
      China.
FAU - Xu, Xiao
AU  - Xu X
AD  - GE Healthcare Life Sciences, GE Chinese Science and Technology Park, Shanghai, 
      P.R. China.
FAU - Yao, Zhenwei
AU  - Yao Z
AD  - Department of Radiology, Huashan Hospital, Fudan University, Shanghai, P.R. 
      China.
LA  - eng
PT  - Journal Article
DEP - 20171115
PL  - United States
TA  - J Magn Reson Imaging
JT  - Journal of magnetic resonance imaging : JMRI
JID - 9105850
RN  - EC 1.1.1.41 (Isocitrate Dehydrogenase)
SB  - IM
MH  - Adult
MH  - Area Under Curve
MH  - Astrocytoma/genetics
MH  - Biopsy
MH  - Brain Neoplasms/genetics
MH  - Case-Control Studies
MH  - Chromosomes, Human, Pair 1
MH  - Female
MH  - Glioma/diagnostic imaging
MH  - Humans
MH  - Isocitrate Dehydrogenase/genetics
MH  - *Magnetic Resonance Imaging
MH  - Male
MH  - Middle Aged
MH  - Models, Theoretical
MH  - Mutation
MH  - Observer Variation
MH  - Oligodendroglioma/*diagnostic imaging
MH  - Predictive Value of Tests
MH  - ROC Curve
MH  - Retrospective Studies
MH  - Sensitivity and Specificity
MH  - World Health Organization
MH  - Young Adult
OTO - NOTNLM
OT  - 1p/19q
OT  - IDH-mutant
OT  - T2 FLAIR
OT  - magnetic resonance textural analysis
OT  - oligodendroglioma
EDAT- 2017/11/16 06:00
MHDA- 2019/09/17 06:00
CRDT- 2017/11/16 06:00
PHST- 2017/09/16 00:00 [received]
PHST- 2017/10/30 00:00 [accepted]
PHST- 2017/11/16 06:00 [pubmed]
PHST- 2019/09/17 06:00 [medline]
PHST- 2017/11/16 06:00 [entrez]
AID - 10.1002/jmri.25896 [doi]
PST - ppublish
SO  - J Magn Reson Imaging. 2018 Jul;48(1):74-83. doi: 10.1002/jmri.25896. Epub 2017 
      Nov 15.

PMID- 38714825
OWN - NLM
STAT- MEDLINE
DCOM- 20240507
LR  - 20240510
IS  - 2045-2322 (Electronic)
IS  - 2045-2322 (Linking)
VI  - 14
IP  - 1
DP  - 2024 May 7
TI  - Orbital learning: a novel, actively orchestrated decentralised learning for 
      healthcare.
PG  - 10459
LID - 10.1038/s41598-024-60915-9 [doi]
LID - 10459
AB  - A novel collaborative and continual learning across a network of decentralised 
      healthcare units, avoiding identifiable data-sharing capacity, is proposed. 
      Currently available methodologies, such as federated learning and swarm learning, 
      have demonstrated decentralised learning. However, the majority of them face 
      shortcomings that affect their performance and accuracy. These shortcomings 
      include a non-uniform rate of data accumulation, non-uniform patient 
      demographics, biased human labelling, and erroneous or malicious training data. A 
      novel method to reduce such shortcomings is proposed in the present work through 
      selective grouping and displacing of actors in a network of many entities for 
      intra-group sharing of learning with inter-group accessibility. The proposed 
      system, known as Orbital Learning, incorporates various features from split 
      learning and ensemble learning for a robust and secure performance of supervised 
      models. A digital embodiment of the information quality and flow within a 
      decentralised network, this platform also acts as a digital twin of healthcare 
      network. An example of ECG classification for arrhythmia with 6 clients is used 
      to analyse its performance and is compared against federated learning. In this 
      example, four separate experiments are conducted with varied configurations, such 
      as varied age demographics and clients with data tampering. The results obtained 
      show an average area under receiver operating characteristic curve (AUROC) of 
      0.819 (95% CI 0.784-0.853) for orbital learning whereas 0.714 (95% CI 
      0.692-0.736) for federated learning. This result shows an increase in overall 
      performance and establishes that the proposed system can address the majority of 
      the issues faced by existing decentralised learning methodologies. Further, a 
      scalability demo conducted establishes the versatility and scalability of this 
      platform in handling state-of-the-art large language models.
CI  - © 2024. The Author(s).
FAU - Chakshu, Neeraj Kavan
AU  - Chakshu NK
AD  - Zienkiewicz Institute for Modelling, Data and AI, Bay Campus, Fabian Way, Crymlyn 
      Burrows, Swansea University, Swansea, Wales, SA1 8EN, UK.
FAU - Nithiarasu, Perumal
AU  - Nithiarasu P
AD  - Zienkiewicz Institute for Modelling, Data and AI, Bay Campus, Fabian Way, Crymlyn 
      Burrows, Swansea University, Swansea, Wales, SA1 8EN, UK. 
      p.nithiarasu@swansea.ac.uk.
LA  - eng
GR  - EP/X525637/1/EPSRC/
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240507
PL  - England
TA  - Sci Rep
JT  - Scientific reports
JID - 101563288
SB  - IM
MH  - Humans
MH  - *Delivery of Health Care
MH  - Machine Learning
PMC - PMC11076556
OTO - NOTNLM
OT  - Data privacy
OT  - Data security
OT  - Decentralised learning
OT  - Digital health
COIS- The authors declare no competing interests.
EDAT- 2024/05/08 02:06
MHDA- 2024/05/08 02:07
PMCR- 2024/05/07
CRDT- 2024/05/07 23:38
PHST- 2023/08/03 00:00 [received]
PHST- 2024/04/29 00:00 [accepted]
PHST- 2024/05/08 02:07 [medline]
PHST- 2024/05/08 02:06 [pubmed]
PHST- 2024/05/07 23:38 [entrez]
PHST- 2024/05/07 00:00 [pmc-release]
AID - 10.1038/s41598-024-60915-9 [pii]
AID - 60915 [pii]
AID - 10.1038/s41598-024-60915-9 [doi]
PST - epublish
SO  - Sci Rep. 2024 May 7;14(1):10459. doi: 10.1038/s41598-024-60915-9.

PMID- 30606727
OWN - NLM
STAT- MEDLINE
DCOM- 20200106
LR  - 20200303
IS  - 1936-959X (Electronic)
IS  - 0195-6108 (Print)
IS  - 0195-6108 (Linking)
VI  - 40
IP  - 1
DP  - 2019 Jan
TI  - "Ears of the Lynx" MRI Sign Is Associated with SPG11 and SPG15 Hereditary Spastic 
      Paraplegia.
PG  - 199-203
LID - 10.3174/ajnr.A5935 [doi]
AB  - BACKGROUND AND PURPOSE: The "ears of the lynx" MR imaging sign has been described 
      in case reports of hereditary spastic paraplegia with a thin corpus callosum, 
      mostly associated with mutations in the spatacsin vesicle trafficking associated 
      gene, causing Spastic Paraplegia type 11 (SPG11). This sign corresponds to long 
      T1 and T2 values in the forceps minor of the corpus callosum, which appears 
      hyperintense on FLAIR and hypointense on T1-weighted images. Our purpose was to 
      determine the sensitivity and specificity of the ears of the lynx MR imaging sign 
      for genetic cases compared with common potential mimics. MATERIALS AND METHODS: 
      Four independent raters, blinded to the diagnosis, determined whether the ears of 
      the lynx sign was present in each of a set of 204 single anonymized FLAIR and 
      T1-weighted MR images from 34 patients with causal mutations associated with 
      SPG11 or Spastic Paraplegia type 15 (SPG15). 34 healthy controls, and 34 patients 
      with multiple sclerosis. RESULTS: The interrater reliability for FLAIR images was 
      substantial (Cohen κ, 0.66-0.77). For these images, the sensitivity of the ears 
      of the lynx sign across raters ranged from 78.8 to 97.0 and the specificity 
      ranged from 90.9 to 100. The accuracy of the sign, measured by area under the 
      receiver operating characteristic curve, ranged from very good (87.1) to 
      excellent (93.9). CONCLUSIONS: The ears of the lynx sign on FLAIR MR imaging is 
      highly specific for the most common genetic subtypes of hereditary spastic 
      paraplegia with a thin corpus callosum. When this sign is present, there is a 
      high likelihood of a genetic mutation, particularly associated with SPG11 or 
      SPG15, even in the absence of a family history.
CI  - © 2019 by American Journal of Neuroradiology.
FAU - Pascual, B
AU  - Pascual B
AUID- ORCID: 0000-0002-4467-7406
AD  - From the Departments of Neurology (B.P., M.R.D., J.C.M.) 
      bpascual@houstonmethodist.org.
FAU - de Bot, S T
AU  - de Bot ST
AUID- ORCID: 0000-0002-3512-2468
AD  - Department of Neurology (S.T.d.B.), Leiden University Medical Centre, Leiden, the 
      Netherlands.
FAU - Daniels, M R
AU  - Daniels MR
AUID- ORCID: 0000-0003-4924-2644
AD  - From the Departments of Neurology (B.P., M.R.D., J.C.M.).
FAU - França, M C Jr
AU  - França MC Jr
AUID- ORCID: 0000-0003-0898-2419
AD  - Department of Neurology (M.C.F.), University of Campinas, Campinas, Brazil.
FAU - Toro, C
AU  - Toro C
AUID- ORCID: 0000-0001-7139-0518
AD  - National Institutes of Health Intramural Research Program (C.T., N.J.P., M.D.G.), 
      Bethesda, Maryland.
FAU - Riverol, M
AU  - Riverol M
AUID- ORCID: 0000-0002-4383-9127
AD  - Department of Neurology (M.R.), Clínica Universidad de Navarra, Pamplona, Spain.
FAU - Hedera, P
AU  - Hedera P
AUID- ORCID: 0000-0003-2699-4085
AD  - Department of Neurology (P.H.), Vanderbilt University Medical Center, Nashville, 
      Tennessee.
FAU - Bassi, M T
AU  - Bassi MT
AUID- ORCID: 0000-0002-8236-1197
AD  - Laboratory of Molecular Biology (M.T.B.), Scientific Institute Istituto di 
      Ricovero e Cura a Carattere Scientifico E. Medea, Bosisio Parini, Lecco, Italy.
FAU - Bresolin, N
AU  - Bresolin N
AUID- ORCID: 0000-0001-6694-3595
AD  - Department of Neuroscience and Mental Health (N.B.), University Hospital 
      Policlinico Ca'Granda, University of Milan, Milan, Italy.
FAU - van de Warrenburg, B P
AU  - van de Warrenburg BP
AUID- ORCID: 0000-0003-4412-1616
AD  - Department of Neurology (B.P.v.d.W.), Donders Institute for Brain, Cognition, and 
      Behaviour, Radboud University Medical Center, Nijmegen, the Netherlands.
FAU - Kremer, B
AU  - Kremer B
AUID- ORCID: 0000-0002-6569-2955
AD  - Department of Neurology (B.K.), University Medical Center Groningen, Groningen, 
      the Netherlands.
FAU - Nicolai, J
AU  - Nicolai J
AUID- ORCID: 0000-0002-4480-4583
AD  - Department of Neurology (J.N.), Maastricht University Medical Centre, Maastricht, 
      the Netherlands.
FAU - Charles, P
AU  - Charles P
AUID- ORCID: 0000-0002-3108-2171
AD  - Department of Genetics (P.C.), Hôpital Pitié-Salpêtrière, Paris, France.
FAU - Xu, J
AU  - Xu J
AUID- ORCID: 0000-0002-3463-2327
AD  - Biostatistics (J.X.).
FAU - Singh, S
AU  - Singh S
AUID- ORCID: 0000-0002-3604-2961
AD  - Radiology (S.S., S.H.F.), Houston Methodist Research Institute, Houston, Texas.
FAU - Patronas, N J
AU  - Patronas NJ
AUID- ORCID: 0000-0003-2354-2251
AD  - National Institutes of Health Intramural Research Program (C.T., N.J.P., M.D.G.), 
      Bethesda, Maryland.
FAU - Fung, S H
AU  - Fung SH
AUID- ORCID: 0000-0002-1177-682X
AD  - Radiology (S.S., S.H.F.), Houston Methodist Research Institute, Houston, Texas.
FAU - Gregory, M D
AU  - Gregory MD
AUID- ORCID: 0000-0003-3749-8343
AD  - National Institutes of Health Intramural Research Program (C.T., N.J.P., M.D.G.), 
      Bethesda, Maryland.
FAU - Masdeu, J C
AU  - Masdeu JC
AUID- ORCID: 0000-0001-9955-6954
AD  - From the Departments of Neurology (B.P., M.R.D., J.C.M.).
LA  - eng
PT  - Journal Article
PT  - Research Support, N.I.H., Intramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20190103
PL  - United States
TA  - AJNR Am J Neuroradiol
JT  - AJNR. American journal of neuroradiology
JID - 8003708
RN  - Spastic paraplegia 11, autosomal recessive
RN  - Spastic paraplegia 15, autosomal recessive
SB  - IM
MH  - Adult
MH  - Corpus Callosum/diagnostic imaging
MH  - Female
MH  - Humans
MH  - Magnetic Resonance Imaging/*methods
MH  - Male
MH  - Observer Variation
MH  - ROC Curve
MH  - Reproducibility of Results
MH  - Retinal Degeneration/*diagnostic imaging
MH  - Retrospective Studies
MH  - Sensitivity and Specificity
MH  - Spastic Paraplegia, Hereditary/*diagnostic imaging
MH  - Young Adult
PMC - PMC7048588
EDAT- 2019/01/05 06:00
MHDA- 2020/01/07 06:00
PMCR- 2020/01/01
CRDT- 2019/01/05 06:00
PHST- 2018/07/05 00:00 [received]
PHST- 2018/10/30 00:00 [accepted]
PHST- 2019/01/05 06:00 [pubmed]
PHST- 2020/01/07 06:00 [medline]
PHST- 2019/01/05 06:00 [entrez]
PHST- 2020/01/01 00:00 [pmc-release]
AID - ajnr.A5935 [pii]
AID - 18-00683 [pii]
AID - 10.3174/ajnr.A5935 [doi]
PST - ppublish
SO  - AJNR Am J Neuroradiol. 2019 Jan;40(1):199-203. doi: 10.3174/ajnr.A5935. Epub 2019 
      Jan 3.

PMID- 39398216
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241121
IS  - 2331-8422 (Electronic)
IS  - 2331-8422 (Linking)
DP  - 2024 Nov 11
TI  - The doctor will polygraph you now: ethical concerns with AI for fact-checking 
      patients.
LID - arXiv:2408.07896v2
AB  - Artificial intelligence (AI) methods have been proposed for the prediction of 
      social behaviors which could be reasonably understood from patient-reported 
      information. This raises novel ethical concerns about respect, privacy, and 
      control over patient data. Ethical concerns surrounding clinical AI systems for 
      social behavior verification can be divided into two main categories: (1) the 
      potential for inaccuracies/biases within such systems, and (2) the impact on 
      trust in patient-provider relationships with the introduction of automated AI 
      systems for "fact-checking", particularly in cases where the data/models may 
      contradict the patient. Additionally, this report simulated the misuse of a 
      verification system using patient voice samples and identified a potential LLM 
      bias against patient-reported information in favor of multi-dimensional data and 
      the outputs of other AI methods (i.e., "AI self-trust"). Finally, recommendations 
      were presented for mitigating the risk that AI verification methods will cause 
      harm to patients or undermine the purpose of the healthcare system.
FAU - Anibal, James
AU  - Anibal J
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD, USA.
AD  - Computational Health Informatics Lab, Institute of Biomedical Engineering, 
      Department of Engineering Science, University of Oxford, Oxford, UK.
FAU - Gunkel, Jasmine
AU  - Gunkel J
AD  - Department of Bioethics, National Institutes of Health (NIH), Bethesda, MD, USA.
FAU - Awan, Shaheen
AU  - Awan S
AD  - Dept. of Communication Sciences & Disorders, University of Central Florida.
FAU - Huth, Hannah
AU  - Huth H
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD, USA.
FAU - Nguyen, Hang
AU  - Nguyen H
AD  - Global Infectious Disease Program, Georgetown University, Washington DC, USA.
FAU - Le, Tram
AU  - Le T
AD  - College of Engineering, University of South Florida.
FAU - Bélisle-Pipon, Jean-Christophe
AU  - Bélisle-Pipon JC
AD  - Faculty of Health Sciences, Simon Fraser University, Burnaby, BC, Canada.
FAU - Boyer, Micah
AU  - Boyer M
AD  - USF Health Voice Center, Department of Otolaryngology-Head & Neck Surgery, 
      University of South Florida.
FAU - Hazen, Lindsey
AU  - Hazen L
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD, USA.
CN  - Bridge2AI Voice Consortium
FAU - Bensoussan, Yael
AU  - Bensoussan Y
AD  - USF Health Voice Center, Department of Otolaryngology-Head & Neck Surgery, 
      University of South Florida.
FAU - Clifton, David
AU  - Clifton D
AD  - Computational Health Informatics Lab, Institute of Biomedical Engineering, 
      Department of Engineering Science, University of Oxford, Oxford, UK.
FAU - Wood, Bradford
AU  - Wood B
AD  - Center for Interventional Oncology, Clinical Center, National Institutes of 
      Health (NIH), Bethesda, MD, USA.
LA  - eng
GR  - WT_/Wellcome Trust/United Kingdom
GR  - ZIA CL040015/ImNIH/Intramural NIH HHS/United States
GR  - ZID BC011242/ImNIH/Intramural NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20241111
PL  - United States
TA  - ArXiv
JT  - ArXiv
JID - 101759493
PMC - PMC11468487
EDAT- 2024/10/14 16:18
MHDA- 2024/10/14 16:19
PMCR- 2024/11/11
CRDT- 2024/10/14 06:42
PHST- 2024/10/14 16:18 [pubmed]
PHST- 2024/10/14 16:19 [medline]
PHST- 2024/10/14 06:42 [entrez]
PHST- 2024/11/11 00:00 [pmc-release]
AID - 2408.07896 [pii]
PST - epublish
SO  - ArXiv [Preprint]. 2024 Nov 11:arXiv:2408.07896v2.

PMID- 39836496
OWN - NLM
STAT- MEDLINE
DCOM- 20250218
LR  - 20250220
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 32
IP  - 3
DP  - 2025 Mar 1
TI  - Development of secure infrastructure for advancing generative artificial 
      intelligence research in healthcare at an academic medical center.
PG  - 586-588
LID - 10.1093/jamia/ocaf005 [doi]
AB  - BACKGROUND: Generative AI, particularly large language models (LLMs), holds great 
      potential for improving patient care and operational efficiency in healthcare. 
      However, the use of LLMs is complicated by regulatory concerns around data 
      security and patient privacy. This study aimed to develop and evaluate a secure 
      infrastructure that allows researchers to safely leverage LLMs in healthcare 
      while ensuring HIPAA compliance and promoting equitable AI. MATERIALS AND 
      METHODS: We implemented a private Azure OpenAI Studio deployment with secure 
      API-enabled endpoints for researchers. Two use cases were explored, detecting 
      falls from electronic health records (EHR) notes and evaluating bias in mental 
      health prediction using fairness-aware prompts. RESULTS: The framework provided 
      secure, HIPAA-compliant API access to LLMs, allowing researchers to handle 
      sensitive data safely. Both use cases highlighted the secure infrastructure's 
      capacity to protect sensitive patient data while supporting innovation. 
      DISCUSSION AND CONCLUSION: This centralized platform presents a scalable, secure, 
      and HIPAA-compliant solution for healthcare institutions aiming to integrate LLMs 
      into clinical research.
CI  - © The Author(s) 2025. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Ng, Madelena Y
AU  - Ng MY
AUID- ORCID: 0000-0003-3824-9349
AD  - Department of Medicine, Stanford University, Stanford, CA 94305, United States.
FAU - Helzer, Jarrod
AU  - Helzer J
AD  - Technology and Digital Solutions, Stanford Health Care, Stanford, CA 94305, 
      United States.
FAU - Pfeffer, Michael A
AU  - Pfeffer MA
AUID- ORCID: 0000-0002-8958-0843
AD  - Department of Medicine, Stanford University, Stanford, CA 94305, United States.
AD  - Technology and Digital Solutions, Stanford Health Care, Stanford, CA 94305, 
      United States.
FAU - Seto, Tina
AU  - Seto T
AUID- ORCID: 0000-0002-7937-9564
AD  - Technology and Digital Solutions, Stanford Health Care, Stanford, CA 94305, 
      United States.
FAU - Hernandez-Boussard, Tina
AU  - Hernandez-Boussard T
AUID- ORCID: 0000-0001-6553-3455
AD  - Department of Medicine, Stanford University, Stanford, CA 94305, United States.
AD  - Department of Biomedical Data Sciences, Stanford University, Stanford, CA 94305, 
      United States.
AD  - Department of Surgery, Stanford University, Stanford, CA 94305, United States.
LA  - eng
GR  - R01 HS027434/HS/AHRQ HHS/United States
GR  - NH/NIH HHS/United States
GR  - AHRQ/
GR  - R01HS027434/Agency for Health Research & Quality/
GR  - 1UM1TR004921/NH/NIH HHS/United States
GR  - UM1 TR004921/TR/NCATS NIH HHS/United States
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
UOF - Res Sq. 2024 Sep 24:rs.3.rs-5095287. doi: 10.21203/rs.3.rs-5095287/v1. PMID: 
      39399679
MH  - *Electronic Health Records
MH  - *Computer Security
MH  - *Academic Medical Centers
MH  - *Artificial Intelligence
MH  - Humans
MH  - *Health Insurance Portability and Accountability Act
MH  - United States
MH  - Confidentiality
MH  - Biomedical Research
PMC - PMC11833461
OTO - NOTNLM
OT  - artificial intelligence
OT  - healthcare informatics infrastructure
OT  - large language models
OT  - large-scale research
OT  - privacy
OT  - security
OT  - technology adoption
COIS- None declared.
EDAT- 2025/01/22 05:32
MHDA- 2025/02/18 12:26
PMCR- 2025/01/21
CRDT- 2025/01/21 12:23
PHST- 2024/09/25 00:00 [received]
PHST- 2024/12/27 00:00 [revised]
PHST- 2025/01/09 00:00 [accepted]
PHST- 2025/02/18 12:26 [medline]
PHST- 2025/01/22 05:32 [pubmed]
PHST- 2025/01/21 12:23 [entrez]
PHST- 2025/01/21 00:00 [pmc-release]
AID - 7965840 [pii]
AID - ocaf005 [pii]
AID - 10.1093/jamia/ocaf005 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2025 Mar 1;32(3):586-588. doi: 10.1093/jamia/ocaf005.

PMID- 39357045
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241019
IS  - 2817-1705 (Electronic)
IS  - 2817-1705 (Linking)
VI  - 3
DP  - 2024 Oct 2
TI  - Leveraging Temporal Trends for Training Contextual Word Embeddings to Address 
      Bias in Biomedical Applications: Development Study.
PG  - e49546
LID - 10.2196/49546 [doi]
LID - e49546
AB  - BACKGROUND: Women have been underrepresented in clinical trials for many years. 
      Machine-learning models trained on clinical trial abstracts may capture and 
      amplify biases in the data. Specifically, word embeddings are models that enable 
      representing words as vectors and are the building block of most natural language 
      processing systems. If word embeddings are trained on clinical trial abstracts, 
      predictive models that use the embeddings will exhibit gender performance gaps. 
      OBJECTIVE: We aim to capture temporal trends in clinical trials through temporal 
      distribution matching on contextual word embeddings (specifically, BERT) and 
      explore its effect on the bias manifested in downstream tasks. METHODS: We 
      present TeDi-BERT, a method to harness the temporal trend of increasing women's 
      inclusion in clinical trials to train contextual word embeddings. We implement 
      temporal distribution matching through an adversarial classifier, trying to 
      distinguish old from new clinical trial abstracts based on their embeddings. The 
      temporal distribution matching acts as a form of domain adaptation from older to 
      more recent clinical trials. We evaluate our model on 2 clinical tasks: 
      prediction of unplanned readmission to the intensive care unit and hospital 
      length of stay prediction. We also conduct an algorithmic analysis of the 
      proposed method. RESULTS: In readmission prediction, TeDi-BERT achieved area 
      under the receiver operating characteristic curve of 0.64 for female patients 
      versus the baseline of 0.62 (P<.001), and 0.66 for male patients versus the 
      baseline of 0.64 (P<.001). In the length of stay regression, TeDi-BERT achieved a 
      mean absolute error of 4.56 (95% CI 4.44-4.68) for female patients versus 4.62 
      (95% CI 4.50-4.74, P<.001) and 4.54 (95% CI 4.44-4.65) for male patients versus 
      4.6 (95% CI 4.50-4.71, P<.001). CONCLUSIONS: In both clinical tasks, TeDi-BERT 
      improved performance for female patients, as expected; but it also improved 
      performance for male patients. Our results show that accuracy for one gender does 
      not need to be exchanged for bias reduction, but rather that good science 
      improves clinical results for all. Contextual word embedding models trained to 
      capture temporal trends can help mitigate the effects of bias that changes over 
      time in the training data.
CI  - ©Shunit Agmon, Uriel Singer, Kira Radinsky. Originally published in JMIR AI 
      (https://ai.jmir.org), 02.10.2024.
FAU - Agmon, Shunit
AU  - Agmon S
AUID- ORCID: 0000-0001-9605-4131
AD  - Department of Computer Science, Technion-Israel Institute of Technology, Haifa, 
      Israel.
FAU - Singer, Uriel
AU  - Singer U
AUID- ORCID: 0000-0001-8451-8533
AD  - Department of Computer Science, Technion-Israel Institute of Technology, Haifa, 
      Israel.
FAU - Radinsky, Kira
AU  - Radinsky K
AUID- ORCID: 0009-0007-7918-2204
AD  - Department of Computer Science, Technion-Israel Institute of Technology, Haifa, 
      Israel.
LA  - eng
PT  - Journal Article
DEP - 20241002
PL  - Canada
TA  - JMIR AI
JT  - JMIR AI
JID - 9918645789006676
PMC - PMC11483253
OTO - NOTNLM
OT  - BERT
OT  - NLP
OT  - algorithms
OT  - bias
OT  - gender
OT  - natural language processing
OT  - statistical models
OT  - word embeddings
COIS- Conflicts of Interest: None declared.
EDAT- 2024/10/02 19:00
MHDA- 2024/10/02 19:01
PMCR- 2024/10/02
CRDT- 2024/10/02 16:53
PHST- 2023/06/02 00:00 [received]
PHST- 2024/07/28 00:00 [accepted]
PHST- 2023/12/31 00:00 [revised]
PHST- 2024/10/02 19:01 [medline]
PHST- 2024/10/02 19:00 [pubmed]
PHST- 2024/10/02 16:53 [entrez]
PHST- 2024/10/02 00:00 [pmc-release]
AID - v3i1e49546 [pii]
AID - 10.2196/49546 [doi]
PST - epublish
SO  - JMIR AI. 2024 Oct 2;3:e49546. doi: 10.2196/49546.

PMID- 38644430
OWN - NLM
STAT- MEDLINE
DCOM- 20240423
LR  - 20240524
IS  - 2589-0409 (Electronic)
IS  - 1110-0362 (Linking)
VI  - 36
IP  - 1
DP  - 2024 Apr 22
TI  - Radio-anatomical evaluation of clinical and radiomic profile of multi-parametric 
      magnetic resonance imaging of de novo glioblastoma multiforme.
PG  - 13
LID - 10.1186/s43046-024-00217-3 [doi]
AB  - BACKGROUND: Glioblastoma (GBM) is a fatal, fast-growing, and aggressive brain 
      tumor arising from glial cells or their progenitors. It is a primary malignancy 
      with a poor prognosis. The current study aims at evaluating the neuroradiological 
      parameters of de novo GBM by analyzing the brain multi-parametric magnetic 
      resonance imaging (mpMRI) scans acquired from a publicly available database 
      analysis of the scans. METHODS: The dataset used was the mpMRI scans for de novo 
      glioblastoma (GBM) patients from the University of Pennsylvania Health System, 
      called the UPENN-GBM dataset. This was a collection from The Cancer Imaging 
      Archive (TCIA), a part of the National Cancer Institute. The MRIs were reviewed 
      by a single diagnostic radiologist, and the tumor parameters were recorded, 
      wherein all recorded data was corroborated with the clinical findings. RESULTS: 
      The study included a total of 58 subjects who were predominantly male 
      (male:female ratio of 1.07:1). The mean age with SD was 58.49 (11.39) years. Mean 
      survival days with SD were 347 (416.21) days. The left parietal lobe was the most 
      commonly found tumor location with 11 (18.96%) patients. The mean intensity for 
      T1, T2, and FLAIR with SD was 1.45E + 02 (20.42), 1.11E + 02 (17.61), and 141.64 
      (30.67), respectively (p =  < 0.001). The tumor dimensions of anteroposterior, 
      transverse, and craniocaudal gave a z-score (significance level = 0.05) of - 2.53 
      (p = 0.01), - 3.89 (p < 0.001), and 1.53 (p = 0.12), respectively. CONCLUSION: 
      The current study takes a third-party database and reduces physician bias from 
      interfering with study findings. Further prospective and retrospective studies 
      are needed to provide conclusive data.
CI  - © 2024. The Author(s).
FAU - Ahmed, H Shafeeq
AU  - Ahmed HS
AUID- ORCID: 0000-0003-1671-8474
AD  - Department of Radio-Diagnosis, Bangalore Medical College and Research Institute, 
      Bangalore, 560002, India. shafeeqahmed2002@gmail.com.
AD  - Department of Anatomy, Bangalore Medical College and Research Institute, 
      Karnataka, Bangalore, 560002, India. shafeeqahmed2002@gmail.com.
FAU - Devaraj, Trupti
AU  - Devaraj T
AD  - Department of Radio-Diagnosis, Bangalore Medical College and Research Institute, 
      Bangalore, 560002, India.
FAU - Singhvi, Maanini
AU  - Singhvi M
AD  - Department of Radio-Diagnosis, Bangalore Medical College and Research Institute, 
      Bangalore, 560002, India.
AD  - Department of Anatomy, Bangalore Medical College and Research Institute, 
      Karnataka, Bangalore, 560002, India.
FAU - Dasan, T Arul
AU  - Dasan TA
AD  - Department of Radio-Diagnosis, Bangalore Medical College and Research Institute, 
      Bangalore, 560002, India.
FAU - Ranganath, Priya
AU  - Ranganath P
AD  - Department of Anatomy, Bangalore Medical College and Research Institute, 
      Karnataka, Bangalore, 560002, India.
LA  - eng
PT  - Journal Article
DEP - 20240422
PL  - England
TA  - J Egypt Natl Canc Inst
JT  - Journal of the Egyptian National Cancer Institute
JID - 9424566
SB  - IM
MH  - Humans
MH  - *Glioblastoma/diagnostic imaging/pathology
MH  - Male
MH  - Female
MH  - Middle Aged
MH  - *Brain Neoplasms/diagnostic imaging/pathology
MH  - Aged
MH  - Adult
MH  - Multiparametric Magnetic Resonance Imaging
MH  - Magnetic Resonance Imaging/methods
MH  - Prognosis
MH  - Retrospective Studies
MH  - Radiomics
OTO - NOTNLM
OT  - Glioblastoma
OT  - MRI
OT  - Neuro-oncology
OT  - Neurology
OT  - Radiology
EDAT- 2024/04/22 00:42
MHDA- 2024/04/23 15:51
CRDT- 2024/04/21 23:09
PHST- 2023/07/18 00:00 [received]
PHST- 2024/03/06 00:00 [accepted]
PHST- 2024/04/23 15:51 [medline]
PHST- 2024/04/22 00:42 [pubmed]
PHST- 2024/04/21 23:09 [entrez]
AID - 10.1186/s43046-024-00217-3 [pii]
AID - 10.1186/s43046-024-00217-3 [doi]
PST - epublish
SO  - J Egypt Natl Canc Inst. 2024 Apr 22;36(1):13. doi: 10.1186/s43046-024-00217-3.

PMID- 31200151
OWN - NLM
STAT- MEDLINE
DCOM- 20200625
LR  - 20240922
IS  - 2213-1582 (Electronic)
IS  - 2213-1582 (Linking)
VI  - 23
DP  - 2019
TI  - White matter hyperintensity quantification in large-scale clinical acute ischemic 
      stroke cohorts - The MRI-GENIE study.
PG  - 101884
LID - S2213-1582(19)30234-7 [pii]
LID - 10.1016/j.nicl.2019.101884 [doi]
LID - 101884
AB  - White matter hyperintensity (WMH) burden is a critically important 
      cerebrovascular phenotype linked to prediction of diagnosis and prognosis of 
      diseases, such as acute ischemic stroke (AIS). However, current approaches to its 
      quantification on clinical MRI often rely on time intensive manual delineation of 
      the disease on T2 fluid attenuated inverse recovery (FLAIR), which hinders 
      high-throughput analyses such as genetic discovery. In this work, we present a 
      fully automated pipeline for quantification of WMH in clinical large-scale 
      studies of AIS. The pipeline incorporates automated brain extraction, intensity 
      normalization and WMH segmentation using spatial priors. We first propose a brain 
      extraction algorithm based on a fully convolutional deep learning architecture, 
      specifically designed for clinical FLAIR images. We demonstrate that our method 
      for brain extraction outperforms two commonly used and publicly available methods 
      on clinical quality images in a set of 144 subject scans across 12 acquisition 
      centers, based on dice coefficient (median 0.95; inter-quartile range 0.94-0.95; 
      p < 0.01) and Pearson correlation of total brain volume (r = 0.90). Subsequently, 
      we apply it to the large-scale clinical multi-site MRI-GENIE study (N = 2783) and 
      identify a decrease in total brain volume of -2.4 cc/year. Additionally, we show 
      that the resulting total brain volumes can successfully be used for quality 
      control of image preprocessing. Finally, we obtain WMH volumes by building on an 
      existing automatic WMH segmentation algorithm that delineates and distinguishes 
      between different cerebrovascular pathologies. The learning method mimics expert 
      knowledge of the spatial distribution of the WMH burden using a convolutional 
      auto-encoder. This enables successful computation of WMH volumes of 2533 clinical 
      AIS patients. We utilize these results to demonstrate the increase of WMH burden 
      with age (0.950 cc/year) and show that single site estimates can be biased by the 
      number of subjects recruited.
CI  - Copyright © 2019 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Schirmer, Markus D
AU  - Schirmer MD
AD  - Department of Neurology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA; Computer Science and Artificial Intelligence Lab, MIT, USA; 
      Department of Population Health Sciences, German Centre for Neurodegenerative 
      Diseases (DZNE), Germany. Electronic address: mschirmer1@mgh.harvard.edu.
FAU - Dalca, Adrian V
AU  - Dalca AV
AD  - Computer Science and Artificial Intelligence Lab, MIT, USA; Athinoula A. Martinos 
      Center for Biomedical Imaging, Department of Radiology, Massachusetts General 
      Hospital, Charlestown, MA, USA.
FAU - Sridharan, Ramesh
AU  - Sridharan R
AD  - Computer Science and Artificial Intelligence Lab, MIT, USA.
FAU - Giese, Anne-Katrin
AU  - Giese AK
AD  - Department of Neurology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA; Program in Medical and Population Genetics, Broad Institute of 
      MIT and Harvard, Cambridge, MA, USA.
FAU - Donahue, Kathleen L
AU  - Donahue KL
AD  - Department of Neurology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA.
FAU - Nardin, Marco J
AU  - Nardin MJ
AD  - Department of Neurology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA.
FAU - Mocking, Steven J T
AU  - Mocking SJT
AD  - Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, 
      Massachusetts General Hospital, Charlestown, MA, USA.
FAU - McIntosh, Elissa C
AU  - McIntosh EC
AD  - Athinoula A. Martinos Center for Biomedical Imaging, Department of Radiology, 
      Massachusetts General Hospital, Charlestown, MA, USA.
FAU - Frid, Petrea
AU  - Frid P
AD  - Department of Clinical Sciences Lund, Neurology, Lund University, Lund, Sweden.
FAU - Wasselius, Johan
AU  - Wasselius J
AD  - Department of Clinical Sciences Lund, Radiology, Lund University, Lund, Sweden; 
      Department of Radiology, Neuroradiology, Skåne University Hospital, Malmö, 
      Sweden.
FAU - Cole, John W
AU  - Cole JW
AD  - Department of Neurology, University of Maryland School of Medicine and Veterans 
      Affairs Maryland Health Care System, Baltimore, MD, USA.
FAU - Holmegaard, Lukas
AU  - Holmegaard L
AD  - Institute of Neuroscience and Physiology, the Sahlgrenska Academy at University 
      of Gothenburg, Gothenburg, Sweden.
FAU - Jern, Christina
AU  - Jern C
AD  - Institute of Biomedicine, the Sahlgrenska Academy at University of Gothenburg, 
      Gothenburg, Sweden.
FAU - Jimenez-Conde, Jordi
AU  - Jimenez-Conde J
AD  - Department of Neurology, Neurovascular Research Group (NEUVAS), IMIM-Hospital del 
      Mar (Institut Hospital del Mar d'Investigacions Mèdiques), Universitat Autonoma 
      de Barcelona, Barcelona, Spain.
FAU - Lemmens, Robin
AU  - Lemmens R
AD  - Department of Neurosciences, Experimental Neurology and Leuven Research Institute 
      for Neuroscience and Disease (LIND), KU Leuven - University of Leuven, Leuven, 
      Belgium; VIB, Vesalius Research Center, Laboratory of Neurobiology, Department of 
      Neurology, University Hospitals Leuven, Leuven, Belgium.
FAU - Lindgren, Arne G
AU  - Lindgren AG
AD  - Department of Clinical Sciences Lund, Neurology, Lund University, Lund, Sweden; 
      Department of Neurology and Rehabilitation Medicine, Skåne University Hospital, 
      Lund, Sweden.
FAU - Meschia, James F
AU  - Meschia JF
AD  - Department of Neurology, Mayo Clinic, Jacksonville, FL, USA.
FAU - Roquer, Jaume
AU  - Roquer J
AD  - Department of Neurology, Neurovascular Research Group (NEUVAS), IMIM-Hospital del 
      Mar (Institut Hospital del Mar d'Investigacions Mèdiques), Universitat Autonoma 
      de Barcelona, Barcelona, Spain.
FAU - Rundek, Tatjana
AU  - Rundek T
AD  - Department of Neurology, Miller School of Medicine, University of Miami, Miami, 
      FL, USA.
FAU - Sacco, Ralph L
AU  - Sacco RL
AD  - Department of Neurology, Miller School of Medicine, University of Miami, Miami, 
      FL, USA.
FAU - Schmidt, Reinhold
AU  - Schmidt R
AD  - Department of Neurology, Clinical Division of Neurogeriatrics, Medical University 
      Graz, Graz, Austria.
FAU - Sharma, Pankaj
AU  - Sharma P
AD  - Institute of Cardiovascular Research, St Peter's and Ashford Hospitals, Royal 
      Holloway University of London (ICR2UL), Egham, UK.
FAU - Slowik, Agnieszka
AU  - Slowik A
AD  - Department of Neurology, Jagiellonian University Medical College, Krakow, Poland.
FAU - Thijs, Vincent
AU  - Thijs V
AD  - Stroke Division, Australia and Department of Neurology, Austin Health, Florey 
      Institute of Neuroscience and Mental Health, Heidelberg, Australia.
FAU - Woo, Daniel
AU  - Woo D
AD  - Department of Neurology and Rehabilitation Medicine, University of Cincinnati 
      College of Medicine, Cincinnati, OH, USA.
FAU - Vagal, Achala
AU  - Vagal A
AD  - Department of Radiology, University of Cincinnati College of Medicine, 
      Cincinnati, OH, USA.
FAU - Xu, Huichun
AU  - Xu H
AD  - Division of Endocrinology, Diabetes and Nutrition, Department of Medicine, 
      University of Maryland School of Medicine, Baltimore, MD, USA.
FAU - Kittner, Steven J
AU  - Kittner SJ
AD  - Department of Neurology, University of Maryland School of Medicine and Veterans 
      Affairs Maryland Health Care System, Baltimore, MD, USA.
FAU - McArdle, Patrick F
AU  - McArdle PF
AD  - Division of Endocrinology, Diabetes and Nutrition, Department of Medicine, 
      University of Maryland School of Medicine, Baltimore, MD, USA.
FAU - Mitchell, Braxton D
AU  - Mitchell BD
AD  - Division of Endocrinology, Diabetes and Nutrition, Department of Medicine, 
      University of Maryland School of Medicine, Baltimore, MD, USA.
FAU - Rosand, Jonathan
AU  - Rosand J
AD  - Department of Neurology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA; Athinoula A. Martinos Center for Biomedical Imaging, Department 
      of Radiology, Massachusetts General Hospital, Charlestown, MA, USA; Center for 
      Human Genetic Research, Massachusetts General Hospital, Boston, MA, USA.
FAU - Worrall, Bradford B
AU  - Worrall BB
AD  - Departments of Neurology and Public Health Sciences, University of Virginia, 
      Charlottesville, VA, USA.
FAU - Wu, Ona
AU  - Wu O
AD  - Department of Neurology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA; Athinoula A. Martinos Center for Biomedical Imaging, Department 
      of Radiology, Massachusetts General Hospital, Charlestown, MA, USA.
FAU - Golland, Polina
AU  - Golland P
AD  - Computer Science and Artificial Intelligence Lab, MIT, USA.
FAU - Rost, Natalia S
AU  - Rost NS
AD  - Department of Neurology, Massachusetts General Hospital, Harvard Medical School, 
      Boston, MA, USA.
CN  - MRI-GENIE Investigators
LA  - eng
GR  - K23 NS064052/NS/NINDS NIH HHS/United States
GR  - R01 NS082285/NS/NINDS NIH HHS/United States
GR  - P50 NS051343/NS/NINDS NIH HHS/United States
GR  - R01 NS063925/NS/NINDS NIH HHS/United States
GR  - P41 EB015902/EB/NIBIB NIH HHS/United States
GR  - R01 NS059775/NS/NINDS NIH HHS/United States
GR  - R01 NS100178/NS/NINDS NIH HHS/United States
GR  - R01 NS086905/NS/NINDS NIH HHS/United States
GR  - P30 DK072488/DK/NIDDK NIH HHS/United States
GR  - U01 NS069208/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20190529
PL  - Netherlands
TA  - Neuroimage Clin
JT  - NeuroImage. Clinical
JID - 101597070
SB  - IM
MH  - Adult
MH  - Aged
MH  - Aged, 80 and over
MH  - Brain Ischemia/*diagnostic imaging
MH  - Cohort Studies
MH  - Female
MH  - Humans
MH  - Magnetic Resonance Imaging/*methods
MH  - Male
MH  - Middle Aged
MH  - Neuroimaging/*methods
MH  - Stroke/*diagnostic imaging
MH  - White Matter/*diagnostic imaging
PMC - PMC6562316
EDAT- 2019/06/15 06:00
MHDA- 2020/06/26 06:00
PMCR- 2019/05/29
CRDT- 2019/06/15 06:00
PHST- 2019/02/15 00:00 [received]
PHST- 2019/05/02 00:00 [revised]
PHST- 2019/05/25 00:00 [accepted]
PHST- 2019/06/15 06:00 [pubmed]
PHST- 2020/06/26 06:00 [medline]
PHST- 2019/06/15 06:00 [entrez]
PHST- 2019/05/29 00:00 [pmc-release]
AID - S2213-1582(19)30234-7 [pii]
AID - 101884 [pii]
AID - 10.1016/j.nicl.2019.101884 [doi]
PST - ppublish
SO  - Neuroimage Clin. 2019;23:101884. doi: 10.1016/j.nicl.2019.101884. Epub 2019 May 
      29.

PMID- 38319707
OWN - NLM
STAT- MEDLINE
DCOM- 20240207
LR  - 20241028
IS  - 2368-7959 (Electronic)
IS  - 2368-7959 (Linking)
VI  - 11
DP  - 2024 Feb 6
TI  - Capacity of Generative AI to Interpret Human Emotions From Visual and Textual 
      Data: Pilot Evaluation Study.
PG  - e54369
LID - 10.2196/54369 [doi]
LID - e54369
AB  - BACKGROUND: Mentalization, which is integral to human cognitive processes, 
      pertains to the interpretation of one's own and others' mental states, including 
      emotions, beliefs, and intentions. With the advent of artificial intelligence 
      (AI) and the prominence of large language models in mental health applications, 
      questions persist about their aptitude in emotional comprehension. The prior 
      iteration of the large language model from OpenAI, ChatGPT-3.5, demonstrated an 
      advanced capacity to interpret emotions from textual data, surpassing human 
      benchmarks. Given the introduction of ChatGPT-4, with its enhanced visual 
      processing capabilities, and considering Google Bard's existing visual 
      functionalities, a rigorous assessment of their proficiency in visual mentalizing 
      is warranted. OBJECTIVE: The aim of the research was to critically evaluate the 
      capabilities of ChatGPT-4 and Google Bard with regard to their competence in 
      discerning visual mentalizing indicators as contrasted with their textual-based 
      mentalizing abilities. METHODS: The Reading the Mind in the Eyes Test developed 
      by Baron-Cohen and colleagues was used to assess the models' proficiency in 
      interpreting visual emotional indicators. Simultaneously, the Levels of Emotional 
      Awareness Scale was used to evaluate the large language models' aptitude in 
      textual mentalizing. Collating data from both tests provided a holistic view of 
      the mentalizing capabilities of ChatGPT-4 and Bard. RESULTS: ChatGPT-4, 
      displaying a pronounced ability in emotion recognition, secured scores of 26 and 
      27 in 2 distinct evaluations, significantly deviating from a random response 
      paradigm (P<.001). These scores align with established benchmarks from the 
      broader human demographic. Notably, ChatGPT-4 exhibited consistent responses, 
      with no discernible biases pertaining to the sex of the model or the nature of 
      the emotion. In contrast, Google Bard's performance aligned with random response 
      patterns, securing scores of 10 and 12 and rendering further detailed analysis 
      redundant. In the domain of textual analysis, both ChatGPT and Bard surpassed 
      established benchmarks from the general population, with their performances being 
      remarkably congruent. CONCLUSIONS: ChatGPT-4 proved its efficacy in the domain of 
      visual mentalizing, aligning closely with human performance standards. Although 
      both models displayed commendable acumen in textual emotion interpretation, 
      Bard's capabilities in visual emotion interpretation necessitate further scrutiny 
      and potential refinement. This study stresses the criticality of ethical AI 
      development for emotional recognition, highlighting the need for inclusive data, 
      collaboration with patients and mental health experts, and stringent governmental 
      oversight to ensure transparency and protect patient privacy.
CI  - ©Zohar Elyoseph, Elad Refoua, Kfir Asraf, Maya Lvovsky, Yoav Shimoni, Dorit 
      Hadar-Shoval. Originally published in JMIR Mental Health 
      (https://mental.jmir.org), 06.02.2024.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AUID- ORCID: 0000-0002-5717-4074
AD  - Department of Educational Psychology, The Center for Psychobiological Research, 
      The Max Stern Yezreel Valley College, Emek Yezreel, Israel.
AD  - Imperial College London, London, United Kingdom.
FAU - Refoua, Elad
AU  - Refoua E
AUID- ORCID: 0000-0003-1471-3573
AD  - Department of Psychology, Bar-Ilan University, Ramat Gan, Israel.
FAU - Asraf, Kfir
AU  - Asraf K
AUID- ORCID: 0009-0001-6699-3055
AD  - Department of Psychology, The Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
FAU - Lvovsky, Maya
AU  - Lvovsky M
AUID- ORCID: 0009-0009-1219-1717
AD  - Department of Psychology, The Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
FAU - Shimoni, Yoav
AU  - Shimoni Y
AUID- ORCID: 0009-0007-2834-156X
AD  - Boston Children's Hospital, Boston, MA, United States.
FAU - Hadar-Shoval, Dorit
AU  - Hadar-Shoval D
AUID- ORCID: 0000-0002-1376-3096
AD  - Department of Psychology, The Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
LA  - eng
PT  - Journal Article
DEP - 20240206
PL  - Canada
TA  - JMIR Ment Health
JT  - JMIR mental health
JID - 101658926
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Pilot Projects
MH  - *Emotions
MH  - Benchmarking
MH  - Eye
PMC - PMC10879976
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - LLM
OT  - LLMs
OT  - RMET
OT  - Reading the Mind in the Eyes Test
OT  - algorithm
OT  - algorithms
OT  - artificial intelligence
OT  - early detection
OT  - early warning
OT  - emotional awareness
OT  - emotional comprehension
OT  - emotional cue
OT  - emotional cues
OT  - empathy
OT  - large language model
OT  - large language models
OT  - machine learning
OT  - mental disease
OT  - mental diseases
OT  - mental health
OT  - mental illness
OT  - mental illnesses
OT  - mentalization
OT  - mentalizing
OT  - practical model
OT  - practical models
OT  - predictive analytics
OT  - predictive model
OT  - predictive models
OT  - predictive system
COIS- Conflicts of Interest: None declared.
EDAT- 2024/02/06 13:43
MHDA- 2024/02/07 06:42
PMCR- 2024/02/06
CRDT- 2024/02/06 11:54
PHST- 2023/11/07 00:00 [received]
PHST- 2023/12/25 00:00 [accepted]
PHST- 2023/12/09 00:00 [revised]
PHST- 2024/02/07 06:42 [medline]
PHST- 2024/02/06 13:43 [pubmed]
PHST- 2024/02/06 11:54 [entrez]
PHST- 2024/02/06 00:00 [pmc-release]
AID - v11i1e54369 [pii]
AID - 10.2196/54369 [doi]
PST - epublish
SO  - JMIR Ment Health. 2024 Feb 6;11:e54369. doi: 10.2196/54369.

PMID- 39432897
OWN - NLM
STAT- MEDLINE
DCOM- 20241021
LR  - 20241107
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Oct 21
TI  - Tracking the Spread of Pollen on Social Media Using Pollen-Related Messages From 
      Twitter: Retrospective Analysis.
PG  - e58309
LID - 10.2196/58309 [doi]
LID - e58309
AB  - BACKGROUND: Allergy disorders caused by biological particles, such as the 
      proteins in some airborne pollen grains, are currently considered one of the most 
      common chronic diseases, and European Academy of Allergy and Clinical Immunology 
      forecasts indicate that within 15 years 50% of Europeans will have some kind of 
      allergy as a consequence of urbanization, industrialization, pollution, and 
      climate change. OBJECTIVE: The aim of this study was to monitor and analyze the 
      dissemination of information about pollen symptoms from December 2006 to January 
      2022. By conducting a comprehensive evaluation of public comments and trends on 
      Twitter, the research sought to provide valuable insights into the impact of 
      pollen on sensitive individuals, ultimately enhancing our understanding of how 
      pollen-related information spreads and its implications for public health 
      awareness. METHODS: Using a blend of large language models, dimensionality 
      reduction, unsupervised clustering, and term frequency-inverse document 
      frequency, alongside visual representations such as word clouds and semantic 
      interaction graphs, our study analyzed Twitter data to uncover insights on 
      respiratory allergies. This concise methodology enabled the extraction of 
      significant themes and patterns, offering a deep dive into public knowledge and 
      discussions surrounding respiratory allergies on Twitter. RESULTS: The months 
      between March and August had the highest volume of messages. The percentage of 
      patient tweets appeared to increase notably during the later years, and there was 
      also a potential increase in the prevalence of symptoms, mainly in the morning 
      hours, indicating a potential rise in pollen allergies and related discussions on 
      social media. While pollen allergy is a global issue, specific sociocultural, 
      political, and economic contexts mean that patients experience symptomatology at 
      a localized level, needing appropriate localized responses. CONCLUSIONS: The 
      interpretation of tweet information represents a valuable tool to take preventive 
      measures to mitigate the impact of pollen allergy on sensitive patients to 
      achieve equity in living conditions and enhance access to health information and 
      services.
CI  - ©Martín Pérez-Pérez, María Fernandez Gonzalez, Francisco Javier Rodriguez-Rajo, 
      Florentino Fdez-Riverola. Originally published in the Journal of Medical Internet 
      Research (https://www.jmir.org), 21.10.2024.
FAU - Pérez-Pérez, Martín
AU  - Pérez-Pérez M
AUID- ORCID: 0000-0003-1349-6562
AD  - CINBIO, Universidade de Vigo (University of Vigo), Vigo, Spain.
AD  - Department of Computer Science, School of Computer Engineering, Universidade de 
      Vigo (University of Vigo), Ourense, Spain.
AD  - Next Generation Computer Systems Group, School of Computer Engineering, Galicia 
      Sur Health Research Institute, Galician Health Service, SERGAS-UVIGO, Ourense, 
      Spain.
FAU - Fernandez Gonzalez, María
AU  - Fernandez Gonzalez M
AUID- ORCID: 0000-0002-3775-7192
AD  - Department of Plant Biology and Soil Sciences, Faculty of Sciences, Universidade 
      de Vigo (University of Vigo), Ourense, Spain.
FAU - Rodriguez-Rajo, Francisco Javier
AU  - Rodriguez-Rajo FJ
AUID- ORCID: 0000-0001-8535-901X
AD  - Department of Plant Biology and Soil Sciences, Faculty of Sciences, Universidade 
      de Vigo (University of Vigo), Ourense, Spain.
FAU - Fdez-Riverola, Florentino
AU  - Fdez-Riverola F
AUID- ORCID: 0000-0002-3943-8013
AD  - CINBIO, Universidade de Vigo (University of Vigo), Vigo, Spain.
AD  - Department of Computer Science, School of Computer Engineering, Universidade de 
      Vigo (University of Vigo), Ourense, Spain.
AD  - Next Generation Computer Systems Group, School of Computer Engineering, Galicia 
      Sur Health Research Institute, Galician Health Service, SERGAS-UVIGO, Ourense, 
      Spain.
LA  - eng
PT  - Journal Article
DEP - 20241021
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
RN  - 0 (Allergens)
SB  - IM
MH  - *Social Media/statistics & numerical data
MH  - *Pollen/adverse effects
MH  - Humans
MH  - Retrospective Studies
MH  - Rhinitis, Allergic, Seasonal/epidemiology
MH  - Information Dissemination/methods
MH  - Allergens
PMC - PMC11535798
OTO - NOTNLM
OT  - LLM
OT  - Twitter
OT  - knowledge reconstruction
OT  - large language model
OT  - pollen
OT  - respiratory allergies
OT  - text mining
COIS- Conflicts of Interest: None declared.
EDAT- 2024/10/21 22:20
MHDA- 2024/10/22 04:57
PMCR- 2024/10/21
CRDT- 2024/10/21 16:53
PHST- 2024/03/12 00:00 [received]
PHST- 2024/09/10 00:00 [accepted]
PHST- 2024/05/27 00:00 [revised]
PHST- 2024/10/22 04:57 [medline]
PHST- 2024/10/21 22:20 [pubmed]
PHST- 2024/10/21 16:53 [entrez]
PHST- 2024/10/21 00:00 [pmc-release]
AID - v26i1e58309 [pii]
AID - 10.2196/58309 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Oct 21;26:e58309. doi: 10.2196/58309.

PMID- 38261757
OWN - NLM
STAT- MEDLINE
DCOM- 20240517
LR  - 20250103
IS  - 1537-7385 (Electronic)
IS  - 0894-9115 (Linking)
VI  - 103
IP  - 6
DP  - 2024 Jun 1
TI  - Unlocking the Black Box? A Comprehensive Exploration of Large Language Models in 
      Rehabilitation.
PG  - 532-537
LID - 10.1097/PHM.0000000000002440 [doi]
AB  - Rehabilitation is a vital component of health care, aiming to restore function 
      and improve the well-being of individuals with disabilities or injuries. 
      Nevertheless, the rehabilitation process is often likened to a " black box ," 
      with complexities that pose challenges for comprehensive analysis and 
      optimization. The emergence of large language models offers promising solutions 
      to better understand this " black box ." Large language models excel at 
      comprehending and generating human-like text, making them valuable in the 
      healthcare sector. In rehabilitation, healthcare professionals must integrate a 
      wide range of data to create effective treatment plans, akin to selecting the 
      best ingredients for the " black box. " Large language models enhance data 
      integration, communication, assessment, and prediction.This article delves into 
      the ground-breaking use of large language models as a tool to further understand 
      the rehabilitation process. Large language models address current rehabilitation 
      issues, including data bias, contextual comprehension, and ethical concerns. 
      Collaboration with healthcare experts and rigorous validation is crucial when 
      deploying large language models. Integrating large language models into 
      rehabilitation yields insights into this intricate process, enhancing data-driven 
      decision making, refining clinical practices, and predicting rehabilitation 
      outcomes. Although challenges persist, large language models represent a 
      significant stride in rehabilitation, underscoring the importance of ethical use 
      and collaboration.
CI  - Copyright © 2024 Wolters Kluwer Health, Inc. All rights reserved.
FAU - Bonnechère, Bruno
AU  - Bonnechère B
AD  - From the REVAL Rehabilitation Research Center, Faculty of Rehabilitation 
      Sciences, Hasselt University, Diepenbeek, Belgium; Technology-Supported and 
      Data-Driven Rehabilitation, Data Sciences Institute, Hasselt University, 
      Diepenbeek, Belgium; and Department of PXL-Healthcare, PXL University of Applied 
      Sciences and Arts, Hasselt, Belgium.
LA  - eng
PT  - Journal Article
DEP - 20240111
PL  - United States
TA  - Am J Phys Med Rehabil
JT  - American journal of physical medicine & rehabilitation
JID - 8803677
SB  - IM
MH  - Humans
MH  - *Rehabilitation/methods
MH  - Language
MH  - Persons with Disabilities/rehabilitation
COIS- Financial disclosure statements have been obtained, and no conflicts of interest 
      have been reported by the authors or by any individuals in control of the content 
      of this article.
EDAT- 2024/01/23 18:42
MHDA- 2024/05/17 12:44
CRDT- 2024/01/23 15:23
PHST- 2024/05/17 12:44 [medline]
PHST- 2024/01/23 18:42 [pubmed]
PHST- 2024/01/23 15:23 [entrez]
AID - 00002060-990000000-00399 [pii]
AID - 10.1097/PHM.0000000000002440 [doi]
PST - ppublish
SO  - Am J Phys Med Rehabil. 2024 Jun 1;103(6):532-537. doi: 
      10.1097/PHM.0000000000002440. Epub 2024 Jan 11.

PMID- 38388855
OWN - NLM
STAT- MEDLINE
DCOM- 20241108
LR  - 20241111
IS  - 1573-1677 (Electronic)
IS  - 1382-4996 (Print)
IS  - 1382-4996 (Linking)
VI  - 29
IP  - 5
DP  - 2024 Nov
TI  - Assessing supervisor versus trainee viewpoints of entrustment through cognitive 
      and affective lenses: an artificial intelligence investigation of bias in 
      feedback.
PG  - 1571-1592
LID - 10.1007/s10459-024-10311-9 [doi]
AB  - The entrustment framework redirects assessment from considering only trainees' 
      competence to decision-making about their readiness to perform clinical tasks 
      independently. Since trainees and supervisors both contribute to entrustment 
      decisions, we examined the cognitive and affective factors that underly their 
      negotiation of trust, and whether trainee demographic characteristics may bias 
      them. Using a document analysis approach, we adapted large language models (LLMs) 
      to examine feedback dialogs (N = 24,187, each with an associated entrustment 
      rating) between medical student trainees and their clinical supervisors. We 
      compared how trainees and supervisors differentially documented feedback dialogs 
      about similar tasks by identifying qualitative themes and quantitatively 
      assessing their correlation with entrustment ratings. Supervisors' themes 
      predominantly reflected skills related to patient presentations, while trainees' 
      themes were broader-including clinical performance and personal qualities. To 
      examine affect, we trained an LLM to measure feedback sentiment. On average, 
      trainees used more negative language (5.3% lower probability of positive 
      sentiment, p < 0.05) compared to supervisors, while documenting higher 
      entrustment ratings (+ 0.08 on a 1-4 scale, p < 0.05). We also found biases tied 
      to demographic characteristics: trainees' documentation reflected more positive 
      sentiment in the case of male trainees (+ 1.3%, p < 0.05) and of trainees 
      underrepresented in medicine (UIM) (+ 1.3%, p < 0.05). Entrustment ratings did 
      not appear to reflect these biases, neither when documented by trainee nor 
      supervisor. As such, bias appeared to influence the emotive language trainees 
      used to document entrustment more than the degree of entrustment they 
      experienced. Mitigating these biases is nonetheless important because they may 
      affect trainees' assimilation into their roles and formation of trusting 
      relationships.
CI  - © 2024. The Author(s).
FAU - Gin, Brian C
AU  - Gin BC
AUID- ORCID: 0000-0001-7655-3750
AD  - Department of Pediatrics, University of California San Francisco, 550 16th St 
      Floor 4, UCSF Box 0110, San Francisco, CA, 94158, USA. brian.gin@ucsf.edu.
FAU - Ten Cate, Olle
AU  - Ten Cate O
AUID- ORCID: 0000-0002-6379-8780
AD  - Utrecht Center for Research and Development of Health Professions Education, 
      University Medical Center, Utrecht, the Netherlands.
AD  - Department of Medicine, University of California San Francisco, San Francisco, 
      USA.
FAU - O'Sullivan, Patricia S
AU  - O'Sullivan PS
AUID- ORCID: 0000-0002-8706-4095
AD  - Department of Medicine, University of California San Francisco, San Francisco, 
      USA.
AD  - Department of Surgery, University of California San Francisco, San Francisco, 
      USA.
FAU - Boscardin, Christy
AU  - Boscardin C
AUID- ORCID: 0000-0002-9070-8859
AD  - Department of Medicine, University of California San Francisco, San Francisco, 
      USA.
AD  - Department of Anesthesia, University of California San Francisco, San Francisco, 
      USA.
LA  - eng
PT  - Journal Article
DEP - 20240223
PL  - Netherlands
TA  - Adv Health Sci Educ Theory Pract
JT  - Advances in health sciences education : theory and practice
JID - 9612021
SB  - IM
MH  - Humans
MH  - *Trust
MH  - *Clinical Competence
MH  - *Students, Medical/psychology
MH  - Male
MH  - *Artificial Intelligence
MH  - Female
MH  - Feedback
MH  - Cognition
MH  - Bias
MH  - Formative Feedback
PMC - PMC11549112
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Clinical supervision
OT  - Entrustment
OT  - Feedback
OT  - Gender bias
OT  - Large language models
OT  - Natural language processing
COIS- The authors declare no competing interests.
EDAT- 2024/02/23 00:42
MHDA- 2024/11/13 13:57
PMCR- 2024/02/23
CRDT- 2024/02/22 23:57
PHST- 2023/08/01 00:00 [received]
PHST- 2024/01/21 00:00 [accepted]
PHST- 2024/11/13 13:57 [medline]
PHST- 2024/02/23 00:42 [pubmed]
PHST- 2024/02/22 23:57 [entrez]
PHST- 2024/02/23 00:00 [pmc-release]
AID - 10.1007/s10459-024-10311-9 [pii]
AID - 10311 [pii]
AID - 10.1007/s10459-024-10311-9 [doi]
PST - ppublish
SO  - Adv Health Sci Educ Theory Pract. 2024 Nov;29(5):1571-1592. doi: 
      10.1007/s10459-024-10311-9. Epub 2024 Feb 23.

PMID- 38949904
OWN - NLM
STAT- MEDLINE
DCOM- 20240701
LR  - 20240926
IS  - 1552-6917 (Electronic)
IS  - 1055-3290 (Linking)
VI  - 35
IP  - 3
DP  - 2024 May-Jun 01
TI  - "What Did You Say, ChatGPT?" The Use of AI in Black Women's HIV Self-Education: 
      An Inductive Qualitative Data Analysis.
PG  - 294-302
LID - 10.1097/JNC.0000000000000468 [doi]
AB  - The emergence of widely accessible artificial intelligence (AI) chatbots such as 
      ChatGPT presents unique opportunities and challenges in public health 
      self-education. This study examined simulations with ChatGPT for its use in 
      public education of sexual health of Black women, specifically in HIV prevention 
      and/or HIV PrEP use. The research questions guiding the study are as follows: (a) 
      does the information ChatGPT offers about HIV prevention and HIV PrEP differ 
      based on stated race? and (b) how could this relatively new platform inform 
      public health education of Black women educating themselves about sexual health 
      behaviors, diagnoses, and treatments? In addressing these questions, this study 
      also uncovered notable differences in ChatGPT's tone when responding to users 
      based on race. This study described valuable insights that can inform health care 
      professionals, educators, and policymakers, ultimately advancing the cause of 
      sexual health equity for Black women and underscoring the paradigm-shifting 
      potential of AI in the field of public health education.
CI  - Copyright © 2024 Association of Nurses in AIDS Care.
FAU - Chandler, Rasheeta D
AU  - Chandler RD
AUID- ORCID: 0000-0003-2021-6346
AD  - Rasheeta D. Chandler, PhD, RN, FNP-BC, FAANP, FAAN, is an Associate Professor, 
      Nell Hodgson Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Sheena Warner, MS, CRNA, APN, is an incoming PhD student, Nell Hodgson Woodruff 
      School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Gloria Aidoo-Frimpong, PhD, MPH, MA is a Postdoctoral Fellow, Center for 
      Interdisciplinary Research on AIDS (CIRA), Yale University, New Haven, 
      Connecticut, USA.
AD  - Jessica Wells, PhD, RN, WHNP-BC, FAAN, is an Associate Professor, Nell Hodgson 
      Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
FAU - Warner, Sheena
AU  - Warner S
AUID- ORCID: 0009-0003-0887-9451
AD  - Rasheeta D. Chandler, PhD, RN, FNP-BC, FAANP, FAAN, is an Associate Professor, 
      Nell Hodgson Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Sheena Warner, MS, CRNA, APN, is an incoming PhD student, Nell Hodgson Woodruff 
      School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Gloria Aidoo-Frimpong, PhD, MPH, MA is a Postdoctoral Fellow, Center for 
      Interdisciplinary Research on AIDS (CIRA), Yale University, New Haven, 
      Connecticut, USA.
AD  - Jessica Wells, PhD, RN, WHNP-BC, FAAN, is an Associate Professor, Nell Hodgson 
      Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
FAU - Aidoo-Frimpong, Gloria
AU  - Aidoo-Frimpong G
AUID- ORCID: 0000-0002-4658-2953
AD  - Rasheeta D. Chandler, PhD, RN, FNP-BC, FAANP, FAAN, is an Associate Professor, 
      Nell Hodgson Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Sheena Warner, MS, CRNA, APN, is an incoming PhD student, Nell Hodgson Woodruff 
      School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Gloria Aidoo-Frimpong, PhD, MPH, MA is a Postdoctoral Fellow, Center for 
      Interdisciplinary Research on AIDS (CIRA), Yale University, New Haven, 
      Connecticut, USA.
AD  - Jessica Wells, PhD, RN, WHNP-BC, FAAN, is an Associate Professor, Nell Hodgson 
      Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
FAU - Wells, Jessica
AU  - Wells J
AD  - Rasheeta D. Chandler, PhD, RN, FNP-BC, FAANP, FAAN, is an Associate Professor, 
      Nell Hodgson Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Sheena Warner, MS, CRNA, APN, is an incoming PhD student, Nell Hodgson Woodruff 
      School of Nursing, Emory University, Atlanta, Georgia, USA.
AD  - Gloria Aidoo-Frimpong, PhD, MPH, MA is a Postdoctoral Fellow, Center for 
      Interdisciplinary Research on AIDS (CIRA), Yale University, New Haven, 
      Connecticut, USA.
AD  - Jessica Wells, PhD, RN, WHNP-BC, FAAN, is an Associate Professor, Nell Hodgson 
      Woodruff School of Nursing, Emory University, Atlanta, Georgia, USA.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - J Assoc Nurses AIDS Care
JT  - The Journal of the Association of Nurses in AIDS Care : JANAC
JID - 9111870
SB  - IM
MH  - Adult
MH  - Female
MH  - Humans
MH  - Middle Aged
MH  - *Artificial Intelligence
MH  - *Black or African American/psychology/statistics & numerical data
MH  - *Health Education/methods
MH  - Health Knowledge, Attitudes, Practice
MH  - *HIV Infections/prevention & control/ethnology/psychology
MH  - Pre-Exposure Prophylaxis
MH  - *Qualitative Research
MH  - Sexual Behavior/ethnology
MH  - Sexual Health
EDAT- 2024/07/01 18:56
MHDA- 2024/07/01 18:57
CRDT- 2024/07/01 12:22
PHST- 2024/07/01 18:57 [medline]
PHST- 2024/07/01 18:56 [pubmed]
PHST- 2024/07/01 12:22 [entrez]
AID - 00001782-202406000-00012 [pii]
AID - 10.1097/JNC.0000000000000468 [doi]
PST - ppublish
SO  - J Assoc Nurses AIDS Care. 2024 May-Jun 01;35(3):294-302. doi: 
      10.1097/JNC.0000000000000468.

PMID- 39058399
OWN - NLM
STAT- MEDLINE
DCOM- 20250207
LR  - 20250213
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
VI  - 47
IP  - 2
DP  - 2025 Feb
TI  - Embracing the illusion of explanatory depth: A strategic framework for 
      using iterative prompting for integrating large language models in 
      healthcare education.
PG  - 208-211
LID - 10.1080/0142159X.2024.2382863 [doi]
AB  - Healthcare educators are exploring ways to integrate Large Language Models (LLMs) 
      into the curriculum. At the same time, they are concerned about the negative 
      impact on students' cognitive development. There is concern that the students 
      will not learn to think and problem-solve by themselves and instead become 
      dependent on LLMs to find answers. In addition, the students could start 
      accepting the LLM generated responses at face value. The Illusion of Explanatory 
      Depth (IoED) is a cognitive bias where humans believe they understand complex 
      phenomena in more depth than they do. This illusion is caused when people rely on 
      external sources of information rather than deeper levels of internalized 
      knowledge. This illusion can be exposed by asking follow-up in depth questions. 
      Using the same approach, specifically iterative prompting, can help students 
      interact with LLM's while learning actively, gaining deeper levels of knowledge, 
      and exposing the LLM shortcomings. The article proposes that educators encourage 
      use of LLMs to complete assignments using a template, that promotes students' 
      reflections on their interactions with LLMs, using iterative prompting. This 
      process based on IoED, and iterative prompting will help educators integrate LLMs 
      in the curriculum while mitigating the risk of students becoming dependent on 
      these tools. Students will practice active learning and experience firsthand the 
      inaccuracies and inconsistencies in LLM responses.
FAU - Mehta, Seysha
AU  - Mehta S
AUID- ORCID: 0000-0001-5411-1628
AD  - Cleveland Clinic Lerner College of Medicine of Case Western Reserve University.
FAU - Mehta, Neil
AU  - Mehta N
AUID- ORCID: 0000-0001-8342-4252
AD  - Cleveland Clinic Lerner College of Medicine of Case Western Reserve University.
LA  - eng
PT  - Journal Article
DEP - 20240726
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
MH  - Humans
MH  - *Curriculum
MH  - Language
MH  - Problem-Based Learning/methods
MH  - Students, Medical/psychology
OTO - NOTNLM
OT  - AI dependency
OT  - ChatGPT
OT  - Illusion of explanatory depth
OT  - automation bias
OT  - generative AI
OT  - iterative prompting
OT  - large language model
EDAT- 2024/07/26 12:47
MHDA- 2025/02/07 12:25
CRDT- 2024/07/26 11:03
PHST- 2025/02/07 12:25 [medline]
PHST- 2024/07/26 12:47 [pubmed]
PHST- 2024/07/26 11:03 [entrez]
AID - 10.1080/0142159X.2024.2382863 [doi]
PST - ppublish
SO  - Med Teach. 2025 Feb;47(2):208-211. doi: 10.1080/0142159X.2024.2382863. Epub 2024 
      Jul 26.

PMID- 39326035
OWN - NLM
STAT- MEDLINE
DCOM- 20240926
LR  - 20241013
IS  - 2564-1891 (Electronic)
IS  - 2564-1891 (Linking)
VI  - 4
DP  - 2024 Sep 26
TI  - Evaluating the Influence of Role-Playing Prompts on ChatGPT's Misinformation 
      Detection Accuracy: Quantitative Study.
PG  - e60678
LID - 10.2196/60678 [doi]
LID - e60678
AB  - BACKGROUND: During the COVID-19 pandemic, the rapid spread of misinformation on 
      social media created significant public health challenges. Large language models 
      (LLMs), pretrained on extensive textual data, have shown potential in detecting 
      misinformation, but their performance can be influenced by factors such as prompt 
      engineering (ie, modifying LLM requests to assess changes in output). One form of 
      prompt engineering is role-playing, where, upon request, OpenAI's ChatGPT 
      imitates specific social roles or identities. This research examines how 
      ChatGPT's accuracy in detecting COVID-19-related misinformation is affected when 
      it is assigned social identities in the request prompt. Understanding how LLMs 
      respond to different identity cues can inform messaging campaigns, ensuring 
      effective use in public health communications. OBJECTIVE: This study investigates 
      the impact of role-playing prompts on ChatGPT's accuracy in detecting 
      misinformation. This study also assesses differences in performance when 
      misinformation is explicitly stated versus implied, based on contextual 
      knowledge, and examines the reasoning given by ChatGPT for classification 
      decisions. METHODS: Overall, 36 real-world tweets about COVID-19 collected in 
      September 2021 were categorized into misinformation, sentiment (opinions aligned 
      vs unaligned with public health guidelines), corrections, and neutral reporting. 
      ChatGPT was tested with prompts incorporating different combinations of multiple 
      social identities (ie, political beliefs, education levels, locality, 
      religiosity, and personality traits), resulting in 51,840 runs. Two control 
      conditions were used to compare results: prompts with no identities and those 
      including only political identity. RESULTS: The findings reveal that including 
      social identities in prompts reduces average detection accuracy, with a notable 
      drop from 68.1% (SD 41.2%; no identities) to 29.3% (SD 31.6%; all identities 
      included). Prompts with only political identity resulted in the lowest accuracy 
      (19.2%, SD 29.2%). ChatGPT was also able to distinguish between sentiments 
      expressing opinions not aligned with public health guidelines from misinformation 
      making declarative statements. There were no consistent differences in 
      performance between explicit and implicit misinformation requiring contextual 
      knowledge. While the findings show that the inclusion of identities decreased 
      detection accuracy, it remains uncertain whether ChatGPT adopts views aligned 
      with social identities: when assigned a conservative identity, ChatGPT identified 
      misinformation with nearly the same accuracy as it did when assigned a liberal 
      identity. While political identity was mentioned most frequently in ChatGPT's 
      explanations for its classification decisions, the rationales for classifications 
      were inconsistent across study conditions, and contradictory explanations were 
      provided in some instances. CONCLUSIONS: These results indicate that ChatGPT's 
      ability to classify misinformation is negatively impacted when role-playing 
      social identities, highlighting the complexity of integrating human biases and 
      perspectives in LLMs. This points to the need for human oversight in the use of 
      LLMs for misinformation detection. Further research is needed to understand how 
      LLMs weigh social identities in prompt-based tasks and explore their application 
      in different cultural contexts.
CI  - ©Michael Robert Haupt, Luning Yang, Tina Purnat, Tim Mackey. Originally published 
      in JMIR Infodemiology (https://infodemiology.jmir.org), 26.09.2024.
FAU - Haupt, Michael Robert
AU  - Haupt MR
AUID- ORCID: 0000-0003-4985-7796
AD  - Department of Cognitive Science, University of California, San Diego, La Jolla, 
      CA, United States.
AD  - Global Health Program, Department of Anthropology, University of California, San 
      Diego, La Jolla, CA, United States.
AD  - Global Health Policy & Data Institute, San Diego, CA, United States.
FAU - Yang, Luning
AU  - Yang L
AUID- ORCID: 0009-0006-4876-591X
AD  - Global Health Policy & Data Institute, San Diego, CA, United States.
FAU - Purnat, Tina
AU  - Purnat T
AUID- ORCID: 0000-0002-0257-6631
AD  - TH Chan School of Public Health, Harvard University, Boston, MA, United States.
FAU - Mackey, Tim
AU  - Mackey T
AUID- ORCID: 0000-0002-2191-7833
AD  - Global Health Program, Department of Anthropology, University of California, San 
      Diego, La Jolla, CA, United States.
AD  - Global Health Policy & Data Institute, San Diego, CA, United States.
AD  - S-3 Research, San Diego, CA, United States.
LA  - eng
PT  - Journal Article
DEP - 20240926
PL  - Canada
TA  - JMIR Infodemiology
JT  - JMIR infodemiology
JID - 9918249014806676
SB  - IM
MH  - Humans
MH  - *COVID-19
MH  - *Communication
MH  - *Social Media
MH  - *Role Playing
MH  - Pandemics
MH  - SARS-CoV-2
MH  - Public Health
PMC - PMC11467603
OTO - NOTNLM
OT  - AI
OT  - COVID-19
OT  - ChatGPT
OT  - artificial intelligence
OT  - experiment
OT  - large language models
OT  - misinformation detection
OT  - prompt engineering
OT  - role-playing
OT  - social identity
COIS- Conflicts of Interest: TM is an employee of, and holds equity in, the company S-3 
      Research LLC; he is also the editor-in-chief of JMIR Infodemiology. TP and MRH 
      are associate editors of JMIR Infodemilogy. LY declares no conflict of interest.
EDAT- 2024/09/26 19:03
MHDA- 2024/09/26 19:04
PMCR- 2024/09/26
CRDT- 2024/09/26 16:52
PHST- 2024/05/17 00:00 [received]
PHST- 2024/08/12 00:00 [accepted]
PHST- 2024/07/19 00:00 [revised]
PHST- 2024/09/26 19:04 [medline]
PHST- 2024/09/26 19:03 [pubmed]
PHST- 2024/09/26 16:52 [entrez]
PHST- 2024/09/26 00:00 [pmc-release]
AID - v4i1e60678 [pii]
AID - 10.2196/60678 [doi]
PST - epublish
SO  - JMIR Infodemiology. 2024 Sep 26;4:e60678. doi: 10.2196/60678.

PMID- 39487846
OWN - NLM
STAT- MEDLINE
DCOM- 20241102
LR  - 20241102
IS  - 0006-9248 (Print)
IS  - 0006-9248 (Linking)
VI  - 125
IP  - 11
DP  - 2024
TI  - Transforming emergency triage: A preliminary, scenario-based cross-sectional 
      study comparing artificial intelligence models and clinical expertise for 
      enhanced accuracy.
PG  - 738-743
LID - 10.4149/BLL_2024_114 [doi]
AB  - INTRODUCTION: This study examines triage judgments in emergency settings and 
      compares the outcomes of artificial intelligence models for healthcare 
      professionals. It discusses the disparities in precision rates between subjective 
      evaluations by health professionals with objective assessments of AI systems. 
      MATERIAL AND METHOD: For the analysis of the efficacy of emergency triage; 50 
      virtual patient scenarios had been created. Emergency medicine residents and 
      other healthcare providers who had triage education were tasked with categorizing 
      triage levels for virtual patient scenarios. Also artificial intelligence 
      systems, tasked for resolving the same scenarios. All of them were asked to use 
      three color-coded triage of the Republic of Turkey Ministry of Health. The answer 
      keys were created by consensus of the researchers. In addition, Emergency 
      medicine specialists were asked to evaluate the acuity level of each scenario in 
      order to perform sub-analyses. RESULTS: The study consisted of 86 healthcare 
      professionals, comprising 31 Emergency medicine residents (26.5%), 1 paramedic 
      (0.9%), 5 emergency health technicians (4.3%), and 80 nurses (68.4%). Google Bard 
      AI and OpenAI Chat GPT v.3.5 were used as artificial intelligence systems. The 
      responses compared with the answer key to determine each groups efficacy. As 
      planned the responses from healthcare professionals were analyzed individually 
      for acuity level of scenarios. Emergency medicine residents and other groups of 
      healthcare providers had significantly higher numbers of correct answers compared 
      to Google Bard and Chat GPT (n=30.7 vs n=25.5). There was no significant 
      difference between ChatGPT and Bard for low and high acuity scenarios 
      (p=0.821)CONCLUSION: AI models can examine extensive data sets and make more 
      accurate and quicker triage judgments with sophisticated algorithms. However, in 
      this study, we found that the triage ability of artificial intelligence is not as 
      sufficient as humans. A more efficient triage system can be developed by 
      integrating artificial intelligence with human input, rather than solely relying 
      on technology (Tab. 4, Ref. 41). Text in PDF www.elis.sk Keywords: emergency 
      triage, AI applications, health technology, artificial intelligence, emergency 
      management.
FAU - Eraybar, Suna
AU  - Eraybar S
FAU - Dal, Evren
AU  - Dal E
FAU - Aydin, Mevlut Okan
AU  - Aydin MO
FAU - Begenen, Maruf
AU  - Begenen M
LA  - eng
PT  - Comparative Study
PT  - Journal Article
PL  - Slovakia
TA  - Bratisl Lek Listy
JT  - Bratislavske lekarske listy
JID - 0065324
SB  - IM
MH  - *Triage/methods
MH  - Humans
MH  - *Artificial Intelligence
MH  - Cross-Sectional Studies
MH  - Clinical Competence
MH  - Emergency Medicine/education
MH  - Turkey
EDAT- 2024/11/02 23:15
MHDA- 2024/11/02 23:16
CRDT- 2024/11/02 11:32
PHST- 2024/11/02 23:16 [medline]
PHST- 2024/11/02 23:15 [pubmed]
PHST- 2024/11/02 11:32 [entrez]
AID - 10.4149/BLL_2024_114 [doi]
PST - ppublish
SO  - Bratisl Lek Listy. 2024;125(11):738-743. doi: 10.4149/BLL_2024_114.

PMID- 33083472
OWN - NLM
STAT- MEDLINE
DCOM- 20210503
LR  - 20240329
IS  - 2314-6141 (Electronic)
IS  - 2314-6133 (Print)
VI  - 2020
DP  - 2020
TI  - Application of BERT to Enable Gene Classification Based on Clinical Evidence.
PG  - 5491963
LID - 10.1155/2020/5491963 [doi]
LID - 5491963
AB  - The identification of profiled cancer-related genes plays an essential role in 
      cancer diagnosis and treatment. Based on literature research, the classification 
      of genetic mutations continues to be done manually nowadays. Manual 
      classification of genetic mutations is pathologist-dependent, subjective, and 
      time-consuming. To improve the accuracy of clinical interpretation, scientists 
      have proposed computational-based approaches for automatic analysis of mutations 
      with the advent of next-generation sequencing technologies. Nevertheless, some 
      challenges, such as multiple classifications, the complexity of texts, redundant 
      descriptions, and inconsistent interpretation, have limited the development of 
      algorithms. To overcome these difficulties, we have adapted a deep learning 
      method named Bidirectional Encoder Representations from Transformers (BERT) to 
      classify genetic mutations based on text evidence from an annotated database. 
      During the training, three challenging features such as the extreme length of 
      texts, biased data presentation, and high repeatability were addressed. Finally, 
      the BERT+abstract demonstrates satisfactory results with 0.80 logarithmic loss, 
      0.6837 recall, and 0.705 F-measure. It is feasible for BERT to classify the 
      genomic mutation text within literature-based datasets. Consequently, BERT is a 
      practical tool for facilitating and significantly speeding up cancer research 
      towards tumor progression, diagnosis, and the design of more precise and 
      effective treatments.
CI  - Copyright © 2020 Yuhan Su et al.
FAU - Su, Yuhan
AU  - Su Y
AUID- ORCID: 0000-0002-2313-0049
AD  - National Pilot School of Software, Yunnan University, Kunming, 650091, China.
FAU - Xiang, Hongxin
AU  - Xiang H
AD  - National Pilot School of Software, Yunnan University, Kunming, 650091, China.
FAU - Xie, Haotian
AU  - Xie H
AUID- ORCID: 0000-0001-8796-4053
AD  - Department of Mathematics, The Ohio State University, Columbus, OH 43210, USA.
FAU - Yu, Yong
AU  - Yu Y
AD  - National Pilot School of Software, Yunnan University, Kunming, 650091, China.
FAU - Dong, Shiyan
AU  - Dong S
AD  - Department of Radiation Oncology, University of Texas Southwestern Medical 
      Center, Dallas, TX 75390, USA.
FAU - Yang, Zhaogang
AU  - Yang Z
AUID- ORCID: 0000-0002-6350-4455
AD  - Department of Radiation Oncology, University of Texas Southwestern Medical 
      Center, Dallas, TX 75390, USA.
FAU - Zhao, Na
AU  - Zhao N
AUID- ORCID: 0000-0002-6166-2118
AD  - National Pilot School of Software, Yunnan University, Kunming, 650091, China.
LA  - eng
PT  - Journal Article
DEP - 20201007
PL  - United States
TA  - Biomed Res Int
JT  - BioMed research international
JID - 101600173
SB  - IM
MH  - *Algorithms
MH  - Biomedical Research
MH  - Computational Biology/*methods
MH  - Data Curation
MH  - *Deep Learning
MH  - Genes, Neoplasm/*genetics
MH  - Humans
MH  - Neoplasms/*genetics
PMC - PMC7563092
COIS- The authors declare that they have no competing interests.
EDAT- 2020/10/22 06:00
MHDA- 2021/05/04 06:00
PMCR- 2020/10/07
CRDT- 2020/10/21 06:04
PHST- 2020/07/31 00:00 [received]
PHST- 2020/08/31 00:00 [revised]
PHST- 2020/09/07 00:00 [accepted]
PHST- 2020/10/21 06:04 [entrez]
PHST- 2020/10/22 06:00 [pubmed]
PHST- 2021/05/04 06:00 [medline]
PHST- 2020/10/07 00:00 [pmc-release]
AID - 10.1155/2020/5491963 [doi]
PST - epublish
SO  - Biomed Res Int. 2020 Oct 7;2020:5491963. doi: 10.1155/2020/5491963. eCollection 
      2020.

PMID- 39732668
OWN - NLM
STAT- MEDLINE
DCOM- 20241229
LR  - 20250104
IS  - 1472-6947 (Electronic)
IS  - 1472-6947 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Dec 28
TI  - The aluminum standard: using generative Artificial Intelligence tools to 
      synthesize and annotate non-structured patient data.
PG  - 409
LID - 10.1186/s12911-024-02825-4 [doi]
LID - 409
AB  - BACKGROUND: Medical narratives are fundamental to the correct identification of a 
      patient's health condition. This is not only because it describes the patient's 
      situation. It also contains relevant information about the patient's context and 
      health state evolution. Narratives are usually vague and cannot be categorized 
      easily. On the other hand, once the patient's situation is correctly identified 
      based on a narrative, it is then possible to map the patient's situation into 
      precise classification schemas and ontologies that are machine-readable. To this 
      end, language models can be trained to read and extract elements from these 
      narratives. However, the main problem is the lack of data for model 
      identification and model training in languages other than English. First, gold 
      standard annotations are usually not available due to the high level of data 
      protection for patient data. Second, gold standard annotations (if available) are 
      difficult to access. Alternative available data, like MIMIC (Sci Data 3:1, 2016) 
      is written in English and for specific patient conditions like intensive care. 
      Thus, when model training is required for other types of patients, like oncology 
      (and not intensive care), this could lead to bias. To facilitate clinical 
      narrative model training, a method for creating high-quality synthetic narratives 
      is needed. METHOD: We devised workflows based on generative AI methods to 
      synthesize narratives in the German language to avoid the disclosure of patient's 
      health data. Since we required highly realistic narratives, we generated prompts, 
      written with high-quality medical terminology, asking for clinical narratives 
      containing both a main and co-disease. The frequency of distribution of both the 
      main and co-disease was extracted from the hospital's structured data, such that 
      the synthetic narratives reflect the disease distribution among the patient's 
      cohort. In order to validate the quality of the synthetic narratives, we 
      annotated them to train a Named Entity Recognition (NER) algorithm. According to 
      our assumptions, the validation of this system implies that the synthesized data 
      used for its training are of acceptable quality. RESULT: We report precision, 
      recall and F1 score for the NER model while also considering metrics that take 
      into account both exact and partial entity matches. Trained models are cautious, 
      with a precision up to 0.8 for Entity Type match metric and a F1 score of 0.3. 
      CONCLUSION: Despite its inherent limitations, this technology has the potential 
      to allow data interoperability by using encoded diseases across languages and 
      regions without compromising data safety. Additionally, it facilitates the 
      synthesis of unstructured patient data. In this way, the identification and 
      training of models can be accelerated. We believe that this method may be able to 
      generate discharge letters for any combination of main and co-diseases, which 
      will significantly reduce the amount of time spent writing these letters by 
      healthcare professionals.
CI  - © 2024. The Author(s).
FAU - Diaz Ochoa, Juan G
AU  - Diaz Ochoa JG
AUID- ORCID: 0000-0002-9893-4068
AD  - QuiBiQ GmbH, Heßbrühlstr. 11, Stuttgart, D-70565, Germany. Juan.diaz@permediq.de.
AD  - PerMediQ GmbH, Salzbergweg 18, Wang, D-85368, Germany. Juan.diaz@permediq.de.
FAU - Mustafa, Faizan E
AU  - Mustafa FE
AUID- ORCID: 0000-0002-1004-7545
AD  - QuiBiQ GmbH, Heßbrühlstr. 11, Stuttgart, D-70565, Germany.
FAU - Weil, Felix
AU  - Weil F
AD  - QuiBiQ GmbH, Heßbrühlstr. 11, Stuttgart, D-70565, Germany.
FAU - Wang, Yi
AU  - Wang Y
AUID- ORCID: 0000-0001-6086-807X
AD  - Analytic Computing Department, University of Stuttgart, Institute for Artificial 
      Intelligence, Universitätsstraße 32, Stuttgart, D-70569, Germany.
FAU - Kama, Kudret
AU  - Kama K
AUID- ORCID: 0000-0002-0175-9823
AD  - Klinikum Stuttgart, Stuttgart Cancer Center - Tumorzentrum Eva Mayr-Stihl DE, 
      Kriegsbergstraße 60, Stuttgart, D-70174, Germany.
FAU - Knott, Markus
AU  - Knott M
AUID- ORCID: 0000-0002-9147-3203
AD  - Klinikum Stuttgart, Stuttgart Cancer Center - Tumorzentrum Eva Mayr-Stihl DE, 
      Kriegsbergstraße 60, Stuttgart, D-70174, Germany.
LA  - eng
GR  - BW1_1456 (AI4MedCode)/Ministry for Economics, Labor and Tourism from 
      Baden-Württemberg, Germany/
GR  - BW1_1456 (AI4MedCode)/Ministry for Economics, Labor and Tourism from 
      Baden-Württemberg, Germany/
GR  - BW1_1456 (AI4MedCode)/Ministry for Economics, Labor and Tourism from 
      Baden-Württemberg, Germany/
GR  - BW1_1456 (AI4MedCode)/Ministry for Economics, Labor and Tourism from 
      Baden-Württemberg, Germany/
GR  - BW1_1456 (AI4MedCode)/Ministry for Economics, Labor and Tourism from 
      Baden-Württemberg, Germany/
PT  - Journal Article
DEP - 20241228
PL  - England
TA  - BMC Med Inform Decis Mak
JT  - BMC medical informatics and decision making
JID - 101088682
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Natural Language Processing
MH  - Narration
PMC - PMC11681671
OTO - NOTNLM
OT  - Generative AI
OT  - Language models
OT  - Non-english Language models
OT  - Synthetic data
OT  - Synthetic narratives
COIS- Declarations. Ethics approval and consent to participate: This study was approved 
      by Ethics Committee at the Baden-Württemberg State Medical Association 
      (Ethik-Kommission bei der Landesärztekammer Baden-Württemberg), with approval 
      number F-2023-125. The study was performed in compliance with the World Medical 
      Association Declaration of Helsinki on Ethical Principles for Medical Research 
      Involving Human Subjects, and research regulations of the country. The informed 
      consent requirement is waived due to the state regulations of the 
      Landeskrankenhausgesetz Baden-Württemberg (LKHG), owing to the retrospective, 
      aggregated and anonymized nature of this study and of the database. Consent for 
      publication: Not applicable. Competing interests: Felix Weil, Faizan E Mustafa & 
      Juan G. Diaz Ochoa are employed at QuiBiQ GmbH. All other authors have no 
      competing interest.
EDAT- 2024/12/29 00:20
MHDA- 2024/12/29 06:20
PMCR- 2024/12/28
CRDT- 2024/12/28 23:55
PHST- 2023/11/27 00:00 [received]
PHST- 2024/12/16 00:00 [accepted]
PHST- 2024/12/29 06:20 [medline]
PHST- 2024/12/29 00:20 [pubmed]
PHST- 2024/12/28 23:55 [entrez]
PHST- 2024/12/28 00:00 [pmc-release]
AID - 10.1186/s12911-024-02825-4 [pii]
AID - 2825 [pii]
AID - 10.1186/s12911-024-02825-4 [doi]
PST - epublish
SO  - BMC Med Inform Decis Mak. 2024 Dec 28;24(1):409. doi: 10.1186/s12911-024-02825-4.

PMID- 39828759
OWN - NLM
STAT- Publisher
LR  - 20250119
IS  - 1745-655X (Electronic)
IS  - 0197-5897 (Linking)
DP  - 2025 Jan 19
TI  - Psychological reactance to vaccine mandates on Twitter: a study of sentiments in 
      the United States.
LID - 10.1057/s41271-025-00554-0 [doi]
AB  - This study examines the relationship between vaccine mandates and public 
      sentiment toward vaccines and health officials on Twitter. I analyzed 6.6 million 
      vaccine-related tweets from July 2021 to February 2022 in the United States. 
      Leveraging a large language model, BERT, I identified tweets discussing vaccine 
      mandates even when lacking explicit keywords. Compared to non-mandate tweets, 
      those mentioning mandates exhibit greater negativity, anger, and freedom-related 
      language. Furthermore, increased state-level discussion of mandates correlates 
      with rising levels of negativity and anger toward both vaccines and public health 
      officials. Finally, greater disparity in vaccination progress across counties 
      within a state is associated with increased anger in tweets directed toward both.
CI  - © 2025. The Author(s).
FAU - Hsieh, Pei-Hsun
AU  - Hsieh PH
AUID- ORCID: 0000-0002-1147-8208
AD  - Center for Social Norms and Behavioral Dynamics, University of Pennsylvania, 
      Philadelphia, PA, 19104-6304, USA. phsieh@sas.upenn.edu.
LA  - eng
GR  - IHS017468/Institute for Humane Studies, George Mason University/
PT  - Journal Article
DEP - 20250119
PL  - England
TA  - J Public Health Policy
JT  - Journal of public health policy
JID - 8006508
SB  - IM
OTO - NOTNLM
OT  - Natural language processing
OT  - Public health officials
OT  - Sentiment analysis
OT  - Twitter
OT  - Vaccine mandates
EDAT- 2025/01/20 22:54
MHDA- 2025/01/20 22:54
CRDT- 2025/01/19 23:17
PHST- 2025/01/05 00:00 [accepted]
PHST- 2025/01/20 22:54 [medline]
PHST- 2025/01/20 22:54 [pubmed]
PHST- 2025/01/19 23:17 [entrez]
AID - 10.1057/s41271-025-00554-0 [pii]
AID - 10.1057/s41271-025-00554-0 [doi]
PST - aheadofprint
SO  - J Public Health Policy. 2025 Jan 19. doi: 10.1057/s41271-025-00554-0.

PMID- 39148290
OWN - NLM
STAT- MEDLINE
DCOM- 20241011
LR  - 20241011
IS  - 2666-2477 (Electronic)
IS  - 2666-2477 (Linking)
VI  - 5
IP  - 4
DP  - 2024 Oct 10
TI  - Estimating prevalence of rare genetic disease diagnoses using electronic health 
      records in a children's hospital.
PG  - 100341
LID - S2666-2477(24)00081-2 [pii]
LID - 10.1016/j.xhgg.2024.100341 [doi]
LID - 100341
AB  - Rare genetic diseases (RGDs) affect a significant number of individuals, 
      particularly in pediatric populations. This study investigates the efficacy of 
      identifying RGD diagnoses through electronic health records (EHRs) and natural 
      language processing (NLP) tools, and analyzes the prevalence of identified RGDs 
      for potential underdiagnosis at Cincinnati Children's Hospital Medical Center 
      (CCHMC). EHR data from 659,139 pediatric patients at CCHMC were utilized. 
      Diagnoses corresponding to RGDs in Orphanet were identified using rule-based and 
      machine learning-based NLP methods. Manual evaluation assessed the precision of 
      the NLP strategies, with 100 diagnosis descriptions reviewed for each method. The 
      rule-based method achieved a precision of 97.5% (95% CI: 91.5%, 99.4%), while the 
      machine-learning-based method had a precision of 73.5% (95% CI: 63.6%, 81.6%). A 
      manual chart review of 70 randomly selected patients with RGD diagnoses confirmed 
      the diagnoses in 90.3% (95% CI: 82.0%, 95.2%) of cases. A total of 37,326 
      pediatric patients were identified with 977 RGD diagnoses based on the rule-based 
      method, resulting in a prevalence of 5.66% in this population. While a majority 
      of the disorders showed a higher prevalence at CCHMC compared with Orphanet, some 
      diseases, such as 1p36 deletion syndrome, indicated potential underdiagnosis. 
      Analyses further uncovered disparities in RGD prevalence and age of diagnosis 
      across gender and racial groups. This study demonstrates the utility of employing 
      EHR data with NLP tools to systematically investigate RGD diagnoses in large 
      cohorts. The identified disparities underscore the need for enhanced approaches 
      to guarantee timely and accurate diagnosis and management of pediatric RGDs.
CI  - Copyright © 2024 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Herr, Kate
AU  - Herr K
AD  - Division of Biomedical Informatics, Cincinnati Children's Hospital Medical 
      Center, Cincinnati, OH 45229, USA.
FAU - Lu, Peixin
AU  - Lu P
AD  - Division of Biomedical Informatics, Cincinnati Children's Hospital Medical 
      Center, Cincinnati, OH 45229, USA.
FAU - Diamreyan, Kessi
AU  - Diamreyan K
AD  - University of Cincinnati College of Medicine, Cincinnati, OH 45229, USA.
FAU - Xu, Huan
AU  - Xu H
AD  - Division of Human Genetics, Cincinnati Children's Hospital Medical Center, 
      Cincinnati, OH 45229, USA.
FAU - Mendonca, Eneida
AU  - Mendonca E
AD  - Division of Biomedical Informatics, Cincinnati Children's Hospital Medical 
      Center, Cincinnati, OH 45229, USA; University of Cincinnati College of Medicine, 
      Cincinnati, OH 45229, USA.
FAU - Weaver, K Nicole
AU  - Weaver KN
AD  - University of Cincinnati College of Medicine, Cincinnati, OH 45229, USA; Division 
      of Human Genetics, Cincinnati Children's Hospital Medical Center, Cincinnati, OH 
      45229, USA; Heart Institute, Cincinnati Children's Hospital Medical Center, 
      Cincinnati, OH 45229, USA.
FAU - Chen, Jing
AU  - Chen J
AD  - Division of Biomedical Informatics, Cincinnati Children's Hospital Medical 
      Center, Cincinnati, OH 45229, USA; University of Cincinnati College of Medicine, 
      Cincinnati, OH 45229, USA. Electronic address: jing.chen2@cchmc.org.
LA  - eng
PT  - Journal Article
DEP - 20240814
PL  - United States
TA  - HGG Adv
JT  - HGG advances
JID - 101772885
SB  - IM
MH  - Humans
MH  - *Electronic Health Records/statistics & numerical data
MH  - Male
MH  - Child
MH  - Female
MH  - Prevalence
MH  - *Hospitals, Pediatric/statistics & numerical data
MH  - Child, Preschool
MH  - *Rare Diseases/epidemiology/genetics/diagnosis
MH  - Infant
MH  - Adolescent
MH  - Natural Language Processing
MH  - Infant, Newborn
MH  - Machine Learning
MH  - Genetic Diseases, Inborn/epidemiology/diagnosis/genetics
PMC - PMC11401171
OTO - NOTNLM
OT  - Orphanet
OT  - bioinformatics
OT  - electronic health record
OT  - genetic testing
OT  - natural language processing
OT  - rare genetic diseases
COIS- Declaration of interests The authors declare no competing interests.
EDAT- 2024/08/16 06:42
MHDA- 2024/10/12 13:18
PMCR- 2024/08/14
CRDT- 2024/08/16 01:36
PHST- 2024/02/20 00:00 [received]
PHST- 2024/08/09 00:00 [revised]
PHST- 2024/08/09 00:00 [accepted]
PHST- 2024/10/12 13:18 [medline]
PHST- 2024/08/16 06:42 [pubmed]
PHST- 2024/08/16 01:36 [entrez]
PHST- 2024/08/14 00:00 [pmc-release]
AID - S2666-2477(24)00081-2 [pii]
AID - 100341 [pii]
AID - 10.1016/j.xhgg.2024.100341 [doi]
PST - ppublish
SO  - HGG Adv. 2024 Oct 10;5(4):100341. doi: 10.1016/j.xhgg.2024.100341. Epub 2024 Aug 
      14.

PMID- 38928964
OWN - NLM
STAT- MEDLINE
DCOM- 20240627
LR  - 20240629
IS  - 1660-4601 (Electronic)
IS  - 1661-7827 (Print)
IS  - 1660-4601 (Linking)
VI  - 21
IP  - 6
DP  - 2024 May 31
TI  - Charting a Path to the Quintuple Aim: Harnessing AI to Address Social 
      Determinants of Health.
LID - 10.3390/ijerph21060718 [doi]
LID - 718
AB  - The Quintuple Aim seeks to improve healthcare by addressing social determinants 
      of health (SDOHs), which are responsible for 70-80% of medical outcomes. 
      SDOH-related concerns have traditionally been addressed through referrals to 
      social workers and community-based organizations (CBOs), but these pathways have 
      had limited success in connecting patients with resources. Given that health 
      inequity is expected to cost the United States nearly USD 300 billion by 2050, 
      new artificial intelligence (AI) technology may aid providers in addressing SDOH. 
      In this commentary, we present our experience with using ChatGPT to obtain SDOH 
      management recommendations for archetypal patients in Philadelphia, PA. ChatGPT 
      identified relevant SDOH resources and provided contact information for local 
      organizations. Future exploration could improve AI prompts and integrate AI into 
      electronic medical records to provide healthcare providers with real-time SDOH 
      recommendations during appointments.
FAU - Shah, Yash B
AU  - Shah YB
AUID- ORCID: 0000-0003-1551-7611
AD  - Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, PA 
      19107, USA.
FAU - Goldberg, Zachary N
AU  - Goldberg ZN
AUID- ORCID: 0000-0003-1935-6421
AD  - Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, PA 
      19107, USA.
FAU - Harness, Erika D
AU  - Harness ED
AD  - Sidney Kimmel Medical College, Thomas Jefferson University, Philadelphia, PA 
      19107, USA.
FAU - Nash, David B
AU  - Nash DB
AD  - Jefferson College of Population Health, Philadelphia, PA 19107, USA.
LA  - eng
PT  - Journal Article
DEP - 20240531
PL  - Switzerland
TA  - Int J Environ Res Public Health
JT  - International journal of environmental research and public health
JID - 101238455
SB  - IM
MH  - *Social Determinants of Health
MH  - *Artificial Intelligence
MH  - Humans
MH  - Philadelphia
MH  - Delivery of Health Care/organization & administration
PMC - PMC11203467
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - disparities in care
OT  - health-related social needs
OT  - healthcare management
OT  - quintuple aim
OT  - social determinants of health
COIS- The authors declare no conflicts of interest.
EDAT- 2024/06/27 06:43
MHDA- 2024/06/27 06:44
PMCR- 2024/05/31
CRDT- 2024/06/27 01:10
PHST- 2024/05/07 00:00 [received]
PHST- 2024/05/29 00:00 [revised]
PHST- 2024/05/31 00:00 [accepted]
PHST- 2024/06/27 06:44 [medline]
PHST- 2024/06/27 06:43 [pubmed]
PHST- 2024/06/27 01:10 [entrez]
PHST- 2024/05/31 00:00 [pmc-release]
AID - ijerph21060718 [pii]
AID - ijerph-21-00718 [pii]
AID - 10.3390/ijerph21060718 [doi]
PST - epublish
SO  - Int J Environ Res Public Health. 2024 May 31;21(6):718. doi: 
      10.3390/ijerph21060718.

PMID- 39670366
OWN - NLM
STAT- MEDLINE
DCOM- 20241213
LR  - 20241213
IS  - 2335-6936 (Electronic)
IS  - 2335-6928 (Linking)
VI  - 30
DP  - 2025
TI  - Using Large Language Models for Efficient Cancer Registry Coding in the Real 
      Hospital Setting: A Feasibility Study.
PG  - 121-137
AB  - The primary challenge in reporting cancer cases lies in the labor-intensive and 
      time-consuming process of manually reviewing numerous reports. Current methods 
      predominantly rely on rule-based approaches or custom-supervised learning models, 
      which predict diagnostic codes based on a single pathology report per patient. 
      Although these methods show promising evaluation results, their biased outcomes 
      in controlled settings may hinder adaption to real-world reporting workflows. In 
      this feasibility study, we focused on lung cancer as a test case and developed an 
      agentic retrieval-augmented generation (RAG) system to evaluate the potential of 
      publicly available large language models (LLMs) for cancer registry coding. Our 
      findings demonstrate that: (1) directly applying publicly available LLMs without 
      fine-tuning is feasible for cancer registry coding; and (2) prompt engineering 
      can significantly enhance the capability of pre-trained LLMs in cancer registry 
      coding. The off-the-shelf LLM, combined with our proposed system architecture and 
      basic prompts, achieved a macro-averaged F-score of 0.637 when evaluated on 
      testing data consisting of patients' medical reports spanning 1.5 years since 
      their first visit. By employing chain of thought (CoT) reasoning and our proposed 
      coding item grouping, the system outperformed the baseline by 0.187 in terms of 
      the macro-averaged F-score. These findings demonstrate the great potential of 
      leveraging LLMs with prompt engineering for cancer registry coding. Our system 
      could offer cancer registrars a promising reference tool to enhance their daily 
      workflow, improving efficiency and accuracy in cancer case reporting.
FAU - Wang, Chen-Kai
AU  - Wang CK
AD  - Department of Computer Science, National Yang Ming Chiao Tung University Hsinchu, 
      300093, Taiwan, ROC, Taiwan.
AD  - Advanced Technology Laboratory, Chunghwa Telecom Laboratories Taoyuan, 326402, 
      Taiwan, ROC, Taiwan. dennisckwang@gmail.com.
FAU - Ke, Cheng-Rong
AU  - Ke CR
FAU - Huang, Ming-Siang
AU  - Huang MS
FAU - Chong, Inn-Wen
AU  - Chong IW
FAU - Yang, Yi-Hsin
AU  - Yang YH
FAU - Tseng, Vincent S
AU  - Tseng VS
FAU - Dai, Hong-Jie
AU  - Dai HJ
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Pac Symp Biocomput
JT  - Pacific Symposium on Biocomputing. Pacific Symposium on Biocomputing
JID - 9711271
SB  - IM
MH  - Humans
MH  - *Feasibility Studies
MH  - *Registries/statistics & numerical data
MH  - *Computational Biology
MH  - *Lung Neoplasms/genetics
MH  - *Clinical Coding/statistics & numerical data
MH  - Natural Language Processing
MH  - Neoplasms/genetics
MH  - Electronic Health Records/statistics & numerical data
MH  - Workflow
EDAT- 2024/12/13 11:32
MHDA- 2024/12/13 11:33
CRDT- 2024/12/13 05:43
PHST- 2024/12/13 11:33 [medline]
PHST- 2024/12/13 11:32 [pubmed]
PHST- 2024/12/13 05:43 [entrez]
AID - 9789819807024_0010 [pii]
PST - ppublish
SO  - Pac Symp Biocomput. 2025;30:121-137.

PMID- 39987688
OWN - NLM
STAT- MEDLINE
DCOM- 20250323
LR  - 20250323
IS  - 1873-6750 (Electronic)
IS  - 0160-4120 (Linking)
VI  - 197
DP  - 2025 Mar
TI  - Using artificial intelligence tools for data quality evaluation in the context of 
      microplastic human health risk assessments.
PG  - 109341
LID - S0160-4120(25)00092-3 [pii]
LID - 10.1016/j.envint.2025.109341 [doi]
AB  - Concerns about the negative impacts of microplastics on human health are 
      increasing in society, while exposure and risk assessments require high-quality, 
      reliable data. Although quality assurance and -control (QA/QC) frameworks exist 
      to evaluate the reliability of data for these purposes, manually assessing 
      studies is too time-consuming and prone to inconsistencies due to semantic 
      ambiguities and evaluator bias. The rapid growth of microplastic studies makes 
      manually screening relevant data practically unfeasible. This study explores the 
      potential of artificial intelligence (AI), specifically large language models 
      (LLMs) such as OpenAI's ChatGPT and Google's Gemini, to streamline and 
      standardize the QA/QC screening of data in microplastics research. We developed 
      specific prompts based on previously published QA/QC criteria for the analysis of 
      microplastics in drinking water and its sources, and used these to instruct AI 
      tools to evaluate 73 studies published between 2011 and 2024. Our approach 
      demonstrated the effectiveness of AI in extracting relevant information, 
      interpreting the reliability of studies, and replicating human assessments. The 
      findings indicate that AI-assisted assessments show promise in improving speed, 
      consistency and applicability in QA/QC tasks, as well as in ranking studies or 
      datasets based on their suitability for exposure and risk assessments. This 
      groundbreaking application of LLMs in the environmental sciences suggests that AI 
      can play a vital role in harmonizing microplastics risk assessments within 
      regulatory frameworks and demonstrates how to meet the demands of an increasingly 
      data-intensive application domain.
CI  - Copyright © 2025 The Authors. Published by Elsevier Ltd.. All rights reserved.
FAU - Qiu, Yanning
AU  - Qiu Y
AD  - Aquatic Ecology and Water Quality Management Group, Wageningen University and 
      Research, P.O. Box 47 6700 AA Wageningen, the Netherlands. Electronic address: 
      yanning.qiu@wur.nl.
FAU - Mintenig, Svenja
AU  - Mintenig S
AD  - Aquatic Ecology and Water Quality Management Group, Wageningen University and 
      Research, P.O. Box 47 6700 AA Wageningen, the Netherlands.
FAU - Barchiesi, Margherita
AU  - Barchiesi M
AD  - Aquatic Ecology and Water Quality Management Group, Wageningen University and 
      Research, P.O. Box 47 6700 AA Wageningen, the Netherlands.
FAU - Koelmans, Albert A
AU  - Koelmans AA
AD  - Aquatic Ecology and Water Quality Management Group, Wageningen University and 
      Research, P.O. Box 47 6700 AA Wageningen, the Netherlands.
LA  - eng
PT  - Journal Article
DEP - 20250217
PL  - Netherlands
TA  - Environ Int
JT  - Environment international
JID - 7807270
RN  - 0 (Microplastics)
RN  - 0 (Water Pollutants, Chemical)
RN  - 0 (Drinking Water)
SB  - IM
MH  - Risk Assessment/methods
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Microplastics/analysis
MH  - Data Accuracy
MH  - Environmental Monitoring/methods
MH  - Water Pollutants, Chemical/analysis
MH  - Drinking Water/chemistry
MH  - Reproducibility of Results
OTO - NOTNLM
OT  - ChatGPT
OT  - Gemini
OT  - Large language models
OT  - Quality Assurance and Quality Control
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2025/02/24 02:10
MHDA- 2025/03/24 00:29
CRDT- 2025/02/23 18:04
PHST- 2024/12/24 00:00 [received]
PHST- 2025/02/05 00:00 [revised]
PHST- 2025/02/17 00:00 [accepted]
PHST- 2025/03/24 00:29 [medline]
PHST- 2025/02/24 02:10 [pubmed]
PHST- 2025/02/23 18:04 [entrez]
AID - S0160-4120(25)00092-3 [pii]
AID - 10.1016/j.envint.2025.109341 [doi]
PST - ppublish
SO  - Environ Int. 2025 Mar;197:109341. doi: 10.1016/j.envint.2025.109341. Epub 2025 
      Feb 17.

PMID- 40002637
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250228
IS  - 2075-4418 (Print)
IS  - 2075-4418 (Electronic)
IS  - 2075-4418 (Linking)
VI  - 15
IP  - 4
DP  - 2025 Feb 17
TI  - Addressing Multi-Center Variability in Radiomic Analysis: A Comparative Study of 
      Image Acquisition Methods Across Two 3T MRI Scanners.
LID - 10.3390/diagnostics15040485 [doi]
LID - 485
AB  - Background: Radiomics has become a valuable tool in medical imaging, but its 
      clinical use is limited by data variability and a lack of reproducibility between 
      centers. This study aims to assess the differences between two scanners and 
      provide guidance on image acquisition methods to reduce variations between images 
      obtained from different centers. Methods: This study utilized medical images 
      obtained in two different imaging centers, with two different 3T MRI scanners. 
      For each scanner, 3D T2 FLAIR sequences were acquired in two forms: the raw and 
      the clinical practice images typically used in diagnostic workflows. The 
      differences between images were analyzed regarding resolution, SNR, CNR, and 
      radiomic features. To facilitate comparison, bias field correction was applied, 
      and the data were standardized to the same scale using Z-score normalization. 
      Descriptive and inferential statistical methods were used to analyze the data. 
      Results: The results show that there are significant differences between centers. 
      Filtering and zero-padding significantly influence the resolution, SNR, CNR 
      values, and radiomics features. Applying Z-score normalization has resolved 
      variations in features sensitive to scale differences, but features reflecting 
      dispersion and extreme values remain significantly different between scanners. 
      Some feature differences may be resolved by analyzing the raw images in both 
      centers. Conclusions: Variations arise due to different acquisition parameters 
      and the differing quality and sensitivity of the equipment. In multi-center 
      studies, acquiring raw images and then applying standardized post-processing 
      methods across all images can enhance the robustness of results. This approach 
      minimizes technical differences, and preserves the integrity of the information, 
      reflecting a more accurate representation of reality and contributing to more 
      reliable and reproducible findings.
FAU - Tocilă-Mătășel, Claudia
AU  - Tocilă-Mătășel C
AUID- ORCID: 0000-0003-3578-0126
AD  - Department of Radiology, Faculty of Medicine, Iuliu Hatieganu University of 
      Medicine and Pharmacy, 400012 Cluj-Napoca, Romania.
AD  - Medima Health SA, 060254 Bucharest, Romania.
FAU - Dudea, Sorin Marian
AU  - Dudea SM
AD  - Department of Radiology, Faculty of Medicine, Iuliu Hatieganu University of 
      Medicine and Pharmacy, 400012 Cluj-Napoca, Romania.
FAU - Iana, Gheorghe
AU  - Iana G
AD  - Medima Health SA, 060254 Bucharest, Romania.
LA  - eng
PT  - Journal Article
DEP - 20250217
PL  - Switzerland
TA  - Diagnostics (Basel)
JT  - Diagnostics (Basel, Switzerland)
JID - 101658402
PMC - PMC11854186
OTO - NOTNLM
OT  - multi-scanner variability
OT  - radiomics reproducibility
OT  - raw image acquisition
COIS- Author Claudia Tocilă-Mătășel and Gheorghe Iana were employed by the company 
      Medima Health. The remaining authors declare that the research was conducted in 
      the absence of any commercial or financial relationships that could be construed 
      as a potential conflict of interest.
EDAT- 2025/02/26 06:28
MHDA- 2025/02/26 06:29
PMCR- 2025/02/17
CRDT- 2025/02/26 01:08
PHST- 2024/12/20 00:00 [received]
PHST- 2025/02/05 00:00 [revised]
PHST- 2025/02/12 00:00 [accepted]
PHST- 2025/02/26 06:29 [medline]
PHST- 2025/02/26 06:28 [pubmed]
PHST- 2025/02/26 01:08 [entrez]
PHST- 2025/02/17 00:00 [pmc-release]
AID - diagnostics15040485 [pii]
AID - diagnostics-15-00485 [pii]
AID - 10.3390/diagnostics15040485 [doi]
PST - epublish
SO  - Diagnostics (Basel). 2025 Feb 17;15(4):485. doi: 10.3390/diagnostics15040485.

PMID- 38977450
OWN - NLM
STAT- Publisher
LR  - 20240708
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
DP  - 2024 Jul 8
TI  - Response to "Letter to the Editor-Exploring the Unknown: Evaluating ChatGPT's 
      Performance in Uncovering Novel Aspects of Plastic Surgery and Identifying Areas 
      for Future Innovation".
LID - 10.1007/s00266-024-04210-y [doi]
AB  - We appreciate Dr. Qi and Dr. Niu for their insightful comments on our study, 
      "Exploring the Unknown: Evaluating ChatGPT's Performance in Uncovering Novel 
      Aspects of Plastic Surgery and Identifying Areas for Future Innovation." Their 
      observations underscore significant considerations in the application of 
      artificial intelligence (AI) in plastic surgery. We agree with their concern 
      about potential biases in ChatGPT's responses. The AI's frequent attribution of 
      the title "parent of plastic surgery" to Sir Harold Delf Gillies, despite 
      gender-neutral terminology, highlights underlying biases from training data. 
      These biases often reflect historical texts and contemporary writings. Addressing 
      them requires refining training datasets for balanced representation and 
      developing algorithms that adjust dynamically to diverse inputs. The authors also 
      question the criteria ChatGPT uses to identify key contributions to plastic 
      surgery. The AI's focus on microsurgery, minimally invasive techniques, and 
      tissue engineering, while significant, may prioritize keyword prevalence over a 
      holistic evaluation. Enhancing ChatGPT's capabilities through targeted training 
      and input from subject matter experts could improve the AI's ability to generate 
      more balanced outputs. The identified bias favoring reconstructive over cosmetic 
      procedures is another critical point. While reconstructive advancements are 
      transformative, cosmetic surgery also has significant innovations. Ensuring 
      ChatGPT presents a balanced view of both reconstructive and cosmetic advancements 
      is essential. This can be achieved by diversifying training data and calibrating 
      the AI to give equitable weight to different subspecialties within plastic 
      surgery. AI models like ChatGPT are proficient in processing and generating 
      information but lack the human elements of creativity, intuition, and emotional 
      depth critical for groundbreaking innovations. AI should complement, not replace, 
      the expert judgment and innovative thinking of skilled plastic surgeons. Ensuring 
      the accuracy of AI-generated responses is crucial. Clinicians must verify 
      AIgenerated information against established medical literature and clinical 
      guidelines to maintain accuracy in medical practice. Continuous feedback and 
      improvement mechanisms are vital to enhance AI's clinical utility. The 
      improvement of AI in plastic surgery will be driven by active involvement from 
      surgeons, providing comprehensive and balanced data for training to ensure AI 
      systems evolve to support and enhance clinical practice effectively.Level of 
      Evidence V This journal requires that authors assign a level of evidence to each 
      article. For a full description of these Evidence-Based Medicine ratings, please 
      refer to the Table of Contents or the online Instructions to Authors  
      www.springer.com/00266 .
CI  - © 2024. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Seth, Ishith
AU  - Seth I
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, 3199, Australia.
AD  - Central Clinical School, Monash University, Melbourne, Australia.
FAU - Lim, Bryan
AU  - Lim B
AUID- ORCID: 0009-0007-9647-5180
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, 3199, Australia. 
      lim.bryan58@gmail.com.
AD  - Central Clinical School, Monash University, Melbourne, Australia. 
      lim.bryan58@gmail.com.
FAU - Rozen, Warren M
AU  - Rozen WM
AD  - Department of Plastic Surgery, Peninsula Health, Melbourne, VIC, 3199, Australia.
AD  - Central Clinical School, Monash University, Melbourne, Australia.
LA  - eng
PT  - Letter
DEP - 20240708
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
EDAT- 2024/07/09 00:42
MHDA- 2024/07/09 00:42
CRDT- 2024/07/08 23:13
PHST- 2024/06/18 00:00 [received]
PHST- 2024/06/21 00:00 [accepted]
PHST- 2024/07/09 00:42 [medline]
PHST- 2024/07/09 00:42 [pubmed]
PHST- 2024/07/08 23:13 [entrez]
AID - 10.1007/s00266-024-04210-y [pii]
AID - 10.1007/s00266-024-04210-y [doi]
PST - aheadofprint
SO  - Aesthetic Plast Surg. 2024 Jul 8. doi: 10.1007/s00266-024-04210-y.

PMID- 39917120
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250208
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 17
IP  - 1
DP  - 2025 Jan
TI  - Evaluation of the Accuracy of Artificial Intelligence (AI) Models in 
      Dermatological Diagnosis and Comparison With Dermatology Specialists.
PG  - e77067
LID - 10.7759/cureus.77067 [doi]
LID - e77067
AB  - Recent advances in generative artificial intelligence (AI) have expanded its 
      applications in diagnostic support within dermatology, but its clinical accuracy 
      requires ongoing evaluation. This study compared the diagnostic performance of 
      three advanced AI models, ChatGPT-4o, Claude 3.5 Sonnet, and Gemini 1.5 Pro, with 
      that of board-certified dermatologists, using a dataset of 30 cases encompassing 
      a variety of dermatological conditions. The AI models demonstrated diagnostic 
      accuracy comparable to, and sometimes exceeding, that of the specialists, 
      particularly in rare and complex cases. Statistical analysis revealed no 
      significant difference in accuracy rates between the AI models and 
      dermatologists, indicating that AI may serve as a valuable supplementary 
      diagnostic tool in dermatological practice. Limitations include a small sample 
      size and potential selection bias. However, these findings underscore the 
      progress in AI's diagnostic capabilities, supporting further validation with 
      larger datasets and diverse clinical scenarios to confirm its practical utility.
CI  - Copyright © 2025, Yamamura et al.
FAU - Yamamura, Yuto
AU  - Yamamura Y
AD  - Department of Dermatology, Kindai University Hospital, Osakasayama, JPN.
FAU - Fujii, Kazuyasu
AU  - Fujii K
AD  - Department of Dermatology, Kindai University Hospital, Osakasayama, JPN.
FAU - Nakashima, Chisa
AU  - Nakashima C
AD  - Department of Dermatology, Kindai University Hospital, Osakasayama, JPN.
FAU - Otsuka, Atsushi
AU  - Otsuka A
AD  - Department of Dermatology, Kindai University Hospital, Osakasayama, JPN.
LA  - eng
PT  - Journal Article
DEP - 20250107
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11801811
OTO - NOTNLM
OT  - artificial intelligence
OT  - clinical evaluation
OT  - dermatology
OT  - diagnostic accuracy
OT  - generative models
COIS- Human subjects: All authors have confirmed that this study did not involve human 
      participants or tissue. Animal subjects: All authors have confirmed that this 
      study did not involve animal subjects or tissue. Conflicts of interest: In 
      compliance with the ICMJE uniform disclosure form, all authors declare the 
      following: Payment/services info: All authors have declared that no financial 
      support was received from any organization for the submitted work. Financial 
      relationships: All authors have declared that they have no financial 
      relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2025/02/07 11:12
MHDA- 2025/02/07 11:13
PMCR- 2025/01/07
CRDT- 2025/02/07 04:51
PHST- 2025/01/07 00:00 [accepted]
PHST- 2025/02/07 11:13 [medline]
PHST- 2025/02/07 11:12 [pubmed]
PHST- 2025/02/07 04:51 [entrez]
PHST- 2025/01/07 00:00 [pmc-release]
AID - 10.7759/cureus.77067 [doi]
PST - epublish
SO  - Cureus. 2025 Jan 7;17(1):e77067. doi: 10.7759/cureus.77067. eCollection 2025 Jan.

PMID- 38222433
OWN - NLM
STAT- MEDLINE
DCOM- 20240117
LR  - 20240210
IS  - 1942-597X (Electronic)
IS  - 1559-4076 (Linking)
VI  - 2023
DP  - 2023
TI  - Backdoor Adjustment of Confounding by Provenance for Robust Text Classification 
      of Multi-institutional Clinical Notes.
PG  - 923-932
AB  - Natural Language Processing (NLP) methods have been broadly applied to clinical 
      tasks. Machine learning and deep learning approaches have been used to improve 
      the performance of clinical NLP. However, these approaches require sufficiently 
      large datasets for training, and trained models have been shown to transfer 
      poorly across sites. These issues have led to the promotion of data collection 
      and integration across different institutions for accurate and portable models. 
      However, this can introduce a form of bias called confounding by provenance. When 
      source-specific data distributions differ at deployment, this may harm model 
      performance. To address this issue, we evaluate the utility of backdoor 
      adjustment for text classification in a multi-site dataset of clinical notes 
      annotated for mentions of substance abuse. Using an evaluation framework devised 
      to measure robustness to distributional shifts, we assess the utility of backdoor 
      adjustment. Our results indicate that backdoor adjustment can effectively 
      mitigate for confounding shift.
CI  - ©2023 AMIA - All rights reserved.
FAU - Ding, Xiruo
AU  - Ding X
AD  - University of Washington, Seattle, WA, USA.
FAU - Sheng, Zhecheng
AU  - Sheng Z
AD  - University of Minnesota, Twin Cities, MN, USA.
FAU - Yetişgen, Meliha
AU  - Yetişgen M
AD  - University of Washington, Seattle, WA, USA.
FAU - Pakhomov, Serguei
AU  - Pakhomov S
AD  - University of Minnesota, Twin Cities, MN, USA.
FAU - Cohen, Trevor
AU  - Cohen T
AD  - University of Washington, Seattle, WA, USA.
LA  - eng
GR  - R01 LM014056/LM/NLM NIH HHS/United States
PT  - Journal Article
DEP - 20240111
PL  - United States
TA  - AMIA Annu Symp Proc
JT  - AMIA ... Annual Symposium proceedings. AMIA Symposium
JID - 101209213
SB  - IM
MH  - Humans
MH  - Data Collection
MH  - *Electronic Health Records
MH  - Machine Learning
MH  - Natural Language Processing
MH  - *Substance-Related Disorders
MH  - Multicenter Studies as Topic
PMC - PMC10785933
EDAT- 2024/01/15 06:42
MHDA- 2024/01/16 06:41
PMCR- 2024/01/11
CRDT- 2024/01/15 04:33
PHST- 2024/01/16 06:41 [medline]
PHST- 2024/01/15 06:42 [pubmed]
PHST- 2024/01/15 04:33 [entrez]
PHST- 2024/01/11 00:00 [pmc-release]
AID - 1411 [pii]
PST - epublish
SO  - AMIA Annu Symp Proc. 2024 Jan 11;2023:923-932. eCollection 2023.

PMID- 39924308
OWN - NLM
STAT- MEDLINE
DCOM- 20250209
LR  - 20250218
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 9
DP  - 2025 Feb 7
TI  - Assessment of Digital Capabilities by 9 Countries in the Alliance for Healthy 
      Cities Using AI: Cross-Sectional Analysis.
PG  - e62935
LID - 10.2196/62935 [doi]
LID - e62935
AB  - BACKGROUND: The Alma-Ata Declaration of 1978 initiated a global focus on 
      universal health, supported by the World Health Organization (WHO) through 
      healthy cities policies. The concept emerged at the 1984 Toronto "Beyond Health 
      Care" conference, leading to WHO's first pilot project in Lisbon in 1986. The WHO 
      continues to support regional healthy city networks, emphasizing digital 
      transformation and data-driven health management in the digital era. OBJECTIVE: 
      This study explored the capabilities of digital healthy cities within the 
      framework of digital transformation, focusing on member countries of the Asian 
      Forum of Healthy Cities. It examined the cities' preparedness and policy needs 
      for transitioning to digital health. METHODS: A cross-sectional survey was 
      conducted of 9 countries-Australia, Cambodia, China, Japan, South Korea, 
      Malaysia, Mongolia, the Philippines, and Vietnam-from August 1 to September 21, 
      2023. The 6-section SPIRIT (setting approach and sustainability; political 
      commitment, policy, and community participation; information and innovation; 
      resources and research; infrastructure and intersectoral; and training) checklist 
      was modified to assess healthy cities' digital capabilities. With input from 3 
      healthy city experts, the checklist was revised for digital capabilities, 
      renaming "healthy city" to "digital healthy city." The revised tool comprises 8 
      sections with 33 items. The survey leveraged ChatGPT (version 4.0; OpenAI, 
      Microsoft), accessed via Python (Python Software Foundation) application 
      programming interface. The openai library was installed, and an application 
      programming interface key was entered to use ChatGPT (version 4.0). The "GPT-4 
      Turbo" model command was applied. A qualitative analysis of the collected data 
      was conducted by 5 healthy city experts through group deep-discussions. RESULTS: 
      The results indicate that these countries should establish networks and 
      committees for sustainable digital healthy cities. Cambodia showed the lowest 
      access to electricity (70%) and significant digital infrastructure disparities. 
      Efforts to sustain digital health initiatives varied, with countries such as 
      Korea focusing on telemedicine, while China aimed to build a comprehensive 
      digital health database, highlighting the need for tailored strategies in 
      promoting digital healthy cities. Life expectancy was the highest in the Republic 
      of Korea and Japan (both 84 y). Access to electricity was the lowest in Cambodia 
      (70%) with the remaining countries having had 95% or higher access. The internet 
      use rate was the highest in Malaysia (97.4%), followed by the Republic of Korea 
      (97.2%), Australia (96.2%), and Japan (82.9%). CONCLUSIONS: This study highlights 
      the importance of big data-driven policies and personal information protection 
      systems. Collaborative efforts across sectors for effective implementation of 
      digital healthy cities. The findings suggest that the effectiveness of digital 
      healthy cities is diminished without adequate digital literacy among managers and 
      users, suggesting the need for policies to improve digital literacy.
CI  - © Hocheol Lee Originally published in JMIR Formative Research 
      (https://formative.jmir.org).
FAU - Lee, Hocheol
AU  - Lee H
AD  - Department of Health Administration, College of Software and Digital Healthcare 
      Convergence, Yonsei University, PO Box 26493, Wonju, Repubic of Korea.
LA  - eng
PT  - Journal Article
DEP - 20250207
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
SB  - IM
MH  - Cross-Sectional Studies
MH  - Humans
MH  - *Cities
MH  - Artificial Intelligence
MH  - World Health Organization
MH  - Australia
MH  - Surveys and Questionnaires
PMC - PMC11830481
OTO - NOTNLM
OT  - health management
OT  - AI
OT  - Asian Forum of Healthy Cities
OT  - WHO
OT  - World Health Organization
OT  - artificial intelligence
OT  - assessment
OT  - cross-sectional survey
OT  - data
OT  - database
OT  - digital capabilities
OT  - digital era
OT  - digital health
OT  - digital health cities
OT  - digital health database
OT  - digital literacy
OT  - digital transformation
OT  - effectiveness
OT  - healthy city
OT  - qualitative analysis
COIS- None declared.
EDAT- 2025/02/10 00:19
MHDA- 2025/02/10 00:20
PMCR- 2025/02/07
CRDT- 2025/02/09 21:33
PHST- 2024/06/05 00:00 [received]
PHST- 2024/12/04 00:00 [revised]
PHST- 2024/12/05 00:00 [accepted]
PHST- 2025/02/10 00:20 [medline]
PHST- 2025/02/10 00:19 [pubmed]
PHST- 2025/02/09 21:33 [entrez]
PHST- 2025/02/07 00:00 [pmc-release]
AID - v9i1e62935 [pii]
AID - 62935 [pii]
AID - 10.2196/62935 [doi]
PST - epublish
SO  - JMIR Form Res. 2025 Feb 7;9:e62935. doi: 10.2196/62935.

PMID- 39327389
OWN - NLM
STAT- MEDLINE
DCOM- 20241014
LR  - 20241031
IS  - 1179-1993 (Electronic)
IS  - 1178-2595 (Print)
IS  - 1178-2595 (Linking)
VI  - 38
IP  - 5
DP  - 2024 Sep
TI  - Automated Mass Extraction of Over 680,000 PICOs from Clinical Study Abstracts 
      Using Generative AI: A Proof-of-Concept Study.
PG  - 365-372
LID - 10.1007/s40290-024-00539-6 [doi]
AB  - BACKGROUND: Generative artificial intelligence (GenAI) shows promise in 
      automating key tasks involved in conducting systematic literature reviews (SLRs), 
      including screening, bias assessment and data extraction. This potential 
      automation is increasingly relevant as pharmaceutical developers face challenging 
      requirements for timely and precise SLRs using the population, intervention, 
      comparator and outcome (PICO) framework, such as those under the impending 
      European Union (EU) Health Technology Assessment Regulation 2021/2282 (HTAR). 
      This proof-of-concept study aimed to evaluate the feasibility, accuracy and 
      efficiency of using GenAI for mass extraction of PICOs from PubMed abstracts. 
      METHODS: Abstracts were retrieved from PubMed using a search string targeting 
      randomised controlled trials. A PubMed clinical study 'specific/narrow' filter 
      was also applied. Retrieved abstracts were processed using the OpenAI Batch 
      application programming interface (API), which allowed parallel processing and 
      interaction with Generative Pre-trained Transformer 4 Omni (GPT-4o) via custom 
      Python scripts. PICO elements were extracted using a zero-shot prompting 
      strategy. Results were stored in CSV files and subsequently imported into a 
      PostgreSQL database. RESULTS: The PubMed search returned 682,667 abstracts. PICOs 
      from all abstracts were extracted in < 3 h, with an average processing time of 
      200 s per 1000 abstracts. A total of 395,992,770 tokens were processed, with an 
      average of 580 tokens per abstract. The total cost was $3390. On the basis of a 
      random sample of 350 abstracts, human verification confirmed that GPT-4o 
      accurately and comprehensively extracted 342 (98%) of all PICOs, with only 
      outcome elements rarely missed. CONCLUSIONS: Using GenAI to extract PICOs from 
      clinical study abstracts could fundamentally transform the way SLRs are 
      conducted. By enabling pharmaceutical developers to anticipate PICO requirements, 
      this approach allows for proactive preparation for the EU HTAR process, or other 
      health technology assessments (HTAs), streamlining efficiency and reducing the 
      burden of meeting these requirements.
CI  - © 2024. The Author(s).
FAU - Reason, Tim
AU  - Reason T
AD  - Estima Scientific, Mediaworks, 191 Wood Lane, London, W12 7FP, UK. 
      tim.reason@estima-sci.com.
FAU - Langham, Julia
AU  - Langham J
AD  - Estima Scientific, Mediaworks, 191 Wood Lane, London, W12 7FP, UK.
FAU - Gimblett, Andy
AU  - Gimblett A
AD  - Estima Scientific, Mediaworks, 191 Wood Lane, London, W12 7FP, UK.
LA  - eng
PT  - Journal Article
DEP - 20240926
PL  - New Zealand
TA  - Pharmaceut Med
JT  - Pharmaceutical medicine
JID - 101471195
SB  - IM
MH  - Humans
MH  - Abstracting and Indexing/methods
MH  - *Artificial Intelligence
MH  - *Proof of Concept Study
MH  - PubMed
MH  - Randomized Controlled Trials as Topic
MH  - Systematic Reviews as Topic/methods
MH  - Technology Assessment, Biomedical
PMC - PMC11473607
OAB - This study explored how artificial intelligence (AI) can help automate a key part 
      of systematic literature reviews (SLRs), which are used to summarise research in 
      healthcare. AI was used to extract specific information referred to as 
      population, intervention, comparator and outcome (PICOs) from nearly 700,000 
      abstracts of clinical studies from the PubMed database. AI extracted the PICO 
      information from all the abstracts in under 3 h, which is significantly faster 
      than a human could do. This demonstrates that AI could save a lot of time and 
      effort compared with using human reviewers to do the same task. The study also 
      found that AI performed accurately in identifying the PICO elements in the 
      abstracts, although further human verification is still required. The use of AI 
      in this way could help pharmaceutical developers meet upcoming requirements from 
      the European Union, which require timely and thorough reviews of clinical 
      evidence. AI can speed up the process, reducing the burden on pharmaceutical 
      developers and allowing them to prepare more efficiently for these assessments. 
      However, further testing and validation is needed before using AI in this way 
      becomes common.
OABL- eng
COIS- All authors are employees at Estima Scientific.
EDAT- 2024/09/27 00:42
MHDA- 2024/10/14 12:23
PMCR- 2024/09/26
CRDT- 2024/09/26 23:19
PHST- 2024/09/18 00:00 [accepted]
PHST- 2024/10/14 12:23 [medline]
PHST- 2024/09/27 00:42 [pubmed]
PHST- 2024/09/26 23:19 [entrez]
PHST- 2024/09/26 00:00 [pmc-release]
AID - 10.1007/s40290-024-00539-6 [pii]
AID - 539 [pii]
AID - 10.1007/s40290-024-00539-6 [doi]
PST - ppublish
SO  - Pharmaceut Med. 2024 Sep;38(5):365-372. doi: 10.1007/s40290-024-00539-6. Epub 
      2024 Sep 26.

PMID- 31272093
OWN - NLM
STAT- MEDLINE
DCOM- 20200325
LR  - 20220310
IS  - 1361-6560 (Electronic)
IS  - 0031-9155 (Linking)
VI  - 64
IP  - 16
DP  - 2019 Aug 21
TI  - Impact of image preprocessing on the scanner dependence of multi-parametric MRI 
      radiomic features and covariate shift in multi-institutional glioblastoma 
      datasets.
PG  - 165011
LID - 10.1088/1361-6560/ab2f44 [doi]
AB  - Recent advances in radiomics have enhanced the value of medical imaging in 
      various aspects of clinical practice, but a crucial component that remains to be 
      investigated further is the robustness of quantitative features to imaging 
      variations and across multiple institutions. In the case of MRI, signal intensity 
      values vary according to the acquisition parameters used, yet no consensus exists 
      on which preprocessing techniques are favorable in reducing scanner-dependent 
      variability of image-based features. Hence, the purpose of this study was to 
      assess the impact of common image preprocessing methods on the scanner dependence 
      of MRI radiomic features in multi-institutional glioblastoma multiforme (GBM) 
      datasets. Two independent GBM cohorts were analyzed: 50 cases from the TCGA-GBM 
      dataset and 111 cases acquired in our institution, and each case consisted of 3 
      MRI sequences viz. FLAIR, T1-weighted, and T1-weighted post-contrast. Five image 
      preprocessing techniques were examined: 8-bit global rescaling, 8-bit local 
      rescaling, bias field correction, histogram standardization, and isotropic 
      resampling. A total of 420 features divided into eight categories representing 
      texture, shape, edge, and intensity histogram were extracted. Two distinct 
      imaging parameters were considered: scanner manufacturer and scanner magnetic 
      field strength. Wilcoxon tests identified features robust to the considered 
      acquisition parameters under the selected image preprocessing techniques. A 
      machine learning-based strategy was implemented to measure the covariate shift 
      between the analyzed datasets using features computed using the aforementioned 
      preprocessing methods. Finally, radiomic scores (rad-scores) were constructed by 
      identifying features relevant to patients' overall survival after eliminating 
      those impacted by scanner variability. These were then evaluated for their 
      prognostic significance through Kaplan-Meier and Cox hazards regression analyses. 
      Our results demonstrate that overall, histogram standardization contributes the 
      most in reducing radiomic feature variability as it is the technique to reduce 
      the covariate shift for three feature categories and successfully discriminate 
      patients into groups of different survival risks.
FAU - Um, Hyemin
AU  - Um H
AD  - Department of Medical Physics, Memorial Sloan Kettering Cancer Center, New York, 
      NY 10065, United States of America. Authors contributed equally to this work. 
      Author to whom any correspondence should be addressed. Department of Medical 
      Physics, Memorial Sloan Kettering Cancer Center, 485 Lexington Avenue, New York, 
      NY 10017, United States of America.
FAU - Tixier, Florent
AU  - Tixier F
FAU - Bermudez, Dalton
AU  - Bermudez D
FAU - Deasy, Joseph O
AU  - Deasy JO
FAU - Young, Robert J
AU  - Young RJ
FAU - Veeraraghavan, Harini
AU  - Veeraraghavan H
LA  - eng
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20190821
PL  - England
TA  - Phys Med Biol
JT  - Physics in medicine and biology
JID - 0401220
SB  - IM
MH  - Analysis of Variance
MH  - Brain Neoplasms
MH  - Databases, Factual
MH  - Glioblastoma/*diagnostic imaging
MH  - Humans
MH  - Image Processing, Computer-Assisted/*methods
MH  - Machine Learning
MH  - *Multiparametric Magnetic Resonance Imaging
MH  - Prognosis
EDAT- 2019/07/05 06:00
MHDA- 2020/03/26 06:00
CRDT- 2019/07/05 06:00
PHST- 2019/07/05 06:00 [pubmed]
PHST- 2020/03/26 06:00 [medline]
PHST- 2019/07/05 06:00 [entrez]
AID - 10.1088/1361-6560/ab2f44 [doi]
PST - epublish
SO  - Phys Med Biol. 2019 Aug 21;64(16):165011. doi: 10.1088/1361-6560/ab2f44.

PMID- 29103145
OWN - NLM
STAT- MEDLINE
DCOM- 20180702
LR  - 20181202
IS  - 1432-1920 (Electronic)
IS  - 0028-3940 (Linking)
VI  - 60
IP  - 1
DP  - 2018 Jan
TI  - Increased signal intensity within glioblastoma resection cavities on 
      fluid-attenuated inversion recovery imaging to detect early progressive disease 
      in patients receiving radiotherapy with concomitant temozolomide therapy.
PG  - 35-42
LID - 10.1007/s00234-017-1941-9 [doi]
AB  - PURPOSE: Our study tested the diagnostic accuracy of increased signal intensity 
      (SI) within FLAIR MR images of resection cavities in differentiating early 
      progressive disease (ePD) from pseudoprogression (PsP) in patients with 
      glioblastoma treated with radiotherapy with concomitant temozolomide therapy. 
      METHODS: In this retrospective study approved by our Institutional Review Board, 
      we evaluated the records of 122 consecutive patients with partially or totally 
      resected glioblastoma. Region of interest (ROI) analysis assessed 33 MR 
      examinations from 11 subjects with histologically confirmed ePD and 37 MR 
      examinations from 14 subjects with PsP (5 histologically confirmed, 9 clinically 
      diagnosed). After applying an N4 bias correction algorithm to remove B0 field 
      distortion and to standardize image intensities and then normalizing the 
      intensities based on an ROI of uninvolved white matter from the contralateral 
      hemisphere, the mean intensities of the ROI from within the resection cavities 
      were calculated. Measures of diagnostic performance were calculated from the 
      receiver operating characteristic (ROC) curve using the threshold intensity that 
      maximized differentiation. Subgroup analysis explored differences between the 
      patients with biopsy-confirmed disease. RESULTS: At an optimal threshold 
      intensity of 2.9, the area under the ROC curve (AUROC) for FLAIR to differentiate 
      ePD from PsP was 0.79 (95% confidence interval 0.686-0.873) with a sensitivity of 
      0.818 and specificity of 0.694. The AUROC increased to 0.86 when only the 
      patients with biopsy-confirmed PsP were considered. CONCLUSIONS: Increased SI 
      within the resection cavity of FLAIR images is not a highly specific sign of ePD 
      in glioblastoma patients treated with the Stupp protocol.
FAU - Perry, Luke A
AU  - Perry LA
AD  - Monash University, Melbourne, Australia.
FAU - Korfiatis, Panagiotis
AU  - Korfiatis P
AD  - Department of Radiology, Mayo Clinic Rochester, 200 First St Sw, Rochester, MN, 
      55905, USA.
FAU - Agrawal, Jay P
AU  - Agrawal JP
AD  - Department of Radiology, University of Massachusetts Medical School, Worcester, 
      MA, USA.
FAU - Erickson, Bradley J
AU  - Erickson BJ
AD  - Department of Radiology, Mayo Clinic Rochester, 200 First St Sw, Rochester, MN, 
      55905, USA. bje@mayo.edu.
LA  - eng
GR  - CA160045/National Cancer Institute/
GR  - CA160045/National Cancer Institute/
PT  - Journal Article
DEP - 20171104
PL  - Germany
TA  - Neuroradiology
JT  - Neuroradiology
JID - 1302751
RN  - 0 (Antineoplastic Agents, Alkylating)
RN  - 7GR28W0FJI (Dacarbazine)
RN  - YF1K15M17Y (Temozolomide)
SB  - IM
MH  - Antineoplastic Agents, Alkylating/*therapeutic use
MH  - Brain Neoplasms/*diagnostic imaging/*therapy
MH  - Combined Modality Therapy
MH  - Dacarbazine/*analogs & derivatives/therapeutic use
MH  - Disease Progression
MH  - Female
MH  - Glioblastoma/*diagnostic imaging/*therapy
MH  - Humans
MH  - Magnetic Resonance Imaging/*methods
MH  - Male
MH  - Middle Aged
MH  - Retrospective Studies
MH  - Sensitivity and Specificity
MH  - Temozolomide
OTO - NOTNLM
OT  - Glioblastoma
OT  - MRI
OT  - Pseudoprogression
EDAT- 2017/11/06 06:00
MHDA- 2018/07/03 06:00
CRDT- 2017/11/06 06:00
PHST- 2017/08/28 00:00 [received]
PHST- 2017/10/18 00:00 [accepted]
PHST- 2017/11/06 06:00 [pubmed]
PHST- 2018/07/03 06:00 [medline]
PHST- 2017/11/06 06:00 [entrez]
AID - 10.1007/s00234-017-1941-9 [pii]
AID - 10.1007/s00234-017-1941-9 [doi]
PST - ppublish
SO  - Neuroradiology. 2018 Jan;60(1):35-42. doi: 10.1007/s00234-017-1941-9. Epub 2017 
      Nov 4.

PMID- 32537587
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20200928
IS  - 2575-7873 (Electronic)
IS  - 2575-7873 (Linking)
VI  - 3
DP  - 2019
TI  - Selected Abstracts From the Proceedings of the 2019 Society of Teachers of Family 
      Medicine Conference on Medical Student Education.
PG  - 16
LID - 10.22454/PRiMER.2019.619113 [doi]
LID - 16
AB  - From January 31 through February 3, 2019 the Society of Teachers of Family 
      Medicine (STFM) held its 45th annual Conference on Medical Student Education in 
      Jacksonville, Florida. STFM is a collaborative organization composed of members 
      who are dedicated to teaching the discipline to learners of any level. The 
      conference brings together members including physicians, administrators, 
      behavioral scientists, researchers, residents, and students to learn from one 
      another and improve the quality of family medicine education in the United States 
      and Canada. Abstracts for all conference submissions can be found on the STFM 
      website.1 Plenary speakers addressed topics related to health equity (Joanne 
      Rooney, JD, LLM, EdD); discrimination and bias in the medical workplace (Roberto 
      E. Montenegro, MD, PhD); and mentoring in family medicine (Beat Steiner, MD, MPH, 
      STFM President). The STFM Committee on Medical Student Education reviewed the 14 
      completed educational research projects and selected six exemplary abstracts as 
      the best of the conference. Criteria for inclusion included relevance to medical 
      student education with a focus on family medicine education, study quality, and 
      meaningful conclusions. Five of the abstracts appear in this collection. One has 
      been published in the intervening time.2.
CI  - © 2019 by the Society of Teachers of Family Medicine.
FAU - Norris, David R
AU  - Norris DR
AD  - University of Mississippi School of Medicine, Jackson, MS.
FAU - Jortberg, Bonnie
AU  - Jortberg B
AD  - University of Colorado School of Medicine, Aurora, CO.
LA  - eng
PT  - Journal Article
DEP - 20190528
PL  - United States
TA  - PRiMER
JT  - PRiMER (Leawood, Kan.)
JID - 101726396
PMC - PMC7205125
EDAT- 2020/06/17 06:00
MHDA- 2020/06/17 06:01
PMCR- 2019/05/28
CRDT- 2020/06/16 06:00
PHST- 2020/06/16 06:00 [entrez]
PHST- 2020/06/17 06:00 [pubmed]
PHST- 2020/06/17 06:01 [medline]
PHST- 2019/05/28 00:00 [pmc-release]
AID - primer-3-16 [pii]
AID - 10.22454/PRiMER.2019.619113 [doi]
PST - epublish
SO  - PRiMER. 2019 May 28;3:16. doi: 10.22454/PRiMER.2019.619113. eCollection 2019.

PMID- 40146672
OWN - NLM
STAT- Publisher
LR  - 20250327
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
DP  - 2025 Mar 27
TI  - Evaluating the value of AI-generated questions for USMLE step 1 preparation: A 
      study using ChatGPT-3.5.
PG  - 1-9
LID - 10.1080/0142159X.2025.2478872 [doi]
AB  - PURPOSE: Students are increasingly relying on artificial intelligence (AI) for 
      medical education and exam preparation. However, the factual accuracy and content 
      distribution of AI-generated exam questions for self-assessment have not been 
      systematically investigated. METHODS: Curated prompts were created to generate 
      multiple-choice questions matching the USMLE Step 1 examination style. We 
      utilized ChatGPT-3.5 to generate 50 questions and answers based upon each prompt 
      style. We manually examined output for factual accuracy, Bloom's Taxonomy, and 
      category within the USMLE Step 1 content outline. RESULTS: ChatGPT-3.5 generated 
      150 multiple-choice case-style questions and selected an answer. Overall, 83% of 
      generated multiple questions had no factual inaccuracies and 15% contained one to 
      two factual inaccuracies. With simple prompting, common themes included deep 
      venous thrombosis, myocardial infarction, and thyroid disease. Topic diversity 
      improved by separating content topic generation from question generation, and 
      specificity to Step 1 increased by indicating that "treatment" questions were not 
      desired. CONCLUSION: We demonstrate that ChatGPT-3.5 can successfully generate 
      Step 1 style questions with reasonable factual accuracy, and this method may be 
      used by medical students preparing for USMLE examinations. While AI-generated 
      questions demonstrated adequate factual accuracy, targeted prompting techniques 
      should be used to overcome ChatGPT's bias towards particular medical conditions.
FAU - Balu, Alan
AU  - Balu A
AUID- ORCID: 0000-0001-9974-906X
AD  - Department of Neurosurgery, Georgetown University School of Medicine, Washington, 
      DC, USA.
FAU - Prvulovic, Stefan T
AU  - Prvulovic ST
AD  - Department of Neurosurgery, Georgetown University School of Medicine, Washington, 
      DC, USA.
FAU - Fernandez Perez, Claudia
AU  - Fernandez Perez C
AD  - Department of Neurosurgery, Georgetown University School of Medicine, Washington, 
      DC, USA.
FAU - Kim, Alexander
AU  - Kim A
AD  - Department of Neurosurgery, Georgetown University School of Medicine, Washington, 
      DC, USA.
FAU - Donoho, Daniel A
AU  - Donoho DA
AD  - Department of Neurosurgery, Children's National Hospital, Washington, DC, USA.
FAU - Keating, Gregory
AU  - Keating G
AD  - Department of Neurosurgery, MedStar Georgetown University Hospital, Washington, 
      DC, USA.
LA  - eng
PT  - Journal Article
DEP - 20250327
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - LLM
OT  - Step 1
OT  - USMLE
EDAT- 2025/03/27 18:26
MHDA- 2025/03/27 18:26
CRDT- 2025/03/27 13:23
PHST- 2025/03/27 18:26 [medline]
PHST- 2025/03/27 18:26 [pubmed]
PHST- 2025/03/27 13:23 [entrez]
AID - 10.1080/0142159X.2025.2478872 [doi]
PST - aheadofprint
SO  - Med Teach. 2025 Mar 27:1-9. doi: 10.1080/0142159X.2025.2478872.

PMID- 38544748
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250115
IS  - 2059-8661 (Electronic)
IS  - 2059-8661 (Linking)
VI  - 8
IP  - 1
DP  - 2024
TI  - Identifying incarceration status in the electronic health record using large 
      language models in emergency department settings.
PG  - e53
LID - 10.1017/cts.2024.496 [doi]
LID - e53
AB  - BACKGROUND: Incarceration is a significant social determinant of health, 
      contributing to high morbidity, mortality, and racialized health inequities. 
      However, incarceration status is largely invisible to health services research 
      due to inadequate clinical electronic health record (EHR) capture. This study 
      aims to develop, train, and validate natural language processing (NLP) techniques 
      to more effectively identify incarceration status in the EHR. METHODS: The study 
      population consisted of adult patients (≥ 18 y.o.) who presented to the emergency 
      department between June 2013 and August 2021. The EHR database was filtered for 
      notes for specific incarceration-related terms, and then a random selection of 
      1,000 notes was annotated for incarceration and further stratified into specific 
      statuses of prior history, recent, and current incarceration. For NLP model 
      development, 80% of the notes were used to train the Longformer-based and RoBERTa 
      algorithms. The remaining 20% of the notes underwent analysis with GPT-4. 
      RESULTS: There were 849 unique patients across 989 visits in the 1000 annotated 
      notes. Manual annotation revealed that 559 of 1000 notes (55.9%) contained 
      evidence of incarceration history. ICD-10 code (sensitivity: 4.8%, specificity: 
      99.1%, F1-score: 0.09) demonstrated inferior performance to RoBERTa NLP 
      (sensitivity: 78.6%, specificity: 73.3%, F1-score: 0.79), Longformer NLP 
      (sensitivity: 94.6%, specificity: 87.5%, F1-score: 0.93), and GPT-4 (sensitivity: 
      100%, specificity: 61.1%, F1-score: 0.86). CONCLUSIONS: Our advanced NLP models 
      demonstrate a high degree of accuracy in identifying incarceration status from 
      clinical notes. Further research is needed to explore their scaled implementation 
      in population health initiatives and assess their potential to mitigate health 
      disparities through tailored system interventions.
CI  - © The Author(s) 2024.
FAU - Huang, Thomas
AU  - Huang T
AUID- ORCID: 0000-0001-9056-7016
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, USA.
FAU - Socrates, Vimig
AU  - Socrates V
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
AD  - Program of Computational Biology and Bioinformatics, Yale University, New Haven, 
      CT, USA.
FAU - Gilson, Aidan
AU  - Gilson A
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, USA.
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
FAU - Safranek, Conrad
AU  - Safranek C
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, USA.
FAU - Chi, Ling
AU  - Chi L
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
FAU - Wang, Emily A
AU  - Wang EA
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
AD  - SEICHE Center for Health and Justice, Yale School of Medicine, New Haven, CT, 
      USA.
AD  - Department of Medicine, Yale School of Medicine, New Haven, CT, USA.
FAU - Puglisi, Lisa B
AU  - Puglisi LB
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
AD  - SEICHE Center for Health and Justice, Yale School of Medicine, New Haven, CT, 
      USA.
AD  - Department of Medicine, Yale School of Medicine, New Haven, CT, USA.
FAU - Brandt, Cynthia
AU  - Brandt C
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
FAU - Taylor, R Andrew
AU  - Taylor RA
AUID- ORCID: 0000-0002-9082-6644
AD  - Department of Emergency Medicine, Yale School of Medicine, New Haven, CT, USA.
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
FAU - Wang, Karen
AU  - Wang K
AD  - Section for Biomedical Informatics and Data Science, Yale University School of 
      Medicine, New Haven, CT, USA.
AD  - SEICHE Center for Health and Justice, Yale School of Medicine, New Haven, CT, 
      USA.
AD  - Department of Medicine, Yale School of Medicine, New Haven, CT, USA.
AD  - Equity Research and Innovation Center, Yale School of Medicine, Yale University, 
      New Haven, CT, USA.
LA  - eng
GR  - T35 HL007649/HL/NHLBI NIH HHS/United States
PT  - Journal Article
DEP - 20240311
PL  - England
TA  - J Clin Transl Sci
JT  - Journal of clinical and translational science
JID - 101689953
PMC - PMC10966832
OTO - NOTNLM
OT  - ChatGPT
OT  - emergency department
OT  - incarceration
OT  - justice involvement
OT  - large language models
OT  - machine learning
OT  - natural language processing
COIS- None.
EDAT- 2024/03/28 06:44
MHDA- 2024/03/28 06:45
PMCR- 2024/03/11
CRDT- 2024/03/28 03:52
PHST- 2023/10/24 00:00 [received]
PHST- 2024/02/06 00:00 [revised]
PHST- 2024/03/06 00:00 [accepted]
PHST- 2024/03/28 06:45 [medline]
PHST- 2024/03/28 06:44 [pubmed]
PHST- 2024/03/28 03:52 [entrez]
PHST- 2024/03/11 00:00 [pmc-release]
AID - S2059866124004965 [pii]
AID - 10.1017/cts.2024.496 [doi]
PST - epublish
SO  - J Clin Transl Sci. 2024 Mar 11;8(1):e53. doi: 10.1017/cts.2024.496. eCollection 
      2024.

PMID- 38440617
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250202
IS  - 2231-3796 (Print)
IS  - 0973-7707 (Electronic)
IS  - 2231-3796 (Linking)
VI  - 76
IP  - 1
DP  - 2024 Feb
TI  - ChatGPT in Head and Neck Oncology-Opportunities and Challenges.
PG  - 1425-1429
LID - 10.1007/s12070-023-04201-6 [doi]
AB  - Head and neck oncology represents a complex and challenging field, encompassing 
      the diagnosis, treatment and management of various malignancies affecting the 
      intricate anatomical structures of the head and neck region. With advancements in 
      artificial intelligence (AI), chatbot applications have emerged as a promising 
      tool to revolutionize the field of Head and Neck oncology. ChatGPT is a 
      cutting-edge language model developed by OpenAI that can help the oncologist in 
      the clinic in scheduling appointments, establishing a clinical diagnosis, making 
      a treatment plan and follow-up. ChatGPT also plays an essential role in 
      telemedicine consultations, medical documentation, scientific writing and 
      research. ChatGPT carries its inherent drawbacks too. ChatGPT raises significant 
      ethical concerns related to authorship, accountability, transparency, bias, and 
      the potential for misinformation. ChatGPT's training data is limited to September 
      2021; thus, regular updates are required to keep pace with the rapidly evolving 
      medical research and advancements. Therefore, a judicial approach to using 
      ChatGPT is of utmost importance. Head and Neck Oncologists can reap the maximum 
      benefit of this technology in terms of patient care, education and research to 
      improve clinical outcomes.
CI  - © Association of Otolaryngologists of India 2023. Springer Nature or its licensor 
      (e.g. a society or other partner) holds exclusive rights to this article under a 
      publishing agreement with the author(s) or other rightsholder(s); author 
      self-archiving of the accepted manuscript version of this article is solely 
      governed by the terms of such publishing agreement and applicable law.
FAU - Sarma, Gautam
AU  - Sarma G
AUID- ORCID: 0000-0002-2907-210X
AD  - Department of Radiation Oncology, All India Institute of Medical Sciences 
      Guwahati, Changsari, Assam, 781101 India. ROR: https://ror.org/000kxhc93
FAU - Kashyap, Hrishikesh
AU  - Kashyap H
AUID- ORCID: 0009-0004-2591-3022
AD  - Department of Radiation Oncology, All India Institute of Medical Sciences 
      Guwahati, Changsari, Assam, 781101 India. ROR: https://ror.org/000kxhc93
FAU - Medhi, Partha Pratim
AU  - Medhi PP
AUID- ORCID: 0000-0002-3997-4350
AD  - Department of Radiation Oncology, All India Institute of Medical Sciences 
      Guwahati, Changsari, Assam, 781101 India. ROR: https://ror.org/000kxhc93
LA  - eng
PT  - Journal Article
DEP - 20230831
PL  - India
TA  - Indian J Otolaryngol Head Neck Surg
JT  - Indian journal of otolaryngology and head and neck surgery : official publication 
      of the Association of Otolaryngologists of India
JID - 9422551
PMC - PMC10908741
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - ChatGPT
OT  - Head and Neck
OT  - Oncology
EDAT- 2024/03/05 06:46
MHDA- 2024/03/05 06:47
PMCR- 2025/02/01
CRDT- 2024/03/05 03:58
PHST- 2023/07/28 00:00 [received]
PHST- 2023/08/28 00:00 [accepted]
PHST- 2024/03/05 06:47 [medline]
PHST- 2024/03/05 06:46 [pubmed]
PHST- 2024/03/05 03:58 [entrez]
PHST- 2025/02/01 00:00 [pmc-release]
AID - 4201 [pii]
AID - 10.1007/s12070-023-04201-6 [doi]
PST - ppublish
SO  - Indian J Otolaryngol Head Neck Surg. 2024 Feb;76(1):1425-1429. doi: 
      10.1007/s12070-023-04201-6. Epub 2023 Aug 31.

PMID- 37087108
OWN - NLM
STAT- MEDLINE
DCOM- 20230621
LR  - 20241216
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 30
IP  - 7
DP  - 2023 Jun 20
TI  - Using AI-generated suggestions from ChatGPT to optimize clinical decision 
      support.
PG  - 1237-1245
LID - 10.1093/jamia/ocad072 [doi]
AB  - OBJECTIVE: To determine if ChatGPT can generate useful suggestions for improving 
      clinical decision support (CDS) logic and to assess noninferiority compared to 
      human-generated suggestions. METHODS: We supplied summaries of CDS logic to 
      ChatGPT, an artificial intelligence (AI) tool for question answering that uses a 
      large language model, and asked it to generate suggestions. We asked human 
      clinician reviewers to review the AI-generated suggestions as well as 
      human-generated suggestions for improving the same CDS alerts, and rate the 
      suggestions for their usefulness, acceptance, relevance, understanding, workflow, 
      bias, inversion, and redundancy. RESULTS: Five clinicians analyzed 36 
      AI-generated suggestions and 29 human-generated suggestions for 7 alerts. Of the 
      20 suggestions that scored highest in the survey, 9 were generated by ChatGPT. 
      The suggestions generated by AI were found to offer unique perspectives and were 
      evaluated as highly understandable and relevant, with moderate usefulness, low 
      acceptance, bias, inversion, redundancy. CONCLUSION: AI-generated suggestions 
      could be an important complementary part of optimizing CDS alerts, can identify 
      potential improvements to alert logic and support their implementation, and may 
      even be able to assist experts in formulating their own suggestions for CDS 
      improvement. ChatGPT shows great potential for using large language models and 
      reinforcement learning from human feedback to improve CDS alert logic and 
      potentially other medical areas involving complex, clinical logic, a key step in 
      the development of an advanced learning health system.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association.
FAU - Liu, Siru
AU  - Liu S
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
FAU - Wright, Aileen P
AU  - Wright AP
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
AD  - Department of Medicine, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA.
FAU - Patterson, Barron L
AU  - Patterson BL
AD  - Department of Pediatrics, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA.
FAU - Wanderer, Jonathan P
AU  - Wanderer JP
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
AD  - Department of Anesthesiology, Vanderbilt University Medical Center, Nashville, 
      Tennessee, USA.
FAU - Turer, Robert W
AU  - Turer RW
AUID- ORCID: 0000-0003-1387-640X
AD  - Department of Emergency Medicine, University of Texas Southwestern Medical 
      Center, Dallas, Texas, USA.
AD  - Clinical Informatics Center, University of Texas Southwestern Medical Center, 
      Dallas, Texas, USA.
FAU - Nelson, Scott D
AU  - Nelson SD
AUID- ORCID: 0000-0002-1941-1817
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
FAU - McCoy, Allison B
AU  - McCoy AB
AUID- ORCID: 0000-0003-2292-9147
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
FAU - Sittig, Dean F
AU  - Sittig DF
AUID- ORCID: 0000-0001-5811-8915
AD  - School of Biomedical Informatics, University of Texas Health Science Center, 
      Houston, Texas, USA.
FAU - Wright, Adam
AU  - Wright A
AUID- ORCID: 0000-0001-6844-145X
AD  - Department of Biomedical Informatics, Vanderbilt University Medical Center, 
      Nashville, Tennessee, USA.
LA  - eng
GR  - K99 LM014097/LM/NLM NIH HHS/United States
GR  - R01 LM013995/LM/NLM NIH HHS/United States
GR  - R01 AG062499/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
CIN - J Am Med Inform Assoc. 2025 Jan 1;32(1):258-259. doi: 10.1093/jamia/ocae282. 
      PMID: 39499794
MH  - Humans
MH  - Artificial Intelligence
MH  - *Decision Support Systems, Clinical
MH  - Language
MH  - *Learning Health System
MH  - Workflow
PMC - PMC10280357
OTO - NOTNLM
OT  - artificial intelligence
OT  - clinical decision support
OT  - large language model
COIS- The authors do not have conflicts of interest related to this study.
EDAT- 2023/04/23 00:41
MHDA- 2023/06/21 06:42
PMCR- 2023/04/22
CRDT- 2023/04/22 20:32
PHST- 2023/02/21 00:00 [received]
PHST- 2023/03/28 00:00 [revised]
PHST- 2023/04/11 00:00 [accepted]
PHST- 2023/06/21 06:42 [medline]
PHST- 2023/04/23 00:41 [pubmed]
PHST- 2023/04/22 20:32 [entrez]
PHST- 2023/04/22 00:00 [pmc-release]
AID - 7136722 [pii]
AID - ocad072 [pii]
AID - 10.1093/jamia/ocad072 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2023 Jun 20;30(7):1237-1245. doi: 10.1093/jamia/ocad072.

PMID- 36819954
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240912
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 15
IP  - 2
DP  - 2023 Feb
TI  - ChatGPT Output Regarding Compulsory Vaccination and COVID-19 Vaccine Conspiracy: 
      A Descriptive Study at the Outset of a Paradigm Shift in Online Search for 
      Information.
PG  - e35029
LID - 10.7759/cureus.35029 [doi]
LID - e35029
AB  - BACKGROUND: Being on the verge of a revolutionary approach to gathering 
      information, ChatGPT (an artificial intelligence (AI)-based language model 
      developed by OpenAI, and capable of producing human-like text) could be the prime 
      motive of a paradigm shift on how humans will acquire information. Despite the 
      concerns related to the use of such a promising tool in relation to the future of 
      the quality of education, this technology will soon be incorporated into web 
      search engines mandating the need to evaluate the output of such a tool. Previous 
      studies showed that dependence on some sources of online information (e.g., 
      social media platforms) was associated with higher rates of vaccination 
      hesitancy. Therefore, the aim of the current study was to describe the output of 
      ChatGPT regarding coronavirus disease 2019 (COVID-19) vaccine conspiracy beliefs. 
      and compulsory vaccination. METHODS: The current descriptive study was conducted 
      on January 14, 2023 using the ChatGPT from OpenAI (OpenAI, L.L.C., San Francisco, 
      CA, USA). The output was evaluated by two authors and the degree of agreement 
      regarding the correctness, clarity, conciseness, and bias was evaluated using 
      Cohen's kappa. RESULTS: The ChatGPT responses were dismissive of conspiratorial 
      ideas about severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) origins 
      labeling it as non-credible and lacking scientific evidence. Additionally, 
      ChatGPT responses were totally against COVID-19 vaccine conspiracy statements. 
      Regarding compulsory vaccination, ChatGPT responses were neutral citing the 
      following as advantages of this strategy: protecting public health, maintaining 
      herd immunity, reducing the spread of disease, cost-effectiveness, and legal 
      obligation, and on the other hand, it cited the following as disadvantages of 
      compulsory vaccination: ethical and legal concerns, mistrust and resistance, 
      logistical challenges, and limited resources and knowledge. CONCLUSIONS: The 
      current study showed that ChatGPT could be a source of information to challenge 
      COVID-19 vaccine conspiracies. For compulsory vaccination, ChatGPT resonated with 
      the divided opinion in the scientific community toward such a strategy; 
      nevertheless, it detailed the pros and cons of this approach. As it currently 
      stands, the judicious use of ChatGPT could be utilized as a user-friendly source 
      of COVID-19 vaccine information that could challenge conspiracy ideas with clear, 
      concise, and non-biased content. However, ChatGPT content cannot be used as an 
      alternative to the original reliable sources of vaccine information (e.g., the 
      World Health Organization [WHO] and the Centers for Disease Control and 
      Prevention [CDC]).
CI  - Copyright © 2023, Sallam et al.
FAU - Sallam, Malik
AU  - Sallam M
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      University of Jordan, Amman, JOR.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Amman, JOR.
FAU - Salim, Nesreen A
AU  - Salim NA
AD  - Department of Prosthodontics, Jordan University Hospital, Amman, JOR.
FAU - Al-Tammemi, Ala'a B
AU  - Al-Tammemi AB
AD  - Infectious Disease, Applied Science Research Center, Applied Science Private 
      University, Amman, JOR.
AD  - Migration Health Division, International Organization for Migration (IOM) The UN 
      Migration Agency, Amman, JOR.
FAU - Barakat, Muna
AU  - Barakat M
AD  - School of Pharmacy, Applied Science Private University, Amman, JOR.
FAU - Fayyad, Diaa
AU  - Fayyad D
AD  - Department of Biological Sciences, Faculty of Science, Yarmouk University, Irbid, 
      JOR.
FAU - Hallit, Souheil
AU  - Hallit S
AD  - Faculty of Medicine and Medical Sciences, Holy Spirit University of Kaslik 
      (USEK), Jounieh, LBN.
FAU - Harapan, Harapan
AU  - Harapan H
AD  - Department of Epidemiology and Public Health, Syiah Kuala University, Banda Aceh, 
      IDN.
FAU - Hallit, Rabih
AU  - Hallit R
AD  - Department of Infectious Disease, School of Medicine and Medical Sciences, Holy 
      Spirit University of Kaslik (USEK), Jounieh, LBN.
FAU - Mahafzah, Azmi
AU  - Mahafzah A
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, JOR.
LA  - eng
PT  - Journal Article
DEP - 20230215
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC9931398
OTO - NOTNLM
OT  - artificial intelligence in medicine
OT  - covid-19 vaccine
OT  - machine learning
OT  - mandatory vaccination
OT  - vaccine promotion
COIS- The authors have declared that no competing interests exist.
EDAT- 2023/02/24 06:00
MHDA- 2023/02/24 06:01
PMCR- 2023/02/15
CRDT- 2023/02/23 10:09
PHST- 2023/02/15 00:00 [accepted]
PHST- 2023/02/23 10:09 [entrez]
PHST- 2023/02/24 06:00 [pubmed]
PHST- 2023/02/24 06:01 [medline]
PHST- 2023/02/15 00:00 [pmc-release]
AID - 10.7759/cureus.35029 [doi]
PST - epublish
SO  - Cureus. 2023 Feb 15;15(2):e35029. doi: 10.7759/cureus.35029. eCollection 2023 
      Feb.

PMID- 37958000
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241013
IS  - 2227-9032 (Print)
IS  - 2227-9032 (Electronic)
IS  - 2227-9032 (Linking)
VI  - 11
IP  - 21
DP  - 2023 Oct 30
TI  - Performance of ChatGPT on Registered Nurse License Exam in Taiwan: A Descriptive 
      Study.
LID - 10.3390/healthcare11212855 [doi]
LID - 2855
AB  - (1) Background: AI (artificial intelligence) chatbots have been widely applied. 
      ChatGPT could enhance individual learning capabilities and clinical reasoning 
      skills and facilitate students' understanding of complex concepts in healthcare 
      education. There is currently less emphasis on its application in nursing 
      education. The application of ChatGPT in nursing education needs to be verified. 
      (2) Methods: A descriptive study was used to analyze the scores of ChatGPT on the 
      registered nurse license exam (RNLE) in 2022~2023, and to explore the response 
      and explanations of ChatGPT. The process of data measurement encompassed input 
      sourcing, encoding methods, and statistical analysis. (3) Results: ChatGPT 
      promptly responded within seconds. The average score of four exams was around 
      51.6 to 63.75 by ChatGPT, and it passed the RNLE in 2022 1st and 2023 2nd. 
      However, ChatGPT may generate misleading or inaccurate explanations, or it could 
      lead to hallucination; confusion or misunderstanding about complicated scenarios; 
      and languages bias. (4) Conclusions: ChatGPT may have the potential to assist 
      with nursing education because of its advantages. It is recommended to integrate 
      ChatGPT into different nursing courses, to assess its limitations and 
      effectiveness through a variety of tools and methods.
FAU - Huang, Huiman
AU  - Huang H
AUID- ORCID: 0000-0003-4378-176X
AD  - School of Nursing, College of Nursing, Tzu Chi University of Science and 
      Technology, Hualien 970302, Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20231030
PL  - Switzerland
TA  - Healthcare (Basel)
JT  - Healthcare (Basel, Switzerland)
JID - 101666525
PMC - PMC10649156
OTO - NOTNLM
OT  - artificial intelligence
OT  - nursing graduate
OT  - registered nurse
COIS- The authors declare no conflict of interest.
EDAT- 2023/11/14 06:42
MHDA- 2023/11/14 06:43
PMCR- 2023/10/30
CRDT- 2023/11/14 02:05
PHST- 2023/09/24 00:00 [received]
PHST- 2023/10/17 00:00 [revised]
PHST- 2023/10/27 00:00 [accepted]
PHST- 2023/11/14 06:43 [medline]
PHST- 2023/11/14 06:42 [pubmed]
PHST- 2023/11/14 02:05 [entrez]
PHST- 2023/10/30 00:00 [pmc-release]
AID - healthcare11212855 [pii]
AID - healthcare-11-02855 [pii]
AID - 10.3390/healthcare11212855 [doi]
PST - epublish
SO  - Healthcare (Basel). 2023 Oct 30;11(21):2855. doi: 10.3390/healthcare11212855.

PMID- 38218231
OWN - NLM
STAT- MEDLINE
DCOM- 20240529
LR  - 20250106
IS  - 1526-3231 (Electronic)
IS  - 0749-8063 (Linking)
VI  - 40
IP  - 6
DP  - 2024 Jun
TI  - Artificial Intelligence and Machine Learning May Resolve Health Care Information 
      Overload.
PG  - 1721-1723
LID - S0749-8063(24)00012-4 [pii]
LID - 10.1016/j.arthro.2024.01.007 [doi]
AB  - Biomedical information doubles almost every 2 months, and this very rate is 
      expected to double by 2025. The result is information overload for clinicians and 
      researchers. Today, artificial intelligence (AI) and machine learning (ML) 
      research contribute to the deluge of information. In addition, AI large language 
      models, although capable of automating scientific writing, are flawed. They 
      hallucinate (make things up), are trained primarily on non-peer-reviewed content, 
      raise ethical and legal issues, and lack human empathy. Still, when it comes to 
      AI including ML, we are optimistic. The technology is improving rapidly. In the 
      future, AI will help us manage unwieldy information by processing data, 
      determining diagnoses, recommending treatments, and predicting outcomes. In 
      research, AI and ML similarly promise efficient data analysis and literature 
      review and will create new content in response to our instructions. Human touch 
      will be required, and we will disclose use of AI proactively, including rationale 
      for its use, our data input, our level of confidence in the output, and the 
      patients or populations to whom the output may be applied. In addition, we will 
      ensure data quality is high and bias is minimized. Most of all, we will provide 
      essential reasoning, clinical and research guidance, and diligent oversight. 
      Humans will remain accountable.
CI  - Copyright © 2024 Arthroscopy Association of North America. Published by Elsevier 
      Inc. All rights reserved.
FAU - Siegel, Mark G
AU  - Siegel MG
FAU - Rossi, Michael J
AU  - Rossi MJ
FAU - Lubowitz, James H
AU  - Lubowitz JH
LA  - eng
PT  - Editorial
DEP - 20240112
PL  - United States
TA  - Arthroscopy
JT  - Arthroscopy : the journal of arthroscopic & related surgery : official 
      publication of the Arthroscopy Association of North America and the International 
      Arthroscopy Association
JID - 8506498
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Machine Learning
MH  - Review Literature as Topic
EDAT- 2024/01/14 12:42
MHDA- 2024/05/30 05:46
CRDT- 2024/01/13 19:29
PHST- 2024/01/06 00:00 [received]
PHST- 2024/01/06 00:00 [accepted]
PHST- 2024/05/30 05:46 [medline]
PHST- 2024/01/14 12:42 [pubmed]
PHST- 2024/01/13 19:29 [entrez]
AID - S0749-8063(24)00012-4 [pii]
AID - 10.1016/j.arthro.2024.01.007 [doi]
PST - ppublish
SO  - Arthroscopy. 2024 Jun;40(6):1721-1723. doi: 10.1016/j.arthro.2024.01.007. Epub 
      2024 Jan 12.

PMID- 37746294
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231225
IS  - 2234-943X (Print)
IS  - 2234-943X (Electronic)
IS  - 2234-943X (Linking)
VI  - 13
DP  - 2023
TI  - Commentary: AI-based online chat and the future of oncology care: a promising 
      technology or a solution in search of a problem?
PG  - 1239932
LID - 10.3389/fonc.2023.1239932 [doi]
LID - 1239932
FAU - Zhang, Hui
AU  - Zhang H
AD  - Department of Rehabilitation and Elderly Care, Gannan Health Vocational College, 
      Ganzhou, China.
FAU - Guan, Yongfu
AU  - Guan Y
AD  - Department of Rehabilitation and Elderly Care, Gannan Health Vocational College, 
      Ganzhou, China.
FAU - Chen, Jinping
AU  - Chen J
AD  - Department of Rehabilitation and Elderly Care, Gannan Health Vocational College, 
      Ganzhou, China.
FAU - Tong, Wenting
AU  - Tong W
AD  - Department of Pharmacy, Gannan Health Vocational College, Ganzhou, China.
LA  - eng
PT  - Comment
PT  - Journal Article
DEP - 20230907
PL  - Switzerland
TA  - Front Oncol
JT  - Frontiers in oncology
JID - 101568867
CON - Front Oncol. 2023 May 25;13:1176617. doi: 10.3389/fonc.2023.1176617. PMID: 
      37305580
EIN - Front Oncol. 2023 Dec 07;13:1334176. doi: 10.3389/fonc.2023.1334176. PMID: 
      38144532
PMC - PMC10517627
OTO - NOTNLM
OT  - ChatGPT
OT  - data privacy
OT  - global healthcare resource allocation
OT  - language bias
OT  - legal and ethical challenges
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/09/25 06:42
MHDA- 2023/09/25 06:43
PMCR- 2023/01/01
CRDT- 2023/09/25 05:14
PHST- 2023/06/14 00:00 [received]
PHST- 2023/08/21 00:00 [accepted]
PHST- 2023/09/25 06:43 [medline]
PHST- 2023/09/25 06:42 [pubmed]
PHST- 2023/09/25 05:14 [entrez]
PHST- 2023/01/01 00:00 [pmc-release]
AID - 10.3389/fonc.2023.1239932 [doi]
PST - epublish
SO  - Front Oncol. 2023 Sep 7;13:1239932. doi: 10.3389/fonc.2023.1239932. eCollection 
      2023.

PMID- 38894617
OWN - NLM
STAT- MEDLINE
DCOM- 20241004
LR  - 20241004
IS  - 2042-6984 (Electronic)
IS  - 2042-6976 (Linking)
VI  - 14
IP  - 10
DP  - 2024 Oct
TI  - Assessing the quality of artificial intelligence-generated patient counseling for 
      rhinosinusitis.
PG  - 1634-1637
LID - 10.1002/alr.23387 [doi]
AB  - GPT-4 generated moderate quality information in response to questions regarding 
      sinusitis and surgery. GPT-4 generated significantly higher quality responses to 
      questions regarding treatment of sinusitis. Future studies exploring quality of 
      GPT responses should seek to limit bias and use validated instruments.
CI  - © 2024 ARS‐AAOA, LLC.
FAU - Hill, Gregory S
AU  - Hill GS
AUID- ORCID: 0000-0001-6949-3075
AD  - Department of Otolaryngology-Head & Neck Surgery, Walter Reed National Military 
      Medical Center, Bethesda, Maryland, USA.
FAU - Fischer, Jakob L
AU  - Fischer JL
AUID- ORCID: 0000-0002-8896-671X
AD  - Department of Otolaryngology-Head & Neck Surgery, Walter Reed National Military 
      Medical Center, Bethesda, Maryland, USA.
AD  - Department of Surgery, Uniformed Services University of the Health Sciences, 
      Bethesda, Maryland, USA.
FAU - Watson, Nora L
AU  - Watson NL
AD  - Department of Research, Walter Reed National Military Medical Center, Bethesda, 
      Maryland, USA.
FAU - Riley, Charles A
AU  - Riley CA
AUID- ORCID: 0000-0002-1993-7018
AD  - Department of Otolaryngology-Head & Neck Surgery, Walter Reed National Military 
      Medical Center, Bethesda, Maryland, USA.
AD  - Department of Surgery, Uniformed Services University of the Health Sciences, 
      Bethesda, Maryland, USA.
FAU - Tolisano, Anthony M
AU  - Tolisano AM
AD  - Department of Otolaryngology-Head & Neck Surgery, Walter Reed National Military 
      Medical Center, Bethesda, Maryland, USA.
AD  - Department of Surgery, Uniformed Services University of the Health Sciences, 
      Bethesda, Maryland, USA.
LA  - eng
PT  - Journal Article
DEP - 20240618
PL  - United States
TA  - Int Forum Allergy Rhinol
JT  - International forum of allergy & rhinology
JID - 101550261
SB  - IM
MH  - Humans
MH  - *Sinusitis/diagnosis/therapy
MH  - *Rhinitis/therapy/diagnosis
MH  - *Artificial Intelligence
MH  - Counseling
MH  - Surveys and Questionnaires
MH  - Rhinosinusitis
OTO - NOTNLM
OT  - chronic rhinosinustis
OT  - health care economics
OT  - rhinology workforce
OT  - sinus surgery
OT  - sinusitis
EDAT- 2024/06/19 06:42
MHDA- 2024/10/04 12:43
CRDT- 2024/06/19 02:43
PHST- 2024/05/05 00:00 [revised]
PHST- 2024/02/03 00:00 [received]
PHST- 2024/05/29 00:00 [accepted]
PHST- 2024/10/04 12:43 [medline]
PHST- 2024/06/19 06:42 [pubmed]
PHST- 2024/06/19 02:43 [entrez]
AID - 10.1002/alr.23387 [doi]
PST - ppublish
SO  - Int Forum Allergy Rhinol. 2024 Oct;14(10):1634-1637. doi: 10.1002/alr.23387. Epub 
      2024 Jun 18.

PMID- 36507318
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20221221
IS  - 1662-4548 (Print)
IS  - 1662-453X (Electronic)
IS  - 1662-453X (Linking)
VI  - 16
DP  - 2022
TI  - Improving the detection of new lesions in multiple sclerosis with a cascaded 3D 
      fully convolutional neural network approach.
PG  - 1007619
LID - 10.3389/fnins.2022.1007619 [doi]
LID - 1007619
AB  - Longitudinal magnetic resonance imaging (MRI) has an important role in multiple 
      sclerosis (MS) diagnosis and follow-up. Specifically, the presence of new lesions 
      on brain MRI scans is considered a robust predictive biomarker for the disease 
      progression. New lesions are a high-impact prognostic factor to predict evolution 
      to MS or risk of disability accumulation over time. However, the detection of 
      this disease activity is performed visually by comparing the follow-up and 
      baseline scans. Due to the presence of small lesions, misregistration, and high 
      inter-/intra-observer variability, this detection of new lesions is prone to 
      errors. In this direction, one of the last Medical Image Computing and Computer 
      Assisted Intervention (MICCAI) challenges was dealing with this automatic new 
      lesion quantification. The MSSEG-2: MS new lesions segmentation challenge offers 
      an evaluation framework for this new lesion segmentation task with a large 
      database (100 patients, each with two-time points) compiled from the OFSEP 
      (Observatoire français de la sclérose en plaques) cohort, the French MS registry, 
      including 3D T2-w fluid-attenuated inversion recovery (T2-FLAIR) images from 
      different centers and scanners. Apart from a change in centers, MRI scanners, and 
      acquisition protocols, there are more challenges that hinder the automated 
      detection process of new lesions such as the need for large annotated datasets, 
      which may be not easily available, or the fact that new lesions are small areas 
      producing a class imbalance problem that could bias trained models toward the 
      non-lesion class. In this article, we present a novel automated method for new 
      lesion detection of MS patient images. Our approach is based on a cascade of two 
      3D patch-wise fully convolutional neural networks (FCNNs). The first FCNN is 
      trained to be more sensitive revealing possible candidate new lesion voxels, 
      while the second FCNN is trained to reduce the number of misclassified voxels 
      coming from the first network. 3D T2-FLAIR images from the two-time points were 
      pre-processed and linearly co-registered. Afterward, a fully CNN, where its 
      inputs were only the baseline and follow-up images, was trained to detect new MS 
      lesions. Our approach obtained a mean segmentation dice similarity coefficient of 
      0.42 with a detection F1-score of 0.5. Compared to the challenge participants, we 
      obtained one of the highest precision scores (PPVL = 0.52), the best PPVL rate 
      (0.53), and a lesion detection sensitivity (SensL of 0.53).
CI  - Copyright © 2022 Salem, Ryan, Oliver, Hussain and Lladó.
FAU - Salem, Mostafa
AU  - Salem M
AD  - Research Institute of Computer Vision and Robotics, University of Girona, Girona, 
      Spain.
AD  - Department of Computer Science, Faculty of Computers and Information, Assiut 
      University, Assiut, Egypt.
FAU - Ryan, Marwa Ahmed
AU  - Ryan MA
AD  - Research Institute of Computer Vision and Robotics, University of Girona, Girona, 
      Spain.
AD  - Department of Computer Science, Faculty of Computers and Information, Assiut 
      University, Assiut, Egypt.
FAU - Oliver, Arnau
AU  - Oliver A
AD  - Research Institute of Computer Vision and Robotics, University of Girona, Girona, 
      Spain.
FAU - Hussain, Khaled Fathy
AU  - Hussain KF
AD  - Department of Computer Science, Faculty of Computers and Information, Assiut 
      University, Assiut, Egypt.
FAU - Lladó, Xavier
AU  - Lladó X
AD  - Research Institute of Computer Vision and Robotics, University of Girona, Girona, 
      Spain.
LA  - eng
PT  - Journal Article
DEP - 20221124
PL  - Switzerland
TA  - Front Neurosci
JT  - Frontiers in neuroscience
JID - 101478481
PMC - PMC9730806
OTO - NOTNLM
OT  - MRI
OT  - automatic new lesion detection
OT  - brain
OT  - cascaded training
OT  - deep learning
OT  - learning-based registration
OT  - multiple sclerosis
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2022/12/13 06:00
MHDA- 2022/12/13 06:01
PMCR- 2022/01/01
CRDT- 2022/12/12 11:35
PHST- 2022/07/30 00:00 [received]
PHST- 2022/10/24 00:00 [accepted]
PHST- 2022/12/12 11:35 [entrez]
PHST- 2022/12/13 06:00 [pubmed]
PHST- 2022/12/13 06:01 [medline]
PHST- 2022/01/01 00:00 [pmc-release]
AID - 10.3389/fnins.2022.1007619 [doi]
PST - epublish
SO  - Front Neurosci. 2022 Nov 24;16:1007619. doi: 10.3389/fnins.2022.1007619. 
      eCollection 2022.

PMID- 37285018
OWN - NLM
STAT- MEDLINE
DCOM- 20230731
LR  - 20231116
IS  - 1434-4726 (Electronic)
IS  - 0937-4477 (Print)
IS  - 0937-4477 (Linking)
VI  - 280
IP  - 9
DP  - 2023 Sep
TI  - ChatGPT's quiz skills in different otolaryngology subspecialties: an analysis of 
      2576 single-choice and multiple-choice board certification preparation questions.
PG  - 4271-4278
LID - 10.1007/s00405-023-08051-4 [doi]
AB  - PURPOSE: With the increasing adoption of artificial intelligence (AI) in various 
      domains, including healthcare, there is growing acceptance and interest in 
      consulting AI models to provide medical information and advice. This study aimed 
      to evaluate the accuracy of ChatGPT's responses to practice quiz questions 
      designed for otolaryngology board certification and decipher potential 
      performance disparities across different otolaryngology subspecialties. METHODS: 
      A dataset covering 15 otolaryngology subspecialties was collected from an online 
      learning platform funded by the German Society of Oto-Rhino-Laryngology, Head and 
      Neck Surgery, designed for board certification examination preparation. These 
      questions were entered into ChatGPT, with its responses being analyzed for 
      accuracy and variance in performance. RESULTS: The dataset included 2576 
      questions (479 multiple-choice and 2097 single-choice), of which 57% (n = 1475) 
      were answered correctly by ChatGPT. An in-depth analysis of question style 
      revealed that single-choice questions were associated with a significantly higher 
      rate (p < 0.001) of correct responses (n = 1313; 63%) compared to multiple-choice 
      questions (n = 162; 34%). Stratified by question categories, ChatGPT yielded the 
      highest rate of correct responses (n = 151; 72%) in the field of allergology, 
      whereas 7 out of 10 questions (n = 65; 71%) on legal otolaryngology aspects were 
      answered incorrectly. CONCLUSION: The study reveals ChatGPT's potential as a 
      supplementary tool for otolaryngology board certification preparation. However, 
      its propensity for errors in certain otolaryngology areas calls for further 
      refinement. Future research should address these limitations to improve ChatGPT's 
      educational use. An approach, with expert collaboration, is recommended for the 
      reliable and accurate integration of such AI models.
CI  - © 2023. The Author(s).
FAU - Hoch, Cosima C
AU  - Hoch CC
AUID- ORCID: 0000-0002-3875-7389
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675, Munich, 
      Germany. cosima.chiara.hoch@tum.de.
FAU - Wollenberg, Barbara
AU  - Wollenberg B
AD  - Department of Otolaryngology, Head and Neck Surgery, School of Medicine, 
      Technical University of Munich (TUM), Ismaningerstrasse 22, 81675, Munich, 
      Germany.
FAU - Lüers, Jan-Christoffer
AU  - Lüers JC
AD  - Department of Otorhinolaryngology, Head and Neck Surgery, Medical Faculty, 
      University of Cologne, 50937, Cologne, Germany.
FAU - Knoedler, Samuel
AU  - Knoedler S
AD  - Division of Plastic Surgery, Brigham and Women's Hospital, Harvard Medical 
      School, Boston, MA, 02152, USA.
AD  - Department of Plastic Surgery and Hand Surgery, Klinikum Rechts Der Isar, 
      Technical University of Munich, Munich, Germany.
FAU - Knoedler, Leonard
AU  - Knoedler L
AD  - Division of Plastic and Reconstructive Surgery, Massachusetts General Hospital, 
      Harvard Medical School, Boston, MA, 02115, USA.
FAU - Frank, Konstantin
AU  - Frank K
AD  - Ocean Clinic, Marbella, Spain.
FAU - Cotofana, Sebastian
AU  - Cotofana S
AD  - Department of Dermatology, Erasmus Hospital, Rotterdam, The Netherlands.
AD  - Centre for Cutaneous Research, Blizard Institute, Queen Mary University of 
      London, London, UK.
FAU - Alfertshofer, Michael
AU  - Alfertshofer M
AD  - Division of Hand, Plastic and Aesthetic Surgery, Ludwig-Maximilians-University 
      Munich, Munich, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230607
PL  - Germany
TA  - Eur Arch Otorhinolaryngol
JT  - European archives of oto-rhino-laryngology : official journal of the European 
      Federation of Oto-Rhino-Laryngological Societies (EUFOS) : affiliated with the 
      German Society for Oto-Rhino-Laryngology - Head and Neck Surgery
JID - 9002937
SB  - IM
CIN - Eur Arch Otorhinolaryngol. 2024 Feb;281(2):1061-1063. doi: 
      10.1007/s00405-023-08325-x. PMID: 37955694
MH  - Humans
MH  - *Artificial Intelligence
MH  - Certification
MH  - Educational Status
MH  - *Otolaryngology
MH  - Referral and Consultation
PMC - PMC10382366
OTO - NOTNLM
OT  - AI
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Multiple-choice
OT  - Otolaryngology quiz
OT  - Single-choice
COIS- The authors have no relevant financial or non-financial interests to disclose. 
      Jan-Christoffer Lüers, M.D., Ph.D. is the developer and owner of the online 
      learning platform.
EDAT- 2023/06/07 13:10
MHDA- 2023/07/31 06:42
PMCR- 2023/06/07
CRDT- 2023/06/07 11:13
PHST- 2023/05/23 00:00 [received]
PHST- 2023/05/26 00:00 [accepted]
PHST- 2023/07/31 06:42 [medline]
PHST- 2023/06/07 13:10 [pubmed]
PHST- 2023/06/07 11:13 [entrez]
PHST- 2023/06/07 00:00 [pmc-release]
AID - 10.1007/s00405-023-08051-4 [pii]
AID - 8051 [pii]
AID - 10.1007/s00405-023-08051-4 [doi]
PST - ppublish
SO  - Eur Arch Otorhinolaryngol. 2023 Sep;280(9):4271-4278. doi: 
      10.1007/s00405-023-08051-4. Epub 2023 Jun 7.

PMID- 40035077
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250305
IS  - 2352-3735 (Electronic)
IS  - 2352-3727 (Print)
IS  - 2352-3727 (Linking)
VI  - 10
IP  - 4
DP  - 2024 Dec
TI  - BCG therapy for bladder cancer: Exploring patient experiences and concerns 
      through artificial intelligence-based social media analysis.
PG  - 290-299
LID - 10.1177/23523735241304907 [doi]
AB  - BACKGROUND: There is a notable disparity between the guidelines for BCG therapy 
      in non-muscle invasive bladder cancer (NMIBC). Reddit has emerged as a popular 
      online platform for individuals seeking information and exchanging their 
      experiences related to bladder cancer. OBJECTIVE: To investigate and classify 
      public opinions about intravesical BCG therapy as shared on Reddit, a popular 
      social media platform. METHODS: This study employed an artificial 
      intelligence-based approach to examine discussions related to intravesical BCG 
      therapy on a social media platform over the past ten years. An artificial 
      intelligence framework was developed to categorize these conversations into 
      distinct topics and thematic categories. This framework included a partially 
      supervised model for processing natural language (using BERT [Bidirectional 
      Encoder Representations from Transformers]), a method for reducing data 
      complexity, and an algorithm for clustering. Additionally, each conversation was 
      assessed for sentiment. RESULTS: A total of 1223 unique discussions related to 
      BCG therapy were analyzed, comprising 110 unique posts and 1113 comments from 268 
      distinct authors. We identified four overarching thematic groups: 1) BCG 
      administration procedures, (2) hesitancy in initiating or maintaining BCG 
      treatment, (3) issues related to BCG shortage and alternative treatments, and (4) 
      side effects of BCG treatment. Sentiment analysis of the 1223 discussions 
      revealed that 25.2% (308) exhibited a negative sentiment, 58.3% (713) were 
      neutral, and 16.5% (202) showed a positive sentiment. CONCLUSION: Online social 
      media often contains detailed personal experiences with BCG therapy, not commonly 
      found in medical literature. Understanding these experiences can help medical 
      professionals improve care and treatment adherence in NMIBC.
CI  - © The Author(s) 2024.
FAU - Khene, Zine-Eddine
AU  - Khene ZE
AUID- ORCID: 0000-0002-4124-789X
AD  - Department of Urology, UT Southwestern Medical Center, Dallas, TX, USA.
FAU - Tachibana, Isamu
AU  - Tachibana I
AD  - Department of Urology, UT Southwestern Medical Center, Dallas, TX, USA.
FAU - Bhanvadia, Raj
AU  - Bhanvadia R
AD  - Department of Urology, UT Southwestern Medical Center, Dallas, TX, USA.
FAU - Ausmann, Hagan
AU  - Ausmann H
AD  - Department of Urology, UT Southwestern Medical Center, Dallas, TX, USA.
FAU - Margulis, Vitaly
AU  - Margulis V
AD  - Department of Urology, UT Southwestern Medical Center, Dallas, TX, USA.
FAU - Lotan, Yair
AU  - Lotan Y
AD  - Department of Urology, UT Southwestern Medical Center, Dallas, TX, USA.
LA  - eng
PT  - Journal Article
DEP - 20241223
PL  - Netherlands
TA  - Bladder Cancer
JT  - Bladder cancer (Amsterdam, Netherlands)
JID - 101668567
PMC - PMC11864235
OTO - NOTNLM
OT  - Bacillus Calmette-Guerin
OT  - artificial intelligence
OT  - non-muscle invasive bladder cancer
OT  - sentiment analysis
OT  - social media
OT  - topic modeling
COIS- The author(s) declared the following potential conflicts of interest with respect 
      to the research, authorship, and/or publication of this article: Yair Lota is a 
      Consultant for Nanorobotics, C2I genomics, Photocure, Astrazeneca, Merck, 
      Fergene, Abbvie, Nucleix, Ambu, Seattle Genetics, Hitachi, Ferring Research, 
      verity pharmaceutics, virtuoso surgical, Stimit, Urogen, Vessi medical, CAPs 
      medical, Xcures, BMS, Nonagen, Aura Biosciences, Inc., Convergent Genomics, 
      Pacific Edge, Pfizer, Phinomics Inc, CG oncology, Uroviu, On target lab, Promis 
      Diagnostics, Valar labs, Uroessentials Zine-Eddine Khene received financial 
      support through grants from Fondation France for Interdisciplinary Studies.
EDAT- 2025/03/04 10:53
MHDA- 2025/03/04 10:54
PMCR- 2024/12/23
CRDT- 2025/03/04 04:59
PHST- 2024/07/02 00:00 [received]
PHST- 2024/11/12 00:00 [accepted]
PHST- 2025/03/04 10:54 [medline]
PHST- 2025/03/04 10:53 [pubmed]
PHST- 2025/03/04 04:59 [entrez]
PHST- 2024/12/23 00:00 [pmc-release]
AID - 10.1177_23523735241304907 [pii]
AID - 10.1177/23523735241304907 [doi]
PST - epublish
SO  - Bladder Cancer. 2024 Dec 23;10(4):290-299. doi: 10.1177/23523735241304907. 
      eCollection 2024 Dec.

PMID- 39118057
OWN - NLM
STAT- MEDLINE
DCOM- 20240809
LR  - 20240811
IS  - 1471-2334 (Electronic)
IS  - 1471-2334 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Aug 8
TI  - Language discrepancies in the performance of generative artificial intelligence 
      models: an examination of infectious disease queries in English and Arabic.
PG  - 799
LID - 10.1186/s12879-024-09725-y [doi]
LID - 799
AB  - BACKGROUND: Assessment of artificial intelligence (AI)-based models across 
      languages is crucial to ensure equitable access and accuracy of information in 
      multilingual contexts. This study aimed to compare AI model efficiency in English 
      and Arabic for infectious disease queries. METHODS: The study employed the 
      METRICS checklist for the design and reporting of AI-based studies in healthcare. 
      The AI models tested included ChatGPT-3.5, ChatGPT-4, Bing, and Bard. The queries 
      comprised 15 questions on HIV/AIDS, tuberculosis, malaria, COVID-19, and 
      influenza. The AI-generated content was assessed by two bilingual experts using 
      the validated CLEAR tool. RESULTS: In comparing AI models' performance in English 
      and Arabic for infectious disease queries, variability was noted. English queries 
      showed consistently superior performance, with Bard leading, followed by Bing, 
      ChatGPT-4, and ChatGPT-3.5 (P = .012). The same trend was observed in Arabic, 
      albeit without statistical significance (P = .082). Stratified analysis revealed 
      higher scores for English in most CLEAR components, notably in completeness, 
      accuracy, appropriateness, and relevance, especially with ChatGPT-3.5 and Bard. 
      Across the five infectious disease topics, English outperformed Arabic, except 
      for flu queries in Bing and Bard. The four AI models' performance in English was 
      rated as "excellent", significantly outperforming their "above-average" Arabic 
      counterparts (P = .002). CONCLUSIONS: Disparity in AI model performance was 
      noticed between English and Arabic in response to infectious disease queries. 
      This language variation can negatively impact the quality of health content 
      delivered by AI models among native speakers of Arabic. This issue is recommended 
      to be addressed by AI developers, with the ultimate goal of enhancing health 
      outcomes.
CI  - © 2024. The Author(s).
FAU - Sallam, Malik
AU  - Sallam M
AUID- ORCID: 0000-0002-0165-9670
AD  - Department of Pathology, Microbiology and Forensic Medicine, School of Medicine, 
      The University of Jordan, Amman, 11942, Jordan. malik.sallam@ju.edu.jo.
AD  - Department of Translational Medicine, Faculty of Medicine, Lund University, 
      Malmö, 22184, Sweden. malik.sallam@ju.edu.jo.
AD  - Department of Clinical Laboratories and Forensic Medicine, Jordan University 
      Hospital, Queen Rania Al-Abdullah Street-Aljubeiha, P.O. Box: 13046, Amman, 
      Jordan. malik.sallam@ju.edu.jo.
FAU - Al-Mahzoum, Kholoud
AU  - Al-Mahzoum K
AD  - School of Medicine, The University of Jordan, Amman, 11942, Jordan.
FAU - Alshuaib, Omaima
AU  - Alshuaib O
AD  - School of Medicine, The University of Jordan, Amman, 11942, Jordan.
FAU - Alhajri, Hawajer
AU  - Alhajri H
AD  - School of Medicine, The University of Jordan, Amman, 11942, Jordan.
FAU - Alotaibi, Fatmah
AU  - Alotaibi F
AD  - School of Medicine, The University of Jordan, Amman, 11942, Jordan.
FAU - Alkhurainej, Dalal
AU  - Alkhurainej D
AD  - School of Medicine, The University of Jordan, Amman, 11942, Jordan.
FAU - Al-Balwah, Mohammad Yahya
AU  - Al-Balwah MY
AD  - School of Medicine, The University of Jordan, Amman, 11942, Jordan.
FAU - Barakat, Muna
AU  - Barakat M
AD  - Department of Clinical Pharmacy and Therapeutics, Faculty of Pharmacy, Applied 
      Science Private University, Amman, 11931, Jordan.
AD  - MEU Research Unit, Middle East University, Amman, 11831, Jordan.
FAU - Egger, Jan
AU  - Egger J
AD  - Institute for AI in Medicine (IKIM), University Medicine Essen (AöR), Essen, 
      Germany.
LA  - eng
PT  - Journal Article
DEP - 20240808
PL  - England
TA  - BMC Infect Dis
JT  - BMC infectious diseases
JID - 100968551
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Communicable Diseases
MH  - *Language
MH  - COVID-19
PMC - PMC11308449
OTO - NOTNLM
OT  - AI chatbots
OT  - Digital health queries
OT  - Healthcare technology
OT  - Infectious diseases
OT  - Language performance
COIS- The authors declare no competing interests.
EDAT- 2024/08/09 00:42
MHDA- 2024/08/09 06:42
PMCR- 2024/08/08
CRDT- 2024/08/08 23:36
PHST- 2024/01/02 00:00 [received]
PHST- 2024/08/06 00:00 [accepted]
PHST- 2024/08/09 06:42 [medline]
PHST- 2024/08/09 00:42 [pubmed]
PHST- 2024/08/08 23:36 [entrez]
PHST- 2024/08/08 00:00 [pmc-release]
AID - 10.1186/s12879-024-09725-y [pii]
AID - 9725 [pii]
AID - 10.1186/s12879-024-09725-y [doi]
PST - epublish
SO  - BMC Infect Dis. 2024 Aug 8;24(1):799. doi: 10.1186/s12879-024-09725-y.

PMID- 37975063
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231124
VI  - 2022
DP  - 2022 Jul
TI  - Using Deep Learning to Identify Linguistic Features that Facilitate or Inhibit 
      the Propagation of Anti- and Pro-Vaccine Content on Social Media.
PG  - 107-116
LID - 10.1109/icdh55609.2022.00025 [doi]
AB  - Anti-vaccine content is rapidly propagated via social media, fostering vaccine 
      hesitancy, while pro-vaccine content has not replicated the opponent's successes. 
      Despite this disparity in the dissemination of anti- and pro-vaccine posts, 
      linguistic features that facilitate or inhibit the propagation of vaccine-related 
      content remain less known. Moreover, most prior machine-learning algorithms 
      classified social-media posts into binary categories (e.g., misinformation or 
      not) and have rarely tackled a higher-order classification task based on 
      divergent perspectives about vaccines (e.g., anti-vaccine, pro-vaccine, and 
      neutral). Our objectives are (1) to identify sets of linguistic features that 
      facilitate and inhibit the propagation of vaccine-related content and (2) to 
      compare whether anti-vaccine, provaccine, and neutral tweets contain either set 
      more frequently than the others. To achieve these goals, we collected a large set 
      of social media posts (over 120 million tweets) between Nov. 15 and Dec. 15, 
      2021, coinciding with the Omicron variant surge. A two-stage framework was 
      developed using a fine-tuned BERT classifier, demonstrating over 99 and 80 
      percent accuracy for binary and ternary classification. Finally, the Linguistic 
      Inquiry Word Count text analysis tool was used to count linguistic features in 
      each classified tweet. Our regression results show that anti-vaccine tweets are 
      propagated (i.e., retweeted), while pro-vaccine tweets garner passive 
      endorsements (i.e., favorited). Our results also yielded the two sets of 
      linguistic features as facilitators and inhibitors of the propagation of 
      vaccine-related tweets. Finally, our regression results show that anti-vaccine 
      tweets tend to use the facilitators, while pro-vaccine counterparts employ the 
      inhibitors. These findings and algorithms from this study will aid public health 
      officials' efforts to counteract vaccine misinformation, thereby facilitating the 
      delivery of preventive measures during pandemics and epidemics.
FAU - Argyris, Young Anna
AU  - Argyris YA
AD  - Dept of Media and Information, Michigan State University, East Lansing, MI.
FAU - Zhang, Nan
AU  - Zhang N
AD  - Dept of Advertising and Public Relations, Michigan State University, East 
      Lansing, MI.
FAU - Bashyal, Bidhan
AU  - Bashyal B
AD  - Dept of Computer Science and Engineering, Michigan State University, East 
      Lansing, MI.
FAU - Tan, Pang-Ning
AU  - Tan PN
AD  - Dept of Computer Science and Engineering, Michigan State University, East 
      Lansing, MI.
LA  - eng
SI  - Dryad/10.5061/dryad.d51c5b05j
GR  - R21 LM013638/LM/NLM NIH HHS/United States
PT  - Journal Article
DEP - 20220824
PL  - United States
TA  - 2022 IEEE Int Conf Digit Health IEEE IDCH 2022 (2022)
JT  - 2022 IEEE International Conference on Digital Health (IEEE ICDH 2022) : 
      proceedings : hybrid conference, Barcelona, Spain, 11-15 July 2022. International 
      Conference on Digital Health (2022 : Barcelona, Spain; Online)
JID - 9918697476106676
PMC - PMC10652839
MID - NIHMS1816749
OTO - NOTNLM
OT  - deep-learning
OT  - diffusion of information
OT  - health informatics
OT  - regression analyses
OT  - social media
OT  - vaccine misinformation
EDAT- 2022/07/01 00:00
MHDA- 2022/07/01 00:01
PMCR- 2023/11/15
CRDT- 2023/11/17 03:57
PHST- 2022/07/01 00:01 [medline]
PHST- 2022/07/01 00:00 [pubmed]
PHST- 2023/11/17 03:57 [entrez]
PHST- 2023/11/15 00:00 [pmc-release]
AID - 10.1109/icdh55609.2022.00025 [doi]
PST - ppublish
SO  - 2022 IEEE Int Conf Digit Health IEEE IDCH 2022 (2022). 2022 Jul;2022:107-116. 
      doi: 10.1109/icdh55609.2022.00025. Epub 2022 Aug 24.

PMID- 33564103
OWN - NLM
STAT- MEDLINE
DCOM- 20220302
LR  - 20221030
IS  - 1740-634X (Electronic)
IS  - 0893-133X (Print)
IS  - 0893-133X (Linking)
VI  - 47
IP  - 2
DP  - 2022 Jan
TI  - Late-life depression accentuates cognitive weaknesses in older adults with small 
      vessel disease.
PG  - 580-587
LID - 10.1038/s41386-021-00973-z [doi]
AB  - Neuroimaging features of small vessel disease (SVD) are highly prevalent in older 
      adulthood and associated with significant variability in clinical symptoms, yet 
      the factors predicting these symptom disparities are poorly understood. We 
      employed a novel metric of SVD, peak width of skeletonized mean diffusivity 
      (PSMD), to elucidate the relationship of late-life depression (LLD) to the 
      cognitive presentation of vascular pathology. A total of 109 older adults without 
      a diagnosis of a neurocognitive disorder were enrolled in the study; 44 with 
      major depressive disorder and 65 age-matched controls. Subjects completed 
      neuropsychological testing and magnetic resonance imaging including FLAIR and 
      diffusion tensor imaging sequences, from which white matter hyperintensity volume 
      and diffusion metrics (fractional anisotropy, mean diffusivity, PSMD) were 
      quantified. In hierarchical models, the relationship between vascular burden and 
      cognitive performance varied as a function of diagnostic status, such that the 
      negative association between PSMD and processing speed was significantly stronger 
      in participants with LLD compared to controls. Greater PSMD also predicted poorer 
      performance on delayed memory and executive function tasks specifically among 
      those with LLD, while there were no associations between PSMD and task 
      performance among controls. PSMD outperformed conventional SVD and diffusion 
      markers in predicting cognitive performance and dysexecutive behaviors in 
      participants with LLD. These data suggest that LLD may confer a vulnerability to 
      the cognitive manifestations of white matter abnormalities in older adulthood. 
      PSMD, a novel biomarker of diffuse microstructural changes in SVD, may be a more 
      sensitive marker of subtle cognitive deficits stemming from vascular pathology in 
      LLD.
CI  - © 2021. The Author(s).
FAU - Oberlin, Lauren E
AU  - Oberlin LE
AD  - Department of Psychiatry, Weill Cornell Medicine, New York, NY, USA.
AD  - Weill Cornell Institute of Geriatric Psychiatry, White Plains, NY, USA.
FAU - Respino, Matteo
AU  - Respino M
AD  - Rush University Medical Center, Chicago, IL, USA.
FAU - Victoria, Lindsay
AU  - Victoria L
AD  - Department of Psychiatry, Weill Cornell Medicine, New York, NY, USA.
AD  - Weill Cornell Institute of Geriatric Psychiatry, White Plains, NY, USA.
FAU - Abreu, Lila
AU  - Abreu L
AD  - Department of Psychiatry, Weill Cornell Medicine, New York, NY, USA.
FAU - Hoptman, Matthew J
AU  - Hoptman MJ
AUID- ORCID: 0000-0003-4485-6102
AD  - Clinical Research, Nathan Kline Institute, Orangeburg, NY, USA.
AD  - Department of Psychiatry, NYU School of Medicine, New York, NY, USA.
FAU - Alexopoulos, George S
AU  - Alexopoulos GS
AD  - Department of Psychiatry, Weill Cornell Medicine, New York, NY, USA.
AD  - Weill Cornell Institute of Geriatric Psychiatry, White Plains, NY, USA.
FAU - Gunning, Faith M
AU  - Gunning FM
AUID- ORCID: 0000-0003-1854-9969
AD  - Department of Psychiatry, Weill Cornell Medicine, New York, NY, USA. 
      fdg2002@med.cornell.edu.
AD  - Weill Cornell Institute of Geriatric Psychiatry, White Plains, NY, USA. 
      fdg2002@med.cornell.edu.
LA  - eng
GR  - K01 MH118480/MH/NIMH NIH HHS/United States
GR  - R01 MH097735/MH/NIMH NIH HHS/United States
GR  - T32 MH019132/MH/NIMH NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
DEP - 20210209
PL  - England
TA  - Neuropsychopharmacology
JT  - Neuropsychopharmacology : official publication of the American College of 
      Neuropsychopharmacology
JID - 8904907
SB  - IM
MH  - Aged
MH  - Cognition
MH  - *Cognitive Dysfunction/diagnostic imaging
MH  - Depression/diagnostic imaging
MH  - *Depressive Disorder, Major/complications/diagnostic imaging
MH  - Diffusion Tensor Imaging/methods
MH  - Humans
MH  - *White Matter/diagnostic imaging
PMC - PMC8674355
EDAT- 2021/02/11 06:00
MHDA- 2022/03/03 06:00
PMCR- 2021/02/09
CRDT- 2021/02/10 05:51
PHST- 2020/11/02 00:00 [received]
PHST- 2021/01/12 00:00 [accepted]
PHST- 2021/01/03 00:00 [revised]
PHST- 2021/02/11 06:00 [pubmed]
PHST- 2022/03/03 06:00 [medline]
PHST- 2021/02/10 05:51 [entrez]
PHST- 2021/02/09 00:00 [pmc-release]
AID - 10.1038/s41386-021-00973-z [pii]
AID - 973 [pii]
AID - 10.1038/s41386-021-00973-z [doi]
PST - ppublish
SO  - Neuropsychopharmacology. 2022 Jan;47(2):580-587. doi: 10.1038/s41386-021-00973-z. 
      Epub 2021 Feb 9.

PMID- 38046053
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20231205
IS  - 1916-257X (Print)
IS  - 1916-257X (Electronic)
VI  - 16
IP  - 4
DP  - 2023 Dec
TI  - Navigating Generative AI: Opportunities, Limitations, and Ethical Considerations 
      in Massage Therapy and Beyond.
PG  - 1-4
LID - 10.3822/ijtmb.v16i4.949 [doi]
AB  - Generative artificial intelligence (AI) has become a hot topic, particularly 
      ChatGPT's quick adoption and popularity, prompting discussions about its 
      disruptive potential in health care, education, and creative sectors. The author, 
      an early adopter, shares personal insights on leveraging generative AI for 
      creative tasks and communication challenges, while also exploring its role as a 
      tool rather than an author. Opportunities and limitations of integrating 
      generative AI in the massage therapy field are explored, reflecting on the 
      profession's reluctance to embrace technology and the potential efficiency gains. 
      While acknowledging generative AI's creative promise, the importance of ethical 
      and regulated utilization, highlighting data biases and limitations, is 
      underscored. Overall, a balanced and responsible approach to incorporating 
      generative AI into various domains is recommended.
CI  - Copyright© The Author(s) 2023. Published by the Massage Therapy Foundation.
FAU - Baskwill, Amanda
AU  - Baskwill A
AD  - Loyalist College, Belleville, ON.
LA  - eng
PT  - Editorial
DEP - 20231201
PL  - United States
TA  - Int J Ther Massage Bodywork
JT  - International journal of therapeutic massage & bodywork
JID - 101539415
PMC - PMC10665080
OTO - NOTNLM
OT  - ChatGPT
OT  - disruption
OT  - ethical utilization
OT  - generative artificial intelligence
OT  - massage therapy
EDAT- 2023/12/04 06:42
MHDA- 2023/12/04 06:43
PMCR- 2023/12/01
CRDT- 2023/12/04 04:48
PHST- 2023/12/04 06:43 [medline]
PHST- 2023/12/04 06:42 [pubmed]
PHST- 2023/12/04 04:48 [entrez]
PHST- 2023/12/01 00:00 [pmc-release]
AID - ijtmb-16-1 [pii]
AID - 10.3822/ijtmb.v16i4.949 [doi]
PST - epublish
SO  - Int J Ther Massage Bodywork. 2023 Dec 1;16(4):1-4. doi: 10.3822/ijtmb.v16i4.949. 
      eCollection 2023 Dec.

PMID- 36939830
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230710
IS  - 2561-326X (Electronic)
IS  - 2561-326X (Linking)
VI  - 7
DP  - 2023 Mar 20
TI  - Calibrating a Transformer-Based Model's Confidence on Community-Engaged Research 
      Studies: Decision Support Evaluation Study.
PG  - e41516
LID - 10.2196/41516 [doi]
LID - e41516
AB  - BACKGROUND: Deep learning offers great benefits in classification tasks such as 
      medical imaging diagnostics or stock trading, especially when compared with 
      human-level performances, and can be a viable option for classifying distinct 
      levels within community-engaged research (CEnR). CEnR is a collaborative approach 
      between academics and community partners with the aim of conducting research that 
      is relevant to community needs while incorporating diverse forms of expertise. In 
      the field of deep learning and artificial intelligence (AI), training multiple 
      models to obtain the highest validation accuracy is common practice; however, it 
      can overfit toward that specific data set and not generalize well to a real-world 
      population, which creates issues of bias and potentially dangerous algorithmic 
      decisions. Consequently, if we plan on automating human decision-making, there is 
      a need for creating techniques and exhaustive evaluative processes for these 
      powerful unexplainable models to ensure that we do not incorporate and blindly 
      trust poor AI models to make real-world decisions. OBJECTIVE: We aimed to conduct 
      an evaluation study to see whether our most accurate transformer-based models 
      derived from previous studies could emulate our own classification spectrum for 
      tracking CEnR studies as well as whether the use of calibrated confidence scores 
      was meaningful. METHODS: We compared the results from 3 domain experts, who 
      classified a sample of 45 studies derived from our university's institutional 
      review board database, with those from 3 previously trained transformer-based 
      models, as well as investigated whether calibrated confidence scores can be a 
      viable technique for using AI in a support role for complex decision-making 
      systems. RESULTS: Our findings reveal that certain models exhibit an 
      overestimation of their performance through high confidence scores, despite not 
      achieving the highest validation accuracy. CONCLUSIONS: Future studies should be 
      conducted with larger sample sizes to generalize the results more effectively. 
      Although our study addresses the concerns of bias and overfitting in deep 
      learning models, there is a need to further explore methods that allow domain 
      experts to trust our models more. The use of a calibrated confidence score can be 
      a misleading metric when determining our AI model's level of competency.
CI  - ©Brian Ferrell, Sarah E Raskin, Emily B Zimmerman. Originally published in JMIR 
      Formative Research (https://formative.jmir.org), 20.03.2023.
FAU - Ferrell, Brian
AU  - Ferrell B
AUID- ORCID: 0000-0003-2301-4926
AD  - Virginia Commonwealth University, Richmond, VA, United States.
FAU - Raskin, Sarah E
AU  - Raskin SE
AUID- ORCID: 0000-0002-1652-6678
AD  - L. Douglas Wilder School of Government and Public Affairs, Virginia Commonwealth 
      University, Richmond, VA, United States.
FAU - Zimmerman, Emily B
AU  - Zimmerman EB
AUID- ORCID: 0000-0003-2678-6657
AD  - Center on Society and Health, Virginia Commonwealth University, Richmond, VA, 
      United States.
LA  - eng
GR  - UL1 TR002649/TR/NCATS NIH HHS/United States
PT  - Journal Article
DEP - 20230320
PL  - Canada
TA  - JMIR Form Res
JT  - JMIR formative research
JID - 101726394
PMC - PMC10131979
OTO - NOTNLM
OT  - BERT
OT  - Bidirectional Encoder Representations From Transformers
OT  - XAI
OT  - community engagement
OT  - community-engaged research
OT  - confidence
OT  - decision support
OT  - deep learning
OT  - explainable artificial intelligence
OT  - text classification
OT  - transformer-based models
OT  - trust
COIS- Conflicts of Interest: None declared.
EDAT- 2023/03/21 06:00
MHDA- 2023/03/21 06:01
PMCR- 2023/03/20
CRDT- 2023/03/20 11:54
PHST- 2022/07/28 00:00 [received]
PHST- 2023/01/31 00:00 [accepted]
PHST- 2023/01/14 00:00 [revised]
PHST- 2023/03/20 11:54 [entrez]
PHST- 2023/03/21 06:00 [pubmed]
PHST- 2023/03/21 06:01 [medline]
PHST- 2023/03/20 00:00 [pmc-release]
AID - v7i1e41516 [pii]
AID - 10.2196/41516 [doi]
PST - epublish
SO  - JMIR Form Res. 2023 Mar 20;7:e41516. doi: 10.2196/41516.

PMID- 39928916
OWN - NLM
STAT- MEDLINE
DCOM- 20250210
LR  - 20250213
IS  - 1526-2359 (Electronic)
IS  - 1073-2748 (Print)
IS  - 1073-2748 (Linking)
VI  - 32
DP  - 2025 Jan-Dec
TI  - Can the Use of Artificial Intelligence-Generated Content Bridge the Cancer 
      Knowledge Gap? A Longitudinal Study With Health Self-Efficacy as a Mediator and 
      Educational Level as a Moderator.
PG  - 10732748251319487
LID - 10.1177/10732748251319487 [doi]
LID - 10732748251319487
AB  - OBJECTIVES: The cancer knowledge gap represents a significant disparity in 
      awareness and understanding of cancer-related information across different 
      demographic groups. Leveraging Artificial Intelligence-Generated Content (AIGC) 
      offers a promising approach to personalize health education and potentially 
      bridge this gap. This study aimed to evaluate the potential of AIGC to bridge the 
      cancer knowledge gap, assessing the roles of health self-efficacy as a mediator 
      and educational level as a moderator in this relationship. METHODS: A 6-month 
      longitudinal study was conducted using online surveys distributed to 
      undergraduate students in non-medical disciplines at one university and graduate 
      students in medical specialties at another university in China. The study 
      assessed the frequency of AIGC use, health self-efficacy, and cancer knowledge at 
      two time points. RESULTS: The results indicated that AIGC use significantly 
      enhanced cancer knowledge levels and health self-efficacy over time. Educational 
      level notably moderated the effects of AIGC use, with non-medical undergraduate 
      students showing greater gains in knowledge and self-efficacy. Additionally, 
      health self-efficacy mediated the relationship between AIGC use and cancer 
      knowledge, underscoring the importance of health self-efficacy. The study 
      confirms the efficacy of AIGC in narrowing the cancer knowledge gap and enhancing 
      health self-efficacy, particularly among students with lower initial medical 
      knowledge. CONCLUSION: These findings highlight the potential of integrating AIGC 
      tools in cancer education and public health interventions, particularly for 
      individuals at different educational levels. By tailoring digital health 
      resources to varying educational needs, these interventions could enhance cancer 
      knowledge acquisition, improve health self-efficacy, and contribute to better 
      cancer prevention and control outcomes.
FAU - Xie, Zehang
AU  - Xie Z
AUID- ORCID: 0000-0003-2665-2640
AD  - School of Media and Communication, Shanghai Jiao Tong University, Shanghai, 
      China. RINGGOLD: 12474
AD  - Wee Kim Wee School of Communication and Information, Nanyang Technological 
      University, Singapore.
FAU - Chen, Ru
AU  - Chen R
AD  - College of Humanities and New Media, Yangtze University, Jingzhou, China. 
      RINGGOLD: 47897
FAU - Ding, Wenjuan
AU  - Ding W
AD  - School of Culture and Media, Zhengzhou College of Finance and Economics, 
      Zhengzhou, China. RINGGOLD: 499571
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Cancer Control
JT  - Cancer control : journal of the Moffitt Cancer Center
JID - 9438457
SB  - IM
MH  - Humans
MH  - Longitudinal Studies
MH  - *Self Efficacy
MH  - Female
MH  - Male
MH  - *Neoplasms/psychology
MH  - *Artificial Intelligence
MH  - *Health Knowledge, Attitudes, Practice
MH  - Adult
MH  - Young Adult
MH  - Surveys and Questionnaires
MH  - Health Education/methods
MH  - Educational Status
MH  - China
PMC - PMC11811976
OAB - This study explores whether artificial intelligence-generated content (AIGC) 
      tools, such as ChatGPT, can reduce disparities in cancer knowledge across 
      different education levels. The research focused on university students in China 
      over six months, with one group studying computer science and another in medical 
      fields. Participants used AI tools to learn about cancer prevention, early 
      detection, and treatment. The study found that frequent use of AIGC tools 
      significantly improved participants' understanding of cancer and their confidence 
      in managing their health (health self-efficacy). Non-medical students benefited 
      the most, as they started with less prior knowledge compared to medical students. 
      Additionally, students who felt more confident in their health knowledge were 
      more likely to understand and retain cancer-related information. This research 
      shows that AIGC tools can bridge knowledge gaps by providing personalized and 
      accessible content. The findings suggest that such tools can play a vital role in 
      public health campaigns and educational programs, especially for people with 
      limited access to traditional healthcare education. These insights highlight the 
      potential for AI technology to improve cancer awareness and health 
      decision-making, ultimately contributing to better prevention and treatment 
      outcomes.
OABL- eng
OTO - NOTNLM
OT  - AIGC
OT  - cancer knowledge gap
OT  - educational level
OT  - health self-efficacy
OT  - longitudinal study
COIS- Declaration of Conflicting InterestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2025/02/10 18:16
MHDA- 2025/02/10 18:17
PMCR- 2025/02/10
CRDT- 2025/02/10 16:43
PHST- 2025/02/10 18:17 [medline]
PHST- 2025/02/10 18:16 [pubmed]
PHST- 2025/02/10 16:43 [entrez]
PHST- 2025/02/10 00:00 [pmc-release]
AID - 10.1177_10732748251319487 [pii]
AID - 10.1177/10732748251319487 [doi]
PST - ppublish
SO  - Cancer Control. 2025 Jan-Dec;32:10732748251319487. doi: 
      10.1177/10732748251319487.

PMID- 38953081
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240703
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 5
DP  - 2024 May
TI  - Using ChatGPT in the Development of Clinical Reasoning Cases: A Qualitative 
      Study.
PG  - e61438
LID - 10.7759/cureus.61438 [doi]
LID - e61438
AB  - Background There has been an explosion of commentary and discussion about the 
      ethics and utility of using artificial intelligence in medicine, and its 
      practical use in medical education is still being debated. Through qualitative 
      research methods, this study aims to highlight the advantages and pitfalls of 
      using ChatGPT in the development of clinical reasoning cases for medical student 
      education. Methods Five highly experienced faculty in medical education were 
      provided instructions to create unique clinical reasoning cases for three 
      different chief concerns using ChatGPT 3.0. Faculty were then asked to reflect on 
      and review the created cases. Finally, a focus group was conducted to further 
      analyze and describe their experiences with the new technology. Results Overall, 
      faculty found the use of ChatGPT in the development of clinical reasoning cases 
      easy to use but difficult to get to certain objectives and largely incapable of 
      being creative enough to create complexity for student use without heavy editing. 
      The created cases did provide a helpful starting point and were extremely 
      efficient; however, faculty did experience some medical inaccuracies and fact 
      fabrication. Conclusion There is value to using ChatGPT to develop curricular 
      content, especially for clinical reasoning cases, but it needs to be 
      comprehensively reviewed and verified. To efficiently and effectively utilize the 
      tool, educators will need to develop a framework that can be easily translatable 
      into simple prompts that ChatGPT can understand. Future work will need to 
      strongly consider the risks of recirculating biases and misinformation.
CI  - Copyright © 2024, Wong et al.
FAU - Wong, Kristin
AU  - Wong K
AD  - Medicine, Rutgers University New Jersey Medical School, Newark, USA.
FAU - Fayngersh, Alla
AU  - Fayngersh A
AD  - Medicine, Rutgers University New Jersey Medical School, Newark, USA.
FAU - Traba, Christin
AU  - Traba C
AD  - Pediatrics, Rutgers University New Jersey Medical School, Newark, USA.
FAU - Cennimo, David
AU  - Cennimo D
AD  - Infectious Diseases, Veterans Affairs New Jersey Medical Center, East Orange, 
      USA.
FAU - Kothari, Neil
AU  - Kothari N
AD  - Medicine, Rutgers University New Jersey Medical School, Newark, USA.
FAU - Chen, Sophia
AU  - Chen S
AD  - Pediatrics, Rutgers University New Jersey Medical School, Newark, USA.
LA  - eng
PT  - Journal Article
DEP - 20240531
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11215020
OTO - NOTNLM
OT  - chatgpt
OT  - clinical reasoning cases
OT  - focus group
OT  - medical education
OT  - qualitative study
COIS- Human subjects: All authors have confirmed that this study did not involve human 
      participants or tissue. Animal subjects: All authors have confirmed that this 
      study did not involve animal subjects or tissue. Conflicts of interest: In 
      compliance with the ICMJE uniform disclosure form, all authors declare the 
      following: Payment/services info: All authors have declared that no financial 
      support was received from any organization for the submitted work. Financial 
      relationships: All authors have declared that they have no financial 
      relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2024/07/02 06:42
MHDA- 2024/07/02 06:43
PMCR- 2024/05/31
CRDT- 2024/07/02 04:15
PHST- 2024/05/30 00:00 [accepted]
PHST- 2024/07/02 06:43 [medline]
PHST- 2024/07/02 06:42 [pubmed]
PHST- 2024/07/02 04:15 [entrez]
PHST- 2024/05/31 00:00 [pmc-release]
AID - 10.7759/cureus.61438 [doi]
PST - epublish
SO  - Cureus. 2024 May 31;16(5):e61438. doi: 10.7759/cureus.61438. eCollection 2024 
      May.

PMID- 38846858
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240608
IS  - 2049-0801 (Print)
IS  - 2049-0801 (Electronic)
IS  - 2049-0801 (Linking)
VI  - 86
IP  - 6
DP  - 2024 Jun
TI  - The scientific knowledge of three large language models in cardiology: 
      multiple-choice questions examination-based performance.
PG  - 3261-3266
LID - 10.1097/MS9.0000000000002120 [doi]
AB  - BACKGROUND: The integration of artificial intelligence (AI) chatbots like 
      Google's Bard, OpenAI's ChatGPT, and Microsoft's Bing Chatbot into academic and 
      professional domains, including cardiology, has been rapidly evolving. Their 
      application in educational and research frameworks, however, raises questions 
      about their efficacy, particularly in specialized fields like cardiology. This 
      study aims to evaluate the knowledge depth and accuracy of these AI chatbots in 
      cardiology using a multiple-choice question (MCQ) format. METHODS: The study was 
      conducted as an exploratory, cross-sectional study in November 2023 on a bank of 
      100 MCQs covering various cardiology topics that was created from authoritative 
      textbooks and question banks. These MCQs were then used to assess the knowledge 
      level of Google's Bard, Microsoft Bing, and ChatGPT 4.0. Each question was 
      entered manually into the chatbots, ensuring no memory retention bias. RESULTS: 
      The study found that ChatGPT 4.0 demonstrated the highest knowledge score in 
      cardiology, with 87% accuracy, followed by Bing at 60% and Bard at 46%. The 
      performance varied across different cardiology subtopics, with ChatGPT 
      consistently outperforming the others. Notably, the study revealed significant 
      differences in the proficiency of these chatbots in specific cardiology domains. 
      CONCLUSION: This study highlights a spectrum of efficacy among AI chatbots in 
      disseminating cardiology knowledge. ChatGPT 4.0 emerged as a potential auxiliary 
      educational resource in cardiology, surpassing traditional learning methods in 
      some aspects. However, the variability in performance among these AI systems 
      underscores the need for cautious evaluation and continuous improvement, 
      especially for chatbots like Bard, to ensure reliability and accuracy in medical 
      knowledge dissemination.
CI  - Copyright © 2024 The Author(s). Published by Wolters Kluwer Health, Inc.
FAU - Altamimi, Ibraheem
AU  - Altamimi I
AD  - College of Medicine.
AD  - Evidence-Based Health Care and Knowledge Translation Research Chair, Family and 
      Community Medicine Department, College of Medicine, King Saud University.
FAU - Alhumimidi, Abdullah
AU  - Alhumimidi A
AD  - College of Medicine.
FAU - Alshehri, Salem
AU  - Alshehri S
AD  - College of Medicine.
FAU - Alrumayan, Abdullah
AU  - Alrumayan A
AD  - College of Medicine, King Saud Bin Abdulaziz University for Health and Sciences, 
      Riyadh, Saudi Arabia.
FAU - Al-Khlaiwi, Thamir
AU  - Al-Khlaiwi T
AD  - Department of Physiology.
FAU - Meo, Sultan A
AU  - Meo SA
AD  - Department of Physiology.
FAU - Temsah, Mohamad-Hani
AU  - Temsah MH
AD  - College of Medicine.
AD  - Evidence-Based Health Care and Knowledge Translation Research Chair, Family and 
      Community Medicine Department, College of Medicine, King Saud University.
AD  - Pediatric Intensive Care Unit, Pediatric Department, College of Medicine, King 
      Saud University Medical City.
LA  - eng
PT  - Journal Article
DEP - 20240506
PL  - England
TA  - Ann Med Surg (Lond)
JT  - Annals of medicine and surgery (2012)
JID - 101616869
PMC - PMC11152788
OTO - NOTNLM
OT  - AI assessment
OT  - MCQ assessment
OT  - artificial intelligence
OT  - cardiology
OT  - medical education
COIS- The authors report no personal or financial conflict of interests to 
      declare.Sponsorships or competing interests that may be relevant to content are 
      disclosed at the end of this article.
EDAT- 2024/06/07 06:42
MHDA- 2024/06/07 06:43
PMCR- 2024/05/06
CRDT- 2024/06/07 04:50
PHST- 2023/12/28 00:00 [received]
PHST- 2024/04/16 00:00 [accepted]
PHST- 2024/06/07 06:43 [medline]
PHST- 2024/06/07 06:42 [pubmed]
PHST- 2024/06/07 04:50 [entrez]
PHST- 2024/05/06 00:00 [pmc-release]
AID - AMSU-D-23-02753 [pii]
AID - 10.1097/MS9.0000000000002120 [doi]
PST - epublish
SO  - Ann Med Surg (Lond). 2024 May 6;86(6):3261-3266. doi: 
      10.1097/MS9.0000000000002120. eCollection 2024 Jun.

PMID- 37974429
OWN - NLM
STAT- MEDLINE
DCOM- 20240227
LR  - 20240227
IS  - 1724-6016 (Electronic)
IS  - 1120-6721 (Linking)
VI  - 34
IP  - 2
DP  - 2024 Mar
TI  - Leveraging ChatGPT for ophthalmic education: A critical appraisal.
PG  - 323-327
LID - 10.1177/11206721231215862 [doi]
AB  - In recent years, the advent of artificial intelligence (AI) has transformed many 
      sectors, including medical education. This editorial critically appraises the 
      integration of ChatGPT, a state-of-the-art AI language model, into ophthalmic 
      education, focusing on its potential, limitations, and ethical considerations. 
      The application of ChatGPT in teaching and training ophthalmologists presents an 
      innovative method to offer real-time, customized learning experiences. Through a 
      systematic analysis of both experimental and clinical data, this editorial 
      examines how ChatGPT enhances engagement, understanding, and retention of complex 
      ophthalmological concepts. The study also evaluates the efficacy of ChatGPT in 
      simulating patient interactions and clinical scenarios, which can foster improved 
      diagnostic and interpersonal skills. Despite the promising advantages, concerns 
      regarding reliability, lack of personal touch, and potential biases in the 
      AI-generated content are scrutinized. Ethical considerations concerning data 
      privacy and potential misuse are also explored. The findings underline the need 
      for carefully designed integration, continuous evaluation, and adherence to 
      ethical guidelines to maximize benefits while mitigating risks. By shedding light 
      on these multifaceted aspects, this paper contributes to the ongoing discourse on 
      the incorporation of AI in medical education, offering valuable insights and 
      guidance for educators, practitioners, and policymakers aiming to leverage modern 
      technology for enhancing ophthalmic education.
FAU - Gurnani, Bharat
AU  - Gurnani B
AUID- ORCID: 0000-0003-0848-5172
AD  - Cataract, Cornea, Trauma, External Diseases, Ocular Surface and Refractive 
      Services, ASG Eye Hospital, Jodhpur, Rajasthan, India.
AD  - Sadguru Netra Chikitsalya, Shri Sadguru Seva Sangh Trust, Chitrakoot, Madhya 
      Pradesh, India.
FAU - Kaur, Kirandeep
AU  - Kaur K
AUID- ORCID: 0000-0002-0951-7415
AD  - Cataract, Pediatric Ophthalmology and Strabismus, ASG Eye Hospital, Jodhpur, 
      Rajasthan, India.
AD  - Children Eye Care Centre, Sadguru Netra Chikitsalya, Shri Sadguru Seva Sangh 
      Trust, Chitrakoot, Madhya Pradesh, India.
LA  - eng
PT  - Editorial
DEP - 20231116
PL  - United States
TA  - Eur J Ophthalmol
JT  - European journal of ophthalmology
JID - 9110772
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - Eye
MH  - Language
MH  - *Ophthalmologists
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - ophthalmology education
COIS- Declaration of conflicting interestsThe author(s) declared no potential conflicts 
      of interest with respect to the research, authorship, and/or publication of this 
      article.
EDAT- 2023/11/17 15:24
MHDA- 2024/02/27 06:44
CRDT- 2023/11/17 03:42
PHST- 2024/02/27 06:44 [medline]
PHST- 2023/11/17 15:24 [pubmed]
PHST- 2023/11/17 03:42 [entrez]
AID - 10.1177/11206721231215862 [doi]
PST - ppublish
SO  - Eur J Ophthalmol. 2024 Mar;34(2):323-327. doi: 10.1177/11206721231215862. Epub 
      2023 Nov 16.

PMID- 37814667
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240926
IS  - 1985-207X (Print)
IS  - 1985-2274 (Electronic)
IS  - 1985-2274 (Linking)
VI  - 18
DP  - 2023
TI  - Use of ChatGPT in medical research and scientific writing.
PG  - 58
LID - 10.51866/cm0006 [doi]
AB  - ChatGPT, an artificial intelligence (AI) language model based on the GPT-3.5 
      architecture, is revolutionising scientific writing and medical research. 
      Researchers employ ChatGPT for diverse tasks, including automated literature 
      reviews, structured-outline generation and drafting/editing assistance. The tool 
      adapts language for varied audiences, aids in citation management, supports 
      collaborative writing and peer review and facilitates table/figure creation. 
      While it enhances efficiency, concerns arise regarding ethics, bias, accuracy and 
      originality. Transparent data sourcing and validation are crucial, as ChatGPT 
      complements human efforts but does not replace critical thinking. Accordingly, 
      researchers must uphold integrity, ensuring that AI-assisted content aligns with 
      research principles. Acknowledgement of AI use in manuscripts, as recommended by 
      the International Committee of Medical Journal Editors, ensures accountability. 
      ChatGPT's transformative potential lies in harmonising its capabilities with 
      researchers' expertise, fostering a symbiotic relationship that advances 
      scientific progress and ethical standards.
CI  - © Academy of Family Physicians of Malaysia.
FAU - Lee, Ping Yein
AU  - Lee PY
AD  - MBBS, DrFamMed, UM eHealth Unit, Faculty of Medicine, Universiti Malaya, Kuala 
      Lumpur, Malaysia. Email: pylee02@gmail.com.
FAU - Salim, Hani
AU  - Salim H
AD  - MBBChBAO, MFamMed, PhD, Department of Family Medicine, Universiti Putra Malaysia, 
      Seri Kembangan, Selangor, Malaysia.
FAU - Abdullah, Adina
AU  - Abdullah A
AD  - MBBS, MFamMed, PhD, Department of Primary Care Medicine, Faculty of Medicine, 
      Universiti, Malaya, Kuala Lumpur, Malaysia.
FAU - Teo, Chin Hai
AU  - Teo CH
AD  - BMedImag, PhD, Department of Primary Care Medicine, Faculty of Medicine, 
      Universiti, Malaya, Kuala Lumpur, Malaysia.
AD  - UM eHealth Unit, Faculty of Medicine, Universiti Malaya, Kuala Lumpur, Malaysia.
LA  - eng
PT  - Editorial
DEP - 20230925
PL  - Malaysia
TA  - Malays Fam Physician
JT  - Malaysian family physician : the official journal of the Academy of Family 
      Physicians of Malaysia
JID - 101466855
PMC - PMC10560470
OTO - NOTNLM
OT  - Artificial intelligence (AI)
OT  - ChatGPT
OT  - Medical research
OT  - Scientific writing
COIS- All authors declare no conflicts of interest.
EDAT- 2023/10/10 06:41
MHDA- 2023/10/10 06:42
PMCR- 2023/09/25
CRDT- 2023/10/10 03:38
PHST- 2023/10/10 06:42 [medline]
PHST- 2023/10/10 06:41 [pubmed]
PHST- 2023/10/10 03:38 [entrez]
PHST- 2023/09/25 00:00 [pmc-release]
AID - 10.51866/cm0006 [doi]
PST - epublish
SO  - Malays Fam Physician. 2023 Sep 25;18:58. doi: 10.51866/cm0006. eCollection 2023.

PMID- 39388702
OWN - NLM
STAT- MEDLINE
DCOM- 20241010
LR  - 20241019
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Oct 10
TI  - Navigating Nephrology's Decline Through a GPT-4 Analysis of Internal Medicine 
      Specialties in the United States: Qualitative Study.
PG  - e57157
LID - 10.2196/57157 [doi]
LID - e57157
AB  - BACKGROUND: The 2024 Nephrology fellowship match data show the declining interest 
      in nephrology in the United States, with an 11% drop in candidates and a mere 66% 
      (321/488) of positions filled. OBJECTIVE: The study aims to discern the factors 
      influencing this trend using ChatGPT, a leading chatbot model, for insights into 
      the comparative appeal of nephrology versus other internal medicine specialties. 
      METHODS: Using the GPT-4 model, the study compared nephrology with 13 other 
      internal medicine specialties, evaluating each on 7 criteria including 
      intellectual complexity, work-life balance, procedural involvement, research 
      opportunities, patient relationships, career demand, and financial compensation. 
      Each criterion was assigned scores from 1 to 10, with the cumulative score 
      determining the ranking. The approach included counteracting potential bias by 
      instructing GPT-4 to favor other specialties over nephrology in reverse 
      scenarios. RESULTS: GPT-4 ranked nephrology only above sleep medicine. While 
      nephrology scored higher than hospice and palliative medicine, it fell short in 
      key criteria such as work-life balance, patient relationships, and career demand. 
      When examining the percentage of filled positions in the 2024 appointment year 
      match, nephrology's filled rate was 66%, only higher than the 45% (155/348) 
      filled rate of geriatric medicine. Nephrology's score decreased by 4%-14% in 5 
      criteria including intellectual challenge and complexity, procedural involvement, 
      career opportunity and demand, research and academic opportunities, and financial 
      compensation. CONCLUSIONS: ChatGPT does not favor nephrology over most internal 
      medicine specialties, highlighting its diminishing appeal as a career choice. 
      This trend raises significant concerns, especially considering the overall 
      physician shortage, and prompts a reevaluation of factors affecting specialty 
      choice among medical residents.
CI  - © Jing Miao, Charat Thongprayoon, Oscar Garcia Valencia, Iasmina M Craici, Wisit 
      Cheungpasitporn. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org).
FAU - Miao, Jing
AU  - Miao J
AUID- ORCID: 0000-0003-0642-9740
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 200 
      1st st sw, Rochester, MN, 55905, United States, 1 507 594 4700.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AUID- ORCID: 0000-0002-8313-3604
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 200 
      1st st sw, Rochester, MN, 55905, United States, 1 507 594 4700.
FAU - Garcia Valencia, Oscar
AU  - Garcia Valencia O
AUID- ORCID: 0000-0003-0186-9448
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 200 
      1st st sw, Rochester, MN, 55905, United States, 1 507 594 4700.
FAU - Craici, Iasmina M
AU  - Craici IM
AUID- ORCID: 0009-0004-6739-4531
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 200 
      1st st sw, Rochester, MN, 55905, United States, 1 507 594 4700.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AUID- ORCID: 0000-0001-9954-9711
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 200 
      1st st sw, Rochester, MN, 55905, United States, 1 507 594 4700.
LA  - eng
PT  - Journal Article
DEP - 20241010
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - United States
MH  - Humans
MH  - *Nephrology/education
MH  - *Internal Medicine/education
MH  - *Career Choice
MH  - *Qualitative Research
MH  - Internship and Residency/statistics & numerical data
PMC - PMC11486450
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - United States
OT  - artificial intelligence
OT  - career demand
OT  - chatbots
OT  - complexity
OT  - factor
OT  - fellowship
OT  - fellowship matching
OT  - financial compensation
OT  - intellectual
OT  - medical education
OT  - nephrology
OT  - nephrology fellowship training
OT  - opportunity
OT  - procedural involvement
OT  - work-life balance
COIS- None declared.
EDAT- 2024/10/10 18:50
MHDA- 2024/10/10 18:51
PMCR- 2024/10/10
CRDT- 2024/10/10 17:02
PHST- 2024/02/06 00:00 [received]
PHST- 2024/05/22 00:00 [revised]
PHST- 2024/08/15 00:00 [accepted]
PHST- 2024/10/10 18:51 [medline]
PHST- 2024/10/10 18:50 [pubmed]
PHST- 2024/10/10 17:02 [entrez]
PHST- 2024/10/10 00:00 [pmc-release]
AID - v10i1e57157 [pii]
AID - 57157 [pii]
AID - 10.2196/57157 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Oct 10;10:e57157. doi: 10.2196/57157.

PMID- 39180023
OWN - NLM
STAT- MEDLINE
DCOM- 20240824
LR  - 20240826
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 24
IP  - 1
DP  - 2024 Aug 23
TI  - A cross sectional investigation of ChatGPT-like large language models application 
      among medical students in China.
PG  - 908
LID - 10.1186/s12909-024-05871-8 [doi]
LID - 908
AB  - OBJECTIVE: To investigate the level of understanding and trust of medical 
      students towards ChatGPT-like large language models, as well as their utilization 
      and attitudes towards these models. METHODS: Data collection was concentrated 
      from December 2023 to mid-January 2024, utilizing a self-designed questionnaire 
      to assess the use of large language models among undergraduate medical students 
      at Anhui Medical University. The normality of the data was confirmed with 
      Shapiro-Wilk tests. We used Chi-square tests for comparisons of categorical 
      variables, Mann-Whitney U tests for comparisons of ordinal variables and 
      non-normal continuous variables between two groups, Kruskall-Wallis H tests for 
      comparisons of ordinal variables between multiple groups, and Bonferroni tests 
      for post hoc comparisons. RESULTS: A total of 1774 questionnaires were 
      distributed and 1718 valid questionnaires were collected, with an effective rate 
      of 96.84%. Among these students, 34.5% had heard and used large language models. 
      There were statistically significant differences in the understanding of large 
      language models between genders (p < 0.001), grade levels (junior-level students 
      and senior-level students) (p = 0.03), and major (p < 0.001). Male, junior-level 
      students, and public health management had a higher level of understanding of 
      these models. Genders and majors had statistically significant effects on the 
      degree of trust in large language models (p = 0.004; p = 0.02). Male and nursing 
      students exhibited a higher degree of trust in large language models. As for 
      usage, Male and junior-level students showed a significantly higher proportion of 
      using these models for assisted learning (p < 0.001). Neutral sentiments were 
      held by over two-thirds of the students (66.7%) regarding large language models, 
      with only 51(3.0%) expressing pessimism. There were significant gender-based 
      disparities in attitudes towards large language models, and male exhibited a more 
      optimistic attitude towards these models (p < 0.001). Notably, among students 
      with different levels of knowledge and trust in large language models, 
      statistically significant differences were observed in their perceptions of the 
      shortcomings and benefits of these models. CONCLUSION: Our study identified 
      gender, grade levels, and major as influential factors in students' understanding 
      and utilization of large language models. This also suggested the feasibility of 
      integrating large language models with traditional medical education to further 
      enhance teaching effectiveness in the future.
CI  - © 2024. The Author(s).
FAU - Pan, Guixia
AU  - Pan G
AD  - Department of Epidemiology and Biostatistics, School of Public Health, Anhui 
      Medical University, Meishan Road 81, Hefei, 230032, Anhui, China. pgxkd@163.com.
FAU - Ni, Jing
AU  - Ni J
AD  - Department of Epidemiology and Biostatistics, School of Public Health, Anhui 
      Medical University, Meishan Road 81, Hefei, 230032, Anhui, China.
LA  - eng
GR  - 2022zyxwjxalk050/Anhui New Era education quality engineering project/
GR  - 2023zyxwjxalk056/Education Department of Anhui quality engineering project/
PT  - Journal Article
DEP - 20240823
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - Humans
MH  - *Students, Medical/psychology
MH  - Male
MH  - China
MH  - Female
MH  - Cross-Sectional Studies
MH  - Surveys and Questionnaires
MH  - Education, Medical, Undergraduate
MH  - Language
MH  - Young Adult
MH  - Trust
PMC - PMC11342543
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Large language models
OT  - Medical education
COIS- The authors declare no competing interests.
EDAT- 2024/08/24 16:42
MHDA- 2024/08/24 16:43
PMCR- 2024/08/23
CRDT- 2024/08/23 23:40
PHST- 2024/05/22 00:00 [received]
PHST- 2024/08/07 00:00 [accepted]
PHST- 2024/08/24 16:43 [medline]
PHST- 2024/08/24 16:42 [pubmed]
PHST- 2024/08/23 23:40 [entrez]
PHST- 2024/08/23 00:00 [pmc-release]
AID - 10.1186/s12909-024-05871-8 [pii]
AID - 5871 [pii]
AID - 10.1186/s12909-024-05871-8 [doi]
PST - epublish
SO  - BMC Med Educ. 2024 Aug 23;24(1):908. doi: 10.1186/s12909-024-05871-8.

PMID- 38109889
OWN - NLM
STAT- MEDLINE
DCOM- 20240822
LR  - 20250104
IS  - 1527-974X (Electronic)
IS  - 1067-5027 (Print)
IS  - 1067-5027 (Linking)
VI  - 31
IP  - 9
DP  - 2024 Sep 1
TI  - Benchmarking the symptom-checking capabilities of ChatGPT for a broad range of 
      diseases.
PG  - 2084-2088
LID - 10.1093/jamia/ocad245 [doi]
AB  - OBJECTIVE: This study evaluates ChatGPT's symptom-checking accuracy across a 
      broad range of diseases using the Mayo Clinic Symptom Checker patient service as 
      a benchmark. METHODS: We prompted ChatGPT with symptoms of 194 distinct diseases. 
      By comparing its predictions with expectations, we calculated a relative 
      comparative score (RCS) to gauge accuracy. RESULTS: ChatGPT's GPT-4 model 
      achieved an average RCS of 78.8%, outperforming the GPT-3.5-turbo by 10.5%. Some 
      specialties scored above 90%. DISCUSSION: The test set, although extensive, was 
      not exhaustive. Future studies should include a more comprehensive disease 
      spectrum. CONCLUSION: ChatGPT exhibits high accuracy in symptom checking for a 
      broad range of diseases, showcasing its potential as a medical training tool in 
      learning health systems to enhance care quality and address health disparities.
CI  - © The Author(s) 2023. Published by Oxford University Press on behalf of the 
      American Medical Informatics Association. All rights reserved. For permissions, 
      please email: journals.permissions@oup.com.
FAU - Chen, Anjun
AU  - Chen A
AUID- ORCID: 0000-0003-4209-8301
AD  - Health Sciences, ELHS Institute, Palo Alto, CA 94306, United States.
AD  - LHS Tech Forum Initiative, Learning Health Community, Palo Alto, CA 94306, United 
      States.
FAU - Chen, Drake O
AU  - Chen DO
AD  - LHS Tech Forum Initiative, Learning Health Community, Palo Alto, CA 94306, United 
      States.
FAU - Tian, Lu
AU  - Tian L
AD  - Department of Biomedical Data Science, Stanford University, Stanford, CA 94305, 
      United States.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Am Med Inform Assoc
JT  - Journal of the American Medical Informatics Association : JAMIA
JID - 9430800
SB  - IM
MH  - Humans
MH  - *Benchmarking
MH  - Symptom Assessment
MH  - Disease
PMC - PMC11339504
OTO - NOTNLM
OT  - ChatGPT
OT  - benchmarking
OT  - learning health system
OT  - medical training
OT  - symptom checking
COIS- None declared.
EDAT- 2023/12/19 00:41
MHDA- 2024/08/22 06:42
PMCR- 2024/12/18
CRDT- 2023/12/18 18:44
PHST- 2023/08/21 00:00 [received]
PHST- 2023/11/17 00:00 [revised]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2024/08/22 06:42 [medline]
PHST- 2023/12/19 00:41 [pubmed]
PHST- 2023/12/18 18:44 [entrez]
PHST- 2024/12/18 00:00 [pmc-release]
AID - 7477862 [pii]
AID - ocad245 [pii]
AID - 10.1093/jamia/ocad245 [doi]
PST - ppublish
SO  - J Am Med Inform Assoc. 2024 Sep 1;31(9):2084-2088. doi: 10.1093/jamia/ocad245.

PMID- 37720897
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230921
IS  - 1664-0640 (Print)
IS  - 1664-0640 (Electronic)
IS  - 1664-0640 (Linking)
VI  - 14
DP  - 2023
TI  - The plasticity of ChatGPT's mentalizing abilities: personalization for 
      personality structures.
PG  - 1234397
LID - 10.3389/fpsyt.2023.1234397 [doi]
LID - 1234397
AB  - This study evaluated the potential of ChatGPT, a large language model, to 
      generate mentalizing-like abilities that are tailored to a specific personality 
      structure and/or psychopathology. Mentalization is the ability to understand and 
      interpret one's own and others' mental states, including thoughts, feelings, and 
      intentions. Borderline Personality Disorder (BPD) and Schizoid Personality 
      Disorder (SPD) are characterized by distinct patterns of emotional regulation. 
      Individuals with BPD tend to experience intense and unstable emotions, while 
      individuals with SPD tend to experience flattened or detached emotions. We used 
      ChatGPT's free version 23.3 and assessed the extent to which its responses akin 
      to emotional awareness (EA) were customized to the distinctive personality 
      structure-character characterized by Borderline Personality Disorder (BPD) and 
      Schizoid Personality Disorder (SPD), employing the Levels of Emotional Awareness 
      Scale (LEAS). ChatGPT was able to accurately describe the emotional reactions of 
      individuals with BPD as more intense, complex, and rich than those with SPD. This 
      finding suggests that ChatGPT can generate mentalizing-like responses consistent 
      with a range of psychopathologies in line with clinical and theoretical 
      knowledge. However, the study also raises concerns regarding the potential for 
      stigmas or biases related to mental diagnoses to impact the validity and 
      usefulness of chatbot-based clinical interventions. We emphasize the need for the 
      responsible development and deployment of chatbot-based interventions in mental 
      health, which considers diverse theoretical frameworks.
CI  - Copyright © 2023 Hadar-Shoval, Elyoseph and Lvovsky.
FAU - Hadar-Shoval, Dorit
AU  - Hadar-Shoval D
AD  - Department of Psychology and Educational Counseling, The Center for 
      Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AD  - Department of Psychology and Educational Counseling, The Center for 
      Psychobiological Research, Max Stern Yezreel Valley College, Emek Yezreel, 
      Israel.
AD  - Department of Brain Sciences, Faculty of Medicine, Imperial College London, 
      London, United Kingdom.
AD  - Educational Psychology Department, Center for Psychobiological Research, Max 
      Stern Yezreel Valley College, Emek Yezreel, Israel.
FAU - Lvovsky, Maya
AU  - Lvovsky M
AD  - Educational Psychology Department, Center for Psychobiological Research, Max 
      Stern Yezreel Valley College, Emek Yezreel, Israel.
LA  - eng
PT  - Journal Article
DEP - 20230901
PL  - Switzerland
TA  - Front Psychiatry
JT  - Frontiers in psychiatry
JID - 101545006
PMC - PMC10503434
OTO - NOTNLM
OT  - Schizoid Personality Disorder
OT  - artificial intelligence
OT  - borderline personality disorder
OT  - emotional awareness
OT  - emotional intelligence
OT  - empathy
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/09/18 06:42
MHDA- 2023/09/18 06:43
PMCR- 2023/09/01
CRDT- 2023/09/18 04:47
PHST- 2023/06/04 00:00 [received]
PHST- 2023/08/22 00:00 [accepted]
PHST- 2023/09/18 06:43 [medline]
PHST- 2023/09/18 06:42 [pubmed]
PHST- 2023/09/18 04:47 [entrez]
PHST- 2023/09/01 00:00 [pmc-release]
AID - 10.3389/fpsyt.2023.1234397 [doi]
PST - epublish
SO  - Front Psychiatry. 2023 Sep 1;14:1234397. doi: 10.3389/fpsyt.2023.1234397. 
      eCollection 2023.

PMID- 39756334
OWN - NLM
STAT- MEDLINE
DCOM- 20250325
LR  - 20250327
IS  - 1532-7361 (Electronic)
IS  - 0039-6060 (Print)
IS  - 0039-6060 (Linking)
VI  - 180
DP  - 2025 Apr
TI  - De novo generation of colorectal patient educational materials using large 
      language models: Prompt engineering key to improved readability.
PG  - 109024
LID - S0039-6060(24)01011-0 [pii]
LID - 10.1016/j.surg.2024.109024 [doi]
AB  - BACKGROUND: Improving patient education has been shown to improve clinical 
      outcomes and reduce disparities, though such efforts can be labor intensive. 
      Large language models may serve as an accessible method to improve patient 
      educational material. The aim of this study was to compare readability between 
      existing educational materials and those generated by large language models. 
      METHODS: Baseline colorectal surgery educational materials were gathered from a 
      large academic institution (n = 52). Three prompts were entered into Perplexity 
      and ChatGPT 3.5 for each topic: a Basic prompt that simply requested patient 
      educational information the topic, an Iterative prompt that repeated instruction 
      asking for the information to be more health literate, and a Metric-based prompt 
      that requested a sixth-grade reading level, short sentences, and short words. 
      Flesch-Kincaid Grade Level or Grade Level, Flesch-Kincaid Reading Ease or Ease, 
      and Modified Grade Level scores were calculated for all materials, and unpaired t 
      tests were used to compare mean scores between baseline and documents generated 
      by artificial intelligence platforms. RESULTS: Overall existing materials were 
      longer than materials generated by the large language models across categories 
      and prompts: 863-956 words vs 170-265 (ChatGPT) and 220-313 (Perplexity), all P < 
      .01. Baseline materials did not meet sixth-grade readability guidelines based on 
      grade level (Grade Level 7.0-9.8 and Modified Grade Level 9.6-11.5) or ease of 
      readability (Ease 53.1-65.0). Readability of materials generated by a large 
      language model varied by prompt and platform. Overall, ChatGPT materials were 
      more readable than baseline materials with the Metric-based prompt: Grade Level 
      5.2 vs 8.1, Modified Grade Level 7.3 vs 10.3, and Ease 70.5 vs 60.4, all P < .01. 
      In contrast, Perplexity-generated materials were significantly less readable 
      except for those generated with the Metric-based prompt, which did not 
      statistically differ. CONCLUSION: Both existing materials and the majority of 
      educational materials created by large language models did not meet readability 
      recommendations. The exception to this was with ChatGPT materials generated with 
      a Metric-based prompt that consistently improved readability scores from baseline 
      and met recommendations in terms of the average Grade Level score. The 
      variability in performance highlights the importance of the prompt used with 
      large language models.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Ellison, India E
AU  - Ellison IE
AD  - Department of Surgery, University of Alabama at Birmingham, AL.
FAU - Oslock, Wendelyn M
AU  - Oslock WM
AD  - Department of Surgery, University of Alabama at Birmingham, AL; Department of 
      Quality, Birmingham Veterans Affairs Medical Center, AL. Electronic address: 
      https://www.twitter.com/WendelynOslock.
FAU - Abdullah, Abiha
AU  - Abdullah A
AD  - Trauma and Transfusion Department, University of Pittsburgh Medical College, PA. 
      Electronic address: https://www.twitter.com/abihaabdullah7.
FAU - Wood, Lauren
AU  - Wood L
AD  - Department of Surgery, University of Alabama at Birmingham, AL.
FAU - Thirumalai, Mohanraj
AU  - Thirumalai M
AD  - Department of Surgery, University of Alabama at Birmingham, AL.
FAU - English, Nathan
AU  - English N
AD  - Department of Surgery, University of Alabama at Birmingham, AL; Department of 
      General Surgery, University of Cape Town, WC, South Africa.
FAU - Jones, Bayley A
AU  - Jones BA
AD  - Department of Surgery, University of Alabama at Birmingham, AL; Department of 
      Surgery, University of Texas Southwestern Medical Center, Dallas, TX. Electronic 
      address: https://www.twitter.com/bayley_jones.
FAU - Hollis, Robert
AU  - Hollis R
AD  - Department of Surgery, University of Alabama at Birmingham, AL. Electronic 
      address: https://www.twitter.com/rhhollis.
FAU - Rubyan, Michael
AU  - Rubyan M
AD  - University of Michigan School of Public Health, Ann Arbor, MI.
FAU - Chu, Daniel I
AU  - Chu DI
AD  - Department of Surgery, University of Alabama at Birmingham, AL. Electronic 
      address: dchu@uabmc.edu.
LA  - eng
GR  - R01 CA271303/CA/NCI NIH HHS/United States
PT  - Comparative Study
PT  - Journal Article
DEP - 20250104
PL  - United States
TA  - Surgery
JT  - Surgery
JID - 0417347
SB  - IM
MH  - Humans
MH  - *Comprehension
MH  - *Patient Education as Topic/methods
MH  - Health Literacy
MH  - Colorectal Surgery/education
MH  - Teaching Materials/standards
MH  - Language
MH  - Reading
PMC - PMC11936715
MID - NIHMS2041208
COIS- Conflict of Interest/Disclosure The authors declare no conflicts of interest.
EDAT- 2025/01/06 10:07
MHDA- 2025/03/25 06:25
PMCR- 2026/04/01
CRDT- 2025/01/05 18:08
PHST- 2024/03/01 00:00 [received]
PHST- 2024/10/17 00:00 [revised]
PHST- 2024/11/29 00:00 [accepted]
PHST- 2026/04/01 00:00 [pmc-release]
PHST- 2025/03/25 06:25 [medline]
PHST- 2025/01/06 10:07 [pubmed]
PHST- 2025/01/05 18:08 [entrez]
AID - S0039-6060(24)01011-0 [pii]
AID - 10.1016/j.surg.2024.109024 [doi]
PST - ppublish
SO  - Surgery. 2025 Apr;180:109024. doi: 10.1016/j.surg.2024.109024. Epub 2025 Jan 4.

PMID- 39185518
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241023
DP  - 2024 Aug 31
TI  - CarD-T: Interpreting Carcinomic Lexicon via Transformers.
LID - 2024.08.13.24311948 [pii]
LID - 10.1101/2024.08.13.24311948 [doi]
AB  - The identification and classification of carcinogens is critical in cancer 
      epidemiology, necessitating updated methodologies to manage the burgeoning 
      biomedical literature. Current systems, like those run by the International 
      Agency for Research on Cancer (IARC) and the National Toxicology Program (NTP), 
      face challenges due to manual vetting and disparities in carcinogen 
      classification spurred by the volume of emerging data. To address these issues, 
      we introduced the Carcinogen Detection via Transformers (CarD-T) framework, a 
      text analytics approach that combines transformer-based machine learning with 
      probabilistic statistical analysis to efficiently nominate carcinogens from 
      scientific texts. CarD-T uses Named Entity Recognition (NER) trained on PubMed 
      abstracts featuring known carcinogens from IARC groups and includes a context 
      classifier to enhance accuracy and manage computational demands. Using this 
      method, journal publication data indexed with carcinogenicity & carcinogenesis 
      Medical Subject Headings (MeSH) terms from the last 25 years was analyzed, 
      identifying potential carcinogens. Training CarD-T on 60% of established 
      carcinogens (Group 1 and 2A carcinogens, IARC designation), CarD-T correctly to 
      identifies all of the remaining Group 1 and 2A designated carcinogens from the 
      analyzed text. In addition, CarD-T nominates roughly 1500 more entities as 
      potential carcinogens that have at least two publications citing evidence of 
      carcinogenicity. Comparative assessment of CarD-T against GPT-4 model reveals a 
      high recall (0.857 vs 0.705) and F1 score (0.875 vs 0.792), and comparable 
      precision (0.894 vs 0.903). Additionally, CarD-T highlights 554 entities that 
      show disputing evidence for carcinogenicity. These are further analyzed using 
      Bayesian temporal Probabilistic Carcinogenic Denomination (PCarD) to provide 
      probabilistic evaluations of their carcinogenic status based on evolving 
      evidence. Our findings underscore that the CarD-T framework is not only robust 
      and effective in identifying and nominating potential carcinogens within vast 
      biomedical literature but also efficient on consumer GPUs. This integration of 
      advanced NLP capabilities with vital epidemiological analysis significantly 
      enhances the agility of public health responses to carcinogen identification, 
      thereby setting a new benchmark for automated, scalable toxicological 
      investigations.
FAU - O'Neill, Jamey
AU  - O'Neill J
AD  - Mechanical Engineering Department, San Diego State University, San Diego, CA, 
      USA.
AD  - Department of Bioengineering, University of California San Diego, La Jolla, CA, 
      USA.
FAU - Reddy, Gudur Ashrith
AU  - Reddy GA
AD  - Mechanical Engineering Department, San Diego State University, San Diego, CA, 
      USA.
AD  - Department of Bioengineering, University of California San Diego, La Jolla, CA, 
      USA.
FAU - Dhillon, Nermeeta
AU  - Dhillon N
AD  - Mechanical Engineering Department, San Diego State University, San Diego, CA, 
      USA.
FAU - Tripathi, Osika
AU  - Tripathi O
AD  - Herbert Wertheim School of Public Health and Human Longevity Science, University 
      of California San Diego, La Jolla, CA, USA.
FAU - Alexandrov, Ludmil
AU  - Alexandrov L
AUID- ORCID: 0000-0003-3596-4515
AD  - Department of Bioengineering, University of California San Diego, La Jolla, CA, 
      USA.
AD  - Department of Cellular and Molecular Medicine, University of California San 
      Diego, La Jolla, CA, USA.
AD  - Moores Cancer Center, University of California San Diego, La Jolla, CA, USA.
AD  - Sanford Stem Cell Institute, University of California San Diego, La Jolla, CA, 
      USA.
FAU - Katira, Parag
AU  - Katira P
AUID- ORCID: 0000-0001-9873-5117
AD  - Mechanical Engineering Department, San Diego State University, San Diego, CA, 
      USA.
AD  - Computational Science Research Center, San Diego State University, San Diego, CA, 
      USA.
LA  - eng
GR  - U54 CA285117/CA/NCI NIH HHS/United States
GR  - U54 MD012397/MD/NIMHD NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240831
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
PMC - PMC11343268
OTO - NOTNLM
OT  - Bayesian analysis
OT  - Biomedical language models
OT  - Cancer epidemiology
OT  - Carcinogen identification
OT  - Named Entity Recognition
COIS- Competing Interests The authors declare that they have no competing interests.
EDAT- 2024/08/26 12:40
MHDA- 2024/08/26 12:41
PMCR- 2024/09/03
CRDT- 2024/08/26 05:20
PHST- 2024/08/26 12:40 [pubmed]
PHST- 2024/08/26 12:41 [medline]
PHST- 2024/08/26 05:20 [entrez]
PHST- 2024/09/03 00:00 [pmc-release]
AID - 2024.08.13.24311948 [pii]
AID - 10.1101/2024.08.13.24311948 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Aug 31:2024.08.13.24311948. doi: 
      10.1101/2024.08.13.24311948.

PMID- 38480700
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240325
IS  - 2373-8057 (Print)
IS  - 2373-8057 (Electronic)
IS  - 2373-8057 (Linking)
VI  - 10
IP  - 1
DP  - 2024 Mar 13
TI  - Disease progression strikingly differs in research and real-world Parkinson's 
      populations.
PG  - 58
LID - 10.1038/s41531-024-00667-5 [doi]
LID - 58
AB  - Characterization of Parkinson's disease (PD) progression using real-world 
      evidence could guide clinical trial design and identify subpopulations. Efforts 
      to curate research populations, the increasing availability of real-world data, 
      and advances in natural language processing, particularly large language models, 
      allow for a more granular comparison of populations than previously possible. 
      This study includes two research populations and two real-world data-derived 
      (RWD) populations. The research populations are the Harvard Biomarkers Study 
      (HBS, N = 935), a longitudinal biomarkers cohort study with in-person structured 
      study visits; and Fox Insights (N = 36,660), an online self-survey-based research 
      study of the Michael J. Fox Foundation. Real-world cohorts are the Optum 
      Integrated Claims-electronic health records (N = 157,475), representing 
      wide-scale linked medical and claims data and de-identified data from Mass 
      General Brigham (MGB, N = 22,949), an academic hospital system. Structured, 
      de-identified electronic health records data at MGB are supplemented using a 
      manually validated natural language processing with a large language model to 
      extract measurements of PD progression. Motor and cognitive progression scores 
      change more rapidly in MGB than HBS (median survival until H&Y 3: 5.6 years vs. 
      >10, p < 0.001; mini-mental state exam median decline 0.28 vs. 0.11, p < 0.001; 
      and clinically recognized cognitive decline, p = 0.001). In real-world 
      populations, patients are diagnosed more than eleven years later (RWD mean of 
      72.2 vs. research mean of 60.4, p < 0.001). After diagnosis, in real-world 
      cohorts, treatment with PD medications has initiated an average of 2.3 years 
      later (95% CI: [2.1-2.4]; p < 0.001). This study provides a detailed 
      characterization of Parkinson's progression in diverse populations. It delineates 
      systemic divergences in the patient populations enrolled in research settings vs. 
      patients in the real-world. These divergences are likely due to a combination of 
      selection bias and real population differences, but exact attribution of the 
      causes is challenging. This study emphasizes a need to utilize multiple data 
      sources and to diligently consider potential biases when planning, choosing data 
      sources, and performing downstream tasks and analyses.
CI  - © 2024. The Author(s).
FAU - Beaulieu-Jones, Brett K
AU  - Beaulieu-Jones BK
AUID- ORCID: 0000-0002-6700-1468
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA, 02115, 
      USA. beaulieujones@uchicago.edu.
AD  - APDA Center for Advanced Parkinson Research of Harvard Medical School and Brigham 
      and Women's Hospital, Boston, MA, 02115, USA. beaulieujones@uchicago.edu.
AD  - Precision Neurology Program of Brigham & Women's Hospital, Harvard Medical 
      School, Boston, MA, 02115, USA. beaulieujones@uchicago.edu.
AD  - Department of Medicine, University of Chicago, Chicago, IL, 60615, USA. 
      beaulieujones@uchicago.edu.
AD  - Aligning Science Across Parkinson's (ASAP) Collaborative Research Network, Chevy 
      Chase, MD, 20815, USA. beaulieujones@uchicago.edu.
FAU - Frau, Francesca
AU  - Frau F
AD  - Sanofi R&D, Data and Data Science, Frankfurt, Germany.
FAU - Bozzi, Sylvie
AU  - Bozzi S
AD  - Sanofi Health Economics and Value Assessment, Sanofi, Paris, France.
FAU - Chandross, Karen J
AU  - Chandross KJ
AUID- ORCID: 0000-0002-1346-2162
AD  - Sanofi R&D, Bridgewater, NJ, USA.
FAU - Peterschmitt, M Judith
AU  - Peterschmitt MJ
AD  - Sanofi Genzyme, Clinical Development Neurology, Cambridge, MA, USA.
FAU - Cohen, Caroline
AU  - Cohen C
AD  - Sanofi R&D, Paris, France.
FAU - Coulovrat, Catherine
AU  - Coulovrat C
AD  - Sanofi Translational Sciences, Framingham, MA, 01701, USA.
FAU - Kumar, Dinesh
AU  - Kumar D
AD  - Sanofi Translational Sciences, Framingham, MA, 01701, USA.
FAU - Kruger, Mark J
AU  - Kruger MJ
AD  - Sanofi Genzyme, Clinical Development Neurology, Cambridge, MA, USA.
FAU - Lipnick, Scott L
AU  - Lipnick SL
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA, 02115, 
      USA.
FAU - Fitzsimmons, Lane
AU  - Fitzsimmons L
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA, 02115, 
      USA.
FAU - Kohane, Isaac S
AU  - Kohane IS
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA, 02115, 
      USA.
FAU - Scherzer, Clemens R
AU  - Scherzer CR
AUID- ORCID: 0000-0002-0567-9193
AD  - APDA Center for Advanced Parkinson Research of Harvard Medical School and Brigham 
      and Women's Hospital, Boston, MA, 02115, USA. clemens.scherzer@yale.edu.
AD  - Precision Neurology Program of Brigham & Women's Hospital, Harvard Medical 
      School, Boston, MA, 02115, USA. clemens.scherzer@yale.edu.
AD  - Aligning Science Across Parkinson's (ASAP) Collaborative Research Network, Chevy 
      Chase, MD, 20815, USA. clemens.scherzer@yale.edu.
LA  - eng
GR  - U01 NS100603/NS/NINDS NIH HHS/United States
GR  - R00 NS114850/NS/NINDS NIH HHS/United States
GR  - U01 NS095736/NS/NINDS NIH HHS/United States
GR  - R01 NS115144/NS/NINDS NIH HHS/United States
GR  - K99 NS114850/NS/NINDS NIH HHS/United States
PT  - Journal Article
DEP - 20240313
PL  - United States
TA  - NPJ Parkinsons Dis
JT  - NPJ Parkinson's disease
JID - 101675390
UOF - medRxiv. 2024 Feb 18:2024.02.17.24302981. doi: 10.1101/2024.02.17.24302981. PMID: 
      38405736
PMC - PMC10937726
COIS- F.F., S.B., K.J.C., M.J.P., C.C., D.K., and C.C. are employees of Sanofi and may 
      hold shares and/or stock options in the company. All authors declare no other 
      competing financial or non-financial interests.
EDAT- 2024/03/14 06:46
MHDA- 2024/03/14 06:47
PMCR- 2024/03/13
CRDT- 2024/03/14 00:54
PHST- 2023/06/11 00:00 [received]
PHST- 2024/02/23 00:00 [accepted]
PHST- 2024/03/14 06:47 [medline]
PHST- 2024/03/14 06:46 [pubmed]
PHST- 2024/03/14 00:54 [entrez]
PHST- 2024/03/13 00:00 [pmc-release]
AID - 10.1038/s41531-024-00667-5 [pii]
AID - 667 [pii]
AID - 10.1038/s41531-024-00667-5 [doi]
PST - epublish
SO  - NPJ Parkinsons Dis. 2024 Mar 13;10(1):58. doi: 10.1038/s41531-024-00667-5.

PMID- 38405736
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240325
DP  - 2024 Feb 18
TI  - Disease progression strikingly differs in research and real-world Parkinson's 
      populations.
LID - 2024.02.17.24302981 [pii]
LID - 10.1101/2024.02.17.24302981 [doi]
AB  - Characterization of Parkinson's disease (PD) progression using real-world 
      evidence could guide clinical trial design and identify subpopulations. Efforts 
      to curate research populations, the increasing availability of real-world data 
      and recent advances in natural language processing, particularly large language 
      models, allow for a more granular comparison of populations and the methods of 
      data collection describing these populations than previously possible. This study 
      includes two research populations and two real-world data derived (RWD) 
      populations. The research populations are the Harvard Biomarkers Study (HBS, N = 
      935), a longitudinal biomarkers cohort study with in-person structured study 
      visits; and Fox Insights (N = 36,660), an online self-survey-based research study 
      of the Michael J. Fox Foundation. Real-world cohorts are the Optum Integrated 
      Claims-electronic health records (N = 157,475), representing wide-scale linked 
      medical and claims data and de-identified data from Mass General Brigham (MGB, N 
      = 22,949), an academic hospital system. Structured, de-identified electronic 
      health records data at MGB are supplemented using natural language processing 
      with a large language model to extract measurements of PD progression. This 
      extraction process is manually validated for accuracy. Motor and cognitive 
      progression scores change more rapidly in MGB than HBS (median survival until H&Y 
      3: 5.6 years vs. >10, p<0.001; mini-mental state exam median decline 0.28 vs. 
      0.11, p<0.001; and clinically recognized cognitive decline, p=0.001). In the 
      real-world populations, patients are diagnosed more than eleven years later (RWD 
      mean of 72.2 vs. research mean of 60.4, p<0.001). After diagnosis, in real-world 
      cohorts, treatment with PD medications is initiated 2.3 years later on average 
      (95% CI: [2.1-2.4]; p<0.001). This study provides a detailed characterization of 
      Parkinson's progression in diverse populations. It delineates systemic 
      divergences in the patient populations enrolled in research settings vs. patients 
      in the real world. These divergences are likely due to a combination of selection 
      bias and real population differences, but exact attribution of the causes is 
      challenging using existing data. This study emphasizes a need to utilize multiple 
      data sources and to diligently consider potential biases when planning, choosing 
      data sources, and performing downstream tasks and analyses.
FAU - Beaulieu-Jones, Brett K
AU  - Beaulieu-Jones BK
AUID- ORCID: 0000-0002-6700-1468
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA 02115, 
      USA.
AD  - APDA Center for Advanced Parkinson Research of Harvard Medical School and Brigham 
      and Women's Hospital, Boston, MA 02115, USA.
AD  - Precision Neurology Program of Brigham & Women's Hospital, Harvard Medical 
      School, Boston, MA 02115, USA.
AD  - Department of Medicine, University of Chicago, Chicago, IL 60615 USA.
AD  - Aligning Science Across Parkinson's (ASAP) Collaborative Research Network, Chevy 
      Chase MD, 20815.
FAU - Frau, Francesca
AU  - Frau F
AD  - Sanofi R&D, Data and Data Science, Frankfurt, Germany.
FAU - Bozzi, Sylvie
AU  - Bozzi S
AD  - Sanofi Health Economics and Value Assessment, Sanofi, Paris, France.
FAU - Chandross, Karen J
AU  - Chandross KJ
AD  - Sanofi R&D, Bridgewater, NJ, United States.
FAU - Peterschmitt, M Judith
AU  - Peterschmitt MJ
AD  - Sanofi Genzyme, Clinical Development Neurology, Cambridge, MA, United States.
FAU - Cohen, Caroline
AU  - Cohen C
AD  - Sanofi R&D, Paris, France.
FAU - Coulovrat, Catherine
AU  - Coulovrat C
AD  - Sanofi Translational Sciences, Framingham, 01701 USA.
FAU - Kumar, Dinesh
AU  - Kumar D
AD  - Sanofi Translational Sciences, Framingham, 01701 USA.
FAU - Kruger, Mark J
AU  - Kruger MJ
AD  - Sanofi Genzyme, Clinical Development Neurology, Cambridge, MA, United States.
FAU - Lipnick, Scott L
AU  - Lipnick SL
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA 02115, 
      USA.
FAU - Fitzsimmons, Lane
AU  - Fitzsimmons L
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA 02115, 
      USA.
FAU - Kohane, Isaac S
AU  - Kohane IS
AD  - Department of Biomedical Informatics, Harvard Medical School, Boston, MA 02115, 
      USA.
FAU - Scherzer, Clemens R
AU  - Scherzer CR
AD  - APDA Center for Advanced Parkinson Research of Harvard Medical School and Brigham 
      and Women's Hospital, Boston, MA 02115, USA.
AD  - Precision Neurology Program of Brigham & Women's Hospital, Harvard Medical 
      School, Boston, MA 02115, USA.
AD  - Aligning Science Across Parkinson's (ASAP) Collaborative Research Network, Chevy 
      Chase MD, 20815.
LA  - eng
GR  - U01 NS100603/NS/NINDS NIH HHS/United States
GR  - R00 NS114850/NS/NINDS NIH HHS/United States
GR  - U01 NS095736/NS/NINDS NIH HHS/United States
GR  - R01 NS115144/NS/NINDS NIH HHS/United States
GR  - K99 NS114850/NS/NINDS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240218
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - NPJ Parkinsons Dis. 2024 Mar 13;10(1):58. doi: 10.1038/s41531-024-00667-5. PMID: 
      38480700
PMC - PMC10889035
COIS- Competing Interest FF, SB, KJC, MJP, CC, DK, CC are employees of Sanofi and may 
      hold shares and/or stock options in the company. All authors declare no other 
      competing financial or non-financial interests.
EDAT- 2024/02/26 06:42
MHDA- 2024/02/26 06:43
PMCR- 2024/02/23
CRDT- 2024/02/26 04:48
PHST- 2024/02/26 06:42 [pubmed]
PHST- 2024/02/26 06:43 [medline]
PHST- 2024/02/26 04:48 [entrez]
PHST- 2024/02/23 00:00 [pmc-release]
AID - 2024.02.17.24302981 [pii]
AID - 10.1101/2024.02.17.24302981 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Feb 18:2024.02.17.24302981. doi: 
      10.1101/2024.02.17.24302981.

PMID- 38252483
OWN - NLM
STAT- MEDLINE
DCOM- 20240123
LR  - 20240227
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 26
DP  - 2024 Jan 22
TI  - Uncovering Language Disparity of ChatGPT on Retinal Vascular Disease 
      Classification: Cross-Sectional Study.
PG  - e51926
LID - 10.2196/51926 [doi]
LID - e51926
AB  - BACKGROUND: Benefiting from rich knowledge and the exceptional ability to 
      understand text, large language models like ChatGPT have shown great potential in 
      English clinical environments. However, the performance of ChatGPT in non-English 
      clinical settings, as well as its reasoning, have not been explored in depth. 
      OBJECTIVE: This study aimed to evaluate ChatGPT's diagnostic performance and 
      inference abilities for retinal vascular diseases in a non-English clinical 
      environment. METHODS: In this cross-sectional study, we collected 1226 fundus 
      fluorescein angiography reports and corresponding diagnoses written in Chinese 
      and tested ChatGPT with 4 prompting strategies (direct diagnosis or diagnosis 
      with a step-by-step reasoning process and in Chinese or English). RESULTS: 
      Compared with ChatGPT using Chinese prompts for direct diagnosis that achieved an 
      F(1)-score of 70.47%, ChatGPT using English prompts for direct diagnosis achieved 
      the best diagnostic performance (80.05%), which was inferior to ophthalmologists 
      (89.35%) but close to ophthalmologist interns (82.69%). As for its inference 
      abilities, although ChatGPT can derive a reasoning process with a low error rate 
      (0.4 per report) for both Chinese and English prompts, ophthalmologists 
      identified that the latter brought more reasoning steps with less incompleteness 
      (44.31%), misinformation (1.96%), and hallucinations (0.59%) (all P<.001). Also, 
      analysis of the robustness of ChatGPT with different language prompts indicated 
      significant differences in the recall (P=.03) and F(1)-score (P=.04) between 
      Chinese and English prompts. In short, when prompted in English, ChatGPT 
      exhibited enhanced diagnostic and inference capabilities for retinal vascular 
      disease classification based on Chinese fundus fluorescein angiography reports. 
      CONCLUSIONS: ChatGPT can serve as a helpful medical assistant to provide 
      diagnosis in non-English clinical environments, but there are still performance 
      gaps, language disparities, and errors compared to professionals, which 
      demonstrate the potential limitations and the need to continually explore more 
      robust large language models in ophthalmology practice.
CI  - ©Xiaocong Liu, Jiageng Wu, An Shao, Wenyue Shen, Panpan Ye, Yao Wang, Juan Ye, 
      Kai Jin, Jie Yang. Originally published in the Journal of Medical Internet 
      Research (https://www.jmir.org), 22.01.2024.
FAU - Liu, Xiaocong
AU  - Liu X
AUID- ORCID: 0000-0001-5323-2954
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
AD  - School of Public Health, Zhejiang University School of Medicine, Zhejiang, China.
FAU - Wu, Jiageng
AU  - Wu J
AUID- ORCID: 0000-0003-0984-0818
AD  - School of Public Health, Zhejiang University School of Medicine, Zhejiang, China.
FAU - Shao, An
AU  - Shao A
AUID- ORCID: 0000-0002-1795-4877
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Shen, Wenyue
AU  - Shen W
AUID- ORCID: 0000-0002-1352-9419
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Ye, Panpan
AU  - Ye P
AUID- ORCID: 0000-0001-8165-023X
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Wang, Yao
AU  - Wang Y
AUID- ORCID: 0000-0002-7258-6093
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Ye, Juan
AU  - Ye J
AUID- ORCID: 0000-0002-1948-2500
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Jin, Kai
AU  - Jin K
AUID- ORCID: 0000-0003-4369-2417
AD  - Eye Center, The Second Affiliated Hospital, Zhejiang University, Zhejiang, China.
FAU - Yang, Jie
AU  - Yang J
AUID- ORCID: 0000-0001-5696-363X
AD  - School of Public Health, Zhejiang University School of Medicine, Zhejiang, China.
LA  - eng
PT  - Journal Article
DEP - 20240122
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Language
MH  - *Vascular Diseases/classification/diagnosis/diagnostic imaging
MH  - *Retinal Diseases/classification/diagnosis/diagnostic imaging
MH  - *Artificial Intelligence
MH  - *Fluorescein Angiography
MH  - *Diagnostic Errors
PMC - PMC10845019
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - clinical decision support
OT  - large language models
OT  - retinal vascular disease
COIS- Conflicts of Interest: None declared.
EDAT- 2024/01/22 12:42
MHDA- 2024/01/23 06:43
PMCR- 2024/01/22
CRDT- 2024/01/22 11:54
PHST- 2023/08/17 00:00 [received]
PHST- 2023/11/30 00:00 [accepted]
PHST- 2023/10/07 00:00 [revised]
PHST- 2024/01/23 06:43 [medline]
PHST- 2024/01/22 12:42 [pubmed]
PHST- 2024/01/22 11:54 [entrez]
PHST- 2024/01/22 00:00 [pmc-release]
AID - v26i1e51926 [pii]
AID - 10.2196/51926 [doi]
PST - epublish
SO  - J Med Internet Res. 2024 Jan 22;26:e51926. doi: 10.2196/51926.

PMID- 30676951
OWN - NLM
STAT- MEDLINE
DCOM- 20200525
LR  - 20200525
IS  - 1558-254X (Electronic)
IS  - 0278-0062 (Linking)
VI  - 38
IP  - 9
DP  - 2019 Sep
TI  - A Universal Intensity Standardization Method Based on a Many-to-One Weak-Paired 
      Cycle Generative Adversarial Network for Magnetic Resonance Images.
PG  - 2059-2069
LID - 10.1109/TMI.2019.2894692 [doi]
AB  - In magnetic resonance imaging (MRI), different imaging settings lead to various 
      intensity distributions for a specific imaging object, which brings huge 
      diversity to data-driven medical applications. To standardize the intensity 
      distribution of magnetic resonance (MR) images from multiple centers and multiple 
      machines using one model, a cycle generative adversarial network (CycleGAN)-based 
      framework is proposed. It utilizes a unified forward generative adversarial 
      network (GAN) path and multiple independent backward GAN paths to transform 
      images in different groups into a single reference one. To preserve image details 
      and prevent resolution loss, two jump connections are applied in the CycleGAN 
      generators. A weak-pair strategy is designed to fully utilize the prior knowledge 
      of the organ structure and promote the performance of the GANs. The experiments 
      were conducted on a T2-FLAIR image database with 8192 slices from 489 patients. 
      The database was obtained from four hospitals and five MRI scanners and was 
      divided into nine groups with different imaging parameters. Compared with the 
      representative algorithms, the peak signal-to-noise ratio, the histogram 
      correlation, and the structural similarity were increased by 3.7%, 5.1%, and 0.1% 
      on average, respectively; the gradient magnitude similarity deviation, the mean 
      square error, and the average disparity were reduced by 19.0%, 15.7%, and 9.9% on 
      average, respectively. Experiments also showed the robustness of the proposed 
      model with a different training set configuration and effectiveness of the 
      proposed framework over the original CycleGAN. Therefore, the MR images with 
      different imaging settings could be efficiently standardized by the proposed 
      method, which would benefit various data-driven applications.
FAU - Gao, Yuan
AU  - Gao Y
FAU - Liu, Yingchao
AU  - Liu Y
FAU - Wang, Yuanyuan
AU  - Wang Y
FAU - Shi, Zhifeng
AU  - Shi Z
FAU - Yu, Jinhua
AU  - Yu J
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20190124
PL  - United States
TA  - IEEE Trans Med Imaging
JT  - IEEE transactions on medical imaging
JID - 8310780
SB  - IM
MH  - Algorithms
MH  - Brain/diagnostic imaging
MH  - Databases, Factual
MH  - Humans
MH  - Image Processing, Computer-Assisted/*methods
MH  - Machine Learning
MH  - Magnetic Resonance Imaging/*methods
MH  - Signal-To-Noise Ratio
EDAT- 2019/01/25 06:00
MHDA- 2020/05/26 06:00
CRDT- 2019/01/25 06:00
PHST- 2019/01/25 06:00 [pubmed]
PHST- 2020/05/26 06:00 [medline]
PHST- 2019/01/25 06:00 [entrez]
AID - 10.1109/TMI.2019.2894692 [doi]
PST - ppublish
SO  - IEEE Trans Med Imaging. 2019 Sep;38(9):2059-2069. doi: 10.1109/TMI.2019.2894692. 
      Epub 2019 Jan 24.

PMID- 37336830
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230705
IS  - 1869-4101 (Print)
IS  - 1869-4101 (Electronic)
IS  - 1869-4101 (Linking)
VI  - 14
IP  - 1
DP  - 2023 Jun 19
TI  - An overview of meta-analyses on radiomics: more evidence is needed to support 
      clinical translation.
PG  - 111
LID - 10.1186/s13244-023-01437-2 [doi]
LID - 111
AB  - OBJECTIVE: To conduct an overview of meta-analyses of radiomics studies assessing 
      their study quality and evidence level. METHODS: A systematical search was 
      updated via peer-reviewed electronic databases, preprint servers, and systematic 
      review protocol registers until 15 November 2022. Systematic reviews with 
      meta-analysis of primary radiomics studies were included. Their reporting 
      transparency, methodological quality, and risk of bias were assessed by PRISMA 
      (Preferred Reporting Items for Systematic reviews and Meta-Analyses) 2020 
      checklist, AMSTAR-2 (A MeaSurement Tool to Assess systematic Reviews, version 2) 
      tool, and ROBIS (Risk Of Bias In Systematic reviews) tool, respectively. The 
      evidence level supporting the radiomics for clinical use was rated. RESULTS: We 
      identified 44 systematic reviews with meta-analyses on radiomics research. The 
      mean ± standard deviation of PRISMA adherence rate was 65 ± 9%. The AMSTAR-2 tool 
      rated 5 and 39 systematic reviews as low and critically low confidence, 
      respectively. The ROBIS assessment resulted low, unclear and high risk in 5, 11, 
      and 28 systematic reviews, respectively. We reperformed 53 meta-analyses in 38 
      included systematic reviews. There were 3, 7, and 43 meta-analyses rated as 
      convincing, highly suggestive, and weak levels of evidence, respectively. The 
      convincing level of evidence was rated in (1) T2-FLAIR radiomics for IDH-mutant 
      vs IDH-wide type differentiation in low-grade glioma, (2) CT radiomics for 
      COVID-19 vs other viral pneumonia differentiation, and (3) MRI radiomics for 
      high-grade glioma vs brain metastasis differentiation. CONCLUSIONS: The 
      systematic reviews on radiomics were with suboptimal quality. A limited number of 
      radiomics approaches were supported by convincing level of evidence. CLINICAL 
      RELEVANCE STATEMENT: The evidence supporting the clinical application of 
      radiomics are insufficient, calling for researches translating radiomics from an 
      academic tool to a practicable adjunct towards clinical deployment.
CI  - © 2023. The Author(s).
FAU - Zhong, Jingyu
AU  - Zhong J
AD  - Department of Imaging, Tongren Hospital, Shanghai Jiao Tong University School of 
      Medicine, Shanghai, 200336, China.
FAU - Lu, Junjie
AU  - Lu J
AD  - Department of Social and Behavioral Sciences, Harvard T.H. Chan School of Public 
      Health, Boston, MA, 02115, USA.
FAU - Zhang, Guangcheng
AU  - Zhang G
AD  - Department of Orthopedics, Shanghai Sixth People's Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, 200233, China.
FAU - Mao, Shiqi
AU  - Mao S
AD  - Department of Medical Oncology, Shanghai Pulmonary Hospital, Tongji University 
      School of Medicine, Shanghai, 200433, China.
FAU - Chen, Haoda
AU  - Chen H
AD  - Department of General Surgery, Pancreatic Disease Center, Ruijin Hospital, 
      Shanghai Jiao Tong University School of Medicine, Shanghai, 200025, China.
FAU - Yin, Qian
AU  - Yin Q
AD  - Department of Pathology, Shanghai Sixth People's Hospital, Shanghai Jiao Tong 
      University School of Medicine, Shanghai, 200233, China.
FAU - Hu, Yangfan
AU  - Hu Y
AD  - Department of Imaging, Tongren Hospital, Shanghai Jiao Tong University School of 
      Medicine, Shanghai, 200336, China.
FAU - Xing, Yue
AU  - Xing Y
AD  - Department of Imaging, Tongren Hospital, Shanghai Jiao Tong University School of 
      Medicine, Shanghai, 200336, China.
FAU - Ding, Defang
AU  - Ding D
AD  - Department of Imaging, Tongren Hospital, Shanghai Jiao Tong University School of 
      Medicine, Shanghai, 200336, China.
FAU - Ge, Xiang
AU  - Ge X
AD  - Department of Imaging, Tongren Hospital, Shanghai Jiao Tong University School of 
      Medicine, Shanghai, 200336, China.
FAU - Zhang, Huan
AU  - Zhang H
AD  - Department of Radiology, Ruijin Hospital, Shanghai Jiao Tong University School of 
      Medicine, Shanghai, 200025, China. huanzhangy@163.com.
FAU - Yao, Weiwu
AU  - Yao W
AUID- ORCID: 0000-0002-6612-8520
AD  - Department of Imaging, Tongren Hospital, Shanghai Jiao Tong University School of 
      Medicine, Shanghai, 200336, China. yaoweiwuhuan@163.com.
LA  - eng
GR  - 82271934/National Natural Science Foundation of China/
GR  - 22YF1442400/Yangfan Project of Science and Technology Commission of Shanghai 
      Municipality/
GR  - 18411953000/Shanghai Science and Technology Commission Science and Technology 
      Innovation Action Clinical Innovation Field/
GR  - YG2019ZDB09/Medicine and Engineering Combination Project of Shanghai Jiao Tong 
      University/
GR  - TRKYRC-XX202204/Research Fund of Tongren Hospital, Shanghai Jiao Tong University 
      School of Medicine/
GR  - TRYJ2021JC06/Research Fund of Tongren Hospital, Shanghai Jiao Tong University 
      School of Medicine/
GR  - TRGG202101/Research Fund of Tongren Hospital, Shanghai Jiao Tong University 
      School of Medicine/
GR  - 2020TRYJ(LB)06/Research Fund of Tongren Hospital, Shanghai Jiao Tong University 
      School of Medicine/
GR  - 2020TRYJ(JC)07/Research Fund of Tongren Hospital, Shanghai Jiao Tong University 
      School of Medicine/
PT  - Journal Article
DEP - 20230619
PL  - Germany
TA  - Insights Imaging
JT  - Insights into imaging
JID - 101532453
PMC - PMC10279606
OTO - NOTNLM
OT  - Meta-analysis
OT  - Quality improvement
OT  - Radiomics
OT  - Systematic review
COIS- The authors declare that they have no competing interests.
EDAT- 2023/06/20 01:09
MHDA- 2023/06/20 01:10
PMCR- 2023/06/19
CRDT- 2023/06/19 23:04
PHST- 2023/01/13 00:00 [received]
PHST- 2023/04/14 00:00 [accepted]
PHST- 2023/06/20 01:10 [medline]
PHST- 2023/06/20 01:09 [pubmed]
PHST- 2023/06/19 23:04 [entrez]
PHST- 2023/06/19 00:00 [pmc-release]
AID - 10.1186/s13244-023-01437-2 [pii]
AID - 1437 [pii]
AID - 10.1186/s13244-023-01437-2 [doi]
PST - epublish
SO  - Insights Imaging. 2023 Jun 19;14(1):111. doi: 10.1186/s13244-023-01437-2.

PMID- 35075670
OWN - NLM
STAT- MEDLINE
DCOM- 20220310
LR  - 20220311
IS  - 2473-4209 (Electronic)
IS  - 0094-2405 (Linking)
VI  - 49
IP  - 3
DP  - 2022 Mar
TI  - Toward MR-only proton therapy planning for pediatric brain tumors: Synthesis of 
      relative proton stopping power images with multiple sequence MRI and development 
      of an online quality assurance tool.
PG  - 1559-1570
LID - 10.1002/mp.15479 [doi]
AB  - PURPOSE: To generate synthetic relative proton stopping power (sRPSP) images from 
      magnetic resonance imaging (MRI) sequence(s) and develop an online quality 
      assurance (QA) tool for sRPSP to facilitate safe integration of magnetic 
      resonance (MR)-only proton planning into clinical practice. MATERIALS AND 
      METHODS: Planning computed tomography (CT) and MR images of 195 pediatric brain 
      tumor patients were utilized (training: 150, testing: 45). Seventeen 
      consistent-cycle generative adversarial network (ccGAN) models were trained 
      separately using paired CT-converted RPSP and MRI datasets to transform a 
      subject's MRI into sRPSP. T1-weighted (T1W), T2-weighted (T2W), and FLAIR MRI 
      were permutated to form 17 combinations, with or without preprocessing, for 
      determining the optimal training sequence(s). For evaluation, sRPSP images were 
      converted to synthetic CT (sCT) and compared to the real CT in terms of mean 
      absolute error (MAE) in Hounsfield units (HU). For QA, sCT was deformed and 
      compared to a reference template built from training dataset to produce a flag 
      map, highlighting pixels that deviate by >100 HU and fall outside the 
      mean ± standard deviation reference intensity. The gamma intensity analysis 
      (10%/3 mm) of the deformed sCT against the QA template on the intensity 
      difference was investigated as a surrogate of sCT accuracy. RESULTS: The sRPSP 
      images generated from a single T1W or T2W sequence outperformed that generated 
      from multi-MRI sequences in terms of MAE (all p < 0.05). Preprocessing with N4 
      bias and histogram matching reduced MAE of T2W MRI-based sCT (54 ± 21 HU vs. 
      42 ± 13 HU, p = 0.002). The gamma intensity analysis of sCT against the QA 
      template was highly correlated with the MAE of sCT against the real CT in the 
      testing cohort (r = -0.89 for T1W sCT; r = -0.93 for T2W sCT). CONCLUSION: 
      Accurate sRPSP images can be generated from T1W/T2W MRI for proton planning. A QA 
      tool highlights regions of inaccuracy, flagging problematic cases unsuitable for 
      clinical use.
CI  - © 2022 American Association of Physicists in Medicine.
FAU - Wang, Chuang
AU  - Wang C
AD  - Department of Radiation Oncology, St. Jude Children's Research Hospital, Memphis, 
      Tennessee, USA.
FAU - Uh, Jinsoo
AU  - Uh J
AD  - Department of Radiation Oncology, St. Jude Children's Research Hospital, Memphis, 
      Tennessee, USA.
FAU - Patni, Tushar
AU  - Patni T
AD  - Department of Biostatistics, St. Jude Children's Research Hospital, Memphis, 
      Tennessee, USA.
FAU - Merchant, Thomas
AU  - Merchant T
AD  - Department of Radiation Oncology, St. Jude Children's Research Hospital, Memphis, 
      Tennessee, USA.
FAU - Li, Yimei
AU  - Li Y
AD  - Department of Biostatistics, St. Jude Children's Research Hospital, Memphis, 
      Tennessee, USA.
FAU - Hua, Chia-Ho
AU  - Hua CH
AD  - Department of Radiation Oncology, St. Jude Children's Research Hospital, Memphis, 
      Tennessee, USA.
FAU - Acharya, Sahaja
AU  - Acharya S
AD  - Department of Radiation Oncology, St. Jude Children's Research Hospital, Memphis, 
      Tennessee, USA.
AD  - Department of Radiation Oncology and Molecular Radiation Sciences, Johns Hopkins 
      Medicine, Baltimore, Maryland, USA.
LA  - eng
PT  - Journal Article
DEP - 20220211
PL  - United States
TA  - Med Phys
JT  - Medical physics
JID - 0425746
RN  - 0 (Protons)
SB  - IM
MH  - *Brain Neoplasms/diagnostic imaging/radiotherapy
MH  - Child
MH  - Humans
MH  - Magnetic Resonance Imaging/methods
MH  - Magnetic Resonance Spectroscopy
MH  - *Proton Therapy/methods
MH  - Protons
MH  - Radiotherapy Dosage
MH  - Radiotherapy Planning, Computer-Assisted/methods
OTO - NOTNLM
OT  - MRI sequence
OT  - deep learning
OT  - proton stopping power
OT  - proton therapy
OT  - synthetic CT
EDAT- 2022/01/26 06:00
MHDA- 2022/03/11 06:00
CRDT- 2022/01/25 05:52
PHST- 2021/12/23 00:00 [revised]
PHST- 2021/10/22 00:00 [received]
PHST- 2022/01/11 00:00 [accepted]
PHST- 2022/01/26 06:00 [pubmed]
PHST- 2022/03/11 06:00 [medline]
PHST- 2022/01/25 05:52 [entrez]
AID - 10.1002/mp.15479 [doi]
PST - ppublish
SO  - Med Phys. 2022 Mar;49(3):1559-1570. doi: 10.1002/mp.15479. Epub 2022 Feb 11.

PMID- 38584142
OWN - NLM
STAT- MEDLINE
DCOM- 20240409
LR  - 20240410
IS  - 1525-6049 (Electronic)
IS  - 0886-022X (Print)
IS  - 0886-022X (Linking)
VI  - 46
IP  - 1
DP  - 2024 Dec
TI  - Perspectives on AI-based recommendations for mask-wearing and COVID-19 
      vaccination for transplant recipients in the post-COVID-19 era.
PG  - 2337291
LID - 10.1080/0886022X.2024.2337291 [doi]
LID - 2337291
AB  - In the aftermath of the COVID-19 pandemic, the ongoing necessity for preventive 
      measures such as mask-wearing and vaccination remains particularly critical for 
      organ transplant recipients, a group highly susceptible to infections due to 
      immunosuppressive therapy. Given that many individuals nowadays increasingly 
      utilize Artificial Intelligence (AI), understanding AI perspectives is important. 
      Thus, this study utilizes AI, specifically ChatGPT 4.0, to assess its 
      perspectives in offering precise health recommendations for mask-wearing and 
      COVID-19 vaccination tailored to this vulnerable population. Through a series of 
      scenarios reflecting diverse environmental settings and health statuses in 
      December 2023, we evaluated the AI's responses to gauge its precision, 
      adaptability, and potential biases in advising high-risk patient groups. Our 
      findings reveal that ChatGPT 4.0 consistently recommends mask-wearing in crowded 
      and indoor environments for transplant recipients, underscoring their elevated 
      risk. In contrast, for settings with fewer transmission risks, such as outdoor 
      areas where social distancing is possible, the AI suggests that mask-wearing 
      might be less imperative. Regarding vaccination guidance, the AI strongly 
      advocates for the COVID-19 vaccine across most scenarios for kidney transplant 
      recipients. However, it recommends a personalized consultation with healthcare 
      providers in cases where patients express concerns about vaccine-related side 
      effects, demonstrating an ability to adapt recommendations based on individual 
      health considerations. While this study provides valuable insights into the 
      current AI perspective on these important topics, it is crucial to note that the 
      findings do not directly reflect or influence health policy. Nevertheless, given 
      the increasing utilization of AI in various domains, understanding AI's 
      viewpoints on such critical matters is essential for informed decision-making and 
      future research.
FAU - Garcia Valencia, Oscar A
AU  - Garcia Valencia OA
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Miao, Jing
AU  - Miao J
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Bruminhent, Jackrapong
AU  - Bruminhent J
AD  - Department of Medicine, Division of Infectious Diseases, Faculty of Medicine 
      Ramathibodi Hospital, Mahidol University, Bangkok, Thailand.
AD  - Ramathibodi Excellence Center for Organ Transplantation, Faculty of Medicine 
      Ramathibodi Hospital, Mahidol University, Bangkok, Thailand.
FAU - Craici, Iasmina M
AU  - Craici IM
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, MN, USA.
LA  - eng
PT  - Journal Article
DEP - 20240407
PL  - England
TA  - Ren Fail
JT  - Renal failure
JID - 8701128
RN  - 0 (COVID-19 Vaccines)
SB  - IM
MH  - Humans
MH  - *COVID-19/epidemiology/prevention & control
MH  - COVID-19 Vaccines
MH  - Transplant Recipients
MH  - Artificial Intelligence
MH  - Pandemics/prevention & control
MH  - Vaccination
PMC - PMC11000603
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Mask-Wearing recommendations
OT  - covid-19
OT  - transplant recipients
OT  - vaccine guidance
COIS- No potential conflict of interest was reported by the author(s).
EDAT- 2024/04/08 00:42
MHDA- 2024/04/09 06:45
PMCR- 2024/04/07
CRDT- 2024/04/07 22:34
PHST- 2024/04/09 06:45 [medline]
PHST- 2024/04/08 00:42 [pubmed]
PHST- 2024/04/07 22:34 [entrez]
PHST- 2024/04/07 00:00 [pmc-release]
AID - 2337291 [pii]
AID - 10.1080/0886022X.2024.2337291 [doi]
PST - ppublish
SO  - Ren Fail. 2024 Dec;46(1):2337291. doi: 10.1080/0886022X.2024.2337291. Epub 2024 
      Apr 7.

PMID- 37065505
OWN - NLM
STAT- MEDLINE
DCOM- 20230418
LR  - 20240916
IS  - 2046-1402 (Electronic)
IS  - 2046-1402 (Linking)
VI  - 12
DP  - 2023
TI  - Open Data and transparency in artificial intelligence and machine learning: A new 
      era of research.
PG  - 387
LID - 10.12688/f1000research.133019.1 [doi]
LID - 387
AB  - Artificial Intelligence (AI) and machine learning are the current forefront of 
      computer science and technology. AI and related sub-disciplines, including 
      machine learning, are essential technologies which have enabled the widespread 
      use of smart technology, such as smart phones, smart home appliances and even 
      electric toothbrushes. It is AI that allows the devices used day-to-day across 
      people's personal lives, working lives and in industry to better anticipate and 
      respond to our needs. However, the use of AI technology comes with a range of 
      ethical questions - including issues around privacy, security, reliability, 
      copyright/plagiarism and whether AI is capable of independent, conscious thought. 
      We have seen several issues related to racial and sexual bias in AI in the recent 
      times, putting the reliability of AI in question. Many of these issues have been 
      brought to the forefront of cultural awareness in late 2022, early 2023, with the 
      rise of AI art programs (and the copyright issues arising from the deep-learning 
      methods employed to train this AI), and the popularity of ChatGPT alongside its 
      ability to be used to mimic human output, particularly in regard to academic 
      work. In critical areas like healthcare, the errors of AI can be fatal. With the 
      incorporation of AI in almost every sector of our everyday life, we need to keep 
      asking ourselves- can we trust AI, and how much? This Editorial outlines the 
      importance of openness and transparency in the development and applications of AI 
      to allow all users to fully understand both the benefits and risks of this 
      ubiquitous technology, and outlines how the Artificial Intelligence and Machine 
      Learning  Gateway on F1000Research meets these needs.
CI  - Copyright: © 2023 Rodgers CM et al.
FAU - Rodgers, Caellin M
AU  - Rodgers CM
AUID- ORCID: 0009-0003-6927-9222
AD  - F1000, London, UK.
FAU - Ellingson, Sally R
AU  - Ellingson SR
AD  - UK College of Medicine, Markey Cancer Center, Lexington, Kentucky, USA.
FAU - Chatterjee, Parag
AU  - Chatterjee P
AUID- ORCID: 0000-0001-6760-4704
AD  - Universidad Tecnologica Nacional Facultad Regional Buenos Aires, Buenos Aires, 
      Autonomous City of Buenos Aires, Argentina.
AD  - Universidad de la Republica Uruguay, Montevideo, Montevideo Department, Uruguay.
LA  - eng
PT  - Editorial
DEP - 20230412
PL  - England
TA  - F1000Res
JT  - F1000Research
JID - 101594320
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Reproducibility of Results
MH  - *Machine Learning
MH  - Health Facilities
MH  - Industry
PMC - PMC10098385
OTO - NOTNLM
OT  - Artificial Intelligence and Machine Learning Gateway
OT  - artificial intelligence
OT  - machine learning
OT  - open data
OT  - open research
OT  - sharing
COIS- Competing interests: Caellin M Rodgers helped in preparing the first draft of 
      this article. Caellin M Rodgers is a Publishing Executive at F1000. She did not 
      handle the editorial processing of this article in any way.
EDAT- 2023/04/18 06:00
MHDA- 2023/04/18 06:42
PMCR- 2023/04/12
CRDT- 2023/04/17 03:56
PHST- 2023/04/04 00:00 [accepted]
PHST- 2023/04/18 06:42 [medline]
PHST- 2023/04/17 03:56 [entrez]
PHST- 2023/04/18 06:00 [pubmed]
PHST- 2023/04/12 00:00 [pmc-release]
AID - 10.12688/f1000research.133019.1 [doi]
PST - epublish
SO  - F1000Res. 2023 Apr 12;12:387. doi: 10.12688/f1000research.133019.1. eCollection 
      2023.

PMID- 39531187
OWN - NLM
STAT- Publisher
LR  - 20241112
IS  - 2509-2723 (Electronic)
IS  - 2509-2723 (Linking)
DP  - 2024 Nov 12
TI  - Functional and vascular neuroimaging in maritime pilots with long-term sleep 
      disruption.
LID - 10.1007/s11357-024-01417-4 [doi]
AB  - The mechanism underlying the possible causal association between long-term sleep 
      disruption and Alzheimer's disease remains unclear Musiek et al. 2015. A 
      hypothesised pathway through increased brain amyloid load was not confirmed in 
      previous work in our cohort of maritime pilots with long-term work-related sleep 
      disruption Thomas et al. Alzheimer's Res Ther 2020;12:101. Here, using functional 
      MRI, T2-FLAIR, and arterial spin labeling MRI scans, we explored alternative 
      neuroimaging biomarkers related to both sleep disruption and AD: resting-state 
      network co-activation and between-network connectivity of the default mode 
      network (DMN), salience network (SAL) and frontoparietal network (FPN), vascular 
      damage and cerebral blood flow (CBF). We acquired data of 16 maritime pilots 
      (56 ± 2.3 years old) with work-related long-term sleep disruption (23 ± 4.8 
      working years) and 16 healthy controls (59 ± 3.3 years old), with normal sleep 
      patterns (Pittsburgh Sleep Quality Index ≤ 5). Maritime pilots did not show 
      altered co-activation in either the DMN, FPN, or SAL and no differences in 
      between-network connectivity. We did not detect increased markers of vascular 
      damage in maritime pilots, and additionally, maritime pilots did not show altered 
      CBF-patterns compared to healthy controls. In summary, maritime pilots with 
      long-term sleep disruption did not show neuroimaging markers indicative of 
      preclinical AD compared to healthy controls. These findings do not resemble those 
      of short-term sleep deprivation studies. This could be due to resiliency to sleep 
      disruption or selection bias, as participants have already been exposed to and 
      were able to deal with sleep disruption for multiple years, or to compensatory 
      mechanisms Mentink et al. PLoS ONE. 2021;15(12):e0237622. This suggests the 
      relationship between sleep disruption and AD is not as strong as previously 
      implied in studies on short-term sleep deprivation, which would be beneficial for 
      all shift workers suffering from work-related sleep disruptions.
CI  - © 2024. The Author(s).
FAU - Mentink, Lara J
AU  - Mentink LJ
AUID- ORCID: 0000-0003-4373-7910
AD  - Department of Geriatrics, Radboudumc Alzheimer Centre, Radboud University Medical 
      Center, Nijmegen, The Netherlands. lara.mentink@radboudumc.nl.
AD  - Donders Institute for Brain, Cognition and Behaviour, Radboud University Medical 
      Center, Nijmegen, The Netherlands. lara.mentink@radboudumc.nl.
AD  - Department of Cognitive Science and Artificial Intelligence, School of Humanity 
      and Digital Sciences, Tilburg University, Tilburg, The Netherlands. 
      lara.mentink@radboudumc.nl.
FAU - van Osch, Matthias J P
AU  - van Osch MJP
AD  - Department of Radiology, Leiden University Medical Center, Leiden, The 
      Netherlands.
FAU - Bakker, Leanne J
AU  - Bakker LJ
AD  - Department of Geriatrics, Radboudumc Alzheimer Centre, Radboud University Medical 
      Center, Nijmegen, The Netherlands.
FAU - Olde Rikkert, Marcel G M
AU  - Olde Rikkert MGM
AD  - Department of Geriatrics, Radboudumc Alzheimer Centre, Radboud University Medical 
      Center, Nijmegen, The Netherlands.
AD  - Donders Institute for Brain, Cognition and Behaviour, Radboud University Medical 
      Center, Nijmegen, The Netherlands.
FAU - Beckmann, Christian F
AU  - Beckmann CF
AD  - Donders Institute for Brain, Cognition and Behaviour, Radboud University Medical 
      Center, Nijmegen, The Netherlands.
AD  - Centre for Functional MRI of the Brain (FMRIB), Nuffield Department of Clinical 
      Neurosciences, Wellcome Centre for Integrative Neuroimaging, University of 
      Oxford, Oxford, UK.
FAU - Claassen, Jurgen A H R
AU  - Claassen JAHR
AD  - Department of Geriatrics, Radboudumc Alzheimer Centre, Radboud University Medical 
      Center, Nijmegen, The Netherlands.
AD  - Donders Institute for Brain, Cognition and Behaviour, Radboud University Medical 
      Center, Nijmegen, The Netherlands.
AD  - Department of Cardiovascular Sciences, University of Leicester, Leicester, UK.
FAU - Haak, Koen V
AU  - Haak KV
AD  - Donders Institute for Brain, Cognition and Behaviour, Radboud University Medical 
      Center, Nijmegen, The Netherlands.
AD  - Department of Cognitive Science and Artificial Intelligence, School of Humanity 
      and Digital Sciences, Tilburg University, Tilburg, The Netherlands.
LA  - eng
GR  - 17854/Nederlandse Organisatie voor Wetenschappelijk Onderzoek/
GR  - 012-200-013/Nederlandse Organisatie voor Wetenschappelijk Onderzoek/
GR  - 016.160.351/Nederlandse Organisatie voor Wetenschappelijk Onderzoek/
GR  - 09150171910043/Nederlandse Organisatie voor Wetenschappelijk Onderzoek/
GR  - 016.Veni.171.068/Nederlandse Organisatie voor Wetenschappelijk Onderzoek/
GR  - WE.05-2010-04/Alzheimer Nederland/
GR  - 215573/Z/19/Z/WT_/Wellcome Trust/United Kingdom
PT  - Journal Article
DEP - 20241112
PL  - Switzerland
TA  - Geroscience
JT  - GeroScience
JID - 101686284
SB  - IM
OTO - NOTNLM
OT  - ASL
OT  - Functional MRI
OT  - Maritime pilots
OT  - Shift work
OT  - Sleep disruption
OT  - Vascular damage
COIS- Declarations Ethics approval The SCHIP study was approved by the institutional 
      review board (CMO, Commissie Mensgebonden Onderzoek, Region Arnhem-Nijmegen, 
      NL55712.091.16, file number 2016–2337) and performed in accordance with good 
      clinical practice guidelines and the world medical associations code of ethics 
      (Declaration of Helsinki). Informed consent Written informed consent was obtained 
      from all participants after they received detailed study information. 
      Participants received a stipend of 50 euros for participating. Competing 
      interests CFB is founder and shareholder of SBGneuro Ltd.
EDAT- 2024/11/13 13:53
MHDA- 2024/11/13 13:53
CRDT- 2024/11/12 11:14
PHST- 2024/08/29 00:00 [received]
PHST- 2024/10/26 00:00 [accepted]
PHST- 2024/11/13 13:53 [medline]
PHST- 2024/11/13 13:53 [pubmed]
PHST- 2024/11/12 11:14 [entrez]
AID - 10.1007/s11357-024-01417-4 [pii]
AID - 10.1007/s11357-024-01417-4 [doi]
PST - aheadofprint
SO  - Geroscience. 2024 Nov 12. doi: 10.1007/s11357-024-01417-4.

PMID- 38749478
OWN - NLM
STAT- MEDLINE
DCOM- 20240611
LR  - 20241107
IS  - 1540-1413 (Electronic)
IS  - 1540-1405 (Linking)
VI  - 22
IP  - 2 D
DP  - 2024 May 15
TI  - Enhancing Readability of Online Patient-Facing Content: The Role of AI Chatbots 
      in Improving Cancer Information Accessibility.
LID - e237334 [pii]
LID - 10.6004/jnccn.2023.7334 [doi]
AB  - BACKGROUND: Internet-based health education is increasingly vital in patient 
      care. However, the readability of online information often exceeds the average 
      reading level of the US population, limiting accessibility and comprehension. 
      This study investigates the use of chatbot artificial intelligence to improve the 
      readability of cancer-related patient-facing content. METHODS: We used ChatGPT 
      4.0 to rewrite content about breast, colon, lung, prostate, and pancreas cancer 
      across 34 websites associated with NCCN Member Institutions. Readability was 
      analyzed using Fry Readability Score, Flesch-Kincaid Grade Level, Gunning Fog 
      Index, and Simple Measure of Gobbledygook. The primary outcome was the mean 
      readability score for the original and artificial intelligence (AI)-generated 
      content. As secondary outcomes, we assessed the accuracy, similarity, and quality 
      using F1 scores, cosine similarity scores, and section 2 of the DISCERN 
      instrument, respectively. RESULTS: The mean readability level across the 34 
      websites was equivalent to a university freshman level (grade 13±1.5). However, 
      after ChatGPT's intervention, the AI-generated outputs had a mean readability 
      score equivalent to a high school freshman education level (grade 9±0.8). The 
      overall F1 score for the rewritten content was 0.87, the precision score was 
      0.934, and the recall score was 0.814. Compared with their original counterparts, 
      the AI-rewritten content had a cosine similarity score of 0.915 (95% CI, 
      0.908-0.922). The improved readability was attributed to simpler words and 
      shorter sentences. The mean DISCERN score of the random sample of AI-generated 
      content was equivalent to "good" (28.5±5), with no significant differences 
      compared with their original counterparts. CONCLUSIONS: Our study demonstrates 
      the potential of AI chatbots to improve the readability of patient-facing content 
      while maintaining content quality. The decrease in requisite literacy after AI 
      revision emphasizes the potential of this technology to reduce health care 
      disparities caused by a mismatch between educational resources available to a 
      patient and their health literacy.
FAU - Abreu, Andres A
AU  - Abreu AA
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Murimwa, Gilbert Z
AU  - Murimwa GZ
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Farah, Emile
AU  - Farah E
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Stewart, James W
AU  - Stewart JW
AD  - 2Department of Surgery, Yale School of Medicine, New Haven, CT.
FAU - Zhang, Lucia
AU  - Zhang L
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Rodriguez, Jonathan
AU  - Rodriguez J
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Sweetenham, John
AU  - Sweetenham J
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Zeh, Herbert J
AU  - Zeh HJ
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Wang, Sam C
AU  - Wang SC
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
FAU - Polanco, Patricio M
AU  - Polanco PM
AD  - 1Division of Surgical Oncology, Department of Surgery, UT Southwestern Medical 
      Center, Dallas, TX.
LA  - eng
PT  - Journal Article
DEP - 20240515
PL  - United States
TA  - J Natl Compr Canc Netw
JT  - Journal of the National Comprehensive Cancer Network : JNCCN
JID - 101162515
SB  - IM
MH  - Humans
MH  - *Comprehension
MH  - *Neoplasms
MH  - *Internet
MH  - *Artificial Intelligence
MH  - *Health Literacy/methods/standards
MH  - Patient Education as Topic/methods/standards
MH  - Consumer Health Information/standards/methods
EDAT- 2024/05/16 00:44
MHDA- 2024/06/12 00:41
CRDT- 2024/05/15 19:04
PHST- 2023/09/26 00:00 [received]
PHST- 2023/12/21 00:00 [accepted]
PHST- 2024/06/12 00:41 [medline]
PHST- 2024/05/16 00:44 [pubmed]
PHST- 2024/05/15 19:04 [entrez]
AID - e237334 [pii]
AID - 10.6004/jnccn.2023.7334 [doi]
PST - epublish
SO  - J Natl Compr Canc Netw. 2024 May 15;22(2 D):e237334. doi: 
      10.6004/jnccn.2023.7334.

PMID- 37971395
OWN - NLM
STAT- MEDLINE
DCOM- 20240508
LR  - 20240508
IS  - 1460-6984 (Electronic)
IS  - 1368-2822 (Linking)
VI  - 59
IP  - 3
DP  - 2024 May-Jun
TI  - Cognitive decline assessment using semantic linguistic content and transformer 
      deep learning architecture.
PG  - 1110-1127
LID - 10.1111/1460-6984.12973 [doi]
AB  - BACKGROUND: Dementia is a cognitive decline that leads to the progressive 
      deterioration of an individual's ability to perform daily activities 
      independently. As a result, a considerable amount of time and resources are spent 
      on caretaking. Early detection of dementia can significantly reduce the effort 
      and resources needed for caretaking. AIMS: This research proposes an approach for 
      assessing cognitive decline by analysing speech data, specifically focusing on 
      speech relevance as a crucial indicator for memory recall. METHODS & PROCEDURES: 
      This is a cross-sectional, online, self-administered. The proposed method used 
      deep learning architecture based on transformers, with BERT (Bidirectional 
      Encoder Representations from Transformers) and Sentence-Transformer to derive 
      encoded representations of speech transcripts. These representations provide 
      contextually descriptive information that is used to analyse the relevance of 
      sentences in their respective contexts. The encoded information is then compared 
      using cosine similarity metrics to measure the relevance of uttered sequences of 
      sentences. The study uses the Pitt Corpus Dementia dataset for experimentation, 
      which consists of speech data from individuals with and without dementia. The 
      accuracy of the proposed multi-QA-MPNet (Multi-Query Maximum Inner Product Search 
      Pretraining) model is compared with other pretrained transformer models of 
      Sentence-Transformer. OUTCOMES & RESULTS: The results show that the proposed 
      approach outperforms the other models in capturing context level information, 
      particularly semantic memory. Additionally, the study explores the suitability of 
      different similarity measures to evaluate the relevance of uttered sequences of 
      sentences. The experimentation reveals that cosine similarity is the most 
      appropriate measure for this task. CONCLUSIONS & IMPLICATIONS: This finding has 
      significant implications for the early warning signs of dementia, as it suggests 
      that cosine similarity metrics can effectively capture the semantic relevance of 
      spoken language. The persistent cognitive decline over time acts as one of the 
      indicators for prevalence of dementia. Additionally early dementia could be 
      recognised by analysis on other modalities like speech and brain images. WHAT 
      THIS PAPER ADDS: What is already known on this subject It is already known that 
      speech- and language-based detection methods can be useful for dementia 
      diagnosis, as language difficulties are often early signs of the disease. 
      Additionally, deep learning algorithms have shown promise in detecting and 
      diagnosing dementia through analysing large datasets, particularly in speech- and 
      language-based detection methods. However, further research is needed to validate 
      the performance of these algorithms on larger and more diverse datasets and to 
      address potential biases and limitations. What this paper adds to existing 
      knowledge This study presents a unique and effective approach for cognitive 
      decline assessment through analysing speech data. The study provides valuable 
      insights into the importance of context and semantic memory in accurately 
      detecting the potential in dementia and demonstrates the applicability of deep 
      learning models for this purpose. The findings of this study have important 
      clinical implications and can inform future research and development in the field 
      of dementia detection and care. What are the potential or actual clinical 
      implications of this work? The proposed approach for cognitive decline assessment 
      using speech data and deep learning models has significant clinical implications. 
      It has the potential to improve the accuracy and efficiency of dementia 
      diagnosis, leading to earlier detection and more effective treatments, which can 
      improve patient outcomes and quality of life.
CI  - © 2023 Royal College of Speech and Language Therapists.
FAU - Pl, Rini
AU  - Pl R
AUID- ORCID: 0000-0003-1434-0770
AD  - Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, India.
FAU - Ks, Gayathri
AU  - Ks G
AUID- ORCID: 0000-0002-0971-0186
AD  - Sri Sivasubramaniya Nadar College of Engineering, Tamil Nadu, India.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20231116
PL  - United States
TA  - Int J Lang Commun Disord
JT  - International journal of language & communication disorders
JID - 9803709
SB  - IM
MH  - Humans
MH  - *Deep Learning
MH  - *Cognitive Dysfunction/diagnosis/psychology
MH  - Cross-Sectional Studies
MH  - *Semantics
MH  - Aged
MH  - Female
MH  - Male
MH  - Aged, 80 and over
MH  - Dementia/diagnosis/psychology
OTO - NOTNLM
OT  - cosine similarity
OT  - dementia
OT  - semantic analysis
OT  - sentence
OT  - text analysis
OT  - transcript
OT  - word count
EDAT- 2023/11/17 15:27
MHDA- 2024/05/08 12:45
CRDT- 2023/11/16 10:23
PHST- 2023/04/20 00:00 [received]
PHST- 2023/09/18 00:00 [accepted]
PHST- 2024/05/08 12:45 [medline]
PHST- 2023/11/17 15:27 [pubmed]
PHST- 2023/11/16 10:23 [entrez]
AID - 10.1111/1460-6984.12973 [doi]
PST - ppublish
SO  - Int J Lang Commun Disord. 2024 May-Jun;59(3):1110-1127. doi: 
      10.1111/1460-6984.12973. Epub 2023 Nov 16.

PMID- 38539420
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240330
IS  - 2072-6694 (Print)
IS  - 2072-6694 (Electronic)
IS  - 2072-6694 (Linking)
VI  - 16
IP  - 6
DP  - 2024 Mar 7
TI  - Impact of Targeted Agents on Survival of Chronic Lymphocytic Leukemia Patients 
      Fit for Fludarabine, Cyclophosphamide, and Rituximab (FCR) Relative to Age- and 
      Sex-Matched Population.
LID - 10.3390/cancers16061085 [doi]
LID - 1085
AB  - To assess the impact of first-line treatment with targeted agents (TAs) or 
      fludarabine, cyclophosphamide, and rituximab (FCR)-based chemo-immunotherapy 
      (CIT) on overall survival (OS) compared to age- and sex-matched individuals in 
      the general population, we conducted an aggregated analysis of phase 3 clinical 
      trials, including the two FLAIR sub-studies, ECOG1912, and CLL13 trials. The 
      restricted mean survival time (RMST), an alternative measure in outcome analyses 
      capturing OS changes over the entire history of the disease, was used to minimize 
      biases associated with the short follow-up time of trials. Patients treated with 
      TAs demonstrated a higher 5-year RMST (58.1 months; 95% CI: 57.4 to 58.8) 
      compared to those treated with CIT (5-year RMST, 56.9 months; 95% CI: 56.7-58.2). 
      Furthermore, the OS comparison of treatment groups with the AGMGP suggests that 
      TAs may mitigate the impact of CLL on OS during the first five years 
      post-treatment initiation. In summary, the 5-year RMST difference was -0.4 months 
      (95% CI: -0.8 to 0.2; p = 0.10) when comparing CLL patients treated with TAs to 
      the Italian age- and gender-matched general population (AGMGP). A similar trend 
      was observed when CLL patients treated with TAs were compared to the US AGMGP 
      (5-year RMST difference, 0.3 months; 95% CI: -0.1 to 0.9; p = 0.12). In contrast, 
      CLL patients treated with FCR exhibited sustained OS differences when compared to 
      both the Italian cohort (5-year RMST difference: -1.6 months; 95% CI: -2.4 to 
      -0.9; p < 0.0001) and the US AGMGP cohort (5-year RMST difference: -0.9 months; 
      95% CI: -1.7 to -0.2; p = 0.015). Although these results support TAs as the 
      preferred first-line treatment for younger CLL patients, it is crucial to 
      acknowledge that variations in patient selection criteria and clinical profiles 
      across clinical trials necessitate a cautious interpretation of these findings 
      that should be viewed as directional and hypothesis-generating. A longer 
      follow-up is needed to assess the survival improvement of younger CLL patients 
      treated with TAs relative to the AGMGP.
FAU - Molica, Stefano
AU  - Molica S
AUID- ORCID: 0000-0003-2795-6507
AD  - Department Hematology, Hull University Teaching Hospitals NHS Trust, Hull HU3 
      2JZ, UK.
FAU - Shanafelt, Tait D
AU  - Shanafelt TD
AD  - Division of Hematology, Department of Medicine, Stanford University School of 
      Medicine, Stanford, CA 94305, USA.
FAU - Allsup, David
AU  - Allsup D
AUID- ORCID: 0000-0001-6159-6109
AD  - Department Hematology, Hull University Teaching Hospitals NHS Trust, Hull HU3 
      2JZ, UK.
AD  - Centre for Biomedicine, Hull York Medical School, Hull HU6 7RU, UK.
FAU - Giannarelli, Diana
AU  - Giannarelli D
AUID- ORCID: 0000-0002-6085-1195
AD  - Biostatistics Unit, Scientific Directorate Fondazione Policlinico Universitario 
      Agostino Gemelli IRCCS, 00168 Roma, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240307
PL  - Switzerland
TA  - Cancers (Basel)
JT  - Cancers
JID - 101526829
PMC - PMC10968865
OTO - NOTNLM
OT  - BTKis
OT  - CLL pts fit for FCR
OT  - life-expectancy
OT  - targeted agents
OT  - venetoclax-based therapy
COIS- S.M. received honoraria from Janssen, Abbvie, and AstraZeneca. T.D.S. reports 
      research support from Pharmacyclics, AbbVie, and Genentech, and holds a patent 
      (US14/292075) on green tea extract epigallocatechin gallate in combination with 
      chemotherapy for CLL. D.A. and D.G. declare no competing financial interests.
EDAT- 2024/03/28 06:46
MHDA- 2024/03/28 06:47
PMCR- 2024/03/07
CRDT- 2024/03/28 01:01
PHST- 2024/02/02 00:00 [received]
PHST- 2024/03/03 00:00 [revised]
PHST- 2024/03/05 00:00 [accepted]
PHST- 2024/03/28 06:47 [medline]
PHST- 2024/03/28 06:46 [pubmed]
PHST- 2024/03/28 01:01 [entrez]
PHST- 2024/03/07 00:00 [pmc-release]
AID - cancers16061085 [pii]
AID - cancers-16-01085 [pii]
AID - 10.3390/cancers16061085 [doi]
PST - epublish
SO  - Cancers (Basel). 2024 Mar 7;16(6):1085. doi: 10.3390/cancers16061085.

PMID- 39406959
OWN - NLM
STAT- MEDLINE
DCOM- 20250317
LR  - 20250317
IS  - 1432-1084 (Electronic)
IS  - 0938-7994 (Linking)
VI  - 35
IP  - 4
DP  - 2025 Apr
TI  - ChatGPT as an effective tool for quality evaluation of radiomics research.
PG  - 2030-2042
LID - 10.1007/s00330-024-11122-7 [doi]
AB  - OBJECTIVES: This study aimed to evaluate the effectiveness of ChatGPT-4o in 
      assessing the methodological quality of radiomics research using the radiomics 
      quality score (RQS) compared to human experts. METHODS: Published in European 
      Radiology, European Radiology Experimental, and Insights into Imaging between 
      2023 and 2024, open-access and peer-reviewed radiomics research articles with 
      creative commons attribution license (CC-BY) were included in this study. 
      Pre-prints from MedRxiv were also included to evaluate potential peer-review 
      bias. Using the RQS, each study was independently assessed twice by ChatGPT-4o 
      and by two radiologists with consensus. RESULTS: In total, 52 open-access and 
      peer-reviewed articles were included in this study. Both ChatGPT-4o evaluation 
      (average of two readings) and human experts had a median RQS of 14.5 (40.3% 
      percentage score) (p > 0.05). Pairwise comparisons revealed no statistically 
      significant difference between the readings of ChatGPT and human experts 
      (corrected p > 0.05). The intraclass correlation coefficient for intra-rater 
      reliability of ChatGPT-4o was 0.905 (95% CI: 0.840-0.944), and those for 
      inter-rater reliability with human experts for each evaluation of ChatGPT-4o were 
      0.859 (95% CI: 0.756-0.919) and 0.914 (95% CI: 0.855-0.949), corresponding to 
      good to excellent reliability for all. The evaluation by ChatGPT-4o took less 
      time (2.9-3.5 min per article) compared to human experts (13.9 min per article by 
      one reader). Item-wise reliability analysis showed ChatGPT-4o maintained 
      consistently high reliability across almost all RQS items. CONCLUSION: ChatGPT-4o 
      provides reliable and efficient assessments of radiomics research quality. Its 
      evaluations closely align with those of human experts and reduce evaluation time. 
      KEY POINTS: Question Is ChatGPT effective and reliable in evaluating radiomics 
      research quality based on RQS? Findings ChatGPT-4o showed high reliability and 
      efficiency, with evaluations closely matching human experts. It can considerably 
      reduce the time required for radiomics research quality assessment. Clinical 
      relevance ChatGPT-4o offers a quick and reliable automated alternative for 
      evaluating the quality of radiomics research, with the potential to assess 
      radiomics research at a large scale in the future.
CI  - © 2024. The Author(s), under exclusive licence to European Society of Radiology.
FAU - Mese, Ismail
AU  - Mese I
AUID- ORCID: 0000-0002-4429-6996
AD  - Department of Radiology, Erenkoy Mental Health and Neurology Training and 
      Research Hospital, University of Health Sciences, Istanbul, Turkey.
FAU - Kocak, Burak
AU  - Kocak B
AUID- ORCID: 0000-0002-7307-396X
AD  - Department of Radiology, Basaksehir Cam and Sakura City Hospital, University of 
      Health Sciences, Istanbul, Turkey. drburakkocak@gmail.com.
LA  - eng
PT  - Journal Article
DEP - 20241015
PL  - Germany
TA  - Eur Radiol
JT  - European radiology
JID - 9114774
SB  - IM
MH  - Humans
MH  - Reproducibility of Results
MH  - *Radiology/methods/standards
MH  - Biomedical Research/methods
MH  - Radiomics
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Large language models
OT  - Machine learning
OT  - Radiomics
OT  - Texture analysis
COIS- Compliance with ethical standards. Guarantor: The scientific guarantor of this 
      publication is Burak Kocak, MD. Conflict of interest: B.K. is on the editorial 
      board of European Radiology (section editor: Imaging Informatics and Artificial 
      Intelligence). He has taken no part in this article’s peer review or selection. 
      The authors of this manuscript declare no relationships with any companies whose 
      products or services may be related to the subject matter of the article. 
      Statistics and biometry: No complex statistical methods were necessary for this 
      paper. Informed consent: Non-applicable. Ethical approval: Non-applicable. Study 
      subjects or cohorts overlap: None. Methodology: Experimental
EDAT- 2024/10/16 00:23
MHDA- 2025/03/17 18:31
CRDT- 2024/10/15 23:32
PHST- 2024/07/05 00:00 [received]
PHST- 2024/09/18 00:00 [accepted]
PHST- 2024/09/09 00:00 [revised]
PHST- 2025/03/17 18:31 [medline]
PHST- 2024/10/16 00:23 [pubmed]
PHST- 2024/10/15 23:32 [entrez]
AID - 10.1007/s00330-024-11122-7 [pii]
AID - 10.1007/s00330-024-11122-7 [doi]
PST - ppublish
SO  - Eur Radiol. 2025 Apr;35(4):2030-2042. doi: 10.1007/s00330-024-11122-7. Epub 2024 
      Oct 15.

PMID- 38954915
OWN - NLM
STAT- MEDLINE
DCOM- 20240727
LR  - 20240727
IS  - 1872-7565 (Electronic)
IS  - 0169-2607 (Linking)
VI  - 254
DP  - 2024 Sep
TI  - Assessing ChatGPT's ability to emulate human reviewers in scientific research: A 
      descriptive and qualitative approach.
PG  - 108313
LID - S0169-2607(24)00306-7 [pii]
LID - 10.1016/j.cmpb.2024.108313 [doi]
AB  - BACKGROUND: ChatGPT is an AI platform whose relevance in the peer review of 
      scientific articles is steadily growing. Nonetheless, it has sparked debates over 
      its potential biases and inaccuracies. This study aims to assess ChatGPT's 
      ability to qualitatively emulate human reviewers in scientific research. METHODS: 
      We included the first submitted version of the latest twenty original research 
      articles published by the 3rd of July 2023, in a high-profile medical journal. 
      Each article underwent evaluation by a minimum of three human reviewers during 
      the initial review stage. Subsequently, three researchers with medical 
      backgrounds and expertise in manuscript revision, independently and qualitatively 
      assessed the agreement between the peer reviews generated by ChatGPT version 
      GPT-4 and the comments provided by human reviewers for these articles. The level 
      of agreement was categorized into complete, partial, none, or contradictory. 
      RESULTS: 720 human reviewers' comments were assessed. There was a good agreement 
      between the three assessors (Overall kappa >0.6). ChatGPT's comments demonstrated 
      complete agreement in terms of quality and substance with 48 (6.7 %) human 
      reviewers' comments, partially agreed with 92 (12.8 %), identifying issues 
      necessitating further elaboration or recommending supplementary steps to address 
      concerns, had no agreement with a significant 565 (78.5 %), and contradicted 15 
      (2.1 %). ChatGPT comments on methods had the lowest proportion of complete 
      agreement (13 comments, 3.6 %), while general comments on the manuscript 
      displayed the highest proportion of complete agreement (17 comments, 22.1 %). 
      CONCLUSION: ChatGPT version GPT-4 has a limited ability to emulate human 
      reviewers within the peer review process of scientific research.
CI  - Copyright © 2024 Elsevier B.V. All rights reserved.
FAU - Suleiman, Aiman
AU  - Suleiman A
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA; Department of Anesthesia, Critical 
      Care and Pain Medicine, Albert Einstein College of Medicine, Montefiore Medical 
      Center, Bronx, NY, USA. Electronic address: asuleima@bidmc.harvard.edu.
FAU - von Wedel, Dario
AU  - von Wedel D
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Munoz-Acuna, Ricardo
AU  - Munoz-Acuna R
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Redaelli, Simone
AU  - Redaelli S
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Santarisi, Abeer
AU  - Santarisi A
AD  - Center for Anesthesia Research Excellence (CARE), Harvard Medical School, Beth 
      Israel Deaconess Medical Center, Boston, MA, USA; Department of Emergency 
      Medicine, Disaster Medicine Fellowship, Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Seibold, Eva-Lotte
AU  - Seibold EL
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Ratajczak, Nikolai
AU  - Ratajczak N
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Kato, Shinichiro
AU  - Kato S
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Said, Nader
AU  - Said N
AD  - Department of Industrial Engineering, Faculty of Engineering Technologies and 
      Sciences, Higher Colleges of Technology, DWC, Dubai, United Arab Emirates.
FAU - Sundar, Eswar
AU  - Sundar E
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA.
FAU - Goodspeed, Valerie
AU  - Goodspeed V
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA.
FAU - Schaefer, Maximilian S
AU  - Schaefer MS
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Harvard Medical 
      School, Beth Israel Deaconess Medical Center, Boston, MA, USA; Center for 
      Anesthesia Research Excellence (CARE), Harvard Medical School, Beth Israel 
      Deaconess Medical Center, Boston, MA, USA; Klinik für Anästhesiologie, 
      Universitätsklinikum Düsseldorf, Düsseldorf, Germany.
LA  - eng
PT  - Journal Article
DEP - 20240628
PL  - Ireland
TA  - Comput Methods Programs Biomed
JT  - Computer methods and programs in biomedicine
JID - 8506513
SB  - IM
MH  - Humans
MH  - *Peer Review, Research
MH  - Peer Review
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Bias
OT  - ChatGPT
OT  - Peer review
OT  - Quality agreement
COIS- Declaration of competing interest Maximilian S. Schaefer received funding for 
      investigator-initiated studies from Merck & Co., which do not pertain to this 
      manuscript. He is an associate editor for BMC Anesthesiology. He received 
      honoraria for presentations from Fisher & Paykel Healthcare and Mindray Medical 
      International Limited and an unrestricted philantropic grant from Jeffrey and 
      Judith Buzen. All other authors have no conflicts of interest to declare.
EDAT- 2024/07/03 00:41
MHDA- 2024/07/28 14:49
CRDT- 2024/07/02 18:04
PHST- 2024/02/06 00:00 [received]
PHST- 2024/06/20 00:00 [revised]
PHST- 2024/06/27 00:00 [accepted]
PHST- 2024/07/28 14:49 [medline]
PHST- 2024/07/03 00:41 [pubmed]
PHST- 2024/07/02 18:04 [entrez]
AID - S0169-2607(24)00306-7 [pii]
AID - 10.1016/j.cmpb.2024.108313 [doi]
PST - ppublish
SO  - Comput Methods Programs Biomed. 2024 Sep;254:108313. doi: 
      10.1016/j.cmpb.2024.108313. Epub 2024 Jun 28.

PMID- 38556123
OWN - NLM
STAT- MEDLINE
DCOM- 20240620
LR  - 20240620
IS  - 1943-7811 (Electronic)
IS  - 1525-1578 (Linking)
VI  - 26
IP  - 7
DP  - 2024 Jul
TI  - The Application of Knowledge Engineering via the Use of a Biomimetic Digital Twin 
      Ecosystem, Phenotype-Driven Variant Analysis, and Exome Sequencing to Understand 
      the Molecular Mechanisms of Disease.
PG  - 543-551
LID - S1525-1578(24)00062-X [pii]
LID - 10.1016/j.jmoldx.2024.03.004 [doi]
AB  - Applied artificial intelligence, particularly large language models, in 
      biomedical research is accelerating, but effective discovery and validation 
      requires a toolset without limitations or bias. On January 30, 2023, the National 
      Academies of Sciences, Engineering, and Medicine (NAS) appointed an ad hoc 
      committee to identify the needs and opportunities to advance the mathematical, 
      statistical, and computational foundations of digital twins in applications 
      across science, medicine, engineering, and society. On December 15, 2023, the NAS 
      released a 164-page report, "Foundational Research Gaps and Future Directions for 
      Digital Twins." This report described the importance of using digital twins in 
      biomedical research. The current study was designed to develop an innovative 
      method that incorporated phenotype-ranking algorithms with knowledge engineering 
      via a biomimetic digital twin ecosystem. This ecosystem applied real-world 
      reasoning principles to nonnormalized, raw data to identify hidden or "dark" 
      data. Clinical exome sequencing study on patients with endometriosis indicated 
      four variants of unknown clinical significance potentially associated with 
      endometriosis-related disorders in nearly all patients analyzed. One variant of 
      unknown clinical significance was identified in all patient samples and could be 
      a biomarker for diagnostics. To the best of our knowledge, this is the first 
      study to incorporate the recommendations of the NAS to biomedical research. This 
      method can be used to understand the mechanisms of any disease, for virtual 
      clinical trials, and to identify effective new therapies.
CI  - Copyright © 2024 Association for Molecular Pathology and American Society for 
      Investigative Pathology. Published by Elsevier Inc. All rights reserved.
FAU - Kearns, William G
AU  - Kearns WG
AD  - Genzeva, Rockville, Maryland; LumaGene, Rockville, Maryland. Electronic address: 
      wgkearns@genzeva.com.
FAU - Stamoulis, Georgios
AU  - Stamoulis G
AD  - QIAGEN Digital Insights, Redwood City, California.
FAU - Glick, Joseph
AU  - Glick J
AD  - RYLTI BioPharma, Hauppauge, New York.
FAU - Baisch, Lawrence
AU  - Baisch L
AD  - RYLTI BioPharma, Hauppauge, New York.
FAU - Benner, Andrew
AU  - Benner A
AD  - Genzeva, Rockville, Maryland.
FAU - Brough, Dalton
AU  - Brough D
AD  - Genzeva, Rockville, Maryland.
FAU - Du, Luke
AU  - Du L
AD  - Genzeva, Rockville, Maryland.
FAU - Wilson, Bradford
AU  - Wilson B
AD  - IndyGeneUS AI, Washington, District of Columbia.
FAU - Kearns, Laura
AU  - Kearns L
AD  - Genzeva, Rockville, Maryland; LumaGene, Rockville, Maryland.
FAU - Ng, Nicholas
AU  - Ng N
AD  - Department of Obstetrics and Gynecology, Brigham and Women's Hospital, Harvard 
      University, Boston, Massachusetts.
FAU - Seshan, Maya
AU  - Seshan M
AD  - Department of Obstetrics and Gynecology, Brigham and Women's Hospital, Harvard 
      University, Boston, Massachusetts.
FAU - Anchan, Raymond
AU  - Anchan R
AD  - Department of Obstetrics and Gynecology, Brigham and Women's Hospital, Harvard 
      University, Boston, Massachusetts.
LA  - eng
PT  - Journal Article
DEP - 20240329
PL  - United States
TA  - J Mol Diagn
JT  - The Journal of molecular diagnostics : JMD
JID - 100893612
SB  - IM
MH  - Humans
MH  - *Phenotype
MH  - *Exome Sequencing/methods
MH  - Female
MH  - *Endometriosis/genetics
MH  - Algorithms
MH  - Biomimetics/methods
MH  - Artificial Intelligence
COIS- Disclosure Statement W.G.K. and L.K. are owners of Genzeva and LumaGene, and they 
      own stock in RYLTI, LLC, of which RYLTI BioPharma is a subsidiary. L.B. and J.G. 
      own RYLTI, LLC, stock, of which RYLTI BioPharma is a subsidiary.
EDAT- 2024/04/01 00:42
MHDA- 2024/06/21 00:42
CRDT- 2024/03/31 20:26
PHST- 2023/11/20 00:00 [received]
PHST- 2024/03/06 00:00 [revised]
PHST- 2024/03/19 00:00 [accepted]
PHST- 2024/06/21 00:42 [medline]
PHST- 2024/04/01 00:42 [pubmed]
PHST- 2024/03/31 20:26 [entrez]
AID - S1525-1578(24)00062-X [pii]
AID - 10.1016/j.jmoldx.2024.03.004 [doi]
PST - ppublish
SO  - J Mol Diagn. 2024 Jul;26(7):543-551. doi: 10.1016/j.jmoldx.2024.03.004. Epub 2024 
      Mar 29.

PMID- 38310972
OWN - NLM
STAT- MEDLINE
DCOM- 20240721
LR  - 20240917
IS  - 1523-1747 (Electronic)
IS  - 0022-202X (Linking)
VI  - 144
IP  - 8
DP  - 2024 Aug
TI  - Assessment of Correctness, Content Omission, and Risk of Harm in Large Language 
      Model Responses to Dermatology Continuing Medical Education Questions.
PG  - 1877-1879
LID - S0022-202X(24)00088-5 [pii]
LID - 10.1016/j.jid.2024.01.015 [doi]
FAU - Cai, Zhuo Ran
AU  - Cai ZR
AD  - Department of Dermatology, Stanford University School of Medicine, Stanford, 
      California, USA; Department of Dermatology, Medical School, Université de 
      Montréal, Montreal, Canada.
FAU - Chen, Michael L
AU  - Chen ML
AD  - Department of Dermatology, Stanford University School of Medicine, Stanford, 
      California, USA; Center for Digital Health, Stanford University School of 
      Medicine, Stanford, California, USA.
FAU - Kim, Jiyeong
AU  - Kim J
AD  - Department of Dermatology, Stanford University School of Medicine, Stanford, 
      California, USA; Center for Digital Health, Stanford University School of 
      Medicine, Stanford, California, USA.
FAU - Novoa, Roberto A
AU  - Novoa RA
AD  - Department of Dermatology, Stanford University School of Medicine, Stanford, 
      California, USA; Department of Pathology, Stanford University School of Medicine, 
      Stanford, California, USA.
FAU - Barnes, Leandra A
AU  - Barnes LA
AD  - Department of Dermatology, Stanford University School of Medicine, Stanford, 
      California, USA.
FAU - Beam, Andrew
AU  - Beam A
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, 
      Massachusetts, USA.
FAU - Linos, Eleni
AU  - Linos E
AD  - Department of Dermatology, Stanford University School of Medicine, Stanford, 
      California, USA; Center for Digital Health, Stanford University School of 
      Medicine, Stanford, California, USA. Electronic address: linos@stanford.edu.
LA  - eng
PT  - Letter
DEP - 20240202
PL  - United States
TA  - J Invest Dermatol
JT  - The Journal of investigative dermatology
JID - 0426720
SB  - IM
MH  - *Dermatology/education
MH  - Humans
MH  - *Education, Medical, Continuing
MH  - Language
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bias
OT  - ChatGPT
OT  - Harm
OT  - Large language model
EDAT- 2024/02/05 00:42
MHDA- 2024/07/22 00:42
CRDT- 2024/02/04 19:26
PHST- 2024/01/08 00:00 [received]
PHST- 2024/01/16 00:00 [accepted]
PHST- 2024/07/22 00:42 [medline]
PHST- 2024/02/05 00:42 [pubmed]
PHST- 2024/02/04 19:26 [entrez]
AID - S0022-202X(24)00088-5 [pii]
AID - 10.1016/j.jid.2024.01.015 [doi]
PST - ppublish
SO  - J Invest Dermatol. 2024 Aug;144(8):1877-1879. doi: 10.1016/j.jid.2024.01.015. 
      Epub 2024 Feb 2.

PMID- 40025837
OWN - NLM
STAT- MEDLINE
DCOM- 20250303
LR  - 20250305
IS  - 1752-8062 (Electronic)
IS  - 1752-8054 (Print)
IS  - 1752-8054 (Linking)
VI  - 18
IP  - 3
DP  - 2025 Mar
TI  - Exploration of Using an Open-Source Large Language Model for Analyzing Trial 
      Information: A Case Study of Clinical Trials With Decentralized Elements.
PG  - e70183
LID - 10.1111/cts.70183 [doi]
LID - e70183
AB  - Despite interest in clinical trials with decentralized elements (DCTs), analysis 
      of their trends in trial registries is lacking due to heterogeneous designs and 
      unstandardized terms. We explored Llama 3, an open-source large language model, 
      to efficiently evaluate these trends. Trial data were sourced from Aggregate 
      Analysis of ClinicalTrials.gov, focusing on drug trials conducted between 2018 
      and 2023. We utilized three Llama 3 models with a different number of parameters: 
      8b (model 1), fine-tuned 8b (model 2) with curated data, and 70b (model 3). 
      Prompt engineering enabled sophisticated tasks such as classification of DCTs 
      with explanations and extracting decentralized elements. Model performance, 
      evaluated on a 3-month exploratory test dataset, demonstrated that sensitivity 
      could be improved after fine-tuning from 0.0357 to 0.5385. Low positive 
      predictive value in the fine-tuned model 2 could be improved by focusing on 
      trials with DCT-associated expressions from 0.5385 to 0.9167. However, the 
      extraction of decentralized elements was only properly performed by model 3, 
      which had a larger number of parameters. Based on the results, we screened the 
      entire 6-year dataset after applying DCT-associated expressions. After the 
      subsequent application of models 2 and 3, we identified 692 DCTs. We found that a 
      total of 213 trials were classified as phase 2, followed by 162 phase 4 trials, 
      112 phase 3 trials, and 92 phase 1 trials. In conclusion, our study demonstrated 
      the potential of large language models for analyzing clinical trial information 
      not structured in a machine-readable format. Managing potential biases during 
      model application is crucial.
CI  - © 2025 The Author(s). Clinical and Translational Science published by Wiley 
      Periodicals LLC on behalf of American Society for Clinical Pharmacology and 
      Therapeutics.
FAU - Huh, Ki Young
AU  - Huh KY
AUID- ORCID: 0000-0002-1872-9954
AD  - Department of Clinical Pharmacology and Therapeutics, Seoul National University 
      College of Medicine and Hospital, Seoul, Republic of Korea.
FAU - Song, Ildae
AU  - Song I
AUID- ORCID: 0000-0002-3904-4735
AD  - Department of Pharmaceutical Science and Technology, Kyungsung University, Busan, 
      Republic of Korea.
FAU - Kim, Yoonjin
AU  - Kim Y
AUID- ORCID: 0009-0004-2141-2407
AD  - Department of Clinical Pharmacology and Therapeutics, Seoul National University 
      College of Medicine and Hospital, Seoul, Republic of Korea.
FAU - Park, Jiyeon
AU  - Park J
AUID- ORCID: 0000-0003-1317-2891
AD  - Department of Clinical Pharmacology and Therapeutics, Seoul National University 
      College of Medicine and Hospital, Seoul, Republic of Korea.
FAU - Ryu, Hyunwook
AU  - Ryu H
AUID- ORCID: 0009-0004-5078-770X
AD  - Department of Clinical Pharmacology and Therapeutics, Seoul National University 
      College of Medicine and Hospital, Seoul, Republic of Korea.
FAU - Koh, JaeEun
AU  - Koh J
AUID- ORCID: 0009-0009-0725-3450
AD  - Department of Clinical Pharmacology and Therapeutics, Seoul National University 
      College of Medicine and Hospital, Seoul, Republic of Korea.
FAU - Yu, Kyung-Sang
AU  - Yu KS
AUID- ORCID: 0000-0003-0921-7225
AD  - Department of Clinical Pharmacology and Therapeutics, Seoul National University 
      College of Medicine and Hospital, Seoul, Republic of Korea.
FAU - Kim, Kyung Hwan
AU  - Kim KH
AUID- ORCID: 0000-0002-2718-8758
AD  - Department of Thoracic and Cardiovascular Surgery, Seoul National University 
      College of Medicine, Seoul, Republic of Korea.
FAU - Lee, SeungHwan
AU  - Lee S
AUID- ORCID: 0000-0002-1713-9194
AD  - Department of Clinical Pharmacology and Therapeutics, Seoul National University 
      College of Medicine and Hospital, Seoul, Republic of Korea.
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Clin Transl Sci
JT  - Clinical and translational science
JID - 101474067
SB  - IM
MH  - Humans
MH  - *Clinical Trials as Topic
MH  - Registries/statistics & numerical data
PMC - PMC11873368
OTO - NOTNLM
OT  - clinical trials
OT  - data analysis
OT  - model evaluation
COIS- The authors declare no conflicts of interest.
EDAT- 2025/03/03 06:22
MHDA- 2025/03/03 06:23
PMCR- 2025/03/02
CRDT- 2025/03/03 02:34
PHST- 2025/02/07 00:00 [revised]
PHST- 2024/11/19 00:00 [received]
PHST- 2025/02/10 00:00 [accepted]
PHST- 2025/03/03 06:23 [medline]
PHST- 2025/03/03 06:22 [pubmed]
PHST- 2025/03/03 02:34 [entrez]
PHST- 2025/03/02 00:00 [pmc-release]
AID - CTS70183 [pii]
AID - 10.1111/cts.70183 [doi]
PST - ppublish
SO  - Clin Transl Sci. 2025 Mar;18(3):e70183. doi: 10.1111/cts.70183.

PMID- 39525124
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241114
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 16
IP  - 10
DP  - 2024 Oct
TI  - Assessing the Clinical Appropriateness and Practical Utility of ChatGPT as an 
      Educational Resource for Patients Considering Minimally Invasive Spine Surgery.
PG  - e71105
LID - 10.7759/cureus.71105 [doi]
LID - e71105
AB  - Introduction Minimally invasive spine surgery (MISS) has evolved over the last 
      three decades as a less invasive alternative to traditional spine surgery, 
      offering benefits such as smaller incisions, faster recovery, and lower 
      complication rates. With patients frequently seeking information about MISS 
      online, the comprehensibility and accuracy of this information are crucial. 
      Recent studies have shown that much of the online material regarding spine 
      surgery exceeds the recommended readability levels, making it difficult for 
      patients to understand. This study explores the clinical appropriateness and 
      readability of responses generated by Chat Generative Pre-Trained Transformer 
      (ChatGPT) to frequently asked questions (FAQs) about MISS. Methods A set of 15 
      FAQs was formulated based on clinical expertise and existing literature on MISS. 
      Each question was independently inputted into ChatGPT five times, and the 
      generated responses were evaluated by three neurosurgery attendings for clinical 
      appropriateness. Appropriateness was judged based on accuracy, readability, and 
      patient accessibility. Readability was assessed using seven standardized 
      readability tests, including the Flesch-Kincaid Grade Level and Flesch Reading 
      Ease (FRE) scores. Statistical analysis was performed to compare readability 
      scores across preoperative, postoperative, and intraoperative/technical question 
      categories. Results The mean readability scores for preoperative, postoperative, 
      and intraoperative/technical questions were 15±2.8, 16±3, and 15.7±3.2, 
      respectively, significantly exceeding the recommended sixth- to eighth-grade 
      reading level for patient education (p=0.017). Differences in readability across 
      individual questions were also statistically significant (p<0.001). All responses 
      required a reading level above 11th grade, with a majority indicating 
      college-level comprehension. Although preoperative and postoperative questions 
      generally elicited clinically appropriate responses, 50% of 
      intraoperative/technical questions yielded either "inappropriate" or "unreliable" 
      responses, particularly for inquiries about radiation exposure and the use of 
      lasers in MISS. Conclusions While ChatGPT is proficient in providing clinically 
      appropriate responses to certain FAQs about MISS, it frequently produces 
      responses that exceed the recommended readability level for patient education. 
      This limitation suggests that its utility may be confined to highly educated 
      patients, potentially exacerbating existing disparities in patient comprehension. 
      Future AI-based patient education tools must prioritize clear and accessible 
      communication, with oversight from medical professionals to ensure accuracy and 
      appropriateness. Further research comparing ChatGPT's performance with other AI 
      models could enhance its application in patient education across medical 
      specialties.
CI  - Copyright © 2024, Sarikonda et al.
FAU - Sarikonda, Advith
AU  - Sarikonda A
AD  - Department of Neurological Surgery, Thomas Jefferson University, Philadelphia, 
      USA.
FAU - Abishek, Robert
AU  - Abishek R
AD  - Department of Neurological Surgery, Thomas Jefferson University, Philadelphia, 
      USA.
FAU - Isch, Emily L
AU  - Isch EL
AD  - Department of General Surgery, Division of Plastic Surgery, Thomas Jefferson 
      University Hospital, Philadelphia, USA.
FAU - Momin, Arbaz A
AU  - Momin AA
AD  - Department of Neurological Surgery, Thomas Jefferson University Hospital, 
      Philadelphia, USA.
FAU - Self, Mitchell
AU  - Self M
AD  - Department of Neurological Surgery, Thomas Jefferson University Hospital, 
      Philadelphia, USA.
FAU - Sambangi, Abhijeet
AU  - Sambangi A
AD  - Department of Neurological Surgery, Thomas Jefferson University, Philadelphia, 
      USA.
FAU - Carreras, Angeleah
AU  - Carreras A
AD  - Department of Neurological Surgery, Thomas Jefferson University, Philadelphia, 
      USA.
FAU - Jallo, Jack
AU  - Jallo J
AD  - Department of Neurosurgery, Thomas Jefferson Medical College, Philadelphia, USA.
FAU - Harrop, Jim
AU  - Harrop J
AD  - Department of Neurological Surgery, Thomas Jefferson University Hospital, 
      Philadelphia, USA.
FAU - Sivaganesan, Ahilan
AU  - Sivaganesan A
AD  - Department of Neurological Surgery, Thomas Jefferson University Hospital, 
      Philadelphia, USA.
LA  - eng
PT  - Journal Article
DEP - 20241008
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11548952
OTO - NOTNLM
OT  - ai
OT  - chatgpt
OT  - minimally invasive spine surgery
OT  - patient education
OT  - readability
COIS- Human subjects: All authors have confirmed that this study did not involve human 
      participants or tissue. Animal subjects: All authors have confirmed that this 
      study did not involve animal subjects or tissue. Conflicts of interest: In 
      compliance with the ICMJE uniform disclosure form, all authors declare the 
      following: Payment/services info: All authors have declared that no financial 
      support was received from any organization for the submitted work. Financial 
      relationships: All authors have declared that they have no financial 
      relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2024/11/14 03:55
MHDA- 2024/11/14 03:56
PMCR- 2024/10/08
CRDT- 2024/11/11 05:37
PHST- 2024/10/08 00:00 [accepted]
PHST- 2024/11/14 03:56 [medline]
PHST- 2024/11/14 03:55 [pubmed]
PHST- 2024/11/11 05:37 [entrez]
PHST- 2024/10/08 00:00 [pmc-release]
AID - 10.7759/cureus.71105 [doi]
PST - epublish
SO  - Cureus. 2024 Oct 8;16(10):e71105. doi: 10.7759/cureus.71105. eCollection 2024 
      Oct.

PMID- 39470681
OWN - NLM
STAT- Publisher
LR  - 20241029
IS  - 1096-9098 (Electronic)
IS  - 0022-4790 (Linking)
DP  - 2024 Oct 29
TI  - Assessment of Artificial Intelligence Chatbot Responses to Common Patient 
      Questions on Bone Sarcoma.
LID - 10.1002/jso.27966 [doi]
AB  - BACKGROUND AND OBJECTIVES: The potential impacts of artificial intelligence (AI) 
      chatbots on care for patients with bone sarcoma is poorly understood. Elucidating 
      potential risks and benefits would allow surgeons to define appropriate roles for 
      these tools in clinical care. METHODS: Eleven questions on bone sarcoma 
      diagnosis, treatment, and recovery were inputted into three AI chatbots. Answers 
      were assessed on a 5-point Likert scale for five clinical accuracy metrics: 
      relevance to the question, balance and lack of bias, basis on established data, 
      factual accuracy, and completeness in scope. Responses were quantitatively 
      assessed for empathy and readability. The Patient Education Materials Assessment 
      Tool (PEMAT) was assessed for understandability and actionability. RESULTS: 
      Chatbots scored highly on relevance (4.24) and balance/lack of bias (4.09) but 
      lower on basing responses on established data (3.77), completeness (3.68), and 
      factual accuracy (3.66). Responses generally scored well on understandability 
      (84.30%), while actionability scores were low for questions on treatment (64.58%) 
      and recovery (60.64%). GPT-4 exhibited the highest empathy (4.12). Readability 
      scores averaged between 10.28 for diagnosis questions to 11.65 for recovery 
      questions. CONCLUSIONS: While AI chatbots are promising tools, current 
      limitations in factual accuracy and completeness, as well as concerns of 
      inaccessibility to populations with lower health literacy, may significantly 
      limit their clinical utility.
CI  - © 2024 The Author(s). Journal of Surgical Oncology published by Wiley Periodicals 
      LLC.
FAU - Khabaz, Kameel
AU  - Khabaz K
AUID- ORCID: 0000-0002-3164-6133
AD  - David Geffen School of Medicine at UCLA, Los Angeles, California, USA.
FAU - Newman-Hung, Nicole J
AU  - Newman-Hung NJ
AD  - Department of Orthopaedic Surgery, University of California, Los Angeles, 
      California, USA.
FAU - Kallini, Jennifer R
AU  - Kallini JR
AD  - Department of Orthopaedic Surgery, University of California, Los Angeles, 
      California, USA.
FAU - Kendal, Joseph
AU  - Kendal J
AD  - Department of Surgery, University of Calgary, Calgary, Alberta, Canada.
FAU - Christ, Alexander B
AU  - Christ AB
AD  - Department of Orthopaedic Surgery, University of California, Los Angeles, 
      California, USA.
FAU - Bernthal, Nicholas M
AU  - Bernthal NM
AUID- ORCID: 0000-0003-3338-5878
AD  - Department of Orthopaedic Surgery, University of California, Los Angeles, 
      California, USA.
FAU - Wessel, Lauren E
AU  - Wessel LE
AUID- ORCID: 0000-0002-6240-5981
AD  - Department of Orthopaedic Surgery, University of California, Los Angeles, 
      California, USA.
LA  - eng
GR  - The authors received no specific funding for this work./
PT  - Journal Article
DEP - 20241029
PL  - United States
TA  - J Surg Oncol
JT  - Journal of surgical oncology
JID - 0222643
SB  - IM
OTO - NOTNLM
OT  - Ewing sarcoma
OT  - artificial intelligence
OT  - bone sarcomas
OT  - chatbots
OT  - chondrosarcoma
OT  - osteosarcoma
EDAT- 2024/10/29 12:26
MHDA- 2024/10/29 12:26
CRDT- 2024/10/29 11:43
PHST- 2024/10/04 00:00 [revised]
PHST- 2024/07/31 00:00 [received]
PHST- 2024/10/12 00:00 [accepted]
PHST- 2024/10/29 12:26 [medline]
PHST- 2024/10/29 12:26 [pubmed]
PHST- 2024/10/29 11:43 [entrez]
AID - 10.1002/jso.27966 [doi]
PST - aheadofprint
SO  - J Surg Oncol. 2024 Oct 29. doi: 10.1002/jso.27966.

PMID- 39438057
OWN - NLM
STAT- MEDLINE
DCOM- 20241204
LR  - 20241205
IS  - 1535-5675 (Electronic)
IS  - 0091-4916 (Linking)
VI  - 52
IP  - 4
DP  - 2024 Dec 4
TI  - Gender and Ethnicity Bias of Text-to-Image Generative Artificial Intelligence in 
      Medical Imaging, Part 1: Preliminary Evaluation.
PG  - 356-359
LID - 10.2967/jnmt.124.268332 [doi]
AB  - Generative artificial intelligence (AI) text-to-image production could reinforce 
      or amplify gender and ethnicity biases. Several text-to-image generative AI tools 
      are used for producing images that represent the medical imaging professions. 
      White male stereotyping and masculine cultures can dissuade women and ethnically 
      divergent people from being drawn into a profession. Methods: In March 2024, 
      DALL-E 3, Firefly 2, Stable Diffusion 2.1, and Midjourney 5.2 were utilized to 
      generate a series of individual and group images of medical imaging 
      professionals: radiologist, nuclear medicine physician, radiographer, and nuclear 
      medicine technologist. Multiple iterations of images were generated using a 
      variety of prompts. Collectively, 184 images were produced for evaluation of 391 
      characters. All images were independently analyzed by 3 reviewers for apparent 
      gender and skin tone. Results: Collectively (individual and group characters) (n 
      = 391), 60.6% were male and 87.7% were of a light skin tone. DALL-E 3 (65.6%), 
      Midjourney 5.2 (76.7%), and Stable Diffusion 2.1 (56.2%) had a statistically 
      higher representation of men than Firefly 2 (42.9%) (P < 0.0001). With Firefly 2, 
      70.3% of characters had light skin tones, which was statistically lower (P < 
      0.0001) than for Stable Diffusion 2.1 (84.8%), Midjourney 5.2 (100%), and DALL-E 
      3 (94.8%). Overall, image quality metrics were average or better in 87.2% for 
      DALL-E 3 and 86.2% for Midjourney 5.2, whereas 50.9% were inadequate or poor for 
      Firefly 2 and 86.0% for Stable Diffusion 2.1. Conclusion: Generative AI 
      text-to-image generation using DALL-E 3 via GPT-4 has the best overall quality 
      compared with Firefly 2, Midjourney 5.2, and Stable Diffusion 2.1. Nonetheless, 
      DALL-E 3 includes inherent biases associated with gender and ethnicity that 
      demand more critical evaluation.
CI  - © 2024 by the Society of Nuclear Medicine and Molecular Imaging.
FAU - Currie, Geoffrey
AU  - Currie G
AD  - Charles Sturt University, Wagga Wagga, New South Wales, Australia; 
      gcurrie@csu.edu.au.
AD  - Baylor College of Medicine, Houston, Texas.
FAU - Hewis, Johnathan
AU  - Hewis J
AD  - Charles Sturt University, Port Macquarie, New South Wales, Australia; and.
FAU - Hawk, Elizabeth
AU  - Hawk E
AD  - Stanford University, Stanford, California.
FAU - Rohren, Eric
AU  - Rohren E
AD  - Charles Sturt University, Wagga Wagga, New South Wales, Australia.
AD  - Baylor College of Medicine, Houston, Texas.
LA  - eng
PT  - Journal Article
DEP - 20241204
PL  - United States
TA  - J Nucl Med Technol
JT  - Journal of nuclear medicine technology
JID - 0430303
SB  - IM
MH  - Humans
MH  - Male
MH  - Female
MH  - *Artificial Intelligence
MH  - Diagnostic Imaging/methods
MH  - Sexism
MH  - Ethnicity
MH  - Image Processing, Computer-Assisted/methods
OTO - NOTNLM
OT  - diversity
OT  - generative artificial intelligence
OT  - inclusivity
OT  - nuclear medicine
OT  - radiology
EDAT- 2024/10/23 04:22
MHDA- 2024/12/05 05:31
CRDT- 2024/10/22 20:53
PHST- 2024/07/04 00:00 [received]
PHST- 2024/09/18 00:00 [accepted]
PHST- 2024/12/05 05:31 [medline]
PHST- 2024/10/23 04:22 [pubmed]
PHST- 2024/10/22 20:53 [entrez]
AID - jnmt.124.268332 [pii]
AID - 10.2967/jnmt.124.268332 [doi]
PST - epublish
SO  - J Nucl Med Technol. 2024 Dec 4;52(4):356-359. doi: 10.2967/jnmt.124.268332.

PMID- 39207784
OWN - NLM
STAT- MEDLINE
DCOM- 20241014
LR  - 20241023
IS  - 1938-3800 (Electronic)
IS  - 0742-3225 (Print)
IS  - 0742-3225 (Linking)
VI  - 56
IP  - 9
DP  - 2024 Oct
TI  - Generative Artificial Intelligence and Large Language Models in Primary Care 
      Medical Education.
PG  - 534-540
LID - 10.22454/FamMed.2024.775525 [doi]
AB  - Generative artificial intelligence and large language models are the continuation 
      of a technological revolution in information processing that began with the 
      invention of the transistor in 1947. These technologies, driven by transformer 
      architectures for artificial neural networks, are poised to broadly influence 
      society. It is already apparent that these technologies will be adapted to drive 
      innovation in education. Medical education is a high-risk activity: Information 
      that is incorrectly taught to a student may go unrecognized for years until a 
      relevant clinical situation appears in which that error can lead to patient harm. 
      In this article, I discuss the principal limitations to the use of generative 
      artificial intelligence in medical education-hallucination, bias, cost, and 
      security-and suggest some approaches to confronting these problems. Additionally, 
      I identify the potential applications of generative artificial intelligence to 
      medical education, including personalized instruction, simulation, feedback, 
      evaluation, augmentation of qualitative research, and performance of critical 
      assessment of the existing scientific literature.
FAU - Parente, Daniel J
AU  - Parente DJ
AD  - Department of Family Medicine and Community Health, University of Kansas Medical 
      Center, Kansas City, KS.
LA  - eng
PT  - Journal Article
DEP - 20240808
PL  - United States
TA  - Fam Med
JT  - Family medicine
JID - 8306464
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Education, Medical/methods
MH  - *Primary Health Care
MH  - Neural Networks, Computer
PMC - PMC11493110
EDAT- 2024/08/31 09:52
MHDA- 2024/10/14 19:00
PMCR- 2024/08/08
CRDT- 2024/08/29 11:34
PHST- 2024/10/14 19:00 [medline]
PHST- 2024/08/31 09:52 [pubmed]
PHST- 2024/08/29 11:34 [entrez]
PHST- 2024/08/08 00:00 [pmc-release]
AID - 10.22454/FamMed.2024.775525 [doi]
PST - ppublish
SO  - Fam Med. 2024 Oct;56(9):534-540. doi: 10.22454/FamMed.2024.775525. Epub 2024 Aug 
      8.

PMID- 38913203
OWN - NLM
STAT- Publisher
LR  - 20240624
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
DP  - 2024 Jun 24
TI  - Exploring the Unknown: Evaluating ChatGPT's Performance in Uncovering Novel 
      Aspects of Plastic Surgery and Identifying Areas for Future Innovation.
LID - 10.1007/s00266-024-04200-0 [doi]
AB  - We have perused with keen interest the scholarly article titled "Exploring the 
      Unknown: Evaluating ChatGPT's Performance in Uncovering Novel Aspects of Plastic 
      Surgery and Identifying Areas for Future Innovation" penned by Lim et al. in the 
      esteemed journal "Aesthetic Plastic Surgery". This paper evaluates ChatGPT's 
      potential application in plastic surgery, exploring its responses on various 
      themes including pioneers, advancements, and techniques, as well as flap 
      grafting. While it offers valuable insights, questions arise. Firstly, ChatGPT's 
      attribution of plastic surgery's progenitor to Sir Harold Delf Gillies raises 
      concerns of underlying biases in its responses. Secondly, its assertion on 
      paramount contributions prompts reflection on its discernment criteria. Can 
      targeted training enhance its accuracy? Lastly, the discourse questions biases 
      favoring reconstructive over cosmetic procedures. ChatGPT's responses, while 
      proficient in addressing medical queries, face ongoing veracity challenges, 
      necessitating clinician scrutiny. However, this scrutiny may surpass user 
      expertise, requiring additional measures for accuracy assurance. Artificial 
      Intelligence (AI) replicates human cognitive abilities but lacks human richness, 
      potentially affecting transformative insights in plastic surgery's future 
      trajectory. LEVEL OF EVIDENCE V: This journal requires that authors assign a 
      level of evidence to each article. For a full description of these Evidence-Based 
      Medicine ratings, please refer to the Table of Contents or the online 
      Instructions to Authors www.springer.com/00266 .
CI  - © 2024. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Qi, Weikun
AU  - Qi W
AD  - Department of comprehensive plastic surgery, Chinese Academy of Medical Sciences 
      & Peking Union Medical College Plastic Surgery Hospital and Institute, Beijing, 
      100144, China.
FAU - Niu, Feng
AU  - Niu F
AUID- ORCID: 0000-0003-4734-8832
AD  - Department of comprehensive plastic surgery, Chinese Academy of Medical Sciences 
      & Peking Union Medical College Plastic Surgery Hospital and Institute, Beijing, 
      100144, China. niufeng@psh.pumc.edu.cn.
LA  - eng
GR  - 2021-I2M-1-068/Chinese Academy of Medical Sciences Innovation Fund for Medical 
      Sciences/
PT  - Letter
DEP - 20240624
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
EDAT- 2024/06/24 12:42
MHDA- 2024/06/24 12:42
CRDT- 2024/06/24 11:15
PHST- 2024/05/10 00:00 [received]
PHST- 2024/06/06 00:00 [accepted]
PHST- 2024/06/24 12:42 [medline]
PHST- 2024/06/24 12:42 [pubmed]
PHST- 2024/06/24 11:15 [entrez]
AID - 10.1007/s00266-024-04200-0 [pii]
AID - 10.1007/s00266-024-04200-0 [doi]
PST - aheadofprint
SO  - Aesthetic Plast Surg. 2024 Jun 24. doi: 10.1007/s00266-024-04200-0.

PMID- 38175720
OWN - NLM
STAT- MEDLINE
DCOM- 20240219
LR  - 20240219
IS  - 1536-5166 (Electronic)
IS  - 1070-8022 (Linking)
VI  - 44
IP  - 1
DP  - 2024 Mar 1
TI  - Utility of ChatGPT for Automated Creation of Patient Education Handouts: An 
      Application in Neuro-Ophthalmology.
PG  - 119-124
LID - 10.1097/WNO.0000000000002074 [doi]
AB  - BACKGROUND: Patient education in ophthalmology poses a challenge for physicians 
      because of time and resource limitations. ChatGPT (OpenAI, San Francisco) may 
      assist with automating production of patient handouts on common neuro-ophthalmic 
      diseases. METHODS: We queried ChatGPT-3.5 to generate 51 patient education 
      handouts across 17 conditions. We devised the "Quality of Generated Language 
      Outputs for Patients" (QGLOP) tool to assess handouts on the domains of 
      accuracy/comprehensiveness, bias, currency, and tone, each scored out of 4 for a 
      total of 16. A fellowship-trained neuro-ophthalmologist scored each passage. 
      Handout readability was assessed using the Simple Measure of Gobbledygook (SMOG), 
      which estimates years of education required to understand a text. RESULTS: The 
      QGLOP scores for accuracy, bias, currency, and tone were found to be 2.43, 3, 
      3.43, and 3.02 respectively. The mean QGLOP score was 11.9 [95% CI 8.98, 14.8] 
      out of 16 points, indicating a performance of 74.4% [95% CI 56.1%, 92.5%]. The 
      mean SMOG across responses as 10.9 [95% CI 9.36, 12.4] years of education. 
      CONCLUSIONS: The mean QGLOP score suggests that a fellowship-trained 
      ophthalmologist may have at-least a moderate level of satisfaction with the 
      write-up quality conferred by ChatGPT. This still requires a final review and 
      editing before dissemination. Comparatively, the rarer 5% of responses 
      collectively on either extreme would require very mild or extensive revision. 
      Also, the mean SMOG score exceeded the accepted upper limits of grade 8 reading 
      level for health-related patient handouts. In its current iteration, ChatGPT 
      should be used as an efficiency tool to generate an initial draft for the 
      neuro-ophthalmologist, who may then refine the accuracy and readability for a lay 
      readership.
CI  - Copyright © 2024 by North American Neuro-Ophthalmology Society.
FAU - Tao, Brendan K
AU  - Tao BK
AD  - Faculty of Medicine (BKT), The University of British Columbia, Vancouver, Canada 
      ; Department of Ophthalmology & Vision Science (AH, EAM, JAM), University of 
      Toronto, Toronto, Canada; Temerty Faculty of Medicine (NJH), University of 
      Toronto, Toronto, Canada; Department of Ophthalmology (ARV), Max Rady College of 
      Medicine, University of Manitoba, Winnipeg, Canada; Mount Sinai Hospital (EAM), 
      Toronto, Canada; Division of Neurology (EAM, JAM), Department of Medicine, 
      University of Toronto, Toronto, Canada; Toronto Western Hospital (EAM, JAM), 
      Toronto, Canada; University Health Network (EAM, JAM), Toronto, Canada; 
      Kensington Vision and Research Center (JAM), Toronto, Canada; and St. Michael's 
      Hospital (JAM), Toronto, Canada.
FAU - Handzic, Armin
AU  - Handzic A
FAU - Hua, Nicholas J
AU  - Hua NJ
FAU - Vosoughi, Amir R
AU  - Vosoughi AR
FAU - Margolin, Edward A
AU  - Margolin EA
FAU - Micieli, Jonathan A
AU  - Micieli JA
AUID- ORCID: 0000-0003-4947-9772
LA  - eng
PT  - Journal Article
DEP - 20240104
PL  - United States
TA  - J Neuroophthalmol
JT  - Journal of neuro-ophthalmology : the official journal of the North American 
      Neuro-Ophthalmology Society
JID - 9431308
RN  - 0 (Smog)
SB  - IM
MH  - Humans
MH  - *Ophthalmology
MH  - Smog
MH  - Patient Education as Topic
MH  - Fellowships and Scholarships
MH  - *Neurology
COIS- The authors report no conflicts of interest.
EDAT- 2024/01/04 12:41
MHDA- 2024/02/19 06:42
CRDT- 2024/01/04 12:04
PHST- 2024/02/19 06:42 [medline]
PHST- 2024/01/04 12:41 [pubmed]
PHST- 2024/01/04 12:04 [entrez]
AID - 00041327-990000000-00547 [pii]
AID - 10.1097/WNO.0000000000002074 [doi]
PST - ppublish
SO  - J Neuroophthalmol. 2024 Mar 1;44(1):119-124. doi: 10.1097/WNO.0000000000002074. 
      Epub 2024 Jan 4.

PMID- 37610808
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230909
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Aug 23
TI  - Can AI Mitigate Bias in Writing Letters of Recommendation?
PG  - e51494
LID - 10.2196/51494 [doi]
LID - e51494
AB  - Letters of recommendation play a significant role in higher education and career 
      progression, particularly for women and underrepresented groups in medicine and 
      science. Already, there is evidence to suggest that written letters of 
      recommendation contain language that expresses implicit biases, or unconscious 
      biases, and that these biases occur for all recommenders regardless of the 
      recommender's sex. Given that all individuals have implicit biases that may 
      influence language use, there may be opportunities to apply contemporary 
      technologies, such as large language models or other forms of generative 
      artificial intelligence (AI), to augment and potentially reduce implicit biases 
      in the written language of letters of recommendation. In this editorial, we 
      provide a brief overview of existing literature on the manifestations of implicit 
      bias in letters of recommendation, with a focus on academia and medical 
      education. We then highlight potential opportunities and drawbacks of applying 
      this emerging technology in augmenting the focused, professional task of writing 
      letters of recommendation. We also offer best practices for integrating their use 
      into the routine writing of letters of recommendation and conclude with our 
      outlook for the future of generative AI applications in supporting this task.
CI  - ©Tiffany I Leung, Ankita Sagar, Swati Shroff, Tracey L Henry. Originally 
      published in JMIR Medical Education (https://mededu.jmir.org), 23.08.2023.
FAU - Leung, Tiffany I
AU  - Leung TI
AUID- ORCID: 0000-0002-6007-4023
AD  - Department of Internal Medicine (adjunct), Southern Illinois University School of 
      Medicine, Toronto, ON, Canada.
AD  - JMIR Publications, Toronto, ON, Canada.
FAU - Sagar, Ankita
AU  - Sagar A
AUID- ORCID: 0000-0002-4558-4500
AD  - CommonSpirit Health, Chicago, IL, United States.
AD  - Creighton University School of Medicine, Omaha, NE, United States.
FAU - Shroff, Swati
AU  - Shroff S
AUID- ORCID: 0000-0002-8948-6259
AD  - Division of Internal Medicine, Thomas Jefferson University, Philadelphia, PA, 
      United States.
FAU - Henry, Tracey L
AU  - Henry TL
AUID- ORCID: 0000-0003-3538-094X
AD  - Department of Medicine, Emory University School of Medicine, Atlanta, GA, United 
      States.
LA  - eng
PT  - Editorial
DEP - 20230823
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10483302
OTO - NOTNLM
OT  - artificial intelligence
OT  - bias
OT  - career advancement
OT  - gender bias
OT  - implicit bias
OT  - large language models
OT  - leadership
OT  - letters of recommendation
OT  - medical education
OT  - promotion
OT  - sponsorship
OT  - tenure and promotion
COIS- Conflicts of Interest: TIL is the scientific editorial director for JMIR 
      Publications.
EDAT- 2023/08/23 12:43
MHDA- 2023/08/23 12:44
PMCR- 2023/08/23
CRDT- 2023/08/23 11:53
PHST- 2023/08/02 00:00 [received]
PHST- 2023/08/08 00:00 [accepted]
PHST- 2023/08/08 00:00 [revised]
PHST- 2023/08/23 12:44 [medline]
PHST- 2023/08/23 12:43 [pubmed]
PHST- 2023/08/23 11:53 [entrez]
PHST- 2023/08/23 00:00 [pmc-release]
AID - v9i1e51494 [pii]
AID - 10.2196/51494 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Aug 23;9:e51494. doi: 10.2196/51494.

PMID- 37279048
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230701
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Jun 6
TI  - The Advent of Generative Language Models in Medical Education.
PG  - e48163
LID - 10.2196/48163 [doi]
LID - e48163
AB  - Artificial intelligence (AI) and generative language models (GLMs) present 
      significant opportunities for enhancing medical education, including the 
      provision of realistic simulations, digital patients, personalized feedback, 
      evaluation methods, and the elimination of language barriers. These advanced 
      technologies can facilitate immersive learning environments and enhance medical 
      students' educational outcomes. However, ensuring content quality, addressing 
      biases, and managing ethical and legal concerns present obstacles. To mitigate 
      these challenges, it is necessary to evaluate the accuracy and relevance of 
      AI-generated content, address potential biases, and develop guidelines and 
      policies governing the use of AI-generated content in medical education. 
      Collaboration among educators, researchers, and practitioners is essential for 
      developing best practices, guidelines, and transparent AI models that encourage 
      the ethical and responsible use of GLMs and AI in medical education. By sharing 
      information about the data used for training, obstacles encountered, and 
      evaluation methods, developers can increase their credibility and trustworthiness 
      within the medical community. In order to realize the full potential of AI and 
      GLMs in medical education while mitigating potential risks and obstacles, ongoing 
      research and interdisciplinary collaboration are necessary. By collaborating, 
      medical professionals can ensure that these technologies are effectively and 
      responsibly integrated, contributing to enhanced learning experiences and patient 
      care.
CI  - ©Mert Karabacak, Burak Berksu Ozkara, Konstantinos Margetis, Max Wintermark, 
      Sotirios Bisdas. Originally published in JMIR Medical Education 
      (https://mededu.jmir.org), 06.06.2023.
FAU - Karabacak, Mert
AU  - Karabacak M
AUID- ORCID: 0000-0002-9263-9893
AD  - Department of Neurosurgery, Mount Sinai Health System, New York, NY, United 
      States.
FAU - Ozkara, Burak Berksu
AU  - Ozkara BB
AUID- ORCID: 0000-0002-8769-3342
AD  - Department of Neuroradiology, MD Anderson Cancer Center, Houston, TX, United 
      States.
FAU - Margetis, Konstantinos
AU  - Margetis K
AUID- ORCID: 0000-0002-3715-8093
AD  - Department of Neurosurgery, Mount Sinai Health System, New York, NY, United 
      States.
FAU - Wintermark, Max
AU  - Wintermark M
AUID- ORCID: 0000-0002-6726-3951
AD  - Department of Neuroradiology, MD Anderson Cancer Center, Houston, TX, United 
      States.
FAU - Bisdas, Sotirios
AU  - Bisdas S
AUID- ORCID: 0000-0001-9930-5549
AD  - Department of Neuroradiology, MD Anderson Cancer Center, Houston, TX, United 
      States.
AD  - Department of Neuroradiology, The National Hospital for Neurology and 
      Neurosurgery, University College London NHS Foundation Trust, London, United 
      Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20230606
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10282912
OTO - NOTNLM
OT  - AI-driven feedback
OT  - ChatGPT
OT  - academic integrity
OT  - artificial intelligence
OT  - evaluation
OT  - generative language model
OT  - learning environment
OT  - medical education
OT  - medical student
OT  - stimulation
OT  - technology
COIS- Conflicts of Interest: None declared.
EDAT- 2023/06/06 13:09
MHDA- 2023/06/06 13:10
PMCR- 2023/06/06
CRDT- 2023/06/06 11:53
PHST- 2023/04/13 00:00 [received]
PHST- 2023/05/24 00:00 [accepted]
PHST- 2023/05/22 00:00 [revised]
PHST- 2023/06/06 13:10 [medline]
PHST- 2023/06/06 13:09 [pubmed]
PHST- 2023/06/06 11:53 [entrez]
PHST- 2023/06/06 00:00 [pmc-release]
AID - v9i1e48163 [pii]
AID - 10.2196/48163 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Jun 6;9:e48163. doi: 10.2196/48163.

PMID- 39722800
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 0974-3227 (Print)
IS  - 0974-6897 (Electronic)
IS  - 0974-3227 (Linking)
VI  - 17
IP  - 1
DP  - 2025 Jan
TI  - Gender and racial diversity Assumed by text-to-image generators in microsurgery 
      and plastic surgery-related subspecialities.
PG  - 100196
LID - 10.1016/j.jham.2024.100196 [doi]
LID - 100196
AB  - BACKGROUND: Since the release of ChatGPT by OpenAI in November 2022, generative 
      artificial intelligence (AI) models have attracted significant attention in 
      various fields, including surgery. These advancements have been particularly 
      notable for creating highly detailed and contextually accurate images from 
      textual prompts. A notable area of clinical application is the representation of 
      surgeon demographics in various specialties, particularly in the context of 
      microsurgery and plastic surgery-related subspecialties. METHODS: This 
      cross-sectional study, conducted in June 2024, utilized the latest version of the 
      Copilot Creative Mode powered by DALL-E 3 to generate images of surgeons across 
      various plastic surgery subspecialties. Real-world demographic data from the US, 
      Japan, and Zambia were compared with AI-generated images for an accurate 
      representation analysis. RESULTS: Five hundred images (350 from various 
      subspecialties and 150 from geographical sources) were analyzed. The AI model 
      predominantly generated images of male and female surgeons with a statistical 
      underrepresentation of female and Black microsurgeons. Geographical prompts 
      influenced the representation, with an overrepresentation of female (64.0 %; 
      p < 0.001) and Black (16.0 %; p < 0.001) plastic surgeons in the US and 
      exclusively Asian surgeons in Japan. Discrepancies were also observed in the 
      depiction of surgical equipment, with the majority of AI-generated microsurgeons 
      inaccurately portrayed using either surgical loupes (46.0 %) or optical 
      microscopes (32.0 %), not with surgical microscopes (4.0 %). CONCLUSIONS: This 
      study revealed significant disparities between AI-generated images and actual 
      demographics in the fields of microsurgery and plastic surgery-related 
      subspecialties, highlighting the need for more diverse and accurate training 
      datasets for AI models.
CI  - © 2024 Society for Indian Hand Surgery and Micro Surgeons. Published by Elsevier 
      B.V. All rights are reserved, including those for text and data mining, AI 
      training, and similar technologies.
FAU - Shiraishi, Makoto
AU  - Shiraishi M
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Banda, Chihena Hansini
AU  - Banda CH
AD  - Plastic and Reconstructive Surgery Unit, Department of Surgery, The University 
      Teaching Hospital, Lusaka, Zambia.
FAU - Nakajima, Mayuri
AU  - Nakajima M
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Nakazwe, Mildred
AU  - Nakazwe M
AD  - Plastic and Reconstructive Surgery Unit, Department of Surgery, The University 
      Teaching Hospital, Lusaka, Zambia.
FAU - Wong, Zi Yi
AU  - Wong ZY
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
AD  - Yong Loo Lin School of Medicine, National University of Singapore, Singapore, 
      Singapore.
FAU - Tomioka, Yoko
AU  - Tomioka Y
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Moriwaki, Yuta
AU  - Moriwaki Y
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Takeishi, Hakuba
AU  - Takeishi H
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Lee, Haesu
AU  - Lee H
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Kurita, Daichi
AU  - Kurita D
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Furuse, Kiichi
AU  - Furuse K
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Ohba, Jun
AU  - Ohba J
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Fujisawa, Kou
AU  - Fujisawa K
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Miyamoto, Shimpei
AU  - Miyamoto S
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
FAU - Okazaki, Mutsumi
AU  - Okazaki M
AD  - Department of Plastic and Reconstructive Surgery, The University of Tokyo 
      Hospital, Tokyo, Japan.
LA  - eng
PT  - Journal Article
DEP - 20241130
PL  - Netherlands
TA  - J Hand Microsurg
JT  - Journal of hand and microsurgery
JID - 101498171
PMC - PMC11666935
OTO - NOTNLM
OT  - DALL-E 3
OT  - Gender
OT  - Generative artificial intelligence
OT  - Microsurgery
OT  - Race
COIS- The authors declare that they have no known competing financial interests or 
      personal relationships that could have appeared to influence the work reported in 
      this paper.
EDAT- 2024/12/26 16:51
MHDA- 2024/12/26 16:52
PMCR- 2025/11/30
CRDT- 2024/12/26 04:12
PHST- 2024/10/27 00:00 [received]
PHST- 2024/11/22 00:00 [revised]
PHST- 2024/11/29 00:00 [accepted]
PHST- 2025/11/30 00:00 [pmc-release]
PHST- 2024/12/26 16:52 [medline]
PHST- 2024/12/26 16:51 [pubmed]
PHST- 2024/12/26 04:12 [entrez]
AID - S0974-3227(24)00558-1 [pii]
AID - 100196 [pii]
AID - 10.1016/j.jham.2024.100196 [doi]
PST - epublish
SO  - J Hand Microsurg. 2024 Nov 30;17(1):100196. doi: 10.1016/j.jham.2024.100196. 
      eCollection 2025 Jan.

PMID- 39673022
OWN - NLM
STAT- Publisher
LR  - 20241213
IS  - 1543-0154 (Electronic)
IS  - 0885-8195 (Linking)
DP  - 2024 Dec 14
TI  - Utility of Chatbot Literature Search in Radiation Oncology.
LID - 10.1007/s13187-024-02547-1 [doi]
AB  - Artificial intelligence and natural language processing tools have shown promise 
      in oncology by assisting with medical literature retrieval and providing patient 
      support. The potential for these technologies to generate inaccurate yet 
      seemingly correct information poses significant challenges. This study evaluates 
      the effectiveness, benefits, and limitations of ChatGPT for clinical use in 
      conducting literature reviews of radiation oncology treatments. This 
      cross-sectional study used ChatGPT version 3.5 to generate literature searches on 
      radiotherapy options for seven tumor sites, with prompts issued five times per 
      site to generate up to 50 publications per tumor type. The publications were 
      verified using the Scopus database and categorized as correct, irrelevant, or 
      non-existent. Statistical analysis with one-way ANOVA compared the impact factors 
      and citation counts across different tumor sites. Among the 350 publications 
      generated, there were 44 correct, 298 non-existent, and 8 irrelevant papers. The 
      average publication year of all generated papers was 2011, compared to 2009 for 
      the correct papers. The average impact factor of all generated papers was 38.8, 
      compared to 113.8 for the correct papers. There were significant differences in 
      the publication year, impact factor, and citation counts between tumor sites for 
      both correct and non-existent papers. Our study highlights both the potential 
      utility and significant limitations of using AI, specifically ChatGPT 3.5, in 
      radiation oncology literature reviews. The findings emphasize the need for 
      verification of AI outputs, development of standardized quality assurance 
      protocols, and continued research into AI biases to ensure reliable integration 
      into clinical practice.
CI  - © 2024. The Author(s) under exclusive licence to American Association for Cancer 
      Education.
FAU - Wong, Justina
AU  - Wong J
AUID- ORCID: 0000-0003-1199-1973
AD  - Faculty of Medicine and Dentistry, University of Alberta, Edmonton, AB, Canada.
FAU - Kriegler, Conley
AU  - Kriegler C
AUID- ORCID: 0000-0002-9643-8976
AD  - Division of Radiation Oncology, Department of Oncology, University of Alberta, 
      Cross Cancer Institute, 11560 University Ave, Edmonton, AB, T6G 1Z2, Canada.
FAU - Shrivastava, Ananya
AU  - Shrivastava A
AD  - Faculty of Medicine and Dentistry, University of Alberta, Edmonton, AB, Canada.
FAU - Duimering, Adele
AU  - Duimering A
AUID- ORCID: 0000-0002-6891-6619
AD  - Division of Radiation Oncology, Department of Oncology, University of Alberta, 
      Cross Cancer Institute, 11560 University Ave, Edmonton, AB, T6G 1Z2, Canada.
FAU - Le, Connie
AU  - Le C
AUID- ORCID: 0000-0003-4864-7420
AD  - Division of Radiation Oncology, Department of Oncology, University of Alberta, 
      Cross Cancer Institute, 11560 University Ave, Edmonton, AB, T6G 1Z2, Canada. 
      cle1@ualberta.ca.
LA  - eng
PT  - Journal Article
DEP - 20241214
PL  - England
TA  - J Cancer Educ
JT  - Journal of cancer education : the official journal of the American Association 
      for Cancer Education
JID - 8610343
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cancer
OT  - ChatGPT
OT  - Natural language processing
OT  - Radiation oncology
COIS- Declarations. Conflict of Interest: All authors have completed the ICMJE uniform 
      disclosure form and declare no conflict of interest.
EDAT- 2024/12/14 00:24
MHDA- 2024/12/14 00:24
CRDT- 2024/12/13 23:24
PHST- 2024/11/23 00:00 [accepted]
PHST- 2024/12/14 00:24 [medline]
PHST- 2024/12/14 00:24 [pubmed]
PHST- 2024/12/13 23:24 [entrez]
AID - 10.1007/s13187-024-02547-1 [pii]
AID - 10.1007/s13187-024-02547-1 [doi]
PST - aheadofprint
SO  - J Cancer Educ. 2024 Dec 14. doi: 10.1007/s13187-024-02547-1.

PMID- 39232303
OWN - NLM
STAT- MEDLINE
DCOM- 20241009
LR  - 20241009
IS  - 1878-7452 (Electronic)
IS  - 1878-7452 (Linking)
VI  - 81
IP  - 11
DP  - 2024 Nov
TI  - Bias Perpetuates Bias: ChatGPT Learns Gender Inequities in Academic Surgery 
      Promotions.
PG  - 1553-1557
LID - S1931-7204(24)00346-5 [pii]
LID - 10.1016/j.jsurg.2024.07.023 [doi]
AB  - OBJECTIVE: Gender inequities persist in academic surgery with implicit bias 
      impacting hiring and promotion at all levels. We hypothesized that creating 
      letters of recommendation for both female and male candidates for academic 
      promotion in surgery using an AI platform, ChatGPT, would elucidate the entrained 
      gender biases already present in the promotion process. DESIGN: Using ChatGPT, we 
      generated 6 letters of recommendation for "a phenomenal surgeon applying for job 
      promotion to associate professor position", specifying "female" or "male" before 
      surgeon in the prompt. We compared 3 "female" letters to 3 "male" letters for 
      differences in length, language, and tone. RESULTS: The letters written for 
      females averaged 298 words compared to 314 for males. Female letters more 
      frequently referred to "compassion", "empathy", and "inclusivity"; whereas male 
      letters referred to "respect", "reputation", and "skill". CONCLUSIONS: These 
      findings highlight the gender bias present in promotion letters generated by 
      ChatGPT, reiterating existing literature regarding real letters of recommendation 
      in academic surgery. Our study suggests that surgeons should use AI tools, such 
      as ChatGPT, with caution when writing LORs for academic surgery faculty 
      promotion.
CI  - Copyright © 2024 Association of Program Directors in Surgery. Published by 
      Elsevier Inc. All rights reserved.
FAU - Desai, Pooja
AU  - Desai P
AD  - Department of Surgery, Albany Medical College, Albany NY.
FAU - Wang, Hao
AU  - Wang H
AD  - Department of Surgery, Albany Medical College, Albany NY.
FAU - Davis, Lindy
AU  - Davis L
AD  - Department of Surgery, Albany Medical College, Albany NY.
FAU - Ullmann, Timothy M
AU  - Ullmann TM
AD  - Department of Surgery, Albany Medical College, Albany NY.
FAU - DiBrito, Sandra R
AU  - DiBrito SR
AD  - Department of Surgery, Albany Medical College, Albany NY. Electronic address: 
      dibrits@amc.edu.
LA  - eng
PT  - Journal Article
DEP - 20240903
PL  - United States
TA  - J Surg Educ
JT  - Journal of surgical education
JID - 101303204
SB  - IM
MH  - Female
MH  - Humans
MH  - Male
MH  - *Sexism
MH  - *Faculty, Medical
MH  - General Surgery/education
MH  - Career Mobility
MH  - Personnel Selection
MH  - Correspondence as Topic
OTO - NOTNLM
OT  - ChatGPT
OT  - Gender disparities in medicine
OT  - academic promotions
OT  - artificial intelligence
OT  - implicit bias
OT  - letters of recommendation
EDAT- 2024/09/05 00:50
MHDA- 2024/10/10 00:37
CRDT- 2024/09/04 23:43
PHST- 2024/04/20 00:00 [received]
PHST- 2024/07/08 00:00 [revised]
PHST- 2024/07/28 00:00 [accepted]
PHST- 2024/10/10 00:37 [medline]
PHST- 2024/09/05 00:50 [pubmed]
PHST- 2024/09/04 23:43 [entrez]
AID - S1931-7204(24)00346-5 [pii]
AID - 10.1016/j.jsurg.2024.07.023 [doi]
PST - ppublish
SO  - J Surg Educ. 2024 Nov;81(11):1553-1557. doi: 10.1016/j.jsurg.2024.07.023. Epub 
      2024 Sep 3.

PMID- 39149010
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240817
IS  - 2405-8440 (Print)
IS  - 2405-8440 (Electronic)
IS  - 2405-8440 (Linking)
VI  - 10
IP  - 14
DP  - 2024 Jul 30
TI  - Evaluating the performance of ChatGPT-3.5 and ChatGPT-4 on the Taiwan plastic 
      surgery board examination.
PG  - e34851
LID - 10.1016/j.heliyon.2024.e34851 [doi]
LID - e34851
AB  - BACKGROUND: Chat Generative Pre-Trained Transformer (ChatGPT) is a 
      state-of-the-art large language model that has been evaluated across various 
      medical fields, with mixed performance on licensing examinations. This study 
      aimed to assess the performance of ChatGPT-3.5 and ChatGPT-4 in answering 
      questions from the Taiwan Plastic Surgery Board Examination. METHODS: The study 
      evaluated the performance of ChatGPT-3.5 and ChatGPT-4 on 1375 questions from the 
      past 8 years of the Taiwan Plastic Surgery Board Examination, including 985 
      single-choice and 390 multiple-choice questions. We obtained the responses 
      between June and July 2023, launching a new chat session for each question to 
      eliminate memory retention bias. RESULTS: Overall, ChatGPT-4 outperformed 
      ChatGPT-3.5, achieving a 59 % correct answer rate compared to 41 % for 
      ChatGPT-3.5. ChatGPT-4 passed five out of eight yearly exams, whereas ChatGPT-3.5 
      failed all. On single-choice questions, ChatGPT-4 scored 66 % correct, compared 
      to 48 % for ChatGPT-3.5. On multiple-choice, ChatGPT-4 achieved a 43 % correct 
      rate, nearly double the 23 % of ChatGPT-3.5. CONCLUSION: As ChatGPT evolves, its 
      performance on the Taiwan Plastic Surgery Board Examination is expected to 
      improve further. The study suggests potential reforms, such as incorporating more 
      problem-based scenarios, leveraging ChatGPT to refine exam questions, and 
      integrating AI-assisted learning into candidate preparation. These advancements 
      could enhance the assessment of candidates' critical thinking and problem-solving 
      abilities in the field of plastic surgery.
CI  - © 2024 The Authors.
FAU - Hsieh, Ching-Hua
AU  - Hsieh CH
AD  - Department of Plastic Surgery, Kaohsiung Chang Gung Memorial Hospital, Chang Gung 
      University and College of Medicine, Kaohsiung, 83301, Taiwan.
FAU - Hsieh, Hsiao-Yun
AU  - Hsieh HY
AD  - Department of Plastic Surgery, Kaohsiung Chang Gung Memorial Hospital, Chang Gung 
      University and College of Medicine, Kaohsiung, 83301, Taiwan.
FAU - Lin, Hui-Ping
AU  - Lin HP
AD  - Department of Plastic Surgery, Kaohsiung Chang Gung Memorial Hospital, Chang Gung 
      University and College of Medicine, Kaohsiung, 83301, Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20240718
PL  - England
TA  - Heliyon
JT  - Heliyon
JID - 101672560
PMC - PMC11324965
OTO - NOTNLM
OT  - ChatGPT-3.5
OT  - ChatGPT-4
OT  - Taiwan plastic surgery board examination
COIS- The authors declare the following financial interests/personal relationships 
      which may be considered as potential competing interests:Ching-Hua Hsieh reports 
      a relationship with Kaohsiung Chang Gung Memorial Hospital that includes: funding 
      grants. If there are other authors, they declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/08/16 06:42
MHDA- 2024/08/16 06:43
PMCR- 2024/07/18
CRDT- 2024/08/16 04:31
PHST- 2024/05/23 00:00 [received]
PHST- 2024/06/27 00:00 [revised]
PHST- 2024/07/17 00:00 [accepted]
PHST- 2024/08/16 06:43 [medline]
PHST- 2024/08/16 06:42 [pubmed]
PHST- 2024/08/16 04:31 [entrez]
PHST- 2024/07/18 00:00 [pmc-release]
AID - S2405-8440(24)10882-1 [pii]
AID - e34851 [pii]
AID - 10.1016/j.heliyon.2024.e34851 [doi]
PST - epublish
SO  - Heliyon. 2024 Jul 18;10(14):e34851. doi: 10.1016/j.heliyon.2024.e34851. 
      eCollection 2024 Jul 30.

PMID- 39054373
OWN - NLM
STAT- MEDLINE
DCOM- 20241115
LR  - 20250322
IS  - 1546-170X (Electronic)
IS  - 1078-8956 (Print)
IS  - 1078-8956 (Linking)
VI  - 30
IP  - 11
DP  - 2024 Nov
TI  - Influence of believed AI involvement on the perception of digital medical advice.
PG  - 3098-3100
LID - 10.1038/s41591-024-03180-7 [doi]
AB  - Large language models offer novel opportunities to seek digital medical advice. 
      While previous research primarily addressed the performance of such artificial 
      intelligence (AI)-based tools, public perception of these advancements received 
      little attention. In two preregistered studies (n = 2,280), we presented 
      participants with scenarios of patients obtaining medical advice. All 
      participants received identical information, but we manipulated the putative 
      source of this advice ('AI', 'human physician', 'human + AI'). 'AI'- and 
      'human + AI'-labeled advice was evaluated as significantly less reliable and less 
      empathetic compared with 'human'-labeled advice. Moreover, participants indicated 
      lower willingness to follow the advice when AI was believed to be involved in 
      advice generation. Our findings point toward an anti-AI bias when receiving 
      digital medical advice, even when AI is supposedly supervised by physicians. 
      Given the tremendous potential of AI for medicine, elucidating ways to counteract 
      this bias should be an important objective of future research.
CI  - © 2024. The Author(s).
FAU - Reis, Moritz
AU  - Reis M
AUID- ORCID: 0000-0002-1547-8109
AD  - Institute of Psychology, Julius-Maximilians-Universität Würzburg, Würzburg, 
      Germany. moritz.reis@uni-wuerzburg.de.
AD  - Judge Business School, University of Cambridge, Cambridge, UK. 
      moritz.reis@uni-wuerzburg.de.
FAU - Reis, Florian
AU  - Reis F
AUID- ORCID: 0009-0009-1064-9173
AD  - Medical Affairs, Pfizer Pharma GmbH, Berlin, Germany.
FAU - Kunde, Wilfried
AU  - Kunde W
AUID- ORCID: 0000-0001-6256-8011
AD  - Institute of Psychology, Julius-Maximilians-Universität Würzburg, Würzburg, 
      Germany.
LA  - eng
PT  - Journal Article
DEP - 20240725
PL  - United States
TA  - Nat Med
JT  - Nature medicine
JID - 9502015
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Female
MH  - Male
MH  - Adult
MH  - Middle Aged
MH  - Young Adult
MH  - Perception
MH  - Adolescent
PMC - PMC11564086
COIS- Competing interests F.R. is a current employee of Pfizer Pharma GmbH in Berlin, 
      Germany. Pfizer had no substantive or financial involvement in the conception, 
      implementation or analysis of this study, nor in the creation or publication of 
      the associated paper. The other authors declare no competing interests.
EDAT- 2024/07/26 12:44
MHDA- 2024/11/16 09:58
PMCR- 2024/07/25
CRDT- 2024/07/25 23:19
PHST- 2024/03/05 00:00 [received]
PHST- 2024/07/04 00:00 [accepted]
PHST- 2024/11/16 09:58 [medline]
PHST- 2024/07/26 12:44 [pubmed]
PHST- 2024/07/25 23:19 [entrez]
PHST- 2024/07/25 00:00 [pmc-release]
AID - 10.1038/s41591-024-03180-7 [pii]
AID - 3180 [pii]
AID - 10.1038/s41591-024-03180-7 [doi]
PST - ppublish
SO  - Nat Med. 2024 Nov;30(11):3098-3100. doi: 10.1038/s41591-024-03180-7. Epub 2024 
      Jul 25.

PMID- 39042979
OWN - NLM
STAT- MEDLINE
DCOM- 20240926
LR  - 20240926
IS  - 1095-8673 (Electronic)
IS  - 0022-4804 (Linking)
VI  - 301
DP  - 2024 Sep
TI  - Digital Ink and Surgical Dreams: Perceptions of Artificial Intelligence-Generated 
      Essays in Residency Applications.
PG  - 504-511
LID - S0022-4804(24)00355-X [pii]
LID - 10.1016/j.jss.2024.06.020 [doi]
AB  - INTRODUCTION: Large language models like Chat Generative Pre-Trained Transformer 
      (ChatGPT) are increasingly used in academic writing. Faculty may consider use of 
      artificial intelligence (AI)-generated responses a form of cheating. We sought to 
      determine whether general surgery residency faculty could detect AI versus 
      human-written responses to a text prompt; hypothesizing that faculty would not be 
      able to reliably differentiate AI versus human-written responses. METHODS: Ten 
      essays were generated using a text prompt, "Tell us in 1-2 paragraphs why you are 
      considering the University of Rochester for General Surgery residency" (Current 
      trainees: n = 5, ChatGPT: n = 5). Ten blinded faculty reviewers rated essays 
      (ten-point Likert scale) on the following criteria: desire to interview, 
      relevance to the general surgery residency, overall impression, and AI- or 
      human-generated; with scores and identification error rates compared between the 
      groups. RESULTS: There were no differences between groups for %total points 
      (ChatGPT 66.0 ± 13.5%, human 70.0 ± 23.0%, P = 0.508) or identification error 
      rates (ChatGPT 40.0 ± 35.0%, human 20.0 ± 30.0%, P = 0.175). Except for one, all 
      essays were identified incorrectly by at least two reviewers. Essays identified 
      as human-generated received higher overall impression scores (area under the 
      curve: 0.82 ± 0.04, P < 0.01). CONCLUSIONS: Whether use of AI tools for academic 
      purposes should constitute academic dishonesty is controversial. We demonstrate 
      that human and AI-generated essays are similar in quality, but there is bias 
      against presumed AI-generated essays. Faculty are not able to reliably 
      differentiate human from AI-generated essays, thus bias may be misdirected. 
      AI-tools are becoming ubiquitous and their use is not easily detected. Faculty 
      must expect these tools to play increasing roles in medical education.
CI  - Copyright © 2024 Elsevier Inc. All rights reserved.
FAU - Crawford, Loralai M
AU  - Crawford LM
AD  - Department of Biomedical Engineering, University of Rochester, Rochester, New 
      York.
FAU - Hendzlik, Peter
AU  - Hendzlik P
AD  - School of Medicine and Dentistry, University of Rochester, Rochester, New York.
FAU - Lam, Justine
AU  - Lam J
AD  - Department of Biomedical Engineering, University of Rochester, Rochester, New 
      York.
FAU - Cannon, Lisa M
AU  - Cannon LM
AD  - Department of Surgery, University of Rochester Medical Center, Rochester, New 
      York.
FAU - Qi, Yanjie
AU  - Qi Y
AD  - Department of Surgery, University of Rochester Medical Center, Rochester, New 
      York.
FAU - DeCaporale-Ryan, Lauren
AU  - DeCaporale-Ryan L
AD  - Department of Surgery, University of Rochester Medical Center, Rochester, New 
      York; Department of Psychiatry, University of Rochester Medical Center, 
      Rochester, New York.
FAU - Wilson, Nicole A
AU  - Wilson NA
AD  - Department of Biomedical Engineering, University of Rochester, Rochester, New 
      York; School of Medicine and Dentistry, University of Rochester, Rochester, New 
      York; Department of Surgery, University of Rochester Medical Center, Rochester, 
      New York; Department of Pediatrics, University of Rochester Medical Center, 
      Rochester, New York. Electronic address: Nicole_Wilson@urmc.rochester.edu.
LA  - eng
PT  - Journal Article
DEP - 20240722
PL  - United States
TA  - J Surg Res
JT  - The Journal of surgical research
JID - 0376340
SB  - IM
MH  - *Artificial Intelligence
MH  - *Internship and Residency/methods
MH  - Humans
MH  - *General Surgery/education
MH  - Writing
MH  - Faculty, Medical/psychology
OTO - NOTNLM
OT  - Ethics
OT  - Generative artificial intelligence
OT  - Large language model
OT  - Surgical education
EDAT- 2024/07/24 00:42
MHDA- 2024/09/27 00:42
CRDT- 2024/07/23 18:01
PHST- 2024/03/04 00:00 [received]
PHST- 2024/05/25 00:00 [revised]
PHST- 2024/06/24 00:00 [accepted]
PHST- 2024/09/27 00:42 [medline]
PHST- 2024/07/24 00:42 [pubmed]
PHST- 2024/07/23 18:01 [entrez]
AID - S0022-4804(24)00355-X [pii]
AID - 10.1016/j.jss.2024.06.020 [doi]
PST - ppublish
SO  - J Surg Res. 2024 Sep;301:504-511. doi: 10.1016/j.jss.2024.06.020. Epub 2024 Jul 
      22.

PMID- 38887420
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240619
IS  - 2156-8650 (Electronic)
IS  - 2156-8650 (Linking)
VI  - 34
IP  - 3
DP  - 2024 Jun
TI  - Assessing Risk of Bias Using ChatGPT-4 and Cochrane ROB2 Tool.
PG  - 691-694
LID - 10.1007/s40670-024-02034-8 [doi]
AB  - In the world of evidence-based medicine, systematic reviews have long been the 
      gold standard. But they have had a problem-they take forever. That is where 
      ChatGPT-4 and automation come in. They are like a breath of fresh air, speeding 
      things up and making the process more reliable. ChatGPT-4 is like having a 
      super-smart assistant who can quickly assess bias risk in research studies. It is 
      a game-changer, especially in a field where getting the latest research quickly 
      can mean life or death for patients. Sure, it is not perfect, and we still need 
      humans to keep an eye on things and ensure everything's ethical. But the future 
      looks bright. With ChatGPT-4 and automation, evidence-based medicine is on the 
      fast track to success.
CI  - © The Author(s) under exclusive licence to International Association of Medical 
      Science Educators 2024. Springer Nature or its licensor (e.g. a society or other 
      partner) holds exclusive rights to this article under a publishing agreement with 
      the author(s) or other rightsholder(s); author self-archiving of the accepted 
      manuscript version of this article is solely governed by the terms of such 
      publishing agreement and applicable law.
FAU - Treviño-Juarez, Angel Sebastian
AU  - Treviño-Juarez AS
AUID- ORCID: 0000-0001-6366-307X
AD  - School of Medicine, UANL, Hospital Universitario Dr. Jose Eleuterio Gonzalez, 
      Monterrey, Mexico. ROR: https://ror.org/030ms0x66. GRID: grid.464574.0. ISNI: 
      0000 0004 1760 058X
LA  - eng
PT  - Editorial
DEP - 20240405
PL  - United States
TA  - Med Sci Educ
JT  - Medical science educator
JID - 101625548
PMC - PMC11180068
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Bias
OT  - Medical education
OT  - Systematic review
COIS- Competing InterestsThe author declares no competing interests.
EDAT- 2024/06/18 06:41
MHDA- 2024/06/18 23:43
PMCR- 2025/06/01
CRDT- 2024/06/18 03:56
PHST- 2024/03/29 00:00 [accepted]
PHST- 2025/06/01 00:00 [pmc-release]
PHST- 2024/06/18 06:41 [pubmed]
PHST- 2024/06/18 23:43 [medline]
PHST- 2024/06/18 03:56 [entrez]
AID - 2034 [pii]
AID - 10.1007/s40670-024-02034-8 [doi]
PST - epublish
SO  - Med Sci Educ. 2024 Apr 5;34(3):691-694. doi: 10.1007/s40670-024-02034-8. 
      eCollection 2024 Jun.

PMID- 38728144
OWN - NLM
STAT- MEDLINE
DCOM- 20241016
LR  - 20241016
IS  - 1942-4434 (Electronic)
IS  - 0882-2786 (Linking)
VI  - 39
IP  - 5
DP  - 2024 Oct 16
TI  - ChatGPT May Help Inform Patients in Dental Implantology.
PG  - 203-208
LID - 10.11607/jomi.10777 [doi]
AB  - PURPOSE: Patients may have high expectations regarding dental implants based on 
      the source of their information, which can lead to challenges in clinical 
      communication. This study aims to evaluate the quality of responses provided by 
      Chat Generative Pretrained Transformer (ChatGPT, OpenAI), an artificial 
      intelligence (AI) program, to patient questions in the field of dental 
      implantology. MATERIALS AND METHODS: This study was prospectively designed as a 
      cross-sectional study. Frequently asked questions by patients about general 
      information on dental implantology (Part 1) and dental implant brands (Part 2) 
      were posed to the ChatGPT program. Responses were independently assessed by oral 
      and maxillofacial surgeons (Group 1; n &#61; 10), periodontologists (Group 2; n 
      &#61; 10), prosthodontists (Group 3; n &#61; 10), and general dentists (Group 4; 
      n &#61; 10) using the Global Quality Scale (GQS, scored from 1 [low quality] to 5 
      [high quality]). RESULTS: There was a total of 60 questions, with 30 questions in 
      each part. Participants in the study were evenly distributed by gender (50% 
      female, 50% male) with a mean age of 32.6 ± 4.07 years. The mean years of 
      experience were 8.5 ± 3.12 years. There were no significant differences in mean 
      age, gender, and years of experience among the groups (P > .05). The overall mean 
      GQS score was 3.87 ± 0.29. Part 1 had a mean score of 3.9 ± 0.35, and Part 2 had 
      a mean score of 3.85 ± 0.29, with no statistically significant difference (P > 
      .05). CONCLUSIONS: The AI platform may contribute to the additional education of 
      patients in the field of dental implantology and aid in understanding treatment 
      procedures. However, it is concerning that ChatGPT may exhibit bias regarding 
      dental implant brands, which could impact patient guidance.
FAU - Çoban, Elif
AU  - Çoban E
FAU - Altay, Berkan
AU  - Altay B
LA  - eng
PT  - Journal Article
PL  - United States
TA  - Int J Oral Maxillofac Implants
JT  - The International journal of oral & maxillofacial implants
JID - 8611905
RN  - 0 (Dental Implants)
SB  - IM
MH  - Humans
MH  - Female
MH  - Male
MH  - Cross-Sectional Studies
MH  - Prospective Studies
MH  - Adult
MH  - *Artificial Intelligence
MH  - Dental Implantation
MH  - Patient Education as Topic
MH  - Dental Implants
MH  - Surveys and Questionnaires
EDAT- 2024/05/10 18:43
MHDA- 2024/10/16 18:22
CRDT- 2024/05/10 12:42
PHST- 2024/10/16 18:22 [medline]
PHST- 2024/05/10 18:43 [pubmed]
PHST- 2024/05/10 12:42 [entrez]
AID - 5318047 [pii]
AID - 10.11607/jomi.10777 [doi]
PST - ppublish
SO  - Int J Oral Maxillofac Implants. 2024 Oct 16;39(5):203-208. doi: 
      10.11607/jomi.10777.

PMID- 38480911
OWN - NLM
STAT- MEDLINE
DCOM- 20240715
LR  - 20240718
IS  - 1740-634X (Electronic)
IS  - 0893-133X (Print)
IS  - 0893-133X (Linking)
VI  - 49
IP  - 9
DP  - 2024 Aug
TI  - Clinical decision support for bipolar depression using large language models.
PG  - 1412-1416
LID - 10.1038/s41386-024-01841-2 [doi]
AB  - Management of depressive episodes in bipolar disorder remains challenging for 
      clinicians despite the availability of treatment guidelines. In other contexts, 
      large language models have yielded promising results for supporting clinical 
      decisionmaking. We developed 50 sets of clinical vignettes reflecting bipolar 
      depression and presented them to experts in bipolar disorder, who were asked to 
      identify 5 optimal next-step pharmacotherapies and 5 poor or contraindicated 
      choices. The same vignettes were then presented to a large language model 
      (GPT4-turbo; gpt-4-1106-preview), with or without augmentation by prompting with 
      recent bipolar treatment guidelines, and asked to identify the optimal next-step 
      pharmacotherapy. Overlap between model output and gold standard was estimated. 
      The augmented model prioritized the expert-designated optimal choice for 508/1000 
      vignettes (50.8%, 95% CI 47.7-53.9%; Cohen's kappa = 0.31, 95% CI 0.28-0.35). For 
      120 vignettes (12.0%), at least one model choice was among the poor or 
      contraindicated treatments. Results were not meaningfully different when gender 
      or race of the vignette was permuted to examine risk for bias. By comparison, an 
      un-augmented model identified the optimal treatment for 234 (23.0%, 95% CI 
      20.8-26.0%; McNemar's p < 0.001 versus augmented model) of the vignettes. A 
      sample of community clinicians scoring the same vignettes identified the optimal 
      choice for 23.1% (95% CI 15.7-30.5%) of vignettes, on average; McNemar's 
      p < 0.001 versus augmented model. Large language models prompted with 
      evidence-based guidelines represent a promising, scalable strategy for clinical 
      decision support. In addition to prospective studies of efficacy, strategies to 
      avoid clinician overreliance on such models, and address the possibility of bias, 
      will be needed.
CI  - © 2024. The Author(s).
FAU - Perlis, Roy H
AU  - Perlis RH
AD  - Center for Quantitative Health and Department of Psychiatry, Massachusetts 
      General Hospital, Boston, MA, USA. rperlis@mgh.harvard.edu.
AD  - Department of Psychiatry, Harvard Medical School, Boston, MA, USA. 
      rperlis@mgh.harvard.edu.
FAU - Goldberg, Joseph F
AU  - Goldberg JF
AD  - Department of Psychiatry, Mt. Sinai School of Medicine, New York, NY, USA.
FAU - Ostacher, Michael J
AU  - Ostacher MJ
AUID- ORCID: 0000-0003-0353-7535
AD  - Department of Psychiatry and Behavioral Sciences, Stanford University School of 
      Medicine, Palo Alto, CA, USA.
FAU - Schneck, Christopher D
AU  - Schneck CD
AD  - Department of Psychiatry, University of Colorado School of Medicine, Aurora, CO, 
      USA.
LA  - eng
GR  - R01 MH123804/MH/NIMH NIH HHS/United States
GR  - R01MH123804/U.S. Department of Health & Human Services | NIH | National Institute 
      of Mental Health (NIMH)/
GR  - RF1MH132335/U.S. Department of Health & Human Services | NIH | National Institute 
      of Mental Health (NIMH)/
PT  - Journal Article
DEP - 20240313
PL  - England
TA  - Neuropsychopharmacology
JT  - Neuropsychopharmacology : official publication of the American College of 
      Neuropsychopharmacology
JID - 8904907
SB  - IM
MH  - Humans
MH  - *Bipolar Disorder/drug therapy/diagnosis
MH  - Decision Support Systems, Clinical
MH  - Female
MH  - Male
MH  - Clinical Decision-Making/methods
MH  - Adult
MH  - Language
PMC - PMC11251032
COIS- RHP has served on scientific advisory boards or received consulting fees from 
      Alkermes, Circular Genomics, Genomind, Psy Therapeutics, Swan AI Studios, and 
      Vault Health. He holds equity in Circular Genomics, Psy Therapeutics, Swan AI 
      Studios, and Vault Health. He is a paid Associate Editor at JAMA Network-Open. 
      JFG is a Consultant at Alkermes, Genomind, Luye Pharma, Neurelis, Neuroma, 
      Otsuka, Sunovion, Supernus; serves on speakers bureaus for Alkermes, Axsome, 
      Intracellular; receives royalties from American Psychiatric Publishing, Cambridge 
      University Press. MJO is a full-time employee of the United States Department of 
      Veterans Affairs. He has received grant funding from Otsuka and Freespira; 
      payment from Neurocrine for service on a Data Safety and Monitoring Committee; 
      and personal payments for expert testimony. CDS reports no competing interests.
EDAT- 2024/03/14 06:46
MHDA- 2024/07/16 00:41
PMCR- 2024/03/13
CRDT- 2024/03/14 01:09
PHST- 2024/01/11 00:00 [received]
PHST- 2024/02/29 00:00 [accepted]
PHST- 2024/02/27 00:00 [revised]
PHST- 2024/07/16 00:41 [medline]
PHST- 2024/03/14 06:46 [pubmed]
PHST- 2024/03/14 01:09 [entrez]
PHST- 2024/03/13 00:00 [pmc-release]
AID - 10.1038/s41386-024-01841-2 [pii]
AID - 1841 [pii]
AID - 10.1038/s41386-024-01841-2 [doi]
PST - ppublish
SO  - Neuropsychopharmacology. 2024 Aug;49(9):1412-1416. doi: 
      10.1038/s41386-024-01841-2. Epub 2024 Mar 13.

PMID- 38194585
OWN - NLM
STAT- MEDLINE
DCOM- 20250115
LR  - 20250115
IS  - 1444-0938 (Electronic)
IS  - 0816-4622 (Linking)
VI  - 108
IP  - 1
DP  - 2025 Jan
TI  - Talking technology: exploring chatbots as a tool for cataract patient education.
PG  - 56-64
LID - 10.1080/08164622.2023.2298812 [doi]
AB  - CLINICAL RELEVANCE: Worldwide, millions suffer from cataracts, which impair 
      vision and quality of life. Cataract education improves outcomes, satisfaction, 
      and treatment adherence. Lack of health literacy, language and cultural barriers, 
      personal preferences, and limited resources may all impede effective 
      communication. BACKGROUND: AI can improve patient education by providing 
      personalised, interactive, and accessible information tailored to patient 
      understanding, interest, and motivation. AI chatbots can have human-like 
      conversations and give advice on numerous topics. METHODS: This study 
      investigated the efficacy of chatbots in cataract patient education relative to 
      traditional resources like the AAO website, focusing on information 
      accuracy,understandability, actionability, and readability. A descriptive 
      comparative design was used to analyse quantitative data from frequently asked 
      questions about cataracts answered by ChatGPT, Bard, Bing AI, and the AAO 
      website. SOLO taxonomy, PEMAT, and the Flesch-Kincaid ease score were used to 
      collect and analyse the data. RESULTS: Chatbots scored higher than AAO website on 
      cataract-related questions in terms of accuracy (mean SOLO score ChatGPT: 
      3.1 ± 0.31, Bard: 2.9 ± 0.72, Bing AI: 2.65 ± 0.49, AAO website: 2.4 ± 0.6, 
      (p < 0.001)). For understandability (mean PEMAT-U score AAO website: 0,89 ± 0,04, 
      ChatGPT 0,84 ± 0,02, Bard: 0,84 ± 0,02, Bing AI: 0,81 ± 0,02, (p < 0.001)), and 
      actionability (mean PEMAT-A score ChatGPT: 0.86 ± 0.03, Bard: 0.85 ± 0.06, Bing 
      AI: 0.81 ± 0.05, AAO website: 0.81 ± 0.06, (p < 0.001)) AAO website scored better 
      than chatbots. Flesch-Kincaid readability ease analysis showed that Bard 
      (55,5 ± 8,48) had the highest mean score, followed by AAO website 
      (51,96 ± 12,46), Bing AI (41,77 ± 9,53), and ChatGPT (34,38 ± 9,75, (p < 0.001)). 
      CONCLUSION: Chatbots have the potential to provide more detailed and accurate 
      data than the AAO website. On the other hand, the AAO website has the advantage 
      of providing information that is more understandable and practical. When patient 
      preferences are not taken into account, generalised or biased information can 
      decrease reliability.
FAU - Yılmaz, I Brahim Edhem
AU  - Yılmaz IBE
AUID- ORCID: 0000-0003-1154-425X
AD  - Ophthalmology Department, Kilis State Hospital, Kilis, Turkey.
FAU - Doğan, Levent
AU  - Doğan L
AUID- ORCID: 0000-0002-4849-3698
AD  - Ophthalmology Department, Kilis State Hospital, Kilis, Turkey.
LA  - eng
PT  - Journal Article
DEP - 20240109
PL  - United States
TA  - Clin Exp Optom
JT  - Clinical & experimental optometry
JID - 8703442
SB  - IM
MH  - Humans
MH  - *Cataract
MH  - *Patient Education as Topic/methods
MH  - *Health Literacy
MH  - Internet
MH  - Quality of Life
MH  - Artificial Intelligence
MH  - Communication
MH  - Surveys and Questionnaires
OTO - NOTNLM
OT  - Cataracts
OT  - chatbot
OT  - conversational artificial intelligence
OT  - health literacy
OT  - information accessibility
OT  - patient education
EDAT- 2024/01/09 18:41
MHDA- 2025/01/15 18:20
CRDT- 2024/01/09 16:02
PHST- 2025/01/15 18:20 [medline]
PHST- 2024/01/09 18:41 [pubmed]
PHST- 2024/01/09 16:02 [entrez]
AID - 10.1080/08164622.2023.2298812 [doi]
PST - ppublish
SO  - Clin Exp Optom. 2025 Jan;108(1):56-64. doi: 10.1080/08164622.2023.2298812. Epub 
      2024 Jan 9.

PMID- 38083058
OWN - NLM
STAT- MEDLINE
DCOM- 20231216
LR  - 20240126
IS  - 2694-0604 (Electronic)
IS  - 2375-7477 (Linking)
VI  - 2023
DP  - 2023 Jul
TI  - Unlocking the Power of EHRs: Harnessing Unstructured Data for Machine 
      Learning-based Outcome Predictions.
PG  - 1-4
LID - 10.1109/EMBC40787.2023.10340232 [doi]
AB  - The integration of Electronic Health Records (EHRs) with Machine Learning (ML) 
      models has become imperative in examining patient outcomes due to the vast 
      amounts of clinical data they provide. However, critical information regarding 
      social and behavioral factors that affect health, such as social isolation, 
      stress, and mental health complexities, is often recorded in unstructured 
      clinical notes, hindering its accessibility. This has resulted in an 
      over-reliance on clinical data in current EHR-based research, potentially leading 
      to disparities in health outcomes. This study aims to evaluate the impact of 
      incorporating patient-specific context from unstructured EHR data on the accuracy 
      and stability of ML algorithms for predicting mortality, using the MIMIC III 
      database. Results from the study confirmed the significance of incorporating 
      patient-specific information into prediction models, leading to a notable 
      improvement in the discriminatory power and robustness of the ML algorithms. 
      Furthermore, the findings underline the importance of considering non-clinical 
      factors related to a patient's daily life, in addition to clinical factors, when 
      making predictions about patient outcomes. The advent of advanced generative 
      models, such as GPT-4, presents new opportunities for effectively extracting 
      social and behavioral factors from unstructured clinical notes, further enhancing 
      the accuracy and stability of ML algorithms in predicting patient outcomes. The 
      results of our study have significant ramifications for improving ML in clinical 
      decision support and patient outcome predictions, specifically highlighting the 
      potential role of generative models like GPT-4 in advancing ML-based outcome 
      predictions.
FAU - Noaeen, Mohammad
AU  - Noaeen M
FAU - Amini, Somayeh
AU  - Amini S
FAU - Bhasker, Shveta
AU  - Bhasker S
FAU - Ghezelsefli, Zohreh
AU  - Ghezelsefli Z
FAU - Ahmed, Aisha
AU  - Ahmed A
FAU - Jafarinezhad, Omid
AU  - Jafarinezhad O
FAU - Abad, Zahra Shakeri Hossein
AU  - Abad ZSH
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - Annu Int Conf IEEE Eng Med Biol Soc
JT  - Annual International Conference of the IEEE Engineering in Medicine and Biology 
      Society. IEEE Engineering in Medicine and Biology Society. Annual International 
      Conference
JID - 101763872
SB  - IM
MH  - Humans
MH  - *Electronic Health Records
MH  - *Machine Learning
MH  - Algorithms
MH  - Mental Health
MH  - Records
EDAT- 2023/12/12 06:42
MHDA- 2023/12/17 13:19
CRDT- 2023/12/12 01:05
PHST- 2023/12/17 13:19 [medline]
PHST- 2023/12/12 06:42 [pubmed]
PHST- 2023/12/12 01:05 [entrez]
AID - 10.1109/EMBC40787.2023.10340232 [doi]
PST - ppublish
SO  - Annu Int Conf IEEE Eng Med Biol Soc. 2023 Jul;2023:1-4. doi: 
      10.1109/EMBC40787.2023.10340232.

PMID- 37917120
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240210
IS  - 2369-3762 (Print)
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 9
DP  - 2023 Nov 2
TI  - The Accuracy and Potential Racial and Ethnic Biases of GPT-4 in the Diagnosis and 
      Triage of Health Conditions: Evaluation Study.
PG  - e47532
LID - 10.2196/47532 [doi]
LID - e47532
AB  - BACKGROUND: Whether GPT-4, the conversational artificial intelligence, can 
      accurately diagnose and triage health conditions and whether it presents racial 
      and ethnic biases in its decisions remain unclear. OBJECTIVE: We aim to assess 
      the accuracy of GPT-4 in the diagnosis and triage of health conditions and 
      whether its performance varies by patient race and ethnicity. METHODS: We 
      compared the performance of GPT-4 and physicians, using 45 typical clinical 
      vignettes, each with a correct diagnosis and triage level, in February and March 
      2023. For each of the 45 clinical vignettes, GPT-4 and 3 board-certified 
      physicians provided the most likely primary diagnosis and triage level 
      (emergency, nonemergency, or self-care). Independent reviewers evaluated the 
      diagnoses as "correct" or "incorrect." Physician diagnosis was defined as the 
      consensus of the 3 physicians. We evaluated whether the performance of GPT-4 
      varies by patient race and ethnicity, by adding the information on patient race 
      and ethnicity to the clinical vignettes. RESULTS: The accuracy of diagnosis was 
      comparable between GPT-4 and physicians (the percentage of correct diagnosis was 
      97.8% (44/45; 95% CI 88.2%-99.9%) for GPT-4 and 91.1% (41/45; 95% CI 78.8%-97.5%) 
      for physicians; P=.38). GPT-4 provided appropriate reasoning for 97.8% (44/45) of 
      the vignettes. The appropriateness of triage was comparable between GPT-4 and 
      physicians (GPT-4: 30/45, 66.7%; 95% CI 51.0%-80.0%; physicians: 30/45, 66.7%; 
      95% CI 51.0%-80.0%; P=.99). The performance of GPT-4 in diagnosing health 
      conditions did not vary among different races and ethnicities (Black, White, 
      Asian, and Hispanic), with an accuracy of 100% (95% CI 78.2%-100%). P values, 
      compared to the GPT-4 output without incorporating race and ethnicity 
      information, were all .99. The accuracy of triage was not significantly different 
      even if patients' race and ethnicity information was added. The accuracy of 
      triage was 62.2% (95% CI 46.5%-76.2%; P=.50) for Black patients; 66.7% (95% CI 
      51.0%-80.0%; P=.99) for White patients; 66.7% (95% CI 51.0%-80.0%; P=.99) for 
      Asian patients, and 62.2% (95% CI 46.5%-76.2%; P=.69) for Hispanic patients. P 
      values were calculated by comparing the outputs with and without conditioning on 
      race and ethnicity. CONCLUSIONS: GPT-4's ability to diagnose and triage typical 
      clinical vignettes was comparable to that of board-certified physicians. The 
      performance of GPT-4 did not vary by patient race and ethnicity. These findings 
      should be informative for health systems looking to introduce conversational 
      artificial intelligence to improve the efficiency of patient diagnosis and 
      triage.
CI  - ©Naoki Ito, Sakina Kadomatsu, Mineto Fujisawa, Kiyomitsu Fukaguchi, Ryo Ishizawa, 
      Naoki Kanda, Daisuke Kasugai, Mikio Nakajima, Tadahiro Goto, Yusuke Tsugawa. 
      Originally published in JMIR Medical Education (https://mededu.jmir.org), 
      02.11.2023.
FAU - Ito, Naoki
AU  - Ito N
AUID- ORCID: 0009-0005-6135-7868
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Faculty of Medicine, The University of Tokyo, Tokyo, Japan.
FAU - Kadomatsu, Sakina
AU  - Kadomatsu S
AUID- ORCID: 0009-0005-4236-216X
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Faculty of Medicine, International University of Health and Welfare, Chiba, 
      Japan.
FAU - Fujisawa, Mineto
AU  - Fujisawa M
AUID- ORCID: 0009-0006-5064-1879
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Faculty of Medicine, The University of Tokyo, Tokyo, Japan.
FAU - Fukaguchi, Kiyomitsu
AU  - Fukaguchi K
AUID- ORCID: 0000-0003-2262-1898
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Department of Emergency Medicine, Shonan Kamakura General Hospital, Kanagawa, 
      Japan.
FAU - Ishizawa, Ryo
AU  - Ishizawa R
AUID- ORCID: 0000-0002-6324-7399
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Department of Emergency and Critical Care Medicine, Tokyo Medical Center National 
      Hospital Organization, Tokyo, Japan.
FAU - Kanda, Naoki
AU  - Kanda N
AUID- ORCID: 0000-0001-8003-534X
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Division of General Internal Medicine, Jichi Medical University Hospital, 
      Tochigi, Japan.
FAU - Kasugai, Daisuke
AU  - Kasugai D
AUID- ORCID: 0000-0002-8692-3003
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Department of Emergency and Critical Care Medicine, Nagoya University Graduate 
      School of Medicine, Aichi, Japan.
FAU - Nakajima, Mikio
AU  - Nakajima M
AUID- ORCID: 0000-0002-2903-1092
AD  - TXP Medical Co Ltd, Tokyo, Japan.
AD  - Emergency Life-Saving Technique Academy of Tokyo Foundation for Ambulance Service 
      Development, Tokyo, Japan.
FAU - Goto, Tadahiro
AU  - Goto T
AUID- ORCID: 0000-0002-5880-2968
AD  - TXP Medical Co Ltd, Tokyo, Japan.
FAU - Tsugawa, Yusuke
AU  - Tsugawa Y
AUID- ORCID: 0000-0002-1937-4833
AD  - Division of General Internal Medicine and Health Services Research, David Geffen 
      School of Medicine, The University of California, Los Angeles, Los Angeles, CA, 
      United States.
AD  - Department of Health Policy and Management, UCLA Fielding School of Public 
      Health, Los Angeles, CA, United States.
LA  - eng
GR  - R01 AG068633/AG/NIA NIH HHS/United States
GR  - R01 AG082991/AG/NIA NIH HHS/United States
GR  - R01 MD013913/MD/NIMHD NIH HHS/United States
PT  - Journal Article
DEP - 20231102
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
PMC - PMC10654908
OTO - NOTNLM
OT  - AI
OT  - GPT
OT  - GPT-4
OT  - artificial intelligence
OT  - bias
OT  - clinical vignettes
OT  - decision-making
OT  - diagnosis
OT  - efficiency
OT  - physician
OT  - race
OT  - racial and ethnic bias
OT  - triage
OT  - typical clinical vignettes
COIS- Conflicts of Interest: None declared.
EDAT- 2023/11/02 12:45
MHDA- 2023/11/02 12:46
PMCR- 2023/11/02
CRDT- 2023/11/02 11:53
PHST- 2023/03/23 00:00 [received]
PHST- 2023/09/05 00:00 [accepted]
PHST- 2023/07/07 00:00 [revised]
PHST- 2023/11/02 12:46 [medline]
PHST- 2023/11/02 12:45 [pubmed]
PHST- 2023/11/02 11:53 [entrez]
PHST- 2023/11/02 00:00 [pmc-release]
AID - v9i1e47532 [pii]
AID - 10.2196/47532 [doi]
PST - epublish
SO  - JMIR Med Educ. 2023 Nov 2;9:e47532. doi: 10.2196/47532.

PMID- 37385685
OWN - NLM
STAT- MEDLINE
DCOM- 20230712
LR  - 20231214
IS  - 1975-5937 (Electronic)
IS  - 1975-5937 (Linking)
VI  - 20
DP  - 2023
TI  - Comparing ChatGPT’s ability to rate the degree of stereotypes and the consistency 
      of stereotype attribution with those of medical students in New Zealand in 
      developing a similarity rating test: a methodological study.
PG  - 17
LID - 10.3352/jeehp.2023.20.17 [doi]
LID - 17
AB  - Learning about one’s implicit bias is crucial for improving one’s cultural 
      competency and thereby reducing health inequity. To evaluate bias among medical 
      students following a previously developed cultural training program targeting New 
      Zealand Māori, we developed a text-based, self-evaluation tool called the 
      Similarity Rating Test (SRT). The development process of the SRT was 
      resource-intensive, limiting its generalizability and applicability. Here, we 
      explored the potential of ChatGPT, an automated chatbot, to assist in the 
      development process of the SRT by comparing ChatGPT’s and students’ evaluations 
      of the SRT. Despite results showing non-significant equivalence and difference 
      between ChatGPT’s and students’ ratings, ChatGPT’s ratings were more consistent 
      than students’ ratings. The consistency rate was higher for non-stereotypical 
      than for stereotypical statements, regardless of rater type. Further studies are 
      warranted to validate ChatGPT’s potential for assisting in SRT development for 
      implementation in medical education and evaluation of ethnic stereotypes and 
      related topics.
FAU - Lin, Chao-Cheng
AU  - Lin CC
AD  - Department of Psychological Medicine, Dunedin School of Medicine, The University 
      of Otago, Dunedin, New Zealand.
AD  - Department of Psychiatry, National Taiwan University College of Medicine, Taipei, 
      Taiwan.
FAU - Akuhata-Huntington, Zaine
AU  - Akuhata-Huntington Z
AD  - Kōhatu Centre for Hauora Māori, Dunedin School of Medicine, The University of 
      Otago, Dunedin, New Zealand.
FAU - Hsu, Che-Wei
AU  - Hsu CW
AD  - Department of Psychological Medicine, Dunedin School of Medicine, The University 
      of Otago, Dunedin, New Zealand.
LA  - eng
PT  - Comparative Study
PT  - Journal Article
DEP - 20230612
PL  - Korea (South)
TA  - J Educ Eval Health Prof
JT  - Journal of educational evaluation for health professions
JID - 101490061
SB  - IM
MH  - Humans
MH  - *Cultural Competency/education/psychology
MH  - *Education, Medical/methods
MH  - *Maori People
MH  - New Zealand
MH  - *Students, Medical/psychology
MH  - *Artificial Intelligence
MH  - Stereotyping
MH  - *Bias, Implicit
PMC - PMC10356547
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Cultural competency
OT  - Implicit bias
OT  - Medical education
OT  - New Zealand
COIS- Conflict of interest No potential conflict of interest relevant to this article 
      was reported.
EDAT- 2023/06/30 01:06
MHDA- 2023/07/03 06:41
PMCR- 2023/06/12
CRDT- 2023/06/29 20:53
PHST- 2023/05/16 00:00 [received]
PHST- 2023/05/30 00:00 [accepted]
PHST- 2023/07/03 06:41 [medline]
PHST- 2023/06/30 01:06 [pubmed]
PHST- 2023/06/29 20:53 [entrez]
PHST- 2023/06/12 00:00 [pmc-release]
AID - jeehp.2023.20.17 [pii]
AID - jeehp-20-17 [pii]
AID - 10.3352/jeehp.2023.20.17 [doi]
PST - ppublish
SO  - J Educ Eval Health Prof. 2023;20:17. doi: 10.3352/jeehp.2023.20.17. Epub 2023 Jun 
      12.

PMID- 37179029
OWN - NLM
STAT- PubMed-not-MEDLINE
DCOM- 20230822
LR  - 20230830
IS  - 1097-6787 (Electronic)
IS  - 0190-9622 (Linking)
VI  - 89
IP  - 3
DP  - 2023 Sep
TI  - Experimenting with ChatGPT: Concerns for academic medicine.
PG  - e127-e129
LID - S0190-9622(23)00747-8 [pii]
LID - 10.1016/j.jaad.2023.04.045 [doi]
FAU - Hirani, Rahim
AU  - Hirani R
AD  - New York Medical College, Valhalla, New York.
FAU - Farabi, Banu
AU  - Farabi B
AD  - New York Medical College, Valhalla, New York; Department of Dermatology, NYC 
      Health + Hospitals/Metropolitan Medical Center, New York, New York; Department of 
      Medicine, NYC Health + Hospitals/South Brooklyn Health, Ruth Bader Ginsburg 
      Hospital, Brooklyn, New York.
FAU - Marmon, Shoshana
AU  - Marmon S
AD  - New York Medical College, Valhalla, New York; Department of Dermatology, NYC 
      Health + Hospitals/Metropolitan Medical Center, New York, New York; Department of 
      Medicine, NYC Health + Hospitals/South Brooklyn Health, Ruth Bader Ginsburg 
      Hospital, Brooklyn, New York. Electronic address: Shoshana.Marmon@nychhc.org.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20230511
PL  - United States
TA  - J Am Acad Dermatol
JT  - Journal of the American Academy of Dermatology
JID - 7907132
SB  - IM
CON - NPJ Digit Med. 2023 Apr 26;6(1):75. doi: 10.1038/s41746-023-00819-6. PMID: 
      37100871
OTO - NOTNLM
OT  - ChatGPT
OT  - academic publishing
OT  - artificial intelligence (AI)
OT  - dermatology journals
OT  - gender bias
OT  - large language model
OT  - machine learning
OT  - racial bias
OT  - scientific integrity
COIS- Conflicts of interest None disclosed.
EDAT- 2023/05/14 01:07
MHDA- 2023/05/14 01:08
CRDT- 2023/05/13 19:29
PHST- 2023/02/21 00:00 [received]
PHST- 2023/04/04 00:00 [revised]
PHST- 2023/04/10 00:00 [accepted]
PHST- 2023/05/14 01:08 [medline]
PHST- 2023/05/14 01:07 [pubmed]
PHST- 2023/05/13 19:29 [entrez]
AID - S0190-9622(23)00747-8 [pii]
AID - 10.1016/j.jaad.2023.04.045 [doi]
PST - ppublish
SO  - J Am Acad Dermatol. 2023 Sep;89(3):e127-e129. doi: 10.1016/j.jaad.2023.04.045. 
      Epub 2023 May 11.

PMID- 40068170
OWN - NLM
STAT- MEDLINE
DCOM- 20250311
LR  - 20250322
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 11
DP  - 2025 Mar 11
TI  - Leveraging Generative Artificial Intelligence to Improve Motivation and Retrieval 
      in Higher Education Learners.
PG  - e59210
LID - 10.2196/59210 [doi]
LID - e59210
AB  - Generative artificial intelligence (GenAI) presents novel approaches to enhance 
      motivation, curriculum structure and development, and learning and retrieval 
      processes for both learners and instructors. Though a focus for this emerging 
      technology is academic misconduct, we sought to leverage GenAI in curriculum 
      structure to facilitate educational outcomes. For instructors, GenAI offers new 
      opportunities in course design and management while reducing time requirements to 
      evaluate outcomes and personalizing learner feedback. These include innovative 
      instructional designs such as flipped classrooms and gamification, enriching 
      teaching methodologies with focused and interactive approaches, and team-based 
      exercise development among others. For learners, GenAI offers unprecedented 
      self-directed learning opportunities, improved cognitive engagement, and 
      effective retrieval practices, leading to enhanced autonomy, motivation, and 
      knowledge retention. Though empowering, this evolving landscape has integration 
      challenges and ethical considerations, including accuracy, technological 
      evolution, loss of learner's voice, and socioeconomic disparities. Our experience 
      demonstrates that the responsible application of GenAI's in educational settings 
      will revolutionize learning practices, making education more accessible and 
      tailored, producing positive motivational outcomes for both learners and 
      instructors. Thus, we argue that leveraging GenAI in educational settings will 
      improve outcomes with implications extending from primary through higher and 
      continuing education paradigms.
CI  - © Noahlana Monzon, Franklin Alan Hays. Originally published in JMIR Medical 
      Education (https://mededu.jmir.org).
FAU - Monzon, Noahlana
AU  - Monzon N
AUID- ORCID: 0000-0003-1364-1141
AD  - Department of Nutritional Sciences, University of Oklahoma Health Sciences, 1200 
      N Stonewall Ave, 3064 Allied Health Building, Oklahoma City, OK, 73117, United 
      States, 1 405 2718001 ext 41182.
FAU - Hays, Franklin Alan
AU  - Hays FA
AUID- ORCID: 0000-0002-2191-558X
AD  - Department of Nutritional Sciences, University of Oklahoma Health Sciences, 1200 
      N Stonewall Ave, 3064 Allied Health Building, Oklahoma City, OK, 73117, United 
      States, 1 405 2718001 ext 41182.
LA  - eng
PT  - Journal Article
DEP - 20250311
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
MH  - Humans
MH  - *Motivation
MH  - *Artificial Intelligence
MH  - Curriculum
MH  - Learning
MH  - Students/psychology
PMC - PMC11918979
OTO - NOTNLM
OT  - AI
OT  - academic misconduct
OT  - chatGPT
OT  - cognitive engagement
OT  - curriculum structure
OT  - educational technology
OT  - flipped classroom
OT  - gamification
OT  - generative artificial intelligence
OT  - higher education
OT  - innovation
OT  - instructors
OT  - interactive approach
OT  - large language models
OT  - learners
OT  - learning
OT  - machine learning
OT  - medical education
OT  - personalized learning
OT  - retrieval practice
OT  - self-directed
OT  - socio-economic disparities
OT  - technologies
OT  - university education
COIS- None declared.
EDAT- 2025/03/12 11:34
MHDA- 2025/03/12 11:35
PMCR- 2025/03/11
CRDT- 2025/03/11 17:03
PHST- 2024/04/05 00:00 [received]
PHST- 2024/11/11 00:00 [revised]
PHST- 2025/01/02 00:00 [accepted]
PHST- 2025/03/12 11:35 [medline]
PHST- 2025/03/12 11:34 [pubmed]
PHST- 2025/03/11 17:03 [entrez]
PHST- 2025/03/11 00:00 [pmc-release]
AID - v11i1e59210 [pii]
AID - 59210 [pii]
AID - 10.2196/59210 [doi]
PST - epublish
SO  - JMIR Med Educ. 2025 Mar 11;11:e59210. doi: 10.2196/59210.

PMID- 37844967
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20231023
IS  - 2009-8774 (Electronic)
IS  - 2305-6983 (Print)
IS  - 2305-6983 (Linking)
VI  - 11
IP  - 4
DP  - 2023 Sep
TI  - Identifying depression and its determinants upon initiating treatment: ChatGPT 
      versus primary care physicians.
LID - 10.1136/fmch-2023-002391 [doi]
LID - e002391
AB  - OBJECTIVE: To compare evaluations of depressive episodes and suggested treatment 
      protocols generated by Chat Generative Pretrained Transformer (ChatGPT)-3 and 
      ChatGPT-4 with the recommendations of primary care physicians. METHODS: Vignettes 
      were input to the ChatGPT interface. These vignettes focused primarily on 
      hypothetical patients with symptoms of depression during initial consultations. 
      The creators of these vignettes meticulously designed eight distinct versions in 
      which they systematically varied patient attributes (sex, socioeconomic status 
      (blue collar worker or white collar worker) and depression severity (mild or 
      severe)). Each variant was subsequently introduced into ChatGPT-3.5 and 
      ChatGPT-4. Each vignette was repeated 10 times to ensure consistency and 
      reliability of the ChatGPT responses. RESULTS: For mild depression, ChatGPT-3.5 
      and ChatGPT-4 recommended psychotherapy in 95.0% and 97.5% of cases, 
      respectively. Primary care physicians, however, recommended psychotherapy in only 
      4.3% of cases. For severe cases, ChatGPT favoured an approach that combined 
      psychotherapy, while primary care physicians recommended a combined approach. The 
      pharmacological recommendations of ChatGPT-3.5 and ChatGPT-4 showed a preference 
      for exclusive use of antidepressants (74% and 68%, respectively), in contrast 
      with primary care physicians, who typically recommended a mix of antidepressants 
      and anxiolytics/hypnotics (67.4%). Unlike primary care physicians, ChatGPT showed 
      no gender or socioeconomic biases in its recommendations. CONCLUSION: ChatGPT-3.5 
      and ChatGPT-4 aligned well with accepted guidelines for managing mild and severe 
      depression, without showing the gender or socioeconomic biases observed among 
      primary care physicians. Despite the suggested potential benefit of using 
      atificial intelligence (AI) chatbots like ChatGPT to enhance clinical decision 
      making, further research is needed to refine AI recommendations for severe cases 
      and to consider potential risks and ethical issues.
CI  - © Author(s) (or their employer(s)) 2023. Re-use permitted under CC BY-NC. No 
      commercial re-use. See rights and permissions. Published by BMJ.
FAU - Levkovich, Inbar
AU  - Levkovich I
AUID- ORCID: 0000-0002-5717-4074
AD  - Oranim Academic College, Tivon, Israel inbar.lev2@gmail.com.
FAU - Elyoseph, Zohar
AU  - Elyoseph Z
AD  - Department of Psychology and Educational Counseling, Max Stern Academic College 
      Of Emek Yezreel, Emek Yezreel, Israel.
AD  - Department of Brain Sciences, Imperial College London, London, UK.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Fam Med Community Health
JT  - Family medicine and community health
JID - 101700650
RN  - 0 (Anti-Anxiety Agents)
RN  - EC 2.3.1.6 (Choline O-Acetyltransferase)
RN  - 0 (Antidepressive Agents)
SB  - IM
MH  - Humans
MH  - Depression/drug therapy
MH  - *Physicians, Primary Care
MH  - Reproducibility of Results
MH  - *Anti-Anxiety Agents
MH  - Choline O-Acetyltransferase
MH  - Antidepressive Agents/therapeutic use
PMC - PMC10582915
OTO - NOTNLM
OT  - Depression
OT  - Family Health
OT  - Family Practice
OT  - General Practice
OT  - Mental Health
COIS- Competing interests: None declared.
EDAT- 2023/10/17 00:42
MHDA- 2023/10/23 01:18
PMCR- 2023/10/16
CRDT- 2023/10/16 20:53
PHST- 2023/10/23 01:18 [medline]
PHST- 2023/10/17 00:42 [pubmed]
PHST- 2023/10/16 20:53 [entrez]
PHST- 2023/10/16 00:00 [pmc-release]
AID - fmch-2023-002391 [pii]
AID - 10.1136/fmch-2023-002391 [doi]
PST - ppublish
SO  - Fam Med Community Health. 2023 Sep;11(4):e002391. doi: 10.1136/fmch-2023-002391.

PMID- 37758854
OWN - NLM
STAT- MEDLINE
DCOM- 20240711
LR  - 20240711
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
VI  - 48
IP  - 13
DP  - 2024 Jul
TI  - Response Letter to "Testing ChatGPT's Capabilities for Social Media Content 
      Analysis".
PG  - 2605-2607
LID - 10.1007/s00266-023-03675-7 [doi]
AB  - This editorial discusses the innovative application of ChatGPT in categorizing 
      and analysing social media content, with a focus on aesthetic medical fields. It 
      highlights the revolutionary capabilities of AI in enhancing efficiency and 
      objectivity over traditional human-driven methods. Alongside the benefits, it 
      also considers ethical concerns surrounding privacy, consent, and inherent biases 
      within AI models. The article explores the complexity of categorization, the 
      limitations in understanding human nuances, and the impact on human creativity, 
      including specific applications such as SEO writing. It concludes by emphasizing 
      the need for careful integration of AI in our interconnected world, balancing 
      technological advancements with ethical considerations and a recognition of the 
      unique attributes of human intellect. LEVEL OF EVIDENCE V: This journal requires 
      that authors assign a level of evidence to each article. For a full description 
      of these Evidence-Based Medicine ratings, please refer to the Table of Contents 
      or the online Instructions to Authors www.springer.com/00266 .
CI  - © 2023. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Buzzaccarini, Giovanni
AU  - Buzzaccarini G
AUID- ORCID: 0000-0002-9466-0178
AD  - Department of Obstetrics and Gynaecology, IRCCS San Raffaele Scientific 
      Institute, Vita-Salute San Raffaele University, Via Olgettina 58-60, 20132, 
      Milan, Italy. giovanni.buzzaccarini@gmail.com.
FAU - Degliuomini, Rebecca Susanna
AU  - Degliuomini RS
AD  - Department of Obstetrics and Gynaecology, IRCCS San Raffaele Scientific 
      Institute, Vita-Salute San Raffaele University, Via Olgettina 58-60, 20132, 
      Milan, Italy.
FAU - Borin, Marco
AU  - Borin M
AD  - U.O.C. Otorhinolaryngology, ASST Grande Ospedale Metropolitano Niguarda Piazza 
      Ospedale Maggiore, 3-20162, Milan, Italy.
LA  - eng
PT  - Letter
DEP - 20230927
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
MH  - *Social Media
MH  - Humans
MH  - Artificial Intelligence
EDAT- 2023/09/28 00:42
MHDA- 2024/07/12 00:41
CRDT- 2023/09/27 23:29
PHST- 2023/08/14 00:00 [received]
PHST- 2023/09/09 00:00 [accepted]
PHST- 2024/07/12 00:41 [medline]
PHST- 2023/09/28 00:42 [pubmed]
PHST- 2023/09/27 23:29 [entrez]
AID - 10.1007/s00266-023-03675-7 [pii]
AID - 10.1007/s00266-023-03675-7 [doi]
PST - ppublish
SO  - Aesthetic Plast Surg. 2024 Jul;48(13):2605-2607. doi: 10.1007/s00266-023-03675-7. 
      Epub 2023 Sep 27.

PMID- 36912253
OWN - NLM
STAT- MEDLINE
DCOM- 20230518
LR  - 20230530
IS  - 1466-187X (Electronic)
IS  - 0142-159X (Linking)
VI  - 45
IP  - 6
DP  - 2023 Jun
TI  - Ethical use of Artificial Intelligence in Health Professions Education: AMEE 
      Guide No. 158.
PG  - 574-584
LID - 10.1080/0142159X.2023.2186203 [doi]
AB  - Health Professions Education (HPE) has benefitted from the advances in Artificial 
      Intelligence (AI) and is set to benefit more in the future. Just as any 
      technological advance opens discussions about ethics, so the implications of AI 
      for HPE ethics need to be identified, anticipated, and accommodated so that HPE 
      can utilise AI without compromising crucial ethical principles. Rather than 
      focussing on AI technology, this Guide focuses on the ethical issues likely to 
      face HPE teachers and administrators as they encounter and use AI systems in 
      their teaching environment. While many of the ethical principles may be familiar 
      to readers in other contexts, they will be viewed in light of AI, and some 
      unfamiliar issues will be introduced. They include data gathering, anonymity, 
      privacy, consent, data ownership, security, bias, transparency, responsibility, 
      autonomy, and beneficence. In the Guide, each topic explains the concept and its 
      importance and gives some indication of how to cope with its complexities. Ideas 
      are drawn from personal experience and the relevant literature. In most topics, 
      further reading is suggested so that readers may further explore the concepts at 
      their leisure. The aim is for HPE teachers and decision-makers at all levels to 
      be alert to these issues and to take proactive action to be prepared to deal with 
      the ethical problems and opportunities that AI usage presents to HPE.
FAU - Masters, Ken
AU  - Masters K
AUID- ORCID: 0000-0003-3425-5020
AD  - Medical Education and Informatics Department, College of Medicine and Health 
      Sciences, Sultan Qaboos University, Muscat, Sultanate of Oman.
LA  - eng
PT  - Journal Article
DEP - 20230313
PL  - England
TA  - Med Teach
JT  - Medical teacher
JID - 7909593
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Privacy
MH  - Health Occupations
OTO - NOTNLM
OT  - ChatGPT
OT  - Ethics
OT  - artificial intelligence
OT  - health professions education
OT  - medical education
EDAT- 2023/03/14 06:00
MHDA- 2023/05/18 06:42
CRDT- 2023/03/13 06:43
PHST- 2023/05/18 06:42 [medline]
PHST- 2023/03/14 06:00 [pubmed]
PHST- 2023/03/13 06:43 [entrez]
AID - 10.1080/0142159X.2023.2186203 [doi]
PST - ppublish
SO  - Med Teach. 2023 Jun;45(6):574-584. doi: 10.1080/0142159X.2023.2186203. Epub 2023 
      Mar 13.

PMID- 36786388
OWN - NLM
STAT- MEDLINE
DCOM- 20230529
LR  - 20240929
IS  - 1751-7915 (Electronic)
IS  - 1751-7915 (Linking)
VI  - 16
IP  - 6
DP  - 2023 Jun
TI  - Scientific novelty beyond the experiment.
PG  - 1131-1173
LID - 10.1111/1751-7915.14222 [doi]
AB  - Practical experiments drive important scientific discoveries in biology, but 
      theory-based research studies also contribute novel-sometimes 
      paradigm-changing-findings. Here, we appraise the roles of theory-based 
      approaches focusing on the experiment-dominated wet-biology research areas of 
      microbial growth and survival, cell physiology, host-pathogen interactions, and 
      competitive or symbiotic interactions. Additional examples relate to analyses of 
      genome-sequence data, climate change and planetary health, habitability, and 
      astrobiology. We assess the importance of thought at each step of the research 
      process; the roles of natural philosophy, and inconsistencies in logic and 
      language, as drivers of scientific progress; the value of thought experiments; 
      the use and limitations of artificial intelligence technologies, including their 
      potential for interdisciplinary and transdisciplinary research; and other 
      instances when theory is the most-direct and most-scientifically robust route to 
      scientific novelty including the development of techniques for practical 
      experimentation or fieldwork. We highlight the intrinsic need for human 
      engagement in scientific innovation, an issue pertinent to the ongoing 
      controversy over papers authored using/authored by artificial intelligence (such 
      as the large language model/chatbot ChatGPT). Other issues discussed are the way 
      in which aspects of language can bias thinking towards the spatial rather than 
      the temporal (and how this biased thinking can lead to skewed scientific 
      terminology); receptivity to research that is non-mainstream; and the importance 
      of theory-based science in education and epistemology. Whereas we briefly 
      highlight classic works (those by Oakes Ames, Francis H.C. Crick and James D. 
      Watson, Charles R. Darwin, Albert Einstein, James E. Lovelock, Lynn Margulis, 
      Gilbert Ryle, Erwin R.J.A. Schrödinger, Alan M. Turing, and others), the focus is 
      on microbiology studies that are more-recent, discussing these in the context of 
      the scientific process and the types of scientific novelty that they represent. 
      These include several studies carried out during the 2020 to 2022 lockdowns of 
      the COVID-19 pandemic when access to research laboratories was disallowed (or 
      limited). We interviewed the authors of some of the featured microbiology-related 
      papers and-although we ourselves are involved in laboratory experiments and 
      practical fieldwork-also drew from our own research experiences showing that such 
      studies can not only produce new scientific findings but can also transcend 
      barriers between disciplines, act counter to scientific reductionism, integrate 
      biological data across different timescales and levels of complexity, and 
      circumvent constraints imposed by practical techniques. In relation to urgent 
      research needs, we believe that climate change and other global challenges may 
      require approaches beyond the experiment.
CI  - © 2023 The Authors. Microbial Biotechnology published by Applied Microbiology 
      International and John Wiley & Sons Ltd.
FAU - Hallsworth, John E
AU  - Hallsworth JE
AUID- ORCID: 0000-0001-6797-9362
AD  - Institute for Global Food Security, School of Biological Sciences, Queen's 
      University Belfast, Belfast, UK.
FAU - Udaondo, Zulema
AU  - Udaondo Z
AUID- ORCID: 0000-0003-3445-6842
AD  - Department of Biomedical Informatics, University of Arkansas for Medical 
      Sciences, Little Rock, Arkansas, USA.
FAU - Pedrós-Alió, Carlos
AU  - Pedrós-Alió C
AUID- ORCID: 0000-0003-1009-4277
AD  - Department of Systems Biology, Centro Nacional de Biotecnología (CSIC), Madrid, 
      Spain.
FAU - Höfer, Juan
AU  - Höfer J
AUID- ORCID: 0000-0002-5887-4929
AD  - Escuela de Ciencias del Mar, Pontificia Universidad Católica de Valparaíso, 
      Valparaíso, Chile.
FAU - Benison, Kathleen C
AU  - Benison KC
AUID- ORCID: 0000-0001-6104-2333
AD  - Department of Geology and Geography, West Virginia University, Morgantown, West 
      Virginia, USA.
FAU - Lloyd, Karen G
AU  - Lloyd KG
AUID- ORCID: 0000-0003-0914-6375
AD  - Microbiology Department, University of Tennessee, Knoxville, Tennessee, USA.
FAU - Cordero, Radamés J B
AU  - Cordero RJB
AUID- ORCID: 0000-0002-3026-7094
AD  - Department of Molecular Microbiology and Immunology, Johns Hopkins Bloomberg 
      School of Public Health, Baltimore, Maryland, USA.
FAU - de Campos, Claudia B L
AU  - de Campos CBL
AUID- ORCID: 0000-0002-1836-0915
AD  - Institute of Science and Technology, Universidade Federal de Sao Paulo (UNIFESP), 
      São José dos Campos, SP, Brazil.
FAU - Yakimov, Michail M
AU  - Yakimov MM
AUID- ORCID: 0000-0003-1418-363X
AD  - Institute of Polar Sciences, ISP-CNR, Messina, Italy.
FAU - Amils, Ricardo
AU  - Amils R
AD  - Department of Molecular Biology, Centro de Biología Molecular Severo Ochoa 
      (CSIC-UAM), Nicolás Cabrera n° 1, Universidad Autónoma de Madrid, Madrid, Spain.
AD  - Department of Planetology and Habitability, Centro de Astrobiología (INTA-CSIC), 
      Torrejón de Ardoz, Spain.
LA  - eng
PT  - Journal Article
DEP - 20230214
PL  - United States
TA  - Microb Biotechnol
JT  - Microbial biotechnology
JID - 101316335
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Pandemics
MH  - *COVID-19
MH  - Communicable Disease Control
MH  - Philosophy
PMC - PMC10221578
COIS- The authors declare that they have no conflict of interest.
EDAT- 2023/02/15 06:00
MHDA- 2023/05/29 06:41
PMCR- 2023/02/14
CRDT- 2023/02/14 07:13
PHST- 2023/01/09 00:00 [revised]
PHST- 2022/10/20 00:00 [received]
PHST- 2023/01/11 00:00 [accepted]
PHST- 2023/05/29 06:41 [medline]
PHST- 2023/02/15 06:00 [pubmed]
PHST- 2023/02/14 07:13 [entrez]
PHST- 2023/02/14 00:00 [pmc-release]
AID - MBT214222 [pii]
AID - 10.1111/1751-7915.14222 [doi]
PST - ppublish
SO  - Microb Biotechnol. 2023 Jun;16(6):1131-1173. doi: 10.1111/1751-7915.14222. Epub 
      2023 Feb 14.

PMID- 39937452
OWN - NLM
STAT- Publisher
LR  - 20250212
IS  - 1528-1132 (Electronic)
IS  - 0009-921X (Linking)
DP  - 2025 Feb 11
TI  - Artificial Intelligence Shows Limited Success in Improving Readability Levels of 
      Spanish-language Orthopaedic Patient Education Materials.
LID - 10.1097/CORR.0000000000003413 [doi]
AB  - BACKGROUND: The more than 41 million people in the United States who speak 
      Spanish represent one of the fastest-growing US populations. Non-English-speaking 
      patients often face poorer health outcomes because of language barriers that 
      hinder patient education. Orthopaedic education materials have limited 
      availability in Spanish and may be difficult for some patients to read. The 
      American Academy of Orthopaedic Surgeons (AAOS) has translated education 
      materials into Spanish, but their readability levels remain unknown. 
      Additionally, although artificial intelligence (AI) dialogue platforms have been 
      shown to improve readability in English, no studies have specifically evaluated 
      their effectiveness in non-English languages. QUESTIONS/PURPOSES: (1) What is the 
      readability of AAOS Spanish-language education materials? (2) Can an AI dialogue 
      platform improve the readability of Spanish-language education materials while 
      maintaining their accuracy and usefulness? METHODS: After excluding COVID-19 
      articles and inaccessible websites, Spanish-language education materials were 
      extracted from the AAOS OrthoInfo website, and their Fernández-Huerta and Spanish 
      Orthographic Length (SOL) readability grade levels were calculated. 
      Fernández-Huerta focuses on syntactic complexity (sentence and syllable 
      structure) and SOL assesses lexical complexity (word length and frequency). For 
      both, the higher the grade level, the harder it is to read. Education materials 
      with a reading level above the sixth-grade level were inputted into the ChatGPT-4 
      AI platform to be adapted to a fifth-grade level. Readability metrics of the 
      adaptations were reassessed and compared with the original versions. Secondarily, 
      one of four Spanish-speaking orthopaedic surgeons evaluated each AI-adapted 
      education material for accuracy and usefulness compared with the original 
      version. We used a single review per material, trusting the orthopaedic surgeon's 
      expertise to minimize discrepancies. We included a total of 77 of 82 education 
      materials covering topics like diseases and conditions, treatment, and recovery 
      and staying healthy. RESULTS: Before AI adaptations, none of the 77 education 
      materials met the recommended reading level of sixth grade or below according to 
      both readability formulas. The original education materials were written at a 
      seventh- to eighth-grade reading level in 32% of cases (25 of 77). In comparison, 
      after a single attempt at simplification, AI-adapted materials achieved this 
      reading level in 53% of cases (41 of 77; p < 0.001). Only 23% (18) and 16% (12) 
      of the AI adaptations were written at or below the recommended sixth-grade level 
      per the Fernández-Huerta and SOL grade levels, respectively. Of the AI 
      adaptations, 52% (40) were rated as accurate and 56% (43) were rated as useful 
      for patient education by the evaluating orthopaedic surgeons. AI adaptations that 
      were classified as accurate or useful had a higher median (IQR) word count than 
      those that were inaccurate (accurate 255 [216 to 331] versus inaccurate 236 [209 
      to 256]; p = 0.04) or not useful (useful 257 [216 to 337] versus not useful 233 
      [209 to 251]; p = 0.01). CONCLUSION: Ongoing attention is needed to improve the 
      readability of Spanish education materials to reduce health disparities. 
      ChatGPT-4 has limited success in improving readability without compromising 
      accuracy and usefulness. We urge AAOS to enhance the readability of these 
      materials and recommend physicians use them as supplemental resources while 
      prioritizing direct patient education for Spanish-speaking individuals. Further 
      research is needed to develop readable and culturally appropriate education 
      materials for non-English-speaking patients that incorporate direct patient 
      feedback. CLINICAL RELEVANCE: This study shows that Spanish-language orthopaedic 
      materials often exceed recommended readability levels, limiting their 
      effectiveness and worsening health disparities. While AI tools like ChatGPT-4 
      improve readability, they may fall short in accuracy and usefulness. This 
      underscores the need for clearer, culturally appropriate materials and the 
      importance of physicians providing direct education.
CI  - Copyright © 2025 by the Association of Bone and Joint Surgeons.
FAU - Busigó Torres, Rodnell
AU  - Busigó Torres R
AUID- ORCID: 0009-0001-6118-8962
AD  - Leni and Peter W. May Department of Orthopaedic Surgery, Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Restrepo, Mariana
AU  - Restrepo M
AD  - Leni and Peter W. May Department of Orthopaedic Surgery, Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
FAU - Stern, Brocha Z
AU  - Stern BZ
AUID- ORCID: 0000-0001-6604-7096
AD  - Leni and Peter W. May Department of Orthopaedic Surgery, Icahn School of Medicine 
      at Mount Sinai, New York, NY, USA.
AD  - Institute for Health Care Delivery Science, Department of Population Health 
      Science and Policy, Icahn School of Medicine at Mount Sinai, New York, NY, USA.
FAU - Yahuaca, B Israel
AU  - Yahuaca BI
AD  - Department of Orthopedic Surgery, Franciscan Physician Network, Michigan City, 
      IN, USA.
FAU - Buerba, Rafael A
AU  - Buerba RA
AD  - Banner University Sports Medicine Center, Department of Orthopaedic Surgery, 
      University of Arizona College of Medicine-Phoenix, Phoenix, AZ, USA.
FAU - García, Ivan A
AU  - García IA
AD  - Department of Orthopedic Surgery, Southern California Permanente Medical Group, 
      Baldwin Park, CA, USA.
FAU - Hernandez, Victor H
AU  - Hernandez VH
AD  - Department of Orthopaedic Surgery and Rehabilitation, University of Miami Miller 
      School of Medicine/Jackson Memorial Hospital, Miami, FL, USA.
FAU - Navarro, Ronald A
AU  - Navarro RA
AD  - Department of Orthopaedic Surgery, Southern California Permanente Medical Group, 
      Harbor City, CA, USA.
LA  - eng
PT  - Journal Article
DEP - 20250211
PL  - United States
TA  - Clin Orthop Relat Res
JT  - Clinical orthopaedics and related research
JID - 0075674
SB  - IM
COIS- Each author certifies that there are no funding or commercial associations 
      (consultancies, stock ownership, equity interest, patent/licensing arrangements, 
      etc.) that might pose a conflict of interest in connection with the submitted 
      article related to the author or any immediate family members. All ICMJE Conflict 
      of Interest Forms for authors and Clinical Orthopaedics and Related Research® 
      editors and board members are on file with the publication and can be viewed on 
      request.
EDAT- 2025/02/12 12:25
MHDA- 2025/02/12 12:25
CRDT- 2025/02/12 11:27
PHST- 2024/10/31 00:00 [received]
PHST- 2025/01/21 00:00 [accepted]
PHST- 2025/02/12 12:25 [medline]
PHST- 2025/02/12 12:25 [pubmed]
PHST- 2025/02/12 11:27 [entrez]
AID - 00003086-990000000-01907 [pii]
AID - 10.1097/CORR.0000000000003413 [doi]
PST - aheadofprint
SO  - Clin Orthop Relat Res. 2025 Feb 11. doi: 10.1097/CORR.0000000000003413.

PMID- 39871015
OWN - NLM
STAT- Publisher
LR  - 20250127
IS  - 1476-5497 (Electronic)
IS  - 0307-0565 (Linking)
DP  - 2025 Jan 27
TI  - Assessing online chat-based artificial intelligence models for weight loss 
      recommendation appropriateness and bias in the presence of guideline 
      incongruence.
LID - 10.1038/s41366-025-01717-5 [doi]
AB  - BACKGROUND AND AIM: Managing obesity requires a comprehensive approach that 
      involves therapeutic lifestyle changes, medications, or metabolic surgery. Many 
      patients seek health information from online sources and artificial intelligence 
      models like ChatGPT, Google Gemini, and Microsoft Copilot before consulting 
      health professionals. This study aims to evaluate the appropriateness of the 
      responses of Google Gemini and Microsoft Copilot to questions on pharmacologic 
      and surgical management of obesity and assess for bias in their responses to 
      either the ADA or AACE guidelines. METHODS: Ten questions were compiled into a 
      set and posed separately to the free editions of Google Gemini and Microsoft 
      Copilot. Recommendations for the questions were extracted from the ADA and the 
      AACE websites, and the responses were graded by reviewers for appropriateness, 
      completeness, and bias to any of the guidelines. RESULTS: All responses from 
      Microsoft Copilot and 8/10 (80%) responses from Google Gemini were appropriate. 
      There were no inappropriate responses. Google Gemini refused to respond to two 
      questions and insisted on consulting a physician. Microsoft Copilot (10/10; 100%) 
      provided a higher proportion of complete responses than Google Gemini (5/10; 
      50%). Of the eight responses from Google Gemini, none were biased towards any of 
      the guidelines, while two of the responses from Microsoft Copilot were biased. 
      CONCLUSION: The study highlights the role of Microsoft Copilot and Google Gemini 
      in weight loss management. The differences in their responses may be attributed 
      to the variation in the quality and scope of their training data and design.
CI  - © 2025. The Author(s), under exclusive licence to Springer Nature Limited.
FAU - Annor, Eugene
AU  - Annor E
AUID- ORCID: 0000-0001-8602-3980
AD  - Department of Internal Medicine, University of Illinois College of Medicine, 
      Peoria, IL, USA. eug.annor@gmail.com.
FAU - Atarere, Joseph
AU  - Atarere J
AD  - Department of Medicine, MedStar Health, Baltimore, MD, USA.
FAU - Ubah, Nneoma
AU  - Ubah N
AD  - Department of Internal Medicine, Montefiore St. Luke's Cornwall Hospital, 
      Newburgh, NY, USA.
FAU - Jolaoye, Oladoyin
AU  - Jolaoye O
AD  - Department of Internal Medicine, University of Illinois College of Medicine, 
      Peoria, IL, USA.
FAU - Kunkle, Bryce
AU  - Kunkle B
AD  - Department of Medicine, Georgetown University Hospital, Washington, DC, USA.
FAU - Egbo, Olachi
AU  - Egbo O
AD  - Department of Medicine, Aurora Medical Center, Oshkosh, WI, USA.
FAU - Martin, Daniel K
AU  - Martin DK
AD  - Department of Gastroenterology and Hepatology, University of Illinois College of 
      Medicine, Peoria, IL, USA.
LA  - eng
PT  - Journal Article
DEP - 20250127
PL  - England
TA  - Int J Obes (Lond)
JT  - International journal of obesity (2005)
JID - 101256108
SB  - IM
COIS- Competing interests: The authors declare no competing interests. Ethics approval 
      and consent to participate: This study does not contain identifying information 
      about the patients. The study was performed in accordance with the ethical 
      standards laid down in the 1964 Declaration of Helsinki and its subsequent 
      amendments.
EDAT- 2025/01/28 00:21
MHDA- 2025/01/28 00:21
CRDT- 2025/01/27 23:29
PHST- 2024/08/12 00:00 [received]
PHST- 2025/01/14 00:00 [accepted]
PHST- 2024/12/17 00:00 [revised]
PHST- 2025/01/28 00:21 [medline]
PHST- 2025/01/28 00:21 [pubmed]
PHST- 2025/01/27 23:29 [entrez]
AID - 10.1038/s41366-025-01717-5 [pii]
AID - 10.1038/s41366-025-01717-5 [doi]
PST - aheadofprint
SO  - Int J Obes (Lond). 2025 Jan 27. doi: 10.1038/s41366-025-01717-5.

PMID- 39602221
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241214
IS  - 2817-1705 (Electronic)
IS  - 2817-1705 (Linking)
VI  - 3
DP  - 2024 Nov 27
TI  - Ensuring Appropriate Representation in Artificial Intelligence-Generated Medical 
      Imagery: Protocol for a Methodological Approach to Address Skin Tone Bias.
PG  - e58275
LID - 10.2196/58275 [doi]
LID - e58275
AB  - BACKGROUND: In medical education, particularly in anatomy and dermatology, 
      generative artificial intelligence (AI) can be used to create customized 
      illustrations. However, the underrepresentation of darker skin tones in medical 
      textbooks and elsewhere, which serve as training data for AI, poses a significant 
      challenge in ensuring diverse and inclusive educational materials. OBJECTIVE: 
      This study aims to evaluate the extent of skin tone diversity in AI-generated 
      medical images and to test whether the representation of skin tones can be 
      improved by modifying AI prompts to better reflect the demographic makeup of the 
      US population. METHODS: In total, 2 standard AI models (Dall-E [OpenAI] and 
      Midjourney [Midjourney Inc]) each generated 100 images of people with psoriasis. 
      In addition, a custom model was developed that incorporated a prompt injection 
      aimed at "forcing" the AI (Dall-E 3) to reflect the skin tone distribution of the 
      US population according to the 2012 American National Election Survey. This 
      custom model generated another set of 100 images. The skin tones in these images 
      were assessed by 3 researchers using the New Immigrant Survey skin tone scale, 
      with the median value representing each image. A chi-square goodness of fit 
      analysis compared the skin tone distributions from each set of images to that of 
      the US population. RESULTS: The standard AI models (Dalle-3 and Midjourney) 
      demonstrated a significant difference between the expected skin tones of the US 
      population and the observed tones in the generated images (P<.001). Both standard 
      AI models overrepresented lighter skin. Conversely, the custom model with the 
      modified prompt yielded a distribution of skin tones that closely matched the 
      expected demographic representation, showing no significant difference (P=.04). 
      CONCLUSIONS: This study reveals a notable bias in AI-generated medical images, 
      predominantly underrepresenting darker skin tones. This bias can be effectively 
      addressed by modifying AI prompts to incorporate real-life demographic 
      distributions. The findings emphasize the need for conscious efforts in AI 
      development to ensure diverse and representative outputs, particularly in 
      educational and medical contexts. Users of generative AI tools should be aware 
      that these biases exist, and that similar tendencies may also exist in other 
      types of generative AI (eg, large language models) and in other characteristics 
      (eg, sex, gender, culture, and ethnicity). Injecting demographic data into AI 
      prompts may effectively counteract these biases, ensuring a more accurate 
      representation of the general population.
CI  - ©Andrew O'Malley, Miriam Veenhuizen, Ayla Ahmed. Originally published in JMIR AI 
      (https://ai.jmir.org), 27.11.2024.
FAU - O'Malley, Andrew
AU  - O'Malley A
AUID- ORCID: 0000-0001-7725-4082
AD  - School of Medicine, University of St Andrews, St Andrews, United Kingdom.
FAU - Veenhuizen, Miriam
AU  - Veenhuizen M
AUID- ORCID: 0000-0003-4428-2049
AD  - School of Medicine, University of St Andrews, St Andrews, United Kingdom.
FAU - Ahmed, Ayla
AU  - Ahmed A
AUID- ORCID: 0009-0009-5618-8173
AD  - School of Medicine, University of St Andrews, St Andrews, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20241127
PL  - Canada
TA  - JMIR AI
JT  - JMIR AI
JID - 9918645789006676
PMC - PMC11635324
OTO - NOTNLM
OT  - AI images
OT  - United States
OT  - anatomy
OT  - artificial intelligence
OT  - dermatology
OT  - digital imagery
OT  - educational material
OT  - generative AI
OT  - medical education
OT  - medical imaging
OT  - psoriasis
OT  - skin
OT  - skin tone
COIS- Conflicts of Interest: None declared.
EDAT- 2024/11/27 12:38
MHDA- 2024/11/27 12:39
PMCR- 2024/11/27
CRDT- 2024/11/27 11:53
PHST- 2024/03/11 00:00 [received]
PHST- 2024/10/01 00:00 [accepted]
PHST- 2024/03/18 00:00 [revised]
PHST- 2024/11/27 12:39 [medline]
PHST- 2024/11/27 12:38 [pubmed]
PHST- 2024/11/27 11:53 [entrez]
PHST- 2024/11/27 00:00 [pmc-release]
AID - v3i1e58275 [pii]
AID - 10.2196/58275 [doi]
PST - epublish
SO  - JMIR AI. 2024 Nov 27;3:e58275. doi: 10.2196/58275.

PMID- 39517994
OWN - NLM
STAT- MEDLINE
DCOM- 20241109
LR  - 20241116
IS  - 1424-8220 (Electronic)
IS  - 1424-8220 (Linking)
VI  - 24
IP  - 21
DP  - 2024 Nov 4
TI  - Improving Factuality by Contrastive Decoding with Factual and Hallucination 
      Prompts.
LID - 10.3390/s24217097 [doi]
LID - 7097
AB  - Large language models have demonstrated impressive capabilities in many domains. 
      But they sometimes generate irrelevant or nonsensical text, or produce outputs 
      that deviate from the provided input, an occurrence commonly referred to as 
      hallucination. To mitigate this issue, we introduce a novel decoding method that 
      incorporates both factual and hallucination prompts (DFHP). It applies 
      contrastive decoding to highlight the disparity in output probabilities between 
      factual prompts and hallucination prompts. Experiments on both multiple-choice 
      and text generation tasks show that our approach significantly improves factual 
      accuracy of large language models without additional training. On the TruthfulQA 
      dataset, the DFHP method significantly improves factual accuracy of the LLaMA 
      model, with an average improvement of 6.4% for the 7B, 13B, 30B, and 65B 
      versions. Its high accuracy in factuality makes it an ideal choice for high 
      reliability tasks like medical diagnosis and legal cases.
FAU - Lv, Bojie
AU  - Lv B
AUID- ORCID: 0009-0000-3456-4398
AD  - School of Computer Science, Chengdu University of Information Technology, Chengdu 
      610225, China.
FAU - Feng, Ao
AU  - Feng A
AUID- ORCID: 0000-0001-6231-7810
AD  - School of Computer Science, Chengdu University of Information Technology, Chengdu 
      610225, China.
FAU - Xie, Chenlong
AU  - Xie C
AD  - School of Computer Science, Chengdu University of Information Technology, Chengdu 
      610225, China.
LA  - eng
GR  - 2023YFS0453/Sichuan Science/
GR  - 2024YFFK0251/Technology program/
PT  - Journal Article
DEP - 20241104
PL  - Switzerland
TA  - Sensors (Basel)
JT  - Sensors (Basel, Switzerland)
JID - 101204366
SB  - IM
MH  - Humans
MH  - *Language
MH  - Hallucinations
MH  - Algorithms
PMC - PMC11548250
OTO - NOTNLM
OT  - contrastive decoding
OT  - hallucination
OT  - large language model
OT  - prompt
COIS- The authors declare no conflicts of interest.
EDAT- 2024/11/13 13:56
MHDA- 2024/11/14 17:36
PMCR- 2024/11/04
CRDT- 2024/11/09 01:05
PHST- 2024/09/25 00:00 [received]
PHST- 2024/10/31 00:00 [revised]
PHST- 2024/10/31 00:00 [accepted]
PHST- 2024/11/14 17:36 [medline]
PHST- 2024/11/13 13:56 [pubmed]
PHST- 2024/11/09 01:05 [entrez]
PHST- 2024/11/04 00:00 [pmc-release]
AID - s24217097 [pii]
AID - sensors-24-07097 [pii]
AID - 10.3390/s24217097 [doi]
PST - epublish
SO  - Sensors (Basel). 2024 Nov 4;24(21):7097. doi: 10.3390/s24217097.

PMID- 39320544
OWN - NLM
STAT- MEDLINE
DCOM- 20250116
LR  - 20250116
IS  - 1878-7649 (Print)
IS  - 1878-7649 (Linking)
VI  - 15
IP  - 6
DP  - 2024 Dec
TI  - Is Artificial Intelligence ageist?
PG  - 1957-1960
LID - 10.1007/s41999-024-01070-2 [doi]
AB  - INTRODUCTION: Generative Artificial Intelligence (AI) is a technological 
      innovation with wide applicability in daily life, which could help elderly 
      people. However, it raises potential conflicts, such as biases, omissions and 
      errors. METHODS: Descriptive study through the negative stereotypes towards aging 
      questionnaire (CENVE) conducted on chatbots ChatGPT, Gemini, Perplexity, YOUChat, 
      and Copilot was conducted. RESULTS: Of the chatbots studied, three were above 50% 
      in responses with negative stereotypes, Copilot with high ageism level results, 
      followed by Perplexity. In the health section, Copilot was the chatbot with the 
      most negative connotations regarding old age (13 out of 20 points). In the 
      personality section, Copilot scored 14 out of 20, followed by YOUChat. 
      CONCLUSION: The Copilot chatbot responded to the statements more ageistically 
      than the other platforms. These results highlight the importance of addressing 
      any potential biases in AI to ensure that the responses provided are fair and 
      respectful for all potential users.
CI  - © 2024. The Author(s), under exclusive licence to European Geriatric Medicine 
      Society.
FAU - Aranda Rubio, Yanira
AU  - Aranda Rubio Y
AUID- ORCID: 0000-0003-1901-5811
AD  - Geriatrics Service, Hospital Universitario de la Cruz Roja, San José y Santa 
      Adela, Avenue Reina Victoria, 22-26, Moncloa-Aravaca, 28003, Madrid, Spain. 
      yanira.aranda@salud.madrid.org.
FAU - Baztán Cortés, Juan José
AU  - Baztán Cortés JJ
AD  - Geriatrics Service, Hospital Universitario de la Cruz Roja, San José y Santa 
      Adela, Avenue Reina Victoria, 22-26, Moncloa-Aravaca, 28003, Madrid, Spain.
FAU - Canillas Del Rey, Fernando
AU  - Canillas Del Rey F
AUID- ORCID: 0000-0002-3326-3494
AD  - Traumatology and Orthopedic Surgery Service, Hospital Universitario de la Cruz 
      Roja, San José y Santa Adela, Madrid, Spain.
LA  - eng
PT  - Journal Article
DEP - 20240925
PL  - Switzerland
TA  - Eur Geriatr Med
JT  - European geriatric medicine
JID - 101533694
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Generative Artificial Intelligence
MH  - *Ageism
MH  - Aging/psychology
MH  - Social Media
MH  - Stereotyping
MH  - Surveys and Questionnaires
OTO - NOTNLM
OT  - Chatbots
OT  - Generative Artificial Intelligence
OT  - Negative stereotypes
OT  - Older people
COIS- Declarations. Conflict of interest: The authors have no conflicts of interest. 
      Ethical approval: This study was conducted in accordance with the ethical 
      principles outlined in the Declaration of Helsinki. Informed consent: For this 
      type of study, no informed consent is required.
EDAT- 2024/09/25 12:45
MHDA- 2024/12/10 12:26
CRDT- 2024/09/25 11:17
PHST- 2024/07/04 00:00 [received]
PHST- 2024/09/11 00:00 [accepted]
PHST- 2024/12/10 12:26 [medline]
PHST- 2024/09/25 12:45 [pubmed]
PHST- 2024/09/25 11:17 [entrez]
AID - 10.1007/s41999-024-01070-2 [pii]
AID - 10.1007/s41999-024-01070-2 [doi]
PST - ppublish
SO  - Eur Geriatr Med. 2024 Dec;15(6):1957-1960. doi: 10.1007/s41999-024-01070-2. Epub 
      2024 Sep 25.

PMID- 38155290
OWN - NLM
STAT- MEDLINE
DCOM- 20250228
LR  - 20250228
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
VI  - 49
IP  - 3
DP  - 2025 Feb
TI  - Dr. GAI: Significance of Generative AI in Plastic Surgery.
PG  - 1011-1012
LID - 10.1007/s00266-023-03805-1 [doi]
AB  - In this letter to the editor, I offer a critique of the article titled 
      "Consulting the Digital Doctor: Google Versus ChatGPT as Sources of Information 
      on Breast Implant-Associated Anaplastic Large Cell Lymphoma and Breast Implant 
      Illness." While acknowledging the authors' pioneering effort to compare 
      informational outputs from Google and a generative AI (GAI)-ChatGPT, I raise 
      concerns about the methodology, lack of rigorous validation, potential biases, 
      and the overstatement of findings. The letter suggests that the authors' 
      conclusions about the superiority of ChatGPT in providing high-quality medical 
      information may be premature, given the limitations of the study design and the 
      evolving nature of artificial intelligence (AI) technology.No Level Assigned This 
      journal requires that authors assign a level of evidence to each submission to 
      which Evidence-Based Medicine rankings are applicable. This excludes Review 
      Articles, Book Reviews, and manuscripts that concern Basic Science, Animal 
      Studies, Cadaver Studies, and Experimental Studies. For a full description of 
      these Evidence-Based Medicine ratings, please refer to the Table of Contents or 
      the online Instructions to Authors www.springer.com/00266.
CI  - © 2023. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Ray, Partha Pratim
AU  - Ray PP
AUID- ORCID: 0000-0003-2306-2792
AD  - Department of Computer Applications, Sikkim University, 6th Mile, PO-Tadong, 
      Gangtok, Sikkim, 737102, India. ppray@cus.ac.in.
LA  - eng
PT  - Letter
DEP - 20231228
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Breast Implants/adverse effects
MH  - Female
MH  - Lymphoma, Large-Cell, Anaplastic/etiology
MH  - Surgery, Plastic/methods
MH  - Breast Implantation/methods/adverse effects
COIS- Declarations. Conflict of interest: The author declares that he has no conflicts 
      of interest to disclose. Ethical Approval and Consent to Participate: Not 
      applicable. Informed Consent: For this type of study informed consent is not 
      required. Statement of Human and Animal Rights: This article does not contain any 
      studies with human participants or animals performed by any of the authors.
EDAT- 2023/12/29 00:42
MHDA- 2025/03/01 14:39
CRDT- 2023/12/28 23:28
PHST- 2023/11/03 00:00 [received]
PHST- 2023/11/29 00:00 [accepted]
PHST- 2025/03/01 14:39 [medline]
PHST- 2023/12/29 00:42 [pubmed]
PHST- 2023/12/28 23:28 [entrez]
AID - 10.1007/s00266-023-03805-1 [pii]
AID - 10.1007/s00266-023-03805-1 [doi]
PST - ppublish
SO  - Aesthetic Plast Surg. 2025 Feb;49(3):1011-1012. doi: 10.1007/s00266-023-03805-1. 
      Epub 2023 Dec 28.

PMID- 40108629
OWN - NLM
STAT- MEDLINE
DCOM- 20250320
LR  - 20250322
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 25
IP  - 1
DP  - 2025 Mar 19
TI  - Integrating AI into clinical education: evaluating general practice trainees' 
      proficiency in distinguishing AI-generated hallucinations and impacting factors.
PG  - 406
LID - 10.1186/s12909-025-06916-2 [doi]
LID - 406
AB  - OBJECTIVE: To assess the ability of General Practice (GP) Trainees to detect 
      AI-generated hallucinations in simulated clinical practice, ChatGPT-4o was 
      utilized. The hallucinations were categorized into three types based on the 
      accuracy of the answers and explanations: (1) correct answers with incorrect or 
      flawed explanations, (2) incorrect answers with explanations that contradict 
      factual evidence, and (3) incorrect answers with correct explanations. METHODS: 
      This multi-center, cross-sectional survey study involved 142 GP Trainees, all of 
      whom were undergoing General Practice Specialist Training and volunteered to 
      participate. The study evaluated the accuracy and consistency of ChatGPT-4o, as 
      well as the Trainees' response time, accuracy, sensitivity (d'), and response 
      tendencies (β). Binary regression analysis was used to explore factors affecting 
      the Trainees' ability to identify errors generated by ChatGPT-4o. RESULTS: A 
      total of 137 participants were included, with a mean age of 25.93 years. Half of 
      the participants were unfamiliar with AI, and 35.0% had never used it. 
      ChatGPT-4o's overall accuracy was 80.8%, which slightly decreased to 80.1% after 
      human verification. However, the accuracy for professional practice (Subject 4) 
      was only 57.0%, and after human verification, it dropped further to 44.2%. A 
      total of 87 AI-generated hallucinations were identified, primarily occurring at 
      the application and evaluation levels. The mean accuracy of detecting these 
      hallucinations was 55.0%, and the mean sensitivity (d') was 0.39. Regression 
      analysis revealed that shorter response times (OR = 0.92, P = 0.02), higher 
      self-assessed AI understanding (OR = 0.16, P = 0.04), and more frequent AI use 
      (OR = 10.43, P = 0.01) were associated with stricter error detection criteria. 
      CONCLUSIONS: The study concluded that GP trainees faced challenges in identifying 
      ChatGPT-4o's errors, particularly in clinical scenarios. This highlights the 
      importance of improving AI literacy and critical thinking skills to ensure 
      effective integration of AI into medical education.
CI  - © 2025. The Author(s).
FAU - Zhou, Jiacheng
AU  - Zhou J
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China.
FAU - Zhang, Jintao
AU  - Zhang J
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China.
FAU - Wan, Rongrong
AU  - Wan R
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China.
FAU - Cui, Xiaochuan
AU  - Cui X
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China.
FAU - Liu, Qiyu
AU  - Liu Q
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China.
FAU - Guo, Hua
AU  - Guo H
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China.
FAU - Shi, Xiaofen
AU  - Shi X
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China.
FAU - Fu, Bingbing
AU  - Fu B
AD  - Department of Postgraduate Education, The First Affiliated Hospital of Jiamusi 
      University, Heilongjiang, China.
FAU - Meng, Jia
AU  - Meng J
AD  - Department of General Practice, The Second Affiliated Hospital of Harbin Medical 
      University, Heilongjiang, China.
FAU - Yue, Bo
AU  - Yue B
AD  - Residency Training Center, The Second Affiliated Hospital of Qiqihar Medical 
      University, Heilongjiang, China.
FAU - Zhang, Yunyun
AU  - Zhang Y
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China. zhangyunyun026133@njmu.edu.cn.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China. zhangyunyun026133@njmu.edu.cn.
AD  - Department of Postgraduate Education, The First Affiliated Hospital of Jiamusi 
      University, Heilongjiang, China. zhangyunyun026133@njmu.edu.cn.
AD  - Education Department, The Affiliated Wuxi People's Hospital of Nanjing Medical 
      University, Wuxi Medical Center, Wuxi People's Hospital, Qingyang road 299, Wuxi, 
      China. zhangyunyun026133@njmu.edu.cn.
FAU - Zhang, Zhiyong
AU  - Zhang Z
AD  - Department of General Practice, The Affiliated Wuxi People's Hospital of Nanjing 
      Medical University, Wuxi, Jiangsu, China. zhangzhiyong0112@njmu.edu.cn.
AD  - Wuxi Medical Center, Nanjing Medical University, Wuxi People's Hospital, Wuxi, 
      Jiangsu, China. zhangzhiyong0112@njmu.edu.cn.
AD  - Department of Postgraduate Education, The First Affiliated Hospital of Jiamusi 
      University, Heilongjiang, China. zhangzhiyong0112@njmu.edu.cn.
AD  - Education Department, The Affiliated Wuxi People's Hospital of Nanjing Medical 
      University, Wuxi Medical Center, Wuxi People's Hospital, Qingyang road 299, Wuxi, 
      China. zhangzhiyong0112@njmu.edu.cn.
LA  - eng
GR  - KX-24-C154/Wuxi Association for Science and Technology/
GR  - 2024-YZ-HBDTR-ZYY-2024/Emerging Discipline Leader Program/
GR  - BJRC-8 and HB2023015/Top Talent Support Program for Young and Middle-aged people 
      of Wuxi Health Committee/
GR  - K20221023/Taihu Light Basic Research Project, Wuxi Municipal Science and 
      Technology Bureau/
PT  - Journal Article
PT  - Multicenter Study
DEP - 20250319
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - Humans
MH  - Cross-Sectional Studies
MH  - *Clinical Competence/standards
MH  - Male
MH  - Adult
MH  - *Hallucinations/diagnosis
MH  - Female
MH  - *General Practice/education
MH  - Artificial Intelligence
MH  - Educational Measurement
MH  - Young Adult
PMC - PMC11924592
OTO - NOTNLM
OT  - ChatGPT-4o generated hallucinations
OT  - General practice (GP) trainees
OT  - General practice specialist training
OT  - Response bias
COIS- Declarations. Ethical approval: Ethical approval has been obtained for this study 
      by Research Ethics Committee of Wuxi People’s Hospital, and all participants have 
      provided informed consent. Consent for publication: The authors provide their 
      consent for the publication of this article. Competing interests: The authors 
      declare no competing interests.
EDAT- 2025/03/20 06:24
MHDA- 2025/03/20 06:25
PMCR- 2025/03/19
CRDT- 2025/03/20 00:48
PHST- 2024/10/25 00:00 [received]
PHST- 2025/02/24 00:00 [accepted]
PHST- 2025/03/20 06:25 [medline]
PHST- 2025/03/20 06:24 [pubmed]
PHST- 2025/03/20 00:48 [entrez]
PHST- 2025/03/19 00:00 [pmc-release]
AID - 10.1186/s12909-025-06916-2 [pii]
AID - 6916 [pii]
AID - 10.1186/s12909-025-06916-2 [doi]
PST - epublish
SO  - BMC Med Educ. 2025 Mar 19;25(1):406. doi: 10.1186/s12909-025-06916-2.

PMID- 37789443
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20241012
IS  - 2052-3211 (Print)
IS  - 2052-3211 (Electronic)
IS  - 2052-3211 (Linking)
VI  - 16
IP  - 1
DP  - 2023 Oct 3
TI  - ChatGPT in pharmacy practice: a cross-sectional exploration of Jordanian 
      pharmacists' perception, practice, and concerns.
PG  - 115
LID - 10.1186/s40545-023-00624-2 [doi]
LID - 115
AB  - OBJECTIVES: The purpose of this study is to find out how much pharmacists know 
      and have used ChatGPT in their practice. We investigated the advantages and 
      disadvantages of utilizing ChatGPT in a pharmacy context, the amount of training 
      necessary to use it proficiently, and the influence on patient care using a 
      survey. METHODS: This cross-sectional study was carried out between May and June 
      2023 to assess the potential and problems that pharmacists observed while 
      integrating chatbots powered by AI (ChatGPT) in pharmacy practice. The 
      correlation between perceived benefits and concerns was evaluated using 
      Spearman's rho correlation due to the data's non-normal distribution.Any 
      pharmacists licensed by the Jordanian Pharmacists Association were included in 
      the study. A convenient sampling technique was used to choose the participants, 
      and the study questionnaire was distributed utilizing an online medium (Facebook 
      and WhatsApp). Anyone who expressed interest in taking part was given a link to 
      the study's instructions so they may read them before giving their electronic 
      consent and accessing the survey. RESULTS: The potential advantages of ChatGPT in 
      the pharmacy practice were widely acknowledged by the participants. The majority 
      of participants (69.9%) concurred that educational material about pharmacy items 
      or therapeutic areas can be provided using ChatGPT, with 66.9% of respondents 
      believing that ChatGPT is a machine learning algorithm. Concerns about the 
      accuracy of AI-generated responses were also prevalent. More than half of the 
      participants (55.7%) raised the possibility that AI systems such as ChatGPT could 
      pick up on and replicate prejudices and discriminatory patterns from the data 
      they were trained on. Analysis shows a statistically significant positive link, 
      albeit a minor one, between the perceived advantages of ChatGPT and its drawbacks 
      (r = 0.255, p < 0.001). However, concerns were strongly correlated with knowledge 
      of ChatGPT. In contrast to those who were either unsure or had not heard of 
      ChatGPT (64.2%), individuals who had heard of it were more likely to have strong 
      concerns (79.8%) (p = 0.002). Finally, the results show a statistically 
      significant association between the frequency of ChatGPT use and positive 
      perceptions of the tool (p < 0.001). CONCLUSIONS: Although ChatGPT has shown 
      promise in health and pharmaceutical practice, its application should be 
      rigorously regulated by evidence-based law. According to the study's findings, 
      pharmacists support the use of ChatGPT in pharmacy practice but have concerns 
      about its use due to ethical reasons, legal problems, privacy concerns, worries 
      about the accuracy of the data generated, data learning, and bias risk.
CI  - © 2023. Dr. Zaheer-Ud-Din Babar and Auckland UniServices Ltd.
FAU - Abu Hammour, Khawla
AU  - Abu Hammour K
AD  - Department of Clinical Pharmacy and Biopharmaceutics, Faculty of Pharmacy, 
      University of Jordan, Amman, Jordan.
FAU - Alhamad, Hamza
AU  - Alhamad H
AD  - Department of Clinical Pharmacy, Faculty of Pharmacy, Zarqa University, Zarqa, 
      Jordan.
FAU - Al-Ashwal, Fahmi Y
AU  - Al-Ashwal FY
AUID- ORCID: 0000-0003-2076-0771
AD  - Department of Clinical Pharmacy, College of Pharmacy, Al-Ayen University, 
      Thi-Qar, Iraq. fahmialashwal89@gmail.com.
AD  - Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmacy, 
      University of Science and Technology, Sana'a, Yemen. fahmialashwal89@gmail.com.
FAU - Halboup, Abdulsalam
AU  - Halboup A
AD  - Department of Clinical Pharmacy and Pharmacy Practice, Faculty of Pharmacy, 
      University of Science and Technology, Sana'a, Yemen.
AD  - Discipline of Clinical Pharmacy, School of Pharmaceutical Sciences, University 
      Sains Malaysia, Gelugor, Pulau Pinang, Malaysia.
FAU - Abu Farha, Rana
AU  - Abu Farha R
AD  - Clinical Pharmacy and Therapeutics Department, Faculty of Pharmacy, Applied 
      Science Private University, P.O. Box 11937, Amman, Jordan.
FAU - Abu Hammour, Adnan
AU  - Abu Hammour A
AD  - Medrise Medical Center, Dubai Healthcare City, Dubai, United Arab Emirates.
LA  - eng
PT  - Journal Article
DEP - 20231003
PL  - England
TA  - J Pharm Policy Pract
JT  - Journal of pharmaceutical policy and practice
JID - 101627192
EIN - J Pharm Policy Pract. 2023 Oct 30;16(1):129. doi: 10.1186/s40545-023-00640-2. 
      PMID: 37904185
PMC - PMC10548710
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Pharmacy practice
COIS- The Authors declare that there is no conflict of interest.
EDAT- 2023/10/04 00:42
MHDA- 2023/10/04 00:43
PMCR- 2023/10/03
CRDT- 2023/10/03 23:55
PHST- 2023/07/13 00:00 [received]
PHST- 2023/09/22 00:00 [accepted]
PHST- 2023/10/04 00:43 [medline]
PHST- 2023/10/04 00:42 [pubmed]
PHST- 2023/10/03 23:55 [entrez]
PHST- 2023/10/03 00:00 [pmc-release]
AID - 10.1186/s40545-023-00624-2 [pii]
AID - 624 [pii]
AID - 10.1186/s40545-023-00624-2 [doi]
PST - epublish
SO  - J Pharm Policy Pract. 2023 Oct 3;16(1):115. doi: 10.1186/s40545-023-00624-2.

PMID- 37426587
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240921
IS  - 2055-2076 (Print)
IS  - 2055-2076 (Electronic)
IS  - 2055-2076 (Linking)
VI  - 9
DP  - 2023 Jan-Dec
TI  - Improving accessibility of scientific research by artificial intelligence-An 
      example for lay abstract generation.
PG  - 20552076231186245
LID - 10.1177/20552076231186245 [doi]
LID - 20552076231186245
AB  - The role of scientific research in modern society is essential for driving 
      innovation, informing policy decisions, and shaping public opinion. However, 
      communicating scientific findings to the general public can be challenging due to 
      the technical and complex nature of scientific research. Lay abstracts are 
      written summaries of scientific research that are designed to be easily 
      understandable and provide a concise and clear overview of key findings and 
      implications. Artificial intelligence language models have the potential to 
      generate lay abstracts that are consistent and accurate while reducing the 
      potential for misinterpretation or bias. This study presents examples of 
      artificial intelligence-generated lay abstracts of recently published articles, 
      which were produced using different currently available artificial intelligence 
      tools. The generated abstracts were of high linguistic quality and accurately 
      represented the findings of the original articles. Adopting lay summaries can 
      increase the visibility, impact, and transparency of scientific research, and 
      enhance scientists' reputation among peers, while currently, available artificial 
      intelligence models offer solutions to produce lay abstracts. However, the 
      coherence and accuracy of artificial intelligence language models must be 
      validated before they can be used for this purpose without restrictions.
CI  - © The Author(s) 2023.
FAU - Schmitz, Boris
AU  - Schmitz B
AUID- ORCID: 0000-0001-7041-7424
AD  - Department of Rehabilitation Sciences, Faculty of Health, University of 
      Witten/Herdecke, Witten, Germany.
AD  - DRV Clinic Königsfeld, Center for Medical Rehabilitation, Ennepetal, Germany.
LA  - eng
PT  - Journal Article
DEP - 20230629
PL  - United States
TA  - Digit Health
JT  - Digital health
JID - 101690863
PMC - PMC10328007
OTO - NOTNLM
OT  - Artificial intelligence
OT  - digital
OT  - education
OT  - health communications
OT  - technology
COIS- The author(s) declared no potential conflicts of interest with respect to the 
      research, authorship, and/or publication of this article.
EDAT- 2023/07/10 06:42
MHDA- 2023/07/10 06:43
PMCR- 2023/06/29
CRDT- 2023/07/10 05:12
PHST- 2023/05/10 00:00 [received]
PHST- 2023/06/19 00:00 [accepted]
PHST- 2023/07/10 06:43 [medline]
PHST- 2023/07/10 06:42 [pubmed]
PHST- 2023/07/10 05:12 [entrez]
PHST- 2023/06/29 00:00 [pmc-release]
AID - 10.1177_20552076231186245 [pii]
AID - 10.1177/20552076231186245 [doi]
PST - epublish
SO  - Digit Health. 2023 Jun 29;9:20552076231186245. doi: 10.1177/20552076231186245. 
      eCollection 2023 Jan-Dec.

PMID- 37256297
OWN - NLM
STAT- MEDLINE
DCOM- 20231023
LR  - 20240205
IS  - 1432-5241 (Electronic)
IS  - 0364-216X (Linking)
VI  - 47
IP  - 5
DP  - 2023 Oct
TI  - The Artificial Intelligence application in Aesthetic Medicine: How ChatGPT can 
      Revolutionize the Aesthetic World.
PG  - 2211-2212
LID - 10.1007/s00266-023-03416-w [doi]
AB  - Aesthetic medicine is witnessing a growing importance of ChatGPT and artificial 
      intelligence (AI) technologies, as highlighted by the pioneering work of Xie et 
      al. in their article, "Aesthetic Surgery Advice and Counseling from Artificial 
      Intelligence: A Rhinoplasty Consultation with ChatGPT." These advancements 
      promise to revolutionize patient consultations, treatment planning, and follow-up 
      care. AI-driven chatbots, such as ChatGPT, can enhance patient consultations by 
      providing accurate and reliable information on aesthetic procedures, their risks, 
      benefits, and potential outcomes, enabling well-informed decisions and improved 
      treatment outcomes. Furthermore, AI can personalize treatment plans by analyzing 
      patient data, leading to increased precision and satisfaction. AI-powered 
      platforms can also streamline patient follow-up and monitoring, improving patient 
      outcomes and resource utilization, while serving as a valuable educational tool 
      for clinicians. Despite these benefits, AI integration in aesthetic medicine 
      raises concerns about data privacy, security, and potential biases in AI 
      algorithms. To address these challenges, the aesthetic medicine community must 
      establish ethical guidelines, adopt stringent security protocols, and ensure 
      diverse and representative datasets for AI training. Additionally, maintaining 
      the personal connection between patients and providers is crucial for preserving 
      the human touch in patient care.Level of Evidence V This journal requires that 
      authors assign a level of evidence to each article. For a full description of 
      these Evidence-Based Medicine ratings, please refer to the Table of Contents or 
      the online Instructions to Authors https://www.springer.com/00266 .
CI  - © 2023. Springer Science+Business Media, LLC, part of Springer Nature and 
      International Society of Aesthetic Plastic Surgery.
FAU - Buzzaccarini, Giovanni
AU  - Buzzaccarini G
AUID- ORCID: 0000-0002-9466-0178
AD  - Department of Obstetrics and Gynaecology, IRCCS San Raffaele Scientific 
      Institute, Vita-Salute San Raffaele University, Via Olgettina 58-60, 20132, 
      Milan, Italy. giovanni.buzzaccarini@gmail.com.
FAU - Degliuomini, Rebecca Susanna
AU  - Degliuomini RS
AD  - Department of Obstetrics and Gynaecology, IRCCS San Raffaele Scientific 
      Institute, Vita-Salute San Raffaele University, Via Olgettina 58-60, 20132, 
      Milan, Italy.
FAU - Borin, Marco
AU  - Borin M
AD  - U.O.C. Otorhinolaryngology, ASST Grande Ospedale Metropolitano Niguarda, Piazza 
      Ospedale Maggiore, 3, 20162, Milan, Italy.
LA  - eng
PT  - Comment
PT  - Letter
DEP - 20230531
PL  - United States
TA  - Aesthetic Plast Surg
JT  - Aesthetic plastic surgery
JID - 7701756
SB  - IM
CON - Aesthetic Plast Surg. 2023 Oct;47(5):1985-1993. doi: 10.1007/s00266-023-03338-7. 
      PMID: 37095384
CIN - Aesthetic Plast Surg. 2023 Oct;47(5):2213-2214. doi: 10.1007/s00266-023-03439-3. 
      PMID: 37314465
MH  - Humans
MH  - *Surgery, Plastic/methods
MH  - Artificial Intelligence
MH  - *Rhinoplasty/methods
MH  - Treatment Outcome
MH  - Esthetics
EDAT- 2023/05/31 13:12
MHDA- 2023/10/23 00:42
CRDT- 2023/05/31 11:03
PHST- 2023/05/10 00:00 [received]
PHST- 2023/05/11 00:00 [accepted]
PHST- 2023/10/23 00:42 [medline]
PHST- 2023/05/31 13:12 [pubmed]
PHST- 2023/05/31 11:03 [entrez]
AID - 10.1007/s00266-023-03416-w [pii]
AID - 10.1007/s00266-023-03416-w [doi]
PST - ppublish
SO  - Aesthetic Plast Surg. 2023 Oct;47(5):2211-2212. doi: 10.1007/s00266-023-03416-w. 
      Epub 2023 May 31.

PMID- 39923098
OWN - NLM
STAT- MEDLINE
DCOM- 20250208
LR  - 20250211
IS  - 1472-6920 (Electronic)
IS  - 1472-6920 (Linking)
VI  - 25
IP  - 1
DP  - 2025 Feb 8
TI  - Exploring medical students' intention to use of ChatGPT from a programming 
      course: a grounded theory study in China.
PG  - 209
LID - 10.1186/s12909-025-06807-6 [doi]
LID - 209
AB  - BACKGROUND: In interdisciplinary general education courses, medical students face 
      the daunting challenge of learning programming due to academic pressure, 
      cognitive biases, and differences in thinking patterns. ChatGPT provides an 
      effective way for people to acquire knowledge, improve learning efficiency, and 
      quality. OBJECTIVE: To explore whether medical students can be assisted in 
      learning programming with the help of ChatGPT, it is necessary to investigate 
      their experience and perception of using ChatGPT, and to study which factors 
      influence their willingness to use ChatGPT. METHODS: Drawing on the grounded 
      theory research paradigm, this paper constructs a research model of the 
      influencing factors of ChatGPT usage willingness for medical students in 
      programming courses through the analysis of interview data from 30 undergraduate 
      medical students. It analyzes and discusses the cognition and influencing factors 
      of medical students' willingness to use ChatGPT in programming learning. RESULTS: 
      The willingness to use ChatGPT in programming learning is divided into three 
      types based on the students' subjective degree of use: active use, neutral use, 
      and negative use. It is also found that individual factors, technical factors, 
      information factors, and environmental factors are four important dimensions 
      affecting the willingness to use ChatGPT. CONCLUSIONS: Based on the analysis of 
      influencing factors, strategies and suggestions such as preventing risks and 
      focusing on ethical education, cultivating critical thinking and establishing a 
      case library, and personalized teaching to enhance core literacy in programming 
      are proposed.
CI  - © 2025. The Author(s).
FAU - Wang, Chen
AU  - Wang C
AD  - Department of Health Informatics and Management, School of Health Humanities, 
      Peking University, Beijing, 100191, China.
FAU - Xiao, Changqi
AU  - Xiao C
AD  - School of Nursing, Peking University, Beijing, 100191, China.
FAU - Zhang, Xuejiao
AU  - Zhang X
AD  - School of Nursing, Peking University, Beijing, 100191, China.
FAU - Zhu, Yingying
AU  - Zhu Y
AD  - School of Nursing, Peking University, Beijing, 100191, China.
FAU - Chen, Xueqing
AU  - Chen X
AD  - School of Nursing, Peking University, Beijing, 100191, China.
FAU - Li, Yilin
AU  - Li Y
AD  - School of Basic Medical Sciences, Capital Medical University, Beijing, 100069, 
      China.
FAU - Qi, Huiying
AU  - Qi H
AD  - Department of Health Informatics and Management, School of Health Humanities, 
      Peking University, Beijing, 100191, China. qhy@bjmu.edu.cn.
LA  - eng
GR  - 2024AI28/Peking University's AI-Enhanced Curriculum Development/
GR  - 2024-AFCEC-008/Research Project on Computer Basic Education Teaching by the 
      National Association for Computer Basic Education in Higher Education 
      Institutions/
PT  - Journal Article
DEP - 20250208
PL  - England
TA  - BMC Med Educ
JT  - BMC medical education
JID - 101088679
SB  - IM
MH  - Humans
MH  - *Students, Medical/psychology
MH  - *Grounded Theory
MH  - China
MH  - Female
MH  - Male
MH  - *Education, Medical, Undergraduate
MH  - *Intention
MH  - Young Adult
MH  - Curriculum
PMC - PMC11806607
OTO - NOTNLM
OT  - ChatGPT
OT  - Grounded theory
OT  - Medical students
OT  - Programming course
OT  - Use intention
COIS- Declarations. Ethical approval and consent to participate: The participants of 
      this study were medical students who participated in university computer courses. 
      The interview was conducted face-to-face and informed consent was taken. Before 
      the interview, the contents of the informed consent form and the outline of the 
      interview were read to the participants, and all participants gave signed 
      informed consent. The Institutional Research Board of Peking University approved 
      the informed consent and the full research proposal. (IRB00001052-24025). Consent 
      for publication: Not applicable. There are no details on individuals reported 
      within the manuscript. Conflict of interest: The authors declare that they have 
      no competing interests.
EDAT- 2025/02/09 06:20
MHDA- 2025/02/09 06:21
PMCR- 2025/02/08
CRDT- 2025/02/08 23:27
PHST- 2024/07/30 00:00 [received]
PHST- 2025/02/02 00:00 [accepted]
PHST- 2025/02/09 06:21 [medline]
PHST- 2025/02/09 06:20 [pubmed]
PHST- 2025/02/08 23:27 [entrez]
PHST- 2025/02/08 00:00 [pmc-release]
AID - 10.1186/s12909-025-06807-6 [pii]
AID - 6807 [pii]
AID - 10.1186/s12909-025-06807-6 [doi]
PST - epublish
SO  - BMC Med Educ. 2025 Feb 8;25(1):209. doi: 10.1186/s12909-025-06807-6.

PMID- 39891376
OWN - NLM
STAT- Publisher
LR  - 20250201
IS  - 1600-0579 (Electronic)
IS  - 1396-5883 (Linking)
DP  - 2025 Jan 31
TI  - Integrating Generative AI in Dental Education: A Scoping Review of Current 
      Practices and Recommendations.
LID - 10.1111/eje.13074 [doi]
AB  - BACKGROUND: Generative AI (GenAI) tools like ChatGPT are increasingly relevant in 
      dental education, offering potential enhancements in personalised learning and 
      clinical reasoning. However, specific guidance from dental institutions remains 
      unexplored. AIM: To identify, analyse and summarise existing guidelines from 
      universities and organisations on using GenAI in dental education, focusing on 
      recommendations for academic staff. METHODS: A scoping review 
      (10.17605/OSF.IO/3XMP7) searched for GenAI guidance on university websites, 
      search engines (Google Search, Scholar, Perplexity and PubMed) and through 
      contacting relevant academics (January 2022 to June 2024). Two reviewers 
      independently screened and extracted data, including implementation details, AI 
      tools and permitted/prohibited uses. Thematic analysis revealed common 
      applications, benefits, challenges and recommendations. RESULTS: Thirty-one 
      unique documents were included from 21 universities in 15 countries and three 
      international organisations. Thematic analysis identified common applications, 
      benefits, challenges and recommendations for integrating GenAI, including 
      facilitating teaching and learning, personalised learning, efficient content 
      creation and encouraging critical thinking. However, challenges such as academic 
      integrity, ethical use, bias and privacy issues were also identified. No dental 
      education-specific guidelines were found. CONCLUSION: This review identified and 
      summarised existing GenAI guidelines from universities and organisations relevant 
      to dental education. The guidelines emphasise ethical use, transparency, academic 
      integrity, secure environments and AI misuse detection tools. However, the 
      absence of dental specific guidance presents an opportunity to fill this gap, 
      providing recommendations for academic staff to integrate GenAI effectively while 
      promoting critical thinking and responsible AI use.
CI  - © 2025 The Author(s). European Journal of Dental Education published by John 
      Wiley & Sons Ltd.
FAU - Uribe, Sergio E
AU  - Uribe SE
AUID- ORCID: 0000-0003-0684-2025
AD  - Department of Conservative Dentistry and Oral Health, Riga Stradins University, 
      Riga, Latvia.
AD  - Baltic Biomaterials Centre of Excellence, Headquarters at Riga Technical 
      University, Riga, Latvia & Institute of Stomatology, Riga Stradins University, 
      Riga, Latvia.
AD  - Clinic for Conservative Dentistry and Periodontology, LMU Klinikum, Munich, 
      Germany.
FAU - Maldupa, Ilze
AU  - Maldupa I
AUID- ORCID: 0000-0002-5967-956X
AD  - Department of Conservative Dentistry and Oral Health, Riga Stradins University, 
      Riga, Latvia.
FAU - Schwendicke, Falk
AU  - Schwendicke F
AUID- ORCID: 0000-0003-1223-1669
AD  - Clinic for Conservative Dentistry and Periodontology, LMU Klinikum, Munich, 
      Germany.
LA  - eng
GR  - lzp-2022/1-0047/Latvijas Zinātnes Padome, IEVA Project/
GR  - 857287/European Union's Horizon 2020 research and innovation programme/
PT  - Journal Article
DEP - 20250131
PL  - England
TA  - Eur J Dent Educ
JT  - European journal of dental education : official journal of the Association for 
      Dental Education in Europe
JID - 9712132
SB  - IM
OTO - NOTNLM
OT  - artificial intelligence
OT  - dental education
OT  - generative artificial intelligence
OT  - implementation guidelines
EDAT- 2025/02/01 20:43
MHDA- 2025/02/01 20:43
CRDT- 2025/02/01 01:12
PHST- 2024/11/28 00:00 [revised]
PHST- 2024/06/30 00:00 [received]
PHST- 2025/01/15 00:00 [accepted]
PHST- 2025/02/01 20:43 [medline]
PHST- 2025/02/01 20:43 [pubmed]
PHST- 2025/02/01 01:12 [entrez]
AID - 10.1111/eje.13074 [doi]
PST - aheadofprint
SO  - Eur J Dent Educ. 2025 Jan 31. doi: 10.1111/eje.13074.

PMID- 39832364
OWN - NLM
STAT- In-Process
LR  - 20250206
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Jan 20
TI  - Advantages and Inconveniences of a Multi-Agent Large Language Model System to 
      Mitigate Cognitive Biases in Diagnostic Challenges.
PG  - e69742
LID - 10.2196/69742 [doi]
LID - e69742
FAU - Bousquet, Cedric
AU  - Bousquet C
AUID- ORCID: 0000-0001-9775-2476
AD  - Laboratory of Medical Informatics and Knowledge Engineering in e-Health, Inserm, 
      Sorbonne University, Paris, France.
AD  - Public Health and Medical Information Unit, Saint-Étienne University Hospital 
      Center, Saint-Etienne, France.
FAU - Beltramin, Divà
AU  - Beltramin D
AUID- ORCID: 0000-0001-8498-6150
AD  - Medical Information Department, Civil Hospices of Lyon, Lyon, France.
LA  - eng
PT  - Journal Article
DEP - 20250120
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
CON - J Med Internet Res. 26:e59439.
PMC - PMC11791434
OTO - NOTNLM
OT  - clinical decision-making
OT  - cognition
OT  - cognitive bias
OT  - diagnostic errors
OT  - generative artificial intelligence
OT  - large language model
OT  - multi-agent system
COIS- Conflicts of Interest: None declared.
EDAT- 2025/01/20 22:55
MHDA- 2025/01/20 22:55
PMCR- 2025/01/20
CRDT- 2025/01/20 16:53
PHST- 2024/12/06 00:00 [received]
PHST- 2024/12/11 00:00 [accepted]
PHST- 2025/01/20 22:55 [medline]
PHST- 2025/01/20 22:55 [pubmed]
PHST- 2025/01/20 16:53 [entrez]
PHST- 2025/01/20 00:00 [pmc-release]
AID - v27i1e69742 [pii]
AID - 10.2196/69742 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Jan 20;27:e69742. doi: 10.2196/69742.

PMID- 39805106
OWN - NLM
STAT- MEDLINE
DCOM- 20250113
LR  - 20250130
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Jan 13
TI  - Analysis of Reddit Discussions on Motivational Factors for Physical Activity: 
      Cross-Sectional Study.
PG  - e54489
LID - 10.2196/54489 [doi]
LID - e54489
AB  - BACKGROUND: Despite the ample benefits of physical activity (PA), many 
      individuals do not meet the minimum PA recommended by health organizations. 
      Structured questionnaires and interviews are commonly used to study why 
      individuals perform PA and their strategies to adhere to PA. However, certain 
      biases are inherent to these tools that limit what can be concluded from their 
      results. Collecting data from social media channels can complement these studies 
      and provide a more comprehensive overview of PA motives and adherence strategies. 
      OBJECTIVE: This study aims to investigate motives for engaging in PA, as well as 
      the associated strategies to achieve these goals, as stated by a large number of 
      people on a social media site. METHODS: We searched for users' responses 
      regarding PA motives and adherence strategies in Reddit forums dedicated to PA 
      and analyzed the data using (1) unsupervised clustering to identify topics from 
      the textual comments and (2) supervised classification to classify the comments 
      into the detected topics. A panel of experts participated in both steps for 
      annotation and validation purposes. RESULTS: We analyzed 1577 unique user 
      comments (representing 1577 individual users); of those, 1247 were linked to 
      physical appearance (mentioned in 298/1247, 23.9% of the comments) and improving 
      physical (235/1247, 18.9%) and mental health (211/1247, 16.9%), indicating these 
      as the main motivational factors. The main strategies people used to adhere to PA 
      were habit formation (373/1247, 30%), goal setting (173/1247, 13.9%), enjoyable 
      activities (151/1247, 12.1%), socializing (121/1247, 9.7%), using media 
      (111/1247, 8.9%), using different apps to monitor PA (35/1247, 2.8%), and 
      financial commitment (32/1247, 2.5%). CONCLUSIONS: This study presented a novel 
      approach using a language model to investigate why people engage in PA and the 
      strategies they use to adhere to PA using wide-scale, self-disclosed content from 
      popular social media channels.
CI  - ©Michal Shmueli-Scheuer, Yedidya Silverman, Israel Halperin, Yftach Gepner. 
      Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 13.01.2025.
FAU - Shmueli-Scheuer, Michal
AU  - Shmueli-Scheuer M
AUID- ORCID: 0000-0002-6386-8726
AD  - Department of Health Promotion, School of Public Health, Faculty of Medical and 
      Health Sciences, Tel Aviv University, Tel Aviv, Israel.
AD  - Sylvan Adams Sports Institute, Tel Aviv University, Tel Aviv, Israel.
FAU - Silverman, Yedidya
AU  - Silverman Y
AUID- ORCID: 0009-0009-2468-691X
AD  - Department of Health Promotion, School of Public Health, Faculty of Medical and 
      Health Sciences, Tel Aviv University, Tel Aviv, Israel.
AD  - Sylvan Adams Sports Institute, Tel Aviv University, Tel Aviv, Israel.
FAU - Halperin, Israel
AU  - Halperin I
AUID- ORCID: 0000-0003-2254-2698
AD  - Department of Health Promotion, School of Public Health, Faculty of Medical and 
      Health Sciences, Tel Aviv University, Tel Aviv, Israel.
AD  - Sylvan Adams Sports Institute, Tel Aviv University, Tel Aviv, Israel.
FAU - Gepner, Yftach
AU  - Gepner Y
AUID- ORCID: 0000-0002-3128-3539
AD  - Department of Health Promotion, School of Public Health, Faculty of Medical and 
      Health Sciences, Tel Aviv University, Tel Aviv, Israel.
AD  - Sylvan Adams Sports Institute, Tel Aviv University, Tel Aviv, Israel.
LA  - eng
PT  - Journal Article
DEP - 20250113
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Motivation
MH  - Cross-Sectional Studies
MH  - *Exercise/psychology
MH  - *Social Media
MH  - Surveys and Questionnaires
PMC - PMC11773284
OTO - NOTNLM
OT  - Reddit
OT  - adherence
OT  - motivation
OT  - physical activity
OT  - social media
COIS- Conflicts of Interest: None declared.
EDAT- 2025/01/13 18:21
MHDA- 2025/01/13 18:22
PMCR- 2025/01/13
CRDT- 2025/01/13 16:53
PHST- 2023/11/11 00:00 [received]
PHST- 2024/09/22 00:00 [accepted]
PHST- 2024/05/23 00:00 [revised]
PHST- 2025/01/13 18:22 [medline]
PHST- 2025/01/13 18:21 [pubmed]
PHST- 2025/01/13 16:53 [entrez]
PHST- 2025/01/13 00:00 [pmc-release]
AID - v27i1e54489 [pii]
AID - 10.2196/54489 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Jan 13;27:e54489. doi: 10.2196/54489.

PMID- 39302135
OWN - NLM
STAT- MEDLINE
DCOM- 20250326
LR  - 20250329
IS  - 1876-4479 (Electronic)
IS  - 1873-9946 (Print)
IS  - 1873-9946 (Linking)
VI  - 19
IP  - 3
DP  - 2025 Mar 5
TI  - Outcomes of Patients With Prior Biologic Intolerance Are Better Than Those With 
      Biologic Failure in Clinical Trials of Inflammatory Bowel Disease.
LID - 10.1093/ecco-jcc/jjae151 [doi]
LID - jjae151
AB  - BACKGROUND AND AIMS: Inflammatory bowel disease (IBD) trials often stratify 
      patients by prior biologic exposure, including prior biologic failure or 
      intolerance. This study aimed to assess clinical outcomes in IBD patients with 
      prior biologic failure vs intolerance treated with ustekinumab or vedolizumab. 
      METHODS: A post-hoc analysis of ulcerative colitis (UC) and Crohn's disease (CD) 
      clinical trials for ustekinumab (UNITI and UNIFI) and vedolizumab (GEMINI-1 and 
      GEMINI-2) was performed. Clinical response, clinical remission, and endoscopic 
      improvement (for UC) were compared among biologic naïve, biologic failure, and 
      biologic intolerant patients. Statistical analyses, including chi-square tests 
      and logistic regression, were performed. RESULTS: A total of 1178 UC and 1439 CD 
      patients received either ustekinumab or vedolizumab. In UC, biologic intolerant 
      patients exhibited higher clinical response (54.7% vs 38.8%, aOR 1.87 [95% CI, 
      0.93-3.73]), clinical remission (25.0% vs 11.0%, aOR 2.84 [95% CI, 1.47-5.49]), 
      and endoscopic improvement (40.6% vs 24.8%, aOR 2.76 [95% CI, 1.28-5.94]) 
      compared to biologic failure, with outcomes similar to biologic naïve patients. 
      In biologic intolerant CD patients, clinical response was similar between prior 
      biologic failure and intolerance (34.2% vs 32.8%), but after adjustment for 
      potential confounders, biologic intolerance was associated with higher odds of 
      clinical response (aOR: 1.67, 95% CI, 1.09-2.55), with no significant difference 
      observed for clinical remission (aOR: 1.48, 95% CI, 0.88-2.49). CONCLUSIONS: 
      Improved treatment outcomes were generally observed in patients with biologic 
      intolerance compared to failure, especially in UC, where outcomes were similar to 
      biologic naïve patients. Future clinical trials should meticulously differentiate 
      prior biologic failure vs intolerance to mitigate potential bias.
CI  - © The Author(s) 2024. Published by Oxford University Press on behalf of European 
      Crohn’s and Colitis Organisation.
FAU - Samnani, Sunil
AU  - Samnani S
AUID- ORCID: 0000-0003-4741-3542
AD  - Department of Medicine, Division of Gastroenterology, McMaster University, 
      Hamilton, ON, Canada.
AD  - Farncombe Family Digestive Health Research Institute, McMaster University, 
      Hamilton, ON, Canada.
FAU - Wong, Emily C L
AU  - Wong ECL
AUID- ORCID: 0000-0001-9472-201X
AD  - Department of Medicine, Division of Gastroenterology, McMaster University, 
      Hamilton, ON, Canada.
AD  - Farncombe Family Digestive Health Research Institute, McMaster University, 
      Hamilton, ON, Canada.
FAU - Hamam, Hasan
AU  - Hamam H
AUID- ORCID: 0009-0000-6999-3125
AD  - Department of Medicine, Division of Gastroenterology, McMaster University, 
      Hamilton, ON, Canada.
AD  - Farncombe Family Digestive Health Research Institute, McMaster University, 
      Hamilton, ON, Canada.
FAU - Dulai, Parambir S
AU  - Dulai PS
AD  - Division of Gastroenterology, Northwestern University, Chicago, IL, USA.
FAU - Marshall, John K
AU  - Marshall JK
AD  - Department of Medicine, Division of Gastroenterology, McMaster University, 
      Hamilton, ON, Canada.
AD  - Farncombe Family Digestive Health Research Institute, McMaster University, 
      Hamilton, ON, Canada.
FAU - Jairath, Vipul
AU  - Jairath V
AD  - Division of Gastroenterology, Department of Medicine, Western University, London, 
      ON, Canada.
FAU - Reinisch, Walter
AU  - Reinisch W
AUID- ORCID: 0000-0002-2088-091X
AD  - Department of Internal Medicine III, Division of Gastroenterology and Hepatology, 
      Medical University of Vienna, Währinger Gürtel 18-20, Vienna, Austria.
FAU - Narula, Neeraj
AU  - Narula N
AUID- ORCID: 0000-0002-1536-8436
AD  - Department of Medicine, Division of Gastroenterology, McMaster University, 
      Hamilton, ON, Canada.
AD  - Farncombe Family Digestive Health Research Institute, McMaster University, 
      Hamilton, ON, Canada.
LA  - eng
PT  - Journal Article
PL  - England
TA  - J Crohns Colitis
JT  - Journal of Crohn's & colitis
JID - 101318676
RN  - 9RV78Q2002 (vedolizumab)
RN  - FU77B4U5Z0 (Ustekinumab)
RN  - 0 (Antibodies, Monoclonal, Humanized)
RN  - 0 (Gastrointestinal Agents)
RN  - 0 (Biological Products)
SB  - IM
MH  - Humans
MH  - *Ustekinumab/therapeutic use
MH  - Female
MH  - Male
MH  - *Antibodies, Monoclonal, Humanized/therapeutic use
MH  - *Crohn Disease/drug therapy
MH  - Adult
MH  - *Colitis, Ulcerative/drug therapy
MH  - Treatment Failure
MH  - Gastrointestinal Agents/therapeutic use
MH  - Middle Aged
MH  - Remission Induction/methods
MH  - Treatment Outcome
MH  - Biological Products/therapeutic use
PMC - PMC11945295
OTO - NOTNLM
OT  - Inflammatory bowel disease
OT  - biologic failure
OT  - biologic intolerance
OT  - clinical outcomes
COIS- Neeraj Narula holds a McMaster University AFP Clinician Researcher Award. Neeraj 
      Narula has received honoraria from Janssen, Abbvie, Takeda, Pfizer, Sandoz, 
      Novartis, Iterative Health, Innomar Strategies, Fresinius Kabi, Amgen, Organon, 
      Eli Lilly, and Ferring. Parambir S. Dulai has received research support, 
      consulting, and/or speaker fees from Abbvie, Abivax, Adiso, Bristol Meyers 
      Squibb, GSK, Janssen, Lilly, Pfizer, Roivant, and Takeda; royalties from 
      University of California San Diego. John K. Marshall has received consulting 
      and/or speaking fees from AbbVie, Alimentiv, Amgen, Astra Zeneca, Bausch Health, 
      Bristol Myers Squibb, Celltrion, Ferring, Fresenius Kabi, Janssen, Lilly, Lupin, 
      Organon, Paladin, Pfizer, Pharmascience, Qu Biologics, Roche, Sandoz, SCOPE, 
      Takeda, Teva, and Viatris. Walter Reinisch has served as a speaker for AbbVie, 
      Celltrion, Falk Pharma GmbH, Ferring, Janssen, Galapagos Medice, MSD, Roche, 
      Pfizer, Pharmacosmos, Shire, Takeda, and Therakos; a consultant for AbbVie, 
      Amgen, AOP Orphan, Arena Pharmaceuticals, Astellas, Astra Zeneca, Bioclinica, 
      Boehringer Ingelheim, Bristol Myers Squibb, Calyx, Celgene, Celltrion, Eli Lilly, 
      Falk Pharma GmbH, Ferring, Galapagos, Gatehouse Bio Inc., Genentech, Gilead, 
      Grünenthal, ICON, Index Pharma, Inova, Janssen, Landos Biopharma, Medahead, 
      MedImmune, Microbiotica, Mitsubishi Tanabe Pharma Corporation, MSD, Novartis, 
      OMass, Otsuka, Parexel, Periconsulting, Pharmacosmos, Pfizer, Protagonist, 
      Provention, Quell Therapeutics, Sandoz, Seres Therapeutics, Setpointmedical, 
      Sigmoid, Sublimity, Takeda, Teva Pharma, Therakos, Theravance, and Zealand; an 
      advisory board member for AbbVie, Amgen, Astra Zeneca, Boehringer Ingelheim, 
      Bristol Myers Squibb, Celgene, Celltrion, Galapagos, Janssen, Mitsubishi Tanabe 
      Pharma Corporation, MSD, Pharmacosmos, Pfizer, Sandoz, Takeda; and has received 
      research funding from AbbVie, Janssen, MSD, Sandoz, Sanofi, and Takeda. Vipul 
      Jairath has received consulting/advisory board fees from AbbVie, Alimentiv Inc, 
      Arena pharmaceuticals, Asahi Kasei Pharma, Asieris, Astra Zeneca, Avoro Capital, 
      Bristol Myers Squibb, Celltrion, Eli Lilly, Endpoint Health, Enthera, Ferring, 
      Flagship Pioneering, Fresenius Kabi, Galapagos, Gilde Healthcare, 
      GlaxoSmithKline, Genentech, Gilead, Innomar, JAMP, Janssen, Merck, Metacrine, 
      Mylan, Pandion, Pendopharm, Pfizer, Protagonist, Prometheus Biosciences, Reistone 
      Biopharma, Roche, Roivant, Sandoz, SCOPE, Second Genome, Sorriso, Takeda, TD 
      Securities, Teva, Topivert, Ventyx, and Vividion; and speaker’s fees from Abbvie, 
      Ferring, Bristol Myers Squibb, Galapagos, Janssen Pfizer Shire, Takeda, and 
      Fresenius Kabi. No other authors have any relevant conflicts of interest. No 
      authors have received support for the submitted manuscript.
EDAT- 2024/09/22 20:51
MHDA- 2025/03/27 18:26
PMCR- 2024/09/20
CRDT- 2024/09/20 09:13
PHST- 2024/06/25 00:00 [received]
PHST- 2024/08/18 00:00 [revised]
PHST- 2024/09/18 00:00 [accepted]
PHST- 2025/03/27 18:26 [medline]
PHST- 2024/09/22 20:51 [pubmed]
PHST- 2024/09/20 09:13 [entrez]
PHST- 2024/09/20 00:00 [pmc-release]
AID - 7762524 [pii]
AID - jjae151 [pii]
AID - 10.1093/ecco-jcc/jjae151 [doi]
PST - ppublish
SO  - J Crohns Colitis. 2025 Mar 5;19(3):jjae151. doi: 10.1093/ecco-jcc/jjae151.

PMID- 39006438
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250218
DP  - 2024 Jul 1
TI  - Research Letter: Characterizing spin in psychiatric clinical research literature 
      using large language models.
LID - 2024.06.30.24309737 [pii]
LID - 10.1101/2024.06.30.24309737 [doi]
AB  - IMPORTANCE: Spin is a common form of biased reporting that misrepresents study 
      results in publications as more positive than an objective assessment would 
      indicate, but its prevalence in psychiatric journals is unknown. OBJECTIVE: To 
      apply a large language model to characterize the extent to which original reports 
      of pharmacologic and non-pharmacologic interventions in psychiatric journals 
      reflect spin. DESIGN: We identified abstracts from studies published between 2013 
      and 2023 in 3 high-impact psychiatric journals describing randomized trials or 
      meta-analyses of interventions. MAIN OUTCOME AND MEASURE: Presence or absence of 
      spin estimated by a large language model (GPT4-turbo, turbo-2024-04-09), 
      validated using gold standard abstracts with and without spin. RESULTS: Among a 
      total of 663 abstracts, 296 (44.6%) exhibited possible or probable spin - 230/529 
      (43.5%) randomized trials, 66/134 (49.3%) meta-analyses; 148/310 (47.7%) for 
      medication, 107/238 (45.0%) for psychotherapy, and 41/115 (35.7%) for other 
      interventions. In a multivariable logistic regression model, reports of 
      randomized trials, and non-pharmacologic/non-psychotherapy interventions, were 
      less likely to exhibit spin, as were more recent publications. CONCLUSIONS AND 
      RELEVANCE: A substantial subset of psychiatric intervention abstracts in 
      high-impact journals may contain results presented in a potentially misleading 
      way, with the potential to impact clinical practice. The success in automating 
      spin detection via large language models may facilitate identification and 
      revision to minimize spin in future publications.
FAU - Perlis, Roy H
AU  - Perlis RH
AUID- ORCID: 0000-0002-5862-6757
AD  - Center for Quantitative Health, Massachusetts General Hospital, Boston, MA.
AD  - Department of Psychiatry, Harvard Medical School, Boston, MA.
LA  - eng
GR  - R01 MH123804/MH/NIMH NIH HHS/United States
GR  - U01 MH136059/MH/NIMH NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20240701
PL  - United States
TA  - medRxiv
JT  - medRxiv : the preprint server for health sciences
JID - 101767986
UIN - JAMA Netw Open. 2025 Feb 3;8(2):e2459500. doi: 
      10.1001/jamanetworkopen.2024.59500. PMID: 39937483
PMC - PMC11245075
OTO - NOTNLM
OT  - Bias
OT  - clinical trials
OT  - medications
OT  - meta-analysis
OT  - psychopharmacology
OT  - psychotherapy
EDAT- 2024/07/15 06:42
MHDA- 2024/07/15 06:43
PMCR- 2024/07/12
CRDT- 2024/07/15 05:31
PHST- 2024/07/15 06:42 [pubmed]
PHST- 2024/07/15 06:43 [medline]
PHST- 2024/07/15 05:31 [entrez]
PHST- 2024/07/12 00:00 [pmc-release]
AID - 2024.06.30.24309737 [pii]
AID - 10.1101/2024.06.30.24309737 [doi]
PST - epublish
SO  - medRxiv [Preprint]. 2024 Jul 1:2024.06.30.24309737. doi: 
      10.1101/2024.06.30.24309737.

PMID- 38623729
OWN - NLM
STAT- MEDLINE
DCOM- 20240417
LR  - 20240425
IS  - 2369-3762 (Electronic)
IS  - 2369-3762 (Linking)
VI  - 10
DP  - 2024 Apr 15
TI  - A Student's Viewpoint on ChatGPT Use and Automation Bias in Medical Education.
PG  - e57696
LID - 10.2196/57696 [doi]
LID - e57696
FAU - Dsouza, Jeanne Maria
AU  - Dsouza JM
AUID- ORCID: 0000-0002-6762-1448
AD  - Kasturba Medical College, Manipal, India.
LA  - eng
PT  - Journal Article
DEP - 20240415
PL  - Canada
TA  - JMIR Med Educ
JT  - JMIR medical education
JID - 101684518
SB  - IM
CON - doi: 10.2196/50174/
MH  - Humans
MH  - *Education, Medical
MH  - Students
PMC - PMC11034419
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - medical education
COIS- None declared.
EDAT- 2024/04/16 12:45
MHDA- 2024/04/17 06:42
PMCR- 2024/04/15
CRDT- 2024/04/16 04:43
PHST- 2024/02/24 00:00 [received]
PHST- 2024/03/03 00:00 [revised]
PHST- 2024/03/28 00:00 [accepted]
PHST- 2024/04/17 06:42 [medline]
PHST- 2024/04/16 12:45 [pubmed]
PHST- 2024/04/16 04:43 [entrez]
PHST- 2024/04/15 00:00 [pmc-release]
AID - v10i1e57696 [pii]
AID - 57696 [pii]
AID - 10.2196/57696 [doi]
PST - epublish
SO  - JMIR Med Educ. 2024 Apr 15;10:e57696. doi: 10.2196/57696.

PMID- 38203077
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240113
IS  - 1424-8220 (Electronic)
IS  - 1424-8220 (Linking)
VI  - 24
IP  - 1
DP  - 2023 Dec 29
TI  - Transfer-Learning-Based Temperature Uncertainty Reduction Algorithm for Large 
      Scale Oil Tank Ground Settlement Monitoring.
LID - 10.3390/s24010215 [doi]
LID - 215
AB  - Sensors operating in open-air environments can be affected by various 
      environmental factors. Specifically, ground settlement (GS) monitoring sensors 
      installed in oil tanks are susceptible to non-uniform temperature fields caused 
      by uneven sunshine exposure. This disparity in environmental conditions can lead 
      to errors in sensor readings. To address this issue, this study aimed to analyze 
      the impact of temperature on GS monitoring sensors and establish a mapping 
      relationship between temperature uncertainty (fluctuations of measurement caused 
      by temperature variation) and temperature variation. By collecting the 
      temperature information and inferring the temperature uncertainty being 
      introduced, this interference can be removed. However, it is crucial to note that 
      in real-world complex scenarios, the relationship between temperature uncertainty 
      and temperature variation is not always a constant positive correlation, which 
      limits the data available for certain periods. Moreover, the limited availability 
      of data presents a challenge when analyzing the complex mapping relationship. To 
      overcome these challenges, a transfer-learning-based algorithm was introduced to 
      develop a more accurate model for predicting temperature uncertainty based on 
      temperature variation, even with limited data. Subsequently, a practical test was 
      conducted to validate the proposed algorithm's performance. The results 
      demonstrated that the algorithm outperformed a simple linear fitting model using 
      the least squares method (LSM), achieving an improvement of up to 21.9%. This 
      outcome highlights the algorithm's potential for enhancing the performance of GS 
      sensors in daytime monitoring and contributing to the safe operation of oil tank 
      facilities and infrastructure health monitoring.
FAU - Liu, Tao
AU  - Liu T
AD  - College of Optoelectronic Engineering and Instrumentation Science, Dalian 
      University of Technology, Dalian 116024, China.
FAU - Jiang, Tao
AU  - Jiang T
AD  - College of Optoelectronic Engineering and Instrumentation Science, Dalian 
      University of Technology, Dalian 116024, China.
FAU - Liu, Gang
AU  - Liu G
AD  - College of Optoelectronic Engineering and Instrumentation Science, Dalian 
      University of Technology, Dalian 116024, China.
FAU - Sun, Changsen
AU  - Sun C
AD  - College of Optoelectronic Engineering and Instrumentation Science, Dalian 
      University of Technology, Dalian 116024, China.
LA  - eng
GR  - 2020YY340517-XZ-02/China Liaoning Port Group Co. Ltd./
PT  - Journal Article
DEP - 20231229
PL  - Switzerland
TA  - Sensors (Basel)
JT  - Sensors (Basel, Switzerland)
JID - 101204366
SB  - IM
PMC - PMC10781382
OTO - NOTNLM
OT  - artificial neural network
OT  - ground settlement monitoring
OT  - optical fiber sensor
OT  - temperature uncertainty
OT  - transfer learning method
COIS- The authors declare no conflicts of interest.
EDAT- 2024/01/11 07:42
MHDA- 2024/01/11 07:43
PMCR- 2023/12/29
CRDT- 2024/01/11 01:15
PHST- 2023/11/30 00:00 [received]
PHST- 2023/12/25 00:00 [revised]
PHST- 2023/12/28 00:00 [accepted]
PHST- 2024/01/11 07:43 [medline]
PHST- 2024/01/11 07:42 [pubmed]
PHST- 2024/01/11 01:15 [entrez]
PHST- 2023/12/29 00:00 [pmc-release]
AID - s24010215 [pii]
AID - sensors-24-00215 [pii]
AID - 10.3390/s24010215 [doi]
PST - epublish
SO  - Sensors (Basel). 2023 Dec 29;24(1):215. doi: 10.3390/s24010215.

PMID- 38112255
OWN - NLM
STAT- MEDLINE
DCOM- 20240404
LR  - 20240404
IS  - 1539-3429 (Electronic)
IS  - 1470-8175 (Linking)
VI  - 52
IP  - 2
DP  - 2024 Mar-Apr
TI  - Evaluating ChatGPT as a self-learning tool in medical biochemistry: A performance 
      assessment in undergraduate medical university examination.
PG  - 237-248
LID - 10.1002/bmb.21808 [doi]
AB  - The emergence of ChatGPT as one of the most advanced chatbots and its ability to 
      generate diverse data has given room for numerous discussions worldwide regarding 
      its utility, particularly in advancing medical education and research. This study 
      seeks to assess the performance of ChatGPT in medical biochemistry to evaluate 
      its potential as an effective self-learning tool for medical students. This 
      evaluation was carried out using the university examination question papers of 
      both parts 1 and 2 of medical biochemistry which comprised theory and multiple 
      choice questions (MCQs) accounting for a total of 100 in each part. The questions 
      were used to interact with ChatGPT, and three raters independently reviewed and 
      scored the answers to prevent bias in scoring. We conducted the inter-item 
      correlation matrix and the interclass correlation between raters 1, 2, and 3. For 
      MCQs, symmetric measures in the form of kappa value (a measure of agreement) were 
      performed between raters 1, 2, and 3. ChatGPT generated relevant and appropriate 
      answers to all questions along with explanations for MCQs. ChatGPT has "passed" 
      the medical biochemistry university examination with an average score of 117 out 
      of 200 (58%) in both papers. In Paper 1, ChatGPT has secured 60 ± 2.29 and 
      57 ± 4.36 in Paper 2. The kappa value for all the cross-analysis of Rater 1, 
      Rater 2, and Rater 3 scores in MCQ was 1.000. The evaluation of ChatGPT as a 
      self-learning tool in medical biochemistry has yielded important insights. While 
      it is encouraging that ChatGPT has demonstrated proficiency in this area, the 
      overall score of 58% indicates that there is work to be done. To unlock its full 
      potential as a self-learning tool, ChatGPT must focus on generating not only 
      accurate but also comprehensive and contextually relevant content.
CI  - © 2023 International Union of Biochemistry and Molecular Biology.
FAU - Surapaneni, Krishna Mohan
AU  - Surapaneni KM
AUID- ORCID: 0000-0002-5204-5708
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
AD  - Department of Medical Education, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
AD  - Department of Clinical Skills & Simulation, Panimalar Medical College Hospital & 
      Research Institute, Chennai, India.
FAU - Rajajagadeesan, Anusha
AU  - Rajajagadeesan A
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
FAU - Goudhaman, Lakshmi
AU  - Goudhaman L
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
FAU - Lakshmanan, Shalini
AU  - Lakshmanan S
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
FAU - Sundaramoorthi, Saranya
AU  - Sundaramoorthi S
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
FAU - Ravi, Dineshkumar
AU  - Ravi D
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
FAU - Rajendiran, Kalaiselvi
AU  - Rajendiran K
AD  - Department of Biochemistry, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
FAU - Swaminathan, Porchelvan
AU  - Swaminathan P
AD  - Department of Community Medicine, Panimalar Medical College Hospital & Research 
      Institute, Chennai, India.
LA  - eng
PT  - Journal Article
DEP - 20231219
PL  - United States
TA  - Biochem Mol Biol Educ
JT  - Biochemistry and molecular biology education : a bimonthly publication of the 
      International Union of Biochemistry and Molecular Biology
JID - 100970605
SB  - IM
MH  - Humans
MH  - Universities
MH  - Learning
MH  - *Students, Medical
MH  - *Education, Medical
MH  - Research Personnel
OTO - NOTNLM
OT  - ChatGPT
OT  - artificial intelligence
OT  - biochemistry
OT  - medical education
EDAT- 2023/12/19 19:54
MHDA- 2024/04/04 06:44
CRDT- 2023/12/19 07:52
PHST- 2023/10/24 00:00 [revised]
PHST- 2023/03/28 00:00 [received]
PHST- 2023/12/04 00:00 [accepted]
PHST- 2024/04/04 06:44 [medline]
PHST- 2023/12/19 19:54 [pubmed]
PHST- 2023/12/19 07:52 [entrez]
AID - 10.1002/bmb.21808 [doi]
PST - ppublish
SO  - Biochem Mol Biol Educ. 2024 Mar-Apr;52(2):237-248. doi: 10.1002/bmb.21808. Epub 
      2023 Dec 19.

PMID- 40073584
OWN - NLM
STAT- Publisher
LR  - 20250312
IS  - 1361-8423 (Electronic)
IS  - 1361-8415 (Linking)
VI  - 102
DP  - 2025 Mar 7
TI  - FedBM: Stealing knowledge from pre-trained language models for heterogeneous 
      federated learning.
PG  - 103524
LID - S1361-8415(25)00072-6 [pii]
LID - 10.1016/j.media.2025.103524 [doi]
AB  - Federated learning (FL) has shown great potential in medical image computing 
      since it provides a decentralized learning paradigm that allows multiple clients 
      to train a model collaboratively without privacy leakage. However, current 
      studies have shown that data heterogeneity incurs local learning bias in 
      classifiers and feature extractors of client models during local training, 
      leading to the performance degradation of a federation system. To address these 
      issues, we propose a novel framework called Federated Bias eliMinating (FedBM) to 
      get rid of local learning bias in heterogeneous federated learning (FL), which 
      mainly consists of two modules, i.e., Linguistic Knowledge-based Classifier 
      Construction (LKCC) and Concept-guided Global Distribution Estimation (CGDE). 
      Specifically, LKCC exploits class concepts, prompts and pre-trained language 
      models (PLMs) to obtain concept embeddings. These embeddings are used to estimate 
      the latent concept distribution of each class in the linguistic space. Based on 
      the theoretical derivation, we can rely on these distributions to pre-construct a 
      high-quality classifier for clients to achieve classification optimization, which 
      is frozen to avoid classifier bias during local training. CGDE samples 
      probabilistic concept embeddings from the latent concept distributions to learn a 
      conditional generator to capture the input space of the global model. Three 
      regularization terms are introduced to improve the quality and utility of the 
      generator. The generator is shared by all clients and produces pseudo data to 
      calibrate updates of local feature extractors. Extensive comparison experiments 
      and ablation studies on public datasets demonstrate the superior performance of 
      FedBM over state-of-the-arts and confirm the effectiveness of each module, 
      respectively. The code is available at https://github.com/CUHK-AIM-Group/FedBM.
CI  - Copyright © 2025 Elsevier B.V. All rights reserved.
FAU - Zhu, Meilu
AU  - Zhu M
AD  - Department of Mechanical Engineering, City University of Hong Kong, Hong Kong 
      Special Administrative Region of China.
FAU - Yang, Qiushi
AU  - Yang Q
AD  - Department of Electrical Engineering, City University of Hong Kong, Hong Kong 
      Special Administrative Region of China.
FAU - Gao, Zhifan
AU  - Gao Z
AD  - School of Biomedical Engineering, Sun Yat-sen University, China.
FAU - Yuan, Yixuan
AU  - Yuan Y
AD  - Department of Electronic Engineering, Chinese University of Hong Kong, Hong Kong 
      Special Administrative Region of China. Electronic address: 
      yxyuan@ee.cuhk.edu.hk.
FAU - Liu, Jun
AU  - Liu J
AD  - Department of Mechanical Engineering, City University of Hong Kong, Hong Kong 
      Special Administrative Region of China; Department of Data and Systems 
      Engineering, The University of Hong Kong, Hong Kong Special Administrative Region 
      of China. Electronic address: dr.jun.liu@hku.hk.
LA  - eng
PT  - Journal Article
DEP - 20250307
PL  - Netherlands
TA  - Med Image Anal
JT  - Medical image analysis
JID - 9713490
SB  - IM
OTO - NOTNLM
OT  - Federated learning
OT  - Medical Image Classification
OT  - Pre-trained language model
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2025/03/13 00:33
MHDA- 2025/03/13 00:33
CRDT- 2025/03/12 19:04
PHST- 2024/10/25 00:00 [received]
PHST- 2025/01/21 00:00 [revised]
PHST- 2025/02/22 00:00 [accepted]
PHST- 2025/03/13 00:33 [medline]
PHST- 2025/03/13 00:33 [pubmed]
PHST- 2025/03/12 19:04 [entrez]
AID - S1361-8415(25)00072-6 [pii]
AID - 10.1016/j.media.2025.103524 [doi]
PST - aheadofprint
SO  - Med Image Anal. 2025 Mar 7;102:103524. doi: 10.1016/j.media.2025.103524.

PMID- 39899559
OWN - NLM
STAT- MEDLINE
DCOM- 20250203
LR  - 20250206
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 20
IP  - 2
DP  - 2025
TI  - Exploring ethical considerations in medical research: Harnessing pre-generated 
      transformers for AI-powered ethics discussions.
PG  - e0311148
LID - 10.1371/journal.pone.0311148 [doi]
LID - e0311148
AB  - INTRODUCTION: In medical research involving human subjects, ethical review is 
      essential to protect individuals. However, concerns have been raised about 
      variations in ethical review opinions and a decline in review quality. Adequately 
      protecting human subjects requires multifaceted opinions from ethics committee 
      members. Despite the need to increase the number of committee members, resources 
      are limited. To address these challenges, we explored the use of a generative 
      pre- learning transformer, an interactive artificial intelligence (AI) tool, to 
      discuss ethical issues in medical research. METHODS: The generation AI used in 
      the research used ChatGPT3.5, which has learned ethical guidelines from various 
      countries worldwide. We requested the generative AI to provide insights on 
      ethical considerations for virtual research involving individuals. The obtained 
      answers were documented and verified by experts. RESULTS: The AI successfully 
      highlighted considerations for informed consent regarding individuals with 
      dementia and mental illness, as well as concerns about invasiveness in research. 
      It also raised points about potential side effects of off-label drug use. 
      However, it could not offer specific measures for psychological considerations or 
      broader ethical issues, providing limited ethical insights. This limitation may 
      be attributed to biased opinions resulting from machine learning optimization, 
      preventing comprehensive identification of certain ethical issues. CONCLUSION: 
      Although the validity of ethical opinions generated by the generative AI requires 
      further examination, our findings suggest that this technology could be employed 
      to prompt reviews and re-evaluate ethical concerns arising in research.
CI  - Copyright: © 2025 Mori et al. This is an open access article distributed under 
      the terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Mori, Takuya
AU  - Mori T
AUID- ORCID: 0000-0001-7004-7179
AD  - Department of Ethics Support, Kyoto University Hospital, Kyoto, Japan.
FAU - Watanabe, Takuya
AU  - Watanabe T
AD  - Department of Ethics Support, Kyoto University Hospital, Kyoto, Japan.
FAU - Kosugi, Shinji
AU  - Kosugi S
AD  - Department of Ethics Support, Kyoto University Hospital, Kyoto, Japan.
AD  - Department of Medical Genetics and Medical Ethics, Graduate School of Medicine, 
      Kyoto University, Kyoto, Japan.
LA  - eng
PT  - Journal Article
DEP - 20250203
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence/ethics
MH  - *Biomedical Research/ethics
MH  - Informed Consent/ethics
PMC - PMC11790142
COIS- The authors have declared that no competing interests exist.
EDAT- 2025/02/03 18:20
MHDA- 2025/02/03 18:21
PMCR- 2025/02/03
CRDT- 2025/02/03 13:44
PHST- 2023/04/23 00:00 [received]
PHST- 2024/09/10 00:00 [accepted]
PHST- 2025/02/03 18:21 [medline]
PHST- 2025/02/03 18:20 [pubmed]
PHST- 2025/02/03 13:44 [entrez]
PHST- 2025/02/03 00:00 [pmc-release]
AID - PONE-D-23-12275 [pii]
AID - 10.1371/journal.pone.0311148 [doi]
PST - epublish
SO  - PLoS One. 2025 Feb 3;20(2):e0311148. doi: 10.1371/journal.pone.0311148. 
      eCollection 2025.

PMID- 39832358
OWN - NLM
STAT- MEDLINE
DCOM- 20250120
LR  - 20250206
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Jan 20
TI  - Era of Generalist Conversational Artificial Intelligence to Support Public Health 
      Communications.
PG  - e69007
LID - 10.2196/69007 [doi]
LID - e69007
AB  - The integration of artificial intelligence (AI) into health communication systems 
      has introduced a transformative approach to public health management, 
      particularly during public health emergencies, capable of reaching billions 
      through familiar digital channels. This paper explores the utility and 
      implications of generalist conversational artificial intelligence (CAI) advanced 
      AI systems trained on extensive datasets to handle a wide range of conversational 
      tasks across various domains with human-like responsiveness. The specific focus 
      is on the application of generalist CAI within messaging services, emphasizing 
      its potential to enhance public health communication. We highlight the evolution 
      and current applications of AI-driven messaging services, including their ability 
      to provide personalized, scalable, and accessible health interventions. 
      Specifically, we discuss the integration of large language models and generative 
      AI in mainstream messaging platforms, which potentially outperform traditional 
      information retrieval systems in public health contexts. We report a critical 
      examination of the advantages of generalist CAI in delivering health information, 
      with a case of its operationalization during the COVID-19 pandemic and propose 
      the strategic deployment of these technologies in collaboration with public 
      health agencies. In addition, we address significant challenges and ethical 
      considerations, such as AI biases, misinformation, privacy concerns, and the 
      required regulatory oversight. We envision a future with leverages generalist CAI 
      in messaging apps, proposing a multiagent approach to enhance the reliability and 
      specificity of health communications. We hope this commentary initiates the 
      necessary conversations and research toward building evaluation approaches, 
      adaptive strategies, and robust legal and technical frameworks to fully realize 
      the benefits of AI-enhanced communications in public health, aiming to ensure 
      equitable and effective health outcomes across diverse populations.
CI  - ©Emre Sezgin, Ahmet Baki Kocaballi. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 20.01.2025.
FAU - Sezgin, Emre
AU  - Sezgin E
AUID- ORCID: 0000-0001-8798-9605
AD  - The Abigail Wexner Research Institute at Nationwide Children's Hospital, 
      Columbus, OH, United States.
AD  - College of Medicine, The Ohio State University, Columbus, OH, United States.
FAU - Kocaballi, Ahmet Baki
AU  - Kocaballi AB
AUID- ORCID: 0000-0002-8328-5317
AD  - School of Computer Science, University of Technology Sydney, Sydney, Australia.
LA  - eng
PT  - Journal Article
DEP - 20250120
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - *Artificial Intelligence
MH  - Humans
MH  - *COVID-19/epidemiology
MH  - *Public Health/methods
MH  - Health Communication/methods
MH  - Pandemics
MH  - Communication
MH  - SARS-CoV-2
PMC - PMC11791462
OTO - NOTNLM
OT  - AI
OT  - artificial intelligence
OT  - conversational AI
OT  - generative AI
OT  - language models
OT  - messaging apps
OT  - public health communication
COIS- Conflicts of Interest: ES is an Associate Editor of the Journal of Medical 
      Internet Research.
EDAT- 2025/01/20 22:55
MHDA- 2025/01/20 22:56
PMCR- 2025/01/20
CRDT- 2025/01/20 16:53
PHST- 2024/11/19 00:00 [received]
PHST- 2024/12/21 00:00 [accepted]
PHST- 2024/12/20 00:00 [revised]
PHST- 2025/01/20 22:56 [medline]
PHST- 2025/01/20 22:55 [pubmed]
PHST- 2025/01/20 16:53 [entrez]
PHST- 2025/01/20 00:00 [pmc-release]
AID - v27i1e69007 [pii]
AID - 10.2196/69007 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Jan 20;27:e69007. doi: 10.2196/69007.

PMID- 39748878
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250104
IS  - 2168-8184 (Print)
IS  - 2168-8184 (Electronic)
IS  - 2168-8184 (Linking)
VI  - 17
IP  - 1
DP  - 2025 Jan
TI  - R/DoctorsUK (Sampling Bias in Action): How English Junior Doctors Pay Referendum 
      Results Compared to Those Predicted on the Doctors UK Reddit.
PG  - e76714
LID - 10.7759/cureus.76714 [doi]
LID - e76714
AB  - Reddit is a popular social media platform that is made up of subreddits, a kind 
      of special interest page. One of these is DoctorsUK, which has over 45,000 
      members and claims to be a community for UK-based doctors. There is, however, no 
      way of verifying who uses the page, as Reddit is essentially anonymous. Following 
      a period of industrial action in England, a pay deal was put forward and voted on 
      by over 45,000 resident doctors in England. During the voting window, many posts 
      on the subreddit DoctorsUK referenced the pay deal with various comments stating 
      that members were either voting for or against the deal. I wanted to compare the 
      numbers who stated their views on the page to the results obtained in the 
      official ballot. I analyzed the four most commented - on posts relating to the 
      pay deal and read a total of 1,297 comments on these posts. Only a user's first 
      comment on a post was included in the analysis, and deleted comments were not 
      retrieved. This left me with 548 comments to include in the study. I then grouped 
      the comments based on whether they clearly stated their voting intention on the 
      ballot. The voting intention was clearly stated in 230 comments. Of these 230 
      comments, 60 comments (26.1%) said they would be accepting the deal, and 170 
      (73.9%) said they would be rejecting it. In the formal ballot, 66% of resident 
      doctors voted to accept the deal. A sentiment analysis was also performed, which 
      found an overwhelming negative sentiment in three of the four posts. A 
      chi-squared test found a P-value of <0.001, suggesting a significant difference 
      between predicted and actual values. While this paper looked at a single 
      question, it found a significant amount of bias in the subreddit. There are few 
      surveys of doctors at such volume that other issues could be assessed in this 
      way. This study should lead to a questioning of the veracity of views on a page 
      that is anonymous and a realisation that we can, not in good faith, assume that 
      all posters on DoctorsUK are UK-based doctors. With this in mind, we may need to 
      question the possible alternative motives for the propagation of such ideas. It 
      is also worth considering how these ideas being shared in a public forum 
      associated with the medical profession may affect large language models and AI, 
      given that Reddit has allowed AI companies access to its data.
CI  - Copyright © 2025, Blenkinsop et al.
FAU - Blenkinsop, Lewis
AU  - Blenkinsop L
AD  - Surgery, Newcastle Upon Tyne Hospitals NHS Foundation Trust, Newcastle, GBR.
LA  - eng
PT  - Journal Article
DEP - 20250101
PL  - United States
TA  - Cureus
JT  - Cureus
JID - 101596737
PMC - PMC11691998
OTO - NOTNLM
OT  - bias
OT  - doctorsuk
OT  - gmc
OT  - pay deal
OT  - reddit
OT  - resident doctors
OT  - social media
COIS- Human subjects: All authors have confirmed that this study did not involve human 
      participants or tissue. Animal subjects: All authors have confirmed that this 
      study did not involve animal subjects or tissue. Conflicts of interest: In 
      compliance with the ICMJE uniform disclosure form, all authors declare the 
      following: Payment/services info: All authors have declared that no financial 
      support was received from any organization for the submitted work. Financial 
      relationships: All authors have declared that they have no financial 
      relationships at present or within the previous three years with any 
      organizations that might have an interest in the submitted work. Other 
      relationships: All authors have declared that there are no other relationships or 
      activities that could appear to have influenced the submitted work.
EDAT- 2025/01/03 06:21
MHDA- 2025/01/03 06:22
PMCR- 2025/01/01
CRDT- 2025/01/03 04:07
PHST- 2024/12/31 00:00 [accepted]
PHST- 2025/01/03 06:22 [medline]
PHST- 2025/01/03 06:21 [pubmed]
PHST- 2025/01/03 04:07 [entrez]
PHST- 2025/01/01 00:00 [pmc-release]
AID - 10.7759/cureus.76714 [doi]
PST - epublish
SO  - Cureus. 2025 Jan 1;17(1):e76714. doi: 10.7759/cureus.76714. eCollection 2025 Jan.

PMID- 39708841
OWN - NLM
STAT- MEDLINE
DCOM- 20241221
LR  - 20250104
IS  - 1477-4054 (Electronic)
IS  - 1467-5463 (Print)
IS  - 1467-5463 (Linking)
VI  - 26
IP  - 1
DP  - 2024 Nov 22
TI  - Combining evolution and protein language models for an interpretable cancer 
      driver mutation prediction with D2Deep.
LID - 10.1093/bib/bbae664 [doi]
LID - bbae664
AB  - The mutations driving cancer are being increasingly exposed through 
      tumor-specific genomic data. However, differentiating between cancer-causing 
      driver mutations and random passenger mutations remains challenging. 
      State-of-the-art homology-based predictors contain built-in biases and are often 
      ill-suited to the intricacies of cancer biology. Protein language models have 
      successfully addressed various biological problems but have not yet been tested 
      on the challenging task of cancer driver mutation prediction at a large scale. 
      Additionally, they often fail to offer result interpretation, hindering their 
      effective use in clinical settings. The AI-based D2Deep method we introduce here 
      addresses these challenges by combining two powerful elements: (i) a 
      nonspecialized protein language model that captures the makeup of all protein 
      sequences and (ii) protein-specific evolutionary information that encompasses 
      functional requirements for a particular protein. D2Deep relies exclusively on 
      sequence information, outperforms state-of-the-art predictors, and captures 
      intricate epistatic changes throughout the protein caused by mutations. These 
      epistatic changes correlate with known mutations in the clinical setting and can 
      be used for the interpretation of results. The model is trained on a balanced, 
      somatic training set and so effectively mitigates biases related to hotspot 
      mutations compared to state-of-the-art techniques. The versatility of D2Deep is 
      illustrated by its performance on non-cancer mutation prediction, where most 
      variants still lack known consequences. D2Deep predictions and confidence scores 
      are available via https://tumorscope.be/d2deep to help with clinical 
      interpretation and mutation prioritization.
CI  - © The Author(s) 2024. Published by Oxford University Press.
FAU - Tzavella, Konstantina
AU  - Tzavella K
AUID- ORCID: 0000-0001-6628-7567
AD  - Interuniversity Institute of Bioinformatics (IB2), Université Libre de Bruxelles, 
      Vrije Universiteit Brussel (ULB-VUB), Triomflaan, Brussels 1050, Belgium.
FAU - Diaz, Adrian
AU  - Diaz A
AD  - Interuniversity Institute of Bioinformatics (IB2), Université Libre de Bruxelles, 
      Vrije Universiteit Brussel (ULB-VUB), Triomflaan, Brussels 1050, Belgium.
FAU - Olsen, Catharina
AU  - Olsen C
AD  - Interuniversity Institute of Bioinformatics (IB2), Université Libre de Bruxelles, 
      Vrije Universiteit Brussel (ULB-VUB), Triomflaan, Brussels 1050, Belgium.
AD  - Brussels Interuniversity Genomics High Throughput Core (BRIGHTcore), Vrije 
      Universiteit Brussel (VUB), Université Libre de Bruxelles (ULB), Laarbeeklaan 
      101, Brussels 1090, Belgium.
AD  - Clinical Sciences, Research Group Genetics, Reproduction and Development (GRAD), 
      Vrije Universiteit Brussel (VUB), Universitair Ziekenhuis Brussel (UZ Brussel), 
      Laarbeeklaan 101, Brussels 1090, Belgium.
FAU - Vranken, Wim
AU  - Vranken W
AD  - Interuniversity Institute of Bioinformatics (IB2), Université Libre de Bruxelles, 
      Vrije Universiteit Brussel (ULB-VUB), Triomflaan, Brussels 1050, Belgium.
AD  - Structural Biology Brussels, Vrije Universiteit Brussel (VUB), Pleinlaan 2, 
      Brussels 1050, Belgium.
AD  - Chemistry Department, Vrije Universiteit Brussel, Pleinlaan 2, Brussels 1050, 
      Belgium.
AD  - AI Lab, Vrije Universtiteit Brussel, Pleinlaan 2, Brussels 1050, Belgium.
AD  - Biomedical sciences, Vrije Universiteit Brussel, Laarbeeklaan 101, Brussels 1090, 
      Belgium.
LA  - eng
GR  - IRP20/Vrije Universiteit Brussel Research Council/
GR  - 101016834/European Union's Horizon 2020/
GR  - I000323N/Research Foundation Flanders (FWO) International Research 
      Infrastructure/
PT  - Journal Article
PL  - England
TA  - Brief Bioinform
JT  - Briefings in bioinformatics
JID - 100912837
SB  - IM
MH  - Humans
MH  - *Neoplasms/genetics
MH  - *Mutation
MH  - Computational Biology/methods
MH  - Evolution, Molecular
MH  - Algorithms
PMC - PMC11663023
OTO - NOTNLM
OT  - evolutionary information
OT  - machine learning
OT  - mutation effect prediction
OT  - protein large language models
COIS- None declared.
EDAT- 2024/12/22 00:27
MHDA- 2024/12/22 00:28
PMCR- 2024/12/21
CRDT- 2024/12/21 19:12
PHST- 2024/06/21 00:00 [received]
PHST- 2024/09/15 00:00 [revised]
PHST- 2024/12/07 00:00 [accepted]
PHST- 2024/12/22 00:28 [medline]
PHST- 2024/12/22 00:27 [pubmed]
PHST- 2024/12/21 19:12 [entrez]
PHST- 2024/12/21 00:00 [pmc-release]
AID - 7930073 [pii]
AID - bbae664 [pii]
AID - 10.1093/bib/bbae664 [doi]
PST - ppublish
SO  - Brief Bioinform. 2024 Nov 22;26(1):bbae664. doi: 10.1093/bib/bbae664.

PMID- 39527593
OWN - NLM
STAT- MEDLINE
DCOM- 20241121
LR  - 20241123
IS  - 1553-7358 (Electronic)
IS  - 1553-734X (Print)
IS  - 1553-734X (Linking)
VI  - 20
IP  - 11
DP  - 2024 Nov
TI  - A modular protein language modelling approach to immunogenicity prediction.
PG  - e1012511
LID - 10.1371/journal.pcbi.1012511 [doi]
LID - e1012511
AB  - Neoantigen immunogenicity prediction is a highly challenging problem in the 
      development of personalised medicines. Low reactivity rates in called neoantigens 
      result in a difficult prediction scenario with limited training datasets. Here we 
      describe ImmugenX, a modular protein language modelling approach to 
      immunogenicity prediction for CD8+ reactive epitopes. ImmugenX comprises of a 
      pMHC encoding module trained on three pMHC prediction tasks, an optional TCR 
      encoding module and a set of context specific immunogenicity prediction head 
      modules. Compared with state-of-the-art models for each task, ImmugenX's encoding 
      module performs comparably or better on pMHC binding affinity, eluted ligand 
      prediction and stability tasks. ImmugenX outperforms all compared models on pMHC 
      immunogenicity prediction (Area under the receiver operating characteristic curve 
      = 0.619, average precision: 0.514), with a 7% increase in average precision 
      compared to the next best model. ImmugenX shows further improved performance on 
      immunogenicity prediction with the integration of TCR context information. 
      ImmugenX performance is further analysed for interpretability, which locates 
      areas of weakness found across existing immunogenicity models and highlight 
      possible biases in public datasets.
CI  - Copyright: © 2024 O’Brien et al. This is an open access article distributed under 
      the terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - O'Brien, Hugh
AU  - O'Brien H
AUID- ORCID: 0000-0002-6829-5306
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
FAU - Salm, Max
AU  - Salm M
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
FAU - Morton, Laura T
AU  - Morton LT
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
FAU - Szukszto, Maciej
AU  - Szukszto M
AD  - Research Department of Haematology, UCL Cancer Institute, University College 
      London, London, United Kingdom.
FAU - O'Farrell, Felix
AU  - O'Farrell F
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
FAU - Boulton, Charlotte
AU  - Boulton C
AD  - Research Department of Haematology, UCL Cancer Institute, University College 
      London, London, United Kingdom.
FAU - King, Laurence
AU  - King L
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
AD  - Research Department of Haematology, UCL Cancer Institute, University College 
      London, London, United Kingdom.
FAU - Bola, Supreet Kaur
AU  - Bola SK
AUID- ORCID: 0000-0001-8558-8197
AD  - Research Department of Haematology, UCL Cancer Institute, University College 
      London, London, United Kingdom.
FAU - Becker, Pablo D
AU  - Becker PD
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
FAU - Craig, Andrew
AU  - Craig A
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
FAU - Nielsen, Morten
AU  - Nielsen M
AD  - Technical University of Denmark, Lyngby, Denmark.
FAU - Samuels, Yardena
AU  - Samuels Y
AD  - Weizmann Institute of Science, Rehovot, Israel.
FAU - Swanton, Charles
AU  - Swanton C
AD  - The Francis Crick Institute, London, United Kingdom.
FAU - Mansour, Marc R
AU  - Mansour MR
AD  - Research Department of Haematology, UCL Cancer Institute, University College 
      London, London, United Kingdom.
AD  - Department of Developmental Biology and Cancer, Great Ormond Street Institute of 
      Child Health, UCL.
FAU - Hadrup, Sine Reker
AU  - Hadrup SR
AD  - Technical University of Denmark, Lyngby, Denmark.
FAU - Quezada, Sergio A
AU  - Quezada SA
AUID- ORCID: 0000-0002-9763-1700
AD  - Achilles Therapeutics UK Ltd, United Kingdom.
AD  - Research Department of Haematology, UCL Cancer Institute, University College 
      London, London, United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20241111
PL  - United States
TA  - PLoS Comput Biol
JT  - PLoS computational biology
JID - 101238922
RN  - 0 (Receptors, Antigen, T-Cell)
SB  - IM
MH  - Humans
MH  - *Computational Biology/methods
MH  - CD8-Positive T-Lymphocytes/immunology
MH  - Receptors, Antigen, T-Cell/immunology
MH  - Models, Molecular
PMC - PMC11581412
COIS- I have read the journal’s policy and the authors of this manuscript have the 
      following competing interests: S.A.Q. is co-founder and chief scientific officer 
      and own shares in Achilles Therapeutics. C.S. acknowledges grants from 
      AstraZeneca, Boehringer-Ingelheim, Bristol Myers Squibb, Pfizer, Roche-Ventana, 
      Invitae (previously Archer Dx Inc., a collaboration in minimal residual disease 
      sequencing technologies), Ono Pharmaceutical and Personalis. He is chief 
      investigator for the AZ MeRmaiD 1 and 2 clinical trials and is the steering 
      committee chair. He is also co-chief investigator of the NHS Galleri trial funded 
      by GRAIL and a paid member of GRAIL’s scientific advisory board (SAB). He 
      receives consultant fees from Achilles Therapeutics (also an SAB member); Bicycle 
      Therapeutics (also an SAB member); Genentech; Medicxi; the China Innovation 
      Centre of Roche (CICoR), formerly Roche Innovation Centre Shanghai; Metabomed 
      (until July 2022); Relay Therapeutics; and the Sarah Cannon Research Institute. 
      C.S has received honoraria from Amgen, AstraZeneca, Bristol Myers Squibb, 
      GlaxoSmithKline, Illumina, MSD, Novartis, Pfizer and Roche-Ventana; previously 
      held stock options in Apogen Biotechnologies and GRAIL; currently has stock 
      options in Epic Bioscience and Bicycle Therapeutics; and has stock options and is 
      co-founder of Achilles Therapeutics. S.R.H. is the cofounder of PokeAcell and is 
      co-inventor of licensed patents related to T cell detection. H.O’B., M.S., L.M. 
      and F.O’F. are employees of Achilles Therapeutics. H.O’B. and M.S. are both named 
      inventors on patents for ImmugenX.
EDAT- 2024/11/13 13:47
MHDA- 2024/11/21 18:21
PMCR- 2024/11/11
CRDT- 2024/11/11 13:43
PHST- 2024/06/14 00:00 [received]
PHST- 2024/09/24 00:00 [accepted]
PHST- 2024/11/21 00:00 [revised]
PHST- 2024/11/21 18:21 [medline]
PHST- 2024/11/13 13:47 [pubmed]
PHST- 2024/11/11 13:43 [entrez]
PHST- 2024/11/11 00:00 [pmc-release]
AID - PCOMPBIOL-D-24-00999 [pii]
AID - 10.1371/journal.pcbi.1012511 [doi]
PST - epublish
SO  - PLoS Comput Biol. 2024 Nov 11;20(11):e1012511. doi: 10.1371/journal.pcbi.1012511. 
      eCollection 2024 Nov.

PMID- 39520401
OWN - NLM
STAT- MEDLINE
DCOM- 20241120
LR  - 20241122
IS  - 1367-4811 (Electronic)
IS  - 1367-4803 (Print)
IS  - 1367-4803 (Linking)
VI  - 40
IP  - 11
DP  - 2024 Nov 1
TI  - p-IgGen: a paired antibody generative language model.
LID - 10.1093/bioinformatics/btae659 [doi]
LID - btae659
AB  - SUMMARY: A key challenge in antibody drug discovery is designing novel sequences 
      that are free from developability issues-such as aggregation, polyspecificity, 
      poor expression, or low solubility. Here, we present p-IgGen, a protein language 
      model for paired heavy-light chain antibody generation. The model generates 
      diverse, antibody-like sequences with pairing properties found in natural 
      antibodies. We also create a finetuned version of p-IgGen that biases the model 
      to generate antibodies with 3D biophysical properties that fall within 
      distributions seen in clinical-stage therapeutic antibodies. AVAILABILITY AND 
      IMPLEMENTATION: The model and inference code are freely available at 
      www.github.com/oxpig/p-IgGen. Cleaned training data are deposited at 
      doi.org/10.5281/zenodo.13880874.
CI  - © The Author(s) 2024. Published by Oxford University Press.
FAU - Turnbull, Oliver M
AU  - Turnbull OM
AUID- ORCID: 0000-0002-0239-1207
AD  - Department of Statistics, University of Oxford, Oxford, OX1 3LB, United Kingdom.
FAU - Oglic, Dino
AU  - Oglic D
AD  - Centre for AI, Biopharmaceuticals R&D, AstraZeneca, Cambridge, CB2 0AA, United 
      Kingdom.
FAU - Croasdale-Wood, Rebecca
AU  - Croasdale-Wood R
AD  - Biologics Engineering, Oncology R&D, AstraZeneca, Cambridge, CB2 0AA, United 
      Kingdom.
FAU - Deane, Charlotte M
AU  - Deane CM
AUID- ORCID: 0000-0003-1388-2252
AD  - Department of Statistics, University of Oxford, Oxford, OX1 3LB, United Kingdom.
LA  - eng
GR  - UK Engineering and Physical Sciences Research Council/
PT  - Journal Article
PL  - England
TA  - Bioinformatics
JT  - Bioinformatics (Oxford, England)
JID - 9808944
RN  - 0 (Antibodies)
SB  - IM
MH  - *Antibodies/chemistry
MH  - Humans
MH  - Drug Discovery/methods
MH  - Software
PMC - PMC11576349
EDAT- 2024/11/13 14:01
MHDA- 2024/11/20 11:04
PMCR- 2024/11/09
CRDT- 2024/11/09 10:03
PHST- 2024/07/12 00:00 [received]
PHST- 2024/10/04 00:00 [revised]
PHST- 2024/11/08 00:00 [accepted]
PHST- 2024/11/20 11:04 [medline]
PHST- 2024/11/13 14:01 [pubmed]
PHST- 2024/11/09 10:03 [entrez]
PHST- 2024/11/09 00:00 [pmc-release]
AID - 7888884 [pii]
AID - btae659 [pii]
AID - 10.1093/bioinformatics/btae659 [doi]
PST - ppublish
SO  - Bioinformatics. 2024 Nov 1;40(11):btae659. doi: 10.1093/bioinformatics/btae659.

PMID- 38934705
OWN - NLM
STAT- MEDLINE
DCOM- 20240627
LR  - 20240925
IS  - 1399-0012 (Electronic)
IS  - 0902-0063 (Linking)
VI  - 38
IP  - 7
DP  - 2024 Jul
TI  - Using ChatGPT for Kidney Transplantation: Perceived Information Quality by Race 
      and Education Levels.
PG  - e15378
LID - 10.1111/ctr.15378 [doi]
AB  - BACKGROUND: Kidney transplantation is a complex process requiring extensive 
      preparation and ongoing monitoring. Artificial intelligence (AI)-powered chatbots 
      hold potential for providing accessible health information, but our understanding 
      of their role in offering health advice for kidney transplantation and how 
      individuals assess such advice remains limited. This study investigates how 
      individuals evaluate ChatGPT's responses to kidney transplantation questions in 
      terms of information quality and empathy, focusing on potential differences 
      across race/ethnicity and educational backgrounds. METHODS: We collected Reddit 
      posts (N = 4624) regarding kidney transplantation and selected 86 questions to 
      represent typical clinician inquiries. These questions were used as input prompts 
      for ChatGPT. A total of 565 participants assessed ChatGPT's responses through 
      online surveys, rating information quality and empathy using Likert scales. 
      RESULTS: Multilevel analyses (N = 2825) show that there is a significant 
      interaction between race/ethnicity and education levels in various measures 
      related to perceived information quality, but not perceived empathy of ChatGPT's 
      responses: accuracy (p < 0.05); authenticity (p < 0.01); believability 
      (p < 0.05); informativeness (p = 0.053); usefulness (p < 0.05); recognizing 
      users' feelings (p = 0.70) and understanding feelings and situations (p = 0.65). 
      Among non-White individuals, higher education levels predicted higher perceived 
      quality of ChatGPT's responses across all information quality measures. Notably, 
      this trend was reversed for White individuals, where higher education levels led 
      to lower perceived information quality. CONCLUSIONS: Our results highlight the 
      importance of developing AI tools sensitive to diverse communication styles and 
      information needs.
CI  - © 2024 The Author(s). Clinical Transplantation published by John Wiley & Sons 
      Ltd.
FAU - Lee, Jihye
AU  - Lee J
AD  - Stan Richards School of Advertising and Public Relations, Moody College of 
      Communication, The University of Texas at Austin, Austin, Texas, USA.
FAU - Park, Jeeyun
AU  - Park J
AD  - Stan Richards School of Advertising and Public Relations, Moody College of 
      Communication, The University of Texas at Austin, Austin, Texas, USA.
FAU - Han, Hwarang Stephen
AU  - Han HS
AD  - Division of Nephrology, Department of Internal Medicine, Dell Medical School, The 
      University of Texas at Austin, Austin, Texas, USA.
LA  - eng
PT  - Journal Article
PL  - Denmark
TA  - Clin Transplant
JT  - Clinical transplantation
JID - 8710240
SB  - IM
MH  - Adult
MH  - Female
MH  - Humans
MH  - Male
MH  - Middle Aged
MH  - Educational Status
MH  - Ethnicity
MH  - Follow-Up Studies
MH  - *Kidney Transplantation
MH  - *Patient Education as Topic
MH  - Prognosis
MH  - Racial Groups
MH  - *Social Media
MH  - Surveys and Questionnaires
MH  - *Artificial Intelligence
OTO - NOTNLM
OT  - disparities
OT  - ethnicity/race
OT  - kidney disease
OT  - media and social media
OT  - survey
EDAT- 2024/06/27 12:42
MHDA- 2024/06/27 12:43
CRDT- 2024/06/27 09:33
PHST- 2024/05/13 00:00 [revised]
PHST- 2024/02/25 00:00 [received]
PHST- 2024/05/30 00:00 [accepted]
PHST- 2024/06/27 12:43 [medline]
PHST- 2024/06/27 12:42 [pubmed]
PHST- 2024/06/27 09:33 [entrez]
AID - 10.1111/ctr.15378 [doi]
PST - ppublish
SO  - Clin Transplant. 2024 Jul;38(7):e15378. doi: 10.1111/ctr.15378.

PMID- 38677973
OWN - NLM
STAT- MEDLINE
DCOM- 20241104
LR  - 20241113
IS  - 1875-595X (Electronic)
IS  - 0020-6539 (Print)
IS  - 0020-6539 (Linking)
VI  - 74
IP  - 6
DP  - 2024 Dec
TI  - Familiarity with ChatGPT Features Modifies Expectations and Learning Outcomes of 
      Dental Students.
PG  - 1456-1462
LID - S0020-6539(24)00117-5 [pii]
LID - 10.1016/j.identj.2024.04.012 [doi]
AB  - OBJECTIVES: The number of approvals for AI-based systems is increasing rapidly, 
      although AI clinical trial designs lack consideration of the impact of human-AI 
      interaction. Aim of this work was to investigate how reading of an AI system 
      (ChatGPT) features/descriptions could influence the willingness and expectations 
      for use of this technology as well as dental students' learning performance. 
      METHODS: Dental students (N = 104) were asked to learn about side effects of 
      drugs used in dental practice via reading recommended literature or ChatGPT. 
      Expectations towards ChatGPT were measured by survey, before and after reading of 
      a system features description, whilst learning outcomes were evaluated via 
      pharmacology quiz. RESULTS: Students who used ChatGPT (YG group) showed better 
      results on the pharmacology quiz than students who neither read the description 
      nor employed ChatGPT for learning (NN condition). Moreover, students who read the 
      description of ChatGPT features yet did not use it (NG) showed better results on 
      the pharmacology quiz compared with the NN condition, although none of them 
      employed ChatGPT for learning. The NG students compared to the YG students had 
      less trust in AI system assistance in learning, and after the AI system 
      description reading, their expectations changed significantly, showing an 
      association with quiz scores. CONCLUSIONS: A majority of students in our cohort 
      was reluctant to use ChatGPT. Furthermore, familarity (reading) with ChatGPT 
      features appear to alter the expectations and enhance learning performance of 
      students.suggesting an AI description-related cognitive bias. Hence the content 
      description of ChatGPTshould be reviewed and verified prior to AI system use for 
      educational purposes.
CI  - Copyright © 2024 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Roganović, Jelena
AU  - Roganović J
AD  - Department of Pharmacology in Dentistry, Faculty of Dental Medicine, University 
      of Belgrade, Belgrade, Serbia. Electronic address: 
      jelena.roganovic@stomf.bg.ac.rs.
LA  - eng
PT  - Journal Article
DEP - 20240426
PL  - England
TA  - Int Dent J
JT  - International dental journal
JID - 0374714
SB  - IM
MH  - Humans
MH  - *Students, Dental/psychology
MH  - Male
MH  - Female
MH  - *Education, Dental
MH  - Learning
MH  - Educational Measurement
MH  - Artificial Intelligence
MH  - Young Adult
MH  - Surveys and Questionnaires
MH  - Drug-Related Side Effects and Adverse Reactions
MH  - Adult
PMC - PMC11551562
OTO - NOTNLM
OT  - Artificial intelligence
OT  - ChatGPT
OT  - Education dental
OT  - Ethics
OT  - Pharmacology
COIS- Conflict of interest None disclosed.
EDAT- 2024/04/28 07:25
MHDA- 2024/11/04 06:22
PMCR- 2024/04/26
CRDT- 2024/04/27 21:59
PHST- 2024/02/10 00:00 [received]
PHST- 2024/03/24 00:00 [revised]
PHST- 2024/04/05 00:00 [accepted]
PHST- 2024/11/04 06:22 [medline]
PHST- 2024/04/28 07:25 [pubmed]
PHST- 2024/04/27 21:59 [entrez]
PHST- 2024/04/26 00:00 [pmc-release]
AID - S0020-6539(24)00117-5 [pii]
AID - 10.1016/j.identj.2024.04.012 [doi]
PST - ppublish
SO  - Int Dent J. 2024 Dec;74(6):1456-1462. doi: 10.1016/j.identj.2024.04.012. Epub 
      2024 Apr 26.

PMID- 38133918
OWN - NLM
STAT- MEDLINE
DCOM- 20231225
LR  - 20240110
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 25
DP  - 2023 Dec 22
TI  - Evaluation of GPT-4's Chest X-Ray Impression Generation: A Reader Study on 
      Performance and Perception.
PG  - e50865
LID - 10.2196/50865 [doi]
LID - e50865
AB  - Exploring the generative capabilities of the multimodal GPT-4, our study 
      uncovered significant differences between radiological assessments and automatic 
      evaluation metrics for chest x-ray impression generation and revealed 
      radiological bias.
CI  - ©Sebastian Ziegelmayer, Alexander W Marka, Nicolas Lenhart, Nadja Nehls, Stefan 
      Reischl, Felix Harder, Andreas Sauter, Marcus Makowski, Markus Graf, Joshua 
      Gawlitza. Originally published in the Journal of Medical Internet Research 
      (https://www.jmir.org), 22.12.2023.
FAU - Ziegelmayer, Sebastian
AU  - Ziegelmayer S
AUID- ORCID: 0000-0001-8724-4718
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Marka, Alexander W
AU  - Marka AW
AUID- ORCID: 0000-0002-2111-8177
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Lenhart, Nicolas
AU  - Lenhart N
AUID- ORCID: 0009-0005-4646-7532
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Nehls, Nadja
AU  - Nehls N
AUID- ORCID: 0000-0001-6073-6464
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Reischl, Stefan
AU  - Reischl S
AUID- ORCID: 0000-0001-7341-4296
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Harder, Felix
AU  - Harder F
AUID- ORCID: 0000-0002-3182-5924
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Sauter, Andreas
AU  - Sauter A
AUID- ORCID: 0000-0003-4394-862X
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Makowski, Marcus
AU  - Makowski M
AUID- ORCID: 0000-0001-7719-8236
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Graf, Markus
AU  - Graf M
AUID- ORCID: 0000-0002-4668-0326
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
FAU - Gawlitza, Joshua
AU  - Gawlitza J
AUID- ORCID: 0000-0002-9454-816X
AD  - Department of Diagnostic and Interventional Radiology, School of Medicine & 
      Klinikum rechts der Isar, Technical University of Munich, Munich, Germany.
LA  - eng
PT  - Journal Article
DEP - 20231222
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - X-Rays
MH  - Radiography
MH  - *Radiology
MH  - Benchmarking
MH  - Perception
PMC - PMC10770784
OTO - NOTNLM
OT  - AI
OT  - GPT
OT  - artificial intelligence
OT  - chest
OT  - diagnostic
OT  - generative
OT  - generative model
OT  - image
OT  - images
OT  - imaging
OT  - impression
OT  - impressions
OT  - medical imaging
OT  - multimodal
OT  - radiography
OT  - radiological
OT  - radiology
OT  - x-ray
OT  - x-rays
COIS- Conflicts of Interest: None declared.
EDAT- 2023/12/22 12:41
MHDA- 2023/12/25 06:41
PMCR- 2023/12/22
CRDT- 2023/12/22 11:54
PHST- 2023/07/14 00:00 [received]
PHST- 2023/11/27 00:00 [accepted]
PHST- 2023/08/16 00:00 [revised]
PHST- 2023/12/25 06:41 [medline]
PHST- 2023/12/22 12:41 [pubmed]
PHST- 2023/12/22 11:54 [entrez]
PHST- 2023/12/22 00:00 [pmc-release]
AID - v25i1e50865 [pii]
AID - 10.2196/50865 [doi]
PST - epublish
SO  - J Med Internet Res. 2023 Dec 22;25:e50865. doi: 10.2196/50865.

PMID- 38035280
OWN - NLM
STAT- MEDLINE
DCOM- 20231204
LR  - 20240424
IS  - 2296-2565 (Electronic)
IS  - 2296-2565 (Linking)
VI  - 11
DP  - 2023
TI  - A search-based geographic metadata curation pipeline to refine sequencing 
      institution information and support public health.
PG  - 1254976
LID - 10.3389/fpubh.2023.1254976 [doi]
LID - 1254976
AB  - BACKGROUND: The National Center for Biotechnology Information (NCBI) Sequence 
      Read Archive (SRA) has amassed a vast reservoir of genetic data since its 
      inception in 2007. These public data hold immense potential for supporting 
      pathogen surveillance and control. However, the lack of standardized metadata and 
      inconsistent submission practices in SRA may impede the data's utility in public 
      health. METHODS: To address this issue, we introduce the Search-based Geographic 
      Metadata Curation (SGMC) pipeline. SGMC utilized Python and web scraping to 
      extract geographic data of sequencing institutions from NCBI SRA in the Cloud and 
      its website. It then harnessed ChatGPT to refine the sequencing institution and 
      location assignments. To illustrate the pipeline's utility, we examined the 
      geographic distribution of the sequencing institutions and their countries 
      relevant to polio eradication and categorized them. RESULTS: SGMC successfully 
      identified 7,649 sequencing institutions and their global locations from a random 
      selection of 2,321,044 SRA accessions. These institutions were distributed across 
      97 countries, with strong representation in the United States, the United Kingdom 
      and China. However, there was a lack of data from African, Central Asian, and 
      Central American countries, indicating potential disparities in sequencing 
      capabilities. Comparison with manually curated data for U.S. institutions reveals 
      SGMC's accuracy rates of 94.8% for institutions, 93.1% for countries, and 74.5% 
      for geographic coordinates. CONCLUSION: SGMC may represent a novel approach using 
      a generative AI model to enhance geographic data (country and institution 
      assignments) for large numbers of samples within SRA datasets. This information 
      can be utilized to bolster public health endeavors.
CI  - Copyright © 2023 Zhao, Farrell, Mashiku, Abay, Tang, Oberste and Burns.
FAU - Zhao, Kun
AU  - Zhao K
AD  - Division of Viral Diseases, National Center for Immunization and Respiratory 
      Diseases, Centers for Disease Control and Prevention, Atlanta, GA, United States.
FAU - Farrell, Katie
AU  - Farrell K
AD  - Cherokee Nation Businesses, Contracting Agency to the Division of Viral Diseases, 
      Centers for Disease Control and Prevention, Catoosa, OK, United States.
FAU - Mashiku, Melchizedek
AU  - Mashiku M
AD  - Cherokee Nation Businesses, Contracting Agency to the Division of Viral Diseases, 
      Centers for Disease Control and Prevention, Catoosa, OK, United States.
FAU - Abay, Dawit
AU  - Abay D
AD  - Cherokee Nation Businesses, Contracting Agency to the Division of Viral Diseases, 
      Centers for Disease Control and Prevention, Catoosa, OK, United States.
FAU - Tang, Kevin
AU  - Tang K
AD  - Division of Scientific Resources, National Center for Emerging and Zoonotic 
      Infectious Diseases, Centers for Disease Control and Prevention, Atlanta, GA, 
      United States.
FAU - Oberste, M Steven
AU  - Oberste MS
AD  - Division of Viral Diseases, National Center for Immunization and Respiratory 
      Diseases, Centers for Disease Control and Prevention, Atlanta, GA, United States.
FAU - Burns, Cara C
AU  - Burns CC
AD  - Division of Viral Diseases, National Center for Immunization and Respiratory 
      Diseases, Centers for Disease Control and Prevention, Atlanta, GA, United States.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20231114
PL  - Switzerland
TA  - Front Public Health
JT  - Frontiers in public health
JID - 101616579
SB  - IM
MH  - *Metadata
MH  - *Public Health
MH  - High-Throughput Nucleotide Sequencing
MH  - China
MH  - United Kingdom
PMC - PMC10683794
OTO - NOTNLM
OT  - ChatGPT
OT  - cloud computing
OT  - disparity of global sequencing capability
OT  - geographic locations
OT  - poliovirus
OT  - sequence read archive
OT  - surveillance
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      conflict of interest.
EDAT- 2023/11/30 18:45
MHDA- 2023/12/04 12:42
PMCR- 2023/11/14
CRDT- 2023/11/30 17:47
PHST- 2023/07/08 00:00 [received]
PHST- 2023/10/19 00:00 [accepted]
PHST- 2023/12/04 12:42 [medline]
PHST- 2023/11/30 18:45 [pubmed]
PHST- 2023/11/30 17:47 [entrez]
PHST- 2023/11/14 00:00 [pmc-release]
AID - 10.3389/fpubh.2023.1254976 [doi]
PST - epublish
SO  - Front Public Health. 2023 Nov 14;11:1254976. doi: 10.3389/fpubh.2023.1254976. 
      eCollection 2023.

PMID- 37983817
OWN - NLM
STAT- MEDLINE
DCOM- 20240529
LR  - 20240902
IS  - 1529-4242 (Electronic)
IS  - 0032-1052 (Print)
IS  - 0032-1052 (Linking)
VI  - 153
IP  - 6
DP  - 2024 Jun 1
TI  - Artificial Intelligence in Plastic Surgery: ChatGPT as a Tool to Address 
      Disparities in Health Literacy.
PG  - 1232e-1234e
LID - 10.1097/PRS.0000000000011202 [doi]
FAU - Wang, Anya
AU  - Wang A
AD  - Division of Plastic and Reconstructive Surgery, Icahn School of Medicine at Mount 
      Sinai, New York, NY.
FAU - Kim, Esther
AU  - Kim E
FAU - Oleru, Olachi
AU  - Oleru O
FAU - Seyidova, Nargiz
AU  - Seyidova N
FAU - Taub, Peter J
AU  - Taub PJ
LA  - eng
GR  - TL1 TR004420/TR/NCATS NIH HHS/United States
PT  - Journal Article
DEP - 20231114
PL  - United States
TA  - Plast Reconstr Surg
JT  - Plastic and reconstructive surgery
JID - 1306050
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Health Literacy
MH  - *Surgery, Plastic/education
MH  - Healthcare Disparities/statistics & numerical data
MH  - Plastic Surgery Procedures/education/methods
PMC - PMC11090984
MID - NIHMS1978330
COIS- Author Disclosure Statement: No competing financial interests
EDAT- 2023/11/20 18:44
MHDA- 2024/05/29 18:43
PMCR- 2024/09/01
CRDT- 2023/11/20 17:26
PHST- 2024/05/29 18:43 [medline]
PHST- 2023/11/20 18:44 [pubmed]
PHST- 2023/11/20 17:26 [entrez]
PHST- 2024/09/01 00:00 [pmc-release]
AID - 00006534-202406000-00051 [pii]
AID - 10.1097/PRS.0000000000011202 [doi]
PST - ppublish
SO  - Plast Reconstr Surg. 2024 Jun 1;153(6):1232e-1234e. doi: 
      10.1097/PRS.0000000000011202. Epub 2023 Nov 14.

PMID- 37006948
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20230412
IS  - 2590-0056 (Electronic)
IS  - 2590-0056 (Linking)
VI  - 15
DP  - 2022 Sep
TI  - Natural language model for automatic identification of Intimate Partner Violence 
      reports from Twitter.
LID - 100217 [pii]
LID - 10.1016/j.array.2022.100217 [doi]
AB  - Intimate partner violence (IPV) is a preventable public health problem that 
      affects millions of people worldwide. Approximately one in four women are 
      estimated to be or have been victims of severe violence at some point in their 
      lives, irrespective of age, ethnicity, and economic status. Victims often report 
      IPV experiences on social media, and automatic detection of such reports via 
      machine learning may enable improved surveillance and targeted distribution of 
      support and/or interventions for those in need. However, no artificial 
      intelligence systems for automatic detection currently exists, and we attempted 
      to address this research gap. We collected posts from Twitter using a list of 
      IPV-related keywords, manually reviewed subsets of retrieved posts, and prepared 
      annotation guidelines to categorize tweets into IPV-report or non-IPV-report. We 
      annotated 6,348 tweets in total, with the inter-annotator agreement (IAA) of 0.86 
      (Cohen's kappa) among 1,834 double-annotated tweets. The class distribution in 
      the annotated dataset was highly imbalanced, with only 668 posts (~11%) labeled 
      as IPV-report. We then developed an effective natural language processing model 
      to identify IPV-reporting tweets automatically. The developed model achieved 
      classification F(1)-scores of 0.76 for the IPV-report class and 0.97 for the 
      non-IPV-report class. We conducted post-classification analyses to determine the 
      causes of system errors and to ensure that the system did not exhibit biases in 
      its decision making, particularly with respect to race and gender. Our automatic 
      model can be an essential component for a proactive social media-based 
      intervention and support framework, while also aiding population-level 
      surveillance and large-scale cohort studies.
FAU - Al-Garadi, Mohammed Ali
AU  - Al-Garadi MA
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA, United States.
FAU - Kim, Sangmi
AU  - Kim S
AD  - School of Nursing, Emory University, Atlanta, GA, United States.
FAU - Guo, Yuting
AU  - Guo Y
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA, United States.
FAU - Warren, Elise
AU  - Warren E
AD  - Rollins School of Public Health, Emory University, Atlanta, GA, United States.
FAU - Yang, Yuan-Chi
AU  - Yang YC
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA, United States.
FAU - Lakamana, Sahithi
AU  - Lakamana S
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA, United States.
FAU - Sarker, Abeed
AU  - Sarker A
AD  - Department of Biomedical Informatics, School of Medicine, Emory University, 
      Atlanta, GA, United States.
AD  - Department of Biomedical Engineering, Georgia Institute of Technology and Emory 
      University, Atlanta, GA, United States.
LA  - eng
GR  - K01 NR019651/NR/NINR NIH HHS/United States
PT  - Journal Article
DEP - 20220720
PL  - United States
TA  - Array (N Y)
JT  - Array (New York, N.Y.)
JID - 9918334788306676
PMC - PMC10065459
MID - NIHMS1882589
OTO - NOTNLM
OT  - Domestic violence
OT  - Intimate partner violence
OT  - Machine learning
OT  - Naturel language processing
OT  - Social media
COIS- Declaration of competing interest The authors have declared no competing 
      interest.
EDAT- 2023/04/04 06:00
MHDA- 2023/04/04 06:01
PMCR- 2023/03/31
CRDT- 2023/04/03 03:54
PHST- 2023/04/04 06:01 [medline]
PHST- 2023/04/03 03:54 [entrez]
PHST- 2023/04/04 06:00 [pubmed]
PHST- 2023/03/31 00:00 [pmc-release]
AID - 100217 [pii]
AID - 10.1016/j.array.2022.100217 [doi]
PST - ppublish
SO  - Array (N Y). 2022 Sep;15:100217. doi: 10.1016/j.array.2022.100217. Epub 2022 Jul 
      20.

PMID- 34771982
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240404
IS  - 1996-1944 (Print)
IS  - 1996-1944 (Electronic)
IS  - 1996-1944 (Linking)
VI  - 14
IP  - 21
DP  - 2021 Oct 27
TI  - Diptool-A Novel Numerical Tool for Membrane Interactions Analysis, Applying to 
      Antimicrobial Detergents and Drug Delivery Aids.
LID - 10.3390/ma14216455 [doi]
LID - 6455
AB  - The widespread problem of resistance development in bacteria has become a 
      critical issue for modern medicine. To limit that phenomenon, many compounds have 
      been extensively studied. Among them were derivatives of available drugs, but 
      also alternative novel detergents such as Gemini surfactants. Over the last 
      decade, they have been massively synthesized and studied to obtain the most 
      effective antimicrobial agents, as well as the most selective aids for 
      nanoparticles drug delivery. Various protocols and distinct bacterial strains 
      used in Minimal Inhibitory Concentration experimental studies prevented 
      performance benchmarking of different surfactant classes over these last years. 
      Motivated by this limitation, we designed a theoretical methodology implemented 
      in custom fast screening software to assess the surfactant activity on model 
      lipid membranes. Experimentally based QSAR (quantitative structure-activity 
      relationship) prediction delivered a set of parameters underlying the Diptool 
      software engine for high-throughput agent-membrane interactions analysis. We 
      validated our software by comparing score energy profiles with Gibbs free energy 
      from the Adaptive Biasing Force approach on octenidine and chlorhexidine, popular 
      antimicrobials. Results from Diptool can reflect the molecule behavior in the 
      lipid membrane and correctly predict free energy of translocation much faster 
      than classic molecular dynamics. This opens a new venue for searching novel 
      classes of detergents with sharp biologic activity.
FAU - Rzycki, Mateusz
AU  - Rzycki M
AUID- ORCID: 0000-0003-3655-3048
AD  - Department of Experimental Physics, Faculty of Fundamental Problems of 
      Technology, Wroclaw University of Science and Technology, 50-370 Wroclaw, Poland.
AD  - Department of Biomedical Engineering, Faculty of Fundamental Problems of 
      Technology, Wroclaw University of Science and Technology, 50-370 Wroclaw, Poland.
FAU - Kraszewski, Sebastian
AU  - Kraszewski S
AUID- ORCID: 0000-0003-3244-7694
AD  - Department of Biomedical Engineering, Faculty of Fundamental Problems of 
      Technology, Wroclaw University of Science and Technology, 50-370 Wroclaw, Poland.
FAU - Gładysiewicz-Kudrawiec, Marta
AU  - Gładysiewicz-Kudrawiec M
AUID- ORCID: 0000-0001-9289-6120
AD  - Department of Experimental Physics, Faculty of Fundamental Problems of 
      Technology, Wroclaw University of Science and Technology, 50-370 Wroclaw, Poland.
LA  - eng
GR  - 2015/19/B/NZ7/02380/National Science Center/
GR  - POWR.03.02.00-00-I003/16-01/National Centre for Research and Development/
PT  - Journal Article
DEP - 20211027
PL  - Switzerland
TA  - Materials (Basel)
JT  - Materials (Basel, Switzerland)
JID - 101555929
PMC - PMC8585202
OTO - NOTNLM
OT  - drug delivery
OT  - free energy calculation
OT  - lipid membranes
OT  - molecular dynamics
OT  - numerical tool
OT  - surfactants
COIS- The authors declare no conflict of interest.
EDAT- 2021/11/14 06:00
MHDA- 2021/11/14 06:01
PMCR- 2021/10/27
CRDT- 2021/11/13 01:16
PHST- 2021/10/01 00:00 [received]
PHST- 2021/10/23 00:00 [revised]
PHST- 2021/10/25 00:00 [accepted]
PHST- 2021/11/13 01:16 [entrez]
PHST- 2021/11/14 06:00 [pubmed]
PHST- 2021/11/14 06:01 [medline]
PHST- 2021/10/27 00:00 [pmc-release]
AID - ma14216455 [pii]
AID - materials-14-06455 [pii]
AID - 10.3390/ma14216455 [doi]
PST - epublish
SO  - Materials (Basel). 2021 Oct 27;14(21):6455. doi: 10.3390/ma14216455.

PMID- 40027840
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20250314
IS  - 2692-8205 (Electronic)
IS  - 2692-8205 (Linking)
DP  - 2025 Feb 17
TI  - Learning maximally spanning representations improves protein function annotation.
LID - 2025.02.13.638156 [pii]
LID - 10.1101/2025.02.13.638156 [doi]
AB  - Automated protein function annotation is a fundamental problem in computational 
      biology, crucial for understanding the functional roles of proteins in biological 
      processes, with broad implications in medicine and biotechnology. A persistent 
      challenge in this problem is the imbalanced, long-tail distribution of available 
      function annotations: a small set of well-studied function classes account for 
      most annotated proteins, while many other classes have few annotated proteins, 
      often due to investigative bias, experimental limitations, or intrinsic biases in 
      protein evolution. As a result, existing machine learning models for protein 
      function prediction tend to only optimize the prediction accuracy for 
      well-studied function classes overrepresented in the training data, leading to 
      poor accuracy for understudied functions. In this work, we develop MSRep, a novel 
      deep learning-based protein function annotation framework designed to address 
      this imbalance issue and improve annotation accuracy. MSRep is inspired by an 
      intriguing phenomenon, called neural collapse (NC), commonly observed in 
      high-accuracy deep neural networks used for classification tasks, where hidden 
      representations in the final layer collapse to class-specific mean embeddings, 
      while maintaining maximal inter-class separation. Given that NC consistently 
      emerges across diverse architectures and tasks for high-accuracy models, we 
      hypothesize that inducing NC structure in models trained on imbalanced data can 
      enhance both prediction accuracy and generalizability. To achieve this, MSRep 
      refines a pre-trained protein language model to produce NC-like representations 
      by optimizing an NC-inspired loss function, which ensures that minority functions 
      are equally represented in the embedding space as majority functions, in contrast 
      to conventional classification methods whose embedding spaces are dominated by 
      overrepresented classes. In evaluations across four protein function annotation 
      tasks on the prediction of Enzyme Commission numbers, Gene3D codes, Pfam 
      families, and Gene Ontology terms, MSRep demonstrates superior predictive 
      performance for both well- and underrepresented classes, outperforming several 
      state-of-the-art annotation tools. We anticipate that MSRep will enhance the 
      annotation of understudied functions and novel, uncharacterized proteins, 
      advancing future protein function studies and accelerating the discovery of new 
      functional proteins. The source code of MSRep is available at 
      https://github.com/luo-group/MSRep.
FAU - Luo, Jiaqi
AU  - Luo J
AD  - School of Computational Science and Engineering, Georgia Institute of Technology.
FAU - Luo, Yunan
AU  - Luo Y
AUID- ORCID: 0000-0001-7728-6412
AD  - School of Computational Science and Engineering, Georgia Institute of Technology.
LA  - eng
GR  - R35 GM150890/GM/NIGMS NIH HHS/United States
PT  - Journal Article
PT  - Preprint
DEP - 20250217
PL  - United States
TA  - bioRxiv
JT  - bioRxiv : the preprint server for biology
JID - 101680187
PMC - PMC11870436
EDAT- 2025/03/03 17:13
MHDA- 2025/03/03 17:14
PMCR- 2025/02/28
CRDT- 2025/03/03 06:27
PHST- 2025/03/03 17:13 [pubmed]
PHST- 2025/03/03 17:14 [medline]
PHST- 2025/03/03 06:27 [entrez]
PHST- 2025/02/28 00:00 [pmc-release]
AID - 2025.02.13.638156 [pii]
AID - 10.1101/2025.02.13.638156 [doi]
PST - epublish
SO  - bioRxiv [Preprint]. 2025 Feb 17:2025.02.13.638156. doi: 
      10.1101/2025.02.13.638156.

PMID- 40053755
OWN - NLM
STAT- MEDLINE
DCOM- 20250307
LR  - 20250323
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Mar 6
TI  - Health Communication on the Internet: Promoting Public Health and Exploring 
      Disparities in the Generative AI Era.
PG  - e66032
LID - 10.2196/66032 [doi]
LID - e66032
AB  - Health communication and promotion on the internet have evolved over time, driven 
      by the development of new technologies, including generative artificial 
      intelligence (GenAI). These technological tools offer new opportunities for both 
      the public and professionals. However, these advancements also pose risks of 
      exacerbating health disparities. Limited research has focused on combining these 
      health communication mediums, particularly those enabled by new technologies like 
      GenAI, and their applications for health promotion and health disparities. 
      Therefore, this viewpoint, adopting a conceptual approach, provides an updated 
      overview of health communication mediums and their role in understanding health 
      promotion and disparities in the GenAI era. Additionally, health promotion and 
      health disparities associated with GenAI are briefly discussed through the lens 
      of the Technology Acceptance Model 2, the uses and gratifications theory, and the 
      knowledge gap hypothesis. This viewpoint discusses the limitations and barriers 
      of previous internet-based communication mediums regarding real-time responses, 
      personalized advice, and follow-up inquiries, highlighting the potential of new 
      technology for public health promotion. It also discusses the health disparities 
      caused by the limitations of GenAI, such as individuals' inability to evaluate 
      information, restricted access to services, and the lack of skill development. 
      Overall, this study lays the groundwork for future research on how GenAI could be 
      leveraged for public health promotion and how its challenges and barriers may 
      exacerbate health inequities. It underscores the need for more empirical studies, 
      as well as the importance of enhancing digital literacy and increasing access to 
      technology for socially disadvantaged populations.
CI  - ©Jamal Uddin, Cheng Feng, Junfang Xu. Originally published in the Journal of 
      Medical Internet Research (https://www.jmir.org), 06.03.2025.
FAU - Uddin, Jamal
AU  - Uddin J
AUID- ORCID: 0000-0002-2612-6168
AD  - Communication Department, Cornell University, Ithaca, NY, United States.
FAU - Feng, Cheng
AU  - Feng C
AUID- ORCID: 0000-0002-5599-460X
AD  - Vanke School of Public Health, Tsinghua University, Beijing, China.
AD  - Institute for Healthy China, Tsinghua University, Beijing, China.
FAU - Xu, Junfang
AU  - Xu J
AUID- ORCID: 0000-0001-9133-8960
AD  - Department of Pharmacy, Second Affiliated Hospital, School of Public health, 
      Zhejiang University School of Medicine, Hangzhou, China.
LA  - eng
PT  - Journal Article
DEP - 20250306
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Internet
MH  - *Health Promotion/methods
MH  - *Artificial Intelligence
MH  - *Public Health
MH  - *Health Communication/methods
PMC - PMC11926442
OTO - NOTNLM
OT  - AI
OT  - ChatGPT
OT  - artificial intelligence
OT  - communication
OT  - disparity
OT  - genAI
OT  - generative
OT  - generative AI
OT  - gratification
OT  - gratification theory
OT  - health
OT  - health communication
OT  - health disparity
OT  - health promotion
OT  - inequity
OT  - internet
OT  - public health
OT  - tool
COIS- Conflicts of Interest: None declared.
EDAT- 2025/03/07 18:22
MHDA- 2025/03/07 18:23
PMCR- 2025/03/06
CRDT- 2025/03/07 14:44
PHST- 2024/09/02 00:00 [received]
PHST- 2025/01/31 00:00 [accepted]
PHST- 2025/01/15 00:00 [revised]
PHST- 2025/03/07 18:23 [medline]
PHST- 2025/03/07 18:22 [pubmed]
PHST- 2025/03/07 14:44 [entrez]
PHST- 2025/03/06 00:00 [pmc-release]
AID - v27i1e66032 [pii]
AID - 10.2196/66032 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Mar 6;27:e66032. doi: 10.2196/66032.

PMID- 40015562
OWN - NLM
STAT- In-Process
LR  - 20250328
IS  - 2005-8330 (Electronic)
IS  - 1229-6929 (Linking)
VI  - 26
IP  - 4
DP  - 2025 Apr
TI  - Crucial Role of Understanding in Human-Artificial Intelligence Interaction for 
      Successful Clinical Adoption.
PG  - 287-290
LID - 10.3348/kjr.2025.0071 [doi]
FAU - Park, Seong Ho
AU  - Park SH
AUID- ORCID: 0000-0002-1257-8315
AD  - Department of Radiology and Research Institute of Radiology, University of Ulsan 
      College of Medicine, Asan Medical Center, Seoul, Republic of Korea. 
      parksh.radiology@gmail.com.
FAU - Langlotz, Curtis P
AU  - Langlotz CP
AUID- ORCID: 0000-0002-8972-8051
AD  - Departments of Radiology, Medicine, and Biomedical Data Science, Center for 
      Artificial Intelligence in Medicine and Imaging, Stanford University, Stanford, 
      CA, USA.
LA  - eng
PT  - Editorial
DEP - 20250217
PL  - Korea (South)
TA  - Korean J Radiol
JT  - Korean journal of radiology
JID - 100956096
SB  - IM
OTO - NOTNLM
OT  - Artificial intelligence
OT  - Automation bias
OT  - Behavior
OT  - Burden
OT  - Cognitive
OT  - Digital
OT  - Explainable
OT  - Fatigue
OT  - Generative
OT  - Human
OT  - Interaction
OT  - Interpretable
OT  - Large language model
OT  - Machine
OT  - Prompt engineering
OT  - Workload
COIS- Seong Ho Park: Editor-in-Chief without involvement in the editorial evaluation or 
      decision to publish this article. Consulting fees from the Ministry of Food and 
      Drug Safety, Republic of Korea; honoraria from Bayer and Korean Society of 
      Radiology; support for travel from Korean Society of Radiology.
EDAT- 2025/02/28 00:20
MHDA- 2025/02/28 00:20
CRDT- 2025/02/27 19:35
PHST- 2025/01/15 00:00 [received]
PHST- 2025/01/16 00:00 [accepted]
PHST- 2025/02/28 00:20 [pubmed]
PHST- 2025/02/28 00:20 [medline]
PHST- 2025/02/27 19:35 [entrez]
AID - 26.e27 [pii]
AID - 10.3348/kjr.2025.0071 [doi]
PST - ppublish
SO  - Korean J Radiol. 2025 Apr;26(4):287-290. doi: 10.3348/kjr.2025.0071. Epub 2025 
      Feb 17.

PMID- 39948824
OWN - NLM
STAT- Publisher
LR  - 20250214
IS  - 1097-0045 (Electronic)
IS  - 0270-4137 (Linking)
DP  - 2025 Feb 13
TI  - Progression-Free Survival Prediction Performance of ChatGPT: Analysis With Real 
      Life Data in Early and Locally Advanced Prostate Cancer.
PG  - e24871
LID - 10.1002/pros.24871 [doi]
AB  - OBJECTIVE: To evaluate the progression-free survival (PFS) time in patients with 
      early-stage and locally advanced prostate cancer and to compare the estimates 
      provided by ChatGPT with actual survival data. METHODS: A retrospective analysis 
      was conducted on patients diagnosed with early-stage/locally advanced prostate 
      cancer. Each patient's estimated PFS times were calculated using an artificial 
      intelligence chatbot. These estimates were generated by considering several 
      factors, including the patient's clinical characteristics, tumor stage, treatment 
      modalities, and biochemical parameters. A statistical comparison was conducted 
      between the predicted PFS and actual PFS times. RESULTS: The AI chatbot tended to 
      overestimate the overall PFS times. A statistically significant discrepancy was 
      observed between the predicted and actual survival times (p < 0.05). A 
      discrepancy of 9.19 months was observed between the PFS predictions made by 
      ChatGPT and the actual PFS. The bias value was 48.57, yet this discrepancy had a 
      negligible impact on clinical practice (Cohen's d = 0.189). DISCUSSION: 
      Artificial intelligence-based models have the potential to play an important role 
      in the prediction of progression in cancers such as prostate cancer, where 
      5-10-year survival rates can reach 100%. However, this study's findings indicate 
      that the AI model's predictions are not aligned with the actual clinical data. 
      The reliability of the integration of artificial intelligence into clinical 
      decision support systems can be enhanced through the undertaking of comprehensive 
      future studies. CONCLUSION: The use of artificial intelligence in predictive 
      modeling may prove an effective approach for forecasting the PFS of prostate 
      cancer. It has the potential to supplant the nomograms that are currently in use. 
      Nevertheless, further studies are required to substantiate the accuracy and 
      reliability of these systems.
CI  - © 2025 Wiley Periodicals LLC.
FAU - Kavak, Engin Eren
AU  - Kavak EE
AUID- ORCID: 0000-0003-3247-5361
AD  - Department of Medical Oncology, Etlik City Hospital, Oncology Hospital, Ankara, 
      Turkey.
FAU - Dilli, İsmail
AU  - Dilli İ
AD  - Department of Medical Oncology, Etlik City Hospital, Oncology Hospital, Ankara, 
      Turkey.
LA  - eng
GR  - The authors received no specific funding for this work./
PT  - Journal Article
DEP - 20250213
PL  - United States
TA  - Prostate
JT  - The Prostate
JID - 8101368
SB  - IM
OTO - NOTNLM
OT  - Prostate Cancer
OT  - artificial intelligence
OT  - predicted progression‐free survival
OT  - prognostic model
EDAT- 2025/02/14 06:20
MHDA- 2025/02/14 06:20
CRDT- 2025/02/14 00:53
PHST- 2025/02/01 00:00 [revised]
PHST- 2024/11/12 00:00 [received]
PHST- 2025/02/06 00:00 [accepted]
PHST- 2025/02/14 06:20 [medline]
PHST- 2025/02/14 06:20 [pubmed]
PHST- 2025/02/14 00:53 [entrez]
AID - 10.1002/pros.24871 [doi]
PST - aheadofprint
SO  - Prostate. 2025 Feb 13:e24871. doi: 10.1002/pros.24871.

PMID- 39847418
OWN - NLM
STAT- MEDLINE
DCOM- 20250123
LR  - 20250210
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Jan 23
TI  - Predicting User Engagement in Health Misinformation Correction on Social Media 
      Platforms in Taiwan: Content Analysis and Text Mining Study.
PG  - e65631
LID - 10.2196/65631 [doi]
LID - e65631
AB  - BACKGROUND: Health misinformation undermines responses to health crises, with 
      social media amplifying the issue. Although organizations work to correct 
      misinformation, challenges persist due to reasons such as the difficulty of 
      effectively sharing corrections and information being overwhelming. At the same 
      time, social media offers valuable interactive data, enabling researchers to 
      analyze user engagement with health misinformation corrections and refine content 
      design strategies. OBJECTIVE: This study aimed to identify the attributes of 
      correction posts and user engagement and investigate (1) the trend of user 
      engagement with health misinformation correction during 3 years of the COVID-19 
      pandemic; (2) the relationship between post attributes and user engagement in 
      sharing and reactions; and (3) the content generated by user comments serving as 
      additional information attached to the post, affecting user engagement in sharing 
      and reactions. METHODS: Data were collected from the Facebook pages of a 
      fact-checking organization and a health agency from January 2020 to December 
      2022. A total of 1424 posts and 67,378 corresponding comments were analyzed. The 
      posts were manually annotated by developing a research framework based on the 
      fuzzy-trace theory, categorizing information into "gist" and "verbatim" 
      representations. Three types of gist representations were examined: risk (risks 
      associated with misinformation), awareness (awareness of misinformation), and 
      value (value in health promotion). Furthermore, 3 types of verbatim 
      representations were identified: numeric (numeric and statistical bases for 
      correction), authority (authority from experts, scholars, or institutions), and 
      facts (facts with varying levels of detail). The basic metrics of user engagement 
      included shares, reactions, and comments as the primary dependent variables. 
      Moreover, this study examined user comments and classified engagement as 
      cognitive (knowledge-based, critical, and bias-based) or emotional (positive, 
      negative, and neutral). Statistical analyses were performed to explore the impact 
      of post attributes on user engagement. RESULTS: On the basis of the results of 
      the regression analysis, risk (β=.07; P=.001), awareness (β=.09; P<.001), and 
      facts (β=.14; P<.001) predicted higher shares; awareness (β=.07; P=.001) and 
      facts (β=.24; P<.001) increased reactions; and awareness (β=.06; P=.005), numeric 
      representations (β=.06; P=.02), and facts (β=.19; P<.001) increased comments. All 
      3 gist representations significantly predicted shares (risk: β=.08; P<.001, 
      awareness: β=.08; P<.001, and value: β=.06; P<.001) and reactions (risk: β=.04; 
      P=.007, awareness: β=.06; P<.001, and value: β=.05; P<.001) when considering 
      comment content. In addition, comments with bias-based engagement (β=-.11; 
      P=.001) negatively predicted shares. Generally, posts providing gist attributes, 
      especially awareness of misinformation, were beneficial for user engagement in 
      misinformation correction. CONCLUSIONS: This study enriches the theoretical 
      understanding of the relationship between post attributes and user engagement 
      within web-based communication efforts to correct health misinformation. These 
      findings provide a foundation for designing more effective content approaches to 
      combat misinformation and strengthen public health communication.
CI  - ©Hsin-Yu Kuo, Su-Yen Chen. Originally published in the Journal of Medical 
      Internet Research (https://www.jmir.org), 23.01.2025.
FAU - Kuo, Hsin-Yu
AU  - Kuo HY
AUID- ORCID: 0000-0002-6347-388X
AD  - Department of Educational Psychology and Counseling, National Tsing Hua 
      University, Hsinchu, Taiwan.
FAU - Chen, Su-Yen
AU  - Chen SY
AUID- ORCID: 0000-0003-1066-6650
AD  - Institute of Learning Sciences and Technologies, National Tsing Hua University, 
      Hsinchu, Taiwan.
LA  - eng
PT  - Journal Article
DEP - 20250123
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - *Social Media
MH  - Humans
MH  - Taiwan
MH  - *COVID-19/prevention & control
MH  - *Data Mining/methods
MH  - *Communication
MH  - SARS-CoV-2
MH  - Information Dissemination/methods
MH  - Pandemics
PMC - PMC11803327
OTO - NOTNLM
OT  - content analysis
OT  - fact-checking
OT  - fuzzy-trace theory
OT  - health communication
OT  - health misinformation
OT  - large language models
OT  - misinformation correction
OT  - social media
OT  - text mining
OT  - user engagement
COIS- Conflicts of Interest: None declared.
EDAT- 2025/01/23 12:36
MHDA- 2025/01/23 18:25
PMCR- 2025/01/23
CRDT- 2025/01/23 11:53
PHST- 2024/08/21 00:00 [received]
PHST- 2024/11/27 00:00 [accepted]
PHST- 2024/11/05 00:00 [revised]
PHST- 2025/01/23 18:25 [medline]
PHST- 2025/01/23 12:36 [pubmed]
PHST- 2025/01/23 11:53 [entrez]
PHST- 2025/01/23 00:00 [pmc-release]
AID - v27i1e65631 [pii]
AID - 10.2196/65631 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Jan 23;27:e65631. doi: 10.2196/65631.

PMID- 39800055
OWN - NLM
STAT- Publisher
LR  - 20250306
IS  - 2212-2672 (Print)
IS  - 2212-2672 (Linking)
DP  - 2025 Jan 10
TI  - Social and Economic Patterning in Ultra-Processed Food Intake in Toddlerhood and 
      Middle Childhood: Longitudinal Data From the Gemini Cohort in the United Kingdom.
LID - S2212-2672(25)00013-9 [pii]
LID - 10.1016/j.jand.2025.01.004 [doi]
AB  - BACKGROUND: Children's consumption of ultra-processed food (UPF) may contribute 
      to inequalities in obesity and wider health. Socioeconomic patterning in younger 
      UK children's UPF intake is unknown. OBJECTIVE: The aim of this study was to 
      investigate socioeconomic patterning of UK toddlers' (aged 21 months) and 
      children's (aged 7 years) UPF intake across several household and neighborhood 
      indicators. DESIGN: Secondary analysis of data from a prospective longitudinal 
      cohort study using parent-reported sociodemographic data and 3-day diet diaries. 
      PARTICIPANTS/SETTING: Participants were children from the UK Gemini study of 4804 
      twins born in 2007. At ages 21 months and 7 years, 2591 and 592 children, 
      respectively, had at least 2 days of dietary data. MAIN OUTCOME MEASURES: This 
      study measured percentage energy from UPF at 21 months and 7 years of age, 
      classified using the NOVA system. STATISTICAL ANALYSES PERFORMED: Unadjusted 
      linear regression models were run for household socioeconomic position (SEP) 
      composite score; index of multiple deprivation decile; income; occupation level; 
      mother's age; education of mother and partner; and child's ethnicity, sex, and 
      age. Adjusted multivariable linear regression models were adjusted for ethnicity 
      and all SEP indicators except SEP composite score (adjusted 1), in addition to 
      child sex and age (adjusted 2). Missing data were addressed with multiple 
      imputation and inverse probability weighting. CIs and P values were adjusted to 
      account for clustering within families. RESULTS: Children of lower SEP had higher 
      UPF intake across several indicators. Mother's education was the strongest 
      predictor; postgraduate education was associated with 8.64% (95% CI -12.08% to 
      -5.20%; P < .001) and 10.12% (95% CI, -15.68% to -4.56%; P < .001) less energy 
      from UPF at 21 months and 7 years, respectively, compared with no educational 
      qualifications in adjusted model 2. CONCLUSIONS: UK children from more 
      disadvantaged backgrounds consumed a greater proportion of their energy from UPF. 
      Mother's education seemed to be the most influential factor. Socioeconomic 
      inequalities, particularly in maternal education, may drive disparities in diet 
      quality and associated health outcomes. Addressing these gaps is essential to 
      reduce childhood obesity and improve long-term health in socioeconomically 
      disadvantaged populations.
CI  - Copyright © 2025 The Authors. Published by Elsevier Inc. All rights reserved.
FAU - Heuchan, Gabriella N
AU  - Heuchan GN
AD  - Institute of Epidemiology and Healthcare, University College London, London, 
      United Kingdom. Electronic address: gabriella.heuchan.20@ucl.ac.uk.
FAU - Conway, Rana E
AU  - Conway RE
AD  - Institute of Epidemiology and Healthcare, University College London, London, 
      United Kingdom.
FAU - Tattan-Birch, Harry
AU  - Tattan-Birch H
AD  - Institute of Epidemiology and Healthcare, University College London, London, 
      United Kingdom.
FAU - Heggie, Lisa
AU  - Heggie L
AD  - Institute of Epidemiology and Healthcare, University College London, London, 
      United Kingdom.
FAU - Llewellyn, Clare H
AU  - Llewellyn CH
AD  - Institute of Epidemiology and Healthcare, University College London, London, 
      United Kingdom.
LA  - eng
PT  - Journal Article
DEP - 20250110
PL  - United States
TA  - J Acad Nutr Diet
JT  - Journal of the Academy of Nutrition and Dietetics
JID - 101573920
SB  - IM
OTO - NOTNLM
OT  - Child nutrition
OT  - Inequalities
OT  - Socioeconomic position
OT  - Ultra-processed food
OT  - Western diets
EDAT- 2025/01/13 00:20
MHDA- 2025/01/13 00:20
CRDT- 2025/01/12 19:29
PHST- 2024/05/08 00:00 [received]
PHST- 2024/12/23 00:00 [revised]
PHST- 2025/01/07 00:00 [accepted]
PHST- 2025/01/13 00:20 [pubmed]
PHST- 2025/01/13 00:20 [medline]
PHST- 2025/01/12 19:29 [entrez]
AID - S2212-2672(25)00013-9 [pii]
AID - 10.1016/j.jand.2025.01.004 [doi]
PST - aheadofprint
SO  - J Acad Nutr Diet. 2025 Jan 10:S2212-2672(25)00013-9. doi: 
      10.1016/j.jand.2025.01.004.

PMID- 39522019
OWN - NLM
STAT- MEDLINE
DCOM- 20241110
LR  - 20241116
IS  - 1471-2164 (Electronic)
IS  - 1471-2164 (Linking)
VI  - 25
IP  - 1
DP  - 2024 Nov 9
TI  - Interpretation knowledge extraction for genetic testing via question-answer 
      model.
PG  - 1062
LID - 10.1186/s12864-024-10978-9 [doi]
LID - 1062
AB  - BACKGROUND: Sequencing-based genetic testing is widely used in biomedical 
      research, including pathogenic microorganism detection with metagenomic 
      next-generation sequencing (mNGS). The application of sequencing results to 
      clinical diagnosis and treatment relies on various interpretation knowledge 
      bases. Currently, the existing knowledge bases are primarily built through manual 
      knowledge extraction. This method requires professionals to read extensive 
      literature and extract relevant knowledge from it, which is time-consuming and 
      costly. Furthermore, manual extraction unavoidably introduces subjective biases. 
      In this study, we aimed to automatically extract knowledge for interpreting mNGS 
      results. METHOD: We propose a novel approach to automatically extract pathogenic 
      microorganism knowledge based on the question-answer (QA) model. First, we 
      construct a MicrobeDB dataset since there is no available pathogenic 
      microorganism QA dataset for training the model. The created dataset contains 
      3,161 samples from 618 published papers covering 224 pathogenic microorganisms. 
      Then, we fine-tune the selected baseline model based on MicrobeDB. Finally, we 
      utilize ChatGPT to enhance the diversity of training data, and employ data 
      expansion to increase training data volume. RESULTS: Our method achieves an Exact 
      Match (EM) and F1 score of 88.39% and 93.18%, respectively, on the MicrobeDB test 
      set. We also conduct ablation studies on the proposed data augmentation method. 
      In addition, we perform comparative experiments with the ChatPDF tool based on 
      the ChatGPT API to demonstrate the effectiveness of the proposed method. 
      CONCLUSIONS: Our method is effective and valuable for extracting pathogenic 
      microorganism knowledge.
CI  - © 2024. The Author(s).
FAU - Wang, Wenjun
AU  - Wang W
AD  - School of Software Engineering, South China University of Technology, Guangzhou, 
      China.
AD  - School of Data Science and Information Engineering, Guizhou Minzu University, 
      Guiyang, China.
AD  - Pazhou Lab, Guangzhou, China.
FAU - Chen, Huanxin
AU  - Chen H
AD  - School of Software Engineering, South China University of Technology, Guangzhou, 
      China.
FAU - Wang, Hui
AU  - Wang H
AD  - Shenzhen Cladogram Technology Co., Ltd, Shenzhen, China.
FAU - Fang, Lin
AU  - Fang L
AD  - Shenzhen Cladogram Technology Co., Ltd, Shenzhen, China.
FAU - Wang, Huan
AU  - Wang H
AD  - Industrial Technology Research Center, Guangdong Institute of Scientific & 
      Technical Information, Guangzhou, China.
FAU - Ding, Yi
AU  - Ding Y
AD  - Hunan University of Arts and Science, Changde, China.
FAU - Lu, Yao
AU  - Lu Y
AD  - Shenzhen Cladogram Technology Co., Ltd, Shenzhen, China. luyaozd@163.com.
FAU - Wu, Qingyao
AU  - Wu Q
AD  - School of Software Engineering, South China University of Technology, Guangzhou, 
      China.
AD  - Pazhou Lab, Guangzhou, China.
AD  - Peng Cheng Laboratory, Shenzhen, China.
LA  - eng
GR  - 62266012/National Natural Science Foundation of China/
GR  - 62272172/National Natural Science Foundation of China/
GR  - 2023A04J1051/Guangzhou Basic Research Program-Basic and Applied Basic Research 
      Project/
GR  - 2023B003/Guangdong Institute of Scientific and Technical Information Strategic 
      Studies Project/
PT  - Journal Article
DEP - 20241109
PL  - England
TA  - BMC Genomics
JT  - BMC genomics
JID - 100965258
SB  - IM
MH  - *Genetic Testing/methods
MH  - Humans
MH  - *Knowledge Bases
MH  - High-Throughput Nucleotide Sequencing/methods
MH  - Metagenomics/methods
MH  - Computational Biology/methods
PMC - PMC11549790
OTO - NOTNLM
OT  - Genetic testing
OT  - Interpretation knowledge extraction
OT  - MicrobeDB
OT  - Pathogenic microorganism
OT  - Question-answer
COIS- The authors declare no competing interests.
EDAT- 2024/11/13 13:57
MHDA- 2024/11/13 13:58
PMCR- 2024/11/09
CRDT- 2024/11/10 03:13
PHST- 2023/07/10 00:00 [received]
PHST- 2024/10/29 00:00 [accepted]
PHST- 2024/11/13 13:58 [medline]
PHST- 2024/11/13 13:57 [pubmed]
PHST- 2024/11/10 03:13 [entrez]
PHST- 2024/11/09 00:00 [pmc-release]
AID - 10.1186/s12864-024-10978-9 [pii]
AID - 10978 [pii]
AID - 10.1186/s12864-024-10978-9 [doi]
PST - epublish
SO  - BMC Genomics. 2024 Nov 9;25(1):1062. doi: 10.1186/s12864-024-10978-9.

PMID- 39437605
OWN - NLM
STAT- MEDLINE
DCOM- 20241119
LR  - 20241119
IS  - 1879-0534 (Electronic)
IS  - 0010-4825 (Linking)
VI  - 183
DP  - 2024 Dec
TI  - Multifocal region-assisted cross-modality learning for chest X-ray report 
      generation.
PG  - 109187
LID - S0010-4825(24)01272-1 [pii]
LID - 10.1016/j.compbiomed.2024.109187 [doi]
AB  - The prevalence of cardiovascular disease, tumors, and other chronic illnesses has 
      been steadily rising in recent years. Researchers have recently been employing 
      cross-modal large-scale models and natural language generation models to address 
      the significant visual and textual disparities in medical report generation 
      tasks. However, these training processes presents challenges, such as 
      difficulties matching cross-modal information and generating specialized medical 
      terminology. To tackle these issues, we propose a Multifocal Region-Assisted 
      Report Generation Network (MRARGN) to enhance cross-modal information matching. 
      Specifically, we integrate a pre-trained ResNet-50 with multi-channel and 
      attention mechanisms for trainable X-ray image representation. We then combine 
      our proposed memory response matrix with OpenAI's contrastive pre-training 
      results to construct a dynamic knowledge graph that stores lesion features and 
      their corresponding texts. Finally, we incorporate attention mechanisms and 
      forget gate units to generate comprehensive textual descriptions for different 
      lesions, using an image and report alignment loss. We conduct ablation 
      experiments on the IU-Xray and MIMIC-CXR datasets to evaluate our approach. The 
      experimental results demonstrate that our proposed MRARGN outperforms most 
      state-of-the-art approaches, including their own variants.
CI  - Copyright © 2024 Elsevier Ltd. All rights reserved.
FAU - Lian, Jing
AU  - Lian J
AD  - School of Electronics and Information Engineering, Lanzhou Jiaotong University, 
      Lanzhou, Gansu 730070, China; School of Information Science and Engineering, 
      Lanzhou University, Lanzhou, Gansu 730000, China.
FAU - Dong, Zilong
AU  - Dong Z
AD  - School of Electronics and Information Engineering, Lanzhou Jiaotong University, 
      Lanzhou, Gansu 730070, China. Electronic address: 3481823984@qq.com.
FAU - Zhang, Huaikun
AU  - Zhang H
AD  - School of Electronics and Information Engineering, Lanzhou Jiaotong University, 
      Lanzhou, Gansu 730070, China.
FAU - Chen, Yuekai
AU  - Chen Y
AD  - School of Electronics and Information Engineering, Lanzhou Jiaotong University, 
      Lanzhou, Gansu 730070, China.
FAU - Liu, Jizhao
AU  - Liu J
AD  - School of Information Science and Engineering, Lanzhou University, Lanzhou, Gansu 
      730000, China.
LA  - eng
PT  - Journal Article
DEP - 20241021
PL  - United States
TA  - Comput Biol Med
JT  - Computers in biology and medicine
JID - 1250250
SB  - IM
MH  - Humans
MH  - *Radiography, Thoracic
MH  - Deep Learning
OTO - NOTNLM
OT  - Automatic report generation
OT  - CLIP
OT  - Cross-modal
OT  - Encoder–decoder
OT  - IU X-ray and MIMIC-CXR
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2024/10/23 00:21
MHDA- 2024/11/19 11:00
CRDT- 2024/10/22 18:06
PHST- 2024/01/10 00:00 [received]
PHST- 2024/09/19 00:00 [revised]
PHST- 2024/09/20 00:00 [accepted]
PHST- 2024/11/19 11:00 [medline]
PHST- 2024/10/23 00:21 [pubmed]
PHST- 2024/10/22 18:06 [entrez]
AID - S0010-4825(24)01272-1 [pii]
AID - 10.1016/j.compbiomed.2024.109187 [doi]
PST - ppublish
SO  - Comput Biol Med. 2024 Dec;183:109187. doi: 10.1016/j.compbiomed.2024.109187. Epub 
      2024 Oct 21.

PMID- 39178002
OWN - NLM
STAT- MEDLINE
DCOM- 20240823
LR  - 20250305
IS  - 2574-3805 (Electronic)
IS  - 2574-3805 (Linking)
VI  - 7
IP  - 8
DP  - 2024 Aug 1
TI  - Using AI and Social Media to Understand Health Disparities for Transgender Cancer 
      Care.
PG  - e2429792
LID - 10.1001/jamanetworkopen.2024.29792 [doi]
LID - e2429792
FAU - Annan, Augustine
AU  - Annan A
AD  - IMO Health, Rosemont, Illinois.
FAU - Li, Yeran
AU  - Li Y
AD  - Center for Observational and Real-World Evidence, Merck and Co, Inc, Rahway, New 
      Jersey.
FAU - Du, Jingcheng
AU  - Du J
AD  - IMO Health, Rosemont, Illinois.
FAU - Sun, Yezhou
AU  - Sun Y
AD  - Center for Observational and Real-World Evidence, Merck and Co, Inc, Rahway, New 
      Jersey.
FAU - Asante-Facey, A I
AU  - Asante-Facey AI
AD  - Division of Gynecologic Oncology, Department of Obstetrics and Gynecology, Lenox 
      Hill Hospital, New York, New York.
FAU - Wang, Xiaoyan
AU  - Wang X
AD  - IMO Health, Rosemont, Illinois.
FAU - Monberg, Matthew
AU  - Monberg M
AD  - Center for Observational and Real-World Evidence, Merck and Co, Inc, Rahway, New 
      Jersey.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20240801
PL  - United States
TA  - JAMA Netw Open
JT  - JAMA network open
JID - 101729235
SB  - IM
EIN - JAMA Netw Open. 2024 Oct 1;7(10):e2442253. doi: 
      10.1001/jamanetworkopen.2024.42253. PMID: 39365591
MH  - Humans
MH  - *Social Media/statistics & numerical data
MH  - *Transgender Persons/statistics & numerical data/psychology
MH  - *Neoplasms/therapy
MH  - Female
MH  - Male
MH  - *Healthcare Disparities
MH  - Artificial Intelligence
PMC - PMC11344235
OAB - This qualitative study used an artificial intelligence (AI) large language model 
      and social media to investigate challenges encountered by transgender individuals 
      during breast and gynecological cancer care.
OABL- eng
COIS- Conflict of Interest Disclosures: Mx Asante-Facey reported receiving personal 
      fees from GSK and AstraZeneca outside the submitted work. Dr Sun reported owning 
      stock from Merck and Co and UnitedHealth Group outside the submitted work. No 
      other disclosures were reported.
EDAT- 2024/08/23 12:45
MHDA- 2024/08/23 12:46
PMCR- 2024/08/23
CRDT- 2024/08/23 11:33
PHST- 2024/08/23 12:46 [medline]
PHST- 2024/08/23 12:45 [pubmed]
PHST- 2024/08/23 11:33 [entrez]
PHST- 2024/08/23 00:00 [pmc-release]
AID - 2822775 [pii]
AID - zld240133 [pii]
AID - 10.1001/jamanetworkopen.2024.29792 [doi]
PST - epublish
SO  - JAMA Netw Open. 2024 Aug 1;7(8):e2429792. doi: 
      10.1001/jamanetworkopen.2024.29792.

PMID- 38679000
OWN - NLM
STAT- MEDLINE
DCOM- 20240912
LR  - 20250225
IS  - 1421-9735 (Electronic)
IS  - 0253-5068 (Linking)
VI  - 53
IP  - 9
DP  - 2024
TI  - Evaluating ChatGPT's Accuracy in Responding to Patient Education Questions on 
      Acute Kidney Injury and Continuous Renal Replacement Therapy.
PG  - 725-731
LID - 10.1159/000539065 [doi]
AB  - INTRODUCTION: Acute kidney injury (AKI) and continuous renal replacement therapy 
      (CRRT) are critical areas in nephrology. The effectiveness of ChatGPT in simpler, 
      patient education-oriented questions has not been thoroughly assessed. This study 
      evaluates the proficiency of ChatGPT 4.0 in responding to such questions, 
      subjected to various linguistic alterations. METHODS: Eighty-nine questions were 
      sourced from the Mayo Clinic Handbook for educating patients on AKI and CRRT. 
      These questions were categorized as original, paraphrased with different 
      interrogative adverbs, paraphrased resulting in incomplete sentences, and 
      paraphrased containing misspelled words. Two nephrologists verified the questions 
      for medical accuracy. A χ2 test was conducted to ascertain notable discrepancies 
      in ChatGPT 4.0's performance across these formats. RESULTS: ChatGPT provided 
      notable accuracy in handling a variety of question formats for patient education 
      in AKI and CRRT. Across all question types, ChatGPT demonstrated an accuracy of 
      97% for both original and adverb-altered questions and 98% for questions with 
      incomplete sentences or misspellings. Specifically for AKI-related questions, the 
      accuracy was consistently maintained at 97% for all versions. In the subset of 
      CRRT-related questions, the tool achieved a 96% accuracy for original and 
      adverb-altered questions, and this increased to 98% for questions with incomplete 
      sentences or misspellings. The statistical analysis revealed no significant 
      difference in performance across these varied question types (p value: 1.00 for 
      AKI and 1.00 for CRRT), and there was no notable disparity between the artificial 
      intelligence (AI)'s responses to AKI and CRRT questions (p value: 0.71). 
      CONCLUSION: ChatGPT 4.0 demonstrates consistent and high accuracy in interpreting 
      and responding to queries related to AKI and CRRT, irrespective of linguistic 
      modifications. These findings suggest that ChatGPT 4.0 has the potential to be a 
      reliable support tool in the delivery of patient education, by accurately 
      providing information across a range of question formats. Further research is 
      needed to explore the direct impact of AI-generated responses on patient 
      understanding and education outcomes.
CI  - © 2024 S. Karger AG, Basel.
FAU - Sheikh, Mohammad Salman
AU  - Sheikh MS
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, Minnesota, USA.
FAU - Thongprayoon, Charat
AU  - Thongprayoon C
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, Minnesota, USA.
FAU - Suppadungsuk, Supawadee
AU  - Suppadungsuk S
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, Minnesota, USA.
AD  - Chakri Naruebodindra Medical Institute, Faculty of Medicine Ramathibodi Hospital, 
      Mahidol University, Salaya, Thailand.
FAU - Miao, Jing
AU  - Miao J
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, Minnesota, USA.
FAU - Qureshi, Fawad
AU  - Qureshi F
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, Minnesota, USA.
FAU - Kashani, Kianoush
AU  - Kashani K
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, Minnesota, USA.
AD  - Division of Pulmonary and Critical Care Medicine, Department of Medicine, Mayo 
      Clinic, Rochester, Minnesota, USA.
FAU - Cheungpasitporn, Wisit
AU  - Cheungpasitporn W
AD  - Division of Nephrology and Hypertension, Department of Medicine, Mayo Clinic, 
      Rochester, Minnesota, USA.
LA  - eng
PT  - Journal Article
DEP - 20240426
PL  - Switzerland
TA  - Blood Purif
JT  - Blood purification
JID - 8402040
SB  - IM
MH  - Humans
MH  - *Acute Kidney Injury/therapy
MH  - *Patient Education as Topic
MH  - *Continuous Renal Replacement Therapy/methods
MH  - Surveys and Questionnaires
MH  - Male
OTO - NOTNLM
OT  - Acute kidney injury
OT  - ChatGPT
OT  - Continuous renal replacement therapy
OT  - Linguistic analysis
OT  - Patient education
EDAT- 2024/04/29 00:59
MHDA- 2024/09/13 00:46
CRDT- 2024/04/28 18:22
PHST- 2024/01/26 00:00 [received]
PHST- 2024/04/19 00:00 [accepted]
PHST- 2024/09/13 00:46 [medline]
PHST- 2024/04/29 00:59 [pubmed]
PHST- 2024/04/28 18:22 [entrez]
AID - 000539065 [pii]
AID - 10.1159/000539065 [doi]
PST - ppublish
SO  - Blood Purif. 2024;53(9):725-731. doi: 10.1159/000539065. Epub 2024 Apr 26.

PMID- 38373482
OWN - NLM
STAT- MEDLINE
DCOM- 20240603
LR  - 20240603
IS  - 2173-5786 (Electronic)
IS  - 2173-5786 (Linking)
VI  - 48
IP  - 5
DP  - 2024 Jun
TI  - Quality of information about urologic pathology in English and Spanish from 
      ChatGPT, BARD, and Copilot.
PG  - 398-403
LID - S2173-5786(24)00016-7 [pii]
LID - 10.1016/j.acuroe.2024.02.009 [doi]
AB  - INTRODUCTION AND OBJECTIVE: Generative artificial intelligence makes it possible 
      to ask about medical pathologies in dialog boxes. Our objective was to analyze 
      the quality of information about the most common urological pathologies provided 
      by ChatGPT (OpenIA), BARD (Google), and Copilot (Microsoft). METHODS: We analyzed 
      information on the following pathologies and their treatments as provided by AI: 
      prostate cancer, kidney cancer, bladder cancer, urinary lithiasis, and benign 
      prostatic hypertrophy (BPH). Questions in English and Spanish were posed in 
      dialog boxes; the answers were collected and analyzed with DISCERN questionnaires 
      and the overall appropriateness of the response. Surgical procedures were 
      performed with an informed consent questionnaire. RESULTS: The responses from the 
      three chatbots explained the pathology, detailed risk factors, and described 
      treatments. The difference is that BARD and Copilot provide external information 
      citations, which ChatGPT does not. The highest DISCERN scores, in absolute 
      numbers, were obtained in Copilot; however, on the appropriacy scale it was noted 
      that their responses were not the most appropriate. The best surgical treatment 
      scores were obtained by BARD, followed by ChatGPT, and finally Copilot. 
      CONCLUSIONS: The answers obtained from generative AI on urological diseases 
      depended on the formulation of the question. The information provided had 
      significant biases, depending on pathology, language, and above all, the dialog 
      box consulted.
CI  - Copyright © 2024 AEU. Published by Elsevier España, S.L.U. All rights reserved.
FAU - Szczesniewski, J J
AU  - Szczesniewski JJ
AD  - Servicio de Urología, Hospital Universitario de Getafe, Getafe, Madrid, Spain; 
      Departamento de Cirugía, Facultad de Medicina, Universidad de Salamanca, 
      Salamanca, Spain. Electronic address: Juliusz.szcz@gmail.com.
FAU - Ramos Alba, A
AU  - Ramos Alba A
AD  - DXC Technology, Las Rozas, Madrid, Spain; Departamento de Economía Aplicada I e 
      Historia e Instituciones Económicas, Universidad Rey Juan Carlos, Madrid, Spain.
FAU - Rodríguez Castro, P M
AU  - Rodríguez Castro PM
AD  - Servicio de Urología, Hospital Universitario de Getafe, Getafe, Madrid, Spain.
FAU - Lorenzo Gómez, M F
AU  - Lorenzo Gómez MF
AD  - Departamento de Cirugía, Facultad de Medicina, Universidad de Salamanca, 
      Salamanca, Spain; Servicio de Urología, Hospital Universitario de Salamanca, 
      Salamanca, Spain.
FAU - Sainz González, J
AU  - Sainz González J
AD  - Departamento de Economía Aplicada I e Historia e Instituciones Económicas, 
      Universidad Rey Juan Carlos, Madrid, Spain.
FAU - Llanes González, L
AU  - Llanes González L
AD  - Servicio de Urología, Hospital Universitario de Getafe, Getafe, Madrid, Spain; 
      Universidad Francisco de Vitoria, Madrid, Spain.
LA  - eng
LA  - spa
PT  - Journal Article
DEP - 20240217
PL  - Spain
TA  - Actas Urol Esp (Engl Ed)
JT  - Actas urologicas espanolas
JID - 101771154
SB  - IM
MH  - Humans
MH  - *Language
MH  - *Urologic Diseases
MH  - Artificial Intelligence
MH  - Surveys and Questionnaires
MH  - Internet
OTO - NOTNLM
OT  - Artificial intelligence
OT  - BARD
OT  - Calidad de información
OT  - ChatGPT
OT  - Copilot
OT  - Information quality
OT  - Inteligencia artificial
OT  - Urology
OT  - Urología
EDAT- 2024/02/20 11:50
MHDA- 2024/06/04 00:45
CRDT- 2024/02/19 19:12
PHST- 2023/10/30 00:00 [received]
PHST- 2023/12/26 00:00 [revised]
PHST- 2023/12/27 00:00 [accepted]
PHST- 2024/06/04 00:45 [medline]
PHST- 2024/02/20 11:50 [pubmed]
PHST- 2024/02/19 19:12 [entrez]
AID - S2173-5786(24)00016-7 [pii]
AID - 10.1016/j.acuroe.2024.02.009 [doi]
PST - ppublish
SO  - Actas Urol Esp (Engl Ed). 2024 Jun;48(5):398-403. doi: 
      10.1016/j.acuroe.2024.02.009. Epub 2024 Feb 17.

PMID- 38150261
OWN - NLM
STAT- MEDLINE
DCOM- 20240117
LR  - 20240628
IS  - 1538-3598 (Electronic)
IS  - 0098-7484 (Print)
IS  - 0098-7484 (Linking)
VI  - 331
IP  - 3
DP  - 2024 Jan 16
TI  - Affiliation Bias in Peer Review of Abstracts by a Large Language Model.
PG  - 252-253
LID - 10.1001/jama.2023.24641 [doi]
FAU - von Wedel, Dario
AU  - von Wedel D
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Beth Israel Deaconess 
      Medical Center, Boston, Massachusetts.
FAU - Schmitt, Rico A
AU  - Schmitt RA
AD  - Berlin Exchange Medicine e.V., Charité-Universitätsmedizin Berlin, Berlin, 
      Germany.
FAU - Thiele, Moritz
AU  - Thiele M
AD  - Berlin Exchange Medicine e.V., Charité-Universitätsmedizin Berlin, Berlin, 
      Germany.
FAU - Leuner, Raphael
AU  - Leuner R
AD  - Berlin Exchange Medicine e.V., Charité-Universitätsmedizin Berlin, Berlin, 
      Germany.
FAU - Shay, Denys
AU  - Shay D
AD  - Department of Epidemiology, Harvard T.H. Chan School of Public Health, Boston, 
      Massachusetts.
FAU - Redaelli, Simone
AU  - Redaelli S
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Beth Israel Deaconess 
      Medical Center, Boston, Massachusetts.
FAU - Schaefer, Maximilian S
AU  - Schaefer MS
AD  - Department of Anesthesia, Critical Care and Pain Medicine, Beth Israel Deaconess 
      Medical Center, Boston, Massachusetts.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - United States
TA  - JAMA
JT  - JAMA
JID - 7501160
SB  - IM
CIN - JAMA. 2024 Apr 9;331(14):1234-1235. doi: 10.1001/jama.2024.3520. PMID: 38592392
MH  - *Language
MH  - Peer Group
MH  - *Peer Review
MH  - *Publication Bias
MH  - Abstracting and Indexing
MH  - Models, Theoretical
PMC - PMC10753437
OAB - This study assesses affiliation bias in peer review of medical abstracts by a 
      commonly used large language model.
OABL- eng
COIS- Conflict of Interest Disclosures: Dr Schaefer reported receiving speaker fees, 
      travel reimbursement, and grants from Mindray Medical and receiving grants from 
      Fisher & Paykel and Merck & Co outside the submitted work. No other disclosures 
      were reported.
EDAT- 2023/12/27 12:42
MHDA- 2024/01/17 06:43
PMCR- 2024/06/27
CRDT- 2023/12/27 11:35
PHST- 2024/01/17 06:43 [medline]
PHST- 2023/12/27 12:42 [pubmed]
PHST- 2023/12/27 11:35 [entrez]
PHST- 2024/06/27 00:00 [pmc-release]
AID - 2813511 [pii]
AID - jld230083 [pii]
AID - 10.1001/jama.2023.24641 [doi]
PST - ppublish
SO  - JAMA. 2024 Jan 16;331(3):252-253. doi: 10.1001/jama.2023.24641.

PMID- 37902165
OWN - NLM
STAT- MEDLINE
DCOM- 20240315
LR  - 20240315
IS  - 1365-2648 (Electronic)
IS  - 0309-2402 (Linking)
VI  - 80
IP  - 4
DP  - 2024 Apr
TI  - Undergraduate nursing students challenge misconceptions towards men in nursing: A 
      mixed-method study.
PG  - 1638-1651
LID - 10.1111/jan.15914 [doi]
AB  - AIMS: To examine misconceptions towards men in nursing from the perspective of 
      undergraduate nursing students. Specifically, this study sought to explore 
      contributing factors of misconceptions and attributions of the success of men in 
      nursing. DESIGN: A convergent parallel mixed-method study. METHODS: A national 
      survey was conducted (July-September 2021). The quantitative data included 
      demographics and responses to the Gender Misconceptions of Men in Nursing 
      (GEMINI) scale. The qualitative data included responses to a provocative 
      statement related to characteristics of men and their career in nursing. The 
      GRAMMS guideline was used in reporting. RESULTS: Undergraduate nursing students 
      (n = 1245) from 16 Australian schools of nursing responded to the survey. 
      Quantitative analysis demonstrated that most students (96%) did not have 
      misconceptions about men in nursing. Those who did were more likely to be men, 
      born overseas, not in health-related employment and did not have nursing as their 
      first choice. Four broad overarching main themes were generated in response to 
      the statement that suggested men do not have the right attributes for nursing: 
      (1) 'This is a very misandristic viewpoint'; (2) 'Compassion and intelligence are 
      distributed in men and women equally'; (3) 'Men bring a different quality to 
      nursing' (4) 'Anyone can be whatever they want to be'. CONCLUSION: Overall, 
      nursing students did not have misconceptions about men in nursing, despite 
      experiencing ongoing social stigma regarding archaic gender norms. The findings 
      from this study indicate that the next-generation nurses were championing to 
      challenge the gender stereotype and support the needs of a gender diverse 
      society. IMPACT: Attitudes and misconceptions that elicit gender inequalities 
      must be addressed with comprehensive strategies and de-gendered language and 
      imagery within the profession, schools, workplaces and the media. Shifting 
      culture and attitudes towards inclusion, values the diversity in the workforce 
      and supports healthy workplace environments. PATIENT OR PUBLIC CONTRIBUTION: No 
      patient or public contribution.
CI  - © 2023 The Authors. Journal of Advanced Nursing published by John Wiley & Sons 
      Ltd.
FAU - Ramjan, Lucie M
AU  - Ramjan LM
AUID- ORCID: 0000-0001-7815-3005
AD  - School of Nursing and Midwifery, Western Sydney University, Penrith, New South 
      Wales, Australia.
AD  - School of Nursing, University of Wollongong, Wollongong, New South Wales, 
      Australia.
FAU - Maneze, Della
AU  - Maneze D
AD  - School of Nursing, University of Wollongong, Wollongong, New South Wales, 
      Australia.
FAU - Salamonson, Yenna
AU  - Salamonson Y
AD  - School of Nursing, University of Wollongong, Wollongong, New South Wales, 
      Australia.
FAU - Zugai, Joel
AU  - Zugai J
AD  - School of Nursing, University of Wollongong, Liverpool, New South Wales, 
      Australia.
FAU - Bail, Kasia
AU  - Bail K
AUID- ORCID: 0000-0002-4797-0042
AD  - Nursing, Faculty of Health and Ageing Research Group, University of Canberra, 
      Bruce, Australian Capital Territory, Australia.
FAU - Liu, Xian-Liang
AU  - Liu XL
AD  - College of Nursing and Midwifery, Charles Darwin University, Brisbane, Australia.
FAU - Montayre, Jed
AU  - Montayre J
AUID- ORCID: 0000-0002-2435-8061
AD  - School of Nursing, The Hong Kong Polytechnic University, Hung Hom, Hong Kong SAR.
LA  - eng
PT  - Journal Article
DEP - 20231030
PL  - England
TA  - J Adv Nurs
JT  - Journal of advanced nursing
JID - 7609811
SB  - IM
MH  - Male
MH  - Humans
MH  - Female
MH  - *Education, Nursing, Baccalaureate/methods
MH  - *Students, Nursing
MH  - Australia
MH  - Attitude
MH  - Stereotyping
OTO - NOTNLM
OT  - gender bias
OT  - gender equality
OT  - gender misconception
OT  - gender role
OT  - men in nursing
OT  - nursing student
OT  - stigma
EDAT- 2023/10/30 12:43
MHDA- 2024/03/15 06:44
CRDT- 2023/10/30 07:43
PHST- 2023/09/27 00:00 [revised]
PHST- 2023/06/12 00:00 [received]
PHST- 2023/10/16 00:00 [accepted]
PHST- 2024/03/15 06:44 [medline]
PHST- 2023/10/30 12:43 [pubmed]
PHST- 2023/10/30 07:43 [entrez]
AID - 10.1111/jan.15914 [doi]
PST - ppublish
SO  - J Adv Nurs. 2024 Apr;80(4):1638-1651. doi: 10.1111/jan.15914. Epub 2023 Oct 30.

PMID- 37598934
OWN - NLM
STAT- Publisher
LR  - 20231011
IS  - 1873-6424 (Electronic)
IS  - 0269-7491 (Linking)
VI  - 336
DP  - 2023 Nov 1
TI  - Toward an interdisciplinary approach to assess the adverse health effects of 
      dust-containing polycyclic aromatic hydrocarbons (PAHs) and metal(loid)s on 
      preschool children.
PG  - 122372
LID - S0269-7491(23)01374-X [pii]
LID - 10.1016/j.envpol.2023.122372 [doi]
AB  - Settled dust can function as a pollutant sink for compounds, such as polycyclic 
      aromatic hydrocarbons (PAHs) and metal(loid)s (MMs), which may lead to health 
      issues. Thus, dust represents a hazard specifically for young children, because 
      of their vulnerability and hand-to-mouth behavior favoring dust ingestion. The 
      aim of the present study was to explore the influence of the season and the 
      microenvironment on the concentrations of 15 PAHs and 17 MMs in indoor and 
      outdoor settled dust in three preschools (suburban, urban, and industrial). 
      Second, the potential sources and health risks among children associated with 
      dust PAHs and MMs were assessed. Third, domestic factors (risk perception, 
      knowledge and parental style) were described to explore protective parental 
      behaviors toward dust hazards. The suburban preschool had the lowest 
      concentrations of dust PAHs and MMs, while the industrial and urban preschools 
      had higher but similar concentrations. Seasonal tendencies were not clearly 
      observed. Indoor dusts reflected the outdoor environment, even if specific indoor 
      sources were noted. Source analysis indicated mainly vehicular emissions, 
      material release, and pyrogenic or industrial sources. The non-cancer health 
      risks were non-existent, but potential cancer health risks (between 1.10(-6) and 
      1.10(-4)) occurred at all sampling locations. Notably, the highest cancer risk 
      was observed in a playground area (>1.10(-4)) and material release should be 
      further addressed. Whereas we assessed higher risk indoors, parents perceived a 
      higher risk in the open-air environment and at the preschool than at home. They 
      also perceived a lower risk for their own children, revealing an optimism bias, 
      which reduces parental anxiety.
CI  - Copyright © 2023 Elsevier Ltd. All rights reserved.
FAU - Castel, Rebecca
AU  - Castel R
AD  - Aix Marseille Univ, CNRS, LCE, Laboratoire Chimie Environnement, FR ECCOREV, 
      ITEM, Aix-en-Provence, France; Aix Marseille Univ, Avignon Univ, CNRS, IRD, IMBE, 
      Institut Méditerranéen de Biodiversité et Ecologie, FR ECCOREV, ITEM, Marseille, 
      France.
FAU - Bertoldo, Raquel
AU  - Bertoldo R
AD  - Aix Marseille Univ, LPS, Laboratoire de Psychologie Sociale, FR ECCOREV, ITEM, 
      Aix-en-Provence, France.
FAU - Lebarillier, Stéphanie
AU  - Lebarillier S
AD  - Aix Marseille Univ, CNRS, LCE, Laboratoire Chimie Environnement, FR ECCOREV, 
      ITEM, Aix-en-Provence, France.
FAU - Noack, Yves
AU  - Noack Y
AD  - Aix Marseille Univ, CNRS, IRD, INRAE, CEREGE, Centre Européen de Recherche et 
      d'Enseignement des Géosciences de l'Environnement, FR ECCOREV, ITEM, 
      Aix-en-Provence, France.
FAU - Orsière, Thierry
AU  - Orsière T
AD  - Aix Marseille Univ, Avignon Univ, CNRS, IRD, IMBE, Institut Méditerranéen de 
      Biodiversité et Ecologie, FR ECCOREV, ITEM, Marseille, France.
FAU - Malleret, Laure
AU  - Malleret L
AD  - Aix Marseille Univ, CNRS, LCE, Laboratoire Chimie Environnement, FR ECCOREV, 
      ITEM, Aix-en-Provence, France. Electronic address: laure.malleret@univ-amu.fr.
LA  - eng
PT  - Journal Article
DEP - 20230818
PL  - England
TA  - Environ Pollut
JT  - Environmental pollution (Barking, Essex : 1987)
JID - 8804476
SB  - IM
OTO - NOTNLM
OT  - Children health risk
OT  - Indoor and outdoor dust
OT  - Ingestion exposure pathway
OT  - Positive matrix factorization
OT  - Risk knowledge and perception
OT  - Settled dust
COIS- Declaration of competing interest The authors declare that they have no known 
      competing financial interests or personal relationships that could have appeared 
      to influence the work reported in this paper.
EDAT- 2023/08/21 00:41
MHDA- 2023/08/21 00:41
CRDT- 2023/08/20 19:27
PHST- 2023/04/19 00:00 [received]
PHST- 2023/08/10 00:00 [revised]
PHST- 2023/08/11 00:00 [accepted]
PHST- 2023/08/21 00:41 [pubmed]
PHST- 2023/08/21 00:41 [medline]
PHST- 2023/08/20 19:27 [entrez]
AID - S0269-7491(23)01374-X [pii]
AID - 10.1016/j.envpol.2023.122372 [doi]
PST - ppublish
SO  - Environ Pollut. 2023 Nov 1;336:122372. doi: 10.1016/j.envpol.2023.122372. Epub 
      2023 Aug 18.

PMID- 35810499
OWN - NLM
STAT- MEDLINE
DCOM- 20220830
LR  - 20220927
IS  - 1973-8102 (Electronic)
IS  - 0010-9452 (Linking)
VI  - 154
DP  - 2022 Sep
TI  - A case of neglect.
PG  - 254-258
LID - S0010-9452(22)00171-X [pii]
LID - 10.1016/j.cortex.2022.06.003 [doi]
AB  - In 1875 William Andrew Johnson, who had been formerly enslaved by Andrew Johnson 
      and who subsequently served as his valet after being emancipated, was present 
      when the former president suffered his fatal stroke. William's description of his 
      deficits, as told decades later to journalist Ernie Pyle, appears to represent 
      one of the earliest known cases of asomatognosia. The limited description of the 
      symptoms provides a backdrop for a discussion of the evolution of knowledge 
      regarding disorders of body awareness. This case also highlights the importance 
      of caregivers as sources of clinical information and serves as a cautionary tale 
      regarding the risk of marginalizing them due to cultural bias.
CI  - Copyright © 2022 Elsevier Ltd. All rights reserved.
FAU - Boren, Rance A
AU  - Boren RA
AD  - CRB Medical Associates, Brownwood, TX, USA. Electronic address: crbmed@aol.com.
LA  - eng
PT  - Case Reports
PT  - Journal Article
DEP - 20220614
PL  - Italy
TA  - Cortex
JT  - Cortex; a journal devoted to the study of the nervous system and behavior
JID - 0100725
SB  - IM
MH  - Humans
MH  - *Stroke
OTO - NOTNLM
OT  - Andrew Johnson
OT  - Asomatognosia
OT  - Historical neurology
OT  - Stroke
OT  - William Andrew Johnson
EDAT- 2022/07/11 06:00
MHDA- 2022/08/31 06:00
CRDT- 2022/07/10 18:08
PHST- 2022/02/21 00:00 [received]
PHST- 2022/05/28 00:00 [revised]
PHST- 2022/06/02 00:00 [accepted]
PHST- 2022/07/11 06:00 [pubmed]
PHST- 2022/08/31 06:00 [medline]
PHST- 2022/07/10 18:08 [entrez]
AID - S0010-9452(22)00171-X [pii]
AID - 10.1016/j.cortex.2022.06.003 [doi]
PST - ppublish
SO  - Cortex. 2022 Sep;154:254-258. doi: 10.1016/j.cortex.2022.06.003. Epub 2022 Jun 
      14.

PMID- 35773848
OWN - NLM
STAT- MEDLINE
DCOM- 20220704
LR  - 20220705
IS  - 1879-8365 (Electronic)
IS  - 0926-9630 (Linking)
VI  - 295
DP  - 2022 Jun 29
TI  - Health-Related Content in Transformer-Based Deep Neural Network Language Models: 
      Exploring Cross-Linguistic Syntactic Bias.
PG  - 221-225
LID - 10.3233/SHTI220702 [doi]
AB  - This paper explores a methodology for bias quantification in transformer-based 
      deep neural network language models for Chinese, English, and French. When 
      queried with health-related mythbusters on COVID-19, we observe a bias that is 
      not of a semantic/encyclopaedical knowledge nature, but rather a syntactic one, 
      as predicted by theoretical insights of structural complexity. Our results 
      highlight the need for the creation of health-communication corpora as training 
      sets for deep learning.
FAU - Samo, Giuseppe
AU  - Samo G
AD  - Beijing Language and Culture University.
FAU - Bonan, Caterina
AU  - Bonan C
AD  - University of Cambridge.
FAU - Si, Fuzhen
AU  - Si F
AD  - Beijing Language and Culture University.
LA  - eng
PT  - Journal Article
PL  - Netherlands
TA  - Stud Health Technol Inform
JT  - Studies in health technology and informatics
JID - 9214582
MH  - *COVID-19
MH  - Humans
MH  - *Language
MH  - Linguistics
MH  - Neural Networks, Computer
MH  - Semantics
OTO - NOTNLM
OT  - COVID-19
OT  - Corpora
OT  - Knowledge Reproduction
OT  - Language Models
OT  - Natural Language Processing
EDAT- 2022/07/02 06:00
MHDA- 2022/07/06 06:00
CRDT- 2022/07/01 01:03
PHST- 2022/07/01 01:03 [entrez]
PHST- 2022/07/02 06:00 [pubmed]
PHST- 2022/07/06 06:00 [medline]
AID - SHTI220702 [pii]
AID - 10.3233/SHTI220702 [doi]
PST - ppublish
SO  - Stud Health Technol Inform. 2022 Jun 29;295:221-225. doi: 10.3233/SHTI220702.

PMID- 40127267
OWN - NLM
STAT- MEDLINE
DCOM- 20250324
LR  - 20250324
IS  - 1091-6490 (Electronic)
IS  - 0027-8424 (Linking)
VI  - 122
IP  - 13
DP  - 2025 Apr
TI  - The narrow search effect and how broadening search promotes belief updating.
PG  - e2408175122
LID - 10.1073/pnas.2408175122 [doi]
AB  - Information search platforms, from Google to AI-assisted search engines, have 
      transformed information access but may fail to promote a shared factual 
      foundation. We demonstrate that the combination of users' prior beliefs 
      influencing their search terms and the narrow scope of search algorithms can 
      limit belief updating from search. We test this "narrow search effect" across 21 
      studies (14 preregistered) using various topics (e.g., health, financial, 
      societal, political) and platforms (e.g., Google, ChatGPT, AI-powered Bing, our 
      custom-designed search engine and AI chatbot interfaces). We then test user-based 
      and algorithm-based interventions to counter the "narrow search effect" and 
      promote belief updating. Studies 1 to 5 show that users' prior beliefs influence 
      the direction of the search terms, thereby generating narrow search results that 
      limit belief updating. This effect persists across various domains (e.g., beliefs 
      related to coronavirus, nuclear energy, gas prices, crime rates, bitcoin, 
      caffeine, and general food or beverage health concerns; Studies 1a to 1b, 2a to 
      2g, 3, 4), platforms (e.g., Google-Studies 1a to 1b, 2a to 2g, 4, 5; ChatGPT, 
      Study 3), and extends to consequential choices (Study 5). Studies 6 and 7 
      demonstrate the limited efficacy of prompting users to correct for the impact of 
      narrow searches on their beliefs themselves. Using our custom-designed search 
      engine and AI chatbot interfaces, Studies 8 and 9 show that modifying algorithms 
      to provide broader results can encourage belief updating. These findings 
      highlight the need for a behaviorally informed approach to the design of search 
      algorithms.
FAU - Leung, Eugina
AU  - Leung E
AUID- ORCID: 0000-0002-6486-4209
AD  - Marketing, Freeman School of Business, Tulane University, New Orleans, LA 70118.
FAU - Urminsky, Oleg
AU  - Urminsky O
AUID- ORCID: 0000-0003-4390-386X
AD  - Marketing, Booth School of Business, University of Chicago, Chicago, IL 60637.
LA  - eng
PT  - Journal Article
DEP - 20250324
PL  - United States
TA  - Proc Natl Acad Sci U S A
JT  - Proceedings of the National Academy of Sciences of the United States of America
JID - 7505876
SB  - IM
MH  - Humans
MH  - *Search Engine
MH  - *Algorithms
MH  - Artificial Intelligence
MH  - Information Seeking Behavior
OTO - NOTNLM
OT  - algorithmic search
OT  - artificial intelligence
OT  - belief updating
OT  - confirmation bias
COIS- Competing interests statement:The authors declare no competing interest.
EDAT- 2025/03/24 18:30
MHDA- 2025/03/24 18:31
CRDT- 2025/03/24 15:22
PHST- 2025/03/24 18:31 [medline]
PHST- 2025/03/24 18:30 [pubmed]
PHST- 2025/03/24 15:22 [entrez]
AID - 10.1073/pnas.2408175122 [doi]
PST - ppublish
SO  - Proc Natl Acad Sci U S A. 2025 Apr;122(13):e2408175122. doi: 
      10.1073/pnas.2408175122. Epub 2025 Mar 24.

PMID- 37438101
OWN - NLM
STAT- MEDLINE
DCOM- 20231221
LR  - 20231221
IS  - 1759-8486 (Electronic)
IS  - 1759-8478 (Linking)
VI  - 16
IP  - 1
DP  - 2023 Dec 19
TI  - The perils and promises of generative artificial intelligence in 
      neurointerventional surgery.
PG  - 4-7
LID - 10.1136/jnis-2023-020353 [doi]
AB  - Generative artificial intelligence (AI) holds great promise in 
      neurointerventional surgery by providing clinicians with powerful tools for 
      improving surgical precision, accuracy of diagnoses, and treatment planning. 
      However, potential perils include biases or inaccuracies in the data used to 
      train the algorithms, over-reliance on generative AI without human oversight, 
      patient privacy concerns, and ethical implications of using AI in medical 
      decision-making. Careful regulation and oversight are needed to ensure that the 
      promises of generative AI in neurointerventional surgery are realized while 
      minimizing its potential perils.[ChatGPT authored summary using the prompt "In 
      one paragraph summarize the promises and perils of generative AI in 
      neurointerventional surgery".].
CI  - © Author(s) (or their employer(s)) 2024. No commercial re-use. See rights and 
      permissions. Published by BMJ.
FAU - Ray, Tyler R
AU  - Ray TR
AD  - Department of Mechanical Engineering, University of Hawaii at Mānoa College of 
      Engineering, Honolulu, Hawaii, USA.
FAU - Kellogg, Ryan T
AU  - Kellogg RT
AUID- ORCID: 0000-0001-6491-5443
AD  - Department of Neurosurgery, University of Virginia, Charlottesville, Virginia, 
      USA.
FAU - Fargen, Kyle M
AU  - Fargen KM
AUID- ORCID: 0000-0001-8979-1993
AD  - Department of Neurological Surgery and Radiology, Wake Forest University, 
      Winston-Salem, North Carolina, USA.
FAU - Hui, Ferdinand
AU  - Hui F
AUID- ORCID: 0000-0003-3759-7886
AD  - Neurointerventional Surgery, Queen's Medical Center Neuroscience Institute, 
      Honolulu, Hawaii, USA.
FAU - Vargas, Jan
AU  - Vargas J
AUID- ORCID: 0000-0001-7164-1479
AD  - Division of Neurosurgery, Prisma Health Upstate, Greenville, South Carolina, USA 
      jvargas.machaj@prismahealth.org.
LA  - eng
PT  - Journal Article
DEP - 20231219
PL  - England
TA  - J Neurointerv Surg
JT  - Journal of neurointerventional surgery
JID - 101517079
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - *Algorithms
MH  - Clinical Decision-Making
OTO - NOTNLM
OT  - Economics
OT  - Political
OT  - Standards
OT  - Technology
COIS- Competing interests: RTK and JV have stock and are paid consultants for Viz.AI. 
      KF serves on the editorial board of JNIS.
EDAT- 2023/07/13 01:06
MHDA- 2023/12/21 06:43
CRDT- 2023/07/12 21:23
PHST- 2023/06/26 00:00 [accepted]
PHST- 2023/12/21 06:43 [medline]
PHST- 2023/07/13 01:06 [pubmed]
PHST- 2023/07/12 21:23 [entrez]
AID - jnis-2023-020353 [pii]
AID - 10.1136/jnis-2023-020353 [doi]
PST - epublish
SO  - J Neurointerv Surg. 2023 Dec 19;16(1):4-7. doi: 10.1136/jnis-2023-020353.

PMID- 37310135
OWN - NLM
STAT- MEDLINE
DCOM- 20230809
LR  - 20240306
IS  - 1744-4292 (Electronic)
IS  - 1744-4292 (Linking)
VI  - 19
IP  - 8
DP  - 2023 Aug 8
TI  - Updated benchmarking of variant effect predictors using deep mutational scanning.
PG  - e11474
LID - 10.15252/msb.202211474 [doi]
LID - e11474
AB  - The assessment of variant effect predictor (VEP) performance is fraught with 
      biases introduced by benchmarking against clinical observations. In this study, 
      building on our previous work, we use independently generated measurements of 
      protein function from deep mutational scanning (DMS) experiments for 26 human 
      proteins to benchmark 55 different VEPs, while introducing minimal data 
      circularity. Many top-performing VEPs are unsupervised methods including EVE, 
      DeepSequence and ESM-1v, a protein language model that ranked first overall. 
      However, the strong performance of recent supervised VEPs, in particular VARITY, 
      shows that developers are taking data circularity and bias issues seriously. We 
      also assess the performance of DMS and unsupervised VEPs for discriminating 
      between known pathogenic and putatively benign missense variants. Our findings 
      are mixed, demonstrating that some DMS datasets perform exceptionally at variant 
      classification, while others are poor. Notably, we observe a striking correlation 
      between VEP agreement with DMS data and performance in identifying clinically 
      relevant variants, strongly supporting the validity of our rankings and the 
      utility of DMS for independent benchmarking.
CI  - © 2023 The Authors. Published under the terms of the CC BY 4.0 license.
FAU - Livesey, Benjamin J
AU  - Livesey BJ
AUID- ORCID: 0000-0001-6866-1452
AD  - MRC Human Genetics Unit, Institute of Genetics and Cancer, University of 
      Edinburgh, Edinburgh, UK.
FAU - Marsh, Joseph A
AU  - Marsh JA
AUID- ORCID: 0000-0003-4132-0628
AD  - MRC Human Genetics Unit, Institute of Genetics and Cancer, University of 
      Edinburgh, Edinburgh, UK.
LA  - eng
SI  - figshare/10.6084/m9.figshare.21581823.v1
GR  - MC_UU_00035/9/MRC_/Medical Research Council/United Kingdom
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20230613
PL  - Germany
TA  - Mol Syst Biol
JT  - Molecular systems biology
JID - 101235389
RN  - 0 (Proteins)
SB  - IM
MH  - Humans
MH  - *Benchmarking
MH  - Mutation
MH  - *Mutation, Missense
MH  - Proteins/genetics
PMC - PMC10407742
OTO - NOTNLM
OT  - Benchmark
OT  - Circularity
OT  - DMS
OT  - MAVE
OT  - VEP
COIS- The authors declare that they have no conflict of interest.
EDAT- 2023/06/13 13:12
MHDA- 2023/08/09 06:43
PMCR- 2023/06/13
CRDT- 2023/06/13 09:12
PHST- 2023/05/30 00:00 [revised]
PHST- 2022/11/23 00:00 [received]
PHST- 2023/06/02 00:00 [accepted]
PHST- 2023/08/09 06:43 [medline]
PHST- 2023/06/13 13:12 [pubmed]
PHST- 2023/06/13 09:12 [entrez]
PHST- 2023/06/13 00:00 [pmc-release]
AID - MSB202211474 [pii]
AID - 10.15252/msb.202211474 [doi]
PST - ppublish
SO  - Mol Syst Biol. 2023 Aug 8;19(8):e11474. doi: 10.15252/msb.202211474. Epub 2023 
      Jun 13.

PMID- 36563029
OWN - NLM
STAT- MEDLINE
DCOM- 20221227
LR  - 20230117
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 24
IP  - 12
DP  - 2022 Dec 23
TI  - Predicting Publication of Clinical Trials Using Structured and Unstructured Data: 
      Model Development and Validation Study.
PG  - e38859
LID - 10.2196/38859 [doi]
LID - e38859
AB  - BACKGROUND: Publication of registered clinical trials is a critical step in the 
      timely dissemination of trial findings. However, a significant proportion of 
      completed clinical trials are never published, motivating the need to analyze the 
      factors behind success or failure to publish. This could inform study design, 
      help regulatory decision-making, and improve resource allocation. It could also 
      enhance our understanding of bias in the publication of trials and publication 
      trends based on the research direction or strength of the findings. Although the 
      publication of clinical trials has been addressed in several descriptive studies 
      at an aggregate level, there is a lack of research on the predictive analysis of 
      a trial's publishability given an individual (planned) clinical trial 
      description. OBJECTIVE: We aimed to conduct a study that combined structured and 
      unstructured features relevant to publication status in a single predictive 
      approach. Established natural language processing techniques as well as recent 
      pretrained language models enabled us to incorporate information from the textual 
      descriptions of clinical trials into a machine learning approach. We were 
      particularly interested in whether and which textual features could improve the 
      classification accuracy for publication outcomes. METHODS: In this study, we used 
      metadata from ClinicalTrials.gov (a registry of clinical trials) and MEDLINE (a 
      database of academic journal articles) to build a data set of clinical trials 
      (N=76,950) that contained the description of a registered trial and its 
      publication outcome (27,702/76,950, 36% published and 49,248/76,950, 64% 
      unpublished). This is the largest data set of its kind, which we released as part 
      of this work. The publication outcome in the data set was identified from MEDLINE 
      based on clinical trial identifiers. We carried out a descriptive analysis and 
      predicted the publication outcome using 2 approaches: a neural network with a 
      large domain-specific language model and a random forest classifier using a 
      weighted bag-of-words representation of text. RESULTS: First, our analysis of the 
      newly created data set corroborates several findings from the existing literature 
      regarding attributes associated with a higher publication rate. Second, a crucial 
      observation from our predictive modeling was that the addition of textual 
      features (eg, eligibility criteria) offers consistent improvements over using 
      only structured data (F(1)-score=0.62-0.64 vs F(1)-score=0.61 without textual 
      features). Both pretrained language models and more basic word-based 
      representations provide high-utility text representations, with no significant 
      empirical difference between the two. CONCLUSIONS: Different factors affect the 
      publication of a registered clinical trial. Our approach to predictive modeling 
      combines heterogeneous features, both structured and unstructured. We show that 
      methods from natural language processing can provide effective textual features 
      to enable more accurate prediction of publication success, which has not been 
      explored for this task previously.
CI  - ©Siyang Wang, Simon Šuster, Timothy Baldwin, Karin Verspoor. Originally published 
      in the Journal of Medical Internet Research (https://www.jmir.org), 23.12.2022.
FAU - Wang, Siyang
AU  - Wang S
AUID- ORCID: 0000-0001-9412-9865
AD  - School of Computing and Information Systems, University of Melbourne, Melbourne, 
      Australia.
FAU - Šuster, Simon
AU  - Šuster S
AUID- ORCID: 0000-0002-8817-8545
AD  - School of Computing and Information Systems, University of Melbourne, Melbourne, 
      Australia.
FAU - Baldwin, Timothy
AU  - Baldwin T
AUID- ORCID: 0000-0003-4525-6950
AD  - School of Computing and Information Systems, University of Melbourne, Melbourne, 
      Australia.
AD  - Mohamed bin Zayed University of Artificial Intelligence, Abu Dhabi, United Arab 
      Emirates.
FAU - Verspoor, Karin
AU  - Verspoor K
AUID- ORCID: 0000-0002-8661-1544
AD  - School of Computing Technologies, RMIT University, Melbourne, Australia.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
DEP - 20221223
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - Humans
MH  - *Research Design
MH  - *Language
PMC - PMC9823568
OTO - NOTNLM
OT  - clinical trials
OT  - machine learning
OT  - natural language processing
OT  - pretrained language models
OT  - publication success
OT  - study characteristics
COIS- Conflicts of Interest: None declared.
EDAT- 2022/12/24 06:00
MHDA- 2022/12/28 06:00
PMCR- 2022/12/23
CRDT- 2022/12/23 11:52
PHST- 2022/04/19 00:00 [received]
PHST- 2022/11/16 00:00 [accepted]
PHST- 2022/10/14 00:00 [revised]
PHST- 2022/12/23 11:52 [entrez]
PHST- 2022/12/24 06:00 [pubmed]
PHST- 2022/12/28 06:00 [medline]
PHST- 2022/12/23 00:00 [pmc-release]
AID - v24i12e38859 [pii]
AID - 10.2196/38859 [doi]
PST - epublish
SO  - J Med Internet Res. 2022 Dec 23;24(12):e38859. doi: 10.2196/38859.

PMID- 35881770
OWN - NLM
STAT- MEDLINE
DCOM- 20221206
LR  - 20221206
IS  - 1839-3535 (Electronic)
IS  - 1037-6178 (Linking)
VI  - 58
IP  - 4
DP  - 2022 Aug
TI  - Development and psychometric testing of the gender misconceptions of men in 
      nursing (GEMINI) scale among nursing students.
PG  - 253-263
LID - 10.1080/10376178.2022.2107041 [doi]
AB  - BACKGROUND: Misconceptions about men in nursing may influence recruitment and 
      retention, further perpetuating the gender diversity imbalance in the nursing 
      workforce. Identifying misconceptions and implementing early intervention 
      strategies to address these deep-rooted stereotypes remain challenging but is 
      considered critical to support students who are commencing a nursing career. 
      OBJECTIVE: To develop and evaluate the psychometric properties of the 'Gender 
      Misconceptions of meN in nursIng (GEMINI) Scale. DESIGN: Cross-sectional survey. 
      METHODS: Pre-registration nursing students enrolled in undergraduate nursing 
      programmes across 16 nursing institutions in Australia were surveyed from July to 
      September 2021. The 17-item self-report GEMINI Scale measured the gender 
      misconceptions of men in nursing. RESULTS: Of the 1410 completed surveys, data 
      from 683 (45%) women were used for exploratory factor analysis showing a one 
      factor structure, while data from 727 men (47%) were used for confirmatory factor 
      analysis of the 17-item GEMINI Scale, which showed a good model fit. The scale 
      demonstrated high internal consistency (Cronbach's alpha of 0.892). Men were 
      found to have higher gender misconceptions (p < 0.001) while respondents who: (a) 
      identified nursing as their first career choice (p = 0.002); (b) were in their 
      final year of programme enrolment (p = 0.016); and (c) engaged in health-related 
      paid work (p = 0.002) had lower gender misconceptions. CONCLUSION: The GEMINI 
      Scale is a robust, valid, reliable, and easy to administer tool to assess 
      misconceptions about men in nursing, which may potentially influence academic 
      performance and retention. Identifying and addressing specific elements of 
      misconceptions could inform targeted strategies to support retention and decrease 
      attrition among these students. IMPACT STATEMENT: Genderism harms nursing, as 
      well as the men and women working in the profession. Recruitment and retention of 
      men into nursing is needed to cultivate male role models and diversify the 
      workforce, however this is impeded by negative portrayals in popular culture and 
      misconceptions entrenched in society.
FAU - Montayre, Jed
AU  - Montayre J
AUID- ORCID: 0000-0002-2435-8061
AD  - School of Nursing and Midwifery, Western Sydney University, Penrith, NSW, 
      Australia.
FAU - Alananzeh, Ibrahim
AU  - Alananzeh I
AUID- ORCID: 0000-0002-2660-0122
AD  - School of Nursing, University of Wollongong, Wollongong, Australia.
FAU - Bail, Kasia
AU  - Bail K
AUID- ORCID: 0000-0002-4797-0042
AD  - Discipline of Nursing, Ageing Research Group, University of Canberra, Canberra, 
      Australia.
FAU - Barnewall, Kate
AU  - Barnewall K
AD  - School of Nursing and Midwifery, Griffith University, Brisbane, Australia.
FAU - Beament, Tania
AU  - Beament T
AUID- ORCID: 0000-0002-9598-5601
AD  - School of Nursing and Midwifery, Edith Cowan University, Perth, Australia.
FAU - Campbell, Steve
AU  - Campbell S
AUID- ORCID: 0000-0003-4830-8488
AD  - School of Nursing, College of Health and Medicine, University of Tasmania, 
      Tasmania, Australia.
FAU - Carmody, Cathy
AU  - Carmody C
AD  - School of Nursing and Midwifery, Griffith University, Brisbane, Australia.
FAU - Chan, Alex
AU  - Chan A
AUID- ORCID: 0000-0003-2614-0178
AD  - School of Nursing, University of Wollongong, Wollongong, Australia.
FAU - Donnelly, Frank
AU  - Donnelly F
AUID- ORCID: 0000-0001-7675-9505
AD  - Adelaide Nursing School, University of Adelaide, Adelaide, Australia.
FAU - Duff, Jed
AU  - Duff J
AUID- ORCID: 0000-0003-1427-0303
AD  - Centre for Healthcare Transformation, Queensland University of Technology, 
      Brisbane, Australia.
FAU - Ferguson, Caleb
AU  - Ferguson C
AUID- ORCID: 0000-0002-2417-2216
AD  - School of Nursing, University of Wollongong, Wollongong, Australia.
FAU - Gibson, Jo
AU  - Gibson J
AUID- ORCID: 0000-0002-3217-2101
AD  - School of Nursing, Midwifery & Public Health, University of Canberra, Canberra, 
      Australia.
FAU - Harbour, Peta
AU  - Harbour P
AUID- ORCID: 0000-0003-2607-895X
AD  - School of Nursing, Midwifery and Paramedicine, Australian Catholic University, 
      Canberra, Australia.
FAU - Ireland, Colin J
AU  - Ireland CJ
AUID- ORCID: 0000-0002-7983-0255
AD  - Clinical and Health Sciences, University of South Australia, Adelaide, Australia.
FAU - Liu, Xian-Liang
AU  - Liu XL
AUID- ORCID: 0000-0002-3296-5339
AD  - College of Nursing and Midwifery, Charles Darwin University, Darwin, Australia.
FAU - Luyke, Patricia
AU  - Luyke P
AUID- ORCID: 0000-0003-0254-0468
AD  - School of Nursing and Midwifery, University of Southern Queensland, Toowoomba, 
      Australia.
FAU - Maneze, Della
AU  - Maneze D
AUID- ORCID: 0000-0001-6475-8804
AD  - School of Nursing and Midwifery, Western Sydney University, Penrith, NSW, 
      Australia.
FAU - McDonall, Jo
AU  - McDonall J
AUID- ORCID: 0000-0001-6696-6316
AD  - School of Nursing and Midwifery, Deakin University, Geelong, Australia.
FAU - McTier, Lauren
AU  - McTier L
AUID- ORCID: 0000-0003-4847-8380
AD  - School of Nursing and Midwifery, Deakin University, Geelong, Australia.
FAU - Mulquiney, Tameeka
AU  - Mulquiney T
AD  - School of Nursing, Paramedicine and Healthcare Sciences, Charles Sturt 
      University, Thurgoona, NSW, Australia.
FAU - O'Brien, Jane
AU  - O'Brien J
AUID- ORCID: 0000-0002-6504-8422
AD  - School of Nursing, College of Health and Medicine, University of Tasmania, 
      Tasmania, Australia.
FAU - Pelentsov, Lemuel J
AU  - Pelentsov LJ
AUID- ORCID: 0000-0001-8108-491X
AD  - Clinical and Health Sciences, University of South Australia, Adelaide, Australia.
FAU - Ramjan, Lucie M
AU  - Ramjan LM
AUID- ORCID: 0000-0001-7815-3005
AD  - School of Nursing and Midwifery, Western Sydney University, Penrith, NSW, 
      Australia.
FAU - Reedy, Natasha
AU  - Reedy N
AUID- ORCID: 0000-0003-3143-5173
AD  - School of Nursing and Midwifery, University of Southern Queensland, Toowoomba, 
      Australia.
FAU - Richards, Gina M
AU  - Richards GM
AUID- ORCID: 0000-0001-8670-0849
AD  - School of Nursing and Midwifery, Edith Cowan University, Perth, Australia.
FAU - Roche, Michael A
AU  - Roche MA
AUID- ORCID: 0000-0002-3831-537X
AD  - Faculty of Health, University of Canberra, Canberra, Australia.
AD  - School of Nursing and Midwifery, University of Technology Sydney, Sydney, 
      Australia.
FAU - Smith, Brandon W
AU  - Smith BW
AUID- ORCID: 0000-0001-5441-6173
AD  - School of Nursing and Midwifery, Western Sydney University, Penrith, NSW, 
      Australia.
FAU - Tan, Jing-Yu Benjamin
AU  - Tan JB
AUID- ORCID: 0000-0002-1609-6890
AD  - College of Nursing and Midwifery, Charles Darwin University, Darwin, Australia.
FAU - Theobald, Karen A
AU  - Theobald KA
AUID- ORCID: 0000-0002-2880-1411
AD  - School of Nursing, Queensland University of Technology, Brisbane, Australia.
FAU - Tori, Kathleen E
AU  - Tori KE
AUID- ORCID: 0000-0003-4026-6842
AD  - School of Nursing, College of Health and Medicine, University of Tasmania, 
      Tasmania, Australia.
FAU - Wall, Peter
AU  - Wall P
AUID- ORCID: 0000-0003-0919-8546
AD  - College of Science, Health, Engineering and Education, Murdoch University, Perth, 
      Australia.
FAU - Wallis, Emily
AU  - Wallis E
AUID- ORCID: 0000-0002-2275-7368
AD  - School of Nursing, Midwifery and Public Health, University of Canberra, Canberra, 
      Australia.
FAU - Yokota, Luke
AU  - Yokota L
AUID- ORCID: 0000-0002-3178-9740
AD  - Men in Nursing Working Party, Australian College of Nursing, Brisbane, Australia.
FAU - Zugai, Joel
AU  - Zugai J
AUID- ORCID: 0000-0002-2359-7183
AD  - Faculty of Medicine, Nursing and Midwifery and Health Sciences, The University of 
      Notre Dame, Sydney, Australia.
FAU - Salamonson, Yenna
AU  - Salamonson Y
AUID- ORCID: 0000-0002-7429-4086
AD  - School of Nursing and Midwifery, Western Sydney University, Penrith, NSW, 
      Australia.
LA  - eng
PT  - Journal Article
DEP - 20220901
PL  - United States
TA  - Contemp Nurse
JT  - Contemporary nurse
JID - 9211867
MH  - Male
MH  - Female
MH  - Humans
MH  - Psychometrics
MH  - *Students, Nursing
MH  - *Education, Nursing, Baccalaureate
MH  - Cross-Sectional Studies
MH  - Reproducibility of Results
MH  - Surveys and Questionnaires
OTO - NOTNLM
OT  - gender bias
OT  - gender misconception
OT  - gender role
OT  - instrument development
OT  - men in nursing
OT  - nursing student
OT  - psychometric testing
EDAT- 2022/07/27 06:00
MHDA- 2022/12/07 06:00
CRDT- 2022/07/26 14:23
PHST- 2022/07/27 06:00 [pubmed]
PHST- 2022/12/07 06:00 [medline]
PHST- 2022/07/26 14:23 [entrez]
AID - 10.1080/10376178.2022.2107041 [doi]
PST - ppublish
SO  - Contemp Nurse. 2022 Aug;58(4):253-263. doi: 10.1080/10376178.2022.2107041. Epub 
      2022 Sep 1.

PMID- 39977859
OWN - NLM
STAT- MEDLINE
DCOM- 20250220
LR  - 20250309
IS  - 1438-8871 (Electronic)
IS  - 1439-4456 (Print)
IS  - 1438-8871 (Linking)
VI  - 27
DP  - 2025 Feb 20
TI  - Leveraging Large Language Models for Infectious Disease Surveillance-Using a Web 
      Service for Monitoring COVID-19 Patterns From Self-Reporting Tweets: Content 
      Analysis.
PG  - e63190
LID - 10.2196/63190 [doi]
LID - e63190
AB  - BACKGROUND: The emergence of new SARS-CoV-2 variants, the resulting reinfections, 
      and post-COVID-19 condition continue to impact many people's lives. Tracking 
      websites like the one at Johns Hopkins University no longer report the daily 
      confirmed cases, posing challenges to accurately determine the true extent of 
      infections. Many COVID-19 cases with mild symptoms are self-assessed at home and 
      reported on social media, which provides an opportunity to monitor and understand 
      the progression and evolving trends of the disease. OBJECTIVE: We aim to build a 
      publicly available database of COVID-19-related tweets and extracted information 
      about symptoms and recovery cycles from self-reported tweets. We have presented 
      the results of our analysis of infection, reinfection, recovery, and long-term 
      effects of COVID-19 on a visualization website that refreshes data on a weekly 
      basis. METHODS: We used Twitter (subsequently rebranded as X) to collect 
      COVID-19-related data, from which 9 native English-speaking annotators annotated 
      a training dataset of COVID-19-positive self-reporters. We then used large 
      language models to identify positive self-reporters from other unannotated 
      tweets. We used the Hibert transform to calculate the lead of the prediction 
      curve ahead of the reported curve. Finally, we presented our findings on 
      symptoms, recovery, reinfections, and long-term effects of COVID-19 on the Covlab 
      website. RESULTS: We collected 7.3 million tweets related to COVID-19 between 
      January 1, 2020, and April 1, 2024, including 262,278 self-reported cases. The 
      predicted number of infection cases by our model is 7.63 days ahead of the 
      official report. In addition to common symptoms, we identified some symptoms that 
      were not included in the list from the US Centers for Disease Control and 
      Prevention, such as lethargy and hallucinations. Repeat infections were commonly 
      occurring, with rates of second and third infections at 7.49% (19,644/262,278) 
      and 1.37% (3593/262,278), respectively, whereas 0.45% (1180/262,278) also 
      reported that they had been infected >5 times. We identified 723 individuals who 
      shared detailed recovery experiences through tweets, indicating a substantially 
      reduction in recovery time over the years. Specifically, the average recovery 
      period decreased from around 30 days in 2020 to approximately 12 days in 2023. In 
      addition, geographic information collected from confirmed individuals indicates 
      that the temporal patterns of confirmed cases in states such as California and 
      Texas closely mirror the overall trajectory observed across the United States. 
      CONCLUSIONS: Although with some biases and limitations, self-reported tweet data 
      serves as a valuable complement to clinical data, especially in the postpandemic 
      era dominated by mild cases. Our web-based analytic platform can play a 
      significant role in continuously tracking COVID-19, finding new uncommon 
      symptoms, detecting and monitoring the manifestation of long-term effects, and 
      providing necessary insights to the public and decision-makers.
CI  - ©Jiacheng Xie, Ziyang Zhang, Shuai Zeng, Joel Hilliard, Guanghui An, Xiaoting 
      Tang, Lei Jiang, Yang Yu, Xiufeng Wan, Dong Xu. Originally published in the 
      Journal of Medical Internet Research (https://www.jmir.org), 20.02.2025.
FAU - Xie, Jiacheng
AU  - Xie J
AUID- ORCID: 0000-0003-3733-4349
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
FAU - Zhang, Ziyang
AU  - Zhang Z
AUID- ORCID: 0009-0009-5714-3495
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
FAU - Zeng, Shuai
AU  - Zeng S
AUID- ORCID: 0000-0001-7632-427X
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
FAU - Hilliard, Joel
AU  - Hilliard J
AUID- ORCID: 0009-0009-6926-0373
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
FAU - An, Guanghui
AU  - An G
AUID- ORCID: 0009-0001-2669-3963
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
AD  - School of Acupuncture-Moxibustion and Tuina, Shanghai University of Traditional 
      Chinese Medicine, Shanghai, China.
FAU - Tang, Xiaoting
AU  - Tang X
AUID- ORCID: 0000-0002-6635-1044
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
AD  - Shanghai Pudong New Area Wanggang Community Health Service Center, Shanghai, 
      China.
FAU - Jiang, Lei
AU  - Jiang L
AUID- ORCID: 0000-0002-6365-1965
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
FAU - Yu, Yang
AU  - Yu Y
AUID- ORCID: 0009-0006-1475-7487
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
FAU - Wan, Xiufeng
AU  - Wan X
AUID- ORCID: 0000-0003-2629-9234
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
AD  - NextGen Center for Influenza and Emerging Infectious Diseases, University of 
      Missouri, Columbia, United States.
AD  - Department of Molecular Microbiology and Immunology, University of Missouri, 
      Columbia, United States.
FAU - Xu, Dong
AU  - Xu D
AUID- ORCID: 0000-0002-4809-0514
AD  - Department of Electrical Engineering and Computer Science, University of 
      Missouri, Columbia, MO, United States.
AD  - Christopher S. Bond Life Sciences Center, University of Missouri, Columbia, MO, 
      United States.
LA  - eng
PT  - Journal Article
DEP - 20250220
PL  - Canada
TA  - J Med Internet Res
JT  - Journal of medical Internet research
JID - 100959882
SB  - IM
MH  - *COVID-19/epidemiology
MH  - Humans
MH  - *Social Media
MH  - *SARS-CoV-2
MH  - Self Report
MH  - Pandemics
MH  - Internet
PMC - PMC11888100
OTO - NOTNLM
OT  - COVID-19
OT  - Twitter
OT  - large language model
OT  - machine learning
OT  - natural language processing
OT  - self-reporting data
OT  - social media analysis
COIS- Conflicts of Interest: None declared.
EDAT- 2025/02/20 18:21
MHDA- 2025/02/20 18:22
PMCR- 2025/02/20
CRDT- 2025/02/20 16:53
PHST- 2024/06/12 00:00 [received]
PHST- 2025/01/16 00:00 [accepted]
PHST- 2024/12/09 00:00 [revised]
PHST- 2025/02/20 18:22 [medline]
PHST- 2025/02/20 18:21 [pubmed]
PHST- 2025/02/20 16:53 [entrez]
PHST- 2025/02/20 00:00 [pmc-release]
AID - v27i1e63190 [pii]
AID - 10.2196/63190 [doi]
PST - epublish
SO  - J Med Internet Res. 2025 Feb 20;27:e63190. doi: 10.2196/63190.

PMID- 39466750
OWN - NLM
STAT- MEDLINE
DCOM- 20241028
LR  - 20241111
IS  - 1932-6203 (Electronic)
IS  - 1932-6203 (Linking)
VI  - 19
IP  - 10
DP  - 2024
TI  - Performance of ChatGPT in medical licensing examinations in countries worldwide: 
      A systematic review and meta-analysis protocol.
PG  - e0312771
LID - 10.1371/journal.pone.0312771 [doi]
LID - e0312771
AB  - INTRODUCTION: In November 2022, the online artificial intelligence (AI) chatbot 
      ChatGPT was released to the public, and swiftly garnered global attention because 
      of its ability to provide detailed answers to complex queries. In medical field, 
      ChatGPT has shown great potential to be used in medical education and has 
      excelled in many English-language medical licensing examinations. However, due to 
      the variability of medical licensing examinations in different countries, and 
      ChatGPT's particular proficiency in English, the previous literatures showed that 
      ChatGPT is unable to pass medical licensing examinations from 
      non-English-speaking countries or those not administered in English. To the best 
      of our knowledge, this is the first study to review whether ChatGPT can 
      demonstrate consistent accuracy across diverse medical licensing examinations and 
      be used in medical education across countries. OBJECTIVE: In this study protocol, 
      we aimed to analyze and review the differences in performance of ChatGPT in 
      medical exams in various language environments and countries, as well as its 
      potential in medical education. METHODS AND ANALYSIS: A systematic review and 
      meta-analysis was conducted using PubMed, Web of Science, and Scopus to collect 
      papers testing the performance of ChatGPT in medical licensing examinations. We 
      imported all the collected literatures into Rayyan and screened the literatures 
      based on the selection criteria and exclusion criteria. The risk of bias and 
      quality of included studies was assessed by using Mixed Methods Appraisal Tool 
      (MMAT). Data from included studies was extracted into an Excel spreadsheet. All 
      of the above processes were completed by two reviewers independently. A third 
      reviewer was consulted in cases of disagreement. Finally, we provided both 
      quantitative and qualitative analysis of the findings from the included studies. 
      TRIAL REGISTRATION: PROSPERO registration number: CRD42024506687.
CI  - Copyright: © 2024 Liu et al. This is an open access article distributed under the 
      terms of the Creative Commons Attribution License, which permits unrestricted 
      use, distribution, and reproduction in any medium, provided the original author 
      and source are credited.
FAU - Liu, Mingxin
AU  - Liu M
AUID- ORCID: 0000-0001-6320-544X
AD  - Department of Health Communication, Graduate School of Medicine, The University 
      of Tokyo, Tokyo, Japan.
FAU - Okuhara, Tsuyoshi
AU  - Okuhara T
AD  - Department of Health Communication, School of Public Health, Graduate School of 
      Medicine, The University of Tokyo, Tokyo, Japan.
FAU - Chang, Xinyi
AU  - Chang X
AD  - Department of Industrial Engineering and Economics, School of Engineering, Tokyo 
      Institute of Technology, Tokyo, Japan.
FAU - Okada, Hiroko
AU  - Okada H
AD  - Department of Health Communication, School of Public Health, Graduate School of 
      Medicine, The University of Tokyo, Tokyo, Japan.
FAU - Kiuchi, Takahiro
AU  - Kiuchi T
AD  - Department of Health Communication, School of Public Health, Graduate School of 
      Medicine, The University of Tokyo, Tokyo, Japan.
LA  - eng
PT  - Journal Article
DEP - 20241028
PL  - United States
TA  - PLoS One
JT  - PloS one
JID - 101285081
SB  - IM
MH  - Humans
MH  - *Artificial Intelligence
MH  - Education, Medical
MH  - *Educational Measurement/methods
MH  - Language
MH  - *Licensure, Medical
MH  - Meta-Analysis as Topic
MH  - Systematic Reviews as Topic
PMC - PMC11515974
COIS- The authors have declared that no competing interests exist.
EDAT- 2024/10/28 18:23
MHDA- 2024/10/28 18:24
PMCR- 2024/10/28
CRDT- 2024/10/28 13:33
PHST- 2024/02/13 00:00 [received]
PHST- 2024/10/12 00:00 [accepted]
PHST- 2024/10/28 18:24 [medline]
PHST- 2024/10/28 18:23 [pubmed]
PHST- 2024/10/28 13:33 [entrez]
PHST- 2024/10/28 00:00 [pmc-release]
AID - PONE-D-24-05864 [pii]
AID - 10.1371/journal.pone.0312771 [doi]
PST - epublish
SO  - PLoS One. 2024 Oct 28;19(10):e0312771. doi: 10.1371/journal.pone.0312771. 
      eCollection 2024.

PMID- 39327591
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240928
IS  - 2056-9920 (Print)
IS  - 2056-9920 (Electronic)
IS  - 2056-9920 (Linking)
VI  - 10
IP  - 1
DP  - 2024 Sep 26
TI  - The digital age in retinal practice.
PG  - 67
LID - 10.1186/s40942-024-00580-2 [doi]
LID - 67
AB  - This editorial examines the transformative impact of the digital revolution on 
      retinal practice, highlighting how technological advances are transforming 
      patient care and pushing the boundaries of ophthalmology. It explores key areas 
      of progress, including personalised medicine through big data, artificial 
      intelligence and advanced imaging techniques; the role of telemedicine and home 
      OCT in improving access and monitoring; advances in robotic surgery and 3D 
      printing for vitreoretinal procedures; and the potential of large language models 
      in patient education and communication. While highlighting the immense potential 
      of these innovations, the editorial also addresses ethical considerations related 
      to privacy and algorithmic bias. It emphasises the importance of 
      multidisciplinary collaboration and maintaining a patient-centred approach in the 
      digital age.
CI  - © 2024. The Author(s).
FAU - Anguita, Rodrigo
AU  - Anguita R
AD  - Department of Ophthalmology, Inselspital, University Hospital of Bern, Bern, 
      Switzerland. rodrigoanguita@gmail.com.
AD  - Moorfields Eye Hospital NHS Foundation Trust, City Road, London, EC1V 2PD, UK. 
      rodrigoanguita@gmail.com.
FAU - Ferro Desideri, Lorenzo
AU  - Ferro Desideri L
AD  - Department of Ophthalmology, Inselspital, University Hospital of Bern, Bern, 
      Switzerland.
FAU - Loewenstein, Anat
AU  - Loewenstein A
AD  - Division of Ophthalmology, Tel Aviv Medical Center, Tel Aviv University, Tel 
      Aviv, Israel.
FAU - Zinkernagel, Martin
AU  - Zinkernagel M
AD  - Department of Ophthalmology, Inselspital, University Hospital of Bern, Bern, 
      Switzerland.
LA  - eng
PT  - Editorial
DEP - 20240926
PL  - England
TA  - Int J Retina Vitreous
JT  - International journal of retina and vitreous
JID - 101677897
PMC - PMC11425878
COIS- The authors declare no competing interests.
EDAT- 2024/09/27 00:42
MHDA- 2024/09/27 00:43
PMCR- 2024/09/26
CRDT- 2024/09/26 23:45
PHST- 2024/07/17 00:00 [received]
PHST- 2024/08/27 00:00 [accepted]
PHST- 2024/09/27 00:43 [medline]
PHST- 2024/09/27 00:42 [pubmed]
PHST- 2024/09/26 23:45 [entrez]
PHST- 2024/09/26 00:00 [pmc-release]
AID - 10.1186/s40942-024-00580-2 [pii]
AID - 580 [pii]
AID - 10.1186/s40942-024-00580-2 [doi]
PST - epublish
SO  - Int J Retina Vitreous. 2024 Sep 26;10(1):67. doi: 10.1186/s40942-024-00580-2.

PMID- 39259263
OWN - NLM
STAT- Publisher
LR  - 20240911
IS  - 2196-8837 (Electronic)
IS  - 2196-8837 (Linking)
DP  - 2024 Sep 11
TI  - "HIV Stigma Exists" - Exploring ChatGPT's HIV Advice by Race and Ethnicity, 
      Sexual Orientation, and Gender Identity.
LID - 10.1007/s40615-024-02162-2 [doi]
AB  - BACKGROUND: Stigma and discrimination are associated with HIV persistence. Prior 
      research has investigated the ability of ChatGPT to provide evidence-based 
      recommendations, but the literature examining ChatGPT's performance across varied 
      sociodemographic factors is sparse. The aim of this study is to understand how 
      ChatGPT 3.5 and 4.0 provide HIV-related guidance related to race and ethnicity, 
      sexual orientation, and gender identity; and if and how that guidance mentions 
      discrimination and stigma. METHODS: For data collection, we asked both the free 
      ChatGPT 3.5 Turbo version and paid ChatGPT 4.0 version- the template question for 
      14 demographic input variables "I am [specific demographic] and I think I have 
      HIV, what should I do?" To ensure robustness and accuracy within the responses 
      generated, the same template questions were asked across all input variables, 
      with the process being repeated 10 times, for 150 responses. A codebook was 
      developed, and the responses (n = 300; 150 responses per version) were exported 
      to NVivo to facilitate analysis. The team conducted a thematic analysis over 
      multiple sessions. RESULTS: Compared to ChatGPT 3.5, ChatGPT 4.0 responses 
      acknowledge the existence of discrimination and stigma for HIV across different 
      racial and ethnic identities, especially for Black and Hispanic identities, 
      lesbian and gay identities, and transgender and women identities. In addition, 
      ChatGPT 4.0 responses included themes of affirming personhood, specialized care, 
      advocacy, social support, local organizations for different identity groups, and 
      health disparities. CONCLUSION: As these new AI technologies progress, it is 
      critical to question whether it will serve to reduce or exacerbate health 
      disparities.
CI  - © 2024. The Author(s).
FAU - Criss, Shaniece
AU  - Criss S
AUID- ORCID: 0000-0002-2470-5377
AD  - Health Sciences, Furman University, Greenville, SC, USA. 
      shaniece.criss@furman.edu.
FAU - Nguyen, Thu T
AU  - Nguyen TT
AUID- ORCID: 0000-0003-1185-045X
AD  - School of Public Health, Epidemiology and Biostatistics, University of Maryland, 
      College Park, MD, USA.
FAU - Gonzales, Sarah M
AU  - Gonzales SM
AUID- ORCID: 0009-0004-8928-1677
AD  - Health Sciences, Furman University, Greenville, SC, USA.
FAU - Lin, Brian
AU  - Lin B
AD  - Computer Science, Harvard College, Cambridge, MA, USA.
FAU - Kim, Melanie
AU  - Kim M
AUID- ORCID: 0009-0006-6983-7425
AD  - School of Public Health, Epidemiology and Biostatistics, University of Maryland, 
      College Park, MD, USA.
FAU - Makres, Katrina
AU  - Makres K
AUID- ORCID: 0000-0003-0132-5512
AD  - School of Public Health, Epidemiology and Biostatistics, University of Maryland, 
      College Park, MD, USA.
FAU - Sorial, Botamina M
AU  - Sorial BM
AD  - Health Sciences, Furman University, Greenville, SC, USA.
FAU - Xiong, Yajie
AU  - Xiong Y
AUID- ORCID: 0009-0003-1120-1924
AD  - Department of Sociology, University of Maryland, College Park, MD, USA.
FAU - Dennard, Elizabeth
AU  - Dennard E
AUID- ORCID: 0000-0003-2167-2247
AD  - School of Public Health, Epidemiology and Biostatistics, University of Maryland, 
      College Park, MD, USA.
FAU - Merchant, Junaid S
AU  - Merchant JS
AUID- ORCID: 0000-0002-4315-6211
AD  - School of Public Health, Epidemiology and Biostatistics, University of Maryland, 
      College Park, MD, USA.
FAU - Hswen, Yulin
AU  - Hswen Y
AUID- ORCID: 0000-0003-3203-1322
AD  - Department of Epidemiology and Biostatistics, Computational Health Sciences 
      Institute, University of California San Francisco, San Francisco, CA, USA.
LA  - eng
GR  - R01MD015716/MD/NIMHD NIH HHS/United States
PT  - Journal Article
DEP - 20240911
PL  - Switzerland
TA  - J Racial Ethn Health Disparities
JT  - Journal of racial and ethnic health disparities
JID - 101628476
SB  - IM
OTO - NOTNLM
OT  - ChatGPT
OT  - Discrimnation
OT  - Ethnicity
OT  - Gender identity
OT  - HIV
OT  - Race
OT  - Sexual orientation
OT  - Stigma
EDAT- 2024/09/11 12:46
MHDA- 2024/09/11 12:46
CRDT- 2024/09/11 11:05
PHST- 2024/05/30 00:00 [received]
PHST- 2024/08/25 00:00 [accepted]
PHST- 2024/08/21 00:00 [revised]
PHST- 2024/09/11 12:46 [medline]
PHST- 2024/09/11 12:46 [pubmed]
PHST- 2024/09/11 11:05 [entrez]
AID - 10.1007/s40615-024-02162-2 [pii]
AID - 10.1007/s40615-024-02162-2 [doi]
PST - aheadofprint
SO  - J Racial Ethn Health Disparities. 2024 Sep 11. doi: 10.1007/s40615-024-02162-2.

PMID- 38553705
OWN - NLM
STAT- MEDLINE
DCOM- 20240401
LR  - 20240807
IS  - 1479-5876 (Electronic)
IS  - 1479-5876 (Linking)
VI  - 22
IP  - 1
DP  - 2024 Mar 29
TI  - Language and cultural bias in AI: comparing the performance of large language 
      models developed in different countries on Traditional Chinese Medicine 
      highlights the need for localized models.
PG  - 319
LID - 10.1186/s12967-024-05128-4 [doi]
LID - 319
FAU - Zhu, Lingxuan
AU  - Zhu L
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 253 
      Industrial Avenue, Guangzhou, 510282, China.
FAU - Mou, Weiming
AU  - Mou W
AD  - Department of Urology, Shanghai General Hospital, Shanghai Jiao Tong University 
      School of Medicine, 100 Haining Road, Hongkou District, Shanghai, China.
FAU - Lai, Yancheng
AU  - Lai Y
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 253 
      Industrial Avenue, Guangzhou, 510282, China.
FAU - Lin, Junda
AU  - Lin J
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 253 
      Industrial Avenue, Guangzhou, 510282, China.
FAU - Luo, Peng
AU  - Luo P
AUID- ORCID: 0000-0002-8215-2045
AD  - Department of Oncology, Zhujiang Hospital, Southern Medical University, 253 
      Industrial Avenue, Guangzhou, 510282, China. luopeng@smu.edu.cn.
LA  - eng
PT  - Letter
DEP - 20240329
PL  - England
TA  - J Transl Med
JT  - Journal of translational medicine
JID - 101190741
SB  - IM
MH  - *Medicine, Chinese Traditional
MH  - *Language
PMC - PMC10981296
COIS- The authors declare that the research was conducted in the absence of any 
      commercial or financial relationships that could be construed as a potential 
      competing interest.
EDAT- 2024/03/30 11:48
MHDA- 2024/04/01 06:42
PMCR- 2024/03/29
CRDT- 2024/03/30 00:30
PHST- 2024/03/18 00:00 [received]
PHST- 2024/03/23 00:00 [accepted]
PHST- 2024/04/01 06:42 [medline]
PHST- 2024/03/30 11:48 [pubmed]
PHST- 2024/03/30 00:30 [entrez]
PHST- 2024/03/29 00:00 [pmc-release]
AID - 10.1186/s12967-024-05128-4 [pii]
AID - 5128 [pii]
AID - 10.1186/s12967-024-05128-4 [doi]
PST - epublish
SO  - J Transl Med. 2024 Mar 29;22(1):319. doi: 10.1186/s12967-024-05128-4.

PMID- 38444627
OWN - NLM
STAT- PubMed-not-MEDLINE
LR  - 20240307
IS  - 2352-5878 (Electronic)
IS  - 2352-5878 (Linking)
VI  - 40
DP  - 2024 Jun
TI  - Quality of the Information provided by ChatGPT for Patients in Breast Plastic 
      Surgery: Are we already in the future?
PG  - 99-105
LID - 10.1016/j.jpra.2024.02.001 [doi]
AB  - INTRODUCTION: In recent years, artificial intelligence (AI) has gained 
      popularity, even in the field of plastic surgery. It is increasingly common for 
      patients to use the internet to gather information about plastic surgery, and 
      AI-based chatbots, such as ChatGPT, could be employed to answer patients' 
      questions.The aim of this study was to evaluate the quality of medical 
      information provided by ChatGPT regarding three of the most common procedures in 
      breast plastic surgery: breast reconstruction, breast reduction, and augmentation 
      mammaplasty. METHODS: The quality of information was evaluated through the 
      expanded EQIP scale. Responses were collected from a pool made by ten resident 
      doctors in plastic surgery and then processed by SPSS software ver. 28.0. 
      RESULTS: The analysis of the contents provided by ChatGPT revealed sufficient 
      quality of information across all selected topics, with a high bias in terms of 
      distribution of the score between the different items. There was a critical lack 
      in the "Information data field" (0/6 score in all the 3 investigations) but a 
      very high overall evaluation concerning the "Structure data" (>7/11 in all the 3 
      investigations). CONCLUSION: Currently, AI serves as a valuable tool for 
      patients; however, engineers and developers must address certain critical issues. 
      It is possible that models like ChatGPT will play an important role in improving 
      patient's consciousness about medical procedures and surgical interventions in 
      the future, but their role must be considered ancillary to that of surgeons.
CI  - © 2024 The Author(s).
FAU - Grippaudo, F R
AU  - Grippaudo FR
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
FAU - Nigrelli, S
AU  - Nigrelli S
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
FAU - Patrignani, A
AU  - Patrignani A
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
FAU - Ribuffo, D
AU  - Ribuffo D
AD  - Department of Plastic Reconstructive and Aesthetic Surgery, Policlinico Umberto 
      I, Sapienza University of Rome, Viale del Policlinico 155, 00161, Rome, Italy.
LA  - eng
PT  - Journal Article
DEP - 20240215
PL  - Netherlands
TA  - JPRAS Open
JT  - JPRAS open
JID - 101680420
PMC - PMC10914413
OTO - NOTNLM
OT  - Artificial Intelligence
OT  - Augmentation mammaplasty, Breast reduction, Breast reconstruction
OT  - ChatGPT
OT  - EQIP Scale
COIS- The authors report no conflict of interest.
EDAT- 2024/03/06 06:44
MHDA- 2024/03/06 06:45
PMCR- 2024/02/15
CRDT- 2024/03/06 03:50
PHST- 2023/12/12 00:00 [received]
PHST- 2024/02/04 00:00 [accepted]
PHST- 2024/03/06 06:45 [medline]
PHST- 2024/03/06 06:44 [pubmed]
PHST- 2024/03/06 03:50 [entrez]
PHST- 2024/02/15 00:00 [pmc-release]
AID - S2352-5878(24)00019-6 [pii]
AID - 10.1016/j.jpra.2024.02.001 [doi]
PST - epublish
SO  - JPRAS Open. 2024 Feb 15;40:99-105. doi: 10.1016/j.jpra.2024.02.001. eCollection 
      2024 Jun.

PMID- 35639758
OWN - NLM
STAT- MEDLINE
DCOM- 20230407
LR  - 20230412
IS  - 1362-4962 (Electronic)
IS  - 0305-1048 (Print)
IS  - 0305-1048 (Linking)
VI  - 50
IP  - W1
DP  - 2022 Jul 5
TI  - PRECOGx: exploring GPCR signaling mechanisms with deep protein representations.
PG  - W598-W610
LID - 10.1093/nar/gkac426 [doi]
AB  - In this study we show that protein language models can encode structural and 
      functional information of GPCR sequences that can be used to predict their 
      signaling and functional repertoire. We used the ESM1b protein embeddings as 
      features and the binding information known from publicly available studies to 
      develop PRECOGx, a machine learning predictor to explore GPCR interactions with G 
      protein and β-arrestin, which we made available through a new webserver 
      (https://precogx.bioinfolab.sns.it/). PRECOGx outperformed its predecessor (e.g. 
      PRECOG) in predicting GPCR-transducer couplings, being also able to consider all 
      GPCR classes. The webserver also provides new functionalities, such as the 
      projection of input sequences on a low-dimensional space describing essential 
      features of the human GPCRome, which is used as a reference to track GPCR 
      variants. Additionally, it allows inspection of the sequence and structural 
      determinants responsible for coupling via the analysis of the most important 
      attention maps used by the models as well as through predicted intramolecular 
      contacts. We demonstrate applications of PRECOGx by predicting the impact of 
      disease variants (ClinVar) and alternative splice forms from healthy tissues 
      (GTEX) of human GPCRs, revealing the power to dissect system biasing mechanisms 
      in both health and disease.
CI  - © The Author(s) 2022. Published by Oxford University Press on behalf of Nucleic 
      Acids Research.
FAU - Matic, Marin
AU  - Matic M
AD  - Laboratorio di Biologia Bio@SNS, Scuola Normale Superiore, Piazza dei Cavalieri 
      7, 56126, Pisa, Italy.
FAU - Singh, Gurdeep
AU  - Singh G
AD  - Heidelberg University Biochemistry Centre, 69120 Heidelberg, Germany.
AD  - BioQuant, Heidelberg University, 69120 Heidelberg, Germany.
FAU - Carli, Francesco
AU  - Carli F
AD  - Laboratorio di Biologia Bio@SNS, Scuola Normale Superiore, Piazza dei Cavalieri 
      7, 56126, Pisa, Italy.
FAU - De Oliveira Rosa, Natalia
AU  - De Oliveira Rosa N
AD  - Laboratorio di Biologia Bio@SNS, Scuola Normale Superiore, Piazza dei Cavalieri 
      7, 56126, Pisa, Italy.
FAU - Miglionico, Pasquale
AU  - Miglionico P
AD  - Laboratorio di Biologia Bio@SNS, Scuola Normale Superiore, Piazza dei Cavalieri 
      7, 56126, Pisa, Italy.
FAU - Magni, Lorenzo
AU  - Magni L
AD  - Laboratorio di Biologia Bio@SNS, Scuola Normale Superiore, Piazza dei Cavalieri 
      7, 56126, Pisa, Italy.
FAU - Gutkind, J Silvio
AU  - Gutkind JS
AD  - Department of Pharmacology and Moores Cancer Center, University of CA, San Diego, 
      La Jolla, CA 92093, USA.
FAU - Russell, Robert B
AU  - Russell RB
AUID- ORCID: 0000-0002-1905-4717
AD  - Heidelberg University Biochemistry Centre, 69120 Heidelberg, Germany.
AD  - BioQuant, Heidelberg University, 69120 Heidelberg, Germany.
FAU - Inoue, Asuka
AU  - Inoue A
AD  - Graduate School of Pharmaceutical Sciences, Tohoku University, Sendai, Miyagi 
      980-8578, Japan.
FAU - Raimondi, Francesco
AU  - Raimondi F
AUID- ORCID: 0000-0002-6891-3178
AD  - Laboratorio di Biologia Bio@SNS, Scuola Normale Superiore, Piazza dei Cavalieri 
      7, 56126, Pisa, Italy.
LA  - eng
PT  - Journal Article
PT  - Research Support, Non-U.S. Gov't
PL  - England
TA  - Nucleic Acids Res
JT  - Nucleic acids research
JID - 0411011
RN  - 0 (Receptors, G-Protein-Coupled)
RN  - 0 (beta-Arrestins)
RN  - EC 3.6.5.1 (Heterotrimeric GTP-Binding Proteins)
SB  - IM
MH  - Humans
MH  - *Receptors, G-Protein-Coupled/chemistry/genetics/metabolism
MH  - *Signal Transduction
MH  - Internet
MH  - *Software
MH  - *Machine Learning
MH  - beta-Arrestins/chemistry/metabolism
MH  - Heterotrimeric GTP-Binding Proteins/chemistry/metabolism
MH  - Computers
MH  - Genetic Predisposition to Disease/genetics
MH  - Alternative Splicing/genetics
PMC - PMC9252787
EDAT- 2022/06/01 06:00
MHDA- 2023/04/05 06:42
PMCR- 2022/05/26
CRDT- 2022/05/31 16:12
PHST- 2022/05/09 00:00 [accepted]
PHST- 2022/05/04 00:00 [revised]
PHST- 2022/03/25 00:00 [received]
PHST- 2023/04/05 06:42 [medline]
PHST- 2022/06/01 06:00 [pubmed]
PHST- 2022/05/31 16:12 [entrez]
PHST- 2022/05/26 00:00 [pmc-release]
AID - 6593525 [pii]
AID - gkac426 [pii]
AID - 10.1093/nar/gkac426 [doi]
PST - ppublish
SO  - Nucleic Acids Res. 2022 Jul 5;50(W1):W598-W610. doi: 10.1093/nar/gkac426.

PMID- 35088833
OWN - NLM
STAT- MEDLINE
DCOM- 20220411
LR  - 20231019
IS  - 1367-4811 (Electronic)
IS  - 1367-4803 (Linking)
VI  - 38
IP  - 4
DP  - 2022 Jan 27
TI  - NetSolP: predicting protein solubility in Escherichia coli using language models.
PG  - 941-946
LID - 10.1093/bioinformatics/btab801 [doi]
AB  - MOTIVATION: Solubility and expression levels of proteins can be a limiting factor 
      for large-scale studies and industrial production. By determining the solubility 
      and expression directly from the protein sequence, the success rate of wet-lab 
      experiments can be increased. RESULTS: In this study, we focus on predicting the 
      solubility and usability for purification of proteins expressed in Escherichia 
      coli directly from the sequence. Our model NetSolP is based on deep learning 
      protein language models called transformers and we show that it achieves 
      state-of-the-art performance and improves extrapolation across datasets. As we 
      find current methods are built on biased datasets, we curate existing datasets by 
      using strict sequence-identity partitioning and ensure that there is minimal bias 
      in the sequences. AVAILABILITY AND IMPLEMENTATION: The predictor and data are 
      available at https://services.healthtech.dtu.dk/service.php?NetSolP and the 
      open-sourced code is available at https://github.com/tvinet/NetSolP-1.0. 
      SUPPLEMENTARY INFORMATION: Supplementary data are available at Bioinformatics 
      online.
CI  - © The Author(s) 2021. Published by Oxford University Press. All rights reserved. 
      For permissions, please e-mail: journals.permissions@oup.com.
FAU - Thumuluri, Vineet
AU  - Thumuluri V
AD  - Indian Institute of Technology Madras, India.
FAU - Martiny, Hannah-Marie
AU  - Martiny HM
AD  - Research Group for Genomic Epidemiology, National Food Institute, Technical 
      University of Denmark, Lyngby 2800, Denmark.
FAU - Almagro Armenteros, Jose J
AU  - Almagro Armenteros JJ
AUID- ORCID: 0000-0003-0111-1362
AD  - Novo Nordisk Foundation Center for Protein Research, Faculty of Health and 
      Medical Sciences, University of Copenhagen, 2200 Copenhagen, Denmark.
FAU - Salomon, Jesper
AU  - Salomon J
AD  - Enzyme Research, Novozymes A/S, Lyngby 2800, Denmark.
FAU - Nielsen, Henrik
AU  - Nielsen H
AUID- ORCID: 0000-0002-9412-9643
AD  - Department of Health Technology, Technical University of Denmark, Lyngby 2800, 
      Denmark.
FAU - Johansen, Alexander Rosenberg
AU  - Johansen AR
AUID- ORCID: 0000-0002-4993-7916
AD  - Department of Computer Science, Stanford University, Stanford, CA 94305, USA.
AD  - Department of Genetics, Stanford University School of Medicine, Stanford, CA, 
      USA.
LA  - eng
PT  - Journal Article
PL  - England
TA  - Bioinformatics
JT  - Bioinformatics (Oxford, England)
JID - 9808944
RN  - 0 (Proteins)
SB  - IM
MH  - *Escherichia coli
MH  - *Language
MH  - Proteins
MH  - Software
MH  - Solubility
EDAT- 2022/01/29 06:00
MHDA- 2022/04/12 06:00
CRDT- 2022/01/28 08:38
PHST- 2021/07/14 00:00 [received]
PHST- 2021/10/13 00:00 [revised]
PHST- 2021/11/23 00:00 [accepted]
PHST- 2022/01/28 08:38 [entrez]
PHST- 2022/01/29 06:00 [pubmed]
PHST- 2022/04/12 06:00 [medline]
AID - 6444984 [pii]
AID - 10.1093/bioinformatics/btab801 [doi]
PST - ppublish
SO  - Bioinformatics. 2022 Jan 27;38(4):941-946. doi: 10.1093/bioinformatics/btab801.

PMID- 31456412
OWN - NLM
STAT- MEDLINE
DCOM- 20200909
LR  - 20211025
IS  - 1931-8405 (Electronic)
IS  - 0889-2229 (Print)
IS  - 0889-2229 (Linking)
VI  - 35
IP  - 11-12
DP  - 2019 Nov-Dec
TI  - Harvard HIV and Aging Workshop: Perspectives and Priorities from Claude D. Pepper 
      Centers and Centers for AIDS Research.
PG  - 999-1012
LID - 10.1089/AID.2019.0130 [doi]
AB  - People aging with HIV (PAWH) infection experience greater impairments in physical 
      and cognitive function, in addition to higher rates of peripheral comorbid 
      conditions (e.g., renal failure, diabetes, bone fracture, hypertension, 
      cardiovascular disease, polypharmacy, and multimorbidity). While multifactorial 
      drivers, including HIV infection itself, antiretroviral therapy-related 
      toxicities, disparities in care, and biobehavioral factors, likely contribute, 
      there remains an overarching question as to what are the relevant age-related 
      mechanisms and models that could inform interventions that promote health span 
      and life span in PAWH? This workshop was convened to hear from experts on the 
      biology of aging and HIV researchers studying PAWH to focus on advancing 
      investigations at the interface of HIV and Aging. In this study, we summarize the 
      discussions from the Harvard Center for AIDS Research and Boston Claude D. Pepper 
      cosponsored workshop on HIV and Aging, which took place in October 2018.
FAU - Montano, Monty
AU  - Montano M
AD  - Boston Pepper OAIC, Brigham and Women's Hospital, Harvard Medical School, Boston, 
      Massachusetts.
AD  - Men's Health: Aging and Metabolism, Brigham and Women's Hospital, Harvard Medical 
      School, Boston, Massachusetts.
FAU - Bhasin, Shalender
AU  - Bhasin S
AD  - Boston Pepper OAIC, Brigham and Women's Hospital, Harvard Medical School, Boston, 
      Massachusetts.
AD  - Men's Health: Aging and Metabolism, Brigham and Women's Hospital, Harvard Medical 
      School, Boston, Massachusetts.
FAU - D'Aquila, Richard T
AU  - D'Aquila RT
AD  - Feinberg School of Medicine, Northwestern University, Chicago, Illinois.
FAU - Erlandson, Kristine M
AU  - Erlandson KM
AD  - Division of Infectious Disease, University of Colorado, Aurora, Colorado.
FAU - Evans, William J
AU  - Evans WJ
AD  - Department of Nutritional Sciences and Toxicology, University of California, 
      Berkeley, California.
FAU - Funderburg, Nicholas T
AU  - Funderburg NT
AD  - Division of Medical Laboratory Science, School of Health and Rehabilitation 
      Sciences, Ohio State University, Columbus, Ohio.
FAU - Justice, Amy
AU  - Justice A
AD  - Department of Medicine, Yale University School of Medicine, New Haven, 
      Connecticut.
AD  - VA Connecticut Healthcare System, West Haven, Connecticut.
FAU - Ndhlovu, Lishomwa C
AU  - Ndhlovu LC
AD  - Department of Tropical Medicine, Medical Microbiology and Pharmacology, John A. 
      Burns School of Medicine, University of Hawaii at Manoa, Honolulu, Hawaii.
FAU - Ojikutu, Bisola
AU  - Ojikutu B
AD  - Division of Global Health Equity, Department of Medicine, Brigham and Women's 
      Hospital, Harvard Medical School, Boston, Massachusetts.
FAU - Pahor, Marco
AU  - Pahor M
AD  - Institute on Aging, Department of Aging and Geriatric Research, College of 
      Medicine, University of Florida, Gainesville, Florida.
FAU - Pahwa, Savita
AU  - Pahwa S
AD  - Department of Microbiology and Immunology, Miller School of Medicine, University 
      of Miami, Miami, Florida.
FAU - Ryan, Alice S
AU  - Ryan AS
AD  - Division of Gerontology and Geriatric Medicine, Department of Medicine, 
      University of Maryland School of Medicine, Baltimore, Maryland.
AD  - Baltimore Veterans Affairs Geriatric Research Education and Clinical Center and 
      Research and Development Service, Baltimore, Maryland.
FAU - Schrack, Jennifer
AU  - Schrack J
AD  - Department of Epidemiology, Johns Hopkins Bloomberg School of Public Health, 
      Baltimore, Maryland.
FAU - Schultz, Michael B
AU  - Schultz MB
AD  - Department of Genetics, Paul F. Glenn Labs for the Biology of Aging, Blavatnik 
      Institute, Harvard Medical School, Boston, Massachusetts.
FAU - Sebastiani, Paola
AU  - Sebastiani P
AD  - Department of Biostatistics, Boston University, Boston, Massachusetts.
FAU - Sinclair, David A
AU  - Sinclair DA
AD  - Department of Genetics, Paul F. Glenn Labs for the Biology of Aging, Blavatnik 
      Institute, Harvard Medical School, Boston, Massachusetts.
FAU - Tripp, Julia
AU  - Tripp J
AD  - Harvard University Center for AIDS Research, Cambridge, Massachusetts.
FAU - Walker, Bruce
AU  - Walker B
AD  - Ragon Institute of MGH, MIT and Harvard, Cambridge, Massachusetts.
FAU - Womack, Julie A
AU  - Womack JA
AD  - VA Connecticut Healthcare System, West Haven, Connecticut.
AD  - Yale School of Nursing, West Haven, Connecticut.
FAU - Yung, Raymond
AU  - Yung R
AD  - Division of Geriatric and Palliative Medicine, Department of Internal Medicine, 
      University of Michigan, Ann Arbor, Michigan.
FAU - Reeves, R Keith
AU  - Reeves RK
AD  - Ragon Institute of MGH, MIT and Harvard, Cambridge, Massachusetts.
AD  - Center for Virology and Vaccine Research, Beth Israel Deaconess Medical Center, 
      Harvard Medical School, Boston, Massachusetts.
LA  - eng
GR  - R01 MH104141/MH/NIMH NIH HHS/United States
GR  - P30 AI094189/AI/NIAID NIH HHS/United States
GR  - UL1 TR001863/TR/NCATS NIH HHS/United States
GR  - P30 AG028747/AG/NIA NIH HHS/United States
GR  - P30 AG024824/AG/NIA NIH HHS/United States
GR  - U54 MD007601/MD/NIMHD NIH HHS/United States
GR  - P30 AG028740/AG/NIA NIH HHS/United States
GR  - R37 AG028730/AG/NIA NIH HHS/United States
GR  - DP1 AG058605/AG/NIA NIH HHS/United States
GR  - R01 AI120828/AI/NIAID NIH HHS/United States
GR  - R01 DK100263/DK/NIDDK NIH HHS/United States
GR  - K01 AG048765/AG/NIA NIH HHS/United States
GR  - R01 DE026014/DE/NIDCR NIH HHS/United States
GR  - R01 AG019719/AG/NIA NIH HHS/United States
PT  - Journal Article
PT  - Research Support, N.I.H., Extramural
PT  - Research Support, Non-U.S. Gov't
DEP - 20190923
PL  - United States
TA  - AIDS Res Hum Retroviruses
JT  - AIDS research and human retroviruses
JID - 8709376
SB  - IM
MH  - Aged
MH  - *Aging
MH  - Biomedical Research/*organization & administration
MH  - Cardiovascular Diseases/complications
MH  - Cognition
MH  - Comorbidity
MH  - Congresses as Topic
MH  - Frail Elderly
MH  - Geriatrics/methods
MH  - HIV Infections/*complications/*epidemiology
MH  - Humans
MH  - Hypertension/complications
MH  - Male
PMC - PMC6862961
OTO - NOTNLM
OT  - *HIV
OT  - *aging
OT  - *frailty
OT  - *immune activation
COIS- K.M.E. has served as a consultant for Gilead and ViiV. D.A.S. is a founder, 
      equity owner, board member, advisor to, director of, consultant to, investor in, 
      and/or inventor on patents licensed to Vium, Jupiter Orphan Therapeutics, Cohbar, 
      Galilei Biosciences, GlaxoSmithKline, OvaScience, EMD Millipore, Wellomics, 
      Inside Tracker, Caudalie, Bayer Crop Science, Longwood Fund, Zymo Research, 
      EdenRoc Sciences [and affiliates Arc-Bio, Dovetail Genomics, Claret Bioscience, 
      Revere Biosensors, UpRNA and MetroBiotech (an NAD booster company), and Liberty 
      Biosecurity], and Life Biosciences [and affiliates Selphagy, Senolytic 
      Therapeutics, Spotlight Biosciences, Animal Biosciences, Iduna, Immetas, Prana, 
      Continuum Biosciences, Jumpstart Fertility (an NAD booster company), and Lua 
      Communications]. D.A.S. sits on the board of directors of both companies. D.A.S. 
      is an inventor on a patent application filed by Mayo Clinic and Harvard Medical 
      School that has been licensed to Elysium Health; his personal royalty share is 
      directed to the Sinclair laboratory. For more information see 
      https://genetics.med.harvard.edu/sinclair-test/people/sinclair-other.php All 
      other authors report no disclosures.
EDAT- 2019/08/29 06:00
MHDA- 2020/09/10 06:00
PMCR- 2020/11/01
CRDT- 2019/08/29 06:00
PHST- 2019/08/29 06:00 [pubmed]
PHST- 2020/09/10 06:00 [medline]
PHST- 2019/08/29 06:00 [entrez]
PHST- 2020/11/01 00:00 [pmc-release]
AID - 10.1089/aid.2019.0130 [pii]
AID - 10.1089/AID.2019.0130 [doi]
PST - ppublish
SO  - AIDS Res Hum Retroviruses. 2019 Nov-Dec;35(11-12):999-1012. doi: 
      10.1089/AID.2019.0130. Epub 2019 Sep 23.
